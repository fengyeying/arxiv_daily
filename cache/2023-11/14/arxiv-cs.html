<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Fri 10 Nov 23  to  Mon 13 Nov 23, announced Tue, 14 Nov 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item548">Cross-lists</a></li>
<li><a href="#item635">Replacements</a></li>
</ul>
<small>[ total of 987 entries:  <b>1-987</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Tue, 14 Nov 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06246" title="Abstract">arXiv:2311.06246</a> [<a href="/pdf/2311.06246" title="Download PDF">pdf</a>, <a href="/ps/2311.06246" title="Download PostScript">ps</a>, <a href="/format/2311.06246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Theoretical Framework for Simulating Organizations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Palma%2C+E+B">Edmundo Barrientos Palma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 2 figures, Chilean Conference Operational Research - OPTIMA 2005
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">This work proposes a theoretical framework using a systemic modeling paradigm
to implement computational agents in the simulation of organizations. The
potential of its use is demonstrated in the modeling of supply chains. Finally,
research tending to develop an organizational modeling system in real-time is
proposed.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06250" title="Abstract">arXiv:2311.06250</a> [<a href="/pdf/2311.06250" title="Download PDF">pdf</a>, <a href="/ps/2311.06250" title="Download PostScript">ps</a>, <a href="/format/2311.06250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Do You Care About: Inferring Values from Emotions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jieting Luo</a>, 
<a href="/search/cs?searchtype=author&query=Dastani%2C+M">Mehdi Dastani</a>, 
<a href="/search/cs?searchtype=author&query=Studer%2C+T">Thomas Studer</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+B">Beishui Liao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">Observers can glean information from others' emotional expressions through
the act of drawing inferences from another individual's emotional expressions.
It is important for socially aware artificial systems to be capable of doing
that as it can facilitate social interaction among agents, and is particularly
important in human-robot interaction for supporting a more personalized
treatment of users. In this short paper, we propose a methodology for
developing a formal model that allows agents to infer another agent's values
from her emotion expressions.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06255" title="Abstract">arXiv:2311.06255</a> [<a href="/pdf/2311.06255" title="Download PDF">pdf</a>, <a href="/ps/2311.06255" title="Download PostScript">ps</a>, <a href="/format/2311.06255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy-Engineered Value Decomposition Networks for Cooperative  Multi-Agent Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gohari%2C+P">Parham Gohari</a>, 
<a href="/search/cs?searchtype=author&query=Hale%2C+M">Matthew Hale</a>, 
<a href="/search/cs?searchtype=author&query=Topcu%2C+U">Ufuk Topcu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted at 62nd IEEE Conference on Decision and Control
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In cooperative multi-agent reinforcement learning (Co-MARL), a team of agents
must jointly optimize the team's long-term rewards to learn a designated task.
Optimizing rewards as a team often requires inter-agent communication and data
sharing, leading to potential privacy implications. We assume privacy
considerations prohibit the agents from sharing their environment interaction
data. Accordingly, we propose Privacy-Engineered Value Decomposition Networks
(PE-VDN), a Co-MARL algorithm that models multi-agent coordination while
provably safeguarding the confidentiality of the agents' environment
interaction data. We integrate three privacy-engineering techniques to redesign
the data flows of the VDN algorithm, an existing Co-MARL algorithm that
consolidates the agents' environment interaction data to train a central
controller that models multi-agent coordination, and develop PE-VDN. In the
first technique, we design a distributed computation scheme that eliminates
Vanilla VDN's dependency on sharing environment interaction data. Then, we
utilize a privacy-preserving multi-party computation protocol to guarantee that
the data flows of the distributed computation scheme do not pose new privacy
risks. Finally, we enforce differential privacy to preempt inference threats
against the agents' training data, past environment interactions, when they
take actions based on their neural network predictions. We implement PE-VDN in
StarCraft Multi-Agent Competition (SMAC) and show that it achieves 80% of
Vanilla VDN's win rate while maintaining differential privacy levels that
provide meaningful privacy guarantees. The results demonstrate that PE-VDN can
safeguard the confidentiality of agents' environment interaction data without
sacrificing multi-agent coordination.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06258" title="Abstract">arXiv:2311.06258</a> [<a href="/pdf/2311.06258" title="Download PDF">pdf</a>, <a href="/format/2311.06258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Post-COVID Highlights: Challenges and Solutions of AI Techniques for  Swift Identification of COVID-19
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yingying Fang</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+X">Xiaodan Xing</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Walsh%2C+S">Simon Walsh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Since the onset of the COVID-19 pandemic in 2019, there has been a concerted
effort to develop cost-effective, non-invasive, and rapid AI-based tools. These
tools were intended to alleviate the burden on healthcare systems, control the
rapid spread of the virus, and enhance intervention outcomes, all in response
to this unprecedented global crisis. As we transition into a post-COVID era, we
retrospectively evaluate these proposed studies and offer a review of the
techniques employed in AI diagnostic models, with a focus on the solutions
proposed for different challenges. This review endeavors to provide insights
into the diverse solutions designed to address the multifaceted challenges that
arose during the pandemic. By doing so, we aim to prepare the AI community for
the development of AI tools tailored to address public health emergencies
effectively.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06260" title="Abstract">arXiv:2311.06260</a> [<a href="/pdf/2311.06260" title="Download PDF">pdf</a>, <a href="/format/2311.06260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> College Dropout Factors: An Analysis with LightGBM and Shapley&#x27;s  Cooperative Game Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paz%2C+H+R">Hugo Roger Paz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">This study was based on data analysis of academic histories of civil
engineering students at FACET-UNT. Our main objective was to determine the
academic performance variables that have a significant impact on the dropout of
the career. To do this, we implemented a correlation model using LightGBM
(Barbier et al., 2016; Ke et al., 2017; Shi et al., 2022). We use this model to
identify the key variables that influence the probability of student dropout.
<br />In addition, we use game theory to interpret the results obtained.
Specifically, we use the SHAP library (Lundberg et al., 2018, 2020; Lundberg &amp;
Lee, 2017) in Python to calculate the Shapley numbers.
<br />The results of our study revealed the most important variables that influence
the dropout from the civil engineering career. Significant differences were
identified in terms of age, time spent in studies, and academic performance,
which includes the number of courses passed and the number of exams taken.
These results may be useful to develop more effective student retention
strategies and improve academic success in this discipline.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06261" title="Abstract">arXiv:2311.06261</a> [<a href="/pdf/2311.06261" title="Download PDF">pdf</a>, <a href="/format/2311.06261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> With ChatGPT, do we have to rewrite our learning objectives -- CASE  study in Cybersecurity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jamieson%2C+P">Peter Jamieson</a>, 
<a href="/search/cs?searchtype=author&query=Bhunia%2C+S">Suman Bhunia</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+D+M">Dhananjai M. Rao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the emergence of Artificial Intelligent chatbot tools such as ChatGPT
and code writing AI tools such as GitHub Copilot, educators need to question
what and how we should teach our courses and curricula in the future. In
reality, automated tools may result in certain academic fields being deeply
reduced in the number of employable people. In this work, we make a case study
of cybersecurity undergrad education by using the lens of ``Understanding by
Design'' (UbD). First, we provide a broad understanding of learning objectives
(LOs) in cybersecurity from a computer science perspective. Next, we dig a
little deeper into a curriculum with an undergraduate emphasis on cybersecurity
and examine the major courses and their LOs for our cybersecurity program at
Miami University. With these details, we perform a thought experiment on how
attainable the LOs are with the above-described tools, asking the key question
``what needs to be enduring concepts?'' learned in this process. If an LO
becomes something that the existence of automation tools might be able to do,
we then ask ``what level is attainable for the LO that is not a simple query to
the tools?''. With this exercise, we hope to establish an example of how to
prompt ChatGPT to accelerate students in their achievements of LOs given the
existence of these new AI tools, and our goal is to push all of us to leverage
and teach these tools as powerful allies in our quest to improve human
existence and knowledge.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06262" title="Abstract">arXiv:2311.06262</a> [<a href="/pdf/2311.06262" title="Download PDF">pdf</a>, <a href="/ps/2311.06262" title="Download PostScript">ps</a>, <a href="/format/2311.06262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Causal Relationship between Walkability and Affective  Walking Experience: Evidence from 7 Major Tertiary Education Campuses in  China
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+B">Bojing Liao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">This study investigates the causal relationship between campus walkability
and the emotional walking experiences of students, with a focus on their mental
well-being. Using data from 697 participants across seven Chinese tertiary
education campuses, the study employs a counterfactual analysis to estimate the
impact of campus walkability on students' walking experiences. The analysis
reveals that students living in campuses with improved walkability are 9.75%
more likely to have positive walking experiences compared to those without
walkability renovations. While walking attitude is strongly correlated with
walking experiences, the study emphasizes the significance of objective factors
such as campus surroundings and the availability of walking spaces in
influencing the walking experience. Geographical features, including campus
walkability improvements, have the most substantial impact, and this effect
varies across different subsets of respondents. These findings underscore the
importance of considering specific subsets and geographical features when
assessing the impact of walkability improvements on the walking experience. In
conclusion, the study provides compelling evidence of a causal link between
improved campus walkability and enhanced emotional walking experiences among
students, suggesting the need for further research on mediating factors and
cultural variations affecting student mental health on various Chinese
campuses.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06263" title="Abstract">arXiv:2311.06263</a> [<a href="/pdf/2311.06263" title="Download PDF">pdf</a>, <a href="/ps/2311.06263" title="Download PostScript">ps</a>, <a href="/format/2311.06263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> No Trust without regulation!
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Terrier%2C+F">Fran&#xe7;ois Terrier</a> (CEA List)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The explosion in the performance of Machine Learning (ML) and the potential
of its applications are strongly encouraging us to consider its use in
industrial systems, including for critical functions such as decision-making in
autonomous systems. While the AI community is well aware of the need to ensure
the trustworthiness of AI-based applications, it is still leaving too much to
one side the issue of safety and its corollary, regulation and standards,
without which it is not possible to certify any level of safety, whether the
systems are slightly or very critical.The process of developing and qualifying
safety-critical software and systems in regulated industries such as aerospace,
nuclear power stations, railways or automotive industry has long been well
rationalized and mastered. They use well-defined standards, regulatory
frameworks and processes, as well as formal techniques to assess and
demonstrate the quality and safety of the systems and software they develop.
However, the low level of formalization of specifications and the uncertainties
and opacity of machine learning-based components make it difficult to validate
and verify them using most traditional critical systems engineering methods.
This raises the question of qualification standards, and therefore of
regulations adapted to AI. With the AI Act, the European Commission has laid
the foundations for moving forward and building solid approaches to the
integration of AI-based applications that are safe, trustworthy and respect
European ethical values. The question then becomes "How can we rise to the
challenge of certification and propose methods and tools for trusted artificial
intelligence?"
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06264" title="Abstract">arXiv:2311.06264</a> [<a href="/pdf/2311.06264" title="Download PDF">pdf</a>, <a href="/ps/2311.06264" title="Download PostScript">ps</a>, <a href="/format/2311.06264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;ChatGPT, a Friend or Foe for Education?&quot; Analyzing the User&#x27;s  Perspectives on the Latest AI Chatbot Via Reddit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Emdad%2C+F+B">Forhan Bin Emdad</a>, 
<a href="/search/cs?searchtype=author&query=Ravuri%2C+B">Benhur Ravuri</a>, 
<a href="/search/cs?searchtype=author&query=Ayinde%2C+L">Lateef Ayinde</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M+I">Mohammad Ishtiaque Rahman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Latest developments in Artificial Intelligence (AI) and big data gave rise to
Artificial Intelligent agents like Open AI's ChatGPT, which has recently become
the fastest growing application since Facebook and WhatsApp. ChatGPT has
demonstrated its ability to impact students' classroom learning experience and
exam outcomes. However, there is evidence that ChatGPT provides biased and
erroneous information, yet students use ChatGPT in academic tasks. Therefore,
an accurate understanding of ChatGPT user perception is crucial. This study has
analyzed 247 Reddit top posts related to the educational use of ChatGPT from a
prominent subreddit called "ChatGPT" for user perception analysis. Descriptive
statistics, sentiment analysis using NLP techniques, and LDA topic modeling
were used for analysis to gather a contextual understanding of the data.
Results show that the majority of the users took a neutral viewpoint. However,
there was more positive perception than negative regarding the usefulness of
ChatGPT in education.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06265" title="Abstract">arXiv:2311.06265</a> [<a href="/pdf/2311.06265" title="Download PDF">pdf</a>, <a href="/ps/2311.06265" title="Download PostScript">ps</a>, <a href="/format/2311.06265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Partially Informed Elections -- Analyzing the Impact of Forced Ballot  Truncation on Bucklin, Coombs, Plurality with Runoff, and Schulze
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stein%2C+J">Jonah Stein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Elections employ various voting systems to determine winners based on voters'
preferences. However, many recent ranked-choice elections have forced voters to
truncate their ballots by only ranking a subset of the candidates. This study
analyzes how forced ballot truncation affects the Bucklin, Coombs, plurality
with runoff, and Schulze voting systems' abilities to output their true winning
sets. Using computer simulations, thousands of preference profiles were
generated with the Mallows model using different numbers of candidates, voters,
and dispersion values. The true winning set was determined for each system
using complete preferences, then compared to winning sets derived from
repeatedly truncated preferences within the same preference profile. Results
show that plurality with runoff was the most resistant to forced truncation,
followed by Schulze, Bucklin, and Coombs. Additionally, elections with fewer
voters and higher dispersion values were found to decrease the probability of
selecting the true winning set across all systems. The findings provide
insights into how forced truncation impacts voting systems, aiding election
designers in their work.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06272" title="Abstract">arXiv:2311.06272</a> [<a href="/pdf/2311.06272" title="Download PDF">pdf</a>, <a href="/ps/2311.06272" title="Download PostScript">ps</a>, <a href="/format/2311.06272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Cognitive Agent Computing-Based Model For The Primary School Student  Migration Problem Using A Descriptive Agent-Based Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tausif%2C+M">Muhammad Tausif</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 117 pages, MS thesis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Computational Engineering, Finance, and Science (cs.CE); Computers and Society (cs.CY)

</div>
<p class="mathjax">Students' migration from public to private schools, due to lack of school
performance of public schools, is one of the major issues faced by the
Government of Punjab to provide compulsory and quality education at low cost.
Due to complex adaptive nature of educational system, interdependencies with
society, constant feedback loops conventional linear regression methods, for
evaluation of effective performance, are ineffective or costly to solve the
issue. Linear regression techniques present the static view of the system,
which are not enough to understand the complex dynamic nature of educational
paradigm. We have presented a Cognitive Agent Computing-Based Model for the
School Student Migration Problem Using a Descriptive Agent-Based Modeling
approach to understand the causes-effects relationship of student migration. We
have presented the primary school students' migration model using descriptive
modeling approach along with exploratory modeling. Our research, in the context
of Software Engineering of Simulation &amp; Modeling, and exploring the Complex
Adaptive nature of school system, is two folds. Firstly, the cause-effect
relationship of students' migration is being investigated using Cognitive
Descriptive Agent-Based Modeling. Secondly, the formalization extent of
Cognitive Agent-Based Computing framework is analyzed by performing its
comparative analysis with exploratory modeling protocol 'Overview, Design, and
Detail'.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06275" title="Abstract">arXiv:2311.06275</a> [<a href="/pdf/2311.06275" title="Download PDF">pdf</a>, <a href="/ps/2311.06275" title="Download PostScript">ps</a>, <a href="/format/2311.06275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithmic Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jensen%2C+D">David Jensen</a>, 
<a href="/search/cs?searchtype=author&query=LaMacchia%2C+B">Brian LaMacchia</a>, 
<a href="/search/cs?searchtype=author&query=Topcu%2C+U">Ufuk Topcu</a>, 
<a href="/search/cs?searchtype=author&query=Wisniewski%2C+P">Pamela Wisniewski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Algorithmic robustness refers to the sustained performance of a computational
system in the face of change in the nature of the environment in which that
system operates or in the task that the system is meant to perform. Below, we
motivate the importance of algorithmic robustness, present a conceptual
framework, and highlight the relevant areas of research for which algorithmic
robustness is relevant. Why robustness? Robustness is an important enabler of
other goals that are frequently cited in the context of public policy decisions
about computational systems, including trustworthiness, accountability,
fairness, and safety. Despite this dependence, it tends to be under-recognized
compared to these other concepts. This is unfortunate, because robustness is
often more immediately achievable than these other ultimate goals, which can be
more subjective and exacting. Thus, we highlight robustness as an important
goal for researchers, engineers, regulators, and policymakers when considering
the design, implementation, and deployment of computational systems. We urge
researchers and practitioners to elevate the attention paid to robustness when
designing and evaluating computational systems. For many key systems, the
immediate question after any demonstration of high performance should be: "How
robust is that performance to realistic changes in the task or environment?"
Greater robustness will set the stage for systems that are more trustworthy,
accountable, fair, and safe. Toward that end, this document provides a brief
roadmap to some of the concepts and existing research around the idea of
algorithmic robustness.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06279" title="Abstract">arXiv:2311.06279</a> [<a href="/pdf/2311.06279" title="Download PDF">pdf</a>, <a href="/ps/2311.06279" title="Download PostScript">ps</a>, <a href="/format/2311.06279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A novel method of restoration path optimization for the AC-DC bulk power  grid after a major blackout
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yang%2C+C">Chao Yang</a>, 
<a href="/search/eess?searchtype=author&query=Liang%2C+G">Gaoshen Liang</a>, 
<a href="/search/eess?searchtype=author&query=Cheng%2C+T">Tianle Cheng</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+S">Shaoyan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IET Generation, Transmission &amp; Distribution
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The restoration control of the modern alternating current-direct current
(AC-DC) hybrid power grid after a major blackout is difficult and complex.
Taking into account the interaction between the line-commutated converter
high-voltage direct current (LCC-HVDC) and the AC power grid, this paper
proposes a novel optimization method of restoration path to reconfigure the
skeleton network for the blackout power grid. Based on the system strength, the
supporting capability of the AC power grid for the LCC-HVDC is first analysed
from the aspects of start-up and operation of LCC-HVDCs. Subsequently, the
quantitative relationship between the restoration path and the restoration
characteristic of LCC-HVDC is derived in detail based on the system strength
indices of the short-circuit capacity and the frequency regulation capability.
Then, an optimization model of restoration path considering non-tree paths is
formulated and a feasible optimization algorithm is proposed to achieve the
optimal path restoration scheme. A modified IEEE 39-bus system and a partial
power grid of Southwest China are simulated to show that the proposed method is
suitable for the restoration of AC-DC power grids and can improve restoration
efficiency. This research can be an important guidance for operators to rapidly
restore the AC-DC power grid.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06281" title="Abstract">arXiv:2311.06281</a> [<a href="/pdf/2311.06281" title="Download PDF">pdf</a>, <a href="/format/2311.06281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parallelization of an Ubiquitous Sequential Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heinsen%2C+F+A">Franz A. Heinsen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Source code for replicating our results is available online at <a href="https://github.com/glassroom/heinsen_sequence">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We show how to compute the elements of a sequence $x_t = a_t x_{t-1} + b_t$
in parallel, given $t = (1, 2, \dots, n)$, $a_t \in \mathbb{R}^n$, $b_t \in
\mathbb{R}^n$, and initial value $x_0 \in \mathbb{R}$. On $n$ parallel
processors, the computation of $n$ elements incurs $\mathcal{O}(\log n)$ time
and $\mathcal{O}(n)$ space. Sequences of this form are ubiquitous in science
and engineering, making their parallelization useful for a vast number of
applications. We implement parallelization in software, test it on parallel
hardware, and verify that it executes faster than sequential computation by a
factor of $\frac{n}{\log n}$.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06285" title="Abstract">arXiv:2311.06285</a> [<a href="/pdf/2311.06285" title="Download PDF">pdf</a>, <a href="/format/2311.06285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sounding Bodies: Modeling 3D Spatial Sound of Humans Using Body Pose and  Audio
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xudong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Markovic%2C+D">Dejan Markovic</a>, 
<a href="/search/cs?searchtype=author&query=Sandakly%2C+J">Jacob Sandakly</a>, 
<a href="/search/cs?searchtype=author&query=Keebler%2C+T">Todd Keebler</a>, 
<a href="/search/cs?searchtype=author&query=Krenn%2C+S">Steven Krenn</a>, 
<a href="/search/cs?searchtype=author&query=Richard%2C+A">Alexander Richard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">While 3D human body modeling has received much attention in computer vision,
modeling the acoustic equivalent, i.e. modeling 3D spatial audio produced by
body motion and speech, has fallen short in the community. To close this gap,
we present a model that can generate accurate 3D spatial audio for full human
bodies. The system consumes, as input, audio signals from headset microphones
and body pose, and produces, as output, a 3D sound field surrounding the
transmitter's body, from which spatial audio can be rendered at any arbitrary
position in the 3D space. We collect a first-of-its-kind multimodal dataset of
human bodies, recorded with multiple cameras and a spherical array of 345
microphones. In an empirical evaluation, we demonstrate that our model can
produce accurate body-induced sound fields when trained with a suitable loss.
Dataset and code are available online.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06291" title="Abstract">arXiv:2311.06291</a> [<a href="/pdf/2311.06291" title="Download PDF">pdf</a>, <a href="/format/2311.06291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven Spatio-Temporal Scaling of Travel Times for AMoD Simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Syed%2C+A+A">Arslan Ali Syed</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yunfei Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Bogenberger%2C+K">Klaus Bogenberger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">With the widespread adoption of mobility-on-demand (MoD) services and the
advancements in autonomous vehicle (AV) technology, the research interest into
the AVs based MoD (AMoD) services has grown immensely. Often agent-based
simulation frameworks are used to study the AMoD services using the trip data
of current Taxi or MoD services. For reliable results of AMoD simulations, a
realistic city network and travel times play a crucial part. However, many
times the researchers do not have access to the actual network state
corresponding to the trip data used for AMoD simulations reducing the
reliability of results. Therefore, this paper introduces a spatio-temporal
optimization strategy for scaling the link-level network travel times using the
simulated trip data without additional data sources on the network state. The
method is tested on the widely used New York City (NYC) Taxi data and shows
that the travel times produced using the scaled network are very close to the
recorded travel times in the original data. Additionally, the paper studies the
performance differences of AMoD simulation when the scaled network is used. The
results indicate that realistic travel times can significantly impact AMoD
simulation outcomes.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06300" title="Abstract">arXiv:2311.06300</a> [<a href="/pdf/2311.06300" title="Download PDF">pdf</a>, <a href="/format/2311.06300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI Chatbot for Generating Episodic Future Thinking (EFT) Cue Texts for  Health
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmadi%2C+S">Sareh Ahmadi</a>, 
<a href="/search/cs?searchtype=author&query=Fox%2C+E+A">Edward A. Fox</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We describe an AI-powered chatbot to aid with health improvement by
generating Episodic Future Thinking (EFT) cue texts that should reduce delay
discounting. In prior studies, EFT has been shown to address maladaptive health
behaviors. Those studies involved participants, working with researchers,
vividly imagining future events, and writing a description that they
subsequently will frequently review, to ensure a shift from an inclination
towards immediate rewards. That should promote behavior change, aiding in
health tasks such as treatment adherence and lifestyle modifications. The AI
chatbot is designed to guide users in generating personalized EFTs, automating
the current labor-intensive interview-based process. This can enhance the
efficiency of EFT interventions and make them more accessible, targeting
specifically those with limited educational backgrounds or communication
challenges. By leveraging AI for EFT intervention, we anticipate broadened
access and improved health outcomes across diverse populations
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06302" title="Abstract">arXiv:2311.06302</a> [<a href="/pdf/2311.06302" title="Download PDF">pdf</a>, <a href="/format/2311.06302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge-Based Support for Adhesive Selection: Will it Stick?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vandevelde%2C+S">Simon Vandevelde</a>, 
<a href="/search/cs?searchtype=author&query=Jordens%2C+J">Jeroen Jordens</a>, 
<a href="/search/cs?searchtype=author&query=Van+Doninck%2C+B">Bart Van Doninck</a>, 
<a href="/search/cs?searchtype=author&query=Witters%2C+M">Maarten Witters</a>, 
<a href="/search/cs?searchtype=author&query=Vennekens%2C+J">Joost Vennekens</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under consideration in Theory and Practice of Logic Programming (TPLP)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">As the popularity of adhesive joints in industry increases, so does the need
for tools to support the process of selecting a suitable adhesive. While some
such tools already exist, they are either too limited in scope, or offer too
little flexibility in use. This work presents a more advanced tool, that was
developed together with a team of adhesive experts. We first extract the
experts' knowledge about this domain and formalize it in a Knowledge Base (KB).
The IDP-Z3 reasoning system can then be used to derive the necessary
functionality from this KB. Together with a user-friendly interactive
interface, this creates an easy-to-use tool capable of assisting the adhesive
experts. To validate our approach, we performed user testing in the form of
qualitative interviews. The experts are very positive about the tool, stating
that, among others, it will help save time and find more suitable adhesives.
Under consideration in Theory and Practice of Logic Programming (TPLP).
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06304" title="Abstract">arXiv:2311.06304</a> [<a href="/pdf/2311.06304" title="Download PDF">pdf</a>, <a href="/format/2311.06304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retro-BLEU: Quantifying Chemical Plausibility of Retrosynthesis Routes  through Reaction Template Sequence Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junren Li</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+L">Lei Fang</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+J">Jian-Guang Lou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Biomolecules (q-bio.BM)

</div>
<p class="mathjax">Computer-assisted methods have emerged as valuable tools for retrosynthesis
analysis. However, quantifying the plausibility of generated retrosynthesis
routes remains a challenging task. We introduce Retro-BLEU, a statistical
metric adapted from the well-established BLEU score in machine translation, to
evaluate the plausibility of retrosynthesis routes based on reaction template
sequences analysis. We demonstrate the effectiveness of Retro-BLEU by applying
it to a diverse set of retrosynthesis routes generated by state-of-the-art
algorithms and compare the performance with other evaluation metrics. The
results show that Retro-BLEU is capable of differentiating between plausible
and implausible routes. Furthermore, we provide insights into the strengths and
weaknesses of Retro-BLEU, paving the way for future developments and
improvements in this field.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06305" title="Abstract">arXiv:2311.06305</a> [<a href="/pdf/2311.06305" title="Download PDF">pdf</a>, <a href="/format/2311.06305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Systematic Review on Fostering Appropriate Trust in Human-AI  Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mehrotra%2C+S">Siddharth Mehrotra</a>, 
<a href="/search/cs?searchtype=author&query=Degachi%2C+C">Chadha Degachi</a>, 
<a href="/search/cs?searchtype=author&query=Vereschak%2C+O">Oleksandra Vereschak</a>, 
<a href="/search/cs?searchtype=author&query=Jonker%2C+C+M">Catholijn M. Jonker</a>, 
<a href="/search/cs?searchtype=author&query=Tielman%2C+M+L">Myrthe L. Tielman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 Pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Appropriate Trust in Artificial Intelligence (AI) systems has rapidly become
an important area of focus for both researchers and practitioners. Various
approaches have been used to achieve it, such as confidence scores,
explanations, trustworthiness cues, or uncertainty communication. However, a
comprehensive understanding of the field is lacking due to the diversity of
perspectives arising from various backgrounds that influence it and the lack of
a single definition for appropriate trust. To investigate this topic, this
paper presents a systematic review to identify current practices in building
appropriate trust, different ways to measure it, types of tasks used, and
potential challenges associated with it. We also propose a Belief, Intentions,
and Actions (BIA) mapping to study commonalities and differences in the
concepts related to appropriate trust by (a) describing the existing
disagreements on defining appropriate trust, and (b) providing an overview of
the concepts and definitions related to appropriate trust in AI from the
existing literature. Finally, the challenges identified in studying appropriate
trust are discussed, and observations are summarized as current trends,
potential gaps, and research opportunities for future work. Overall, the paper
provides insights into the complex concept of appropriate trust in human-AI
interaction and presents research opportunities to advance our understanding on
this topic.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06307" title="Abstract">arXiv:2311.06307</a> [<a href="/pdf/2311.06307" title="Download PDF">pdf</a>, <a href="/ps/2311.06307" title="Download PostScript">ps</a>, <a href="/format/2311.06307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthetic Speaking Children -- Why We Need Them and How to Make Them
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farooq%2C+M+A">Muhammad Ali Farooq</a>, 
<a href="/search/cs?searchtype=author&query=Bigioi%2C+D">Dan Bigioi</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+R">Rishabh Jain</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+W">Wang Yao</a>, 
<a href="/search/cs?searchtype=author&query=Yiwere%2C+M">Mariam Yiwere</a>, 
<a href="/search/cs?searchtype=author&query=Corcoran%2C+P">Peter Corcoran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at SpeD 23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Contemporary Human Computer Interaction (HCI) research relies primarily on
neural network models for machine vision and speech understanding of a system
user. Such models require extensively annotated training datasets for optimal
performance and when building interfaces for users from a vulnerable population
such as young children, GDPR introduces significant complexities in data
collection, management, and processing. Motivated by the training needs of an
Edge AI smart toy platform this research explores the latest advances in
generative neural technologies and provides a working proof of concept of a
controllable data generation pipeline for speech driven facial training data at
scale. In this context, we demonstrate how StyleGAN2 can be finetuned to create
a gender balanced dataset of children's faces. This dataset includes a variety
of controllable factors such as facial expressions, age variations, facial
poses, and even speech-driven animations with realistic lip synchronization. By
combining generative text to speech models for child voice synthesis and a 3D
landmark based talking heads pipeline, we can generate highly realistic,
entirely synthetic, talking child video clips. These video clips can provide
valuable, and controllable, synthetic training data for neural network models,
bridging the gap when real data is scarce or restricted due to privacy
regulations.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06311" title="Abstract">arXiv:2311.06311</a> [<a href="/pdf/2311.06311" title="Download PDF">pdf</a>, <a href="/ps/2311.06311" title="Download PostScript">ps</a>, <a href="/format/2311.06311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Game Theory Solutions in Sensor-Based Human Activity Recognition: A  Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shayesteh%2C+M+H">Mohammad Hossein Shayesteh</a>, 
<a href="/search/cs?searchtype=author&query=Sharokhzadeh%2C+B">Behrooz Sharokhzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Masoumi%2C+B">Behrooz Masoumi</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Artificial Intelligence and Data Mining (JAIDM), Vol.
  11, No. 2, 2023, 259-289
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The Human Activity Recognition (HAR) tasks automatically identify human
activities using the sensor data, which has numerous applications in
healthcare, sports, security, and human-computer interaction. Despite
significant advances in HAR, critical challenges still exist. Game theory has
emerged as a promising solution to address these challenges in machine learning
problems including HAR. However, there is a lack of research work on applying
game theory solutions to the HAR problems. This review paper explores the
potential of game theory as a solution for HAR tasks, and bridges the gap
between game theory and HAR research work by suggesting novel game-theoretic
approaches for HAR problems. The contributions of this work include exploring
how game theory can improve the accuracy and robustness of HAR models,
investigating how game-theoretic concepts can optimize recognition algorithms,
and discussing the game-theoretic approaches against the existing HAR methods.
The objective is to provide insights into the potential of game theory as a
solution for sensor-based HAR, and contribute to develop a more accurate and
efficient recognition system in the future research directions.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06315" title="Abstract">arXiv:2311.06315</a> [<a href="/pdf/2311.06315" title="Download PDF">pdf</a>, <a href="/format/2311.06315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ShipGen: A Diffusion Model for Parametric Ship Hull Generation with  Multiple Objectives and Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bagazinski%2C+N+J">Noah J. Bagazinski</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+F">Faez Ahmed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Ship design is a years-long process that requires balancing complex design
trade-offs to create a ship that is efficient and effective. Finding new ways
to improve the ship design process can lead to significant cost savings for
ship building and operation. One promising technology is generative artificial
intelligence, which has been shown to reduce design cycle time and create
novel, high-performing designs. In literature review, generative artificial
intelligence has been shown to generate ship hulls; however, ship design is
particularly difficult as the hull of a ship requires the consideration of many
objectives. This paper presents a study on the generation of parametric ship
hull designs using a parametric diffusion model that considers multiple
objectives and constraints for the hulls. This denoising diffusion
probabilistic model (DDPM) generates the tabular parametric design vectors of a
ship hull for evaluation. In addition to a tabular DDPM, this paper details
adding guidance to improve the quality of generated ship hull designs. By
leveraging classifier guidance, the DDPM produced feasible parametric ship
hulls that maintain the coverage of the initial training dataset of ship hulls
with a 99.5% rate, a 149x improvement over random sampling of the design vector
parameters across the design space. Parametric ship hulls produced with
performance guidance saw an average of 91.4% reduction in wave drag
coefficients and an average of a 47.9x relative increase in the total displaced
volume of the hulls compared to the mean performance of the hulls in the
training dataset. The use of a DDPM to generate parametric ship hulls can
reduce design time by generating high-performing hull designs for future
analysis. These generated hulls have low drag and high volume, which can reduce
the cost of operating a ship and increase its potential to generate revenue.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06318" title="Abstract">arXiv:2311.06318</a> [<a href="/pdf/2311.06318" title="Download PDF">pdf</a>, <a href="/format/2311.06318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge-Augmented Large Language Models for Personalized Contextual  Query Suggestion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baek%2C+J">Jinheon Baek</a>, 
<a href="/search/cs?searchtype=author&query=Chandrasekaran%2C+N">Nirupama Chandrasekaran</a>, 
<a href="/search/cs?searchtype=author&query=Cucerzan%2C+S">Silviu Cucerzan</a>, 
<a href="/search/cs?searchtype=author&query=herring%2C+A">Allen herring</a>, 
<a href="/search/cs?searchtype=author&query=Jauhar%2C+S+K">Sujay Kumar Jauhar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models (LLMs) excel at tackling various natural language
tasks. However, due to the significant costs involved in re-training or
fine-tuning them, they remain largely static and difficult to personalize.
Nevertheless, a variety of applications could benefit from generations that are
tailored to users' preferences, goals, and knowledge. Among them is web search,
where knowing what a user is trying to accomplish, what they care about, and
what they know can lead to improved search experiences. In this work, we
propose a novel and general approach that augments an LLM with relevant context
from users' interaction histories with a search engine in order to personalize
its outputs. Specifically, we construct an entity-centric knowledge store for
each user based on their search and browsing activities on the web, which is
then leveraged to provide contextually relevant LLM prompt augmentations. This
knowledge store is light-weight, since it only produces user-specific aggregate
projections of interests and knowledge onto public knowledge graphs, and
leverages existing search log infrastructure, thereby mitigating the privacy,
compliance, and scalability concerns associated with building deep user
profiles for personalization. We then validate our approach on the task of
contextual query suggestion, which requires understanding not only the user's
current search context but also what they historically know and care about.
Through a number of experiments based on human evaluation, we show that our
approach is significantly better than several other LLM-powered baselines,
generating query suggestions that are contextually more relevant, personalized,
and useful.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06321" title="Abstract">arXiv:2311.06321</a> [<a href="/pdf/2311.06321" title="Download PDF">pdf</a>, <a href="/format/2311.06321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Machine Learning Uncover Insights into Vehicle Travel Demand from  Our Built Environment?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zixun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hao Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">In this paper, we propose a machine learning-based approach to address the
lack of ability for designers to optimize urban land use planning from the
perspective of vehicle travel demand. Research shows that our computational
model can help designers quickly obtain feedback on the vehicle travel demand,
which includes its total amount and temporal distribution based on the urban
function distribution designed by the designers. It also assists in design
optimization and evaluation of the urban function distribution from the
perspective of vehicle travel. We obtain the city function distribution
information and vehicle hours traveled (VHT) information by collecting the city
point-of-interest (POI) data and online vehicle data. The artificial neural
networks (ANNs) with the best performance in prediction are selected. By using
data sets collected in different regions for mutual prediction and remapping
the predictions onto a map for visualization, we evaluate the extent to which
the computational model sees use across regions in an attempt to reduce the
workload of future urban researchers. Finally, we demonstrate the application
of the computational model to help designers obtain feedback on vehicle travel
demand in the built environment and combine it with genetic algorithms to
optimize the current state of the urban environment to provide recommendations
to designers.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06322" title="Abstract">arXiv:2311.06322</a> [<a href="/pdf/2311.06322" title="Download PDF">pdf</a>, <a href="/format/2311.06322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Post-training Quantization with Progressive Calibration and Activation  Relaxing for Text-to-Image Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Siao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+C">Chaoyu Guan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zewen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yansong Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenwu Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Diffusion models have achieved great success due to their remarkable
generation ability. However, their high computational overhead is still a
troublesome problem. Recent studies have leveraged post-training quantization
(PTQ) to compress diffusion models. However, most of them only focus on
unconditional models, leaving the quantization of widely used large pretrained
text-to-image models, e.g., Stable Diffusion, largely unexplored. In this
paper, we propose a novel post-training quantization method PCR (Progressive
Calibration and Relaxing) for text-to-image diffusion models, which consists of
a progressive calibration strategy that considers the accumulated quantization
error across timesteps, and an activation relaxing strategy that improves the
performance with negligible cost. Additionally, we demonstrate the previous
metrics for text-to-image diffusion model quantization are not accurate due to
the distribution gap. To tackle the problem, we propose a novel QDiffBench
benchmark, which utilizes data in the same domain for more accurate evaluation.
Besides, QDiffBench also considers the generalization performance of the
quantized model outside the calibration dataset. Extensive experiments on
Stable Diffusion and Stable Diffusion XL demonstrate the superiority of our
method and benchmark. Moreover, we are the first to achieve quantization for
Stable Diffusion XL while maintaining the performance.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06323" title="Abstract">arXiv:2311.06323</a> [<a href="/pdf/2311.06323" title="Download PDF">pdf</a>, <a href="/ps/2311.06323" title="Download PostScript">ps</a>, <a href="/format/2311.06323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reviewing Developments of Graph Convolutional Network Techniques for  Recommendation Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Haojun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Kapoor%2C+V">Vikram Kapoor</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+P">Priya Sharma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2103.08976">arXiv:2103.08976</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The Recommender system is a vital information service on today's Internet.
Recently, graph neural networks have emerged as the leading approach for
recommender systems. We try to review recent literature on graph neural
network-based recommender systems, covering the background and development of
both recommender systems and graph neural networks. Then categorizing
recommender systems by their settings and graph neural networks by spectral and
spatial models, we explore the motivation behind incorporating graph neural
networks into recommender systems. We also analyze challenges and open problems
in graph construction, embedding propagation and aggregation, and computation
efficiency. This guides us to better explore the future directions and
developments in this domain.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06329" title="Abstract">arXiv:2311.06329</a> [<a href="/pdf/2311.06329" title="Download PDF">pdf</a>, <a href="/ps/2311.06329" title="Download PostScript">ps</a>, <a href="/format/2311.06329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of AI Text-to-Image and AI Text-to-Video Generators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Aditi Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 2 tables, 4th International Conference on Artificial Intelligence, Robotics and Control (AIRC 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Text-to-Image and Text-to-Video AI generation models are revolutionary
technologies that use deep learning and natural language processing (NLP)
techniques to create images and videos from textual descriptions. This paper
investigates cutting-edge approaches in the discipline of Text-to-Image and
Text-to-Video AI generations. The survey provides an overview of the existing
literature as well as an analysis of the approaches used in various studies. It
covers data preprocessing techniques, neural network types, and evaluation
metrics used in the field. In addition, the paper discusses the challenges and
limitations of Text-to-Image and Text-to-Video AI generations, as well as
future research directions. Overall, these models have promising potential for
a wide range of applications such as video production, content creation, and
digital marketing.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06330" title="Abstract">arXiv:2311.06330</a> [<a href="/pdf/2311.06330" title="Download PDF">pdf</a>, <a href="/format/2311.06330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Smart Agent-Based Modeling: On the Use of Large Language Models in  Computer Simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zengqing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+R">Run Peng</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xu Han</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shuyuan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yixin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chuan Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Source codes are available at <a href="https://github.com/Roihn/SABM">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computational Engineering, Finance, and Science (cs.CE); Multiagent Systems (cs.MA); General Economics (econ.GN)

</div>
<p class="mathjax">Computer simulations offer a robust toolset for exploring complex systems
across various disciplines. A particularly impactful approach within this realm
is Agent-Based Modeling (ABM), which harnesses the interactions of individual
agents to emulate intricate system dynamics. ABM's strength lies in its
bottom-up methodology, illuminating emergent phenomena by modeling the
behaviors of individual components of a system. Yet, ABM has its own set of
challenges, notably its struggle with modeling natural language instructions
and common sense in mathematical equations or rules. This paper seeks to
transcend these boundaries by integrating Large Language Models (LLMs) like GPT
into ABM. This amalgamation gives birth to a novel framework, Smart Agent-Based
Modeling (SABM). Building upon the concept of smart agents -- entities
characterized by their intelligence, adaptability, and computation ability --
we explore in the direction of utilizing LLM-powered agents to simulate
real-world scenarios with increased nuance and realism. In this comprehensive
exploration, we elucidate the state of the art of ABM, introduce SABM's
potential and methodology, and present three case studies (source codes
available at https://github.com/Roihn/SABM), demonstrating the SABM methodology
and validating its effectiveness in modeling real-world systems. Furthermore,
we cast a vision towards several aspects of the future of SABM, anticipating a
broader horizon for its applications. Through this endeavor, we aspire to
redefine the boundaries of computer simulations, enabling a more profound
understanding of complex systems.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06345" title="Abstract">arXiv:2311.06345</a> [<a href="/pdf/2311.06345" title="Download PDF">pdf</a>, <a href="/format/2311.06345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Schema Graph-Guided Prompt for Multi-Domain Dialogue State Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+R">Ruolin Su</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Ting-Wei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Juang%2C+B">Biing-Hwang Juang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Tracking dialogue states is an essential topic in task-oriented dialogue
systems, which involve filling in the necessary information in pre-defined
slots corresponding to a schema. While general pre-trained language models have
been shown effective in slot-filling, their performance is limited when applied
to specific domains. We propose a graph-based framework that learns
domain-specific prompts by incorporating the dialogue schema. Specifically, we
embed domain-specific schema encoded by a graph neural network into the
pre-trained language model, which allows for relations in the schema to guide
the model for better adaptation to the specific domain. Our experiments
demonstrate that the proposed graph-based method outperforms other multi-domain
DST approaches while using similar or fewer trainable parameters. We also
conduct a comprehensive study of schema graph architectures, parameter usage,
and module ablation that demonstrate the effectiveness of our model on
multi-domain dialogue state tracking.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06358" title="Abstract">arXiv:2311.06358</a> [<a href="/pdf/2311.06358" title="Download PDF">pdf</a>, <a href="/format/2311.06358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compact Matrix Quantum Group Equivariant Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pearce-Crump%2C+E">Edward Pearce-Crump</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Combinatorics (math.CO); Category Theory (math.CT); Representation Theory (math.RT); Machine Learning (stat.ML)

</div>
<p class="mathjax">We derive the existence of a new type of neural network, called a compact
matrix quantum group equivariant neural network, that learns from data that has
an underlying quantum symmetry. We apply the Woronowicz formulation of
Tannaka-Krein duality to characterise the weight matrices that appear in these
neural networks for any easy compact matrix quantum group. We show that compact
matrix quantum group equivariant neural networks contain, as a subclass, all
compact matrix group equivariant neural networks. Moreover, we obtain
characterisations of the weight matrices for many compact matrix group
equivariant neural networks that have not previously appeared in the machine
learning literature.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06360" title="Abstract">arXiv:2311.06360</a> [<a href="/pdf/2311.06360" title="Download PDF">pdf</a>, <a href="/format/2311.06360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Initiative and Materiality: Exploring Mixed-Initiative Calculators with  the Tangible Human-A.I. Interaction Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Lunshi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Bremers%2C+A">Alexandra Bremers</a>, 
<a href="/search/cs?searchtype=author&query=Ju%2C+W">Wendy Ju</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">How can interactions with A.I. systems be designed? This paper explores the
design space for A.I. interaction to develop tools for designers to think about
tangible and physical A.I. interactions. Our proposed framework consists of two
dimensions: initiative (human, mixed, or machine) and materiality (physical,
combined, or digital form). A particularly interesting area of interactions we
identify is the quadrant of physical, machine-initiated interactions. With our
framework, we examine calculator interactions and attempt to expand these to
the tangible, mixed-initiative space. We illustrate each area in our proposed
framework with one representative example of a calculator -- a common and
well-known example of a computing device. We discuss existing examples of
calculators and speculative future interactions with mixed-initiative and
physical calculator systems. We reflect on the implications of our framework
for the larger task of designing human-A.I. collaborative systems. Designers
can also apply this framework as a guideline for analogous solutions to
problems in the same domain.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06361" title="Abstract">arXiv:2311.06361</a> [<a href="/pdf/2311.06361" title="Download PDF">pdf</a>, <a href="/ps/2311.06361" title="Download PostScript">ps</a>, <a href="/format/2311.06361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CALLOC: Curriculum Adversarial Learning for Secure and Robust Indoor  Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gufran%2C+D">Danish Gufran</a>, 
<a href="/search/cs?searchtype=author&query=Pasricha%2C+S">Sudeep Pasricha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Indoor localization has become increasingly vital for many applications from
tracking assets to delivering personalized services. Yet, achieving pinpoint
accuracy remains a challenge due to variations across indoor environments and
devices used to assist with localization. Another emerging challenge is
adversarial attacks on indoor localization systems that not only threaten
service integrity but also reduce localization accuracy. To combat these
challenges, we introduce CALLOC, a novel framework designed to resist
adversarial attacks and variations across indoor environments and devices that
reduce system accuracy and reliability. CALLOC employs a novel adaptive
curriculum learning approach with a domain specific lightweight scaled-dot
product attention neural network, tailored for adversarial and variation
resilience in practical use cases with resource constrained mobile devices.
Experimental evaluations demonstrate that CALLOC can achieve improvements of up
to 6.03x in mean error and 4.6x in worst-case error against state-of-the-art
indoor localization frameworks, across diverse building floorplans, mobile
devices, and adversarial attacks scenarios.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06362" title="Abstract">arXiv:2311.06362</a> [<a href="/pdf/2311.06362" title="Download PDF">pdf</a>, <a href="/format/2311.06362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Word Definitions from Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yunting Yin</a>, 
<a href="/search/cs?searchtype=author&query=Skiena%2C+S">Steven Skiena</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Dictionary definitions are historically the arbitrator of what words mean,
but this primacy has come under threat by recent progress in NLP, including
word embeddings and generative models like ChatGPT. We present an exploratory
study of the degree of alignment between word definitions from classical
dictionaries and these newer computational artifacts. Specifically, we compare
definitions from three published dictionaries to those generated from variants
of ChatGPT. We show that (i) definitions from different traditional
dictionaries exhibit more surface form similarity than do model-generated
definitions, (ii) that the ChatGPT definitions are highly accurate, comparable
to traditional dictionaries, and (iii) ChatGPT-based embedding definitions
retain their accuracy even on low frequency words, much better than GloVE and
FastText word embeddings.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06364" title="Abstract">arXiv:2311.06364</a> [<a href="/pdf/2311.06364" title="Download PDF">pdf</a>, <a href="/format/2311.06364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relation Extraction in underexplored biomedical domains: A  diversity-optimised sampling and synthetic data generation approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Delmas%2C+M">Maxime Delmas</a>, 
<a href="/search/cs?searchtype=author&query=Wysocka%2C+M">Magdalena Wysocka</a>, 
<a href="/search/cs?searchtype=author&query=Freitas%2C+A">Andr&#xe9; Freitas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The sparsity of labelled data is an obstacle to the development of Relation
Extraction models and the completion of databases in various biomedical areas.
While being of high interest in drug-discovery, the natural-products
literature, reporting the identification of potential bioactive compounds from
organisms, is a concrete example of such an overlooked topic. To mark the start
of this new task, we created the first curated evaluation dataset and extracted
literature items from the LOTUS database to build training sets. To this end,
we developed a new sampler inspired by diversity metrics in ecology, named
Greedy Maximum Entropy sampler, or GME-sampler
(https://github.com/idiap/gme-sampler). The strategic optimization of both
balance and diversity of the selected items in the evaluation set is important
given the resource-intensive nature of manual curation. After quantifying the
noise in the training set, in the form of discrepancies between the input
abstracts text and the expected output labels, we explored different strategies
accordingly. Framing the task as an end-to-end Relation Extraction, we
evaluated the performance of standard fine-tuning as a generative task and
few-shot learning with open Large Language Models (LLaMA 7B-65B). In addition
to their evaluation in few-shot settings, we explore the potential of open
Large Language Models (Vicuna-13B) as synthetic data generator and propose a
new workflow for this purpose. All evaluated models exhibited substantial
improvements when fine-tuned on synthetic abstracts rather than the original
noisy data. We provide our best performing (f1-score=59.0) BioGPT-Large model
for end-to-end RE of natural-products relationships along with all the
generated synthetic data and the evaluation dataset. See more details at
https://github.com/idiap/abroad-re.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06368" title="Abstract">arXiv:2311.06368</a> [<a href="/pdf/2311.06368" title="Download PDF">pdf</a>, <a href="/format/2311.06368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The AeroSonicDB (YPAD-0523) Dataset for Acoustic Detection and  Classification of Aircraft
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Downward%2C+B">Blake Downward</a>, 
<a href="/search/cs?searchtype=author&query=Nordby%2C+J">Jon Nordby</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The time and expense required to collect and label audio data has been a
prohibitive factor in the availability of domain specific audio datasets. As
the predictive specificity of a classifier depends on the specificity of the
labels it is trained on, it follows that finely-labelled datasets are crucial
for advances in machine learning. Aiming to stimulate progress in the field of
machine listening, this paper introduces AeroSonicDB (YPAD-0523), a dataset of
low-flying aircraft sounds for training acoustic detection and classification
systems. This paper describes the method of exploiting ADS-B radio
transmissions to passively collect and label audio samples. Provides a summary
of the collated dataset. Presents baseline results from three binary
classification models, then discusses the limitations of the current dataset
and its future potential. The dataset contains 625 aircraft recordings ranging
in event duration from 18 to 60 seconds, for a total of 8.87 hours of aircraft
audio. These 625 samples feature 301 unique aircraft, each of which are
supplied with 14 supplementary (non-acoustic) labels to describe the aircraft.
The dataset also contains 3.52 hours of ambient background audio ("silence"),
as a means to distinguish aircraft noise from other local environmental noises.
Additionally, 6 hours of urban soundscape recordings (with aircraft
annotations) are included as an ancillary method for evaluating model
performance, and to provide a testing ground for real-time applications.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06372" title="Abstract">arXiv:2311.06372</a> [<a href="/pdf/2311.06372" title="Download PDF">pdf</a>, <a href="/ps/2311.06372" title="Download PostScript">ps</a>, <a href="/format/2311.06372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blockchain-Enabled Federated Learning Approach for Vehicular Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sultana%2C+S">Shirin Sultana</a>, 
<a href="/search/cs?searchtype=author&query=Hossain%2C+J">Jahin Hossain</a>, 
<a href="/search/cs?searchtype=author&query=Billah%2C+M">Maruf Billah</a>, 
<a href="/search/cs?searchtype=author&query=Shajeeb%2C+H+H">Hasibul Hossain Shajeeb</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+S">Saifur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Ansari%2C+K">Keyvan Ansari</a>, 
<a href="/search/cs?searchtype=author&query=Hasan%2C+K+F">Khondokar Fida Hasan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Data from interconnected vehicles may contain sensitive information such as
location, driving behavior, personal identifiers, etc. Without adequate
safeguards, sharing this data jeopardizes data privacy and system security. The
current centralized data-sharing paradigm in these systems raises particular
concerns about data privacy. Recognizing these challenges, the shift towards
decentralized interactions in technology, as echoed by the principles of
Industry 5.0, becomes paramount. This work is closely aligned with these
principles, emphasizing decentralized, human-centric, and secure technological
interactions in an interconnected vehicular ecosystem. To embody this, we
propose a practical approach that merges two emerging technologies: Federated
Learning (FL) and Blockchain. The integration of these technologies enables the
creation of a decentralized vehicular network. In this setting, vehicles can
learn from each other without compromising privacy while also ensuring data
integrity and accountability. Initial experiments show that compared to
conventional decentralized federated learning techniques, our proposed approach
significantly enhances the performance and security of vehicular networks. The
system's accuracy stands at 91.92\%. While this may appear to be low in
comparison to state-of-the-art federated learning models, our work is
noteworthy because, unlike others, it was achieved in a malicious vehicle
setting. Despite the challenging environment, our method maintains high
accuracy, making it a competent solution for preserving data privacy in
vehicular networks.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06373" title="Abstract">arXiv:2311.06373</a> [<a href="/pdf/2311.06373" title="Download PDF">pdf</a>, <a href="/format/2311.06373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Partial Information Decomposition for Continuous Variables based on  Shared Exclusions: Analytical Formulation and Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ehrlich%2C+D+A">David A. Ehrlich</a>, 
<a href="/search/cs?searchtype=author&query=Schick-Poland%2C+K">Kyle Schick-Poland</a>, 
<a href="/search/cs?searchtype=author&query=Makkeh%2C+A">Abdullah Makkeh</a>, 
<a href="/search/cs?searchtype=author&query=Lanfermann%2C+F">Felix Lanfermann</a>, 
<a href="/search/cs?searchtype=author&query=Wollstadt%2C+P">Patricia Wollstadt</a>, 
<a href="/search/cs?searchtype=author&query=Wibral%2C+M">Michael Wibral</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Probability (math.PR); Statistics Theory (math.ST); Computation (stat.CO)

</div>
<p class="mathjax">Describing statistical dependencies is foundational to empirical scientific
research. For uncovering intricate and possibly non-linear dependencies between
a single target variable and several source variables within a system, a
principled and versatile framework can be found in the theory of Partial
Information Decomposition (PID). Nevertheless, the majority of existing PID
measures are restricted to categorical variables, while many systems of
interest in science are continuous. In this paper, we present a novel analytic
formulation for continuous redundancy--a generalization of mutual
information--drawing inspiration from the concept of shared exclusions in
probability space as in the discrete PID definition of $I^\mathrm{sx}_\cap$.
Furthermore, we introduce a nearest-neighbor based estimator for continuous
PID, and showcase its effectiveness by applying it to a simulated energy
management system provided by the Honda Research Institute Europe GmbH. This
work bridges the gap between the measure-theoretically postulated existence
proofs for a continuous $I^\mathrm{sx}_\cap$ and its practical application to
real-world scientific problems.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06375" title="Abstract">arXiv:2311.06375</a> [<a href="/pdf/2311.06375" title="Download PDF">pdf</a>, <a href="/format/2311.06375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Classification using Combination of Topological Features and  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lima%2C+M+D+P">Mariana D&#xf3;ria Prata Lima</a>, 
<a href="/search/cs?searchtype=author&query=Giraldi%2C+G+A">Gilson Antonio Giraldi</a>, 
<a href="/search/cs?searchtype=author&query=Junior%2C+G+F+M">Gast&#xe3;o Flor&#xea;ncio Miranda Junior</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">In this work we use the persistent homology method, a technique in
topological data analysis (TDA), to extract essential topological features from
the data space and combine them with deep learning features for classification
tasks. In TDA, the concepts of complexes and filtration are building blocks.
Firstly, a filtration is constructed from some complex. Then, persistent
homology classes are computed, and their evolution along the filtration is
visualized through the persistence diagram. Additionally, we applied
vectorization techniques to the persistence diagram to make this topological
information compatible with machine learning algorithms. This was carried out
with the aim of classifying images from multiple classes in the MNIST dataset.
Our approach inserts topological features into deep learning approaches
composed by single and two-streams neural networks architectures based on a
multi-layer perceptron (MLP) and a convolutional neral network (CNN) taylored
for multi-class classification in the MNIST dataset. In our analysis, we
evaluated the obtained results and compared them with the outcomes achieved
through the baselines that are available in the TensorFlow library. The main
conclusion is that topological information may increase neural network accuracy
in multi-class classification tasks with the price of computational complexity
of persistent homology calculation. Up to the best of our knowledge, it is the
first work that combines deep learning features and the combination of
topological features for multi-class classification tasks.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06377" title="Abstract">arXiv:2311.06377</a> [<a href="/pdf/2311.06377" title="Download PDF">pdf</a>, <a href="/format/2311.06377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heaps&#x27; Law in GPT-Neo Large Language Model Emulated Corpora
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+U">Uyen Lai</a>, 
<a href="/search/cs?searchtype=author&query=Randhawa%2C+G+S">Gurjit S. Randhawa</a>, 
<a href="/search/cs?searchtype=author&query=Sheridan%2C+P">Paul Sheridan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 1 figure, 1 table, EVIA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Heaps' law is an empirical relation in text analysis that predicts vocabulary
growth as a function of corpus size. While this law has been validated in
diverse human-authored text corpora, its applicability to large language model
generated text remains unexplored. This study addresses this gap, focusing on
the emulation of corpora using the suite of GPT-Neo large language models. To
conduct our investigation, we emulated corpora of PubMed abstracts using three
different parameter sizes of the GPT-Neo model. Our emulation strategy involved
using the initial five words of each PubMed abstract as a prompt and
instructing the model to expand the content up to the original abstract's
length. Our findings indicate that the generated corpora adhere to Heaps' law.
Interestingly, as the GPT-Neo model size grows, its generated vocabulary
increasingly adheres to Heaps' law as as observed in human-authored text. To
further improve the richness and authenticity of GPT-Neo outputs, future
iterations could emphasize enhancing model size or refining the model
architecture to curtail vocabulary repetition.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06379" title="Abstract">arXiv:2311.06379</a> [<a href="/pdf/2311.06379" title="Download PDF">pdf</a>, <a href="/format/2311.06379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeMuX: Data-efficient Multilingual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khanuja%2C+S">Simran Khanuja</a>, 
<a href="/search/cs?searchtype=author&query=Gowriraj%2C+S">Srinivas Gowriraj</a>, 
<a href="/search/cs?searchtype=author&query=Dery%2C+L">Lucio Dery</a>, 
<a href="/search/cs?searchtype=author&query=Neubig%2C+G">Graham Neubig</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We consider the task of optimally fine-tuning pre-trained multilingual
models, given small amounts of unlabelled target data and an annotation budget.
In this paper, we introduce DEMUX, a framework that prescribes the exact
data-points to label from vast amounts of unlabelled multilingual data, having
unknown degrees of overlap with the target set. Unlike most prior works, our
end-to-end framework is language-agnostic, accounts for model representations,
and supports multilingual target configurations. Our active learning strategies
rely upon distance and uncertainty measures to select task-specific neighbors
that are most informative to label, given a model. DeMuX outperforms strong
baselines in 84% of the test cases, in the zero-shot setting of disjoint source
and target language sets (including multilingual target pools), across three
models and four tasks. Notably, in low-budget settings (5-100 examples), we
observe gains of up to 8-11 F1 points for token-level tasks, and 2-5 F1 for
complex tasks. Our code is released here:
https://github.com/simran-khanuja/demux.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06380" title="Abstract">arXiv:2311.06380</a> [<a href="/pdf/2311.06380" title="Download PDF">pdf</a>, <a href="/format/2311.06380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Theory and implementation of inelastic Constitutive Artificial Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Holthusen%2C+H">Hagen Holthusen</a>, 
<a href="/search/cs?searchtype=author&query=Lamm%2C+L">Lukas Lamm</a>, 
<a href="/search/cs?searchtype=author&query=Brepols%2C+T">Tim Brepols</a>, 
<a href="/search/cs?searchtype=author&query=Reese%2C+S">Stefanie Reese</a>, 
<a href="/search/cs?searchtype=author&query=Kuhl%2C+E">Ellen Kuhl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 54 pages, 14 figures, 14 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Materials Science (cond-mat.mtrl-sci)

</div>
<p class="mathjax">Nature has always been our inspiration in the research, design and
development of materials and has driven us to gain a deep understanding of the
mechanisms that characterize anisotropy and inelastic behavior. All this
knowledge has been accumulated in the principles of thermodynamics. Deduced
from these principles, the multiplicative decomposition combined with pseudo
potentials are powerful and universal concepts. Simultaneously, the tremendous
increase in computational performance enabled us to investigate and rethink our
history-dependent material models to make the most of our predictions. Today,
we have reached a point where materials and their models are becoming
increasingly sophisticated. This raises the question: How do we find the best
model that includes all inelastic effects to explain our complex data?
Constitutive Artificial Neural Networks (CANN) may answer this question. Here,
we extend the CANNs to inelastic materials (iCANN). Rigorous considerations of
objectivity, rigid motion of the reference configuration, multiplicative
decomposition and its inherent non-uniqueness, restrictions of energy and
pseudo potential, and consistent evolution guide us towards the architecture of
the iCANN satisfying thermodynamics per design. We combine feed-forward
networks of the free energy and pseudo potential with a recurrent neural
network approach to take time dependencies into account. We demonstrate that
the iCANN is capable of autonomously discovering models for artificially
generated data, the response of polymers for cyclic loading and the relaxation
behavior of muscle data. As the design of the network is not limited to
visco-elasticity, our vision is that the iCANN will reveal to us new ways to
find the various inelastic phenomena hidden in the data and to understand their
interaction. Our source code, data, and examples are available at
doi.org/10.5281/zenodo.10066805
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06381" title="Abstract">arXiv:2311.06381</a> [<a href="/pdf/2311.06381" title="Download PDF">pdf</a>, <a href="/format/2311.06381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Fidelity Selection for Improved Performance in Human-in-the-Loop  Queues for Underwater Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+P">Piyush Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+V">Vaibhav Srivastava</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">In the context of human-supervised autonomy, we study the problem of optimal
fidelity selection for a human operator performing an underwater visual search
task. Human performance depends on various cognitive factors such as workload
and fatigue. We perform human experiments in which participants perform two
tasks simultaneously: a primary task, which is subject to evaluation, and a
secondary task to estimate their workload. The primary task requires
participants to search for underwater mines in videos, while the secondary task
involves a simple visual test where they respond when a green light displayed
on the side of their screens turns red. Videos arrive as a Poisson process and
are stacked in a queue to be serviced by the human operator. The operator can
choose to watch the video with either normal or high fidelity, with normal
fidelity videos playing at three times the speed of high fidelity ones.
Participants receive rewards for their accuracy in mine detection for each
primary task and penalties based on the number of videos waiting in the queue.
We consider the workload of the operator as a hidden state and model the
workload dynamics as an Input-Output Hidden Markov Model (IOHMM). We use a
Partially Observable Markov Decision Process (POMDP) to learn an optimal
fidelity selection policy, where the objective is to maximize total rewards.
Our results demonstrate improved performance when videos are serviced based on
the optimal fidelity policy compared to a baseline where humans choose the
fidelity level themselves.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06382" title="Abstract">arXiv:2311.06382</a> [<a href="/pdf/2311.06382" title="Download PDF">pdf</a>, <a href="/format/2311.06382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transfer Learning for Structured Pruning under Limited Task Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dery%2C+L">Lucio Dery</a>, 
<a href="/search/cs?searchtype=author&query=Grangier%2C+D">David Grangier</a>, 
<a href="/search/cs?searchtype=author&query=Hannun%2C+A">Awni Hannun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures and 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Large, pre-trained models are problematic to use in resource constrained
applications. Fortunately, task-aware structured pruning methods offer a
solution. These approaches reduce model size by dropping structural units like
layers and attention heads in a manner that takes into account the end-task.
However, these pruning algorithms require more task-specific data than is
typically available. We propose a framework which combines structured pruning
with transfer learning to reduce the need for task-specific data. Our empirical
results answer questions such as: How should the two tasks be coupled? What
parameters should be transferred? And, when during training should transfer
learning be introduced? Leveraging these insights, we demonstrate that our
framework results in pruned models with improved generalization over strong
baselines.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06383" title="Abstract">arXiv:2311.06383</a> [<a href="/pdf/2311.06383" title="Download PDF">pdf</a>, <a href="/format/2311.06383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distilling Large Language Models using Skill-Occupation Graph Context  for HR-Related Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pezeshkpour%2C+P">Pouya Pezeshkpour</a>, 
<a href="/search/cs?searchtype=author&query=Iso%2C+H">Hayate Iso</a>, 
<a href="/search/cs?searchtype=author&query=Lake%2C+T">Thom Lake</a>, 
<a href="/search/cs?searchtype=author&query=Bhutani%2C+N">Nikita Bhutani</a>, 
<a href="/search/cs?searchtype=author&query=Hruschka%2C+E">Estevam Hruschka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Numerous HR applications are centered around resumes and job descriptions.
While they can benefit from advancements in NLP, particularly large language
models, their real-world adoption faces challenges due to absence of
comprehensive benchmarks for various HR tasks, and lack of smaller models with
competitive capabilities. In this paper, we aim to bridge this gap by
introducing the Resume-Job Description Benchmark (RJDB). We meticulously craft
this benchmark to cater to a wide array of HR tasks, including matching and
explaining resumes to job descriptions, extracting skills and experiences from
resumes, and editing resumes. To create this benchmark, we propose to distill
domain-specific knowledge from a large language model (LLM). We rely on a
curated skill-occupation graph to ensure diversity and provide context for LLMs
generation. Our benchmark includes over 50 thousand triples of job
descriptions, matched resumes and unmatched resumes. Using RJDB, we train
multiple smaller student models. Our experiments reveal that the student models
achieve near/better performance than the teacher model (GPT-4), affirming the
effectiveness of the benchmark. Additionally, we explore the utility of RJDB on
out-of-distribution data for skill extraction and resume-job description
matching, in zero-shot and weak supervision manner. We release our datasets and
code to foster further research and industry applications.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06386" title="Abstract">arXiv:2311.06386</a> [<a href="/pdf/2311.06386" title="Download PDF">pdf</a>, <a href="/format/2311.06386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards A Unified Neural Architecture for Visual Recognition and  Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+C">Calvin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+B">Boqing Gong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Ting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Chen Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recognition and reasoning are two pillars of visual understanding. However,
these tasks have an imbalance in focus; whereas recent advances in neural
networks have shown strong empirical performance in visual recognition, there
has been comparably much less success in solving visual reasoning. Intuitively,
unifying these two tasks under a singular framework is desirable, as they are
mutually dependent and beneficial. Motivated by the recent success of
multi-task transformers for visual recognition and language understanding, we
propose a unified neural architecture for visual recognition and reasoning with
a generic interface (e.g., tokens) for both. Our framework enables the
principled investigation of how different visual recognition tasks, datasets,
and inductive biases can help enable spatiotemporal reasoning capabilities.
Noticeably, we find that object detection, which requires spatial localization
of individual objects, is the most beneficial recognition task for reasoning.
We further demonstrate via probing that implicit object-centric representations
emerge automatically inside our framework. Intriguingly, we discover that
certain architectural choices such as the backbone model of the visual encoder
have a significant impact on visual reasoning, but little on object detection.
Given the results of our experiments, we believe that visual reasoning should
be considered as a first-class citizen alongside visual recognition, as they
are strongly correlated but benefit from potentially different design choices.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06390" title="Abstract">arXiv:2311.06390</a> [<a href="/pdf/2311.06390" title="Download PDF">pdf</a>, <a href="/ps/2311.06390" title="Download PostScript">ps</a>, <a href="/format/2311.06390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatGPT in the context of precision agriculture data analytics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Potamitis%2C+I">Ilyas Potamitis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 21 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this study we argue that integrating ChatGPT into the data processing
pipeline of automated sensors in precision agriculture has the potential to
bring several benefits and enhance various aspects of modern farming practices.
Policy makers often face a barrier when they need to get informed about the
situation in vast agricultural fields to reach to decisions. They depend on the
close collaboration between agricultural experts in the field, data analysts,
and technology providers to create interdisciplinary teams that cannot always
be secured on demand or establish effective communication across these diverse
domains to respond in real-time. In this work we argue that the speech
recognition input modality of ChatGPT provides a more intuitive and natural way
for policy makers to interact with the database of the server of an
agricultural data processing system to which a large, dispersed network of
automated insect traps and sensors probes reports. The large language models
map the speech input to text, allowing the user to form its own version of
unconstrained verbal query, raising the barrier of having to learn and adapt
oneself to a specific data analytics software. The output of the language model
can interact through Python code and Pandas with the entire database, visualize
the results and use speech synthesis to engage the user in an iterative and
refining discussion related to the data. We show three ways of how ChatGPT can
interact with the database of the remote server to which a dispersed network of
different modalities (optical counters, vibration recordings, pictures, and
video), report. We examine the potential and the validity of the response of
ChatGPT in analyzing, and interpreting agricultural data, providing real time
insights and recommendations to stakeholders
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06391" title="Abstract">arXiv:2311.06391</a> [<a href="/pdf/2311.06391" title="Download PDF">pdf</a>, <a href="/ps/2311.06391" title="Download PostScript">ps</a>, <a href="/format/2311.06391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BUSSARD -- Better Understanding Social Situations for Autonomous Robot  Decision-Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schiffer%2C+S">Stefan Schiffer</a>, 
<a href="/search/cs?searchtype=author&query=der+P%C3%BCtten%2C+A+R">Astrid Rosenthal-von der P&#xfc;tten</a>, 
<a href="/search/cs?searchtype=author&query=Leibe%2C+B">Bastian Leibe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In SCRITA 2023 Workshop Proceedings (<a href="/abs/2311.05401">arXiv:2311.05401</a>) held in conjunction with 32nd IEEE International Conference on Robot &amp; Human Interactive Communication, 28/08 - 31/08 2023, Busan (Korea)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We report on our effort to create a corpus dataset of different social
context situations in an office setting for further disciplinary and
interdisciplinary research in computer vision, psychology, and
human-robot-interaction. For social robots to be able to behave appropriately,
they need to be aware of the social context they act in. Consider, for example,
a robot with the task to deliver a personal message to a person. If the person
is arguing with an office mate at the time of message delivery, it might be
more appropriate to delay playing the message as to respect the recipient's
privacy and not to interfere with the current situation. This can only be done
if the situation is classified correctly and in a second step if an appropriate
behavior is chosen that fits the social situation. Our work aims to enable
robots accomplishing the task of classifying social situations by creating a
dataset composed of semantically annotated video scenes of office situations
from television soap operas. The dataset can then serve as a basis for
conducting research in both computer vision and human-robot interaction.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06396" title="Abstract">arXiv:2311.06396</a> [<a href="/pdf/2311.06396" title="Download PDF">pdf</a>, <a href="/format/2311.06396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A comprehensive analysis of concept drift locality in data streams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aguiar%2C+G+J">Gabriel J. Aguiar</a>, 
<a href="/search/cs?searchtype=author&query=Cano%2C+A">Alberto Cano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Adapting to drifting data streams is a significant challenge in online
learning. Concept drift must be detected for effective model adaptation to
evolving data properties. Concept drift can impact the data distribution
entirely or partially, which makes it difficult for drift detectors to
accurately identify the concept drift. Despite the numerous concept drift
detectors in the literature, standardized procedures and benchmarks for
comprehensive evaluation considering the locality of the drift are lacking. We
present a novel categorization of concept drift based on its locality and
scale. A systematic approach leads to a set of 2,760 benchmark problems,
reflecting various difficulty levels following our proposed categorization. We
conduct a comparative assessment of 9 state-of-the-art drift detectors across
diverse difficulties, highlighting their strengths and weaknesses for future
research. We examine how drift locality influences the classifier performance
and propose strategies for different drift categories to minimize the recovery
time. Lastly, we provide lessons learned and recommendations for future concept
drift research. Our benchmark data streams and experiments are publicly
available at https://github.com/gabrieljaguiar/locality-concept-drift.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06399" title="Abstract">arXiv:2311.06399</a> [<a href="/pdf/2311.06399" title="Download PDF">pdf</a>, <a href="/format/2311.06399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conservation properties of the augmented basis update &amp; Galerkin  integrator for kinetic problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Einkemmer%2C+L">Lukas Einkemmer</a>, 
<a href="/search/math?searchtype=author&query=Kusch%2C+J">Jonas Kusch</a>, 
<a href="/search/math?searchtype=author&query=Schotth%C3%B6fer%2C+S">Steffen Schotth&#xf6;fer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Numerical simulations of kinetic problems can become prohibitively expensive
due to their large memory footprint and computational costs. A method that has
proven to successfully reduce these costs is the dynamical low-rank
approximation (DLRA). One key question when using DLRA methods is the
construction of robust time integrators that preserve the invariances and
associated conservation laws of the original problem. In this work, we
demonstrate that the augmented basis update &amp; Galerkin integrator (BUG)
preserves solution invariances and the associated conservation laws when using
a conservative truncation step and an appropriate time and space
discretization. We present numerical comparisons to existing conservative
integrators and discuss advantages and disadvantages
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06400" title="Abstract">arXiv:2311.06400</a> [<a href="/pdf/2311.06400" title="Download PDF">pdf</a>, <a href="/format/2311.06400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EviPrompt: A Training-Free Evidential Prompt Generation Method for  Segment Anything Model in Medical Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yinsong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiaqi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Men%2C+A">Aidong Men</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qingchao Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Medical image segmentation has immense clinical applicability but remains a
challenge despite advancements in deep learning. The Segment Anything Model
(SAM) exhibits potential in this field, yet the requirement for expertise
intervention and the domain gap between natural and medical images poses
significant obstacles. This paper introduces a novel training-free evidential
prompt generation method named EviPrompt to overcome these issues. The proposed
method, built on the inherent similarities within medical images, requires only
a single reference image-annotation pair, making it a training-free solution
that significantly reduces the need for extensive labeling and computational
resources. First, to automatically generate prompts for SAM in medical images,
we introduce an evidential method based on uncertainty estimation without the
interaction of clinical experts. Then, we incorporate the human prior into the
prompts, which is vital for alleviating the domain gap between natural and
medical images and enhancing the applicability and usefulness of SAM in medical
scenarios. EviPrompt represents an efficient and robust approach to medical
image segmentation, with evaluations across a broad range of tasks and
modalities confirming its efficacy.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06401" title="Abstract">arXiv:2311.06401</a> [<a href="/pdf/2311.06401" title="Download PDF">pdf</a>, <a href="/format/2311.06401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autoregressive Language Models For Estimating the Entropy of Epic EHR  Audit Logs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Warner%2C+B+C">Benjamin C. Warner</a>, 
<a href="/search/cs?searchtype=author&query=Kannampallil%2C+T">Thomas Kannampallil</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seunghwan Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">EHR audit logs are a highly granular stream of events that capture clinician
activities, and is a significant area of interest for research in
characterizing clinician workflow on the electronic health record (EHR).
Existing techniques to measure the complexity of workflow through EHR audit
logs (audit logs) involve time- or frequency-based cross-sectional aggregations
that are unable to capture the full complexity of a EHR session. We briefly
evaluate the usage of transformer-based tabular language model (tabular LM) in
measuring the entropy or disorderedness of action sequences within workflow and
release the evaluated models publicly.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06402" title="Abstract">arXiv:2311.06402</a> [<a href="/pdf/2311.06402" title="Download PDF">pdf</a>, <a href="/ps/2311.06402" title="Download PostScript">ps</a>, <a href="/format/2311.06402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Dynamic Shortest Paths Toolbox: Low-Congestion Vertex Sparsifiers and  their Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kyng%2C+R">Rasmus Kyng</a>, 
<a href="/search/cs?searchtype=author&query=Meierhans%2C+S">Simon Meierhans</a>, 
<a href="/search/cs?searchtype=author&query=Gutenberg%2C+M+P">Maximilian Probst Gutenberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We present a general toolbox, based on new vertex sparsifiers, for designing
data structures to maintain shortest paths in dynamic graphs.
<br />In an $m$-edge graph undergoing edge insertions and deletions, our data
structures give the first algorithms for maintaining (a) $m^{o(1)}$-approximate
all-pairs shortest paths (APSP) with \emph{worst-case} update time $m^{o(1)}$
and query time $\tilde{O}(1)$, and (b) a tree $T$ that has diameter no larger
than a subpolynomial factor times the diameter of the underlying graph, where
each update is handled in amortized subpolynomial time.
<br />In graphs undergoing only edge deletions, we develop a simpler and more
efficient data structure to maintain a $(1+\epsilon)$-approximate single-source
shortest paths (SSSP) tree $T$ in a graph undergoing edge deletions in
amortized time $m^{o(1)}$ per update.
<br />Our data structures are deterministic. The trees we can maintain are not
subgraphs of $G$, but embed with small edge congestion into $G$. This is in
stark contrast to previous approaches and is useful for algorithms that
internally use trees to route flow.
<br />To illustrate the power of our new toolbox, we show that our SSSP data
structure gives simple deterministic implementations of flow-routing MWU
methods in several contexts, where previously only randomized methods had been
known.
<br />To obtain our toolbox, we give the first algorithm that, given a graph $G$
undergoing edge insertions and deletions and a dynamic terminal set $A$,
maintains a vertex sparsifier $H$ that approximately preserves distances
between terminals in $A$, consists of at most $|A|m^{o(1)}$ vertices and edges,
and can be updated in worst-case time $m^{o(1)}$.
<br />Crucially, our vertex sparsifier construction allows us to maintain a low
edge-congestion embedding of $H$ into $G$, which is needed for our
applications.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06411" title="Abstract">arXiv:2311.06411</a> [<a href="/pdf/2311.06411" title="Download PDF">pdf</a>, <a href="/format/2311.06411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Modular Approaches for Visual Question Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khandelwal%2C+A">Apoorv Khandelwal</a>, 
<a href="/search/cs?searchtype=author&query=Pavlick%2C+E">Ellie Pavlick</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Chen Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at EMNLP 2023 (Main Conference). Source code: <a href="https://github.com/brown-palm/visual-question-decomposition">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Modular neural networks without additional training have recently been shown
to surpass end-to-end neural networks on challenging vision-language tasks. The
latest such methods simultaneously introduce LLM-based code generation to build
programs and a number of skill-specific, task-oriented modules to execute them.
In this paper, we focus on ViperGPT and ask where its additional performance
comes from and how much is due to the (state-of-art, end-to-end) BLIP-2 model
it subsumes vs. additional symbolic components. To do so, we conduct a
controlled study (comparing end-to-end, modular, and prompting-based methods
across several VQA benchmarks). We find that ViperGPT's reported gains over
BLIP-2 can be attributed to its selection of task-specific modules, and when we
run ViperGPT using a more task-agnostic selection of modules, these gains go
away. Additionally, ViperGPT retains much of its performance if we make
prominent alterations to its selection of modules: e.g. removing or retaining
only BLIP-2. Finally, we compare ViperGPT against a prompting-based
decomposition strategy and find that, on some benchmarks, modular approaches
significantly benefit by representing subtasks with natural language, instead
of code.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06413" title="Abstract">arXiv:2311.06413</a> [<a href="/pdf/2311.06413" title="Download PDF">pdf</a>, <a href="/format/2311.06413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forte: An Interactive Visual Analytic Tool for Trust-Augmented Net Load  Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhattacharjee%2C+K">Kaustav Bhattacharjee</a>, 
<a href="/search/cs?searchtype=author&query=Kundu%2C+S">Soumya Kundu</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+I">Indrasis Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Dasgupta%2C+A">Aritra Dasgupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in the proceedings of 2024 IEEE Power &amp; Energy Society Innovative Smart Grid Technologies Conference, North America (ISGT NA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">Accurate net load forecasting is vital for energy planning, aiding decisions
on trade and load distribution. However, assessing the performance of
forecasting models across diverse input variables, like temperature and
humidity, remains challenging, particularly for eliciting a high degree of
trust in the model outcomes. In this context, there is a growing need for
data-driven technological interventions to aid scientists in comprehending how
models react to both noisy and clean input variables, thus shedding light on
complex behaviors and fostering confidence in the outcomes. In this paper, we
present Forte, a visual analytics-based application to explore deep
probabilistic net load forecasting models across various input variables and
understand the error rates for different scenarios. With carefully designed
visual interventions, this web-based interface empowers scientists to derive
insights about model performance by simulating diverse scenarios, facilitating
an informed decision-making process. We discuss observations made using Forte
and demonstrate the effectiveness of visualization techniques to provide
valuable insights into the correlation between weather inputs and net load
forecasts, ultimately advancing grid capabilities by improving trust in
forecasting models.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06414" title="Abstract">arXiv:2311.06414</a> [<a href="/pdf/2311.06414" title="Download PDF">pdf</a>, <a href="/format/2311.06414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Graphs are not Created Equal: Exploring the Properties and  Structure of Real KGs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Teneva%2C+N">Nedelina Teneva</a>, 
<a href="/search/cs?searchtype=author&query=Hruschka%2C+E">Estevam Hruschka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023 New Frontiers in Graph Learning Workshop (NeurIPS GLFrontiers 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Despite the recent popularity of knowledge graph (KG) related tasks and
benchmarks such as KG embeddings, link prediction, entity alignment and
evaluation of the reasoning abilities of pretrained language models as KGs, the
structure and properties of real KGs are not well studied. In this paper, we
perform a large scale comparative study of 29 real KG datasets from diverse
domains such as the natural sciences, medicine, and NLP to analyze their
properties and structural patterns. Based on our findings, we make several
recommendations regarding KG-based model development and evaluation. We believe
that the rich structural information contained in KGs can benefit the
development of better KG models across fields and we hope this study will
contribute to breaking the existing data silos between different areas of
research (e.g., ML, NLP, AI for sciences).
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06417" title="Abstract">arXiv:2311.06417</a> [<a href="/pdf/2311.06417" title="Download PDF">pdf</a>, <a href="/format/2311.06417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resolving uncertainty on the fly: Modeling adaptive driving behavior as  active inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Engstr%C3%B6m%2C+J">Johan Engstr&#xf6;m</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+R">Ran Wei</a>, 
<a href="/search/cs?searchtype=author&query=McDonald%2C+A">Anthony McDonald</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+A">Alfredo Garcia</a>, 
<a href="/search/cs?searchtype=author&query=O%27Kelly%2C+M">Matt O&#x27;Kelly</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+L">Leif Johnson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Understanding adaptive human driving behavior, in particular how drivers
manage uncertainty, is of key importance for developing simulated human driver
models that can be used in the evaluation and development of autonomous
vehicles. However, existing traffic psychology models of adaptive driving
behavior either lack computational rigor or only address specific scenarios
and/or behavioral phenomena. While models developed in the fields of machine
learning and robotics can effectively learn adaptive driving behavior from
data, due to their black box nature, they offer little or no explanation of the
mechanisms underlying the adaptive behavior. Thus, a generalizable,
interpretable, computational model of adaptive human driving behavior is still
lacking. This paper proposes such a model based on active inference, a
behavioral modeling framework originating in computational neuroscience. The
model offers a principled solution to how humans trade progress against caution
through policy selection based on the single mandate to minimize expected free
energy. This casts goal-seeking and information-seeking (uncertainty-resolving)
behavior under a single objective function, allowing the model to seamlessly
resolve uncertainty as a means to obtain its goals. We apply the model in two
apparently disparate driving scenarios that require managing uncertainty, (1)
driving past an occluding object and (2) visual time sharing between driving
and a secondary task, and show how human-like adaptive driving behavior emerges
from the single principle of expected free energy minimization.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06419" title="Abstract">arXiv:2311.06419</a> [<a href="/pdf/2311.06419" title="Download PDF">pdf</a>, <a href="/format/2311.06419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Energy Saving Opportunities in Fault Tolerant HPC Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moran%2C+M">Marina Moran</a>, 
<a href="/search/cs?searchtype=author&query=Balladini%2C+J">Javier Balladini</a>, 
<a href="/search/cs?searchtype=author&query=Rexachs%2C+D">Dolores Rexachs</a>, 
<a href="/search/cs?searchtype=author&query=Rucci%2C+E">Enzo Rucci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review in Journal of Parallel and Distributed Computing (ISSN 1096-0848). arXiv admin note: text overlap with <a href="/abs/2012.11396">arXiv:2012.11396</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Nowadays, improving the energy efficiency of high-performance computing (HPC)
systems is one of the main drivers in scientific and technological research. As
large-scale HPC systems require some fault-tolerant method, the opportunities
to reduce energy consumption should be explored. In particular,
rollback-recovery methods using uncoordinated checkpoints prevent all processes
from re-executing when a failure occurs. In this context, it is possible to
take actions to reduce the energy consumption of the nodes whose processes do
not re-execute. This work is an extension of a previous one, in which we
proposed a series of strategies to manage energy consumption at failure-time.
In this work, we have enriched our previous energy model by including
non-blocking communications (with and without system buffering). We have also
considered other nodes in addition to those directly affected by the failure.
As an indicative example, the simulations show that in an interval of around
8.5 minutes it is possible to achieve around 42% of energy saving. As a result,
we show the feasibility of improving energy efficiency in HPC systems in the
presence of a failure.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06420" title="Abstract">arXiv:2311.06420</a> [<a href="/pdf/2311.06420" title="Download PDF">pdf</a>, <a href="/format/2311.06420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> R$^2$NMPC: A Real-Time Reduced Robustified Nonlinear Model Predictive  Control with Ellipsoidal Uncertainty Sets for Autonomous Vehicle Motion  Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zarrouki%2C+B">Baha Zarrouki</a>, 
<a href="/search/eess?searchtype=author&query=Nunes%2C+J">Jo&#xe3;o Nunes</a>, 
<a href="/search/eess?searchtype=author&query=Betz%2C+J">Johannes Betz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">In this paper, we present a novel Reduced Robustified NMPC (R$^2$NMPC)
algorithm that has the same complexity as an equivalent nominal NMPC while
enhancing it with robustified constraints based on the dynamics of ellipsoidal
uncertainty sets. This promises both a closed-loop- and constraint satisfaction
performance equivalent to common Robustified NMPC approaches, while drastically
reducing the computational complexity. The main idea lies in approximating the
ellipsoidal uncertainty sets propagation over the prediction horizon with the
system dynamics' sensitivities inferred from the last optimal control problem
(OCP) solution, and similarly for the gradients to robustify the constraints.
Thus, we do not require the decision variables related to the uncertainty
propagation within the OCP, rendering it computationally tractable. Next, we
illustrate the real-time control capabilities of our algorithm in handling a
complex, high-dimensional, and highly nonlinear system, namely the trajectory
following of an autonomous passenger vehicle modeled with a dynamic nonlinear
single-track model. Our experimental findings, alongside a comparative
assessment against other Robust NMPC approaches, affirm the robustness of our
method in effectively tracking an optimal racetrack trajectory while satisfying
the nonlinear constraints. This performance is achieved while fully utilizing
the vehicle's interface limits, even at high speeds of up to 37.5m/s, and
successfully managing state estimation disturbances. Remarkably, our approach
maintains a mean solving frequency of 144Hz.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06423" title="Abstract">arXiv:2311.06423</a> [<a href="/pdf/2311.06423" title="Download PDF">pdf</a>, <a href="/format/2311.06423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flatness-aware Adversarial Attack
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+M">Mingyuan Fan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaodan Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Cen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yinggui Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The transferability of adversarial examples can be exploited to launch
black-box attacks. However, adversarial examples often present poor
transferability. To alleviate this issue, by observing that the diversity of
inputs can boost transferability, input regularization based methods are
proposed, which craft adversarial examples by combining several transformed
inputs. We reveal that input regularization based methods make resultant
adversarial examples biased towards flat extreme regions. Inspired by this, we
propose an attack called flatness-aware adversarial attack (FAA) which
explicitly adds a flatness-aware regularization term in the optimization target
to promote the resultant adversarial examples towards flat extreme regions. The
flatness-aware regularization term involves gradients of samples around the
resultant adversarial examples but optimizing gradients requires the evaluation
of Hessian matrix in high-dimension spaces which generally is intractable. To
address the problem, we derive an approximate solution to circumvent the
construction of Hessian matrix, thereby making FAA practical and cheap.
Extensive experiments show the transferability of adversarial examples crafted
by FAA can be considerably boosted compared with state-of-the-art baselines.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06427" title="Abstract">arXiv:2311.06427</a> [<a href="/pdf/2311.06427" title="Download PDF">pdf</a>, <a href="/format/2311.06427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatGPT Prompting Cannot Estimate Predictive Uncertainty in  High-Resource Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pelucchi%2C+M">Martino Pelucchi</a>, 
<a href="/search/cs?searchtype=author&query=Valdenegro-Toro%2C+M">Matias Valdenegro-Toro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 4 figures, with appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">ChatGPT took the world by storm for its impressive abilities. Due to its
release without documentation, scientists immediately attempted to identify its
limits, mainly through its performance in natural language processing (NLP)
tasks. This paper aims to join the growing literature regarding ChatGPT's
abilities by focusing on its performance in high-resource languages and on its
capacity to predict its answers' accuracy by giving a confidence level. The
analysis of high-resource languages is of interest as studies have shown that
low-resource languages perform worse than English in NLP tasks, but no study so
far has analysed whether high-resource languages perform as well as English.
The analysis of ChatGPT's confidence calibration has not been carried out
before either and is critical to learn about ChatGPT's trustworthiness. In
order to study these two aspects, five high-resource languages and two NLP
tasks were chosen. ChatGPT was asked to perform both tasks in the five
languages and to give a numerical confidence value for each answer. The results
show that all the selected high-resource languages perform similarly and that
ChatGPT does not have a good confidence calibration, often being overconfident
and never giving low confidence values.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06428" title="Abstract">arXiv:2311.06428</a> [<a href="/pdf/2311.06428" title="Download PDF">pdf</a>, <a href="/format/2311.06428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Trichotomy for Transductive Online Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hanneke%2C+S">Steve Hanneke</a>, 
<a href="/search/cs?searchtype=author&query=Moran%2C+S">Shay Moran</a>, 
<a href="/search/cs?searchtype=author&query=Shafer%2C+J">Jonathan Shafer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We present new upper and lower bounds on the number of learner mistakes in
the `transductive' online learning setting of Ben-David, Kushilevitz and
Mansour (1997). This setting is similar to standard online learning, except
that the adversary fixes a sequence of instances $x_1,\dots,x_n$ to be labeled
at the start of the game, and this sequence is known to the learner.
Qualitatively, we prove a trichotomy, stating that the minimal number of
mistakes made by the learner as $n$ grows can take only one of precisely three
possible values: $n$, $\Theta\left(\log (n)\right)$, or $\Theta(1)$.
Furthermore, this behavior is determined by a combination of the VC dimension
and the Littlestone dimension. Quantitatively, we show a variety of bounds
relating the number of mistakes to well-known combinatorial dimensions. In
particular, we improve the known lower bound on the constant in the $\Theta(1)$
case from $\Omega\left(\sqrt{\log(d)}\right)$ to $\Omega(\log(d))$ where $d$ is
the Littlestone dimension. Finally, we extend our results to cover multiclass
classification and the agnostic setting.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06429" title="Abstract">arXiv:2311.06429</a> [<a href="/pdf/2311.06429" title="Download PDF">pdf</a>, <a href="/ps/2311.06429" title="Download PostScript">ps</a>, <a href="/format/2311.06429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impact of Load Altering Attacks on Distribution Systems with ZIP  Loads
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Maleki%2C+S">Sajjad Maleki</a>, 
<a href="/search/eess?searchtype=author&query=Pan%2C+S">Shijie Pan</a>, 
<a href="/search/eess?searchtype=author&query=Belmega%2C+E+V">E. Veronica Belmega</a>, 
<a href="/search/eess?searchtype=author&query=Konstantinou%2C+C">Charalambos Konstantinou</a>, 
<a href="/search/eess?searchtype=author&query=Lakshminarayana%2C+S">Subhash Lakshminarayana</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Load-altering attacks (LAAs) pose a significant threat to power systems with
Internet of Things (IoT)-controllable load devices. This research examines the
detrimental impact of LAAs on the voltage profile of distribution systems,
taking into account the realistic load model with constant impedance Z,
constant current I, and constant power P (ZIP). We derive closed-form
expressions for computing the voltages of buses following LAA by making
approximations to the power flow as well as the load model. We also
characterize the minimum number of devices to be manipulated in order to cause
voltage safety violations in the system. We conduct extensive simulations using
the IEEE-33 bus system to verify the accuracy of the proposed approximations
and highlight the difference between the attack impacts while considering
constant power and the ZIP load model (which is more representative of
real-world loads).
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06430" title="Abstract">arXiv:2311.06430</a> [<a href="/pdf/2311.06430" title="Download PDF">pdf</a>, <a href="/format/2311.06430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GOAT: GO to Any Thing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+M">Matthew Chang</a>, 
<a href="/search/cs?searchtype=author&query=Gervet%2C+T">Theophile Gervet</a>, 
<a href="/search/cs?searchtype=author&query=Khanna%2C+M">Mukul Khanna</a>, 
<a href="/search/cs?searchtype=author&query=Yenamandra%2C+S">Sriram Yenamandra</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+D">Dhruv Shah</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+S+Y">So Yeon Min</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+K">Kavit Shah</a>, 
<a href="/search/cs?searchtype=author&query=Paxton%2C+C">Chris Paxton</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Saurabh Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Batra%2C+D">Dhruv Batra</a>, 
<a href="/search/cs?searchtype=author&query=Mottaghi%2C+R">Roozbeh Mottaghi</a>, 
<a href="/search/cs?searchtype=author&query=Malik%2C+J">Jitendra Malik</a>, 
<a href="/search/cs?searchtype=author&query=Chaplot%2C+D+S">Devendra Singh Chaplot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In deployment scenarios such as homes and warehouses, mobile robots are
expected to autonomously navigate for extended periods, seamlessly executing
tasks articulated in terms that are intuitively understandable by human
operators. We present GO To Any Thing (GOAT), a universal navigation system
capable of tackling these requirements with three key features: a) Multimodal:
it can tackle goals specified via category labels, target images, and language
descriptions, b) Lifelong: it benefits from its past experience in the same
environment, and c) Platform Agnostic: it can be quickly deployed on robots
with different embodiments. GOAT is made possible through a modular system
design and a continually augmented instance-aware semantic memory that keeps
track of the appearance of objects from different viewpoints in addition to
category-level semantics. This enables GOAT to distinguish between different
instances of the same category to enable navigation to targets specified by
images and language descriptions. In experimental comparisons spanning over 90
hours in 9 different homes consisting of 675 goals selected across 200+
different object instances, we find GOAT achieves an overall success rate of
83%, surpassing previous methods and ablations by 32% (absolute improvement).
GOAT improves with experience in the environment, from a 60% success rate at
the first goal to a 90% success after exploration. In addition, we demonstrate
that GOAT can readily be applied to downstream tasks such as pick and place and
social navigation.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06432" title="Abstract">arXiv:2311.06432</a> [<a href="/pdf/2311.06432" title="Download PDF">pdf</a>, <a href="/ps/2311.06432" title="Download PostScript">ps</a>, <a href="/format/2311.06432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effective Communication: When to Pull Updates?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agheli%2C+P">Pouya Agheli</a>, 
<a href="/search/cs?searchtype=author&query=Pappas%2C+N">Nikolaos Pappas</a>, 
<a href="/search/cs?searchtype=author&query=Popovski%2C+P">Petar Popovski</a>, 
<a href="/search/cs?searchtype=author&query=Kountouris%2C+M">Marios Kountouris</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">We study a pull-based communication system where a sensing agent updates an
actuation agent using a query control policy, which is adjusted in the
evolution of an observed information source and the usefulness of each update
for achieving a specific goal. For that, a controller decides whether to pull
an update at each slot, predicting what is probably occurring at the source and
how much effective impact that update could have at the endpoint. Thus,
temporal changes in the source evolution could modify the query arrivals so as
to capture important updates. The amount of impact is determined by a grade of
effectiveness (GoE) metric, which incorporates both freshness and usefulness
attributes of the communicated updates. Applying an iterative algorithm, we
derive query decisions that maximize the long-term average GoE for the
communicated packets, subject to cost constraints. Our analytical and numerical
results show that the proposed query policy exhibits higher effectiveness than
existing periodic and probabilistic query policies for a wide range of query
arrival rates.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06433" title="Abstract">arXiv:2311.06433</a> [<a href="/pdf/2311.06433" title="Download PDF">pdf</a>, <a href="/ps/2311.06433" title="Download PostScript">ps</a>, <a href="/format/2311.06433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regret-Optimal Control under Partial Observability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hajar%2C+J">Joudi Hajar</a>, 
<a href="/search/eess?searchtype=author&query=Sabag%2C+O">Oron Sabag</a>, 
<a href="/search/eess?searchtype=author&query=Hassibi%2C+B">Babak Hassibi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ACC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper studies online solutions for regret-optimal control in partially
observable systems over an infinite-horizon. Regret-optimal control aims to
minimize the difference in LQR cost between causal and non-causal controllers
while considering the worst-case regret across all $\ell_2$-norm-bounded
disturbance and measurement sequences. Building on ideas from Sabag et al.,
2023, on the the full-information setting, our work extends the framework to
the scenario of partial observability (measurement-feedback). We derive an
explicit state-space solution when the non-causal solution is the one that
minimizes the $\mathcal H_2$ criterion, and demonstrate its practical utility
on several practical examples. These results underscore the framework's
significant relevance and applicability in real-world systems.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06436" title="Abstract">arXiv:2311.06436</a> [<a href="/pdf/2311.06436" title="Download PDF">pdf</a>, <a href="/format/2311.06436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augmented Degree Correction for Bipartite Networks with Applications to  Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leinwand%2C+B">Benjamin Leinwand</a>, 
<a href="/search/cs?searchtype=author&query=Pipiras%2C+V">Vladas Pipiras</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Applications (stat.AP)

</div>
<p class="mathjax">In recommender systems, users rate items, and are subsequently served other
product recommendations based on these ratings. Even though users usually rate
a tiny percentage of the available items, the system tries to estimate
unobserved preferences by finding similarities across users and across items.
In this work, we treat the observed ratings data as partially observed, dense,
weighted, bipartite networks. For a class of systems without outside
information, we adapt an approach developed for dense, weighted networks to
account for unobserved edges and the bipartite nature of the problem. This
approach allows for community structure, and for local estimation of flexible
patterns of ratings across different pairs of communities. We compare the
performance of our proposed approach to existing methods on a simulated data
set, as well as on a data set of joke ratings, examining model performance in
both cases at differing levels of sparsity.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06438" title="Abstract">arXiv:2311.06438</a> [<a href="/pdf/2311.06438" title="Download PDF">pdf</a>, <a href="/format/2311.06438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controllability-Constrained Deep Network Models for Enhanced Control of  Dynamical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sharma%2C+S">Suruchi Sharma</a>, 
<a href="/search/eess?searchtype=author&query=Makarenko%2C+V">Volodymyr Makarenko</a>, 
<a href="/search/eess?searchtype=author&query=Kumar%2C+G">Gautam Kumar</a>, 
<a href="/search/eess?searchtype=author&query=Tiomkin%2C+S">Stas Tiomkin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Control of a dynamical system without the knowledge of dynamics is an
important and challenging task. Modern machine learning approaches, such as
deep neural networks (DNNs), allow for the estimation of a dynamics model from
control inputs and corresponding state observation outputs. Such data-driven
models are often utilized for the derivation of model-based controllers.
However, in general, there are no guarantees that a model represented by DNNs
will be controllable according to the formal control-theoretical meaning of
controllability, which is crucial for the design of effective controllers. This
often precludes the use of DNN-estimated models in applications, where formal
controllability guarantees are required. In this proof-of-the-concept work, we
propose a control-theoretical method that explicitly enhances models estimated
from data with controllability. That is achieved by augmenting the model
estimation objective with a controllability constraint, which penalizes models
with a low degree of controllability. As a result, the models estimated with
the proposed controllability constraint allow for the derivation of more
efficient controllers, they are interpretable by the control-theoretical
quantities and have a lower long-term prediction error. The proposed method
provides new insights on the connection between the DNN-based estimation of
unknown dynamics and the control-theoretical guarantees of the solution
properties. We demonstrate the superiority of the proposed method in two
standard classical control systems with state observation given by low
resolution high-dimensional images.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06440" title="Abstract">arXiv:2311.06440</a> [<a href="/pdf/2311.06440" title="Download PDF">pdf</a>, <a href="/format/2311.06440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Separating the Wheat from the Chaff with BREAD: An open-source benchmark  and metrics to detect redundancy in text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caswell%2C+I">Isaac Caswell</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lisa Wang</a>, 
<a href="/search/cs?searchtype=author&query=Papadimitriou%2C+I">Isabel Papadimitriou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to GEM workshop 2023; 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Data quality is a problem that perpetually resurfaces throughout the field of
NLP, regardless of task, domain, or architecture, and remains especially severe
for lower-resource languages. A typical and insidious issue, affecting both
training data and model output, is data that is repetitive and dominated by
linguistically uninteresting boilerplate, such as price catalogs or
computer-generated log files. Though this problem permeates many web-scraped
corpora, there has yet to be a benchmark to test against, or a systematic study
to find simple metrics that generalize across languages and agree with human
judgements of data quality. In the present work, we create and release BREAD, a
human-labeled benchmark on repetitive boilerplate vs. plausible linguistic
content, spanning 360 languages. We release several baseline CRED (Character
REDundancy) scores along with it, and evaluate their effectiveness on BREAD. We
hope that the community will use this resource to develop better filtering
methods, and that our reference implementations of CRED scores can become
standard corpus evaluation tools, driving the development of cleaner language
modeling corpora, especially in low-resource languages.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06443" title="Abstract">arXiv:2311.06443</a> [<a href="/pdf/2311.06443" title="Download PDF">pdf</a>, <a href="/format/2311.06443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CVTHead: One-shot Controllable Head Avatar with Vertex-feature  Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Haoyu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shanlin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xiangyi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Kun Han</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaohui Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Reconstructing personalized animatable head avatars has significant
implications in the fields of AR/VR. Existing methods for achieving explicit
face control of 3D Morphable Models (3DMM) typically rely on multi-view images
or videos of a single subject, making the reconstruction process complex.
Additionally, the traditional rendering pipeline is time-consuming, limiting
real-time animation possibilities. In this paper, we introduce CVTHead, a novel
approach that generates controllable neural head avatars from a single
reference image using point-based neural rendering. CVTHead considers the
sparse vertices of mesh as the point set and employs the proposed
Vertex-feature Transformer to learn local feature descriptors for each vertex.
This enables the modeling of long-range dependencies among all the vertices.
Experimental results on the VoxCeleb dataset demonstrate that CVTHead achieves
comparable performance to state-of-the-art graphics-based methods. Moreover, it
enables efficient rendering of novel human heads with various expressions, head
poses, and camera views. These attributes can be explicitly controlled using
the coefficients of 3DMMs, facilitating versatile and realistic animation in
real-time scenarios.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06444" title="Abstract">arXiv:2311.06444</a> [<a href="/pdf/2311.06444" title="Download PDF">pdf</a>, <a href="/format/2311.06444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Pooling Bias in E-commerce Search via False Negative  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaochen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xiao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruhan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Na%2C+T">Taesik Na</a>, 
<a href="/search/cs?searchtype=author&query=Tenneti%2C+T">Tejaswi Tenneti</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haixun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+F">Fenglong Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to WWW'24 Industry Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Efficient and accurate product relevance assessment is critical for user
experiences and business success. Training a proficient relevance assessment
model requires high-quality query-product pairs, often obtained through
negative sampling strategies. Unfortunately, current methods introduce pooling
bias by mistakenly sampling false negatives, diminishing performance and
business impact. To address this, we present Bias-mitigating Hard Negative
Sampling (BHNS), a novel negative sampling strategy tailored to identify and
adjust for false negatives, building upon our original False Negative
Estimation algorithm. Our experiments in the Instacart search setting confirm
BHNS as effective for practical e-commerce use. Furthermore, comparative
analyses on public dataset showcase its domain-agnostic potential for diverse
applications.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06446" title="Abstract">arXiv:2311.06446</a> [<a href="/pdf/2311.06446" title="Download PDF">pdf</a>, <a href="/ps/2311.06446" title="Download PostScript">ps</a>, <a href="/format/2311.06446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> THOS: A Benchmark Dataset for Targeted Hate and Offensive Speech
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Almohaimeed%2C+S">Saad Almohaimeed</a>, 
<a href="/search/cs?searchtype=author&query=Almohaimeed%2C+S">Saleh Almohaimeed</a>, 
<a href="/search/cs?searchtype=author&query=Shafin%2C+A+A">Ashfaq Ali Shafin</a>, 
<a href="/search/cs?searchtype=author&query=Carbunar%2C+B">Bogdan Carbunar</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%B6l%C3%B6ni%2C+L">Ladislau B&#xf6;l&#xf6;ni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Detecting harmful content on social media, such as Twitter, is made difficult
by the fact that the seemingly simple yes/no classification conceals a
significant amount of complexity. Unfortunately, while several datasets have
been collected for training classifiers in hate and offensive speech, there is
a scarcity of datasets labeled with a finer granularity of target classes and
specific targets. In this paper, we introduce THOS, a dataset of 8.3k tweets
manually labeled with fine-grained annotations about the target of the message.
We demonstrate that this dataset makes it feasible to train classifiers, based
on Large Language Models, to perform classification at this level of
granularity.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06453" title="Abstract">arXiv:2311.06453</a> [<a href="/pdf/2311.06453" title="Download PDF">pdf</a>, <a href="/format/2311.06453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DocGen: Generating Detailed Parameter Docstrings in Python
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Venkatkrishna%2C+V">Vatsal Venkatkrishna</a>, 
<a href="/search/cs?searchtype=author&query=Nagabushanam%2C+D+S">Durga Shree Nagabushanam</a>, 
<a href="/search/cs?searchtype=author&query=Simon%2C+E+I">Emmanuel Iko-Ojo Simon</a>, 
<a href="/search/cs?searchtype=author&query=Fard%2C+F+H">Fatemeh H. Fard</a>, 
<a href="/search/cs?searchtype=author&query=Vidoni%2C+M">Melina Vidoni</a>, 
<a href="/search/cs?searchtype=author&query=Codabux%2C+Z">Zadia Codabux</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Documentation debt hinders the effective utilization of open-source software.
Although code summarization tools have been helpful for developers, most would
prefer a detailed account of each parameter in a function rather than a
high-level summary. However, generating such a summary is too intricate for a
single generative model to produce reliably due to the lack of high-quality
training data. Thus, we propose a multi-step approach that combines multiple
task-specific models, each adept at producing a specific section of a
docstring. The combination of these models ensures the inclusion of each
section in the final docstring. We compared the results from our approach with
existing generative models using both automatic metrics and a human-centred
evaluation with 17 participating developers, which proves the superiority of
our approach over existing methods.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06454" title="Abstract">arXiv:2311.06454</a> [<a href="/pdf/2311.06454" title="Download PDF">pdf</a>, <a href="/format/2311.06454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Saliency-based Clustering Framework for Identifying Aberrant  Predictions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Montserrat%2C+A+T">Aina Tersol Montserrat</a>, 
<a href="/search/cs?searchtype=author&query=Loftus%2C+A+R">Alexander R. Loftus</a>, 
<a href="/search/cs?searchtype=author&query=Daihes%2C+Y">Yael Daihes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In machine learning, classification tasks serve as the cornerstone of a wide
range of real-world applications. Reliable, trustworthy classification is
particularly intricate in biomedical settings, where the ground truth is often
inherently uncertain and relies on high degrees of human expertise for
labeling. Traditional metrics such as precision and recall, while valuable, are
insufficient for capturing the nuances of these ambiguous scenarios. Here we
introduce the concept of aberrant predictions, emphasizing that the nature of
classification errors is as critical as their frequency. We propose a novel,
efficient training methodology aimed at both reducing the misclassification
rate and discerning aberrant predictions. Our framework demonstrates a
substantial improvement in model performance, achieving a 20\% increase in
precision. We apply this methodology to the less-explored domain of veterinary
radiology, where the stakes are high but have not been as extensively studied
compared to human medicine. By focusing on the identification and mitigation of
aberrant predictions, we enhance the utility and trustworthiness of machine
learning classifiers in high-stakes, real-world scenarios, including new
applications in the veterinary world.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06455" title="Abstract">arXiv:2311.06455</a> [<a href="/pdf/2311.06455" title="Download PDF">pdf</a>, <a href="/format/2311.06455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aria-NeRF: Multimodal Egocentric View Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiankai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+J">Jianing Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Chuanyang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Tucker%2C+J">John Tucker</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Javier Yu</a>, 
<a href="/search/cs?searchtype=author&query=Schwager%2C+M">Mac Schwager</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We seek to accelerate research in developing rich, multimodal scene models
trained from egocentric data, based on differentiable volumetric ray-tracing
inspired by Neural Radiance Fields (NeRFs). The construction of a NeRF-like
model from an egocentric image sequence plays a pivotal role in understanding
human behavior and holds diverse applications within the realms of VR/AR. Such
egocentric NeRF-like models may be used as realistic simulations, contributing
significantly to the advancement of intelligent agents capable of executing
tasks in the real-world. The future of egocentric view synthesis may lead to
novel environment representations going beyond today's NeRFs by augmenting
visual data with multimodal sensors such as IMU for egomotion tracking, audio
sensors to capture surface texture and human language context, and eye-gaze
trackers to infer human attention patterns in the scene. To support and
facilitate the development and evaluation of egocentric multimodal scene
modeling, we present a comprehensive multimodal egocentric video dataset. This
dataset offers a comprehensive collection of sensory data, featuring RGB
images, eye-tracking camera footage, audio recordings from a microphone,
atmospheric pressure readings from a barometer, positional coordinates from
GPS, connectivity details from Wi-Fi and Bluetooth, and information from
dual-frequency IMU datasets (1kHz and 800Hz) paired with a magnetometer. The
dataset was collected with the Meta Aria Glasses wearable device platform. The
diverse data modalities and the real-world context captured within this dataset
serve as a robust foundation for furthering our understanding of human behavior
and enabling more immersive and intelligent experiences in the realms of VR,
AR, and robotics.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06456" title="Abstract">arXiv:2311.06456</a> [<a href="/pdf/2311.06456" title="Download PDF">pdf</a>, <a href="/format/2311.06456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asymmetric Contrastive Multimodal Learning for Advancing Chemical  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunrui Li</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+P">Pengyu Hong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The versatility of multimodal deep learning holds tremendous promise for
advancing scientific research and practical applications. As this field
continues to evolve, the collective power of cross-modal analysis promises to
drive transformative innovations, leading us to new frontiers in chemical
understanding and discovery. Hence, we introduce Asymmetric Contrastive
M}ultimodal Learning (ACML) as a novel approach tailored for molecules,
showcasing its potential to advance the field of chemistry. ACML harnesses the
power of effective asymmetric contrastive learning to seamlessly transfer
information from various chemical modalities to molecular graph
representations. By combining pre-trained chemical unimodal encoders and a
shallow-designed graph encoder, ACML facilitates the assimilation of
coordinated chemical semantics from different modalities, leading to
comprehensive representation learning with efficient training. This innovative
framework enhances the interpretability of learned representations and bolsters
the expressive power of graph neural networks. Through practical tasks such as
isomer discrimination and uncovering crucial chemical properties for drug
discovery, ACML exhibits its capability to revolutionize chemical research and
applications, providing a deeper understanding of chemical semantics of
different modalities.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06460" title="Abstract">arXiv:2311.06460</a> [<a href="/pdf/2311.06460" title="Download PDF">pdf</a>, <a href="/format/2311.06460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Continual Learning via Logit Adjusted Softmax
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhehao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tao Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Chenhe Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yingwen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaolin Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Online continual learning is a challenging problem where models must learn
from a non-stationary data stream while avoiding catastrophic forgetting.
Inter-class imbalance during training has been identified as a major cause of
forgetting, leading to model prediction bias towards recently learned classes.
In this paper, we theoretically analyze that inter-class imbalance is entirely
attributed to imbalanced class-priors, and the function learned from
intra-class intrinsic distributions is the Bayes-optimal classifier. To that
end, we present that a simple adjustment of model logits during training can
effectively resist prior class bias and pursue the corresponding Bayes-optimum.
Our proposed method, Logit Adjusted Softmax, can mitigate the impact of
inter-class imbalance not only in class-incremental but also in realistic
general setups, with little additional computational cost. We evaluate our
approach on various benchmarks and demonstrate significant performance
improvements compared to prior arts. For example, our approach improves the
best baseline by 4.6% on CIFAR10.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06461" title="Abstract">arXiv:2311.06461</a> [<a href="/pdf/2311.06461" title="Download PDF">pdf</a>, <a href="/ps/2311.06461" title="Download PostScript">ps</a>, <a href="/format/2311.06461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> L-structure least squares solutions of reduced biquaternion matrix  equations with applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ahmad%2C+S+S">Sk. Safique Ahmad</a>, 
<a href="/search/math?searchtype=author&query=Bhadala%2C+N">Neha Bhadala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper presents a framework for computing the structure-constrained least
squares solutions to the generalized reduced biquaternion matrix equations
(RBMEs). The investigation focuses on three different matrix equations: a
linear matrix equation with multiple unknown L-structures, a linear matrix
equation with one unknown L-structure, and the general coupled linear matrix
equations with one unknown L-structure. Our approach leverages the complex
representation of reduced biquaternion matrices. To showcase the versatility of
the developed framework, we utilize it to find structure-constrained solutions
for complex and real matrix equations, broadening its applicability to various
inverse problems. Specifically, we explore its utility in addressing partially
described inverse eigenvalue problems (PDIEPs) and generalized PDIEPs. Our
study concludes with numerical examples.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06462" title="Abstract">arXiv:2311.06462</a> [<a href="/pdf/2311.06462" title="Download PDF">pdf</a>, <a href="/ps/2311.06462" title="Download PostScript">ps</a>, <a href="/format/2311.06462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Electronic Communication Data Link Encryption Simulation Based on  Wireless Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+R">Rulin Bai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In order to improve the simulation effect of electronic communication data
link encryption, the author proposes a solution based on wireless
communication. The main content of this technology is based on the research of
wireless communication, improve the elliptic curve cryptographic algorithm to
build a system encryption model, obtain legal and valid node private keys,
evaluate and analyze the relevant security attributes of the system, verify the
security of the keys, and realize the encryption optimization of wireless
network communication. Experimental results show that: Using the improved
elliptic curve to simulate the system data chain encryption under the
certificateless public key cryptosystem in network communication, the time is
only 2.31 milliseconds, which is lower than other algorithms. Conclusion: It is
proved that the technology research based on wireless communication can
effectively improve the encryption simulation effect of electronic
communication data link.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06464" title="Abstract">arXiv:2311.06464</a> [<a href="/pdf/2311.06464" title="Download PDF">pdf</a>, <a href="/format/2311.06464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algebraic technique for mixed least squares and total least squares  problem in the reduced biquaternion algebra
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ahmad%2C+S+S">Sk. Safique Ahmad</a>, 
<a href="/search/math?searchtype=author&query=Bhadala%2C+N">Neha Bhadala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper presents the reduced biquaternion mixed least squares and total
least squares (RBMTLS) method for solving an overdetermined system $AX \approx
B$ in the reduced biquaternion algebra. The RBMTLS method is suitable when
matrix $B$ and a few columns of matrix $A$ contain errors. By examining real
representations of reduced biquaternion matrices, we investigate the conditions
for the existence and uniqueness of the real RBMTLS solution and derive an
explicit expression for the real RBMTLS solution. The proposed technique covers
two special cases: the reduced biquaternion total least squares (RBTLS) method
and the reduced biquaternion least squares (RBLS) method. Furthermore, the
developed method is also used to find the best approximate solution to $AX
\approx B$ over a complex field. Lastly, a numerical example is presented to
support our findings.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06465" title="Abstract">arXiv:2311.06465</a> [<a href="/pdf/2311.06465" title="Download PDF">pdf</a>, <a href="/ps/2311.06465" title="Download PostScript">ps</a>, <a href="/format/2311.06465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The stabilizer free weak Galerkin mixed finite elements method for the  biharmonic equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gu%2C+S">Shanshan Gu</a>, 
<a href="/search/math?searchtype=author&query=Zhai%2C+Q">Qilong Zhai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this article, the stabilizer free weak Galerkin (SFWG) finite element
method is applied to the Ciarlet-Raviart mixed form of the Biharmonic equation.
We utilize the SFWG solutions of the second elliptic problems to define
projection operators, build error equations, and further derive the error
estimates. Finally, numerical examples support the results reached by the
theory.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06467" title="Abstract">arXiv:2311.06467</a> [<a href="/pdf/2311.06467" title="Download PDF">pdf</a>, <a href="/format/2311.06467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Language-based Mental Health Assessment with Item-Response  Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Varadarajan%2C+V">Vasudha Varadarajan</a>, 
<a href="/search/cs?searchtype=author&query=Sikstr%C3%B6m%2C+S">Sverker Sikstr&#xf6;m</a>, 
<a href="/search/cs?searchtype=author&query=Kjell%2C+O+N+E">Oscar N.E. Kjell</a>, 
<a href="/search/cs?searchtype=author&query=Schwartz%2C+H+A">H. Andrew Schwartz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Mental health issues widely vary across individuals - the manifestations of
signs and symptoms can be fairly heterogeneous. Recently, language-based
depression and anxiety assessments have shown promise for capturing this
heterogeneous nature by evaluating a patient's own language, but such
approaches require a large sample of words per person to be accurate. In this
work, we introduce adaptive language-based assessment - the task of iteratively
estimating an individual's psychological score based on limited language
responses to questions that the model also decides to ask. To this end, we
explore two statistical learning-based approaches for measurement/scoring:
classical test theory (CTT) and item response theory (IRT). We find that using
adaptive testing in general can significantly reduce the number of questions
required to achieve high validity (r ~ 0.7) with standardized tests, bringing
down from 11 total questions down to 3 for depression and 5 for anxiety. Given
the combinatorial nature of the problem, we empirically evaluate multiple
strategies for both the ordering and scoring objectives, introducing two new
methods: a semi-supervised item response theory based method (ALIRT), and a
supervised actor-critic based model. While both of the models achieve
significant improvements over random and fixed orderings, we find ALIRT to be a
scalable model that achieves the highest accuracy with lower numbers of
questions (e.g. achieves Pearson r ~ 0.93 after only 3 questions versus asking
all 11 questions). Overall, ALIRT allows prompting a reduced number of
questions without compromising accuracy or overhead computational costs.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06472" title="Abstract">arXiv:2311.06472</a> [<a href="/pdf/2311.06472" title="Download PDF">pdf</a>, <a href="/format/2311.06472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Special least squares solutions of the reduced biquaternion matrix  equation with applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ahmad%2C+S+S">Sk. Safique Ahmad</a>, 
<a href="/search/math?searchtype=author&query=Bhadala%2C+N">Neha Bhadala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper presents an efficient method for obtaining the least squares
Hermitian solutions of the reduced biquaternion matrix equation $(AXB, CXD) =
(E, F )$. The method leverages the real representation of reduced biquaternion
matrices. Furthermore, we establish the necessary and sufficient conditions for
the existence and uniqueness of the Hermitian solution, along with a general
expression for it. Notably, this approach differs from the one previously
developed by Yuan et al. $(2020)$, which relied on the complex representation
of reduced biquaternion matrices. In contrast, our method exclusively employs
real matrices and utilizes real arithmetic operations, resulting in enhanced
efficiency. We also apply our developed framework to find the Hermitian
solutions for the complex matrix equation $(AXB, CXD) = (E, F )$, expanding its
utility in addressing inverse problems. Specifically, we investigate its
effectiveness in addressing partially described inverse eigenvalue problems.
Finally, we provide numerical examples to demonstrate the effectiveness of our
method and its superiority over the existing approach.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06474" title="Abstract">arXiv:2311.06474</a> [<a href="/pdf/2311.06474" title="Download PDF">pdf</a>, <a href="/format/2311.06474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An energy-based discontinuous Galerkin method for the nonlinear  Schr&#xf6;dinger equation with wave operator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ren%2C+K">Kui Ren</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+L">Lu Zhang</a>, 
<a href="/search/math?searchtype=author&query=Zhou%2C+Y">Yin Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This work develops an energy-based discontinuous Galerkin (EDG) method for
the nonlinear Schr\"odinger equation with the wave operator. The focus of the
study is on the energy-conserving or energy-dissipating behavior of the method
with some simple mesh-independent numerical fluxes we designed. We establish
error estimates in the energy norm that require careful selection of a test
function for the auxiliary equation involving the time derivative of the
displacement variable. A critical part of the convergence analysis is to
establish the L2 error bounds for the time derivative of the approximation
error in the displacement variable by using the equation that determines its
mean value. Using a specially chosen test function, we show that one can create
a linear system for the time evolution of the unknowns even when dealing with
nonlinear properties in the original problem. Extensive numerical experiments
are provided to demonstrate the optimal convergence of the scheme in the L2
norm with our choices of the numerical flux.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06477" title="Abstract">arXiv:2311.06477</a> [<a href="/pdf/2311.06477" title="Download PDF">pdf</a>, <a href="/ps/2311.06477" title="Download PostScript">ps</a>, <a href="/format/2311.06477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Report of the 1st Workshop on Generative AI and Law
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cooper%2C+A+F">A. Feder Cooper</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Katherine Lee</a>, 
<a href="/search/cs?searchtype=author&query=Grimmelmann%2C+J">James Grimmelmann</a>, 
<a href="/search/cs?searchtype=author&query=Ippolito%2C+D">Daphne Ippolito</a>, 
<a href="/search/cs?searchtype=author&query=Callison-Burch%2C+C">Christopher Callison-Burch</a>, 
<a href="/search/cs?searchtype=author&query=Choquette-Choo%2C+C+A">Christopher A. Choquette-Choo</a>, 
<a href="/search/cs?searchtype=author&query=Mireshghallah%2C+N">Niloofar Mireshghallah</a>, 
<a href="/search/cs?searchtype=author&query=Brundage%2C+M">Miles Brundage</a>, 
<a href="/search/cs?searchtype=author&query=Mimno%2C+D">David Mimno</a>, 
<a href="/search/cs?searchtype=author&query=Choksi%2C+M+Z">Madiha Zahrah Choksi</a>, 
<a href="/search/cs?searchtype=author&query=Balkin%2C+J+M">Jack M. Balkin</a>, 
<a href="/search/cs?searchtype=author&query=Carlini%2C+N">Nicholas Carlini</a>, 
<a href="/search/cs?searchtype=author&query=De+Sa%2C+C">Christopher De Sa</a>, 
<a href="/search/cs?searchtype=author&query=Frankle%2C+J">Jonathan Frankle</a>, 
<a href="/search/cs?searchtype=author&query=Ganguli%2C+D">Deep Ganguli</a>, 
<a href="/search/cs?searchtype=author&query=Gipson%2C+B">Bryant Gipson</a>, 
<a href="/search/cs?searchtype=author&query=Guadamuz%2C+A">Andres Guadamuz</a>, 
<a href="/search/cs?searchtype=author&query=Harris%2C+S+L">Swee Leng Harris</a>, 
<a href="/search/cs?searchtype=author&query=Jacobs%2C+A+Z">Abigail Z. Jacobs</a>, 
<a href="/search/cs?searchtype=author&query=Joh%2C+E">Elizabeth Joh</a>, 
<a href="/search/cs?searchtype=author&query=Kamath%2C+G">Gautam Kamath</a>, 
<a href="/search/cs?searchtype=author&query=Lemley%2C+M">Mark Lemley</a>, 
<a href="/search/cs?searchtype=author&query=Matthews%2C+C">Cass Matthews</a>, 
<a href="/search/cs?searchtype=author&query=McLeavey%2C+C">Christine McLeavey</a>, 
<a href="/search/cs?searchtype=author&query=McSherry%2C+C">Corynne McSherry</a>, 
<a href="/search/cs?searchtype=author&query=Nasr%2C+M">Milad Nasr</a>, 
<a href="/search/cs?searchtype=author&query=Ohm%2C+P">Paul Ohm</a>, 
<a href="/search/cs?searchtype=author&query=Roberts%2C+A">Adam Roberts</a>, 
<a href="/search/cs?searchtype=author&query=Rubin%2C+T">Tom Rubin</a>, 
<a href="/search/cs?searchtype=author&query=Samuelson%2C+P">Pamela Samuelson</a>, 
<a href="/search/cs?searchtype=author&query=Schubert%2C+L">Ludwig Schubert</a>, 
<a href="/search/cs?searchtype=author&query=Vaccaro%2C+K">Kristen Vaccaro</a>, 
<a href="/search/cs?searchtype=author&query=Villa%2C+L">Luis Villa</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Felix Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zeide%2C+E">Elana Zeide</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">This report presents the takeaways of the inaugural Workshop on Generative AI
and Law (GenLaw), held in July 2023. A cross-disciplinary group of
practitioners and scholars from computer science and law convened to discuss
the technical, doctrinal, and policy challenges presented by law for Generative
AI, and by Generative AI for law, with an emphasis on U.S. law in particular.
We begin the report with a high-level statement about why Generative AI is both
immensely significant and immensely challenging for law. To meet these
challenges, we conclude that there is an essential need for 1) a shared
knowledge base that provides a common conceptual language for experts across
disciplines; 2) clarification of the distinctive technical capabilities of
generative-AI systems, as compared and contrasted to other computer and AI
systems; 3) a logical taxonomy of the legal issues these systems raise; and, 4)
a concrete research agenda to promote collaboration and knowledge-sharing on
emerging issues at the intersection of Generative AI and law. In this report,
we synthesize the key takeaways from the GenLaw workshop that begin to address
these needs. All of the listed authors contributed to the workshop upon which
this report is based, but they and their organizations do not necessarily
endorse all of the specific claims in this report.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06480" title="Abstract">arXiv:2311.06480</a> [<a href="/pdf/2311.06480" title="Download PDF">pdf</a>, <a href="/format/2311.06480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Fine-tuning using Generated Respiratory Sound to Address  Class Imbalance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">June-Woo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+C">Chihyeon Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Toikkanen%2C+M">Miika Toikkanen</a>, 
<a href="/search/cs?searchtype=author&query=Bae%2C+S">Sangmin Bae</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+H">Ho-Young Jung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted in NeurIPS 2023 Workshop on Deep Generative Models for Health (DGM4H)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Deep generative models have emerged as a promising approach in the medical
image domain to address data scarcity. However, their use for sequential data
like respiratory sounds is less explored. In this work, we propose a
straightforward approach to augment imbalanced respiratory sound data using an
audio diffusion model as a conditional neural vocoder. We also demonstrate a
simple yet effective adversarial fine-tuning method to align features between
the synthetic and real respiratory sound samples to improve respiratory sound
classification performance. Our experimental results on the ICBHI dataset
demonstrate that the proposed adversarial fine-tuning is effective, while only
using the conventional augmentation method shows performance degradation.
Moreover, our method outperforms the baseline by 2.24% on the ICBHI Score and
improves the accuracy of the minority classes up to 26.58%. For the
supplementary material, we provide the code at
https://github.com/kaen2891/adversarial_fine-tuning_using_generated_respiratory_sound.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06481" title="Abstract">arXiv:2311.06481</a> [<a href="/pdf/2311.06481" title="Download PDF">pdf</a>, <a href="/format/2311.06481" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topology-Matching Normalizing Flows for Out-of-Distribution Detection in  Robot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jianxiang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jongseok Lee</a>, 
<a href="/search/cs?searchtype=author&query=Geisler%2C+S">Simon Geisler</a>, 
<a href="/search/cs?searchtype=author&query=Gunnemann%2C+S">Stephan Gunnemann</a>, 
<a href="/search/cs?searchtype=author&query=Triebel%2C+R">Rudolph Triebel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted on CoRL2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">To facilitate reliable deployments of autonomous robots in the real world,
Out-of-Distribution (OOD) detection capabilities are often required. A powerful
approach for OOD detection is based on density estimation with Normalizing
Flows (NFs). However, we find that prior work with NFs attempts to match the
complex target distribution topologically with naive base distributions leading
to adverse implications. In this work, we circumvent this topological mismatch
using an expressive class-conditional base distribution trained with an
information-theoretic objective to match the required topology. The proposed
method enjoys the merits of wide compatibility with existing learned models
without any performance degradation and minimum computation overhead while
enhancing OOD detection capabilities. We demonstrate superior results in
density estimation and 2D object detection benchmarks in comparison with
extensive baselines. Moreover, we showcase the applicability of the method with
a real-robot deployment.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06482" title="Abstract">arXiv:2311.06482</a> [<a href="/pdf/2311.06482" title="Download PDF">pdf</a>, <a href="/ps/2311.06482" title="Download PostScript">ps</a>, <a href="/format/2311.06482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous Robots for Active Removal of Orbital Debris
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aghili%2C+F">Farhad Aghili</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Trans. on IEEE Trans. on Aerospace and Electronic Systems,
  June 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper presents a vision guidance and control method for autonomous
robotic capture and stabilization of orbital objects in a time-critical manner.
The method takes into account various operational and physical constraints,
including ensuring a smooth capture, handling line-of-sight (LOS) obstructions
of the target, and staying within the acceleration, force, and torque limits of
the robot. Our approach involves the development of an optimal control
framework for an eye-to-hand visual servoing method, which integrates two
sequential sub-maneuvers: a pre-capturing maneuver and a post-capturing
maneuver, aimed at achieving the shortest possible capture time. Integrating
both control strategies enables a seamless transition between them, allowing
for real-time switching to the appropriate control system. Moreover, both
controllers are adaptively tuned through vision feedback to account for the
unknown dynamics of the target. The integrated estimation and control
architecture also facilitates fault detection and recovery of the visual
feedback in situations where the feedback is temporarily obstructed. The
experimental results demonstrate the successful execution of pre- and
post-capturing operations on a tumbling and drifting target, despite multiple
operational constraints.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06483" title="Abstract">arXiv:2311.06483</a> [<a href="/pdf/2311.06483" title="Download PDF">pdf</a>, <a href="/format/2311.06483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stacked networks improve physics-informed training: applications to  neural networks and deep operator networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Howard%2C+A+A">Amanda A Howard</a>, 
<a href="/search/cs?searchtype=author&query=Murphy%2C+S+H">Sarah H Murphy</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+S+E">Shady E Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Stinis%2C+P">Panos Stinis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Physics-informed neural networks and operator networks have shown promise for
effectively solving equations modeling physical systems. However, these
networks can be difficult or impossible to train accurately for some systems of
equations. We present a novel multifidelity framework for stacking
physics-informed neural networks and operator networks that facilitates
training. We successively build a chain of networks, where the output at one
step can act as a low-fidelity input for training the next step, gradually
increasing the expressivity of the learned model. The equations imposed at each
step of the iterative process can be the same or different (akin to simulated
annealing). The iterative (stacking) nature of the proposed method allows us to
progressively learn features of a solution that are hard to learn directly.
Through benchmark problems including a nonlinear pendulum, the wave equation,
and the viscous Burgers equation, we show how stacking can be used to improve
the accuracy and reduce the required size of physics-informed neural networks
and operator networks.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06487" title="Abstract">arXiv:2311.06487</a> [<a href="/pdf/2311.06487" title="Download PDF">pdf</a>, <a href="/format/2311.06487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Augmented Index-based Efficient Community Search for Large Directed  Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yankai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yixiang Fang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xin Cao</a>, 
<a href="/search/cs?searchtype=author&query=King%2C+I">Irwin King</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full version of our IJCAI20 paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Given a graph G and a query vertex q, the topic of community search (CS),
aiming to retrieve a dense subgraph of G containing q, has gained much
attention. Most existing works focus on undirected graphs which overlooks the
rich information carried by the edge directions. Recently, the problem of
community search over directed graphs (or CSD problem) has been studied; it
finds a connected subgraph containing q, where the in-degree and out-degree of
each vertex within the subgraph are at least k and l, respectively. However,
existing solutions are inefficient, especially on large graphs. To tackle this
issue, in this paper, we propose a novel index called D-Forest, which allows a
CSD query to be completed within the optimal time cost. We further propose
efficient index construction methods. Extensive experiments on six real large
graphs show that our index-based query algorithm is up to two orders of
magnitude faster than existing solutions.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06491" title="Abstract">arXiv:2311.06491</a> [<a href="/pdf/2311.06491" title="Download PDF">pdf</a>, <a href="/format/2311.06491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonsmooth-Optimization-Based Bandwidth Optimal Control for Precision  Motion Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wu%2C+J">Jingjie Wu</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+L">Lei Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Precision motion systems are at the core of various manufacturing equipment.
The rapidly increasing demand for higher productivity necessitates higher
control bandwidth in the motion systems to effectively reject disturbances
while maintaining excellent positioning accuracy. However, most existing
optimal control methods do not explicitly optimize for control bandwidth, and
the classic loop-shaping method suffers from conservative designs and fails to
address cross-couplings, which motivates the development of new control
solutions for bandwidth optimization. This paper proposes a novel bandwidth
optimal control formulation based on nonsmooth optimization for precision
motion systems. Our proposed method explicitly optimizes the system's MIMO
control bandwidth while constraining the H-infinity norm of the closed-loop
sensitivity function for robustness. A nonsmooth optimization solver, GRANSO,
is used to solve the proposed program, and an augmented quadratic programming
(QP)--based descent direction search is proposed to facilitate convergence.
Simulation evaluations show that the bandwidth optimal control method can
achieve a 23% higher control bandwidth than conventional loop-shaping design,
and the QP-based descent direction search can reduce iteration number by 60%,
which illustrates the effectiveness and efficiency of the proposed approach.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06493" title="Abstract">arXiv:2311.06493</a> [<a href="/pdf/2311.06493" title="Download PDF">pdf</a>, <a href="/format/2311.06493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> L3 Ensembles: Lifelong Learning Approach for Ensemble of Foundational  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shiri%2C+A">Aidin Shiri</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+K">Kaushik Roy</a>, 
<a href="/search/cs?searchtype=author&query=Sheth%2C+A">Amit Sheth</a>, 
<a href="/search/cs?searchtype=author&query=Gaur%2C+M">Manas Gaur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Fine-tuning pre-trained foundational language models (FLM) for specific tasks
is often impractical, especially for resource-constrained devices. This
necessitates the development of a Lifelong Learning (L3) framework that
continuously adapts to a stream of Natural Language Processing (NLP) tasks
efficiently. We propose an approach that focuses on extracting meaningful
representations from unseen data, constructing a structured knowledge base, and
improving task performance incrementally. We conducted experiments on various
NLP tasks to validate its effectiveness, including benchmarks like GLUE and
SuperGLUE. We measured good performance across the accuracy, training
efficiency, and knowledge transfer metrics. Initial experimental results show
that the proposed L3 ensemble method increases the model accuracy by 4% ~ 36%
compared to the fine-tuned FLM. Furthermore, L3 model outperforms naive
fine-tuning approaches while maintaining competitive or superior performance
(up to 15.4% increase in accuracy) compared to the state-of-the-art language
model (T5) for the given task, STS benchmark.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06495" title="Abstract">arXiv:2311.06495</a> [<a href="/pdf/2311.06495" title="Download PDF">pdf</a>, <a href="/format/2311.06495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LayoutPrompter: Awaken the Design Ability of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jiawei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiaqi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shizhao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z+J">Zijiang James Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+J">Jian-Guang Lou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongmei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Conditional graphic layout generation, which automatically maps user
constraints to high-quality layouts, has attracted widespread attention today.
Although recent works have achieved promising performance, the lack of
versatility and data efficiency hinders their practical applications. In this
work, we propose LayoutPrompter, which leverages large language models (LLMs)
to address the above problems through in-context learning. LayoutPrompter is
made up of three key components, namely input-output serialization, dynamic
exemplar selection and layout ranking. Specifically, the input-output
serialization component meticulously designs the input and output formats for
each layout generation task. Dynamic exemplar selection is responsible for
selecting the most helpful prompting exemplars for a given input. And a layout
ranker is used to pick the highest quality layout from multiple outputs of
LLMs. We conduct experiments on all existing layout generation tasks using four
public datasets. Despite the simplicity of our approach, experimental results
show that LayoutPrompter can compete with or even outperform state-of-the-art
approaches on these tasks without any model training or fine-tuning. This
demonstrates the effectiveness of this versatile and training-free approach. In
addition, the ablation studies show that LayoutPrompter is significantly
superior to the training-based baseline in a low-data regime, further
indicating the data efficiency of LayoutPrompter. Our project is available at
https://github.com/microsoft/LayoutGeneration/tree/main/LayoutPrompter.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06497" title="Abstract">arXiv:2311.06497</a> [<a href="/pdf/2311.06497" title="Download PDF">pdf</a>, <a href="/format/2311.06497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DRUformer: Enhancing the driving scene Important object detection with  driving relationship self-understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+Y">Yingjie Niu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Ming Ding</a>, 
<a href="/search/cs?searchtype=author&query=Fujii%2C+K">Keisuke Fujii</a>, 
<a href="/search/cs?searchtype=author&query=Ohtani%2C+K">Kento Ohtani</a>, 
<a href="/search/cs?searchtype=author&query=Carballo%2C+A">Alexander Carballo</a>, 
<a href="/search/cs?searchtype=author&query=Takeda%2C+K">Kazuya Takeda</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Traffic accidents frequently lead to fatal injuries, contributing to over 50
million deaths until 2023. To mitigate driving hazards and ensure personal
safety, it is crucial to assist vehicles in anticipating important objects
during travel. Previous research on important object detection primarily
assessed the importance of individual participants, treating them as
independent entities and frequently overlooking the connections between these
participants. Unfortunately, this approach has proven less effective in
detecting important objects in complex scenarios. In response, we introduce
Driving scene Relationship self-Understanding transformer (DRUformer), designed
to enhance the important object detection task. The DRUformer is a
transformer-based multi-modal important object detection model that takes into
account the relationships between all the participants in the driving scenario.
Recognizing that driving intention also significantly affects the detection of
important objects during driving, we have incorporated a module for embedding
driving intention. To assess the performance of our approach, we conducted a
comparative experiment on the DRAMA dataset, pitting our model against other
state-of-the-art (SOTA) models. The results demonstrated a noteworthy 16.2\%
improvement in mIoU and a substantial 12.3\% boost in ACC compared to SOTA
methods. Furthermore, we conducted a qualitative analysis of our model's
ability to detect important objects across different road scenarios and
classes, highlighting its effectiveness in diverse contexts. Finally, we
conducted various ablation studies to assess the efficiency of the proposed
modules in our DRUformer model.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06498" title="Abstract">arXiv:2311.06498</a> [<a href="/pdf/2311.06498" title="Download PDF">pdf</a>, <a href="/format/2311.06498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Communication for Cooperative Perception based on Importance  Map
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sheng%2C+Y">Yucheng Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Hao Ye</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+L">Le Liang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Shi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G+Y">Geoffrey Ye Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages,22 figures;journal;submitted for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Cooperative perception, which has a broader perception field than
single-vehicle perception, has played an increasingly important role in
autonomous driving to conduct 3D object detection. Through vehicle-to-vehicle
(V2V) communication technology, various connected automated vehicles (CAVs) can
share their sensory information (LiDAR point clouds) for cooperative
perception. We employ an importance map to extract significant semantic
information and propose a novel cooperative perception semantic communication
scheme with intermediate fusion. Meanwhile, our proposed architecture can be
extended to the challenging time-varying multipath fading channel. To alleviate
the distortion caused by the time-varying multipath fading, we adopt explicit
orthogonal frequency-division multiplexing (OFDM) blocks combined with channel
estimation and channel equalization. Simulation results demonstrate that our
proposed model outperforms the traditional separate source-channel coding over
various channel models. Moreover, a robustness study indicates that only part
of semantic information is key to cooperative perception. Although our proposed
model has only been trained over one specific channel, it has the ability to
learn robust coded representations of semantic information that remain
resilient to various channel models, demonstrating its generality and
robustness.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06500" title="Abstract">arXiv:2311.06500</a> [<a href="/pdf/2311.06500" title="Download PDF">pdf</a>, <a href="/format/2311.06500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Distillation and Training Balance for Heterogeneous  Decentralized Multi-Modal Learning over Wireless Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+B">Benshun Yin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhiyong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+M">Meixia Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to IEEE Trans. on Mobile Computing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Decentralized learning is widely employed for collaboratively training models
using distributed data over wireless networks. Existing decentralized learning
methods primarily focus on training single-modal networks. For the
decentralized multi-modal learning (DMML), the modality heterogeneity and the
non-independent and non-identically distributed (non-IID) data across devices
make it difficult for the training model to capture the correlated features
across different modalities. Moreover, modality competition can result in
training imbalance among different modalities, which can significantly impact
the performance of DMML. To improve the training performance in the presence of
non-IID data and modality heterogeneity, we propose a novel DMML with knowledge
distillation (DMML-KD) framework, which decomposes the extracted feature into
the modality-common and the modality-specific components. In the proposed
DMML-KD, a generator is applied to learn the global conditional distribution of
the modality-common features, thereby guiding the modality-common features of
different devices towards the same distribution. Meanwhile, we propose to
decrease the number of local iterations for the modalities with fast training
speed in DMML-KD to address the imbalanced training. We design a balance metric
based on the parameter variation to evaluate the training speed of different
modalities in DMML-KD. Using this metric, we optimize the number of local
iterations for different modalities on each device under the constraint of
remaining energy on devices. Experimental results demonstrate that the proposed
DMML-KD with training balance can effectively improve the training performance
of DMML.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06502" title="Abstract">arXiv:2311.06502</a> [<a href="/pdf/2311.06502" title="Download PDF">pdf</a>, <a href="/format/2311.06502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Superconvergent P1 honeycomb virtual elements and lifted P3 solutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lin%2C+Y">Yanping Lin</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+X">Xuejun Xu</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+S">Shangyou Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">When solving the Poisson equation on honeycomb hexagonal grids, we show that
the $P_1$ virtual element is three-order superconvergent in $H^1$-norm, and
two-order superconvergent in $L^2$ and $L^\infty$ norms. We define a local
post-process which lifts the superconvergent $P_1$ solution to a $P_3$ solution
of the optimal-order approximation. The theory is confirmed by a numerical
test.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06503" title="Abstract">arXiv:2311.06503</a> [<a href="/pdf/2311.06503" title="Download PDF">pdf</a>, <a href="/format/2311.06503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledgeable Preference Alignment for LLMs in Domain-specific Question  Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yichi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yin Fang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Lei Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yanxi Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fangming Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huajun Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress. Code is available at <a href="https://github.com/zjukg/KnowPAT">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently, the development of large language models (LLMs) has attracted wide
attention in academia and industry. Deploying LLMs to real scenarios is one of
the key directions in the current Internet industry. In this paper, we present
a novel pipeline to apply LLMs for domain-specific question answering (QA) that
incorporates domain knowledge graphs (KGs), addressing an important direction
of LLM application. As a real-world application, the content generated by LLMs
should be user-friendly to serve the customers. Additionally, the model needs
to utilize domain knowledge properly to generate reliable answers. These two
issues are the two major difficulties in the LLM application as vanilla
fine-tuning can not adequately address them. We think both requirements can be
unified as the model preference problem that needs to align with humans to
achieve practical application. Thus, we introduce Knowledgeable Preference
AlignmenT (KnowPAT), which constructs two kinds of preference set called style
preference set and knowledge preference set respectively to tackle the two
issues. Besides, we design a new alignment objective to align the LLM
preference with human preference, aiming to train a better LLM for
real-scenario domain-specific QA to generate reliable and user-friendly
answers. Adequate experiments and comprehensive with 15 baseline methods
demonstrate that our KnowPAT is an outperforming pipeline for real-scenario
domain-specific QA with LLMs. Our code is open-source at
https://github.com/zjukg/KnowPAT.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06504" title="Abstract">arXiv:2311.06504</a> [<a href="/pdf/2311.06504" title="Download PDF">pdf</a>, <a href="/format/2311.06504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised Context Learning for Visual Inspection of Industrial  Defects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+H">Haiming Yao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenyong Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The unsupervised visual inspection of defects in industrial products poses a
significant challenge due to substantial variations in product surfaces.
Current unsupervised models struggle to strike a balance between detecting
texture and object defects, lacking the capacity to discern latent
representations and intricate features. In this paper, we present a novel
self-supervised learning algorithm designed to derive an optimal encoder by
tackling the renowned jigsaw puzzle. Our approach involves dividing the target
image into nine patches, tasking the encoder with predicting the relative
position relationships between any two patches to extract rich semantics.
Subsequently, we introduce an affinity-augmentation method to accentuate
differences between normal and abnormal latent representations. Leveraging the
classic support vector data description algorithm yields final detection
results. Experimental outcomes demonstrate that our proposed method achieves
outstanding detection and segmentation performance on the widely used MVTec AD
dataset, with rates of 95.8% and 96.8%, respectively, establishing a
state-of-the-art benchmark for both texture and object defects. Comprehensive
experimentation underscores the effectiveness of our approach in diverse
industrial applications.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06505" title="Abstract">arXiv:2311.06505</a> [<a href="/pdf/2311.06505" title="Download PDF">pdf</a>, <a href="/format/2311.06505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CompCodeVet: A Compiler-guided Validation and Enhancement Approach for  Code Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Le Chen</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharjee%2C+A">Arijit Bhattacharjee</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+N+K">Nesreen K. Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Hasabnis%2C+N">Niranjan Hasabnis</a>, 
<a href="/search/cs?searchtype=author&query=Oren%2C+G">Gal Oren</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+B">Bin Lei</a>, 
<a href="/search/cs?searchtype=author&query=Jannesari%2C+A">Ali Jannesari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Large language models (LLMs) have become increasingly prominent in academia
and industry due to their remarkable performance in diverse applications. As
these models evolve with increasing parameters, they excel in tasks like
sentiment analysis and machine translation. However, even models with billions
of parameters face challenges in tasks demanding multi-step reasoning. Code
generation and comprehension, especially in C and C++, emerge as significant
challenges. While LLMs trained on code datasets demonstrate competence in many
tasks, they struggle with rectifying non-compilable C and C++ code. Our
investigation attributes this subpar performance to two primary factors: the
quality of the training dataset and the inherent complexity of the problem
which demands intricate reasoning. Existing "Chain of Thought" (CoT) prompting
techniques aim to enhance multi-step reasoning. This approach, however, retains
the limitations associated with the latent drawbacks of LLMs. In this work, we
propose CompCodeVet, a compiler-guided CoT approach to produce compilable code
from non-compilable ones. Diverging from the conventional approach of utilizing
larger LLMs, we employ compilers as a teacher to establish a more robust
zero-shot thought process. The evaluation of CompCodeVet on two open-source
code datasets shows that CompCodeVet has the ability to improve the training
dataset quality for LLMs.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06511" title="Abstract">arXiv:2311.06511</a> [<a href="/pdf/2311.06511" title="Download PDF">pdf</a>, <a href="/ps/2311.06511" title="Download PostScript">ps</a>, <a href="/format/2311.06511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chebyshev admissible meshes and Lebesgue constants of complex polynomial  projections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bialas-Ciez%2C+L">Leokadia Bialas-Ciez</a>, 
<a href="/search/math?searchtype=author&query=Kenne%2C+D+J">Dimitri Jordan Kenne</a>, 
<a href="/search/math?searchtype=author&query=Sommariva%2C+A">Alvise Sommariva</a>, 
<a href="/search/math?searchtype=author&query=Vianello%2C+M">Marco Vianello</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We construct admissible polynomial meshes on piecewise polynomial or
trigonometric curves of the complex plane, by mapping univariate Chebyshev
points. Such meshes can be used for polynomial least-squares, for the
extraction of Fekete-like and Leja-like interpolation sets, and also for the
evaluation of their Lebesgue constants.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06513" title="Abstract">arXiv:2311.06513</a> [<a href="/pdf/2311.06513" title="Download PDF">pdf</a>, <a href="/format/2311.06513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Step by Step to Fairness: Attributing Societal Bias in Task-oriented  Dialogue Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hsuan Su</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+R">Rebecca Qian</a>, 
<a href="/search/cs?searchtype=author&query=Sankar%2C+C">Chinnadhurai Sankar</a>, 
<a href="/search/cs?searchtype=author&query=Shayandeh%2C+S">Shahin Shayandeh</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shang-Tse Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hung-yi Lee</a>, 
<a href="/search/cs?searchtype=author&query=Bikel%2C+D+M">Daniel M. Bikel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent works have shown considerable improvements in task-oriented dialogue
(TOD) systems by utilizing pretrained large language models (LLMs) in an
end-to-end manner. However, the biased behavior of each component in a TOD
system and the error propagation issue in the end-to-end framework can lead to
seriously biased TOD responses. Existing works of fairness only focus on the
total bias of a system. In this paper, we propose a diagnosis method to
attribute bias to each component of a TOD system. With the proposed attribution
method, we can gain a deeper understanding of the sources of bias.
Additionally, researchers can mitigate biased model behavior at a more granular
level. We conduct experiments to attribute the TOD system's bias toward three
demographic axes: gender, age, and race. Experimental results show that the
bias of a TOD system usually comes from the response generation model.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06514" title="Abstract">arXiv:2311.06514</a> [<a href="/pdf/2311.06514" title="Download PDF">pdf</a>, <a href="/format/2311.06514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Set Augmented Finite Automata over Infinite Alphabets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+A">Ansuman Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+K">Kingshuk Chatterjee</a>, 
<a href="/search/cs?searchtype=author&query=Guha%2C+S">Shibashis Guha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a full version of a paper with the same name accepted in DLT 2023. Other than the full proofs, this paper contains several new results concerning more closure properties, universality problem, comparison of expressiveness with register automata and class counter automata, and more results on deterministic SAFA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
<p class="mathjax">A data language is a set of finite words defined on an infinite alphabet.
Data languages are used to express properties associated with data values
(domain defined over a countably infinite set). In this paper, we introduce set
augmented finite automata (SAFA), a new class of automata for expressing data
languages. We investigate the decision problems, closure properties, and
expressiveness of SAFA. We also study the deterministic variant of these
automata.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06517" title="Abstract">arXiv:2311.06517</a> [<a href="/pdf/2311.06517" title="Download PDF">pdf</a>, <a href="/format/2311.06517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BClean: A Bayesian Data Cleaning System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+J">Jianbin Qin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Sifan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaoshu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jing Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+Y">Yukai Miao</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+R">Rui Mao</a>, 
<a href="/search/cs?searchtype=author&query=Onizuka%2C+M">Makoto Onizuka</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chuan Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Our source code is available at <a href="https://github.com/yyssl88/BClean">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Databases (cs.DB); Machine Learning (cs.LG); Applications (stat.AP)

</div>
<p class="mathjax">There is a considerable body of work on data cleaning which employs various
principles to rectify erroneous data and transform a dirty dataset into a
cleaner one. One of prevalent approaches is probabilistic methods, including
Bayesian methods. However, existing probabilistic methods often assume a
simplistic distribution (e.g., Gaussian distribution), which is frequently
underfitted in practice, or they necessitate experts to provide a complex prior
distribution (e.g., via a programming language). This requirement is both
labor-intensive and costly, rendering these methods less suitable for
real-world applications. In this paper, we propose BClean, a Bayesian Cleaning
system that features automatic Bayesian network construction and user
interaction. We recast the data cleaning problem as a Bayesian inference that
fully exploits the relationships between attributes in the observed dataset and
any prior information provided by users. To this end, we present an automatic
Bayesian network construction method that extends a structure learning-based
functional dependency discovery method with similarity functions to capture the
relationships between attributes. Furthermore, our system allows users to
modify the generated Bayesian network in order to specify prior information or
correct inaccuracies identified by the automatic generation process. We also
design an effective scoring model (called the compensative scoring model)
necessary for the Bayesian inference. To enhance the efficiency of data
cleaning, we propose several approximation strategies for the Bayesian
inference, including graph partitioning, domain pruning, and pre-detection. By
evaluating on both real-world and synthetic datasets, we demonstrate that
BClean is capable of achieving an F-measure of up to 0.9 in data cleaning,
outperforming existing Bayesian methods by 2% and other data cleaning methods
by 15%.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06518" title="Abstract">arXiv:2311.06518</a> [<a href="/pdf/2311.06518" title="Download PDF">pdf</a>, <a href="/format/2311.06518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimum Description Length Hopfield Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abudy%2C+M">Matan Abudy</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+N">Nur Lan</a>, 
<a href="/search/cs?searchtype=author&query=Chemla%2C+E">Emmanuel Chemla</a>, 
<a href="/search/cs?searchtype=author&query=Katzir%2C+R">Roni Katzir</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, Associative Memory &amp; Hopfield Networks Workshop at NeurIPS2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Associative memory architectures are designed for memorization but also
offer, through their retrieval method, a form of generalization to unseen
inputs: stored memories can be seen as prototypes from this point of view.
Focusing on Modern Hopfield Networks (MHN), we show that a large memorization
capacity undermines the generalization opportunity. We offer a solution to
better optimize this tradeoff. It relies on Minimum Description Length (MDL) to
determine during training which memories to store, as well as how many of them.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06520" title="Abstract">arXiv:2311.06520</a> [<a href="/pdf/2311.06520" title="Download PDF">pdf</a>, <a href="/format/2311.06520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamics of toxic behavior in the Covid-19 vaccination debate
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bouleimen%2C+A">Azza Bouleimen</a>, 
<a href="/search/cs?searchtype=author&query=Pagan%2C+N">Nicol&#xf2; Pagan</a>, 
<a href="/search/cs?searchtype=author&query=Cresci%2C+S">Stefano Cresci</a>, 
<a href="/search/cs?searchtype=author&query=Urman%2C+A">Aleksandra Urman</a>, 
<a href="/search/cs?searchtype=author&query=Giordano%2C+S">Silvia Giordano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">In this paper, we study the behavior of users on Online Social Networks in
the context of Covid-19 vaccines in Italy. We identify two main polarized
communities: Provax and Novax. We find that Novax users are more active, more
clustered in the network, and share less reliable information compared to the
Provax users. On average, Novax are more toxic than Provax. However, starting
from June 2021, the Provax became more toxic than the Novax. We show that the
change in trend is explained by the aggregation of some contagion effects and
the change in the activity level within communities. In fact, we establish that
Provax users who increase their intensity of activity after May 2021 are
significantly more toxic than the other users, shifting the toxicity up within
the Provax community. Our study suggests that users presenting a spiky activity
pattern tend to be more toxic.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06523" title="Abstract">arXiv:2311.06523</a> [<a href="/pdf/2311.06523" title="Download PDF">pdf</a>, <a href="/format/2311.06523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative AI for Space-Air-Ground Integrated Networks (SAGIN)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruichen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Hongyang Du</a>, 
<a href="/search/cs?searchtype=author&query=Niyato%2C+D">Dusit Niyato</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jiawen Kang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zehui Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Jamalipour%2C+A">Abbas Jamalipour</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Ping Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D+I">Dong In Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9page, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Recently, generative AI technologies have emerged as a significant
advancement in artificial intelligence field, renowned for their language and
image generation capabilities. Meantime, space-air-ground integrated network
(SAGIN) is an integral part of future B5G/6G for achieving ubiquitous
connectivity. Inspired by this, this article explores an integration of
generative AI in SAGIN, focusing on potential applications and case study. We
first provide a comprehensive review of SAGIN and generative AI models,
highlighting their capabilities and opportunities of their integration.
Benefiting from generative AI's ability to generate useful data and facilitate
advanced decision-making processes, it can be applied to various scenarios of
SAGIN. Accordingly, we present a concise survey on their integration, including
channel modeling and channel state information (CSI) estimation, joint
air-space-ground resource allocation, intelligent network deployment, semantic
communications, image extraction and processing, security and privacy
enhancement. Next, we propose a framework that utilizes a Generative Diffusion
Model (GDM) to construct channel information map to enhance quality of service
for SAGIN. Simulation results demonstrate the effectiveness of the proposed
framework. Finally, we discuss potential research directions for generative
AI-enabled SAGIN.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06524" title="Abstract">arXiv:2311.06524</a> [<a href="/pdf/2311.06524" title="Download PDF">pdf</a>, <a href="/format/2311.06524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Personal Health Knowledge Graph Framework for Patient  Monitoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bloor%2C+D">Daniel Bloor</a>, 
<a href="/search/cs?searchtype=author&query=Ugwuoke%2C+N">Nnamdi Ugwuoke</a>, 
<a href="/search/cs?searchtype=author&query=Taylor%2C+D">David Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Lewis%2C+K">Keir Lewis</a>, 
<a href="/search/cs?searchtype=author&query=Mur%2C+L">Luis Mur</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Chuan Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures, conference proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Healthcare providers face significant challenges with monitoring and managing
patient data outside of clinics, particularly with insufficient resources and
limited feedback on their patients' conditions. Effective management of these
symptoms and exploration of larger bodies of data are vital for maintaining
long-term quality of life and preventing late interventions. In this paper, we
propose a framework for constructing personal health knowledge graphs from
heterogeneous data sources. Our approach integrates clinical databases,
relevant ontologies and standard healthcare guidelines to support alert
generation, clinician interpretation and querying of patient data. Through a
use case of monitoring Chronic Obstructive Pulmonary Disease (COPD) patients,
we demonstrate that inference and reasoning on personal health knowledge graphs
built with our framework can aid in patient monitoring and enhance the efficacy
and accuracy of patient data queries.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06527" title="Abstract">arXiv:2311.06527</a> [<a href="/pdf/2311.06527" title="Download PDF">pdf</a>, <a href="/format/2311.06527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TURBO: The Swiss Knife of Auto-Encoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%C3%A9tant%2C+G">Guillaume Qu&#xe9;tant</a>, 
<a href="/search/cs?searchtype=author&query=Belousov%2C+Y">Yury Belousov</a>, 
<a href="/search/cs?searchtype=author&query=Kinakh%2C+V">Vitaliy Kinakh</a>, 
<a href="/search/cs?searchtype=author&query=Voloshynovskiy%2C+S">Slava Voloshynovskiy</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Qu\'etant, G.; Belousov, Y.; Kinakh, V.; Voloshynovskiy, S. TURBO:
  The Swiss Knife of Auto-Encoders. Entropy 2023, 25, 1471
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Information Theory (cs.IT); High Energy Physics - Phenomenology (hep-ph)

</div>
<p class="mathjax">We present a novel information-theoretic framework, termed as TURBO, designed
to systematically analyse and generalise auto-encoding methods. We start by
examining the principles of information bottleneck and bottleneck-based
networks in the auto-encoding setting and identifying their inherent
limitations, which become more prominent for data with multiple relevant,
physics-related representations. The TURBO framework is then introduced,
providing a comprehensive derivation of its core concept consisting of the
maximisation of mutual information between various data representations
expressed in two directions reflecting the information flows. We illustrate
that numerous prevalent neural network models are encompassed within this
framework. The paper underscores the insufficiency of the information
bottleneck concept in elucidating all such models, thereby establishing TURBO
as a preferable theoretical reference. The introduction of TURBO contributes to
a richer understanding of data representation and the structure of neural
network models, enabling more efficient and versatile applications.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06530" title="Abstract">arXiv:2311.06530</a> [<a href="/pdf/2311.06530" title="Download PDF">pdf</a>, <a href="/format/2311.06530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How ChatGPT is Solving Vulnerability Management Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Peiyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+L">Lirong Fu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+K">Kangjie Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yifan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenzhi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+H">Haiqin Weng</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shouling Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenhai Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Recently, ChatGPT has attracted great attention from the code analysis
domain. Prior works show that ChatGPT has the capabilities of processing
foundational code analysis tasks, such as abstract syntax tree generation,
which indicates the potential of using ChatGPT to comprehend code syntax and
static behaviors. However, it is unclear whether ChatGPT can complete more
complicated real-world vulnerability management tasks, such as the prediction
of security relevance and patch correctness, which require an all-encompassing
understanding of various aspects, including code syntax, program semantics, and
related manual comments.
<br />In this paper, we explore ChatGPT's capabilities on 6 tasks involving the
complete vulnerability management process with a large-scale dataset containing
78,445 samples. For each task, we compare ChatGPT against SOTA approaches,
investigate the impact of different prompts, and explore the difficulties. The
results suggest promising potential in leveraging ChatGPT to assist
vulnerability management. One notable example is ChatGPT's proficiency in tasks
like generating titles for software bug reports. Furthermore, our findings
reveal the difficulties encountered by ChatGPT and shed light on promising
future directions. For instance, directly providing random demonstration
examples in the prompt cannot consistently guarantee good performance in
vulnerability management. By contrast, leveraging ChatGPT in a self-heuristic
way -- extracting expertise from demonstration examples itself and integrating
the extracted expertise in the prompt is a promising research direction.
Besides, ChatGPT may misunderstand and misuse the information in the prompt.
Consequently, effectively guiding ChatGPT to focus on helpful information
rather than the irrelevant content is still an open problem.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06532" title="Abstract">arXiv:2311.06532</a> [<a href="/pdf/2311.06532" title="Download PDF">pdf</a>, <a href="/format/2311.06532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Added Toxicity Mitigation at Inference Time for Multimodal and Massively  Multilingual Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Costa-juss%C3%A0%2C+M+R">Marta R. Costa-juss&#xe0;</a>, 
<a href="/search/cs?searchtype=author&query=Dale%2C+D">David Dale</a>, 
<a href="/search/cs?searchtype=author&query=Elbayad%2C+M">Maha Elbayad</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bokai Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Added toxicity in the context of translation refers to the fact of producing
a translation output with more toxicity than there exists in the input. In this
paper, we present MinTox which is a novel pipeline to identify added toxicity
and mitigate this issue which works at inference time. MinTox uses a toxicity
detection classifier which is multimodal (speech and text) and works in
languages at scale. The mitigation method is applied to languages at scale and
directly in text outputs. MinTox is applied to SEAMLESSM4T, which is the latest
multimodal and massively multilingual machine translation system. For this
system, MinTox achieves significant added toxicity mitigation across domains,
modalities and language directions. MinTox manages to approximately filter out
from 25% to 95% of added toxicity (depending on the modality and domain) while
keeping translation quality.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06534" title="Abstract">arXiv:2311.06534</a> [<a href="/pdf/2311.06534" title="Download PDF">pdf</a>, <a href="/format/2311.06534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Public Understanding of Court Opinions with Automated  Summarizers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ash%2C+E">Elliott Ash</a>, 
<a href="/search/cs?searchtype=author&query=Kesari%2C+A">Aniket Kesari</a>, 
<a href="/search/cs?searchtype=author&query=Naidu%2C+S">Suresh Naidu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Lena Song</a>, 
<a href="/search/cs?searchtype=author&query=Stammbach%2C+D">Dominik Stammbach</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Written judicial opinions are an important tool for building public trust in
court decisions, yet they can be difficult for non-experts to understand. We
present a pipeline for using an AI assistant to generate simplified summaries
of judicial opinions. These are more accessible to the public and more easily
understood by non-experts, We show in a survey experiment that the simplified
summaries help respondents understand the key features of a ruling. We discuss
how to integrate legal domain knowledge into studies using large language
models. Our results suggest a role both for AI assistants to inform the public,
and for lawyers to guide the process of generating accessible summaries.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06536" title="Abstract">arXiv:2311.06536</a> [<a href="/pdf/2311.06536" title="Download PDF">pdf</a>, <a href="/format/2311.06536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CrashCar101: Procedural Generation for Damage Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parslov%2C+J">Jens Parslov</a>, 
<a href="/search/cs?searchtype=author&query=Riise%2C+E">Erik Riise</a>, 
<a href="/search/cs?searchtype=author&query=Papadopoulos%2C+D+P">Dim P. Papadopoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we are interested in addressing the problem of damage
assessment for vehicles, such as cars. This task requires not only detecting
the location and the extent of the damage but also identifying the damaged
part. To train a computer vision system for the semantic part and damage
segmentation in images, we need to manually annotate images with costly pixel
annotations for both part categories and damage types. To overcome this need,
we propose to use synthetic data to train these models. Synthetic data can
provide samples with high variability, pixel-accurate annotations, and
arbitrarily large training sets without any human intervention. We propose a
procedural generation pipeline that damages 3D car models and we obtain
synthetic 2D images of damaged cars paired with pixel-accurate annotations for
part and damage categories. To validate our idea, we execute our pipeline and
render our CrashCar101 dataset. We run experiments on three real datasets for
the tasks of part and damage segmentation. For part segmentation, we show that
the segmentation models trained on a combination of real data and our synthetic
data outperform all models trained only on real data. For damage segmentation,
we show the sim2real transfer ability of CrashCar101.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06537" title="Abstract">arXiv:2311.06537</a> [<a href="/pdf/2311.06537" title="Download PDF">pdf</a>, <a href="/ps/2311.06537" title="Download PostScript">ps</a>, <a href="/format/2311.06537" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is Machine Learning Unsafe and Irresponsible in Social Sciences?  Paradoxes and Reconsidering from Recidivism Prediction Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianhong Liu</a> (1), 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dianshi Li</a> (1) ((1) Faculty of Law, University of Macau, Macau, China)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Applications (stat.AP); Methodology (stat.ME)

</div>
<p class="mathjax">The paper addresses some fundamental and hotly debated issues for high-stakes
event predictions underpinning the computational approach to social sciences.
We question several prevalent views against machine learning and outline a new
paradigm that highlights the promises and promotes the infusion of
computational methods and conventional social science approaches.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06542" title="Abstract">arXiv:2311.06542</a> [<a href="/pdf/2311.06542" title="Download PDF">pdf</a>, <a href="/ps/2311.06542" title="Download PostScript">ps</a>, <a href="/format/2311.06542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generation Of Colors using Bidirectional Long Short Term Memory Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sinha%2C+A">A. Sinha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 17 figures, submitted to Pattern Recognition Letters, <a href="/abs/1508.01991">arXiv:1508.01991</a>, <a href="/abs/1409.0473">arXiv:1409.0473</a>, Author Roles: Sole Author
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Human vision can distinguish between a vast spectrum of colours, estimated to
be between 2 to 7 million discernible shades. However, this impressive range
does not inherently imply that all these colours have been precisely named and
described within our lexicon. We often associate colours with familiar objects
and concepts in our daily lives. This research endeavors to bridge the gap
between our visual perception of countless shades and our ability to articulate
and name them accurately. A novel model has been developed to achieve this
goal, leveraging Bidirectional Long Short-Term Memory (BiLSTM) networks with
Active learning. This model operates on a proprietary dataset meticulously
curated for this study. The primary objective of this research is to create a
versatile tool for categorizing and naming previously unnamed colours or
identifying intermediate shades that elude traditional colour terminology. The
findings underscore the potential of this innovative approach in
revolutionizing our understanding of colour perception and language. Through
rigorous experimentation and analysis, this study illuminates a promising
avenue for Natural Language Processing (NLP) applications in diverse
industries. By facilitating the exploration of the vast colour spectrum the
potential applications of NLP are extended beyond conventional boundaries.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06543" title="Abstract">arXiv:2311.06543</a> [<a href="/pdf/2311.06543" title="Download PDF">pdf</a>, <a href="/format/2311.06543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bootstrapping Robotic Skill Learning With Intuitive Teleoperation:  Initial Feasibility Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu%2C+X">Xiangyu Chu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yunxi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Kwok%2C+L+H">Lam Him Kwok</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yuanpei Cai</a>, 
<a href="/search/cs?searchtype=author&query=Au%2C+K+W+S">Kwok Wai Samuel Au</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures, accepted by ISER2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Robotic skill learning has been increasingly studied but the demonstration
collections are more challenging compared to collecting images/videos in
computer vision and texts in natural language processing. This paper presents a
skill learning paradigm by using intuitive teleoperation devices to generate
high-quality human demonstrations efficiently for robotic skill learning in a
data-driven manner. By using a reliable teleoperation interface, the da Vinci
Research Kit (dVRK) master, a system called dVRK-Simulator-for-Demonstration
(dS4D) is proposed in this paper. Various manipulation tasks show the system's
effectiveness and advantages in efficiency compared to other interfaces. Using
the collected data for policy learning has been investigated, which verifies
the initial feasibility. We believe the proposed paradigm can facilitate robot
learning driven by high-quality demonstrations and efficiency while generating
them.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06545" title="Abstract">arXiv:2311.06545</a> [<a href="/pdf/2311.06545" title="Download PDF">pdf</a>, <a href="/format/2311.06545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Generalization via Set Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shiqi Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Generalization is at the core of machine learning models. However, the
definition of generalization is not entirely clear. We employ set theory to
introduce the concepts of algorithms, hypotheses, and dataset generalization.
We analyze the properties of dataset generalization and prove a theorem on
surrogate generalization procedures. This theorem leads to our generalization
method. Through a generalization experiment on the MNIST dataset, we obtain
13,541 sample bases. When we use the entire training set to evaluate the
model's performance, the models achieve an accuracy of 99.945%. However, if we
shift the sample bases or modify the neural network structure, the performance
experiences a significant decline. We also identify consistently mispredicted
samples and find that they are all challenging examples. The experiments
substantiated the accuracy of the generalization definition and the
effectiveness of the proposed methods. Both the set-theoretic deduction and the
experiments help us better understand generalization.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06547" title="Abstract">arXiv:2311.06547</a> [<a href="/pdf/2311.06547" title="Download PDF">pdf</a>, <a href="/format/2311.06547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Charts to Atlas: Merging Latent Spaces into One
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Crisostomi%2C+D">Donato Crisostomi</a>, 
<a href="/search/cs?searchtype=author&query=Cannistraci%2C+I">Irene Cannistraci</a>, 
<a href="/search/cs?searchtype=author&query=Moschella%2C+L">Luca Moschella</a>, 
<a href="/search/cs?searchtype=author&query=Barbiero%2C+P">Pietro Barbiero</a>, 
<a href="/search/cs?searchtype=author&query=Ciccone%2C+M">Marco Ciccone</a>, 
<a href="/search/cs?searchtype=author&query=Li%C3%B2%2C+P">Pietro Li&#xf2;</a>, 
<a href="/search/cs?searchtype=author&query=Rodol%C3%A0%2C+E">Emanuele Rodol&#xe0;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the NeurReps workshop @ NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Models trained on semantically related datasets and tasks exhibit comparable
inter-sample relations within their latent spaces. We investigate in this study
the aggregation of such latent spaces to create a unified space encompassing
the combined information. To this end, we introduce Relative Latent Space
Aggregation, a two-step approach that first renders the spaces comparable using
relative representations, and then aggregates them via a simple mean. We
carefully divide a classification problem into a series of learning tasks under
three different settings: sharing samples, classes, or neither. We then train a
model on each task and aggregate the resulting latent spaces. We compare the
aggregated space with that derived from an end-to-end model trained over all
tasks and show that the two spaces are similar. We then observe that the
aggregated space is better suited for classification, and empirically
demonstrate that it is due to the unique imprints left by task-specific
embedders within the representations. We finally test our framework in
scenarios where no shared region exists and show that it can still be used to
merge the spaces, albeit with diminished benefits over naive merging.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06549" title="Abstract">arXiv:2311.06549</a> [<a href="/pdf/2311.06549" title="Download PDF">pdf</a>, <a href="/format/2311.06549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot Cross-Lingual Sentiment Classification under Distribution  Shift: an Exploratory Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Raedt%2C+M">Maarten De Raedt</a>, 
<a href="/search/cs?searchtype=author&query=Bitew%2C+S+K">Semere Kiros Bitew</a>, 
<a href="/search/cs?searchtype=author&query=Godin%2C+F">Fr&#xe9;deric Godin</a>, 
<a href="/search/cs?searchtype=author&query=Demeester%2C+T">Thomas Demeester</a>, 
<a href="/search/cs?searchtype=author&query=Develder%2C+C">Chris Develder</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 3rd Workshop on Multilingual Representation Learning (MRL@EMNLP2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The brittleness of finetuned language model performance on
out-of-distribution (OOD) test samples in unseen domains has been well-studied
for English, yet is unexplored for multi-lingual models. Therefore, we study
generalization to OOD test data specifically in zero-shot cross-lingual
transfer settings, analyzing performance impacts of both language and domain
shifts between train and test data. We further assess the effectiveness of
counterfactually augmented data (CAD) in improving OOD generalization for the
cross-lingual setting, since CAD has been shown to benefit in a monolingual
English setting. Finally, we propose two new approaches for OOD generalization
that avoid the costly annotation process associated with CAD, by exploiting the
power of recent large language models (LLMs). We experiment with 3 multilingual
models, LaBSE, mBERT, and XLM-R trained on English IMDb movie reviews, and
evaluate on OOD test sets in 13 languages: Amazon product reviews, Tweets, and
Restaurant reviews. Results echo the OOD performance decline observed in the
monolingual English setting. Further, (i) counterfactuals from the original
high-resource language do improve OOD generalization in the low-resource
language, and (ii) our newly proposed cost-effective approaches reach similar
or up to +3.1% better accuracy than CAD for Amazon and Restaurant reviews.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06551" title="Abstract">arXiv:2311.06551</a> [<a href="/pdf/2311.06551" title="Download PDF">pdf</a>, <a href="/format/2311.06551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FDNet: Feature Decoupled Segmentation Network for Tooth CBCT Image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xiang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengkai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chengyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunxiang Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yongbo He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaiqi Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE ISBI 2024 for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Precise Tooth Cone Beam Computed Tomography (CBCT) image segmentation is
crucial for orthodontic treatment planning. In this paper, we propose FDNet, a
Feature Decoupled Segmentation Network, to excel in the face of the variable
dental conditions encountered in CBCT scans, such as complex artifacts and
indistinct tooth boundaries. The Low-Frequency Wavelet Transform (LF-Wavelet)
is employed to enrich the semantic content by emphasizing the global structural
integrity of the teeth, while the SAM encoder is leveraged to refine the
boundary delineation, thus improving the contrast between adjacent dental
structures. By integrating these dual aspects, FDNet adeptly addresses the
semantic gap, providing a detailed and accurate segmentation. The framework's
effectiveness is validated through rigorous benchmarks, achieving the top Dice
and IoU scores of 85.28% and 75.23%, respectively. This innovative decoupling
of semantic and boundary features capitalizes on the unique strengths of each
element to significantly elevate the quality of segmentation performance.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06553" title="Abstract">arXiv:2311.06553</a> [<a href="/pdf/2311.06553" title="Download PDF">pdf</a>, <a href="/format/2311.06553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Commonsense based Heterogeneous Graph Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zongzhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiangyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoxiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Z">Zhen Lei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">How to select relevant key objects and reason about the complex relationships
cross vision and linguistic domain are two key issues in many multi-modality
applications such as visual question answering (VQA). In this work, we
incorporate the visual commonsense information and propose a heterogeneous
graph contrastive learning method to better finish the visual reasoning task.
Our method is designed as a plug-and-play way, so that it can be quickly and
easily combined with a wide range of representative methods. Specifically, our
model contains two key components: the Commonsense-based Contrastive Learning
and the Graph Relation Network. Using contrastive learning, we guide the model
concentrate more on discriminative objects and relevant visual commonsense
attributes. Besides, thanks to the introduction of the Graph Relation Network,
the model reasons about the correlations between homogeneous edges and the
similarities between heterogeneous edges, which makes information transmission
more effective. Extensive experiments on four benchmarks show that our method
greatly improves seven representative VQA models, demonstrating its
effectiveness and generalizability.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06554" title="Abstract">arXiv:2311.06554</a> [<a href="/pdf/2311.06554" title="Download PDF">pdf</a>, <a href="/format/2311.06554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph ODE with Factorized Prototypes for Modeling Complicated  Interacting Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yiyang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Huiyu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jinsheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ju%2C+W">Wei Ju</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Ming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yizhou Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper studies the problem of modeling interacting dynamical systems,
which is critical for understanding physical dynamics and biological processes.
Recent research predominantly uses geometric graphs to represent these
interactions, which are then captured by powerful graph neural networks (GNNs).
However, predicting interacting dynamics in challenging scenarios such as
out-of-distribution shift and complicated underlying rules remains unsolved. In
this paper, we propose a new approach named Graph ODE with factorized
prototypes (GOAT) to address the problem. The core of GOAT is to incorporate
factorized prototypes from contextual knowledge into a continuous graph ODE
framework. Specifically, GOAT employs representation disentanglement and system
parameters to extract both object-level and system-level contexts from
historical trajectories, which allows us to explicitly model their independent
influence and thus enhances the generalization capability under system changes.
Then, we integrate these disentangled latent representations into a graph ODE
model, which determines a combination of various interacting prototypes for
enhanced model expressivity. The entire model is optimized using an end-to-end
variational inference framework to maximize the likelihood. Extensive
experiments in both in-distribution and out-of-distribution settings validate
the superiority of GOAT.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06555" title="Abstract">arXiv:2311.06555</a> [<a href="/pdf/2311.06555" title="Download PDF">pdf</a>, <a href="/format/2311.06555" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heuristics-Driven Link-of-Analogy Prompting: Enhancing Large Language  Models for Document-Level Event Argument Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hanzhang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+J">Junlang Qian</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zijian Feng</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hui Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zixiao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+K">Kezhi Mao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this study, we investigate in-context learning (ICL) in document-level
event argument extraction (EAE). The paper identifies key challenges in this
problem, including example selection, context length limitation, abundance of
event types, and the limitation of Chain-of-Thought (CoT) prompting in
non-reasoning tasks. To address these challenges, we introduce the
Heuristic-Driven Link-of-Analogy (HD-LoA) prompting method. Specifically, we
hypothesize and validate that LLMs learn task-specific heuristics from
demonstrations via ICL. Building upon this hypothesis, we introduce an explicit
heuristic-driven demonstration construction approach, which transforms the
haphazard example selection process into a methodical method that emphasizes
task heuristics. Additionally, inspired by the analogical reasoning of human,
we propose the link-of-analogy prompting, which enables LLMs to process new
situations by drawing analogies to known situations, enhancing their
adaptability. Extensive experiments show that our method outperforms the
existing prompting methods and few-shot supervised learning methods, exhibiting
F1 score improvements of 4.53% and 9.38% on the document-level EAE dataset.
Furthermore, when applied to sentiment analysis and natural language inference
tasks, the HD-LoA prompting achieves accuracy gains of 2.87% and 2.63%,
indicating its effectiveness across different tasks.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06558" title="Abstract">arXiv:2311.06558</a> [<a href="/pdf/2311.06558" title="Download PDF">pdf</a>, <a href="/format/2311.06558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convolve and Conquer: Data Comparison with Wiener Filters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cruz%2C+D+P">Deborah Pelacani Cruz</a>, 
<a href="/search/cs?searchtype=author&query=Strong%2C+G">George Strong</a>, 
<a href="/search/cs?searchtype=author&query=Bates%2C+O">Oscar Bates</a>, 
<a href="/search/cs?searchtype=author&query=Cueto%2C+C">Carlos Cueto</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jiashun Yao</a>, 
<a href="/search/cs?searchtype=author&query=Guasch%2C+L">Lluis Guasch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures, Medical Imaging Meets Neurips Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Quantitative evaluations of differences and/or similarities between data
samples define and shape optimisation problems associated with learning data
distributions. Current methods to compare data often suffer from limitations in
capturing such distributions or lack desirable mathematical properties for
optimisation (e.g. smoothness, differentiability, or convexity). In this paper,
we introduce a new method to measure (dis)similarities between paired samples
inspired by Wiener-filter theory. The convolutional nature of Wiener filters
allows us to comprehensively compare data samples in a globally correlated way.
We validate our approach in four machine learning applications: data
compression, medical imaging imputation, translated classification, and
non-parametric generative modelling. Our results demonstrate increased
resolution in reconstructed images with better perceptual quality and higher
data fidelity, as well as robustness against translations, compared to
conventional mean-squared-error analogue implementations.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06563" title="Abstract">arXiv:2311.06563</a> [<a href="/pdf/2311.06563" title="Download PDF">pdf</a>, <a href="/ps/2311.06563" title="Download PostScript">ps</a>, <a href="/format/2311.06563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> All instances of MONOTONE 3-SAT-(3,1) are satisfiable
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Van+Santvliet%2C+H">Hannah Van Santvliet</a>, 
<a href="/search/cs?searchtype=author&query=de+Haan%2C+R">Ronald de Haan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">The satisfiability problem is NP-complete but there are subclasses where all
the instances are satisfiable. For this, restrictions on the shape of the
formula are made. Darman and D\"ocker show that the subclass MONOTONE
$3$-SAT-($k$,1) with $k \geq 5$ proves to be NP-complete and pose the open
question whether instances of MONOTONE $3$-SAT-(3,1) are satisfiable. This
paper shows that all instances of MONOTONE $3$-SAT-(3,1) are satisfiable using
the new concept of a color-structures.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06564" title="Abstract">arXiv:2311.06564</a> [<a href="/pdf/2311.06564" title="Download PDF">pdf</a>, <a href="/format/2311.06564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seeing is Believing: A Federated Learning Based Prototype to Detect  Wireless Injection Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hussain%2C+A">Aadil Hussain</a>, 
<a href="/search/cs?searchtype=author&query=Gundapu%2C+N">Nitheesh Gundapu</a>, 
<a href="/search/cs?searchtype=author&query=Drugkar%2C+S">Sarang Drugkar</a>, 
<a href="/search/cs?searchtype=author&query=Kiran%2C+S">Suraj Kiran</a>, 
<a href="/search/cs?searchtype=author&query=Harshan%2C+J">J. Harshan</a>, 
<a href="/search/cs?searchtype=author&query=Prasad%2C+R">Ranjitha Prasad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages with 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Reactive injection attacks are a class of security threats in wireless
networks wherein adversaries opportunistically inject spoofing packets in the
frequency band of a client thereby forcing the base-station to deploy
impersonation-detection methods. Towards circumventing such threats, we
implement secret-key based physical-layer signalling methods at the clients
which allow the base-stations to deploy machine learning (ML) models on their
in-phase and quadrature samples at the baseband for attack detection. Using
Adalm Pluto based software defined radios to implement the secret-key based
signalling methods, we show that robust ML models can be designed at the
base-stations. However, we also point out that, in practice, insufficient
availability of training datasets at the base-stations can make these methods
ineffective. Thus, we use a federated learning framework in the backhaul
network, wherein a group of base-stations that need to protect their clients
against reactive injection threats collaborate to refine their ML models by
ensuring privacy on their datasets. Using a network of XBee devices to
implement the backhaul network, experimental results on our federated learning
setup shows significant enhancements in the detection accuracy, thus presenting
wireless security as an excellent use-case for federated learning in 6G
networks and beyond.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06567" title="Abstract">arXiv:2311.06567</a> [<a href="/pdf/2311.06567" title="Download PDF">pdf</a>, <a href="/format/2311.06567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCADI: Self-supervised Causal Disentanglement in Latent Variable Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nam%2C+H">Heejeong Nam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Causal disentanglement has great potential for capturing complex situations.
However, there is a lack of practical and efficient approaches. It is already
known that most unsupervised disentangling methods are unable to produce
identifiable results without additional information, often leading to randomly
disentangled output. Therefore, most existing models for disentangling are
weakly supervised, providing information about intrinsic factors, which incurs
excessive costs. Therefore, we propose a novel model, SCADI(SElf-supervised
CAusal DIsentanglement), that enables the model to discover semantic factors
and learn their causal relationships without any supervision. This model
combines a masked structural causal model (SCM) with a pseudo-label generator
for causal disentanglement, aiming to provide a new direction for
self-supervised causal disentanglement models.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06570" title="Abstract">arXiv:2311.06570</a> [<a href="/pdf/2311.06570" title="Download PDF">pdf</a>, <a href="/format/2311.06570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OR Residual Connection Achieving Comparable Accuracy to ADD Residual  Connection in Deep Residual Spiking Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Yimeng Shan</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xuerui Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+R">Rui-jie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruike Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Meng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+H">Haicheng Qu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 8 figures and 11tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Spiking Neural Networks (SNNs) have garnered substantial attention in
brain-like computing for their biological fidelity and the capacity to execute
energy-efficient spike-driven operations. As the demand for heightened
performance in SNNs surges, the trend towards training deeper networks becomes
imperative, while residual learning stands as a pivotal method for training
deep neural networks. In our investigation, we identified that the SEW-ResNet,
a prominent representative of deep residual spiking neural networks,
incorporates non-event-driven operations. To rectify this, we introduce the OR
Residual connection (ORRC) to the architecture. Additionally, we propose the
Synergistic Attention (SynA) module, an amalgamation of the Inhibitory
Attention (IA) module and the Multi-dimensional Attention (MA) module, to
offset energy loss stemming from high quantization. When integrating SynA into
the network, we observed the phenomenon of "natural pruning", where after
training, some or all of the shortcuts in the network naturally drop out
without affecting the model's classification accuracy. This significantly
reduces computational overhead and makes it more suitable for deployment on
edge devices. Experimental results on various public datasets confirmed that
the SynA enhanced OR-Spiking ResNet achieved single-sample classification with
as little as 0.8 spikes per neuron. Moreover, when compared to other spike
residual models, it exhibited higher accuracy and lower power consumption.
Codes are available at https://github.com/Ym-Shan/ORRC-SynA-natural-pruning.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06574" title="Abstract">arXiv:2311.06574</a> [<a href="/pdf/2311.06574" title="Download PDF">pdf</a>, <a href="/format/2311.06574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Word Linear Complexity of sequences and Local Inversion of maps over  finite fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sule%2C+V">Virendra Sule</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computational Complexity (cs.CC); Rings and Algebras (math.RA)

</div>
<p class="mathjax">This paper develops the notion of \emph{Word Linear Complexity} ($WLC$) of
vector valued sequences over finite fields $\ff$ as an extension of Linear
Complexity ($LC$) of sequences and their ensembles. This notion of complexity
extends the concept of the minimal polynomial of an ensemble (vector valued)
sequence to that of a matrix minimal polynomial and shows that the matrix
minimal polynomial can be used with iteratively generated vector valued
sequences by maps $F:\ff^n\rightarrow\ff^n$ at a given $y$ in $\ff^n$ for
solving the unique local inverse $x$ of the equation $y=F(x)$ when the sequence
is periodic. The idea of solving a local inverse of a map in finite fields when
the iterative sequence is periodic and its application to various problems of
Cryptanalysis is developed in previous papers \cite{sule322, sule521,
sule722,suleCAM22} using the well known notion of $LC$ of sequences. $LC$ is
the degree of the associated minimal polynomial of the sequence. The
generalization of $LC$ to $WLC$ considers vector valued (or word oriented)
sequences such that the word oriented recurrence relation is obtained by matrix
vector multiplication instead of scalar multiplication as considered in the
definition of $LC$. Hence the associated minimal polynomial is matrix valued
whose degree is called $WLC$. A condition is derived when a nontrivial matrix
polynomial associated with the word oriented recurrence relation exists when
the sequence is periodic. It is shown that when the matrix minimal polynomial
exists $n(WLC)=LC$. Finally it is shown that the local inversion problem is
solved using the matrix minimal polynomial when such a polynomail exists hence
leads to a word oriented approach to local inversion.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06575" title="Abstract">arXiv:2311.06575</a> [<a href="/pdf/2311.06575" title="Download PDF">pdf</a>, <a href="/ps/2311.06575" title="Download PostScript">ps</a>, <a href="/format/2311.06575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Attention-Based Neural Networks for Code Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiang%2C+Z">Ziyang Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zaixi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 3rd International Conference on Digital Society and Intelligent Systems (DSInS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Categorizing source codes accurately and efficiently is a challenging problem
in real-world programming education platform management. In recent years,
model-based approaches utilizing abstract syntax trees (ASTs) have been widely
applied to code classification tasks. We introduce an approach named the Sparse
Attention-based neural network for Code Classification (SACC) in this paper.
The approach involves two main steps: In the first step, source code undergoes
syntax parsing and preprocessing. The generated abstract syntax tree is split
into sequences of subtrees and then encoded using a recursive neural network to
obtain a high-dimensional representation. This step simultaneously considers
both the logical structure and lexical level information contained within the
code. In the second step, the encoded sequences of subtrees are fed into a
Transformer model that incorporates sparse attention mechanisms for the purpose
of classification. This method efficiently reduces the computational cost of
the self-attention mechanisms, thus improving the training speed while
preserving effectiveness. Our work introduces a carefully designed sparse
attention pattern that is specifically designed to meet the unique needs of
code classification tasks. This design helps reduce the influence of redundant
information and enhances the overall performance of the model. Finally, we also
deal with problems in previous related research, which include issues like
incomplete classification labels and a small dataset size. We annotated the
CodeNet dataset with algorithm-related labeling categories, which contains a
significantly large amount of data. Extensive comparative experimental results
demonstrate the effectiveness and efficiency of SACC for the code
classification tasks.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06576" title="Abstract">arXiv:2311.06576</a> [<a href="/pdf/2311.06576" title="Download PDF">pdf</a>, <a href="/format/2311.06576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Intelligent Social Learning-based Optimization Strategy for Black-box  Robotic Control with Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xubo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jian Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Ting Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yaozhen He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Neural and Evolutionary Computing (cs.NE); Robotics (cs.RO)

</div>
<p class="mathjax">Implementing intelligent control of robots is a difficult task, especially
when dealing with complex black-box systems, because of the lack of visibility
and understanding of how these robots work internally. This paper proposes an
Intelligent Social Learning (ISL) algorithm to enable intelligent control of
black-box robotic systems. Inspired by mutual learning among individuals in
human social groups, ISL includes learning, imitation, and self-study styles.
Individuals in the learning style use the Levy flight search strategy to learn
from the best performer and form the closest relationships. In the imitation
style, individuals mimic the best performer with a second-level rapport by
employing a random perturbation strategy. In the self-study style, individuals
learn independently using a normal distribution sampling method while
maintaining a distant relationship with the best performer. Individuals in the
population are regarded as autonomous intelligent agents in each style. Neural
networks perform strategic actions in three styles to interact with the
environment and the robot and iteratively optimize the network policy. Overall,
ISL builds on the principles of intelligent optimization, incorporating ideas
from reinforcement learning, and possesses strong search capabilities, fast
computation speed, fewer hyperparameters, and insensitivity to sparse rewards.
The proposed ISL algorithm is compared with four state-of-the-art methods on
six continuous control benchmark cases in MuJoCo to verify its effectiveness
and advantages. Furthermore, ISL is adopted in the simulation and experimental
grasping tasks of the UR3 robot for validations, and satisfactory solutions are
yielded.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06579" title="Abstract">arXiv:2311.06579</a> [<a href="/pdf/2311.06579" title="Download PDF">pdf</a>, <a href="/format/2311.06579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Five-Tiered Route Planner for Multi-AUV Accessing Fixed Nodes in  Uncertain Ocean Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Meiqin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Senlin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+R">Ronghao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+S">Shanling Dong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This article introduces a five-tiered route planner for accessing multiple
nodes with multiple autonomous underwater vehicles (AUVs) that enables
efficient task completion in stochastic ocean environments. First, the
pre-planning tier solves the single-AUV routing problem to find the optimal
giant route (GR), estimates the number of required AUVs based on GR
segmentation, and allocates nodes for each AUV to access. Second, the route
planning tier plans individual routes for each AUV. During navigation, the path
planning tier provides each AUV with physical paths between any two points,
while the actuation tier is responsible for path tracking and obstacle
avoidance. Finally, in the stochastic ocean environment, deviations from the
initial plan may occur, thus, an auction-based coordination tier drives online
task coordination among AUVs in a distributed manner. Simulation experiments
are conducted in multiple different scenarios to test the performance of the
proposed planner, and the promising results show that the proposed method
reduces AUV usage by 7.5% compared with the existing methods. When using the
same number of AUVs, the fleet equipped with the proposed planner achieves a
6.2% improvement in average task completion rate.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06580" title="Abstract">arXiv:2311.06580</a> [<a href="/pdf/2311.06580" title="Download PDF">pdf</a>, <a href="/format/2311.06580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Power Systems Dynamics with Symbolic Physics-Informed Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tran%2C+H+T+T">Huynh T. T. Tran</a>, 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+H+T">Hieu T. Nguyen</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The 2024 Conference on Innovative Smart Grid Technologies, North
  America (ISGT NA 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In recent years, scientific machine learning, particularly physic-informed
neural networks (PINNs), has introduced new innovative methods to understanding
the differential equations that describe power system dynamics, providing a
more efficient alternative to traditional methods. However, using a single
neural network to capture patterns of all variables requires a large enough
size of networks, leading to a long time of training and still high
computational costs. In this paper, we utilize the interfacing of PINNs with
symbolic techniques to construct multiple single-output neural networks by
taking the loss function apart and integrating it over the relevant domain.
Also, we reweigh the factors of the components in the loss function to improve
the performance of the network for instability systems. Our results show that
the symbolic PINNs provide higher accuracy with significantly fewer parameters
and faster training time. By using the adaptive weight method, the symbolic
PINNs can avoid the vanishing gradient problem and numerical instability.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06582" title="Abstract">arXiv:2311.06582</a> [<a href="/pdf/2311.06582" title="Download PDF">pdf</a>, <a href="/format/2311.06582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combinatory Array Logic with Sums
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raya%2C+R">Rodrigo Raya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">We prove an NP upper bound on a theory of integer-indexed integer-valued
arrays that extends combinatory array logic with an ordering relation on the
index set and the ability to express sums of elements. We compare our fragment
with seven other fragments in the literature in terms of their expressiveness
and computational complexity.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06586" title="Abstract">arXiv:2311.06586</a> [<a href="/pdf/2311.06586" title="Download PDF">pdf</a>, <a href="/ps/2311.06586" title="Download PostScript">ps</a>, <a href="/format/2311.06586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Power of Attention: Bridging Cognitive Load, Multimedia Learning,  and AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Macedo%2C+H+d+S">Herbert dos Santos Macedo</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+I+T+F+d">Italo Thiago Felix dos Santos</a>, 
<a href="/search/cs?searchtype=author&query=da+Silva%2C+E+L+O">Edgard Luciano Oliveira da Silva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">This article addresses the intersection of various educational theories and
their relationship with the education of computer science students, with a
focus on the importance of understanding computational thinking and its
application in education. The historical context and fundamental concepts of
Cognitive Load Theory, Multimedia Learning, and Constructivism are explored,
highlighting their underlying biological assumptions about human learning. It
also examines how these theories can be integrated with the use of Artificial
Intelligence (AI) in education, with a particular emphasis on the attention
mechanisms and abstract learning present in AI models like Transformers.
Lastly, the relevance of these theories and practices for computer education
student training is discussed, emphasizing how the development of computational
thinking can contribute to a more effective approach in teaching and learning.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06589" title="Abstract">arXiv:2311.06589</a> [<a href="/pdf/2311.06589" title="Download PDF">pdf</a>, <a href="/format/2311.06589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stability and Convergence analysis of a Crank-Nicolson Galerkin scheme  for the fractional Korteweg-de Vries equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dwivedi%2C+M">Mukul Dwivedi</a>, 
<a href="/search/math?searchtype=author&query=Sarkar%2C+T">Tanmay Sarkar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper we study the convergence of a fully discrete Crank-Nicolson
Galerkin scheme for the initial value problem associated with the fractional
Korteweg-de Vries (KdV) equation, which involves the fractional Laplacian and
non-linear convection terms. Our proof relies on the Kato type local smoothing
effect to estimate the localized $H^{\alpha/2}$-norm of the approximated
solution, where $\alpha \in [1,2)$. We demonstrate that the scheme converges
strongly in $L^2(0,T;L^2_{loc}(\mathbb{R}))$ to a weak solution of the
fractional KdV equation provided the initial data in $L^2(\mathbb{R})$.
Assuming the initial data is sufficiently regular, we obtain the rate of
convergence for the numerical scheme. Finally, the theoretical convergence
rates are justified numerically through various numerical illustrations.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06592" title="Abstract">arXiv:2311.06592</a> [<a href="/pdf/2311.06592" title="Download PDF">pdf</a>, <a href="/format/2311.06592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Study of Using ChatGPT for Fact Verification Task
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+M">Mohna Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+A">Adithya Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qi Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">ChatGPT has recently emerged as a powerful tool for performing diverse NLP
tasks. However, ChatGPT has been criticized for generating nonfactual
responses, raising concerns about its usability for sensitive tasks like fact
verification. This study investigates three key research questions: (1) Can
ChatGPT be used for fact verification tasks? (2) What are different prompts
performance using ChatGPT for fact verification tasks? (3) For the
best-performing prompt, what common mistakes does ChatGPT make? Specifically,
this study focuses on conducting a comprehensive and systematic analysis by
designing and comparing the performance of three different prompts for fact
verification tasks on the benchmark FEVER dataset using ChatGPT.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06595" title="Abstract">arXiv:2311.06595</a> [<a href="/pdf/2311.06595" title="Download PDF">pdf</a>, <a href="/format/2311.06595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Classification to Generation: Insights into Crosslingual Retrieval  Augmented ICL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoqian Li</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+E">Ercong Nie</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+S">Sheng Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2311.00587">arXiv:2311.00587</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The remarkable ability of Large Language Models (LLMs) to understand and
follow instructions has sometimes been limited by their in-context learning
(ICL) performance in low-resource languages. To address this, we introduce a
novel approach that leverages cross-lingual retrieval-augmented in-context
learning (CREA-ICL). By extracting semantically similar prompts from
high-resource languages, we aim to improve the zero-shot performance of
multilingual pre-trained language models (MPLMs) across diverse tasks. Though
our approach yields steady improvements in classification tasks, it faces
challenges in generation tasks. Our evaluation offers insights into the
performance dynamics of retrieval-augmented in-context learning across both
classification and generation domains.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06597" title="Abstract">arXiv:2311.06597</a> [<a href="/pdf/2311.06597" title="Download PDF">pdf</a>, <a href="/format/2311.06597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Grokking Through A Robustness Viewpoint
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zhiquan Tan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Weiran Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently, an unusual phenomenon called grokking has gained much attention,
where sometimes a neural network generalizes long after it perfectly fits the
training data. We try to understand this seemingly strange phenomenon using the
robustness of the neural network. Using a robustness viewpoint, we show that
the popular $l_2$ weight norm (metric) of the neural network is actually a
sufficient condition for grokking. As we also empirically find that $l_2$ norm
correlates with grokking on the test data not in a timely way, we propose new
metrics based on robustness and information theory and find that our new
metrics correlate well with the grokking phenomenon. Based on the previous
observations, we propose methods to speed up the generalization process. In
addition, we examine the standard training process on modulo addition dataset
and find that it hardly learns other basic group operations before grokking,
including the commutative law. Interestingly, the speed up of generalization
when using our proposed method can be partially explained by learning the
commutative law, a necessary condition when the model groks on test dataset.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06602" title="Abstract">arXiv:2311.06602</a> [<a href="/pdf/2311.06602" title="Download PDF">pdf</a>, <a href="/format/2311.06602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BizBench: A Quantitative Reasoning Benchmark for Business and Finance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koncel-Kedziorski%2C+R">Rik Koncel-Kedziorski</a>, 
<a href="/search/cs?searchtype=author&query=Krumdick%2C+M">Michael Krumdick</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+V">Viet Lai</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+V">Varshini Reddy</a>, 
<a href="/search/cs?searchtype=author&query=Lovering%2C+C">Charles Lovering</a>, 
<a href="/search/cs?searchtype=author&query=Tanner%2C+C">Chris Tanner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">As large language models (LLMs) impact a growing number of complex domains,
it is becoming increasingly important to have fair, accurate, and rigorous
evaluation benchmarks. Evaluating the reasoning skills required for business
and financial NLP stands out as a particularly difficult challenge. We
introduce BizBench, a new benchmark for evaluating models' ability to reason
about realistic financial problems. BizBench comprises 8 quantitative reasoning
tasks. Notably, BizBench targets the complex task of question-answering (QA)
for structured and unstructured financial data via program synthesis (i.e.,
code generation). We introduce three diverse financially-themed code-generation
tasks from newly collected and augmented QA data. Additionally, we isolate
distinct financial reasoning capabilities required to solve these QA tasks:
reading comprehension of financial text and tables, which is required to
extract correct intermediate values; and understanding domain knowledge (e.g.,
financial formulas) needed to calculate complex solutions. Collectively, these
tasks evaluate a model's financial background knowledge, ability to extract
numeric entities from financial documents, and capacity to solve problems with
code. We conduct an in-depth evaluation of open-source and commercial LLMs,
illustrating that BizBench is a challenging benchmark for quantitative
reasoning in the finance and business domain.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06604" title="Abstract">arXiv:2311.06604</a> [<a href="/pdf/2311.06604" title="Download PDF">pdf</a>, <a href="/ps/2311.06604" title="Download PostScript">ps</a>, <a href="/format/2311.06604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hub-Based Platoon Formation: Optimal Release Policies and Approximate  Solutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Johansson%2C+A">Alexander Johansson</a>, 
<a href="/search/eess?searchtype=author&query=Nekouei%2C+E">Ehsan Nekouei</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+X">Xiaotong Sun</a>, 
<a href="/search/eess?searchtype=author&query=Johansson%2C+K+H">Karl Henrik Johansson</a>, 
<a href="/search/eess?searchtype=author&query=M%C3%A5rtensson%2C+J">Jonas M&#xe5;rtensson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for T-ITS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper studies the optimal hub-based platoon formation at hubs along a
highway under decentralized, distributed, and centralized policies. Hubs are
locations along highways where trucks can wait for other trucks to form
platoons. A coordinator at each hub decides the departure time of trucks, and
the released trucks from the hub will form platoons. The problem is cast as an
optimization problem where the objective is to maximize the platooning reward.
We first show that the optimal release policy in the decentralized case, where
the hubs do not exchange information, is to release all trucks at the hub when
the number of trucks exceeds a threshold computed by dynamic programming. We
develop efficient approximate release policies for the dependent arrival case
using this result. To study the value of information exchange among hubs on
platoon formation, we next study the distributed and centralized platoon
formation policies which require information exchange among hubs. To this end,
we develop receding horizon solutions for the distributed and centralized
platoon formation at hubs using the dynamic programming technique. Finally, we
perform a simulation study over three hubs in northern Sweden. The profits of
the decentralized policies are shown to be approximately 3.5% lower than the
distributed policy and 8% lower than the centralized release policy. This
observation suggests that decentralized policies are prominent solutions for
hub-based platooning as they do not require information exchange among hubs and
can achieve a similar performance compared with distributed and centralized
policies.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06607" title="Abstract">arXiv:2311.06607</a> [<a href="/pdf/2311.06607" title="Download PDF">pdf</a>, <a href="/format/2311.06607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monkey: Image Resolution and Text Label Are Important Things for Large  Multi-modal Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Biao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhiyin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jingxu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yabo Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiang Bai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Large Multimodal Models have demonstrated impressive capabilities in
understanding general vision-language tasks. However, due to the limitation of
supported input resolution (e.g., 448 x 448) as well as the inexhaustive
description of the training image-text pair, these models often encounter
challenges when dealing with intricate scene understandings and narratives.
Here we address the problem by proposing the Monkey. Our contributions are
two-fold: 1) without pretraining from the start, our method can be built upon
an existing vision encoder (e.g., vit-BigHuge) to effectively improve the input
resolution capacity up to 896 x 1344 pixels; 2) we propose a multi-level
description generation method, which automatically provides rich information
that can guide model to learn contextual association between scenes and
objects. Our extensive testing across more than 16 distinct datasets reveals
that Monkey achieves consistently competitive performance over the existing
LMMs on fundamental tasks, such as Image Captioning, General Visual Question
Answering (VQA), and Document-oriented VQA. Models, interactive demo, and the
source code are provided at the following
https://github.com/Yuliang-Liu/Monkey.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06609" title="Abstract">arXiv:2311.06609</a> [<a href="/pdf/2311.06609" title="Download PDF">pdf</a>, <a href="/ps/2311.06609" title="Download PostScript">ps</a>, <a href="/format/2311.06609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Power of Bidiagonal Matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Higham%2C+N+J">Nicholas J. Higham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Bidiagonal matrices are widespread in numerical linear algebra, not least
because of their use in the standard algorithm for computing the singular value
decomposition and their appearance as LU factors of tridiagonal matrices. We
show that bidiagonal matrices have a number of interesting properties that make
them powerful tools in a variety of problems, especially when they are
multiplied together. We show that the inverse of a product of bidiagonal
matrices is insensitive to small componentwise relative perturbations in the
factors if the factors or their inverses are nonnegative. We derive
componentwise rounding error bounds for the solution of a linear system $Ax =
b$, where $A$ or $A^{-1}$ is a product $B_1 B_2\dots B_k$ of bidiagonal
matrices, showing that strong results are obtained when the $B_i$ are
nonnegative or have a checkerboard sign pattern. We show that given the \fact\
of an $n\times n$ totally nonnegative matrix $A$ into the product of bidiagonal
matrices, $\|A^{-1}\|_{\infty}$ can be computed in $O(n^2)$ flops and that in
floating-point arithmetic the computed result has small relative error, no
matter how large $\|A^{-1}\|_{\infty}$ is. We also show how factorizations
involving bidiagonal matrices of some special matrices, such as the Frank
matrix and the Kac--Murdock--Szeg\"o matrix, yield simple proofs of the total
nonnegativity and other properties of these matrices.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06612" title="Abstract">arXiv:2311.06612</a> [<a href="/pdf/2311.06612" title="Download PDF">pdf</a>, <a href="/format/2311.06612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PerceptionGPT: Effectively Fusing Visual Perception into LLM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pi%2C+R">Renjie Pi</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+L">Lewei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jiahui Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jipeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">The integration of visual inputs with large language models (LLMs) has led to
remarkable advancements in multi-modal capabilities, giving rise to visual
large language models (VLLMs). However, effectively harnessing VLLMs for
intricate visual perception tasks remains a challenge. In this paper, we
present a novel end-to-end framework named PerceptionGPT, which efficiently and
effectively equips the VLLMs with visual perception abilities by leveraging the
representation power of LLMs' token embedding. Our proposed method treats the
token embedding of the LLM as the carrier of spatial information, then leverage
lightweight visual task encoders and decoders to perform visual perception
tasks (e.g., detection, segmentation). Our approach significantly alleviates
the training difficulty suffered by previous approaches that formulate the
visual outputs as discrete tokens, and enables achieving superior performance
with fewer trainable parameters, less training data and shorted training time.
Moreover, as only one token embedding is required to decode the visual outputs,
the resulting sequence length during inference is significantly reduced.
Consequently, our approach enables accurate and flexible representations,
seamless integration of visual perception tasks, and efficient handling of a
multiple of visual outputs. We validate the effectiveness and efficiency of our
approach through extensive experiments. The results demonstrate significant
improvements over previous methods with much fewer trainable parameters and GPU
hours, which facilitates future research in enabling LLMs with visual
perception abilities.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06613" title="Abstract">arXiv:2311.06613</a> [<a href="/pdf/2311.06613" title="Download PDF">pdf</a>, <a href="/ps/2311.06613" title="Download PostScript">ps</a>, <a href="/format/2311.06613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computer Vision for Particle Size Analysis of Coarse-Grained Soils
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Youwai%2C+S">Sompote Youwai</a>, 
<a href="/search/cs?searchtype=author&query=Makam%2C+P">Parchya Makam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Particle size analysis (PSA) is a fundamental technique for evaluating the
physical characteristics of soils. However, traditional methods like sieving
can be time-consuming and labor-intensive. In this study, we present a novel
approach that utilizes computer vision (CV) and the Python programming language
for PSA of coarse-grained soils, employing a standard mobile phone camera. By
eliminating the need for a high-performance camera, our method offers
convenience and cost savings. Our methodology involves using the OPENCV library
to detect and measure soil particles in digital photographs taken under
ordinary lighting conditions. For accurate particle size determination, a
calibration target with known dimensions is placed on a plain paper alongside
20 different sand samples. The proposed method is compared with traditional
sieve analysis and exhibits satisfactory performance for soil particles larger
than 2 mm, with a mean absolute percent error (MAPE) of approximately 6%.
However, particles smaller than 2 mm result in higher MAPE, reaching up to 60%.
To address this limitation, we recommend using a higher-resolution camera to
capture images of the smaller soil particles. Furthermore, we discuss the
advantages, limitations, and potential future improvements of our method.
Remarkably, the program can be executed on a mobile phone, providing immediate
results without the need to send soil samples to a laboratory. This
field-friendly feature makes our approach highly convenient for on-site usage,
outside of a traditional laboratory setting. Ultimately, this novel method
represents an initial disruption to the industry, enabling efficient particle
size analysis of soil without the reliance on laboratory-based sieve analysis.
KEYWORDS: Computer vision, Grain size, ARUCO
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06615" title="Abstract">arXiv:2311.06615</a> [<a href="/pdf/2311.06615" title="Download PDF">pdf</a>, <a href="/format/2311.06615" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A review of potential barriers to the participation of electric vehicles  in German balancing markets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cunat%2C+P">P&#xe9;rine Cunat</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">As conventional flexibility providers are gradually being replaced by
variable renewable energies and electricity demand keeps rising, additional
flexibility will become increasingly valuable for the power system. Meanwhile,
new sources of flexibility known as distributed energy resources are starting
to emerge. Among them electric vehicles have a promising potential to provide
short-term frequency-control services. However their integration into balancing
markets faces various barriers. Based on the existing literature, this paper
aims at identifying which potential barriers exist in the case of the
participation of electric vehicles in German balancing markets.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06622" title="Abstract">arXiv:2311.06622</a> [<a href="/pdf/2311.06622" title="Download PDF">pdf</a>, <a href="/format/2311.06622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TrainerAgent: Customizable and Efficient Model Training through  LLM-Powered Multi-Agent System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Hao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianke Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhelun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+A">Aoxiong Yin</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+S">Siming Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+W">Wanggui He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Training AI models has always been challenging, especially when there is a
need for custom models to provide personalized services. Algorithm engineers
often face a lengthy process to iteratively develop models tailored to specific
business requirements, making it even more difficult for non-experts. The quest
for high-quality and efficient model development, along with the emergence of
Large Language Model (LLM) Agents, has become a key focus in the industry.
Leveraging the powerful analytical, planning, and decision-making capabilities
of LLM, we propose a TrainerAgent system comprising a multi-agent framework
including Task, Data, Model and Server agents. These agents analyze
user-defined tasks, input data, and requirements (e.g., accuracy, speed),
optimizing them comprehensively from both data and model perspectives to obtain
satisfactory models, and finally deploy these models as online service.
Experimental evaluations on classical discriminative and generative tasks in
computer vision and natural language processing domains demonstrate that our
system consistently produces models that meet the desired criteria.
Furthermore, the system exhibits the ability to critically identify and reject
unattainable tasks, such as fantastical scenarios or unethical requests,
ensuring robustness and safety. This research presents a significant
advancement in achieving desired models with increased efficiency and quality
as compared to traditional model development, facilitated by the integration of
LLM-powered analysis, decision-making, and execution capabilities, as well as
the collaboration among four agents. We anticipate that our work will
contribute to the advancement of research on TrainerAgent in both academic and
industry communities, potentially establishing it as a new paradigm for model
development in the field of AI.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06623" title="Abstract">arXiv:2311.06623</a> [<a href="/pdf/2311.06623" title="Download PDF">pdf</a>, <a href="/format/2311.06623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VT-Former: A Transformer-based Vehicle Trajectory Prediction Approach  For Intelligent Highway Transportation Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pazho%2C+A+D">Armin Danesh Pazho</a>, 
<a href="/search/cs?searchtype=author&query=Katariya%2C+V">Vinit Katariya</a>, 
<a href="/search/cs?searchtype=author&query=Noghre%2C+G+A">Ghazal Alinezhad Noghre</a>, 
<a href="/search/cs?searchtype=author&query=Tabkhi%2C+H">Hamed Tabkhi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Enhancing roadway safety and traffic management has become an essential focus
area for a broad range of modern cyber-physical systems and intelligent
transportation systems. Vehicle Trajectory Prediction is a pivotal element
within numerous applications for highway and road safety. These applications
encompass a wide range of use cases, spanning from traffic management and
accident prevention to enhancing work-zone safety and optimizing energy
conservation. The ability to implement intelligent management in this context
has been greatly advanced by the developments in the field of Artificial
Intelligence (AI), alongside the increasing deployment of surveillance cameras
across road networks. In this paper, we introduce a novel transformer-based
approach for vehicle trajectory prediction for highway safety and surveillance,
denoted as VT-Former. In addition to utilizing transformers to capture
long-range temporal patterns, a new Graph Attentive Tokenization (GAT) module
has been proposed to capture intricate social interactions among vehicles.
Combining these two core components culminates in a precise approach for
vehicle trajectory prediction. Our study on three benchmark datasets with three
different viewpoints demonstrates the State-of-The-Art (SoTA) performance of
VT-Former in vehicle trajectory prediction and its generalizability and
robustness. We also evaluate VT-Former's efficiency on embedded boards and
explore its potential for vehicle anomaly detection as a sample application,
showcasing its broad applicability.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06625" title="Abstract">arXiv:2311.06625</a> [<a href="/pdf/2311.06625" title="Download PDF">pdf</a>, <a href="/format/2311.06625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Streamlining Energy Transition Scenarios to Key Policy Decisions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baader%2C+F+J">Florian Joseph Baader</a>, 
<a href="/search/cs?searchtype=author&query=Moret%2C+S">Stefano Moret</a>, 
<a href="/search/cs?searchtype=author&query=Wiesemann%2C+W">Wolfram Wiesemann</a>, 
<a href="/search/cs?searchtype=author&query=Staffell%2C+I">Iain Staffell</a>, 
<a href="/search/cs?searchtype=author&query=Bardow%2C+A">Andr&#xe9; Bardow</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Uncertainties surrounding the energy transition often lead modelers to
present large sets of scenarios that are challenging for policymakers to
interpret and act upon. An alternative approach is to define a few qualitative
storylines from stakeholder discussions, which can be affected by biases and
infeasibilities. Leveraging decision trees, a popular machine-learning
technique, we derive interpretable storylines from many quantitative scenarios
and show how the key decisions in the energy transition are interlinked.
Specifically, our results demonstrate that choosing a high deployment of
renewables and sector coupling makes global decarbonization scenarios robust
against uncertainties in climate sensitivity and demand. Also, the energy
transition to a fossil-free Europe is primarily determined by choices on the
roles of bioenergy, storage, and heat electrification. Our transferrable
approach translates vast energy model results into a small set of critical
decisions, guiding decision-makers in prioritizing the key factors that will
shape the energy transition.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06633" title="Abstract">arXiv:2311.06633</a> [<a href="/pdf/2311.06633" title="Download PDF">pdf</a>, <a href="/ps/2311.06633" title="Download PostScript">ps</a>, <a href="/format/2311.06633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Pros and Cons of Using Machine Learning and Interpretable Machine  Learning Methods in psychiatry detection applications, specifically  depression disorder: A Brief Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Simchi%2C+H">Hossein Simchi</a>, 
<a href="/search/cs?searchtype=author&query=Tajik%2C+S">Samira Tajik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The COVID-19 pandemic has forced many people to limit their social
activities, which has resulted in a rise in mental illnesses, particularly
depression. To diagnose these illnesses with accuracy and speed, and prevent
severe outcomes such as suicide, the use of machine learning has become
increasingly important. Additionally, to provide precise and understandable
diagnoses for better treatment, AI scientists and researchers must develop
interpretable AI-based solutions. This article provides an overview of relevant
articles in the field of machine learning and interpretable AI, which helps to
understand the advantages and disadvantages of using AI in psychiatry disorder
detection applications.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06640" title="Abstract">arXiv:2311.06640</a> [<a href="/pdf/2311.06640" title="Download PDF">pdf</a>, <a href="/format/2311.06640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NewsGPT: ChatGPT Integration for Robot-Reporter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hireche%2C+A">Abdelhadi Hireche</a>, 
<a href="/search/cs?searchtype=author&query=Belkacem%2C+A+N">Abdelkader Nasreddine Belkacem</a>, 
<a href="/search/cs?searchtype=author&query=Jamil%2C+S">Sadia Jamil</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chao Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC); Multimedia (cs.MM)

</div>
<p class="mathjax">The integration of large language models (LLMs) with social robots has
emerged as a promising avenue for enhancing human-robot interactions at a time
when news reports generated by artificial intelligence (AI) are gaining in
credibility. This integration is expected to intensify and become a more
productive resource for journalism, media, communication, and education. In
this paper a novel system is proposed that integrates AI's generative
pretrained transformer (GPT) model with the Pepper robot, with the aim of
improving the robot's natural language understanding and response generation
capabilities for enhanced social interactions. By leveraging GPT's powerful
language processing capabilities, this system offers a comprehensive pipeline
that incorporates voice input recording, speech-to-text transcription, context
analysis, and text-to-speech synthesis action generation. The Pepper robot is
enabled to comprehend user queries, generate informative responses with general
knowledge, maintain contextually relevant conversations, and act as a more
domain-oriented news reporter. It is also linked with a news resource and
powered with a Google search capability. To evaluate the performance of the
framework, experiments were conducted involving a set of diverse questions. The
robot's responses were assessed on the basis of eight criteria, including
relevance, context, and fluency. Despite some identified limitations, this
system contributes to the field of journalism and human-robot interaction by
showcasing the potential of integrating LLMs with social robots. The proposed
framework opens up opportunities for improving the conversational capabilities
of robots, enabling interactions that are smoother, more engaging, and more
context aware.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06643" title="Abstract">arXiv:2311.06643</a> [<a href="/pdf/2311.06643" title="Download PDF">pdf</a>, <a href="/format/2311.06643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy Risks Analysis and Mitigation in Federated Learning for Medical  Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Das%2C+B+C">Badhan Chandra Das</a>, 
<a href="/search/cs?searchtype=author&query=Amini%2C+M+H">M. Hadi Amini</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yanzhao Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> V1
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Federated learning (FL) is gaining increasing popularity in the medical
domain for analyzing medical images, which is considered an effective technique
to safeguard sensitive patient data and comply with privacy regulations.
However, several recent studies have revealed that the default settings of FL
may leak private training data under privacy attacks. Thus, it is still unclear
whether and to what extent such privacy risks of FL exist in the medical
domain, and if so, ``how to mitigate such risks?''. In this paper, first, we
propose a holistic framework for Medical data Privacy risk analysis and
mitigation in Federated Learning (MedPFL) to analyze privacy risks and develop
effective mitigation strategies in FL for protecting private medical data.
Second, we demonstrate the substantial privacy risks of using FL to process
medical images, where adversaries can easily perform privacy attacks to
reconstruct private medical images accurately. Third, we show that the defense
approach of adding random noises may not always work effectively to protect
medical images against privacy attacks in FL, which poses unique and pressing
challenges associated with medical data for privacy protection.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06647" title="Abstract">arXiv:2311.06647</a> [<a href="/pdf/2311.06647" title="Download PDF">pdf</a>, <a href="/format/2311.06647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Text Classification: Analyzing Prototype-Based Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sourati%2C+Z">Zhivar Sourati</a>, 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+D">Darshan Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Ilievski%2C+F">Filip Ilievski</a>, 
<a href="/search/cs?searchtype=author&query=Gashteovski%2C+K">Kiril Gashteovski</a>, 
<a href="/search/cs?searchtype=author&query=Saralajew%2C+S">Sascha Saralajew</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Downstream applications often require text classification models to be
accurate, robust, and interpretable. While the accuracy of the stateof-the-art
language models approximates human performance, they are not designed to be
interpretable and often exhibit a drop in performance on noisy data. The family
of PrototypeBased Networks (PBNs) that classify examples based on their
similarity to prototypical examples of a class (prototypes) is natively
interpretable and shown to be robust to noise, which enabled its wide usage for
computer vision tasks. In this paper, we study whether the robustness
properties of PBNs transfer to text classification tasks. We design a modular
and comprehensive framework for studying PBNs, which includes different
backbone architectures, backbone sizes, and objective functions. Our evaluation
protocol assesses the robustness of models against character-, word-, and
sentence-level perturbations. Our experiments on three benchmarks show that the
robustness of PBNs transfers to NLP classification tasks facing realistic
perturbations. Moreover, the robustness of PBNs is supported mostly by the
objective function that keeps prototypes interpretable, while the robustness
superiority of PBNs over vanilla models becomes more salient as datasets get
more complex.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06648" title="Abstract">arXiv:2311.06648</a> [<a href="/pdf/2311.06648" title="Download PDF">pdf</a>, <a href="/format/2311.06648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design of Reconfigurable Intelligent Surfaces by Using S-Parameter  Multiport Network Theory -- Optimization and Full-Wave Validation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abrardo%2C+A">Andrea Abrardo</a>, 
<a href="/search/cs?searchtype=author&query=Toccafondi%2C+A">Alberto Toccafondi</a>, 
<a href="/search/cs?searchtype=author&query=Di+Renzo%2C+M">Marco Di Renzo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for journal publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Multiport network theory has been proved to be a suitable abstraction model
for analyzing and optimizing reconfigurable intelligent surfaces (RISs),
especially for studying the impact of the electromagnetic mutual coupling among
radiating elements that are spaced less than half of the wavelength. Both
representations in terms of $Z$-parameter (impedance) and $S$-parameter
(scattering) matrices are widely utilized. In this paper, we embrace multiport
network theory for analyzing and optimizing the reradiation properties of
RIS-aided channels, and provide four new contributions. (i) First, we offer a
thorough comparison between the $Z$-parameter and $S$-parameter
representations. This comparison allows us to unveil that the typical
scattering models utilized for RIS-aided channels ignore the structural
scattering from the RIS, which results in an unwanted specular reflection. (ii)
Then, we develop an iterative algorithm for optimizing, in the presence of
electromagnetic mutual coupling, the tunable loads of the RIS based on the
$S$-parameters representation. We prove that small perturbations of the step
size of the algorithm result in larger variations of the $S$-parameter matrix
compared with the $Z$-parameter matrix, resulting in a faster convergence rate.
(iii) Subsequently, we generalize the proposed algorithm to suppress the
specular reflection due to the structural scattering, while maximizing the
received power towards the direction of interest, and analyze the effectiveness
and tradeoffs of the proposed approach. (iv) Finally, we validate the
theoretical findings and algorithms with numerical simulations and a commercial
full-wave electromagnetic simulator based on the method of moments.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06649" title="Abstract">arXiv:2311.06649</a> [<a href="/pdf/2311.06649" title="Download PDF">pdf</a>, <a href="/format/2311.06649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Template Is All You Meme
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bates%2C+L">Luke Bates</a>, 
<a href="/search/cs?searchtype=author&query=Christensen%2C+P+E">Peter Ebert Christensen</a>, 
<a href="/search/cs?searchtype=author&query=Nakov%2C+P">Preslav Nakov</a>, 
<a href="/search/cs?searchtype=author&query=Gurevych%2C+I">Iryna Gurevych</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 11 supplemental pages, 6 Tables, 10 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Memes are a modern form of communication and meme templates possess a base
semantics that is customizable by whomever posts it on social media. Machine
learning systems struggle with memes, which is likely due to such systems
having insufficient context to understand memes, as there is more to memes than
the obvious image and text. Here, to aid understanding of memes, we release a
knowledge base of memes and information found on www.knowyourmeme.com, which we
call the Know Your Meme Knowledge Base (KYMKB), composed of more than 54,000
images. The KYMKB includes popular meme templates, examples of each template,
and detailed information about the template. We hypothesize that meme templates
can be used to inject models with the context missing from previous approaches.
To test our hypothesis, we create a non-parametric majority-based classifier,
which we call Template-Label Counter (TLC). We find TLC more effective than or
competitive with fine-tuned baselines. To demonstrate the power of meme
templates and the value of both our knowledge base and method, we conduct
thorough classification experiments and exploratory data analysis in the
context of five meme analysis tasks.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06651" title="Abstract">arXiv:2311.06651</a> [<a href="/pdf/2311.06651" title="Download PDF">pdf</a>, <a href="/format/2311.06651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Traffic Sign Recognition Using Local Vision Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farzipour%2C+A">Ali Farzipour</a>, 
<a href="/search/cs?searchtype=author&query=Manzari%2C+O+N">Omid Nejati Manzari</a>, 
<a href="/search/cs?searchtype=author&query=Shokouhi%2C+S+B">Shahriar B. Shokouhi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recognition of traffic signs is a crucial aspect of self-driving cars and
driver assistance systems, and machine vision tasks such as traffic sign
recognition have gained significant attention. CNNs have been frequently used
in machine vision, but introducing vision transformers has provided an
alternative approach to global feature learning. This paper proposes a new
novel model that blends the advantages of both convolutional and
transformer-based networks for traffic sign recognition. The proposed model
includes convolutional blocks for capturing local correlations and
transformer-based blocks for learning global dependencies. Additionally, a
locality module is incorporated to enhance local perception. The performance of
the suggested model is evaluated on the Persian Traffic Sign Dataset and German
Traffic Sign Recognition Benchmark and compared with SOTA convolutional and
transformer-based models. The experimental evaluations demonstrate that the
hybrid network with the locality module outperforms pure transformer-based
models and some of the best convolutional networks in accuracy. Specifically,
our proposed final model reached 99.66% accuracy in the German traffic sign
recognition benchmark and 99.8% in the Persian traffic sign dataset, higher
than the best convolutional models. Moreover, it outperforms existing CNNs and
ViTs while maintaining fast inference speed. Consequently, the proposed model
proves to be significantly faster and more suitable for real-world
applications.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06654" title="Abstract">arXiv:2311.06654</a> [<a href="/pdf/2311.06654" title="Download PDF">pdf</a>, <a href="/format/2311.06654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised and semi-supervised co-salient object detection via  segmentation frequency statistics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+S">Souradeep Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Naha%2C+S">Shujon Naha</a>, 
<a href="/search/cs?searchtype=author&query=Bastan%2C+M">Muhammet Bastan</a>, 
<a href="/search/cs?searchtype=author&query=C%2C+A+K+K">Amit Kumar K C</a>, 
<a href="/search/cs?searchtype=author&query=Samaras%2C+D">Dimitris Samaras</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we address the detection of co-occurring salient objects
(CoSOD) in an image group using frequency statistics in an unsupervised manner,
which further enable us to develop a semi-supervised method. While previous
works have mostly focused on fully supervised CoSOD, less attention has been
allocated to detecting co-salient objects when limited segmentation annotations
are available for training. Our simple yet effective unsupervised method
US-CoSOD combines the object co-occurrence frequency statistics of unsupervised
single-image semantic segmentations with salient foreground detections using
self-supervised feature learning. For the first time, we show that a large
unlabeled dataset e.g. ImageNet-1k can be effectively leveraged to
significantly improve unsupervised CoSOD performance. Our unsupervised model is
a great pre-training initialization for our semi-supervised model SS-CoSOD,
especially when very limited labeled data is available for training. To avoid
propagating erroneous signals from predictions on unlabeled data, we propose a
confidence estimation module to guide our semi-supervised training. Extensive
experiments on three CoSOD benchmark datasets show that both of our
unsupervised and semi-supervised models outperform the corresponding
state-of-the-art models by a significant margin (e.g., on the Cosal2015
dataset, our US-CoSOD model has an 8.8% F-measure gain over a SOTA unsupervised
co-segmentation model and our SS-CoSOD model has an 11.81% F-measure gain over
a SOTA semi-supervised CoSOD model).
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06658" title="Abstract">arXiv:2311.06658</a> [<a href="/pdf/2311.06658" title="Download PDF">pdf</a>, <a href="/ps/2311.06658" title="Download PostScript">ps</a>, <a href="/format/2311.06658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconfigurable Inspection in Manufacturing: State of the Art and  Taxonomy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gupta%2C+H">Harshit Gupta</a>, 
<a href="/search/eess?searchtype=author&query=Madan%2C+A+K">Ashok Kumar Madan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7th International Conference on Automation, Control and Robotics (ICACR) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Applications (stat.AP)

</div>
<p class="mathjax">This article provides an overview of the evolution of the product quality and
measurement inspection procedure with emphasis on the Reconfigurable Inspection
System and Machine. The major components of a reconfigurable manufacturing
system have been examined, and the evolution of manufacturing processes has
been briefly discussed. Different Reconfigurable Inspection Machines (RIMs) and
their arrangement in an assembly line as an inspection system have been
carefully studied and the modern inspection system equipped in RMS has been
compared to the traditional techniques commonly used in inspection of product
quality. A survey of evolving inspection techniques is offered from the
standpoint of technological challenges and advancement affecting manufacturing
over time. As per authors' knowledge, the review on Reconfigurable Inspection
in Manufacturing and taxonomy of reconfigurable inspection systems is rare.
Considering the studies done in this domain, there is still resourceful
taxonomy for this paradigm. Therefore, different types of inspection procedures
have been discussed, their features and applications have been compared to
arrive at the taxonomy of the RIS based on the understanding of the nature of a
RIS after a critical review.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06659" title="Abstract">arXiv:2311.06659</a> [<a href="/pdf/2311.06659" title="Download PDF">pdf</a>, <a href="/format/2311.06659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3DFusion, A real-time 3D object reconstruction pipeline based on  streamed instance segmented data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Jacoby%2C+D">Derek Jacoby</a>, 
<a href="/search/cs?searchtype=author&query=Coady%2C+Y">Yvonne Coady</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents a real-time segmentation and reconstruction system that
utilizes RGB-D images to generate accurate and detailed individual 3D models of
objects within a captured scene. Leveraging state-of-the-art instance
segmentation techniques, the system performs pixel-level segmentation on RGB-D
data, effectively separating foreground objects from the background. The
segmented objects are then reconstructed into distinct 3D models in a
high-performance computation platform. The real-time 3D modelling can be
applied across various domains, including augmented/virtual reality, interior
design, urban planning, road assistance, security systems, and more. To achieve
real-time performance, the paper proposes a method that effectively samples
consecutive frames to reduce network load while ensuring reconstruction
quality. Additionally, a multi-process SLAM pipeline is adopted for parallel 3D
reconstruction, enabling efficient cutting of the clustering objects into
individuals. This system employs the industry-leading framework YOLO for
instance segmentation. To improve YOLO's performance and accuracy,
modifications were made to resolve duplicated or false detection of similar
objects, ensuring the reconstructed models align with the targets. Overall,
this work establishes a robust real-time system with a significant enhancement
for object segmentation and reconstruction in the indoor environment. It can
potentially be extended to the outdoor scenario, opening up numerous
opportunities for real-world applications.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06661" title="Abstract">arXiv:2311.06661</a> [<a href="/pdf/2311.06661" title="Download PDF">pdf</a>, <a href="/ps/2311.06661" title="Download PostScript">ps</a>, <a href="/format/2311.06661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Electromagnetic Signal and Information Theory -- On Electromagnetically  Consistent Communication Models for the Transmission and Processing of  Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Di+Renzo%2C+M">Marco Di Renzo</a>, 
<a href="/search/cs?searchtype=author&query=Migliore%2C+M+D">Marco Donald Migliore</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for journal publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this paper, we overview electromagnetic signal and information theory
(ESIT). ESIT is an interdisciplinary scientific discipline, which amalgamates
electromagnetic theory, signal processing theory, and information theory. ESIT
is aimed at studying and designing physically consistent communication schemes
for the transmission and processing of information in communication networks.
In simple terms, ESIT can be defined as physics-aware information theory and
signal processing for communications. We consider three relevant problems in
contemporary communication theory, and we show how they can be tackled under
the lenses of ESIT. Specifically, we focus on (i) the theoretical and practical
motivations behind antenna designs based on sub-wavelength radiating elements
and interdistances; (ii) the modeling and role played by the electromagnetic
mutual coupling, and the appropriateness of multiport network theory for
modeling it; and (iii) the analytical tools for unveiling the performance
limits and realizing spatial multiplexing in near field, line-of-sight,
channels. To exemplify the role played by ESIT and the need for electromagnetic
consistency, we consider case studies related to reconfigurable intelligent
surfaces and holographic surfaces, and we highlight the inconsistencies of
widely utilized communication models, as opposed to communication models that
originate from first electromagnetic principles.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06668" title="Abstract">arXiv:2311.06668</a> [<a href="/pdf/2311.06668" title="Download PDF">pdf</a>, <a href="/format/2311.06668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-context Vectors: Making In Context Learning More Effective and  Controllable Through Latent Space Steering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+L">Lei Xing</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">James Zou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Large language models (LLMs) demonstrate emergent in-context learning
capabilities, where they adapt to new tasks based on example demonstrations.
However, in-context learning has seen limited effectiveness in many settings,
is difficult to quantitatively control and takes up context window space. To
overcome these limitations, we propose an alternative approach that recasts
in-context learning as in-context vectors (ICV). Using ICV has two steps. We
first use a forward pass on demonstration examples to create the in-context
vector from the latent embedding of the LLM. This vector captures essential
information about the intended task. On a new query, instead of adding
demonstrations to the prompt, we shift the latent states of the LLM using the
ICV. The ICV approach has several benefits: 1) it enables the LLM to more
effectively follow the demonstration examples; 2) it's easy to control by
adjusting the magnitude of the ICV; 3) it reduces the length of the prompt by
removing the in-context demonstrations; 4) ICV is computationally much more
efficient than fine-tuning. We demonstrate that ICV achieves better performance
compared to standard in-context learning and fine-tuning on diverse tasks
including safety, style transfer, role-playing and formatting. Moreover, we
show that we can flexibly teach LLM to simultaneously follow different types of
instructions by simple vector arithmetics on the corresponding ICVs.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06670" title="Abstract">arXiv:2311.06670</a> [<a href="/pdf/2311.06670" title="Download PDF">pdf</a>, <a href="/ps/2311.06670" title="Download PostScript">ps</a>, <a href="/format/2311.06670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EPSAPG: A Pipeline Combining MMseqs2 and PSI-BLAST to Quickly Generate  Extensive Protein Sequence Alignment Profiles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arab%2C+I">Issar Arab</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10th IEEE/ACM International Conference on Big Data Computing, Applications and Technologies
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Numerous machine learning (ML) models employed in protein function and
structure prediction depend on evolutionary information, which is captured
through multiple-sequence alignments (MSA) or position-specific scoring
matrices (PSSM) as generated by PSI-BLAST. Consequently, these predictive
methods are burdened by substantial computational demands and prolonged
computing time requirements. The principal challenge stems from the necessity
imposed on the PSI-BLAST software to load large sequence databases sequentially
in batches and then search for sequence alignments akin to a given query
sequence. In the case of batch queries, the runtime scales even linearly. The
predicament at hand is becoming more challenging as the size of bio-sequence
data repositories experiences exponential growth over time and as a
consequence, this upward trend exerts a proportional strain on the runtime of
PSI-BLAST. To address this issue, an eminent resolution lies in leveraging the
MMseqs2 method, capable of expediting the search process by a magnitude of 100.
However, MMseqs2 cannot be directly employed to generate the final output in
the desired format of PSI-BLAST alignments and PSSM profiles. In this research
work, I developed a comprehensive pipeline that synergistically integrates both
MMseqs2 and PSI-BLAST, resulting in the creation of a robust, optimized, and
highly efficient hybrid alignment pipeline. Notably, the hybrid tool exhibits a
significant speed improvement, surpassing the runtime performance of PSI-BLAST
in generating sequence alignment profiles by a factor of two orders of
magnitude. It is implemented in C++ and is freely available under the MIT
license at https://github.com/issararab/EPSAPG.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06671" title="Abstract">arXiv:2311.06671</a> [<a href="/pdf/2311.06671" title="Download PDF">pdf</a>, <a href="/ps/2311.06671" title="Download PostScript">ps</a>, <a href="/format/2311.06671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guideline for the Production of Digital Rights Management (DRM)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Coates%2C+S+K">Shannon Kathleen Coates</a>, 
<a href="/search/cs?searchtype=author&query=Abroshan%2C+H">Hossein Abroshan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Multiple news sources over the years have reported on the problematic effects
of Digital Rights Management, yet there are no reforms for DRM development,
simply removal. The issues are well-known to the public, frequently repeated
even when addressed: impact on the software and to the devices that run them.
Yet few, if any, have discussed it in recent years, especially with the intent
of eliminating the shown issues. This study reviews Digital Rights Management
as a general topic, including the various forms it can take, the current laws
that affect DRM, and the current public reception and responses. This study
describes the different types of DRM in general terms and then lists both
positive and negative examples.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06673" title="Abstract">arXiv:2311.06673</a> [<a href="/pdf/2311.06673" title="Download PDF">pdf</a>, <a href="/format/2311.06673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dream to Adapt: Meta Reinforcement Learning by Latent Context  Imagination and MDP Imagination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+L">Lu Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Songan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tseng%2C+H+E">H. Eric Tseng</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Huei Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Meta reinforcement learning (Meta RL) has been amply explored to quickly
learn an unseen task by transferring previously learned knowledge from similar
tasks. However, most state-of-the-art algorithms require the meta-training
tasks to have a dense coverage on the task distribution and a great amount of
data for each of them. In this paper, we propose MetaDreamer, a context-based
Meta RL algorithm that requires less real training tasks and data by doing
meta-imagination and MDP-imagination. We perform meta-imagination by
interpolating on the learned latent context space with disentangled properties,
as well as MDP-imagination through the generative world model where physical
knowledge is added to plain VAE networks. Our experiments with various
benchmarks show that MetaDreamer outperforms existing approaches in data
efficiency and interpolated generalization.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06684" title="Abstract">arXiv:2311.06684</a> [<a href="/pdf/2311.06684" title="Download PDF">pdf</a>, <a href="/ps/2311.06684" title="Download PostScript">ps</a>, <a href="/format/2311.06684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contraction-based Tracking Control of Electromechanical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Javanmardi%2C+N">Najmeh Javanmardi</a>, 
<a href="/search/eess?searchtype=author&query=Borja%2C+P">Pablo Borja</a>, 
<a href="/search/eess?searchtype=author&query=Scherpen%2C+J+M+A">Jacquelien M. A. Scherpen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper addresses the trajectory-tracking problem for a class of
electromechanical systems. To this end, the dynamics of the plants are modeled
in the so-called port-Hamiltonian framework. Then, the notion of contraction is
exploited to design the desired closed-loop dynamics and the corresponding
tracking controller. Notably, the proposed control design method does not
require solving partial differential equations or changing the coordinates of
the plant, which permits preserving the physical interpretation of the
controller. The applicability of the proposed approach is illustrated in
several electromechanical systems via simulations.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06688" title="Abstract">arXiv:2311.06688</a> [<a href="/pdf/2311.06688" title="Download PDF">pdf</a>, <a href="/format/2311.06688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Effect of Trust and its Antecedents on Robot Acceptance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fischer%2C+K">Katrin Fischer</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Donggyu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+J">Joo-Wha Hong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In SCRITA 2023 Workshop Proceedings (<a href="/abs/2311.05401">arXiv:2311.05401</a>) held in conjunction with 32nd IEEE International Conference on Robot &amp; Human Interactive Communication, 28/08 - 31/08 2023, Busan (Korea)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">As social and socially assistive robots are becoming more prevalent in our
society, it is beneficial to understand how people form first impressions of
them and eventually come to trust and accept them. This paper describes an
Amazon Mechanical Turk study (n = 239) that investigated trust and its
antecedents trustworthiness and first impressions. Participants evaluated the
social robot Pepper's warmth and competence as well as trustworthiness
characteristics ability, benevolence and integrity followed by their trust in
and intention to use the robot. Mediation analyses assessed to what degree
participants' first impressions affected their willingness to trust and use it.
Known constructs from user acceptance and trust research were introduced to
explain the pathways in which one perception predicted the next. Results showed
that trustworthiness and trust, in serial, mediated the relationship between
first impressions and behavioral intention.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06689" title="Abstract">arXiv:2311.06689</a> [<a href="/pdf/2311.06689" title="Download PDF">pdf</a>, <a href="/ps/2311.06689" title="Download PostScript">ps</a>, <a href="/format/2311.06689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Metric Optimization and Mainstream Bias Mitigation in Recommender  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+R+Z">Roger Zhe Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD Thesis defended on Nov 14, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">The first part of this thesis focuses on maximizing the overall
recommendation accuracy. This accuracy is usually evaluated with some
user-oriented metric tailored to the recommendation scenario, but because
recommendation is usually treated as a machine learning problem, recommendation
models are trained to maximize some other generic criteria that does not
necessarily align with the criteria ultimately captured by the user-oriented
evaluation metric. Recent research aims at bridging this gap between training
and evaluation via direct ranking optimization, but still assumes that the
metric used for evaluation should also be the metric used for training. We
challenge this assumption, mainly because some metrics are more informative
than others. Indeed, we show that models trained via the optimization of a loss
inspired by Rank-Biased Precision (RBP) tend to yield higher accuracy, even
when accuracy is measured with metrics other than RBP. However, the superiority
of this RBP-inspired loss stems from further benefiting users who are already
well-served, rather than helping those who are not.
<br />This observation inspires the second part of this thesis, where our focus
turns to helping non-mainstream users. These are users who are difficult to
recommend to either because there is not enough data to model them, or because
they have niche taste and thus few similar users to look at when recommending
in a collaborative way. These differences in mainstreamness introduce a bias
reflected in an accuracy gap between users or user groups, which we try to
narrow.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06690" title="Abstract">arXiv:2311.06690</a> [<a href="/pdf/2311.06690" title="Download PDF">pdf</a>, <a href="/format/2311.06690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agnostic Membership Query Learning with Nontrivial Savings: New Results,  Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karchmer%2C+A">Ari Karchmer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Complexity (cs.CC); Machine Learning (stat.ML)

</div>
<p class="mathjax">(Abridged) Designing computationally efficient algorithms in the agnostic
learning model (Haussler, 1992; Kearns et al., 1994) is notoriously difficult.
In this work, we consider agnostic learning with membership queries for
touchstone classes at the frontier of agnostic learning, with a focus on how
much computation can be saved over the trivial runtime of 2^n$. This approach
is inspired by and continues the study of ``learning with nontrivial savings''
(Servedio and Tan, 2017). To this end, we establish multiple agnostic learning
algorithms, highlighted by:
<br />1. An agnostic learning algorithm for circuits consisting of a sublinear
number of gates, which can each be any function computable by a sublogarithmic
degree k polynomial threshold function (the depth of the circuit is bounded
only by size). This algorithm runs in time 2^{n -s(n)} for s(n) \approx
n/(k+1), and learns over the uniform distribution over unlabelled examples on
\{0,1\}^n.
<br />2. An agnostic learning algorithm for circuits consisting of a sublinear
number of gates, where each can be any function computable by a \sym^+ circuit
of subexponential size and sublogarithmic degree k. This algorithm runs in time
2^{n-s(n)} for s(n) \approx n/(k+1), and learns over distributions of
unlabelled examples that are products of k+1 arbitrary and unknown
distributions, each over \{0,1\}^{n/(k+1)} (assume without loss of generality
that k+1 divides n).
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06691" title="Abstract">arXiv:2311.06691</a> [<a href="/pdf/2311.06691" title="Download PDF">pdf</a>, <a href="/format/2311.06691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatized Self-Supervised Learning for Skin Lesion Screening
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Useini%2C+V">Vullnet Useini</a>, 
<a href="/search/cs?searchtype=author&query=Tanadini-Lang%2C+S">Stephanie Tanadini-Lang</a>, 
<a href="/search/cs?searchtype=author&query=Lohmeyer%2C+Q">Quentin Lohmeyer</a>, 
<a href="/search/cs?searchtype=author&query=Meboldt%2C+M">Mirko Meboldt</a>, 
<a href="/search/cs?searchtype=author&query=Andratschke%2C+N">Nicolaus Andratschke</a>, 
<a href="/search/cs?searchtype=author&query=Braun%2C+R+P">Ralph P. Braun</a>, 
<a href="/search/cs?searchtype=author&query=Garc%C3%ADa%2C+J+B">Javier Barranco Garc&#xed;a</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The incidence rates of melanoma, the deadliest form of skin cancer, have been
increasing steadily worldwide, presenting a significant challenge to
dermatologists. Early detection of melanoma is crucial for improving patient
survival rates, but identifying suspicious lesions through ugly duckling (UD)
screening, the current method used for skin cancer screening, can be
challenging and often requires expertise in pigmented lesions. To address these
challenges and improve patient outcomes, an artificial intelligence (AI)
decision support tool was developed to assist dermatologists in identifying UD
from wide-field patient images. The tool uses a state-of-the-art object
detection algorithm to identify and extract all skin lesions from patient
images, which are then sorted by suspiciousness using a self-supervised AI
algorithm. A clinical validation study was conducted to evaluate the tool's
performance, which demonstrated an average sensitivity of 93% for the top-10
AI-identified UDs on skin lesions selected by the majority of experts in
pigmented skin lesions. The study also found that dermatologists confidence
increased, and the average majority agreement with the top-10 AI-identified UDs
improved to 100% when assisted by AI. The development of this AI decision
support tool aims to address the shortage of specialists, enable at-risk
patients to receive faster consultations and understand the impact of
AI-assisted screening. The tool's automation can assist dermatologists in
identifying suspicious lesions and provide a more objective assessment,
reducing subjectivity in the screening process. The future steps for this
project include expanding the dataset to include histologically confirmed
melanoma cases and increasing the number of participants for clinical
validation to strengthen the tool's reliability and adapt it for real-world
consultation.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06693" title="Abstract">arXiv:2311.06693</a> [<a href="/pdf/2311.06693" title="Download PDF">pdf</a>, <a href="/format/2311.06693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Mesh Refinement for Electromagnetic Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Belokrys-Fedotov%2C+A">Alexey Belokrys-Fedotov</a>, 
<a href="/search/math?searchtype=author&query=Garanzha%2C+V">Vladimir Garanzha</a>, 
<a href="/search/math?searchtype=author&query=Kamenski%2C+L">Lennard Kamenski</a>, 
<a href="/search/math?searchtype=author&query=Chikitkin%2C+A">Alexandr Chikitkin</a>, 
<a href="/search/math?searchtype=author&query=Pesnya%2C+E">Evgeniy Pesnya</a>, 
<a href="/search/math?searchtype=author&query=Aseev%2C+N">Nikita Aseev</a>, 
<a href="/search/math?searchtype=author&query=Vorobyev%2C+A">Andrey Vorobyev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We consider problems related to initial meshing and adaptive mesh refinement
for the electromagnetic simulation of various structures. The quality of the
initial mesh and the performance of the adaptive refinement are of great
importance for the finite element solution of the Maxwell equations, since they
directly affect the accuracy and the computational time. In this paper, we
describe the complete meshing workflow, which allows the simulation of
arbitrary structures. Test simulations confirm that the presented approach
allows to reach the quality of the industrial simulation software.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06694" title="Abstract">arXiv:2311.06694</a> [<a href="/pdf/2311.06694" title="Download PDF">pdf</a>, <a href="/format/2311.06694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative Multi-View Language Grounding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mitra%2C+C">Chancharik Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Anwar%2C+A">Abrar Anwar</a>, 
<a href="/search/cs?searchtype=author&query=Corona%2C+R">Rodolfo Corona</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+D">Dan Klein</a>, 
<a href="/search/cs?searchtype=author&query=Thomason%2C+J">Jesse Thomason</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)

</div>
<p class="mathjax">In this work, we consider the task of resolving object referents when given a
comparative language description. We present a Multi-view Approach to Grounding
in Context (MAGiC) that leverages transformers to pragmatically reason over
both objects given multiple image views and a language description. In contrast
to past efforts that attempt to connect vision and language for this task
without fully considering the resulting referential context, MAGiC makes use of
the comparative information by jointly reasoning over multiple views of both
object referent candidates and the referring language expression. We present an
analysis demonstrating that comparative reasoning contributes to SOTA
performance on the SNARE object reference task.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06695" title="Abstract">arXiv:2311.06695</a> [<a href="/pdf/2311.06695" title="Download PDF">pdf</a>, <a href="/format/2311.06695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conversational Data Exploration: A Game-Changer for Designing Data  Science Pipelines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vargas-Solar%2C+G">Genoveva Vargas-Solar</a>, 
<a href="/search/cs?searchtype=author&query=Cerquitelli%2C+T">Tania Cerquitelli</a>, 
<a href="/search/cs?searchtype=author&query=Espinosa-Oviedo%2C+J+A">Javier A. Espinosa-Oviedo</a>, 
<a href="/search/cs?searchtype=author&query=Cheval%2C+F">Fran&#xe7;ois Cheval</a>, 
<a href="/search/cs?searchtype=author&query=Buchaille%2C+A">Anthelme Buchaille</a>, 
<a href="/search/cs?searchtype=author&query=Polgar%2C+L">Luca Polgar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Databases (cs.DB)

</div>
<p class="mathjax">This paper proposes a conversational approach implemented by the system
Chatin for driving an intuitive data exploration experience. Our work aims to
unlock the full potential of data analytics and artificial intelligence with a
new generation of data science solutions. Chatin is a cutting-edge tool that
democratises access to AI-driven solutions, empowering non-technical users from
various disciplines to explore data and extract knowledge from it.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06696" title="Abstract">arXiv:2311.06696</a> [<a href="/pdf/2311.06696" title="Download PDF">pdf</a>, <a href="/format/2311.06696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simple and Effective Input Reformulations for Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Brian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lillemark%2C+H">Hansen Lillemark</a>, 
<a href="/search/cs?searchtype=author&query=Keutzer%2C+K">Kurt Keutzer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures. To be published in Empirical Methods in Natural Language Processing (Main) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Foundation language models learn from their finetuning input context in
different ways. In this paper, we reformulate inputs during finetuning for
challenging translation tasks, leveraging model strengths from pretraining in
novel ways to improve downstream performance. These reformulations are simple
data level modifications, require no additional collection of training data or
modification of data at inference time. They can be applied either on single
language pair translation tasks or massively multilingual translation tasks.
Experiments with these techniques demonstrate significant performance
improvements up to $\textbf{3.5 chrF++ on the Flores200 translation
benchmark}$. We hope our research accessibly improves finetuning data
efficiency, enabling more effective training to scalably improve
state-of-the-art performance. Our code is released
$\href{https://github.com/bri25yu/LanguageModelExperimentation}{here}.$
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06697" title="Abstract">arXiv:2311.06697</a> [<a href="/pdf/2311.06697" title="Download PDF">pdf</a>, <a href="/format/2311.06697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trusted Source Alignment in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bashlovkina%2C+V">Vasilisa Bashlovkina</a>, 
<a href="/search/cs?searchtype=author&query=Kuang%2C+Z">Zhaobin Kuang</a>, 
<a href="/search/cs?searchtype=author&query=Matthews%2C+R">Riley Matthews</a>, 
<a href="/search/cs?searchtype=author&query=Clifford%2C+E">Edward Clifford</a>, 
<a href="/search/cs?searchtype=author&query=Jun%2C+Y">Yennie Jun</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+W+W">William W. Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Baumgartner%2C+S">Simon Baumgartner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) are trained on web-scale corpora that inevitably
include contradictory factual information from sources of varying reliability.
In this paper, we propose measuring an LLM property called trusted source
alignment (TSA): the model's propensity to align with content produced by
trusted publishers in the face of uncertainty or controversy. We present
FactCheckQA, a TSA evaluation dataset based on a corpus of fact checking
articles. We describe a simple protocol for evaluating TSA and offer a detailed
analysis of design considerations including response extraction, claim
contextualization, and bias in prompt formulation. Applying the protocol to
PaLM-2, we find that as we scale up the model size, the model performance on
FactCheckQA improves from near-random to up to 80% balanced accuracy in
aligning with trusted sources.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06698" title="Abstract">arXiv:2311.06698</a> [<a href="/pdf/2311.06698" title="Download PDF">pdf</a>, <a href="/format/2311.06698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VidPlat: A Tool for Fast Crowdsourcing of Quality-of-Experience  Measurements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hanchen Li</a>, 
<a href="/search/cs?searchtype=author&query=Schmitt%2C+P">Paul Schmitt</a>, 
<a href="/search/cs?searchtype=author&query=Chetty%2C+M">Marshini Chetty</a>, 
<a href="/search/cs?searchtype=author&query=Feamster%2C+N">Nick Feamster</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Junchen Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">For video or web services, it is crucial to measure user-perceived quality of
experience (QoE) at scale under various video quality or page loading delays.
However, fast QoE measurements remain challenging as they must elicit
subjective assessment from human users. Previous work either (1) automates QoE
measurements by letting crowdsourcing raters watch and rate QoE test videos or
(2) dynamically prunes redundant QoE tests based on previously collected QoE
measurements. Unfortunately, it is hard to combine both ideas because
traditional crowdsourcing requires QoE test videos to be pre-determined before
a crowdsourcing campaign begins. Thus, if researchers want to dynamically prune
redundant test videos based on other test videos' QoE, they are forced to
launch multiple crowdsourcing campaigns, causing extra overheads to
re-calibrate or train raters every time.
<br />This paper presents VidPlat, the first open-source tool for fast and
automated QoE measurements, by allowing dynamic pruning of QoE test videos
within a single crowdsourcing task. VidPlat creates an indirect shim layer
between researchers and the crowdsourcing platforms. It allows researchers to
define a logic that dynamically determines which new test videos need more QoE
ratings based on the latest QoE measurements, and it then redirects
crowdsourcing raters to watch QoE test videos dynamically selected by this
logic. Other than having fewer crowdsourcing campaigns, VidPlat also reduces
the total number of QoE ratings by dynamically deciding when enough ratings are
gathered for each test video. It is an open-source platform that future
researchers can reuse and customize. We have used VidPlat in three projects
(web loading, on-demand video, and online gaming). We show that VidPlat can
reduce crowdsourcing cost by 31.8% - 46.0% and latency by 50.9% - 68.8%.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06700" title="Abstract">arXiv:2311.06700</a> [<a href="/pdf/2311.06700" title="Download PDF">pdf</a>, <a href="/format/2311.06700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep JKO: time-implicit particle methods for general nonlinear gradient  flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lee%2C+W">Wonjun Lee</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+L">Li Wang</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+W">Wuchen Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph)

</div>
<p class="mathjax">We develop novel neural network-based implicit particle methods to compute
high-dimensional Wasserstein-type gradient flows with linear and nonlinear
mobility functions. The main idea is to use the Lagrangian formulation in the
Jordan--Kinderlehrer--Otto (JKO) framework, where the velocity field is
approximated using a neural network. We leverage the formulations from the
neural ordinary differential equation (neural ODE) in the context of continuous
normalizing flow for efficient density computation. Additionally, we make use
of an explicit recurrence relation for computing derivatives, which greatly
streamlines the backpropagation process. Our methodology demonstrates
versatility in handling a wide range of gradient flows, accommodating various
potential functions and nonlinear mobility scenarios. Extensive experiments
demonstrate the efficacy of our approach, including an illustrative example
from Bayesian inverse problems. This underscores that our scheme provides a
viable alternative solver for the Kalman-Wasserstein gradient flow.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06703" title="Abstract">arXiv:2311.06703</a> [<a href="/pdf/2311.06703" title="Download PDF">pdf</a>, <a href="/ps/2311.06703" title="Download PostScript">ps</a>, <a href="/format/2311.06703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enabling Human-Centered AI: A Methodological Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zaifeng Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Software Engineering (cs.SE)

</div>
<p class="mathjax">Human-centered AI (HCAI) is a design philosophy that advocates prioritizing
humans in designing, developing, and deploying intelligent systems, aiming to
maximize the benefits of AI to humans and avoid potential adverse impacts.
While HCAI continues to influence, the lack of guidance on methodology in
practice makes its adoption challenging. This paper proposes a comprehensive
HCAI framework based on our previous work with integrated components, including
design goals, design principles, implementation approaches, interdisciplinary
teams, HCAI methods, and HCAI processes. This paper also presents a
"three-layer" approach to facilitate the implementation of the framework. We
believe this systematic and executable framework can overcome the weaknesses in
current HCAI frameworks and the challenges currently faced in practice, putting
it into action to enable HCAI further.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06705" title="Abstract">arXiv:2311.06705</a> [<a href="/pdf/2311.06705" title="Download PDF">pdf</a>, <a href="/format/2311.06705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Equal Incremental Cost-Based Optimization Method to Enhance Efficiency  for IPOP-Type Converters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cai%2C+H">Hanfeng Cai</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+H">Haiyang Liu</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+H">Heyang Sun</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Q">Qiao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Systematic optimization over a wide power range is often achieved through the
combination of modules of different power levels. This paper addresses the
issue of enhancing the efficiency of a multiple module system connected in
parallel during operation and proposes an algorithm based on equal incremental
cost for dynamic load allocation. Initially, a polynomial fitting technique is
employed to fit efficiency test points for individual modules. Subsequently,
the equal incremental cost-based optimization is utilized to formulate an
efficiency optimization and allocation scheme for the multi-module system. A
simulated annealing algorithm is applied to determine the optimal power output
strategy for each module at given total power flow requirement. Finally, a dual
active bridge (DAB) experimental prototype with two
input-parallel-output-parallel (IPOP) configurations is constructed to validate
the effectiveness of the proposed strategy. Experimental results demonstrate
that under the 800W operating condition, the approach in this paper achieves an
efficiency improvement of over 0.74\% by comparison with equal power sharing
between both modules.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06707" title="Abstract">arXiv:2311.06707</a> [<a href="/pdf/2311.06707" title="Download PDF">pdf</a>, <a href="/format/2311.06707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transfer Learning to Detect COVID-19 Coughs with Incremental Addition of  Patient Coughs to Healthy People&#x27;s Cough Detection Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vhaduri%2C+S">Sudip Vhaduri</a>, 
<a href="/search/cs?searchtype=author&query=Paik%2C+S">Seungyeon Paik</a>, 
<a href="/search/cs?searchtype=author&query=Huber%2C+J+E">Jessica E Huber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted to publish at EAI International Conference on Wireless Mobile Communication and Healthcare (MobiHealth'23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Millions of people have died worldwide from COVID-19. In addition to its high
death toll, COVID-19 has led to unbearable suffering for individuals and a huge
global burden to the healthcare sector. Therefore, researchers have been trying
to develop tools to detect symptoms of this human-transmissible disease
remotely to control its rapid spread. Coughing is one of the common symptoms
that researchers have been trying to detect objectively from smartphone
microphone-sensing. While most of the approaches to detect and track cough
symptoms rely on machine learning models developed from a large amount of
patient data, this is not possible at the early stage of an outbreak. In this
work, we present an incremental transfer learning approach that leverages the
relationship between healthy peoples' coughs and COVID-19 patients' coughs to
detect COVID-19 coughs with reasonable accuracy using a pre-trained healthy
cough detection model and a relatively small set of patient coughs, reducing
the need for large patient dataset to train the model. This type of model can
be a game changer in detecting the onset of a novel respiratory virus.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06711" title="Abstract">arXiv:2311.06711</a> [<a href="/pdf/2311.06711" title="Download PDF">pdf</a>, <a href="/ps/2311.06711" title="Download PostScript">ps</a>, <a href="/format/2311.06711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal $L^\infty(L^2)$ and $L^1(L^2)$ a posteriori error estimates for  the fully discrete approximations of time fractional parabolic differential  equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cao%2C+J">Jiliang Cao</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+W">Wansheng Wang</a>, 
<a href="/search/math?searchtype=author&query=Xiao%2C+A">Aiguo Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We derive optimal order a posteriori error estimates in the $L^\infty(L^2)$
and $L^1(L^2)$-norms for the fully discrete approximations of time fractional
parabolic differential equations. For the discretization in time, we use the
$L1$ methods, while for the spatial discretization, we use standard conforming
finite element methods. The linear and quadratic space-time reconstructions are
introduced, which are generalizations of the elliptic space reconstruction.
Then the related a posteriori error estimates for the linear and quadratic
space-time reconstructions play key roles in deriving global and pointwise
final error estimates. Numerical experiments verify and complement our
theoretical results.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06714" title="Abstract">arXiv:2311.06714</a> [<a href="/pdf/2311.06714" title="Download PDF">pdf</a>, <a href="/format/2311.06714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What factors influence the popularity of user-generated text in the  creative domain? A case study of book reviews
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sazzed%2C+S">Salim Sazzed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in 22nd IEEE International Conference on Machine Learning and Applications (ICMLA), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">This study investigates a range of psychological, lexical, semantic, and
readability features of book reviews to elucidate the factors underlying their
perceived popularity. To this end, we conduct statistical analyses of various
features, including the types and frequency of opinion and emotion-conveying
terms, connectives, character mentions, word uniqueness, commonness, and
sentence structure, among others. Additionally, we utilize two readability
tests to explore whether reading ease is positively associated with review
popularity. Finally, we employ traditional machine learning classifiers and
transformer-based fine-tuned language models with n-gram features to
automatically determine review popularity. Our findings indicate that, with the
exception of a few features (e.g., review length, emotions, and word
uniqueness), most attributes do not exhibit significant differences between
popular and non-popular review groups. Furthermore, the poor performance of
machine learning classifiers using the word n-gram feature highlights the
challenges associated with determining popularity in creative domains. Overall,
our study provides insights into the factors underlying review popularity and
highlights the need for further research in this area, particularly in the
creative realm.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06720" title="Abstract">arXiv:2311.06720</a> [<a href="/pdf/2311.06720" title="Download PDF">pdf</a>, <a href="/format/2311.06720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cappy: Outperforming and Boosting Large Multi-Task LMs with a Small  Scorer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+B">Bowen Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lijuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+E">Eric Xing</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhiting Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jindong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In proceedings of NeurIPS 2023; Code and model available at <a href="https://github.com/tanyuqian/cappy">this https URL</a> and <a href="https://huggingface.co/btan2/cappy-large">this https URL</a>, respectively
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large language models (LLMs) such as T0, FLAN, and OPT-IML, excel in
multi-tasking under a unified instruction-following paradigm, where they also
exhibit remarkable generalization abilities to unseen tasks. Despite their
impressive performance, these LLMs, with sizes ranging from several billion to
hundreds of billions of parameters, demand substantial computational resources,
making their training and inference expensive and inefficient. Furthermore,
adapting these models to downstream applications, particularly complex tasks,
is often unfeasible due to the extensive hardware requirements for finetuning,
even when utilizing parameter-efficient approaches such as prompt tuning.
Additionally, the most powerful multi-task LLMs, such as OPT-IML-175B and
FLAN-PaLM-540B, are not publicly accessible, severely limiting their
customization potential. To address these challenges, we introduce a pretrained
small scorer, Cappy, designed to enhance the performance and efficiency of
multi-task LLMs. With merely 360 million parameters, Cappy functions either
independently on classification tasks or serve as an auxiliary component for
LLMs, boosting their performance. Moreover, Cappy enables efficiently
integrating downstream supervision without requiring LLM finetuning nor the
access to their parameters. Our experiments demonstrate that, when working
independently on 11 language understanding tasks from PromptSource, Cappy
outperforms LLMs that are several orders of magnitude larger. Besides, on 45
complex tasks from BIG-Bench, Cappy boosts the performance of the advanced
multi-task LLM, FLAN-T5, by a large margin. Furthermore, Cappy is flexible to
cooperate with other LLM adaptations, including finetuning and in-context
learning, offering additional performance enhancement.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06723" title="Abstract">arXiv:2311.06723</a> [<a href="/pdf/2311.06723" title="Download PDF">pdf</a>, <a href="/format/2311.06723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Nonlinear Analysis Software Toolkit for Biomechanical Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarwar%2C+S">Shifat Sarwar</a>, 
<a href="/search/cs?searchtype=author&query=Likens%2C+A">Aaron Likens</a>, 
<a href="/search/cs?searchtype=author&query=Stergiou%2C+N">Nick Stergiou</a>, 
<a href="/search/cs?searchtype=author&query=Mastorakis%2C+S">Spyridon Mastorakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">In this paper, we present a nonlinear analysis software toolkit, which can
help in biomechanical gait data analysis by implementing various nonlinear
statistical analysis algorithms. The toolkit is proposed to tackle the need for
an easy-to-use and friendly analyzer for gait data where algorithms seem
complex to implement in software and execute. With the availability of our
toolkit, people without programming knowledge can run the analysis to receive
human gait data analysis results. Our toolkit includes the implementation of
several nonlinear analysis algorithms, while it is also possible for users with
programming experience to expand its scope by implementing and adding more
algorithms to the toolkit. Currently, the toolkit supports MatLab bindings
while being developed in Python. The toolkit can seamlessly run as a background
process to analyze hundreds of different gait data and produce analysis
outcomes and figures that illustrate these results.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06724" title="Abstract">arXiv:2311.06724</a> [<a href="/pdf/2311.06724" title="Download PDF">pdf</a>, <a href="/format/2311.06724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controllable Topic-Focused Abstractive Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bahrainian%2C+S+A">Seyed Ali Bahrainian</a>, 
<a href="/search/cs?searchtype=author&query=Jaggi%2C+M">Martin Jaggi</a>, 
<a href="/search/cs?searchtype=author&query=Eickhoff%2C+C">Carsten Eickhoff</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Controlled abstractive summarization focuses on producing condensed versions
of a source article to cover specific aspects by shifting the distribution of
generated text towards a desired style, e.g., a set of topics. Subsequently,
the resulting summaries may be tailored to user-defined requirements. This
paper presents a new Transformer-based architecture capable of producing
topic-focused summaries. The architecture modifies the cross-attention
mechanism of the Transformer to bring topic-focus control to the generation
process while not adding any further parameters to the model. We show that our
model sets a new state of the art on the NEWTS dataset in terms of
topic-focused abstractive summarization as well as a topic-prevalence score.
Moreover, we show via extensive experiments that our proposed topical
cross-attention mechanism can be plugged into various Transformer models, such
as BART and T5, improving their performance on the CNN/Dailymail and XSum
benchmark datasets for abstractive summarization. This is achieved via
fine-tuning, without requiring training from scratch. Finally, we show through
human evaluation that our model generates more faithful summaries outperforming
the state-of-the-art Frost model.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06725" title="Abstract">arXiv:2311.06725</a> [<a href="/pdf/2311.06725" title="Download PDF">pdf</a>, <a href="/ps/2311.06725" title="Download PostScript">ps</a>, <a href="/format/2311.06725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advanced Feedback Linearization Control for Tiltrotor UAVs: Gait Plan,  Controller Design, and Stability Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zhe Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Doctoral Thesis at The University of Tokyo
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Three challenges, however, can hinder the application of Feedback
Linearization: over-intensive control signals, singular decoupling matrix, and
saturation. Activating any of these three issues can challenge the stability
proof. To solve these three challenges, first, this research proposed the drone
gait plan. The gait plan was initially used to figure out the control problems
in quadruped (four-legged) robots; applying this approach, accompanied by
Feedback Linearization, the quality of the control signals was enhanced. Then,
we proposed the concept of unacceptable attitude curves, which are not allowed
for the tiltrotor to travel to. The Two Color Map Theorem was subsequently
established to enlarge the supported attitude for the tiltrotor. These theories
were employed in the tiltrotor tracking problem with different references.
Notable improvements in the control signals were witnessed in the tiltrotor
simulator. Finally, we explored the control theory, the stability proof of the
novel mobile robot (tilt vehicle) stabilized by Feedback Linearization with
saturation. Instead of adopting the tiltrotor model, which is over-complicated,
we designed a conceptual mobile robot (tilt-car) to analyze the stability
proof. The stability proof (stable in the sense of Lyapunov) was found for a
mobile robot (tilt vehicle) controlled by Feedback Linearization with
saturation for the first time. The success tracking result with the promising
control signals in the tiltrotor simulator demonstrates the advances of our
control method. Also, the Lyapunov candidate and the tracking result in the
mobile robot (tilt-car) simulator confirm our deductions of the stability
proof. These results reveal that these three challenges in Feedback
Linearization are solved, to some extents.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06726" title="Abstract">arXiv:2311.06726</a> [<a href="/pdf/2311.06726" title="Download PDF">pdf</a>, <a href="/format/2311.06726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Distributed Complexity of Locally Checkable Labeling Problems Beyond  Paths and Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Yi-Jun Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We consider locally checkable labeling LCL problems in the LOCAL model of
distributed computing. Since 2016, there has been a substantial body of work
examining the possible complexities of LCL problems. For example, it has been
established that there are no LCL problems exhibiting deterministic
complexities falling between $\omega(\log^* n)$ and $o(\log n)$. This line of
inquiry has yielded a wealth of algorithmic techniques and insights that are
useful for algorithm designers.
<br />While the complexity landscape of LCL problems on general graphs, trees, and
paths is now well understood, graph classes beyond these three cases remain
largely unexplored. Indeed, recent research trends have shifted towards a
fine-grained study of special instances within the domains of paths and trees.
<br />In this paper, we generalize the line of research on characterizing the
complexity landscape of LCL problems to a much broader range of graph classes.
We propose a conjecture that characterizes the complexity landscape of LCL
problems for an arbitrary class of graphs that is closed under minors, and we
prove a part of the conjecture.
<br />Some highlights of our findings are as follows.
<br />1. We establish a simple characterization of the minor-closed graph classes
sharing the same deterministic complexity landscape as paths, where $O(1)$,
$\Theta(\log^* n)$, and $\Theta(n)$ are the only possible complexity classes.
<br />2. It is natural to conjecture that any minor-closed graph class shares the
same complexity landscape as trees if and only if the graph class has bounded
treewidth and unbounded pathwidth. We prove the "only if" part of the
conjecture.
<br />3. In addition to the well-known complexity landscapes for paths, trees, and
general graphs, there are infinitely many different complexity landscapes among
minor-closed graph classes.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06728" title="Abstract">arXiv:2311.06728</a> [<a href="/pdf/2311.06728" title="Download PDF">pdf</a>, <a href="/format/2311.06728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Survey on Database Management System Fuzzing:  Techniques, Taxonomy and Experimental Comparison
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiyue Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhuang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Jiangtao Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hui Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+K">Kewei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+K">Kankan Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 22 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Database Management System (DBMS) fuzzing is an automated testing technique
aimed at detecting errors and vulnerabilities in DBMSs by generating, mutating,
and executing test cases. It not only reduces the time and cost of manual
testing but also enhances detection coverage, providing valuable assistance in
developing commercial DBMSs. Existing fuzzing surveys mainly focus on
general-purpose software. However, DBMSs are different from them in terms of
internal structure, input/output, and test objectives, requiring specialized
fuzzing strategies. Therefore, this paper focuses on DBMS fuzzing and provides
a comprehensive review and comparison of the methods in this field. We first
introduce the fundamental concepts. Then, we systematically define a general
fuzzing procedure and decompose and categorize existing methods. Furthermore,
we classify existing methods from the testing objective perspective, covering
various components in DBMSs. For representative works, more detailed
descriptions are provided to analyze their strengths and limitations. To
objectively evaluate the performance of each method, we present an open-source
DBMS fuzzing toolkit, OpenDBFuzz. Based on this toolkit, we conduct a detailed
experimental comparative analysis of existing methods and finally discuss
future research directions.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06729" title="Abstract">arXiv:2311.06729</a> [<a href="/pdf/2311.06729" title="Download PDF">pdf</a>, <a href="/format/2311.06729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comprehending Lexical and Affective Ontologies in the Demographically  Diverse Spatial Social Media Discourse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sazzed%2C+S">Salim Sazzed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in 22nd IEEE International Conference on Machine Learning and Applications (ICMLA), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This study aims to comprehend linguistic and socio-demographic features,
encompassing English language styles, conveyed sentiments, and lexical
diversity within spatial online social media review data. To this end, we
undertake a case study that scrutinizes reviews composed by two distinct and
demographically diverse groups. Our analysis entails the extraction and
examination of various statistical, grammatical, and sentimental features from
these two groups. Subsequently, we leverage these features with machine
learning (ML) classifiers to discern their potential in effectively
differentiating between the groups. Our investigation unveils substantial
disparities in certain linguistic attributes between the two groups. When
integrated into ML classifiers, these attributes exhibit a marked efficacy in
distinguishing the groups, yielding a macro F1 score of approximately 0.85.
Furthermore, we conduct a comparative evaluation of these linguistic features
with word n-gram-based lexical features in discerning demographically diverse
review data. As expected, the n-gram lexical features, coupled with fine-tuned
transformer-based models, show superior performance, attaining accuracies
surpassing 95\% and macro F1 scores exceeding 0.96. Our meticulous analysis and
comprehensive evaluations substantiate the efficacy of linguistic and
sentimental features in effectively discerning demographically diverse review
data. The findings of this study provide valuable guidelines for future
research endeavors concerning the analysis of demographic patterns in textual
content across various social media platforms.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06730" title="Abstract">arXiv:2311.06730</a> [<a href="/pdf/2311.06730" title="Download PDF">pdf</a>, <a href="/ps/2311.06730" title="Download PostScript">ps</a>, <a href="/format/2311.06730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stability analysis for large-scale multi-agent molecular communication  systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kotsuka%2C+T">Taishi Kotsuka</a>, 
<a href="/search/eess?searchtype=author&query=Hori%2C+Y">Yutaka Hori</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Information Theory (cs.IT); Molecular Networks (q-bio.MN)

</div>
<p class="mathjax">Molecular communication (MC) is recently featured as a novel communication
tool to connect individual biological nanorobots in vivo. It is expected that a
large number of nanorobots can form large multi-agent MC systems through MC to
accomplish complex and large-scale tasks that cannot be achieved by a single
nanorobot. However, most previous models for MC systems assume a unidirectional
diffusion communication channel and cannot capture the feedback between each
nanorobot, which is important for multi-agent MC systems. In this paper, we
introduce the system theoretic model for large-scale multi-agent MC systems
using transfer functions, and then propose a method to analyze the stability
for multi-agent MC systems. The proposed method decomposes the multi-agent MC
system into multiple single-input and single-output (SISO) systems, which
facilitates to analyze the stability of the large-scale multi-agent MC system.
Finally, we demonstrate the proposed method by analyzing the stability of a
specific large-scale multi-agent MC system.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06731" title="Abstract">arXiv:2311.06731</a> [<a href="/pdf/2311.06731" title="Download PDF">pdf</a>, <a href="/format/2311.06731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An advantage based policy transfer algorithm for reinforcement learning  with metrics of transferability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alam%2C+M+F">Md Ferdous Alam</a>, 
<a href="/search/cs?searchtype=author&query=Naghizadeh%2C+P">Parinaz Naghizadeh</a>, 
<a href="/search/cs?searchtype=author&query=Hoelzle%2C+D">David Hoelzle</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Reinforcement learning (RL) can enable sequential decision-making in complex
and high-dimensional environments if the acquisition of a new state-action pair
is efficient, i.e., when interaction with the environment is inexpensive.
However, there are a myriad of real-world applications in which a high number
of interactions are infeasible. In these environments, transfer RL algorithms,
which can be used for the transfer of knowledge from one or multiple source
environments to a target environment, have been shown to increase learning
speed and improve initial and asymptotic performance. However, most existing
transfer RL algorithms are on-policy and sample inefficient, and often require
heuristic choices in algorithm design. This paper proposes an off-policy
Advantage-based Policy Transfer algorithm, APT-RL, for fixed domain
environments. Its novelty is in using the popular notion of ``advantage'' as a
regularizer, to weigh the knowledge that should be transferred from the source,
relative to new knowledge learned in the target, removing the need for
heuristic choices. Further, we propose a new transfer performance metric to
evaluate the performance of our algorithm and unify existing transfer RL
frameworks. Finally, we present a scalable, theoretically-backed task
similarity measurement algorithm to illustrate the alignments between our
proposed transferability metric and similarities between source and target
environments. Numerical experiments on three continuous control benchmark tasks
demonstrate that APT-RL outperforms existing transfer RL algorithms on most
tasks, and is $10\%$ to $75\%$ more sample efficient than learning from
scratch.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06735" title="Abstract">arXiv:2311.06735</a> [<a href="/pdf/2311.06735" title="Download PDF">pdf</a>, <a href="/ps/2311.06735" title="Download PostScript">ps</a>, <a href="/format/2311.06735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepQC: A Deep Learning System for Automatic Quality Control of In-situ  Soil Moisture Sensor Time Series Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bandaru%2C+L">Lahari Bandaru</a>, 
<a href="/search/cs?searchtype=author&query=Irigireddy%2C+B+C">Bharat C Irigireddy</a>, 
<a href="/search/cs?searchtype=author&query=Davis%2C+B">Brian Davis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Amidst changing climate, real-time soil moisture monitoring is vital for the
development of in-season decision support tools to help farmers manage weather
related risks. Precision Sustainable Agriculture (PSA) recently established a
real-time soil moisture monitoring network across the central, Midwest, and
eastern U.S., but field-scale sensor observations often come with data gaps and
anomalies. To maintain the data quality needed for development of decision
tools, a quality control system is necessary. The International Soil Moisture
Network (ISMN) introduced the Flagit module for anomaly detection in soil
moisture observations. However, under certain conditions, Flagit's quality
control approaches may underperform in identifying anomalies. Recently deep
learning methods have been successfully applied to detect anomalies in time
series data in various disciplines. However, their use in agriculture has not
been yet investigated. This study focuses on developing a Bi-directional Long
Short-Term Memory (LSTM) model, referred to as DeepQC, to identify anomalies in
soil moisture data. Manual flagged PSA observations were used for training,
validation, and testing the model, following an 80:10:10 split. The study then
compared the DeepQC and Flagit based estimates to assess their relative
performance. Flagit corrected flagged 95.5% of the corrected observations and
50.3% of the anomaly observations, indicating its limitations in identifying
anomalies. On the other hand, the DeepQC correctly flagged 99.7% of the correct
observations and 95.6% of the anomalies in significantly less time,
demonstrating its superiority over Flagit approach. Importantly, DeepQC's
performance remained consistent regardless of the number of anomalies. Given
the promising results obtained with the DeepQC, future studies will focus on
implementing this model on national and global soil moisture networks.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06736" title="Abstract">arXiv:2311.06736</a> [<a href="/pdf/2311.06736" title="Download PDF">pdf</a>, <a href="/format/2311.06736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are LLMs Rigorous Logical Reasoner? Empowering Natural Language Proof  Generation with Contrastive Stepwise Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Ying Su</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xiaojin Fu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mingwen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhijiang Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Logical reasoning remains a pivotal component within the realm of artificial
intelligence. The recent evolution of large language models (LLMs) has marked
significant progress in this domain. The adoption of strategies like
chain-of-thought (CoT) has enhanced the performance of LLMs across diverse
reasoning tasks. Nonetheless, logical reasoning that involves proof planning,
specifically those that necessitate the validation of explanation accuracy,
continues to present stumbling blocks. In this study, we first evaluate the
efficacy of LLMs with advanced CoT strategies concerning such tasks. Our
analysis reveals that LLMs still struggle to navigate complex reasoning chains,
which demand the meticulous linkage of premises to derive a cogent conclusion.
To address this issue, we finetune a smaller-scale language model, equipping it
to decompose proof objectives into more manageable subgoals. We also introduce
contrastive decoding to stepwise proof generation, making use of negative
reasoning paths to strengthen the model's capacity for logical deduction.
Experiments on EntailmentBank underscore the success of our method in
augmenting the proof planning abilities of language models.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06737" title="Abstract">arXiv:2311.06737</a> [<a href="/pdf/2311.06737" title="Download PDF">pdf</a>, <a href="/format/2311.06737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting and Correcting Hate Speech in Multimodal Memes with Large  Visual Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Van%2C+M">Minh-Hao Van</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xintao Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently, large language models (LLMs) have taken the spotlight in natural
language processing. Further, integrating LLMs with vision enables the users to
explore more emergent abilities in multimodality. Visual language models
(VLMs), such as LLaVA, Flamingo, or GPT-4, have demonstrated impressive
performance on various visio-linguistic tasks. Consequently, there are enormous
applications of large models that could be potentially used on social media
platforms. Despite that, there is a lack of related work on detecting or
correcting hateful memes with VLMs. In this work, we study the ability of VLMs
on hateful meme detection and hateful meme correction tasks with zero-shot
prompting. From our empirical experiments, we show the effectiveness of the
pretrained LLaVA model and discuss its strengths and weaknesses in these tasks.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06738" title="Abstract">arXiv:2311.06738</a> [<a href="/pdf/2311.06738" title="Download PDF">pdf</a>, <a href="/format/2311.06738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Robust Numerical Scheme for Solving Riesz-Tempered Fractional  Reaction-Diffusion Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Partohaghighi%2C+M">Mohammad Partohaghighi</a>, 
<a href="/search/math?searchtype=author&query=Asante-Asamani%2C+E">Emmanuel Asante-Asamani</a>, 
<a href="/search/math?searchtype=author&query=Iyiola%2C+O+S">Olaniyi S. Iyiola</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The Fractional Diffusion Equation (FDE) is a mathematical model that
describes anomalous transport phenomena characterized by non-local and
long-range dependencies which deviate from the traditional behavior of
diffusion. Solving this equation numerically is challenging due to the need to
discretize complicated integral operators which increase the computational
costs. These complexities are exacerbated by nonlinear source terms, nonsmooth
data and irregular domains. In this study, we propose a second order
Exponential Time Differencing Finite Element Method (ETD-RDP-FEM) to
efficiently solve nonlinear FDE, posed in irregular domains. This approach
discretizes matrix exponentials using a rational function with real and
distinct poles, resulting in an L-stable scheme that damps spurious
oscillations caused by non-smooth initial data. The method is shown to
outperform existing second-order methods for FDEs with a higher accuracy and
faster computational time.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06742" title="Abstract">arXiv:2311.06742</a> [<a href="/pdf/2311.06742" title="Download PDF">pdf</a>, <a href="/ps/2311.06742" title="Download PostScript">ps</a>, <a href="/format/2311.06742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta-Reinforcement Learning for Timely and Energy-efficient Data  Collection in Solar-powered UAV-assisted IoT Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+M">Mengjie Yi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xijun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Juan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+R">Ronghui Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Unmanned aerial vehicles (UAVs) have the potential to greatly aid Internet of
Things (IoT) networks in mission-critical data collection, thanks to their
flexibility and cost-effectiveness. However, challenges arise due to the UAV's
limited onboard energy and the unpredictable status updates from sensor nodes
(SNs), which impact the freshness of collected data. In this paper, we
investigate the energy-efficient and timely data collection in IoT networks
through the use of a solar-powered UAV. Each SN generates status updates at
stochastic intervals, while the UAV collects and subsequently transmits these
status updates to a central data center. Furthermore, the UAV harnesses solar
energy from the environment to maintain its energy level above a predetermined
threshold. To minimize both the average age of information (AoI) for SNs and
the energy consumption of the UAV, we jointly optimize the UAV trajectory, SN
scheduling, and offloading strategy. Then, we formulate this problem as a
Markov decision process (MDP) and propose a meta-reinforcement learning
algorithm to enhance the generalization capability. Specifically, the
compound-action deep reinforcement learning (CADRL) algorithm is proposed to
handle the discrete decisions related to SN scheduling and the UAV's offloading
policy, as well as the continuous control of UAV flight. Moreover, we
incorporate meta-learning into CADRL to improve the adaptability of the learned
policy to new tasks. To validate the effectiveness of our proposed algorithms,
we conduct extensive simulations and demonstrate their superiority over other
baseline algorithms.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06746" title="Abstract">arXiv:2311.06746</a> [<a href="/pdf/2311.06746" title="Download PDF">pdf</a>, <a href="/format/2311.06746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two Stream Scene Understanding on Graph Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenkai Yang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wenyuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+R">Runxaing Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The paper presents a novel two-stream network architecture for enhancing
scene understanding in computer vision. This architecture utilizes a graph
feature stream and an image feature stream, aiming to merge the strengths of
both modalities for improved performance in image classification and scene
graph generation tasks. The graph feature stream network comprises a
segmentation structure, scene graph generation, and a graph representation
module. The segmentation structure employs the UPSNet architecture with a
backbone that can be a residual network, Vit, or Swin Transformer. The scene
graph generation component focuses on extracting object labels and neighborhood
relationships from the semantic map to create a scene graph. Graph
Convolutional Networks (GCN), GraphSAGE, and Graph Attention Networks (GAT) are
employed for graph representation, with an emphasis on capturing node features
and their interconnections. The image feature stream network, on the other
hand, focuses on image classification through the use of Vision Transformer and
Swin Transformer models. The two streams are fused using various data fusion
methods. This fusion is designed to leverage the complementary strengths of
graph-based and image-based features.Experiments conducted on the ADE20K
dataset demonstrate the effectiveness of the proposed two-stream network in
improving image classification accuracy compared to conventional methods. This
research provides a significant contribution to the field of computer vision,
particularly in the areas of scene understanding and image classification, by
effectively combining graph-based and image-based approaches.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06749" title="Abstract">arXiv:2311.06749</a> [<a href="/pdf/2311.06749" title="Download PDF">pdf</a>, <a href="/format/2311.06749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aggregate, Decompose, and Fine-Tune: A Simple Yet Effective  Factor-Tuning Method for Vision Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dongping Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advancements have illuminated the efficacy of some
tensorization-decomposition Parameter-Efficient Fine-Tuning methods like LoRA
and FacT in the context of Vision Transformers (ViT). However, these methods
grapple with the challenges of inadequately addressing inner- and cross-layer
redundancy. To tackle this issue, we introduce EFfective Factor-Tuning (EFFT),
a simple yet effective fine-tuning method. Within the VTAB-1K dataset, our EFFT
surpasses all baselines, attaining state-of-the-art performance with a
categorical average of 75.9% in top-1 accuracy with only 0.28% of the
parameters for full fine-tuning. Considering the simplicity and efficacy of
EFFT, it holds the potential to serve as a foundational benchmark. The code and
model are now available at
https://github.com/Dongping-Chen/EFFT-EFfective-Factor-Tuning.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06750" title="Abstract">arXiv:2311.06750</a> [<a href="/pdf/2311.06750" title="Download PDF">pdf</a>, <a href="/format/2311.06750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning for Generalization, Robustness, Fairness: A Survey  and Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wenke Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+M">Mang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zekun Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+G">Guancheng Wan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">He Li</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+B">Bo Du</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qiang Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Federated learning has emerged as a promising paradigm for privacy-preserving
collaboration among different parties. Recently, with the popularity of
federated learning, an influx of approaches have delivered towards different
realistic challenges. In this survey, we provide a systematic overview of the
important and recent developments of research on federated learning. Firstly,
we introduce the study history and terminology definition of this area. Then,
we comprehensively review three basic lines of research: generalization,
robustness, and fairness, by introducing their respective background concepts,
task settings, and main challenges. We also offer a detailed overview of
representative literature on both methods and datasets. We further benchmark
the reviewed methods on several well-known datasets. Finally, we point out
several open issues in this field and suggest opportunities for further
research. We also provide a public website to continuously track developments
in this fast advancing field: https://github.com/WenkeHuang/MarsFL.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06752" title="Abstract">arXiv:2311.06752</a> [<a href="/pdf/2311.06752" title="Download PDF">pdf</a>, <a href="/format/2311.06752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BeautifulPrompt: Towards Automatic Prompt Engineering for Text-to-Image  Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+T">Tingfeng Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bingyan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Ziheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jinhui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jun Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> emnlp 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recently, diffusion-based deep generative models (e.g., Stable Diffusion)
have shown impressive results in text-to-image synthesis. However, current
text-to-image models often require multiple passes of prompt engineering by
humans in order to produce satisfactory results for real-world applications. We
propose BeautifulPrompt, a deep generative model to produce high-quality
prompts from very simple raw descriptions, which enables diffusion-based models
to generate more beautiful images. In our work, we first fine-tuned the
BeautifulPrompt model over low-quality and high-quality collecting prompt
pairs. Then, to ensure that our generated prompts can generate more beautiful
images, we further propose a Reinforcement Learning with Visual AI Feedback
technique to fine-tune our model to maximize the reward values of the generated
prompts, where the reward values are calculated based on the PickScore and the
Aesthetic Scores. Our results demonstrate that learning from visual AI feedback
promises the potential to improve the quality of generated prompts and images
significantly. We further showcase the integration of BeautifulPrompt to a
cloud-native AI platform to provide better text-to-image generation service in
the cloud.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06753" title="Abstract">arXiv:2311.06753</a> [<a href="/pdf/2311.06753" title="Download PDF">pdf</a>, <a href="/format/2311.06753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards General-Purpose Speech Abilities for Large Language Models Using  Unpaired Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fathullah%2C+Y">Yassir Fathullah</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chunyang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lakomkin%2C+E">Egor Lakomkin</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Junteng Jia</a>, 
<a href="/search/cs?searchtype=author&query=Shangguan%2C+Y">Yuan Shangguan</a>, 
<a href="/search/cs?searchtype=author&query=Mahadeokar%2C+J">Jay Mahadeokar</a>, 
<a href="/search/cs?searchtype=author&query=Kalinli%2C+O">Ozlem Kalinli</a>, 
<a href="/search/cs?searchtype=author&query=Fuegen%2C+C">Christian Fuegen</a>, 
<a href="/search/cs?searchtype=author&query=Seltzer%2C+M">Mike Seltzer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this work, we extend the instruction-tuned Llama-2 model with end-to-end
general-purpose speech processing and reasoning abilities while maintaining the
wide range of LLM capabilities, without using any carefully curated paired
data. The proposed model can utilize audio prompts as a replacement for text
and sustain a conversation. Such a model also has extended cross-modal
capabilities such as being able to perform speech question answering, speech
translation, and audio summarization amongst many other closed and open-domain
tasks. This is unlike prior approaches in speech, in which LLMs are extended to
handle audio for a limited number of pre-designated tasks. Experiments show
that our end-to-end approach is on par with or outperforms a cascaded system
(speech recognizer + LLM) in terms of modeling the response to a prompt.
Furthermore, unlike a cascade, our approach shows the ability to interchange
text and audio modalities and utilize the prior context in a conversation to
provide better results.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06754" title="Abstract">arXiv:2311.06754</a> [<a href="/pdf/2311.06754" title="Download PDF">pdf</a>, <a href="/format/2311.06754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Complex to Simple: Unraveling the Cognitive Tree for Reasoning with  Small Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junbing Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Taolin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiaofeng He</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> emnlp 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Reasoning is a distinctive human capacity, enabling us to address complex
problems by breaking them down into a series of manageable cognitive steps.
Yet, complex logical reasoning is still cumbersome for language models. Based
on the dual process theory in cognitive science, we are the first to unravel
the cognitive reasoning abilities of language models. Our framework employs an
iterative methodology to construct a Cognitive Tree (CogTree). The root node of
this tree represents the initial query, while the leaf nodes consist of
straightforward questions that can be answered directly. This construction
involves two main components: the implicit extraction module (referred to as
the intuitive system) and the explicit reasoning module (referred to as the
reflective system). The intuitive system rapidly generates multiple responses
by utilizing in-context examples, while the reflective system scores these
responses using comparative learning. The scores guide the intuitive system in
its subsequent generation step. Our experimental results on two popular and
challenging reasoning tasks indicate that it is possible to achieve a
performance level comparable to that of GPT-3.5 (with 175B parameters), using a
significantly smaller language model that contains fewer parameters (&lt;=7B) than
5% of GPT-3.5.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06756" title="Abstract">arXiv:2311.06756</a> [<a href="/pdf/2311.06756" title="Download PDF">pdf</a>, <a href="/format/2311.06756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personalized Federated Learning via ADMM with Moreau Envelope
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Shengkun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+J">Jinshan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Z">Zhiyong Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Personalized federated learning (PFL) is an approach proposed to address the
issue of poor convergence on heterogeneous data. However, most existing PFL
frameworks require strong assumptions for convergence. In this paper, we
propose an alternating direction method of multipliers (ADMM) for training PFL
models with Moreau envelope (FLAME), which achieves a sublinear convergence
rate, relying on the relatively weak assumption of gradient Lipschitz
continuity. Moreover, due to the gradient-free nature of ADMM, FLAME alleviates
the need for hyperparameter tuning, particularly in avoiding the adjustment of
the learning rate when training the global model. In addition, we propose a
biased client selection strategy to expedite the convergence of training of PFL
models. Our theoretical analysis establishes the global convergence under both
unbiased and biased client selection strategies. Our experiments validate that
FLAME, when trained on heterogeneous data, outperforms state-of-the-art methods
in terms of model performance. Regarding communication efficiency, it exhibits
an average speedup of 3.75x compared to the baselines. Furthermore,
experimental results validate that the biased client selection strategy speeds
up the convergence of both personalized and global models.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06758" title="Abstract">arXiv:2311.06758</a> [<a href="/pdf/2311.06758" title="Download PDF">pdf</a>, <a href="/format/2311.06758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sharing, Teaching and Aligning: Knowledgeable Transfer Learning for  Cross-Lingual Machine Reading Comprehension
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+T">Tingfeng Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Chuanqi Tan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jinhui Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> emnlp 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In cross-lingual language understanding, machine translation is often
utilized to enhance the transferability of models across languages, either by
translating the training data from the source language to the target, or from
the target to the source to aid inference. However, in cross-lingual machine
reading comprehension (MRC), it is difficult to perform a deep level of
assistance to enhance cross-lingual transfer because of the variation of answer
span positions in different languages. In this paper, we propose X-STA, a new
approach for cross-lingual MRC. Specifically, we leverage an attentive teacher
to subtly transfer the answer spans of the source language to the answer output
space of the target. A Gradient-Disentangled Knowledge Sharing technique is
proposed as an improved cross-attention block. In addition, we force the model
to learn semantic alignments from multiple granularities and calibrate the
model outputs with teacher guidance to enhance cross-lingual transferability.
Experiments on three multi-lingual MRC datasets show the effectiveness of our
method, outperforming state-of-the-art approaches.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06761" title="Abstract">arXiv:2311.06761</a> [<a href="/pdf/2311.06761" title="Download PDF">pdf</a>, <a href="/format/2311.06761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Knowledge-Enhanced Contextual Language Representations for  Domain Natural Language Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ruyao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Taolin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Z">Zhongjie Duan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Cen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+M">Minghui Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+D">Dawei Cheng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiaofeng He</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+W">Weining Qian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> emnlp 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Knowledge-Enhanced Pre-trained Language Models (KEPLMs) improve the
performance of various downstream NLP tasks by injecting knowledge facts from
large-scale Knowledge Graphs (KGs). However, existing methods for pre-training
KEPLMs with relational triples are difficult to be adapted to close domains due
to the lack of sufficient domain graph semantics. In this paper, we propose a
Knowledge-enhanced lANGuAge Representation learning framework for various
clOsed dOmains (KANGAROO) via capturing the implicit graph structure among the
entities. Specifically, since the entity coverage rates of closed-domain KGs
can be relatively low and may exhibit the global sparsity phenomenon for
knowledge injection, we consider not only the shallow relational
representations of triples but also the hyperbolic embeddings of deep
hierarchical entity-class structures for effective knowledge fusion.Moreover,
as two closed-domain entities under the same entity-class often have locally
dense neighbor subgraphs counted by max point biconnected component, we further
propose a data augmentation strategy based on contrastive learning over
subgraphs to construct hard negative samples of higher quality. It makes the
underlying KELPMs better distinguish the semantics of these neighboring
entities to further complement the global semantic sparsity. In the
experiments, we evaluate KANGAROO over various knowledge-aware and general NLP
tasks in both full and few-shot learning settings, outperforming various KEPLM
training paradigms performance in closed-domains significantly.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06766" title="Abstract">arXiv:2311.06766</a> [<a href="/pdf/2311.06766" title="Download PDF">pdf</a>, <a href="/ps/2311.06766" title="Download PostScript">ps</a>, <a href="/format/2311.06766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Control Performance through ESN-Based Model Compensation in  MPC for Dynamic Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Niu%2C+S">Shuai Niu</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+Q">Qing Sun</a>, 
<a href="/search/eess?searchtype=author&query=Fei%2C+M">Minrui Fei</a>, 
<a href="/search/eess?searchtype=author&query=Ju%2C+X">Xuqian Ju</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages,3 figures,conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Deriving precise system dynamic models through traditional numerical methods
is often a challenging endeavor. The performance of Model Predictive Control is
heavily contingent on the accuracy of the system dynamic model. Consequently,
this study employs Echo State Networks to acquire knowledge of the unmodeled
dynamic characteristics inherent in the system. This information is then
integrated with the nominal model, functioning as a form of model compensation.
The present paper introduces a control framework that combines ESN with MPC. By
perpetually assimilating the disparities between the nominal and real models,
control performance experiences augmentation. In a demonstrative example, a
second order dynamic system is subjected to simulation. The outcomes
conclusively evince that ESNbased MPC adeptly assimilates unmodeled dynamic
attributes, thereby elevating the system control proficiency.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06769" title="Abstract">arXiv:2311.06769</a> [<a href="/pdf/2311.06769" title="Download PDF">pdf</a>, <a href="/format/2311.06769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Predictive Safety Filter via Decomposition of Robust Invariant  Set
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zeyang Li</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+C">Chuxiong Hu</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+W">Weiye Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+C">Changliu Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Ensuring safety of nonlinear systems under model uncertainty and external
disturbances is crucial, especially for real-world control tasks. Predictive
methods such as robust model predictive control (RMPC) require solving
nonconvex optimization problems online, which leads to high computational
burden and poor scalability. Reinforcement learning (RL) works well with
complex systems, but pays the price of losing rigorous safety guarantee. This
paper presents a theoretical framework that bridges the advantages of both RMPC
and RL to synthesize safety filters for nonlinear systems with state- and
action-dependent uncertainty. We decompose the robust invariant set (RIS) into
two parts: a target set that aligns with terminal region design of RMPC, and a
reach-avoid set that accounts for the rest of RIS. We propose a policy
iteration approach for robust reach-avoid problems and establish its monotone
convergence. This method sets the stage for an adversarial actor-critic deep RL
algorithm, which simultaneously synthesizes a reach-avoid policy network, a
disturbance policy network, and a reach-avoid value network. The learned
reach-avoid policy network is utilized to generate nominal trajectories for
online verification, which filters potentially unsafe actions that may drive
the system into unsafe regions when worst-case disturbances are applied. We
formulate a second-order cone programming (SOCP) approach for online
verification using system level synthesis, which optimizes for the worst-case
reach-avoid value of any possible trajectories. The proposed safety filter
requires much lower computational complexity than RMPC and still enjoys
persistent robust safety guarantee. The effectiveness of our method is
illustrated through a numerical example.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06770" title="Abstract">arXiv:2311.06770</a> [<a href="/pdf/2311.06770" title="Download PDF">pdf</a>, <a href="/format/2311.06770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compressive Sensing-Based Grant-Free Massive Access for 6G Massive  Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhen Gao</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+M">Malong Ke</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+Y">Yikun Mei</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+L">Li Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+D+W+K">Derrick Wing Kwan Ng</a>, 
<a href="/search/cs?searchtype=author&query=Poor%2C+H+V">H. Vincent Poor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE IoT Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The advent of the sixth-generation (6G) of wireless communications has given
rise to the necessity to connect vast quantities of heterogeneous wireless
devices, which requires advanced system capabilities far beyond existing
network architectures. In particular, such massive communication has been
recognized as a prime driver that can empower the 6G vision of future
ubiquitous connectivity, supporting Internet of Human-Machine-Things for which
massive access is critical. This paper surveys the most recent advances toward
massive access in both academic and industry communities, focusing primarily on
the promising compressive sensing-based grant-free massive access paradigm. We
first specify the limitations of existing random access schemes and reveal that
the practical implementation of massive communication relies on a dramatically
different random access paradigm from the current ones mainly designed for
human-centric communications. Then, a compressive sensing-based grant-free
massive access roadmap is presented, where the evolutions from single-antenna
to large-scale antenna array-based base stations, from single-station to
cooperative massive multiple-input multiple-output systems, and from unsourced
to sourced random access scenarios are detailed. Finally, we discuss the key
challenges and open issues to shed light on the potential future research
directions of grant-free massive access.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06771" title="Abstract">arXiv:2311.06771</a> [<a href="/pdf/2311.06771" title="Download PDF">pdf</a>, <a href="/format/2311.06771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Globally Optimized Language Structure via Adversarial Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xuwang Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent work has explored integrating autoregressive language models with
energy-based models (EBMs) to enhance text generation capabilities. However,
learning effective EBMs for text is challenged by the discrete nature of
language. This work proposes an adversarial training strategy to address
limitations in prior efforts. Specifically, an iterative adversarial attack
algorithm is presented to generate negative samples for training the EBM by
perturbing text from the autoregressive model. This aims to enable the EBM to
suppress spurious modes outside the support of the data distribution.
Experiments on an arithmetic sequence generation task demonstrate that the
proposed adversarial training approach can substantially enhance the quality of
generated sequences compared to prior methods. The results highlight the
promise of adversarial techniques to improve discrete EBM training. Key
contributions include: (1) an adversarial attack strategy tailored to text to
generate negative samples, circumventing MCMC limitations; (2) an adversarial
training algorithm for EBMs leveraging these attacks; (3) empirical validation
of performance improvements on a sequence generation task.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06772" title="Abstract">arXiv:2311.06772</a> [<a href="/pdf/2311.06772" title="Download PDF">pdf</a>, <a href="/format/2311.06772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatAnything: Facetime Chat with LLM-Enhanced Personas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yilin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xinbin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shanghua Gao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhijie Lin</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Q">Qibin Hou</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiashi Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Daquan Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this technical report, we target generating anthropomorphized personas for
LLM-based characters in an online manner, including visual appearance,
personality and tones, with only text descriptions. To achieve this, we first
leverage the in-context learning capability of LLMs for personality generation
by carefully designing a set of system prompts. We then propose two novel
concepts: the mixture of voices (MoV) and the mixture of diffusers (MoD) for
diverse voice and appearance generation. For MoV, we utilize the text-to-speech
(TTS) algorithms with a variety of pre-defined tones and select the most
matching one based on the user-provided text description automatically. For
MoD, we combine the recent popular text-to-image generation techniques and
talking head algorithms to streamline the process of generating talking
objects. We termed the whole framework as ChatAnything. With it, users could be
able to animate anything with any personas that are anthropomorphic using just
a few text inputs. However, we have observed that the anthropomorphic objects
produced by current generative models are often undetectable by pre-trained
face landmark detectors, leading to failure of the face motion generation, even
if these faces possess human-like appearances because those images are nearly
seen during the training (e.g., OOD samples). To address this issue, we
incorporate pixel-level guidance to infuse human face landmarks during the
image generation phase. To benchmark these metrics, we have built an evaluation
dataset. Based on it, we verify that the detection rate of the face landmark is
significantly increased from 57.0% to 92.5% thus allowing automatic face
animation based on generated speech content. The code and more results can be
found at https://chatanything.github.io/.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06774" title="Abstract">arXiv:2311.06774</a> [<a href="/pdf/2311.06774" title="Download PDF">pdf</a>, <a href="/ps/2311.06774" title="Download PostScript">ps</a>, <a href="/format/2311.06774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Challenges in Controllers on UAV Aircraft: Theory and Practice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Oersted%2C+H">Hans Oersted</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+Y">Yudong Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This review explores the theoretical foundations and experimental dynamics of
modern tiltrotor aircraft. Emphasizing feedback linearization, the study delves
into the distinctive constraints and angular velocity ranges shaping tiltrotor
behavior. Experimental findings highlight challenges in tracking circular
trajectories, with color-coded representations illustrating the impact of
angular velocity. Practical implications for applications like unmanned aerial
vehicles are discussed, alongside identified challenges and avenues for future
research. This work contributes to both theoretical understanding and practical
considerations in the evolving field of tiltrotor control.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06777" title="Abstract">arXiv:2311.06777</a> [<a href="/pdf/2311.06777" title="Download PDF">pdf</a>, <a href="/format/2311.06777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Alleviating Behavior Data Imbalance for Multi-Behavior Graph  Collaborative Filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yijie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bei%2C+Y">Yuanchen Bei</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shiqi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiqing Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lijia Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Feiran Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by ICDM2023 Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Graph collaborative filtering, which learns user and item representations
through message propagation over the user-item interaction graph, has been
shown to effectively enhance recommendation performance. However, most current
graph collaborative filtering models mainly construct the interaction graph on
a single behavior domain (e.g. click), even though users exhibit various types
of behaviors on real-world platforms, including actions like click, cart, and
purchase. Furthermore, due to variations in user engagement, there exists an
imbalance in the scale of different types of behaviors. For instance, users may
click and view multiple items but only make selective purchases from a small
subset of them. How to alleviate the behavior imbalance problem and utilize
information from the multiple behavior graphs concurrently to improve the
target behavior conversion (e.g. purchase) remains underexplored. To this end,
we propose IMGCF, a simple but effective model to alleviate behavior data
imbalance for multi-behavior graph collaborative filtering. Specifically, IMGCF
utilizes a multi-task learning framework for collaborative filtering on
multi-behavior graphs. Then, to mitigate the data imbalance issue, IMGCF
improves representation learning on the sparse behavior by leveraging
representations learned from the behavior domain with abundant data volumes.
Experiments on two widely-used multi-behavior datasets demonstrate the
effectiveness of IMGCF.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06783" title="Abstract">arXiv:2311.06783</a> [<a href="/pdf/2311.06783" title="Download PDF">pdf</a>, <a href="/format/2311.06783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Q-Instruct: Improving Low-level Visual Abilities for Multi-modality  Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haoning Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zicheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+E">Erli Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chaofeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+L">Liang Liao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Annan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kaixin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chunyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Jingwen Hou</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+G">Guangtao Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+G">Geng Xue</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wenxiu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Q">Qiong Yan</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Weisi Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 11 figures, page 12-16 as appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Multi-modality foundation models, as represented by GPT-4V, have brought a
new paradigm for low-level visual perception and understanding tasks, that can
respond to a broad range of natural human instructions in a model. While
existing foundation models have shown exciting potentials on low-level visual
tasks, their related abilities are still preliminary and need to be improved.
In order to enhance these models, we conduct a large-scale subjective
experiment collecting a vast number of real human feedbacks on low-level
vision. Each feedback follows a pathway that starts with a detailed description
on the low-level visual appearance (*e.g. clarity, color, brightness* of an
image, and ends with an overall conclusion, with an average length of 45 words.
The constructed **Q-Pathway** dataset includes 58K detailed human feedbacks on
18,973 images with diverse low-level appearance. Moreover, to enable foundation
models to robustly respond to diverse types of questions, we design a
GPT-participated conversion to process these feedbacks into diverse-format 200K
instruction-response pairs. Experimental results indicate that the
**Q-Instruct** consistently elevates low-level perception and understanding
abilities across several foundational models. We anticipate that our datasets
can pave the way for a future that general intelligence can perceive,
understand low-level visual appearance and evaluate visual quality like a
human. Our dataset, model zoo, and demo is published at:
https://q-future.github.io/Q-Instruct.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06784" title="Abstract">arXiv:2311.06784</a> [<a href="/pdf/2311.06784" title="Download PDF">pdf</a>, <a href="/ps/2311.06784" title="Download PostScript">ps</a>, <a href="/format/2311.06784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometric and Feedback Linearization on UAV: Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oersted%2C+H">Hans Oersted</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yudong Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The pervasive integration of Unmanned Aerial Vehicles (UAVs) across
multifarious domains necessitates a nuanced understanding of control
methodologies to ensure their optimal functionality. This exhaustive review
meticulously examines two pivotal control paradigms in the UAV landscape,
Geometric Control and Feedback Linearization. Delving into the intricate
theoretical underpinnings, practical applications, strengths, and challenges of
these methodologies, the paper endeavors to provide a comprehensive overview.
Geometric Control, grounded in the principles of differential geometry, offers
an elegant and intuitive approach to trajectory tracking and mission execution.
In contrast, Feedback Linearization employs nonlinear control techniques to
linearize UAV dynamics, paving the way for enhanced controllability. This
review not only dissects the theoretical foundations but also scrutinizes
real-world applications, integration challenges, and the ongoing research
trajectory of Geometric Control and Feedback Linearization in the realm of
UAVs.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06785" title="Abstract">arXiv:2311.06785</a> [<a href="/pdf/2311.06785" title="Download PDF">pdf</a>, <a href="/ps/2311.06785" title="Download PostScript">ps</a>, <a href="/format/2311.06785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Depth and Breadth of Research Area Coverage and Its Impact on  Publication Citation: An Analysis of Bibliometric Papers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhuoran Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongjun Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">Many other factors affecting citation of publications, except for research
area coverage, have been studied. This study aims to investigate impact of
research area coverage. Bibliometric papers and their related papers (referred
papers, citing papers and first author's papers) were screened and matched by
Python program. Papers' research areas were classified according to Web of
Science. Bibliometric parameters of the most cited 5% and the least cited 5%
papers were compared. Firstly, coverage of related papers' research areas
impacts the citation of their original papers. The impact of references and
citing papers are positive and negative, separately, while the first author's
papers have no influence. Secondly, high-influence papers tend to cite
references from a wider area and are cited by followers from a wider area.
Additionally, the pattern of knowledge flow differs significantly between high-
and low-influence papers. Low-influence papers narrow knowledge flow, whereas
high-influence papers broaden it. This study has shown that both depth and
breadth of research area coverage can influence citations. It is recommended
that authors should extensively cite high-influence publications, both within
and beyond their own area.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06786" title="Abstract">arXiv:2311.06786</a> [<a href="/pdf/2311.06786" title="Download PDF">pdf</a>, <a href="/format/2311.06786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainability of Vision Transformers: A Comprehensive Review and New  Perspectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kashefi%2C+R">Rojina Kashefi</a>, 
<a href="/search/cs?searchtype=author&query=Barekatain%2C+L">Leili Barekatain</a>, 
<a href="/search/cs?searchtype=author&query=Sabokrou%2C+M">Mohammad Sabokrou</a>, 
<a href="/search/cs?searchtype=author&query=Aghaeipoor%2C+F">Fatemeh Aghaeipoor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages,5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Transformers have had a significant impact on natural language processing and
have recently demonstrated their potential in computer vision. They have shown
promising results over convolution neural networks in fundamental computer
vision tasks. However, the scientific community has not fully grasped the inner
workings of vision transformers, nor the basis for their decision-making, which
underscores the importance of explainability methods. Understanding how these
models arrive at their decisions not only improves their performance but also
builds trust in AI systems. This study explores different explainability
methods proposed for visual transformers and presents a taxonomy for organizing
them according to their motivations, structures, and application scenarios. In
addition, it provides a comprehensive review of evaluation criteria that can be
used for comparing explanation results, as well as explainability tools and
frameworks. Finally, the paper highlights essential but unexplored aspects that
can enhance the explainability of visual transformers, and promising research
directions are suggested for future investment.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06787" title="Abstract">arXiv:2311.06787</a> [<a href="/pdf/2311.06787" title="Download PDF">pdf</a>, <a href="/format/2311.06787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Moving Horizon Estimation Using Bayesian Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sun%2C+Q">Qing Sun</a>, 
<a href="/search/eess?searchtype=author&query=Niu%2C+S">Shuai Niu</a>, 
<a href="/search/eess?searchtype=author&query=Fei%2C+M">Minrui Fei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages,3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this work, an innovative data-driven moving horizon state estimation is
proposed for model dynamic-unknown systems based on Bayesian optimization. As
long as the measurement data is received, a locally linear dynamics model can
be obtained from one Bayesian optimization-based offline learning framework.
Herein, the learned model is continuously updated iteratively based on the
actual observed data to approximate the actual system dynamic with the intent
of minimizing the cost function of the moving horizon estimator until the
desired performance is achieved. Meanwhile, the characteristics of Bayesian
optimization can guarantee the closest approximation of the learned model to
the actual system dynamic. Thus, one effective data-driven moving horizon
estimator can be designed further on the basis of this learned model. Finally,
the efficiency of the proposed state estimation algorithm is demonstrated by
several numerical simulations.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06788" title="Abstract">arXiv:2311.06788</a> [<a href="/pdf/2311.06788" title="Download PDF">pdf</a>, <a href="/format/2311.06788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-Time Probabilistic Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hummelgren%2C+L">Lars Hummelgren</a>, 
<a href="/search/cs?searchtype=author&query=Becker%2C+M">Matthias Becker</a>, 
<a href="/search/cs?searchtype=author&query=Broman%2C+D">David Broman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Complex cyber-physical systems interact in real-time and must consider both
timing and uncertainty. Developing software for such systems is both expensive
and difficult, especially when modeling, inference, and real-time behavior need
to be developed from scratch. Recently, a new kind of language has emerged --
called probabilistic programming languages (PPLs) -- that simplify modeling and
inference by separating the concerns between probabilistic modeling and
inference algorithm implementation. However, these languages have primarily
been designed for offline problems, not online real-time systems. In this
paper, we combine PPLs and real-time programming primitives by introducing the
concept of real-time probabilistic programming languages (RTPPL). We develop an
RTPPL called ProbTime and demonstrate its usability on an automotive testbed
performing indoor positioning and braking. Moreover, we study fundamental
properties and design alternatives for runtime behavior, including a new
fairness-guided approach that automatically optimizes the accuracy of a
ProbTime system under schedulability constraints.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06791" title="Abstract">arXiv:2311.06791</a> [<a href="/pdf/2311.06791" title="Download PDF">pdf</a>, <a href="/format/2311.06791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InfMLLM: A Unified Framework for Visual-Language Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qiang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhibin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+W">Wei Chu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yinghui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yuan Qi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large language models (LLMs) have proven their remarkable versatility in
handling a comprehensive range of language-centric applications. To expand
LLMs' capabilities to a broader spectrum of modal inputs, multimodal large
language models (MLLMs) have attracted growing interest. This work delves into
enabling LLMs to tackle more vision-language-related tasks, particularly image
captioning, visual question answering (VQA,) and visual grounding. To this end,
we implemented a three-stage training scheme: starting with lightweight
alignment pretraining, then moderate-weight multitask hybrid training, and
finally, LLM fine-tuning to improve instruction following capability.
Throughout the training process, the requirements on GPU memory gradually
increase. To effectively manage the number of visual embeddings passed to the
LLM while preserving their positional information, we introduce a
straightforward visual adapter module dubbed pool-adapter. Our experiments
demonstrate that preserving the positional information of visual embeddings
through the pool-adapter is particularly beneficial for tasks like visual
grounding. We name our proposed approach InfMLLM and have evaluated it
extensively on various benchmark datasets. Our results demonstrate that InfMLLM
achieves either state-of-the-art (SOTA) performance or performance comparable
to recent MLLMs. The code and model will be made open-source at:
\url{https://github.com/mightyzau/InfMLLM}.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06792" title="Abstract">arXiv:2311.06792</a> [<a href="/pdf/2311.06792" title="Download PDF">pdf</a>, <a href="/format/2311.06792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IMPUS: Image Morphing with Perceptually-Uniform Sampling Using Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhaoyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhengyang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+J">Jaskirat Singh</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Campbell%2C+D">Dylan Campbell</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+P">Peter Tu</a>, 
<a href="/search/cs?searchtype=author&query=Hartley%2C+R">Richard Hartley</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present a diffusion-based image morphing approach with
perceptually-uniform sampling (IMPUS) that produces smooth, direct, and
realistic interpolations given an image pair. A latent diffusion model has
distinct conditional distributions and data embeddings for each of the two
images, especially when they are from different classes. To bridge this gap, we
interpolate in the locally linear and continuous text embedding space and
Gaussian latent space. We first optimize the endpoint text embeddings and then
map the images to the latent space using a probability flow ODE. Unlike
existing work that takes an indirect morphing path, we show that the model
adaptation yields a direct path and suppresses ghosting artifacts in the
interpolated images. To achieve this, we propose an adaptive bottleneck
constraint based on a novel relative perceptual path diversity score that
automatically controls the bottleneck size and balances the diversity along the
path with its directness. We also propose a perceptually-uniform sampling
technique that enables visually smooth changes between the interpolated images.
Extensive experiments validate that our IMPUS can achieve smooth, direct, and
realistic image morphing and be applied to other image generation tasks.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06794" title="Abstract">arXiv:2311.06794</a> [<a href="/pdf/2311.06794" title="Download PDF">pdf</a>, <a href="/format/2311.06794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CL-Flow:Strengthening the Normalizing Flows by Contrastive Learning for  Better Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shunfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yueyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Haichi Luo</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+C">Chenyang Bi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages,6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In the anomaly detection field, the scarcity of anomalous samples has
directed the current research emphasis towards unsupervised anomaly detection.
While these unsupervised anomaly detection methods offer convenience, they also
overlook the crucial prior information embedded within anomalous samples.
Moreover, among numerous deep learning methods, supervised methods generally
exhibit superior performance compared to unsupervised methods. Considering the
reasons mentioned above, we propose a self-supervised anomaly detection
approach that combines contrastive learning with 2D-Flow to achieve more
precise detection outcomes and expedited inference processes. On one hand, we
introduce a novel approach to anomaly synthesis, yielding anomalous samples in
accordance with authentic industrial scenarios, alongside their surrogate
annotations. On the other hand, having obtained a substantial number of
anomalous samples, we enhance the 2D-Flow framework by incorporating
contrastive learning, leveraging diverse proxy tasks to fine-tune the network.
Our approach enables the network to learn more precise mapping relationships
from self-generated labels while retaining the lightweight characteristics of
the 2D-Flow. Compared to mainstream unsupervised approaches, our
self-supervised method demonstrates superior detection accuracy, fewer
additional model parameters, and faster inference speed. Furthermore, the
entire training and inference process is end-to-end. Our approach showcases new
state-of-the-art results, achieving a performance of 99.6\% in image-level
AUROC on the MVTecAD dataset and 96.8\% in image-level AUROC on the BTAD
dataset.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06796" title="Abstract">arXiv:2311.06796</a> [<a href="/pdf/2311.06796" title="Download PDF">pdf</a>, <a href="/format/2311.06796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Perspective Transformation Based Vehicle Localization on Bird&#x27;s Eye  View
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahyar%2C+A">Abtin Mahyar</a>, 
<a href="/search/cs?searchtype=author&query=Motamednia%2C+H">Hossein Motamednia</a>, 
<a href="/search/cs?searchtype=author&query=Rahmati%2C+D">Dara Rahmati</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">An accurate understanding of a self-driving vehicle's surrounding environment
is crucial for its navigation system. To enhance the effectiveness of existing
algorithms and facilitate further research, it is essential to provide
comprehensive data to the routing system. Traditional approaches rely on
installing multiple sensors to simulate the environment, leading to high costs
and complexity. In this paper, we propose an alternative solution by generating
a top-down representation of the scene, enabling the extraction of distances
and directions of other cars relative to the ego vehicle. We introduce a new
synthesized dataset that offers extensive information about the ego vehicle and
its environment in each frame, providing valuable resources for similar
downstream tasks. Additionally, we present an architecture that transforms
perspective view RGB images into bird's-eye-view maps with segmented
surrounding vehicles. This approach offers an efficient and cost-effective
method for capturing crucial environmental information for self-driving cars.
Code and dataset are available at
https://github.com/IPM-HPC/Perspective-BEV-Transformer.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06797" title="Abstract">arXiv:2311.06797</a> [<a href="/pdf/2311.06797" title="Download PDF">pdf</a>, <a href="/format/2311.06797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual-Branch Reconstruction Network for Industrial Anomaly Detection with  RGB-D Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bi%2C+C">Chenyang Bi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yueyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Haichi Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Unsupervised anomaly detection methods are at the forefront of industrial
anomaly detection efforts and have made notable progress. Previous work
primarily used 2D information as input, but multi-modal industrial anomaly
detection based on 3D point clouds and RGB images is just beginning to emerge.
The regular approach involves utilizing large pre-trained models for feature
representation and storing them in memory banks. However, the above methods
require a longer inference time and higher memory usage, which cannot meet the
real-time requirements of the industry. To overcome these issues, we propose a
lightweight dual-branch reconstruction network(DBRN) based on RGB-D input,
learning the decision boundary between normal and abnormal examples. The
requirement for alignment between the two modalities is eliminated by using
depth maps instead of point cloud input. Furthermore, we introduce an
importance scoring module in the discriminative network to assist in fusing
features from these two modalities, thereby obtaining a comprehensive
discriminative result. DBRN achieves 92.8% AUROC with high inference efficiency
on the MVTec 3D-AD dataset without large pre-trained models and memory banks.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06798" title="Abstract">arXiv:2311.06798</a> [<a href="/pdf/2311.06798" title="Download PDF">pdf</a>, <a href="/format/2311.06798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MetaMix: Meta-state Precision Searcher for Mixed-precision Activation  Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Han-Byul Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+H">Joo Hyung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+S">Sungjoo Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hong-Seok Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Mixed-precision quantization of efficient networks often suffer from
activation instability encountered in the exploration of bit selections. To
address this problem, we propose a novel method called MetaMix which consists
of bit selection and weight training phases. The bit selection phase iterates
two steps, (1) the mixed-precision-aware weight update, and (2) the bit-search
training with the fixed mixed-precision-aware weights, both of which combined
reduce activation instability in mixed-precision quantization and contribute to
fast and high-quality bit selection. The weight training phase exploits the
weights and step sizes trained in the bit selection phase and fine-tunes them
thereby offering fast training. Our experiments with efficient and
hard-to-quantize networks, i.e., MobileNet v2 and v3, and ResNet-18 on ImageNet
show that our proposed method pushes the boundary of mixed-precision
quantization, in terms of accuracy vs. operations, by outperforming both mixed-
and single-precision SOTA methods.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06801" title="Abstract">arXiv:2311.06801</a> [<a href="/pdf/2311.06801" title="Download PDF">pdf</a>, <a href="/ps/2311.06801" title="Download PostScript">ps</a>, <a href="/format/2311.06801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Survey On Client Selections in Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gouissem%2C+A">Ala Gouissem</a>, 
<a href="/search/cs?searchtype=author&query=Chkirbene%2C+Z">Zina Chkirbene</a>, 
<a href="/search/cs?searchtype=author&query=Hamila%2C+R">Ridha Hamila</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated Learning (FL) is a rapidly growing field in machine learning that
allows data to be trained across multiple decentralized devices. The selection
of clients to participate in the training process is a critical factor for the
performance of the overall system. In this survey, we provide a comprehensive
overview of the state-of-the-art client selection techniques in FL, including
their strengths and limitations, as well as the challenges and open issues that
need to be addressed. We cover conventional selection techniques such as random
selection where all or partial random of clients is used for the trained. We
also cover performance-aware selections and as well as resource-aware
selections for resource-constrained networks and heterogeneous networks. We
also discuss the usage of client selection in model security enhancement.
Lastly, we discuss open issues and challenges related to clients selection in
dynamic constrained, and heterogeneous networks.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06805" title="Abstract">arXiv:2311.06805</a> [<a href="/pdf/2311.06805" title="Download PDF">pdf</a>, <a href="/format/2311.06805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tunable Soft Prompts are Messengers in Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+C">Chenhe Dong</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yuexiang Xie</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+B">Bolin Ding</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Ying Shen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yaliang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EMNLP-23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Federated learning (FL) enables multiple participants to collaboratively
train machine learning models using decentralized data sources, alleviating
privacy concerns that arise from directly sharing local data. However, the lack
of model privacy protection in FL becomes an unneglectable challenge,
especially when people want to federally finetune models based on a proprietary
large language model. In this study, we propose a novel FL training approach
that accomplishes information exchange among participants via tunable soft
prompts. These soft prompts, updated and transmitted between the server and
clients, assume the role of the global model parameters and serve as messengers
to deliver useful knowledge from the local data and global model. As the global
model itself is not required to be shared and the local training is conducted
based on an auxiliary model with fewer parameters than the global model, the
proposed approach provides protection for the global model while reducing
communication and computation costs in FL. Extensive experiments show the
effectiveness of the proposed approach compared to several baselines. We have
released the source code at
\url{https://github.com/alibaba/FederatedScope/tree/fedsp/federatedscope/nlp/fedsp}.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06807" title="Abstract">arXiv:2311.06807</a> [<a href="/pdf/2311.06807" title="Download PDF">pdf</a>, <a href="/format/2311.06807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Robustness of Question Rewriting Systems to Questions of Varying  Hardness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Hai Ye</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+H+T">Hwee Tou Ng</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+W">Wenjuan Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACL'22, main, long paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In conversational question answering (CQA), the task of question
rewriting~(QR) in context aims to rewrite a context-dependent question into an
equivalent self-contained question that gives the same answer. In this paper,
we are interested in the robustness of a QR system to questions varying in
rewriting hardness or difficulty. Since there is a lack of questions classified
based on their rewriting hardness, we first propose a heuristic method to
automatically classify questions into subsets of varying hardness, by measuring
the discrepancy between a question and its rewrite. To find out what makes
questions hard or easy for rewriting, we then conduct a human evaluation to
annotate the rewriting hardness of questions. Finally, to enhance the
robustness of QR systems to questions of varying hardness, we propose a novel
learning framework for QR that first trains a QR model independently on each
subset of questions of a certain level of hardness, then combines these QR
models as one joint model for inference. Experimental results on two datasets
show that our framework improves the overall performance compared to the
baselines.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06809" title="Abstract">arXiv:2311.06809</a> [<a href="/pdf/2311.06809" title="Download PDF">pdf</a>, <a href="/ps/2311.06809" title="Download PostScript">ps</a>, <a href="/format/2311.06809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Review of PID Controller Applications for UAVs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oersted%2C+H">Hans Oersted</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yudong Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Unmanned Aerial Vehicles (UAVs) have gained widespread recognition for their
diverse applications, ranging from surveillance to delivery services. Among the
various control algorithms employed to stabilize and navigate UAVs, the
Proportional-Integral-Derivative (PID) controller stands out as a classical yet
robust solution. This review provides a comprehensive examination of PID
controller applications in the context of UAVs, addressing their fundamental
principles, dynamics modeling, stability control, navigation tasks, parameter
tuning methods, challenges, and future directions.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06812" title="Abstract">arXiv:2311.06812</a> [<a href="/pdf/2311.06812" title="Download PDF">pdf</a>, <a href="/format/2311.06812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MANSY: Generalizing Neural Adaptive Immersive Video Streaming With  Ensemble and Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Duo Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+P">Panlong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Miao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fangxin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE Transactions on Mobile Computing for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The popularity of immersive videos has prompted extensive research into
neural adaptive tile-based streaming to optimize video transmission over
networks with limited bandwidth. However, the diversity of users' viewing
patterns and Quality of Experience (QoE) preferences has not been fully
addressed yet by existing neural adaptive approaches for viewport prediction
and bitrate selection. Their performance can significantly deteriorate when
users' actual viewing patterns and QoE preferences differ considerably from
those observed during the training phase, resulting in poor generalization. In
this paper, we propose MANSY, a novel streaming system that embraces user
diversity to improve generalization. Specifically, to accommodate users'
diverse viewing patterns, we design a Transformer-based viewport prediction
model with an efficient multi-viewport trajectory input output architecture
based on implicit ensemble learning. Besides, we for the first time combine the
advanced representation learning and deep reinforcement learning to train the
bitrate selection model to maximize diverse QoE objectives, enabling the model
to generalize across users with diverse preferences. Extensive experiments
demonstrate that MANSY outperforms state-of-the-art approaches in viewport
prediction accuracy and QoE improvement on both trained and unseen viewing
patterns and QoE preferences, achieving better generalization.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06813" title="Abstract">arXiv:2311.06813</a> [<a href="/pdf/2311.06813" title="Download PDF">pdf</a>, <a href="/format/2311.06813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Power iteration for matrices with power series entries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ebker%2C+R">Ragon Ebker</a>, 
<a href="/search/math?searchtype=author&query=Muranova%2C+A">Anna Muranova</a>, 
<a href="/search/math?searchtype=author&query=Schmidt%2C+M">Max Schmidt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph); Algebraic Geometry (math.AG); Spectral Theory (math.SP)

</div>
<p class="mathjax">We prove the method of power iteration for matrices with at most finite
entries from the Levi-Civita field $\mathcal C$ under the assumption that there
exists an eigenvalue with the strictly largest in absolute value complex part.
In this case the weak convergence of a start vector to the eigenvector, that
corresponds to the largest eigenvalue, is proven. Further, we prove that the
Rayleigh quotient of the largest eigenvector also converges weakly to the
corresponding eigenvalue. As a corollary, the same holds for matrices and
polynomials over the Puiseux series field. In addition to that, we deliver an
implementation of our method in Python.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06815" title="Abstract">arXiv:2311.06815</a> [<a href="/pdf/2311.06815" title="Download PDF">pdf</a>, <a href="/ps/2311.06815" title="Download PostScript">ps</a>, <a href="/format/2311.06815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of GPT-4 for chest X-ray impression generation: A reader  study on performance and perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ziegelmayer%2C+S">Sebastian Ziegelmayer</a>, 
<a href="/search/cs?searchtype=author&query=Marka%2C+A+W">Alexander W. Marka</a>, 
<a href="/search/cs?searchtype=author&query=Lenhart%2C+N">Nicolas Lenhart</a>, 
<a href="/search/cs?searchtype=author&query=Nehls%2C+N">Nadja Nehls</a>, 
<a href="/search/cs?searchtype=author&query=Reischl%2C+S">Stefan Reischl</a>, 
<a href="/search/cs?searchtype=author&query=Harder%2C+F">Felix Harder</a>, 
<a href="/search/cs?searchtype=author&query=Sauter%2C+A">Andreas Sauter</a>, 
<a href="/search/cs?searchtype=author&query=Makowski%2C+M">Marcus Makowski</a>, 
<a href="/search/cs?searchtype=author&query=Graf%2C+M">Markus Graf</a>, 
<a href="/search/cs?searchtype=author&query=Gawlitza%2C+J">Joshua Gawlitza</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The remarkable generative capabilities of multimodal foundation models are
currently being explored for a variety of applications. Generating radiological
impressions is a challenging task that could significantly reduce the workload
of radiologists. In our study we explored and analyzed the generative abilities
of GPT-4 for Chest X-ray impression generation. To generate and evaluate
impressions of chest X-rays based on different input modalities (image, text,
text and image), a blinded radiological report was written for 25-cases of the
publicly available NIH-dataset. GPT-4 was given image, finding section or both
sequentially to generate an input dependent impression. In a blind randomized
reading, 4-radiologists rated the impressions and were asked to classify the
impression origin (Human, AI), providing justification for their decision.
Lastly text model evaluation metrics and their correlation with the
radiological score (summation of the 4 dimensions) was assessed. According to
the radiological score, the human-written impression was rated highest,
although not significantly different to text-based impressions. The automated
evaluation metrics showed moderate to substantial correlations to the
radiological score for the image impressions, however individual scores were
highly divergent among inputs, indicating insufficient representation of
radiological quality. Detection of AI-generated impressions varied by input and
was 61% for text-based impressions. Impressions classified as AI-generated had
significantly worse radiological scores even when written by a radiologist,
indicating potential bias. Our study revealed significant discrepancies between
a radiological assessment and common automatic evaluation metrics depending on
the model input. The detection of AI-generated findings is subject to bias that
highly rated impressions are perceived as human-written.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06816" title="Abstract">arXiv:2311.06816</a> [<a href="/pdf/2311.06816" title="Download PDF">pdf</a>, <a href="/format/2311.06816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On original and latent space connectivity in deep neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+B">Boyang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Borovykh%2C+A">Anastasia Borovykh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We study whether inputs from the same class can be connected by a continuous
path, in original or latent representation space, such that all points on the
path are mapped by the neural network model to the same class. Understanding
how the neural network views its own input space and how the latent spaces are
structured has value for explainability and robustness. We show that paths,
linear or nonlinear, connecting same-class inputs exist in all cases studied.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06818" title="Abstract">arXiv:2311.06818</a> [<a href="/pdf/2311.06818" title="Download PDF">pdf</a>, <a href="/format/2311.06818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cricket Player Profiling: Unraveling Strengths and Weaknesses Using Text  Commentary Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Behera%2C+S+R">Swarup Ranjan Behera</a>, 
<a href="/search/cs?searchtype=author&query=Saradhi%2C+V+V">Vijaya V. Saradhi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The initial work was published in the ICMLA 2019 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Devising player-specific strategies in cricket necessitates a meticulous
understanding of each player's unique strengths and weaknesses. Nevertheless,
the absence of a definitive computational approach to extract such insights
from cricket players poses a significant challenge. This paper seeks to address
this gap by establishing computational models designed to extract the rules
governing player strengths and weaknesses, thereby facilitating the development
of tailored strategies for individual players. The complexity of this endeavor
lies in several key areas: the selection of a suitable dataset, the precise
definition of strength and weakness rules, the identification of an appropriate
learning algorithm, and the validation of the derived rules. To tackle these
challenges, we propose the utilization of unstructured data, specifically
cricket text commentary, as a valuable resource for constructing comprehensive
strength and weakness rules for cricket players. We also introduce
computationally feasible definitions for the construction of these rules, and
present a dimensionality reduction technique for the rule-building process. In
order to showcase the practicality of this approach, we conduct an in-depth
analysis of cricket player strengths and weaknesses using a vast corpus of more
than one million text commentaries. Furthermore, we validate the constructed
rules through two distinct methodologies: intrinsic and extrinsic. The outcomes
of this research are made openly accessible, including the collected data,
source code, and results for over 250 cricket players, which can be accessed at
https://bit.ly/2PKuzx8.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06820" title="Abstract">arXiv:2311.06820</a> [<a href="/pdf/2311.06820" title="Download PDF">pdf</a>, <a href="/format/2311.06820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Nonlinear Negative Imaginary Systems Framework with Actuator  Saturation for Control of Electrical Power Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yijun Chen</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+K">Kanghong Shi</a>, 
<a href="/search/eess?searchtype=author&query=Petersen%2C+I+R">Ian R. Petersen</a>, 
<a href="/search/eess?searchtype=author&query=Ratnam%2C+E+L">Elizabeth L. Ratnam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, European Control Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In the transition to net zero, it has been suggested that a massive expansion
of the electric power grid will be required to support emerging renewable
energy zones. In this paper, we propose the use of battery-based feedback
control and nonlinear negative imaginary systems theory to reduce the need for
such an expansion by enabling the more complete utilization of existing grid
infrastructure. By constructing a novel Lur'e-Postnikov-like Lyapunov function,
a stability result is developed for the feedback interconnection of a nonlinear
negative imaginary system and a nonlinear negative imaginary controller.
Additionally, a new class of nonlinear negative imaginary controllers is
proposed to deal with actuator saturation. We show that in this control
framework, the controller eventually leaves the saturation boundary, and the
feedback system is locally stable in the sense of Lyapunov. This provides
theoretical support for the application of battery-based control in electrical
power systems. Validation through simulation results for
single-machine-infinite-bus power systems supports our results. Our approach
has the potential to enable a transmission line to operate at its maximum power
capacity, as stability robustness is ensured by the use of a feedback
controller.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06823" title="Abstract">arXiv:2311.06823</a> [<a href="/pdf/2311.06823" title="Download PDF">pdf</a>, <a href="/format/2311.06823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training A Multi-stage Deep Classifier with Feedback Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rongzhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B">Bojia Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multi-Stage Classifier (MSC) - several classifiers working sequentially in an
arranged order and classification decision is partially made at each step - is
widely used in industrial applications for various resource limitation reasons.
The classifiers of a multi-stage process are usually Neural Network (NN) models
trained independently or in their inference order without considering the
signals from the latter stages. Aimed at two-stage binary classification
process, the most common type of MSC, we propose a novel training framework,
named Feedback Training. The classifiers are trained in an order reverse to
their actual working order, and the classifier at the later stage is used to
guide the training of initial-stage classifier via a sample weighting method.
We experimentally show the efficacy of our proposed approach, and its great
superiority under the scenario of few-shot training.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06825" title="Abstract">arXiv:2311.06825</a> [<a href="/pdf/2311.06825" title="Download PDF">pdf</a>, <a href="/ps/2311.06825" title="Download PostScript">ps</a>, <a href="/format/2311.06825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure Rate-Splitting Multiple Access Transmissions in LMS Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+M">Minjue He</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+X">Xiaqing Miao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+G">Gaofeng Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This letter investigates the secure delivery performance of the
rate-splitting multiple access scheme in land mobile satellite (LMS) systems,
considering that the private messages intended by a terminal can be
eavesdropped by any others from the broadcast signals. Specifically, the
considered system has an N-antenna satellite and numerous single-antenna land
users. Maximum ratio transmission (MRT) and matched-filtering (MF) precoding
techniques are adopted at the satellite separately for the common messages
(CMs) and for the private messages (PMs), which are both implemented based on
the estimated LMS channels suffering from the Shadowed-Rician fading. Then,
closed-form expressions are derived for the ergodic rates for decoding the CM,
and for decoding the PM at the intended user respectively, and more
importantly, we also derive the ergodic secrecy rate against eavesdropping.
Finally, numerical results are provided to validate the correctness of the
proposed analysis models, as well as to show some interesting comparisons.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06826" title="Abstract">arXiv:2311.06826</a> [<a href="/pdf/2311.06826" title="Download PDF">pdf</a>, <a href="/format/2311.06826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fairness Hacking: The Malicious Practice of Shrouding Unfairness in  Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meding%2C+K">Kristof Meding</a>, 
<a href="/search/cs?searchtype=author&query=Hagendorff%2C+T">Thilo Hagendorff</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">Fairness in machine learning (ML) is an ever-growing field of research due to
the manifold potential for harm from algorithmic discrimination. To prevent
such harm, a large body of literature develops new approaches to quantify
fairness. Here, we investigate how one can divert the quantification of
fairness by describing a practice we call "fairness hacking" for the purpose of
shrouding unfairness in algorithms. This impacts end-users who rely on learning
algorithms, as well as the broader community interested in fair AI practices.
We introduce two different categories of fairness hacking in reference to the
established concept of p-hacking. The first category, intra-metric fairness
hacking, describes the misuse of a particular metric by adding or removing
sensitive attributes from the analysis. In this context, countermeasures that
have been developed to prevent or reduce p-hacking can be applied to similarly
prevent or reduce fairness hacking. The second category of fairness hacking is
inter-metric fairness hacking. Inter-metric fairness hacking is the search for
a specific fair metric with given attributes. We argue that countermeasures to
prevent or reduce inter-metric fairness hacking are still in their infancy.
Finally, we demonstrate both types of fairness hacking using real datasets. Our
paper intends to serve as a guidance for discussions within the fair ML
community to prevent or reduce the misuse of fairness metrics, and thus reduce
overall harm from ML applications.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06828" title="Abstract">arXiv:2311.06828</a> [<a href="/pdf/2311.06828" title="Download PDF">pdf</a>, <a href="/format/2311.06828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Continual Reinforcement Learning for Quadruped Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Minelli%2C+G">Giovanni Minelli</a>, 
<a href="/search/cs?searchtype=author&query=Vassiliades%2C+V">Vassilis Vassiliades</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages; Presented in the 3rd International Conference on Interactive Media, Smart Systems and Emerging Technologies (IMET)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Quadruped robots have emerged as an evolving technology that currently
leverages simulators to develop a robust controller capable of functioning in
the real-world without the need for further training. However, since it is
impossible to predict all possible real-world situations, our research explores
the possibility of enabling them to continue learning even after their
deployment. To this end, we designed two continual learning scenarios,
sequentially training the robot on different environments while simultaneously
evaluating its performance across all of them. Our approach sheds light on the
extent of both forward and backward skill transfer, as well as the degree to
which the robot might forget previously acquired skills. By addressing these
factors, we hope to enhance the adaptability and performance of quadruped
robots in real-world scenarios.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06835" title="Abstract">arXiv:2311.06835</a> [<a href="/pdf/2311.06835" title="Download PDF">pdf</a>, <a href="/format/2311.06835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open-Set Graph Anomaly Detection via Normal Structure Regularisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qizhou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+G">Guansong Pang</a>, 
<a href="/search/cs?searchtype=author&query=Salehi%2C+M">Mahsa Salehi</a>, 
<a href="/search/cs?searchtype=author&query=Buntine%2C+W">Wray Buntine</a>, 
<a href="/search/cs?searchtype=author&query=Leckie%2C+C">Christopher Leckie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">This paper considers an under-explored Graph Anomaly Detection (GAD) task,
namely open-set GAD, which aims to detect anomalous nodes using a small number
of labelled training normal and anomaly nodes (known as seen anomalies) that
cannot illustrate all possible inference-time abnormalities. The task has
attracted growing attention due to the availability of anomaly prior knowledge
from the label information that can help to substantially reduce detection
errors. However, current methods tend to over-emphasise fitting the seen
anomalies, leading to a weak generalisation ability to detect unseen anomalies,
i.e., those that are not illustrated by the labelled anomaly nodes. Further,
they were introduced to handle Euclidean data, failing to effectively capture
important non-Euclidean features for GAD. In this work, we propose a novel
open-set GAD approach, namely normal structure regularisation (NSReg), to
leverage the rich normal graph structure embedded in the labelled nodes to
tackle the aforementioned two issues. In particular, NSReg trains an
anomaly-discriminative supervised graph anomaly detector, with a plug-and-play
regularisation term to enforce compact, semantically-rich representations of
normal nodes. To this end, the regularisation is designed to differentiate
various types of normal nodes, including labelled normal nodes that are
connected in their local neighbourhood, and those that are not connected. By
doing so, it helps incorporate strong normality into the supervised anomaly
detector learning, mitigating their overfitting to the seen anomalies.
Extensive empirical results on real-world datasets demonstrate the superiority
of our proposed NSReg for open-set GAD.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06837" title="Abstract">arXiv:2311.06837</a> [<a href="/pdf/2311.06837" title="Download PDF">pdf</a>, <a href="/format/2311.06837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraNNDis: Efficient Unified Distributed Training Framework for Deep GNNs  on Large Clusters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jaeyong Song</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+H">Hongsun Jang</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+J">Jaewon Jung</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Youngsok Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jinho Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Graph neural networks (GNNs) are one of the most rapidly growing fields
within deep learning. According to the growth in the dataset and the model size
used for GNNs, an important problem is that it becomes nearly impossible to
keep the whole network on GPU memory. Among numerous attempts, distributed
training is one popular approach to address the problem. However, due to the
nature of GNNs, existing distributed approaches suffer from poor scalability,
mainly due to the slow external server communications.
<br />In this paper, we propose GraNNDis, an efficient distributed GNN training
framework for training GNNs on large graphs and deep layers. GraNNDis
introduces three new techniques. First, shared preloading provides a training
structure for a cluster of multi-GPU servers. We suggest server-wise preloading
of essential vertex dependencies to reduce the low-bandwidth external server
communications. Second, we present expansion-aware sampling. Because shared
preloading alone has limitations because of the neighbor explosion,
expansion-aware sampling reduces vertex dependencies that span across server
boundaries. Third, we propose cooperative batching to create a unified
framework for full-graph and minibatch training. It significantly reduces
redundant memory usage in mini-batch training. From this, GraNNDis enables a
reasonable trade-off between full-graph and mini-batch training through
unification especially when the entire graph does not fit into the GPU memory.
With experiments conducted on a multi-server/multi-GPU cluster, we show that
GraNNDis provides superior speedup over the state-of-the-art distributed GNN
training frameworks.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06838" title="Abstract">arXiv:2311.06838</a> [<a href="/pdf/2311.06838" title="Download PDF">pdf</a>, <a href="/format/2311.06838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GIELLM: Japanese General Information Extraction Large Language Model  Utilizing Mutual Reinforcement Effect
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gan%2C+C">Chengguang Gan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qinghao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mori%2C+T">Tatsunori Mori</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Information Extraction (IE) stands as a cornerstone in natural language
processing, traditionally segmented into distinct sub-tasks. The advent of
Large Language Models (LLMs) heralds a paradigm shift, suggesting the
feasibility of a singular model addressing multiple IE subtasks. In this vein,
we introduce the General Information Extraction Large Language Model (GIELLM),
which integrates text Classification, Sentiment Analysis, Named Entity
Recognition, Relation Extraction, and Event Extraction using a uniform
input-output schema. This innovation marks the first instance of a model
simultaneously handling such a diverse array of IE subtasks. Notably, the
GIELLM leverages the Mutual Reinforcement Effect (MRE), enhancing performance
in integrated tasks compared to their isolated counterparts. Our experiments
demonstrate State-of-the-Art (SOTA) results in five out of six Japanese mixed
datasets, significantly surpassing GPT-3.5-Turbo. Further, an independent
evaluation using the novel Text Classification Relation and Event
Extraction(TCREE) dataset corroborates the synergistic advantages of MRE in
text and word classification. This breakthrough paves the way for most IE
subtasks to be subsumed under a singular LLM framework. Specialized fine-tune
task-specific models are no longer needed.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06839" title="Abstract">arXiv:2311.06839</a> [<a href="/pdf/2311.06839" title="Download PDF">pdf</a>, <a href="/format/2311.06839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inference and Interference: The Role of Clipping, Pruning and Loss  Landscapes in Differentially Private Stochastic Gradient Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Watson%2C+L">Lauren Watson</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+E">Eric Gan</a>, 
<a href="/search/cs?searchtype=author&query=Dantam%2C+M">Mohan Dantam</a>, 
<a href="/search/cs?searchtype=author&query=Mirzasoleiman%2C+B">Baharan Mirzasoleiman</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+R">Rik Sarkar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Differentially private stochastic gradient descent (DP-SGD) is known to have
poorer training and test performance on large neural networks, compared to
ordinary stochastic gradient descent (SGD). In this paper, we perform a
detailed study and comparison of the two processes and unveil several new
insights. By comparing the behavior of the two processes separately in early
and late epochs, we find that while DP-SGD makes slower progress in early
stages, it is the behavior in the later stages that determines the end result.
This separate analysis of the clipping and noise addition steps of DP-SGD shows
that while noise introduces errors to the process, gradient descent can recover
from these errors when it is not clipped, and clipping appears to have a larger
impact than noise. These effects are amplified in higher dimensions (large
neural networks), where the loss basin occupies a lower dimensional space. We
argue theoretically and using extensive experiments that magnitude pruning can
be a suitable dimension reduction technique in this regard, and find that heavy
pruning can improve the test accuracy of DPSGD.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06840" title="Abstract">arXiv:2311.06840</a> [<a href="/pdf/2311.06840" title="Download PDF">pdf</a>, <a href="/ps/2311.06840" title="Download PostScript">ps</a>, <a href="/format/2311.06840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distribution Re-weighting and Voting Paradoxes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mazaheri%2C+B">Bijan Mazaheri</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+S">Siddharth Jain</a>, 
<a href="/search/cs?searchtype=author&query=Cook%2C+M">Matthew Cook</a>, 
<a href="/search/cs?searchtype=author&query=Bruck%2C+J">Jehoshua Bruck</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT); Social and Information Networks (cs.SI); Methodology (stat.ME)

</div>
<p class="mathjax">We explore a specific type of distribution shift called domain expertise, in
which training is limited to a subset of all possible labels. This setting is
common among specialized human experts, or specific focused studies. We show
how the standard approach to distribution shift, which involves re-weighting
data, can result in paradoxical disagreements among differing domain expertise.
We also demonstrate how standard adjustments for causal inference lead to the
same paradox. We prove that the characteristics of these paradoxes exactly
mimic another set of paradoxes which arise among sets of voter preferences.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06845" title="Abstract">arXiv:2311.06845</a> [<a href="/pdf/2311.06845" title="Download PDF">pdf</a>, <a href="/format/2311.06845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sampler Scheduler for Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zitong Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Diffusion modeling (DM) has high-quality generative performance, and the
sampling problem is an important part of the DM performance. Thanks to
efficient differential equation solvers, the sampling speed can be reduced
while higher sampling quality is guaranteed. However, currently, there is a
contradiction in samplers for diffusion-based generative models: the mainstream
sampler choices are diverse, each with its own characteristics in terms of
performance. However, only a single sampler algorithm can be specified on all
sampling steps in the generative process. This often makes one torn between
sampler choices; in other words, it makes it difficult to fully utilize the
advantages of each sampler. In this paper, we propose the feasibility of using
different samplers (ODE/SDE) on different sampling steps of the same sampling
process based on analyzing and generalizing the updating formulas of each
mainstream sampler, and experimentally demonstrate that such a multi-sampler
scheduling improves the sampling results to some extent. In particular, we also
verify that the combination of using SDE in the early sampling steps and ODE in
the later sampling steps solves the inherent problems previously caused by
using both singly. We show that our design changes improve the sampling
efficiency and quality in previous work. For instance, when Number of Function
Evaluations (NFE) = 24, the ODE Sampler Scheduler achieves a FID score of 1.91
on the CIFAR-10 dataset, compared to 2.02 for DPM++ 2M, 1.97 for DPM2, and
11.90 for Heun for the same NFE. Meanwhile the Sampler Scheduler with the
combined scheduling of SDE and ODE reaches 1.899, compared to 18.63 for Euler
a, 3.14 for DPM2 a and 23.14 for DPM++ SDE.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06847" title="Abstract">arXiv:2311.06847</a> [<a href="/pdf/2311.06847" title="Download PDF">pdf</a>, <a href="/format/2311.06847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mass Loss and Displacement Modeling for Multi-Axis Milling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=R%C3%BCppel%2C+A+K">Adrian Karl R&#xfc;ppel</a>, 
<a href="/search/eess?searchtype=author&query=Ochudlo%2C+P">Patrick Ochudlo</a>, 
<a href="/search/eess?searchtype=author&query=Bickel%2C+M">Mathias Bickel</a>, 
<a href="/search/eess?searchtype=author&query=Stemmler%2C+S">Sebastian Stemmler</a>, 
<a href="/search/eess?searchtype=author&query=Bergs%2C+T">Thomas Bergs</a>, 
<a href="/search/eess?searchtype=author&query=Abel%2C+D">Dirk Abel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">During the cutting process, material of the workpiece is continuously being
removed by the cutting tool, which results in a reduction of mass as well as a
displacement in the center of the workpiece mass. When using workpiece sided
force sensors, such as table dynamometers, the total mass and the displacement
of the center of mass affects the force measurement due to gravitational and
inertial effects. The high flexibility of the milling process leads to a
complex change of volume and mass and necessitates the consideration of the
engagement conditions between tool and workpiece along the tool path in order
to estimate changes in mass and center of mass. This paper proposes a method
for estimating the mass loss and the displacement of the center of mass during
multi-axis milling processes. In this method the tool gets numerically sliced
along the tool axis and the workpiece removal for each slice along an arbitrary
tool path gets calculated. To validate the mass loss model, experiments in both
three-axis milling as well as multi-axis milling processes have been conducted.
Since it is difficult to measure the center of mass, validation for the
displacement of the center of mass was done by comparison with data extracted
from CAD. The results show good agreement between the simulated and measured
mass loss using the proposed approach.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06851" title="Abstract">arXiv:2311.06851</a> [<a href="/pdf/2311.06851" title="Download PDF">pdf</a>, <a href="/format/2311.06851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Textual Normalization for Hate Speech Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+A+T">Anh Thi-Hoang Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+H">Dung Ha Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+N+T">Nguyet Thi Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+K+T">Khanh Thanh-Duy Ho</a>, 
<a href="/search/cs?searchtype=author&query=Van+Nguyen%2C+K">Kiet Van Nguyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Social media data is a valuable resource for research, yet it contains a wide
range of non-standard words (NSW). These irregularities hinder the effective
operation of NLP tools. Current state-of-the-art methods for the Vietnamese
language address this issue as a problem of lexical normalization, involving
the creation of manual rules or the implementation of multi-staged deep
learning frameworks, which necessitate extensive efforts to craft intricate
rules. In contrast, our approach is straightforward, employing solely a
sequence-to-sequence (Seq2Seq) model. In this research, we provide a dataset
for textual normalization, comprising 2,181 human-annotated comments with an
inter-annotator agreement of 0.9014. By leveraging the Seq2Seq model for
textual normalization, our results reveal that the accuracy achieved falls
slightly short of 70%. Nevertheless, textual normalization enhances the
accuracy of the Hate Speech Detection (HSD) task by approximately 2%,
demonstrating its potential to improve the performance of complex NLP tasks.
Our dataset is accessible for research purposes.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06852" title="Abstract">arXiv:2311.06852</a> [<a href="/pdf/2311.06852" title="Download PDF">pdf</a>, <a href="/format/2311.06852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Learning of View-Invariant Representations for Facial  Expressions Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roy%2C+S">Shuvendu Roy</a>, 
<a href="/search/cs?searchtype=author&query=Etemad%2C+A">Ali Etemad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ACM Transactions on Multimedia Computing, Communications, and Applications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Although there has been much progress in the area of facial expression
recognition (FER), most existing methods suffer when presented with images that
have been captured from viewing angles that are non-frontal and substantially
different from those used in the training process. In this paper, we propose
ViewFX, a novel view-invariant FER framework based on contrastive learning,
capable of accurately classifying facial expressions regardless of the input
viewing angles during inference. ViewFX learns view-invariant features of
expression using a proposed self-supervised contrastive loss which brings
together different views of the same subject with a particular expression in
the embedding space. We also introduce a supervised contrastive loss to push
the learnt view-invariant features of each expression away from other
expressions. Since facial expressions are often distinguished with very subtle
differences in the learned feature space, we incorporate the Barlow twins loss
to reduce the redundancy and correlations of the representations in the learned
representations. The proposed method is a substantial extension of our
previously proposed CL-MEx, which only had a self-supervised loss. We test the
proposed framework on two public multi-view facial expression recognition
datasets, KDEF and DDCF. The experiments demonstrate that our approach
outperforms previous works in the area and sets a new state-of-the-art for both
datasets while showing considerably less sensitivity to challenging angles and
the number of output labels used for training. We also perform detailed
sensitivity and ablation experiments to evaluate the impact of different
components of our model as well as its sensitivity to different parameters.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06855" title="Abstract">arXiv:2311.06855</a> [<a href="/pdf/2311.06855" title="Download PDF">pdf</a>, <a href="/format/2311.06855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DialMAT: Dialogue-Enabled Transformer with Moment-Based Adversarial  Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaneda%2C+K">Kanta Kaneda</a>, 
<a href="/search/cs?searchtype=author&query=Korekata%2C+R">Ryosuke Korekata</a>, 
<a href="/search/cs?searchtype=author&query=Wada%2C+Y">Yuiga Wada</a>, 
<a href="/search/cs?searchtype=author&query=Nagashima%2C+S">Shunya Nagashima</a>, 
<a href="/search/cs?searchtype=author&query=Kambara%2C+M">Motonari Kambara</a>, 
<a href="/search/cs?searchtype=author&query=Iioka%2C+Y">Yui Iioka</a>, 
<a href="/search/cs?searchtype=author&query=Matsuo%2C+H">Haruka Matsuo</a>, 
<a href="/search/cs?searchtype=author&query=Imai%2C+Y">Yuto Imai</a>, 
<a href="/search/cs?searchtype=author&query=Nishimura%2C+T">Takayuki Nishimura</a>, 
<a href="/search/cs?searchtype=author&query=Sugiura%2C+K">Komei Sugiura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation at Fourth Annual Embodied AI Workshop at CVPR
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Robotics (cs.RO)

</div>
<p class="mathjax">This paper focuses on the DialFRED task, which is the task of embodied
instruction following in a setting where an agent can actively ask questions
about the task. To address this task, we propose DialMAT. DialMAT introduces
Moment-based Adversarial Training, which incorporates adversarial perturbations
into the latent space of language, image, and action. Additionally, it
introduces a crossmodal parallel feature extraction mechanism that applies
foundation models to both language and image. We evaluated our model using a
dataset constructed from the DialFRED dataset and demonstrated superior
performance compared to the baseline method in terms of success rate and path
weighted success rate. The model secured the top position in the DialFRED
Challenge, which took place at the CVPR 2023 Embodied AI workshop.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06856" title="Abstract">arXiv:2311.06856</a> [<a href="/pdf/2311.06856" title="Download PDF">pdf</a>, <a href="/format/2311.06856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On learning spatial sequences with the movement of attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Osaulenko%2C+V+M">Viacheslav M. Osaulenko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">In this paper we start with a simple question, how is it possible that humans
can recognize different movements over skin with only a prior visual experience
of them? Or in general, what is the representation of spatial sequences that
are invariant to scale, rotation, and translation across different modalities?
To answer, we rethink the mathematical representation of spatial sequences,
argue against the minimum description length principle, and focus on the
movements of attention. We advance the idea that spatial sequences must be
represented on different levels of abstraction, this adds redundancy but is
necessary for recognition and generalization. To address the open question of
how these abstractions are formed we propose two hypotheses: the first invites
exploring selectionism learning, instead of finding parameters in some models;
the second proposes to find new data structures, not neural network
architectures, to efficiently store and operate over redundant features to be
further selected. Movements of attention are central to human cognition and
lessons should be applied to new better learning algorithms.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06858" title="Abstract">arXiv:2311.06858</a> [<a href="/pdf/2311.06858" title="Download PDF">pdf</a>, <a href="/ps/2311.06858" title="Download PostScript">ps</a>, <a href="/format/2311.06858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Large Language Models Augment a Biomedical Ontology with missing  Concepts and Relations?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zaitoun%2C+A">Antonio Zaitoun</a>, 
<a href="/search/cs?searchtype=author&query=Sagi%2C+T">Tomer Sagi</a>, 
<a href="/search/cs?searchtype=author&query=Wilk%2C+S">Szymon Wilk</a>, 
<a href="/search/cs?searchtype=author&query=Peleg%2C+M">Mor Peleg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented as a short paper at the Knowledge Representation for Healthcare 2023 workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Ontologies play a crucial role in organizing and representing knowledge.
However, even current ontologies do not encompass all relevant concepts and
relationships. Here, we explore the potential of large language models (LLM) to
expand an existing ontology in a semi-automated fashion. We demonstrate our
approach on the biomedical ontology SNOMED-CT utilizing semantic relation types
from the widely used UMLS semantic network. We propose a method that uses
conversational interactions with an LLM to analyze clinical practice guidelines
(CPGs) and detect the relationships among the new medical concepts that are not
present in SNOMED-CT. Our initial experimentation with the conversational
prompts yielded promising preliminary results given a manually generated gold
standard, directing our future potential improvements.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06861" title="Abstract">arXiv:2311.06861</a> [<a href="/pdf/2311.06861" title="Download PDF">pdf</a>, <a href="/format/2311.06861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-efficient Beamforming for RISs-aided Communications: Gradient  Based Meta Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinquan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Fenghao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qianyun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qihao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chongwen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Alhammadi%2C+A">Ahmed Alhammadi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yuen%2C+C">Chau Yuen</a>, 
<a href="/search/cs?searchtype=author&query=Debbah%2C+M">M&#xe9;rouane Debbah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Reconfigurable intelligent surfaces (RISs) have become a promising technology
to meet the requirements of energy efficiency and scalability in future
six-generation (6G) communications. However, a significant challenge in
RISs-aided communications is the joint optimization of active and passive
beamforming at base stations (BSs) and RISs respectively. Specifically, the
main difficulty is attributed to the highly non-convex optimization space of
beamforming matrices at both BSs and RISs, as well as the diversity and
mobility of communication scenarios. To address this, we present a greenly
gradient based meta learning beamforming (GMLB) approach. Unlike traditional
deep learning based methods which take channel information directly as input,
GMLB feeds the gradient of sum rate into neural networks. Coherently, we design
a differential regulator to address the phase shift optimization of RISs.
Moreover, we use the meta learning to iteratively optimize the beamforming
matrices of BSs and RISs. These techniques make the proposed method to work
well without requiring energy-consuming pre-training. Simulations show that
GMLB could achieve higher sum rate than that of typical alternating
optimization algorithms with the energy consumption by two orders of magnitude
less.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06864" title="Abstract">arXiv:2311.06864</a> [<a href="/pdf/2311.06864" title="Download PDF">pdf</a>, <a href="/format/2311.06864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Practices around Computational News Discovery Tools in the  Domain of Science Journalism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nishal%2C+S">Sachita Nishal</a>, 
<a href="/search/cs?searchtype=author&query=Sinchai%2C+J">Jasmine Sinchai</a>, 
<a href="/search/cs?searchtype=author&query=Diakopoulos%2C+N">Nicholas Diakopoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in CSCW 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">Science and technology journalists today face challenges in finding
newsworthy leads due to increased workloads, reduced resources, and expanding
scientific publishing ecosystems. Given this context, we explore computational
methods to aid these journalists' news discovery in terms of time-efficiency
and agency. In particular, we prototyped three computational information
subsidies into an interactive tool that we used as a probe to better understand
how such a tool may offer utility or more broadly shape the practices of
professional science journalists. Our findings highlight central considerations
around science journalists' agency, context, and responsibilities that such
tools can influence and could account for in design. Based on this, we suggest
design opportunities for greater and longer-term user agency; incorporating
contextual, personal and collaborative notions of newsworthiness; and
leveraging flexible interfaces and generative models. Overall, our findings
contribute a richer view of the sociotechnical system around computational news
discovery tools, and suggest ways to improve such tools to better support the
practices of science journalists.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06865" title="Abstract">arXiv:2311.06865</a> [<a href="/pdf/2311.06865" title="Download PDF">pdf</a>, <a href="/format/2311.06865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Centralised or Decentralised? Data Analysis of Transaction Network of  Hedera Hashgraph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amherd%2C+L">Lucas Amherd</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sheng-Nan Li</a>, 
<a href="/search/cs?searchtype=author&query=Tessone%2C+C+J">Claudio J. Tessone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; General Economics (econ.GN)

</div>
<p class="mathjax">An important virtue of distributed ledger technologies is their acclaimed
higher level of decentralisation compared to traditional financial systems.
Empirical literature, however, suggests that many systems tend towards
centralisation as well. This study expands the current literature by offering a
first-time, data-driven analysis of the degree of decentralisation of the
platform Hedera Hashgraph, a public permissioned distributed ledger technology,
employing data directly fetched from a network node. The results show a
considerably higher amount of released supply compared to the release schedule
and a growing number of daily active accounts. Also, Hedera Hashgraph exhibits
a high centralisation of wealth and a shrinking core that acts as an
intermediary in transactions for the rest of the network. However, the Nakamoto
index and Theil index point to recent progress towards a more decentralised
network.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06868" title="Abstract">arXiv:2311.06868</a> [<a href="/pdf/2311.06868" title="Download PDF">pdf</a>, <a href="/format/2311.06868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concept-wise Fine-tuning Matters in Preventing Negative Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yunqiao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Long-Kai Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Ying Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">A multitude of prevalent pre-trained models mark a major milestone in the
development of artificial intelligence, while fine-tuning has been a common
practice that enables pretrained models to figure prominently in a wide array
of target datasets. Our empirical results reveal that off-the-shelf finetuning
techniques are far from adequate to mitigate negative transfer caused by two
types of underperforming features in a pre-trained model, including rare
features and spuriously correlated features. Rooted in structural causal models
of predictions after fine-tuning, we propose a Concept-wise fine-tuning
(Concept-Tuning) approach which refines feature representations in the level of
patches with each patch encoding a concept. Concept-Tuning minimizes the
negative impacts of rare features and spuriously correlated features by (1)
maximizing the mutual information between examples in the same category with
regard to a slice of rare features (a patch) and (2) applying front-door
adjustment via attention neural networks in channels and feature slices
(patches). The proposed Concept-Tuning consistently and significantly (by up to
4.76%) improves prior state-of-the-art fine-tuning methods on eleven datasets,
diverse pre-training strategies (supervised and self-supervised ones), various
network architectures, and sample sizes in a target dataset.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06869" title="Abstract">arXiv:2311.06869</a> [<a href="/pdf/2311.06869" title="Download PDF">pdf</a>, <a href="/ps/2311.06869" title="Download PostScript">ps</a>, <a href="/format/2311.06869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convolution quadrature for Hadamard fractional calculus and correction  methods for the subdiffusion with singular source terms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yin%2C+B">Baoli Yin</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+G">Guoyu Zhang</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+H">Hong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The convolution quadrature method originally developed for the
Riemann-Liouville fractional calculus is extended in this work to the Hadamard
fractional calculus by using the exponential type meshes. Local truncation
error analysis is presented for singular solutions. By adopting the fractional
BDF-$p(1\leq p \leq 6)$ for the Caputo-Hadamard fractional derivative in
solving subdiffusion problem with singular source terms, and using the finite
element method to discretize the space variable, we carry out the sharp error
analysis rigorously and obtain the optimal accuracy by the novel correction
technique. Our correction method is a natural generalization of the one
developed for subdiffusion problems with smooth source terms. Numerical tests
confirm the correctness of our theoretical results.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06874" title="Abstract">arXiv:2311.06874</a> [<a href="/pdf/2311.06874" title="Download PDF">pdf</a>, <a href="/format/2311.06874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Charging Coordination of Electric Trucks with Limited  Charging Resources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bai%2C+T">Ting Bai</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yuchao Li</a>, 
<a href="/search/eess?searchtype=author&query=Johansson%2C+K+H">Karl Henrik Johansson</a>, 
<a href="/search/eess?searchtype=author&query=M%C3%A5rtensson%2C+J">Jonas M&#xe5;rtensson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper for ECC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Electric trucks usually need to charge their batteries during long-range
delivery missions, and the charging times are often nontrivial. As charging
resources are limited, waiting times for some trucks can be prolonged at
certain stations. To facilitate the efficient operation of electric trucks, we
propose a distributed charging coordination framework. Within the scheme, the
charging stations provide waiting estimates to incoming trucks upon request and
assign charging ports according to the first-come, first-served rule. Based on
the updated information, the individual trucks compute where and how long to
charge whenever approaching a charging station in order to complete their
delivery missions timely and cost-effectively. We perform empirical studies for
trucks traveling over the Swedish road network and compare our scheme with the
one where charging plans are computed offline, assuming unlimited charging
facilities. It is shown that the proposed scheme outperforms the offline
approach at the expense of little communication overhead.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06876" title="Abstract">arXiv:2311.06876</a> [<a href="/pdf/2311.06876" title="Download PDF">pdf</a>, <a href="/format/2311.06876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unified machine learning tasks and datasets for enhancing renewable  energy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aryandoust%2C+A">Arsam Aryandoust</a>, 
<a href="/search/cs?searchtype=author&query=Rigoni%2C+T">Thomas Rigoni</a>, 
<a href="/search/cs?searchtype=author&query=di+Stefano%2C+F">Francesco di Stefano</a>, 
<a href="/search/cs?searchtype=author&query=Patt%2C+A">Anthony Patt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Multi-tasking machine learning (ML) models exhibit prediction abilities in
domains with little to no training data available (few-shot and zero-shot
learning). Over-parameterized ML models are further capable of zero-loss
training and near-optimal generalization performance. An open research question
is, how these novel paradigms contribute to solving tasks related to enhancing
the renewable energy transition and mitigating climate change. A collection of
unified ML tasks and datasets from this domain can largely facilitate the
development and empirical testing of such models, but is currently missing.
Here, we introduce the ETT-17 (Energy Transition Tasks-17), a collection of 17
datasets from six different application domains related to enhancing renewable
energy, including out-of-distribution validation and testing data. We unify all
tasks and datasets, such that they can be solved using a single multi-tasking
ML model. We further analyse the dimensions of each dataset; investigate what
they require for designing over-parameterized models; introduce a set of
dataset scores that describe important properties of each task and dataset; and
provide performance benchmarks.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06879" title="Abstract">arXiv:2311.06879</a> [<a href="/pdf/2311.06879" title="Download PDF">pdf</a>, <a href="/format/2311.06879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> pFedES: Model Heterogeneous Personalized Federated Learning with Feature  Extractor Sharing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+L">Liping Yi</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Han Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Gang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoguang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 10 figures. arXiv admin note: text overlap with <a href="/abs/2310.13283">arXiv:2310.13283</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">As a privacy-preserving collaborative machine learning paradigm, federated
learning (FL) has attracted significant interest from academia and the industry
alike. To allow each data owner (a.k.a., FL clients) to train a heterogeneous
and personalized local model based on its local data distribution, system
resources and requirements on model structure, the field of model-heterogeneous
personalized federated learning (MHPFL) has emerged. Existing MHPFL approaches
either rely on the availability of a public dataset with special
characteristics to facilitate knowledge transfer, incur high computation and
communication costs, or face potential model leakage risks. To address these
limitations, we propose a model-heterogeneous personalized Federated learning
approach based on feature Extractor Sharing (pFedES). It incorporates a small
homogeneous feature extractor into each client's heterogeneous local model.
Clients train them via the proposed iterative learning method to enable the
exchange of global generalized knowledge and local personalized knowledge. The
small local homogeneous extractors produced after local training are uploaded
to the FL server and for aggregation to facilitate easy knowledge sharing among
clients. We theoretically prove that pFedES can converge over wall-to-wall
time. Extensive experiments on two real-world datasets against six
state-of-the-art methods demonstrate that pFedES builds the most accurate
model, while incurring low communication and computation costs. Compared with
the best-performing baseline, it achieves 1.61% higher test accuracy, while
reducing communication and computation costs by 99.6% and 82.9%, respectively.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06887" title="Abstract">arXiv:2311.06887</a> [<a href="/pdf/2311.06887" title="Download PDF">pdf</a>, <a href="/format/2311.06887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anticipating User Needs: Insights from Design Fiction on Conversational  Agents for Computational Thinking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Penney%2C+J">Jacob Penney</a>, 
<a href="/search/cs?searchtype=author&query=Pimentel%2C+J+F">Jo&#xe3;o Felipe Pimentel</a>, 
<a href="/search/cs?searchtype=author&query=Steinmacher%2C+I">Igor Steinmacher</a>, 
<a href="/search/cs?searchtype=author&query=Gerosa%2C+M+A">Marco A. Gerosa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, three figures, accepted at Conversations 2023 but not yet published in workshop proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Computational thinking, and by extension, computer programming, is
notoriously challenging to learn. Conversational agents and generative
artificial intelligence (genAI) have the potential to facilitate this learning
process by offering personalized guidance, interactive learning experiences,
and code generation. However, current genAI-based chatbots focus on
professional developers and may not adequately consider educational needs.
Involving educators in conceiving educational tools is critical for ensuring
usefulness and usability. We enlisted \numParticipants{} instructors to engage
in design fiction sessions in which we elicited abilities such a conversational
agent supported by genAI should display. Participants envisioned a
conversational agent that guides students stepwise through exercises, tuning
its method of guidance with an awareness of the educational background, skills
and deficits, and learning preferences. The insights obtained in this paper can
guide future implementations of tutoring conversational agents oriented toward
teaching computational thinking and computer programming.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06888" title="Abstract">arXiv:2311.06888</a> [<a href="/pdf/2311.06888" title="Download PDF">pdf</a>, <a href="/format/2311.06888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preserving Node-level Privacy in Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiang%2C+Z">Zihang Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Di Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Differential privacy (DP) has seen immense applications in learning on
tabular, image, and sequential data where instance-level privacy is concerned.
In learning on graphs, contrastingly, works on node-level privacy are highly
sparse. Challenges arise as existing DP protocols hardly apply to the
message-passing mechanism in Graph Neural Networks (GNNs).
<br />In this study, we propose a solution that specifically addresses the issue of
node-level privacy. Our protocol consists of two main components: 1) a sampling
routine called HeterPoisson, which employs a specialized node sampling strategy
and a series of tailored operations to generate a batch of sub-graphs with
desired properties, and 2) a randomization routine that utilizes symmetric
multivariate Laplace (SML) noise instead of the commonly used Gaussian noise.
Our privacy accounting shows this particular combination provides a non-trivial
privacy guarantee. In addition, our protocol enables GNN learning with good
performance, as demonstrated by experiments on five real-world datasets;
compared with existing baselines, our method shows significant advantages,
especially in the high privacy regime. Experimentally, we also 1) perform
membership inference attacks against our protocol and 2) apply privacy audit
techniques to confirm our protocol's privacy integrity.
<br />In the sequel, we present a study on a seemingly appealing approach
\cite{sajadmanesh2023gap} (USENIX'23) that protects node-level privacy via
differentially private node/instance embeddings. Unfortunately, such work has
fundamental privacy flaws, which are identified through a thorough case study.
More importantly, we prove an impossibility result of achieving both (strong)
privacy and (acceptable) utility through private instance embedding. The
implication is that such an approach has intrinsic utility barriers when
enforcing differential privacy.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06889" title="Abstract">arXiv:2311.06889</a> [<a href="/pdf/2311.06889" title="Download PDF">pdf</a>, <a href="/format/2311.06889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Programmatic Strategy Synthesis -- Resolving Nondeterminism in  Probabilistic Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Batz%2C+K">Kevin Batz</a>, 
<a href="/search/cs?searchtype=author&query=Biskup%2C+T">Tom Biskup</a>, 
<a href="/search/cs?searchtype=author&query=Katoen%2C+J">Joost-Pieter Katoen</a>, 
<a href="/search/cs?searchtype=author&query=Winkler%2C+T">Tobias Winkler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">We consider imperative programs that involve both randomization and pure
nondeterminism. The central question is how to find a strategy resolving the
pure nondeterminism such that the so-obtained determinized program satisfies a
given quantitative specification, i.e., bounds on expected outcomes such as the
expected final value of a program variable or the probability to terminate in a
given set of states. We show how memoryless and deterministic (MD) strategies
can be obtained in a semi-automatic fashion using deductive verification
techniques. For loop-free programs, the MD strategies resulting from our
weakest precondition-style framework are correct by construction. This extends
to loopy programs, provided the loops are equipped with suitable loop
invariants - just like in program verification. We show how our technique
relates to the well-studied problem of obtaining strategies in countably
infinite Markov decision processes with reachability-reward objectives.
Finally, we apply our technique to several case studies.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06890" title="Abstract">arXiv:2311.06890</a> [<a href="/pdf/2311.06890" title="Download PDF">pdf</a>, <a href="/ps/2311.06890" title="Download PostScript">ps</a>, <a href="/format/2311.06890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Sequential Receding Horizon Control of Multi-Agent Systems  under Recurring Signal Temporal Logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Vlahakis%2C+E+E">Eleftherios E. Vlahakis</a>, 
<a href="/search/eess?searchtype=author&query=Lindemann%2C+L">Lars Lindemann</a>, 
<a href="/search/eess?searchtype=author&query=Dimarogonas%2C+D+V">Dimos V. Dimarogonas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to ECC24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">We consider the synthesis problem of a multi-agent system under Signal
Temporal Logic (STL) specifications representing bounded-time tasks that need
to be satisfied recurrently over an infinite horizon. Motivated by the limited
approaches to handling recurring STL systematically, we tackle the
infinite-horizon control problem with a receding horizon scheme equipped with
additional STL constraints that introduce minimal complexity and a
backward-reachability-based terminal condition that is straightforward to
construct and ensures recursive feasibility. Subsequently, assuming a separable
performance index, we decompose the global receding horizon optimization
problem defined at the multi-agent level into local programs at the
individual-agent level the objective of which is to minimize the local cost
function subject to local and joint STL constraints. We propose a scheduling
policy that allows individual agents to sequentially optimize their control
actions while maintaining recursive feasibility. This results in a distributed
strategy that can operate online as a model predictive controller. Last, we
illustrate the effectiveness of our method via a multi-agent system example
assigned a surveillance task.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06892" title="Abstract">arXiv:2311.06892</a> [<a href="/pdf/2311.06892" title="Download PDF">pdf</a>, <a href="/ps/2311.06892" title="Download PostScript">ps</a>, <a href="/format/2311.06892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Setting a Baseline for long-shot real-time Player and Ball detection in  Soccer Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moutselos%2C+K">Konstantinos Moutselos</a>, 
<a href="/search/cs?searchtype=author&query=Maglogiannis%2C+I">Ilias Maglogiannis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures, 1 table. 14th International Conference on Information,Intelligence, Systems and Applications (IISA 2023) , Thessaly, Volos, Greece, 10-12 July 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Players and ball detection are among the first required steps on a football
analytics platform. Until recently, the existing open datasets on which the
evaluations of most models were based, were not sufficient. In this work, we
point out their weaknesses, and with the advent of the SoccerNet v3, we propose
and deliver to the community an edited part of its dataset, in YOLO normalized
annotation format for training and evaluation. The code of the methods and
metrics are provided so that they can be used as a benchmark in future
comparisons. The recent YOLO8n model proves better than FootAndBall in
long-shot real-time detection of the ball and players on football fields.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06894" title="Abstract">arXiv:2311.06894</a> [<a href="/pdf/2311.06894" title="Download PDF">pdf</a>, <a href="/format/2311.06894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Application of Vector Autoregressive Model for Analyzing the Impact  of Weather And Nearby Traffic Flow On The Traffic Volume
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+A+T">Anh Thi-Hoang Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+H">Dung Ha Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Do%2C+T">Trong-Hop Do</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Conference on Computing and Communication Technologies (RIVF2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper aims to predict the traffic flow at one road segment based on
nearby traffic volume and weather conditions. Our team also discover the impact
of weather conditions and nearby traffic volume on the traffic flow at a target
point. The analysis results will help solve the problem of traffic flow
prediction and develop an optimal transport network with efficient traffic
movement and minimal traffic congestion. Hourly historical weather and traffic
flow data are selected to solve this problem. This paper uses model VAR(36)
with time trend and constant to train the dataset and forecast. With an RMSE of
565.0768111 on average, the model is considered appropriate although some
statistical tests implies that the residuals are unstable and non-normal. Also,
this paper points out some variables that are not useful in forecasting, which
helps simplify the data-collecting process when building the forecasting
system.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06895" title="Abstract">arXiv:2311.06895</a> [<a href="/pdf/2311.06895" title="Download PDF">pdf</a>, <a href="/format/2311.06895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asymmetric Design of Control Barrier Function for Multiagent Autonomous  Robotic Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Etchu%2C+H">Hiroki Etchu</a>, 
<a href="/search/cs?searchtype=author&query=Origane%2C+Y">Yuki Origane</a>, 
<a href="/search/cs?searchtype=author&query=Kurabayashi%2C+D">Daisuke Kurabayashi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In this paper, we propose a method to avoid "no-solution" situations of the
control barrier function (CBF) for distributed collision avoidance in a
multiagent autonomous robotic system (MARS). MARS, which is composed of
distributed autonomous mobile robots, is expected to effectively perform
cooperative tasks such as searching in a certain area. Therefore, collision
avoidance must be considered when implementing MARS in the real world. The CBF
is effective for solving collision-avoidance problems. However, in extreme
conditions where many robots congregate at one location, the CBF constraints
that ensure a safe distance between robots may be violated. We theoretically
demonstrate that this problem can occur in certain situations, and introduce an
asymmetric design for the inequality constraints of CBF. We asymmetrically
decentralized inequality constraints with weight functions using the absolute
speed of the robot so that other robots can take over the constraints of the
robot in severe condition. We demonstrate the effectiveness of the proposed
method in a two-dimensional situation wherein multiple robots congregate at one
location. We implement the proposed method on real robots and the confirmed the
effectiveness of this theory.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06898" title="Abstract">arXiv:2311.06898</a> [<a href="/pdf/2311.06898" title="Download PDF">pdf</a>, <a href="/ps/2311.06898" title="Download PostScript">ps</a>, <a href="/format/2311.06898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrieval and Generative Approaches for a Pregnancy Chatbot in Nepali  with Stemmed and Non-Stemmed Data : A Comparative Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Poudel%2C+S">Sujan Poudel</a>, 
<a href="/search/cs?searchtype=author&query=Ghimire%2C+N">Nabin Ghimire</a>, 
<a href="/search/cs?searchtype=author&query=Subedi%2C+B">Bipesh Subedi</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Saugat Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures, 4 tables. In proceedings of the International Conference on Technologies for Computer, Electrical, Electronics &amp; Communication (ICT-CEEL 2023), Bhaktapur, Nepal
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Conference on Technologies for Computer, Electrical,
  Electronics &amp; Communication (ICT-CEEL 2023), Bhaktapur, Nepal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The field of Natural Language Processing which involves the use of artificial
intelligence to support human languages has seen tremendous growth due to its
high-quality features. Its applications such as language translation, chatbots,
virtual assistants, search autocomplete, and autocorrect are widely used in
various domains including healthcare, advertising, customer service, and target
advertising. To provide pregnancy-related information a health domain chatbot
has been proposed and this work explores two different NLP-based approaches for
developing the chatbot. The first approach is a multiclass classification-based
retrieval approach using BERTbased multilingual BERT and multilingual
DistilBERT while the other approach employs a transformer-based generative
chatbot for pregnancy-related information. The performance of both stemmed and
non-stemmed datasets in Nepali language has been analyzed for each approach.
The experimented results indicate that BERT-based pre-trained models perform
well on non-stemmed data whereas scratch transformer models have better
performance on stemmed data. Among the models tested the DistilBERT model
achieved the highest training and validation accuracy and testing accuracy of
0.9165 on the retrieval-based model architecture implementation on the
non-stemmed dataset. Similarly, in the generative approach architecture
implementation with transformer 1 gram BLEU and 2 gram BLEU scores of 0.3570
and 0.1413 respectively were achieved.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06899" title="Abstract">arXiv:2311.06899</a> [<a href="/pdf/2311.06899" title="Download PDF">pdf</a>, <a href="/format/2311.06899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flames: Benchmarking Value Alignment of Chinese Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kexin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiangyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qianyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+T">Tianxiang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiawei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaru Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zeyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yixu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+Y">Yan Teng</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xipeng Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yingchun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The widespread adoption of large language models (LLMs) across various
regions underscores the urgent need to evaluate their alignment with human
values. Current benchmarks, however, fall short of effectively uncovering
safety vulnerabilities in LLMs. Despite numerous models achieving high scores
and 'topping the chart' in these evaluations, there is still a significant gap
in LLMs' deeper alignment with human values and achieving genuine harmlessness.
To this end, this paper proposes the first highly adversarial benchmark named
Flames, consisting of 2,251 manually crafted prompts, ~18.7K model responses
with fine-grained annotations, and a specified scorer. Our framework
encompasses both common harmlessness principles, such as fairness, safety,
legality, and data protection, and a unique morality dimension that integrates
specific Chinese values such as harmony. Based on the framework, we carefully
design adversarial prompts that incorporate complex scenarios and jailbreaking
methods, mostly with implicit malice. By prompting mainstream LLMs with such
adversarially constructed prompts, we obtain model responses, which are then
rigorously annotated for evaluation. Our findings indicate that all the
evaluated LLMs demonstrate relatively poor performance on Flames, particularly
in the safety and fairness dimensions. Claude emerges as the best-performing
model overall, but with its harmless rate being only 63.08% while GPT-4 only
scores 39.04%. The complexity of Flames has far exceeded existing benchmarks,
setting a new challenge for contemporary LLMs and highlighting the need for
further alignment of LLMs. To efficiently evaluate new models on the benchmark,
we develop a specified scorer capable of scoring LLMs across multiple
dimensions, achieving an accuracy of 77.4%. The Flames Benchmark is publicly
available on https://github.com/AIFlames/Flames.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06900" title="Abstract">arXiv:2311.06900</a> [<a href="/pdf/2311.06900" title="Download PDF">pdf</a>, <a href="/ps/2311.06900" title="Download PostScript">ps</a>, <a href="/format/2311.06900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symbol-Error Probability Constrained Power Minimization for  Reconfigurable Intelligent Surfaces-based Passive Transmitter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lopes%2C+E+S+P">Erico S. P. Lopes</a>, 
<a href="/search/cs?searchtype=author&query=Landau%2C+L+T+N">Lukas T. N. Landau</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This study considers a virtual multiuser multiple-input multiple-output
system with PSK modulation realized via the reconfigurable intelligent
surface-based passive transmitter setup. Under this framework, the study
derives the formulation for the union-bound symbol-error probability, which is
an upper bound on the actual symbol-error probability. Based on this, a
symbol-level precoding power minimization problem under the condition that the
union-bound symbol-error probability is below a given requirement is proposed.
The problem is formulated as a constrained optimization on an oblique manifold,
and solved via a bisection method. The method consists of successively
optimizing transmit power while evaluating the feasibility of the union-bound
symbol-error probability requisite by solving, via the Riemannian conjugate
gradient algorithm, an auxiliary problem dependent only on the reflection
coefficients of the reconfigurable intelligent surface elements. Numerical
results demonstrate the effectiveness of the proposed approach in minimizing
the transmit power for different symbol-error probability requirements.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06903" title="Abstract">arXiv:2311.06903</a> [<a href="/pdf/2311.06903" title="Download PDF">pdf</a>, <a href="/format/2311.06903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spotting Fake Profiles in Social Networks via Keystroke Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuruvilla%2C+A">Alvin Kuruvilla</a>, 
<a href="/search/cs?searchtype=author&query=Daley%2C+R">Rojanaye Daley</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+R">Rajesh Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2024 IEEE 21st Consumer Communications \&amp; Networking Conference (CCNC) | 9 pages, 8 figures, 3 algos,
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Spotting and removing fake profiles could curb the menace of fake news in
society. This paper, thus, investigates fake profile detection in social
networks via users' typing patterns. We created a novel dataset of 468 posts
from 26 users on three social networks: Facebook, Instagram, and X (previously
Twitter) over six sessions. Then, we extract a series of features from
keystroke timings and use them to predict whether two posts originated from the
same users using three prominent statistical methods and their score-level
fusion. The models' performance is evaluated under same, cross, and
combined-cross-platform scenarios. We report the performance using k-rank
accuracy for k varying from 1 to 5. The best-performing model obtained
accuracies between 91.6-100% on Facebook (Fusion), 70.8-87.5% on Instagram
(Fusion), and 75-87.5% on X (Fusion) for k from 1 to 5. Under a cross-platform
scenario, the fusion model achieved mean accuracies of 79.1-91.6%, 87.5-91.6%,
and 83.3-87.5% when trained on Facebook, Instagram, and Twitter posts,
respectively. In combined cross-platform, which involved mixing two platforms'
data for model training while testing happened on the third platform's data,
the best model achieved accuracy ranges of 75-95.8% across different scenarios.
The results highlight the potential of the presented method in uncovering fake
profiles across social network platforms.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06911" title="Abstract">arXiv:2311.06911</a> [<a href="/pdf/2311.06911" title="Download PDF">pdf</a>, <a href="/format/2311.06911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> More Than 50% Of The Time, Users Detect Real SMS as Fake: A Smishing  Detection Study Of US Population
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Timko%2C+D">Daniel Timko</a>, 
<a href="/search/cs?searchtype=author&query=Castillo%2C+D+H">Daniel Hernandez Castillo</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M+L">Muhammad Lutfor Rahman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">With the booming popularity of smartphones, threats related to these devices
are increasingly on the rise. Smishing, a combination of SMS (Short Message
Service) and phishing has emerged as a treacherous cyber threat used by
malicious actors to deceive users, aiming to steal sensitive information, money
or install malware on their mobile devices. Despite the increase in smishing
attacks in recent years, there are very few studies aimed at understanding the
factors that contribute to a user's ability to differentiate real from fake
messages.
<br />To address this gap in knowledge, we have conducted an online survey on
smishing detection with 214 participants. In this study, we presented them with
16 SMS screenshots and evaluated how different factors affect their decision
making process in smishing detection. Next, we conducted a follow-up survey to
garner information on the participants' security attitudes, behavior and
knowledge. Our results highlighted that attention and security behavioral
scores had a significant impact on participants' accuracy identifying smishing
messages. Interestingly, we found that participants had more difficulty
identifying real messages from fake ones, with an accuracy of 64% with fake
messages and 46\% with real messages. Understanding these factors is pivotal to
bolstering users' resilience against these threats and to create a safer
digital environment.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06914" title="Abstract">arXiv:2311.06914</a> [<a href="/pdf/2311.06914" title="Download PDF">pdf</a>, <a href="/format/2311.06914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-assisted Reinforcement Learning of a Quadrotor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Javeed%2C+A">Arshad Javeed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In recent times, reinforcement learning has produced baffling results when it
comes to performing control tasks with highly non-linear systems. The
impressive results always outweigh the potential vulnerabilities or
uncertainties associated with the agents when deployed in the real-world. While
the performance is remarkable compared to the classical control algorithms, the
reinforcement learning-based methods suffer from two flaws, robustness and
interpretability, which are vital for contemporary real-world applications. The
paper attempts to alleviate such problems with reinforcement learning and
proposes the concept of model-assisted reinforcement learning to induce a
notion of conservativeness in the agents. The control task considered for the
experiment involves navigating a CrazyFlie quadrotor. The paper also describes
a way of reformulating the task to have the flexibility of tuning the level of
conservativeness via multi-objective reinforcement learning. The results
include a comparison of the vanilla reinforcement learning approaches and the
proposed approach. The metrics are evaluated by systematically injecting
disturbances to classify the inherent robustness and conservativeness of the
agents. More concrete arguments are made by computing and comparing the
backward reachability tubes of the RL policies by solving the
Hamilton-Jacobi-Bellman partial differential equation (HJ PDE).
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06916" title="Abstract">arXiv:2311.06916</a> [<a href="/pdf/2311.06916" title="Download PDF">pdf</a>, <a href="/ps/2311.06916" title="Download PostScript">ps</a>, <a href="/format/2311.06916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TSViT: A Time Series Vision Transformer for Fault Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+S">Shouhua Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+J">Jiehan Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+X">Xue Ma</a>, 
<a href="/search/eess?searchtype=author&query=Wen%2C+C">Chenglin Wen</a>, 
<a href="/search/eess?searchtype=author&query=Pirttikangas%2C+S">Susanna Pirttikangas</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+C">Chen Yu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+W">Weishan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+C">Chunsheng Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Traditional fault diagnosis methods using Convolutional Neural Networks
(CNNs) face limitations in capturing temporal features (i.e., the variation of
vibration signals over time). To address this issue, this paper introduces a
novel model, the Time Series Vision Transformer (TSViT), specifically designed
for fault diagnosis. On one hand, TSViT model integrates a convolutional layer
to segment vibration signals and capture local features. On the other hand, it
employs a transformer encoder to learn long-term temporal information. The
experimental results with other methods on two distinct datasets validate the
effectiveness and generalizability of TSViT with a comparative analysis of its
hyperparameters' impact on model performance, computational complexity, and
overall parameter quantity. TSViT reaches average accuracies of 100% and 99.99%
on two test sets, correspondingly.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06917" title="Abstract">arXiv:2311.06917</a> [<a href="/pdf/2311.06917" title="Download PDF">pdf</a>, <a href="/format/2311.06917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FLASH-RL: Federated Learning Addressing System and Static Heterogeneity  using Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bouaziz%2C+S">Sofiane Bouaziz</a>, 
<a href="/search/cs?searchtype=author&query=Benmeziane%2C+H">Hadjer Benmeziane</a>, 
<a href="/search/cs?searchtype=author&query=Imine%2C+Y">Youcef Imine</a>, 
<a href="/search/cs?searchtype=author&query=Hamdad%2C+L">Leila Hamdad</a>, 
<a href="/search/cs?searchtype=author&query=Niar%2C+S">Smail Niar</a>, 
<a href="/search/cs?searchtype=author&query=Ouarnoughi%2C+H">Hamza Ouarnoughi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in the 41st IEEE International Conference on Computer Design (ICCD 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated Learning (FL) has emerged as a promising Machine Learning paradigm,
enabling multiple users to collaboratively train a shared model while
preserving their local data. To minimize computing and communication costs
associated with parameter transfer, it is common practice in FL to select a
subset of clients in each training round. This selection must consider both
system and static heterogeneity. Therefore, we propose FLASH-RL, a framework
that utilizes Double Deep QLearning (DDQL) to address both system and static
heterogeneity in FL. FLASH-RL introduces a new reputation-based utility
function to evaluate client contributions based on their current and past
performances. Additionally, an adapted DDQL algorithm is proposed to expedite
the learning process. Experimental results on MNIST and CIFAR-10 datasets have
shown FLASH-RL's effectiveness in achieving a balanced trade-off between model
performance and end-to-end latency against existing solutions. Indeed, FLASH-RL
reduces latency by up to 24.83% compared to FedAVG and 24.67% compared to
FAVOR. It also reduces the training rounds by up to 60.44% compared to FedAVG
and +76% compared to FAVOR. In fall detection using the MobiAct dataset,
FLASH-RL outperforms FedAVG by up to 2.82% in model's performance and reduces
latency by up to 34.75%. Additionally, FLASH-RL achieves the target performance
faster, with up to a 45.32% reduction in training rounds compared to FedAVG.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06918" title="Abstract">arXiv:2311.06918</a> [<a href="/pdf/2311.06918" title="Download PDF">pdf</a>, <a href="/format/2311.06918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resource-Aware Hierarchical Federated Learning for Video Caching in  Wireless Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pervej%2C+M+F">Md Ferdous Pervej</a>, 
<a href="/search/cs?searchtype=author&query=Molisch%2C+A+F">Andreas F Molisch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">Video caching can significantly improve backhaul traffic congestion by
locally storing the popular content that users frequently request. A
privacy-preserving method is desirable to learn how users' demands change over
time. As such, this paper proposes a novel resource-aware hierarchical
federated learning (RawHFL) solution to predict users' future content requests
under the realistic assumptions that content requests are sporadic and users'
datasets can only be updated based on the requested content's information.
Considering a partial client participation case, we first derive the upper
bound of the global gradient norm that depends on the clients' local training
rounds and the successful reception of their accumulated gradients over the
wireless links. Under delay, energy and radio resource constraints, we then
optimize client selection and their local rounds and central processing unit
(CPU) frequencies to minimize a weighted utility function that facilitates
RawHFL's convergence in an energy-efficient way. Our simulation results show
that the proposed solution significantly outperforms the considered baselines
in terms of prediction accuracy and total energy expenditure.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06921" title="Abstract">arXiv:2311.06921</a> [<a href="/pdf/2311.06921" title="Download PDF">pdf</a>, <a href="/format/2311.06921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concept Matching: Clustering-based Federated Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xiaopeng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Borcea%2C+C">Cristian Borcea</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated Continual Learning (FCL) has emerged as a promising paradigm that
combines Federated Learning (FL) and Continual Learning (CL). To achieve good
model accuracy, FCL needs to tackle catastrophic forgetting due to concept
drift over time in CL, and to overcome the potential interference among clients
in FL. We propose Concept Matching (CM), a clustering-based framework for FCL
to address these challenges. The CM framework groups the client models into
concept model clusters, and then builds different global models to capture
different concepts in FL over time. In each round, the server sends the global
concept models to the clients. To avoid catastrophic forgetting, each client
selects the concept model best-matching the concept of the current data for
further fine-tuning. To avoid interference among client models with different
concepts, the server clusters the models representing the same concept,
aggregates the model weights in each cluster, and updates the global concept
model with the cluster model of the same concept. Since the server does not
know the concepts captured by the aggregated cluster models, we propose a novel
server concept matching algorithm that effectively updates a global concept
model with a matching cluster model. The CM framework provides flexibility to
use different clustering, aggregation, and concept matching algorithms. The
evaluation demonstrates that CM outperforms state-of-the-art systems and scales
well with the number of clients and the model size.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06922" title="Abstract">arXiv:2311.06922</a> [<a href="/pdf/2311.06922" title="Download PDF">pdf</a>, <a href="/format/2311.06922" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Socially Aware Robot Navigation: Taxonomy and Future  Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singamaneni%2C+P+T">Phani Teja Singamaneni</a>, 
<a href="/search/cs?searchtype=author&query=Bachiller-Burgos%2C+P">Pilar Bachiller-Burgos</a>, 
<a href="/search/cs?searchtype=author&query=Manso%2C+L+J">Luis J. Manso</a>, 
<a href="/search/cs?searchtype=author&query=Garrell%2C+A">Ana/&#x27;is Garrell</a>, 
<a href="/search/cs?searchtype=author&query=Sanfeliu%2C+A">Alberto Sanfeliu</a>, 
<a href="/search/cs?searchtype=author&query=Spalanzani%2C+A">Anne Spalanzani</a>, 
<a href="/search/cs?searchtype=author&query=Alami%2C+R">Rachid Alami</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Socially aware robot navigation is gaining popularity with the increase in
delivery and assistive robots. The research is further fueled by a need for
socially aware navigation skills in autonomous vehicles to move safely and
appropriately in spaces shared with humans. Although most of these are ground
robots, drones are also entering the field. In this paper, we present a
literature survey of the works on socially aware robot navigation in the past
10 years. We propose four different faceted taxonomies to navigate the
literature and examine the field from four different perspectives. Through the
taxonomic review, we discuss the current research directions and the extending
scope of applications in various domains. Further, we put forward a list of
current research opportunities and present a discussion on possible future
challenges that are likely to emerge in the field.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06926" title="Abstract">arXiv:2311.06926</a> [<a href="/pdf/2311.06926" title="Download PDF">pdf</a>, <a href="/format/2311.06926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Matrix-free polynomial preconditioning of saddle point systems using the  hyper-power method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mika%2C+M+%C5%81">Micha&#x142; &#x141;ukasz Mika</a>, 
<a href="/search/cs?searchtype=author&query=Eikelder%2C+M+t">Marco ten Eikelder</a>, 
<a href="/search/cs?searchtype=author&query=Schillinger%2C+D">Dominik Schillinger</a>, 
<a href="/search/cs?searchtype=author&query=Hiemstra%2C+R+R">Ren&#xe9; Rinke Hiemstra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">This study explores the integration of the hyper-power sequence, a method
commonly employed for approximating the Moore-Penrose inverse, to enhance the
effectiveness of an existing preconditioner. The approach is closely related to
polynomial preconditioning based on Neumann series. We commence with a
state-of-the-art matrix-free preconditioner designed for the saddle point
system derived from isogeometric structure-preserving discretization of the
Stokes equations. Our results demonstrate that incorporating multiple
iterations of the hyper-power method enhances the effectiveness of the
preconditioner, leading to a substantial reduction in both iteration counts and
overall solution time for simulating Stokes flow within a 3D lid-driven cavity.
Through a comprehensive analysis, we assess the stability, accuracy, and
numerical cost associated with the proposed scheme.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06928" title="Abstract">arXiv:2311.06928</a> [<a href="/pdf/2311.06928" title="Download PDF">pdf</a>, <a href="/format/2311.06928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention for Causal Relationship Discovery from Biological Neural  Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Ziyu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Tabassum%2C+A">Anika Tabassum</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+S">Shruti Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+L">Lu Mi</a>, 
<a href="/search/cs?searchtype=author&query=Kutz%2C+J+N">J. Nathan Kutz</a>, 
<a href="/search/cs?searchtype=author&query=Shea-Brown%2C+E">Eric Shea-Brown</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+S">Seung-Hwan Lim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the NeurIPS 2023 Workshop on Causal Representation Learning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
<p class="mathjax">This paper explores the potential of the transformer models for learning
Granger causality in networks with complex nonlinear dynamics at every node, as
in neurobiological and biophysical networks. Our study primarily focuses on a
proof-of-concept investigation based on simulated neural dynamics, for which
the ground-truth causality is known through the underlying connectivity matrix.
For transformer models trained to forecast neuronal population dynamics, we
show that the cross attention module effectively captures the causal
relationship among neurons, with an accuracy equal or superior to that for the
most popular Granger causality analysis method. While we acknowledge that
real-world neurobiology data will bring further challenges, including dynamic
connectivity and unobserved variability, this research offers an encouraging
preliminary glimpse into the utility of the transformer model for causal
representation learning in neuroscience.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06930" title="Abstract">arXiv:2311.06930</a> [<a href="/pdf/2311.06930" title="Download PDF">pdf</a>, <a href="/format/2311.06930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video-based sympathetic arousal assessment via peripheral blood flow  estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Braun%2C+B">Bjoern Braun</a>, 
<a href="/search/cs?searchtype=author&query=McDuff%2C+D">Daniel McDuff</a>, 
<a href="/search/cs?searchtype=author&query=Baltrusaitis%2C+T">Tadas Baltrusaitis</a>, 
<a href="/search/cs?searchtype=author&query=Holz%2C+C">Christian Holz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted and to be published at Biomedical Optics Express
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Electrodermal activity (EDA) is considered a standard marker of sympathetic
activity. However, traditional EDA measurement requires electrodes in steady
contact with the skin. Can sympathetic arousal be measured using only an
optical sensor, such as an RGB camera? This paper presents a novel approach to
infer sympathetic arousal by measuring the peripheral blood flow on the face or
hand optically. We contribute a self-recorded dataset of 21 participants,
comprising synchronized videos of participants' faces and palms and
gold-standard EDA and photoplethysmography (PPG) signals. Our results show that
we can measure peripheral sympathetic responses that closely correlate with the
ground truth EDA. We obtain median correlations of 0.57 to 0.63 between our
inferred signals and the ground truth EDA using only videos of the
participants' palms or foreheads or PPG signals from the foreheads or fingers.
We also show that sympathetic arousal is best inferred from the forehead,
finger, or palm.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06937" title="Abstract">arXiv:2311.06937</a> [<a href="/pdf/2311.06937" title="Download PDF">pdf</a>, <a href="/ps/2311.06937" title="Download PostScript">ps</a>, <a href="/format/2311.06937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kleene Algebra with Dynamic Tests: Completeness and Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sedl%C3%A1r%2C+I">Igor Sedl&#xe1;r</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">We study versions of Kleene algebra with dynamic tests, that is, extensions
of Kleene algebra with domain and antidomain operators. We show that Kleene
algebras with tests and Propositional dynamic logic correspond to special cases
of the dynamic test framework. In particular, we establish completeness results
with respect to relational models and guarded-language models, and we show that
two prominent classes of Kleene algebras with dynamic tests have an
EXPTIME-complete equational theory.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06938" title="Abstract">arXiv:2311.06938</a> [<a href="/pdf/2311.06938" title="Download PDF">pdf</a>, <a href="/ps/2311.06938" title="Download PostScript">ps</a>, <a href="/format/2311.06938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 5G Networks and IoT Devices: Mitigating DDoS Attacks with Deep Learning  Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alzhrani%2C+R+M">Reem M. Alzhrani</a>, 
<a href="/search/cs?searchtype=author&query=Alliheedi%2C+M+A">Mohammed A. Alliheedi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">The development and implementation of Internet of Things (IoT) devices have
been accelerated dramatically in recent years. As a result, a super-network is
required to handle the massive volumes of data collected and transmitted to
these devices. Fifth generation (5G) technology is a new, comprehensive
wireless technology that has the potential to be the primary enabling
technology for the IoT. The rapid spread of IoT devices can encounter many
security limits and concerns. As a result, new and serious security and privacy
risks have emerged. Attackers use IoT devices to launch massive attacks; one of
the most famous is the Distributed Denial of Service (DDoS) attack. Deep
Learning techniques have proven their effectiveness in detecting and mitigating
DDoS attacks. In this paper, we applied two Deep Learning algorithms
Convolutional Neural Network (CNN) and Feed Forward Neural Network (FNN) in
dataset was specifically designed for IoT devices within 5G networks. We
constructed the 5G network infrastructure using OMNeT++ with the INET and
Simu5G frameworks. The dataset encompasses both normal network traffic and DDoS
attacks. The Deep Learning algorithms, CNN and FNN, showed impressive accuracy
levels, both reaching 99%. These results underscore the potential of Deep
Learning to enhance the security of IoT devices within 5G networks.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06942" title="Abstract">arXiv:2311.06942</a> [<a href="/pdf/2311.06942" title="Download PDF">pdf</a>, <a href="/format/2311.06942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contractive Systems Improve Graph Neural Networks Against Adversarial  Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eliasof%2C+M">Moshe Eliasof</a>, 
<a href="/search/cs?searchtype=author&query=Murari%2C+D">Davide Murari</a>, 
<a href="/search/cs?searchtype=author&query=Sherry%2C+F">Ferdia Sherry</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6nlieb%2C+C">Carola-Bibiane Sch&#xf6;nlieb</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Graph Neural Networks (GNNs) have established themselves as a key component
in addressing diverse graph-based tasks. Despite their notable successes, GNNs
remain susceptible to input perturbations in the form of adversarial attacks.
This paper introduces an innovative approach to fortify GNNs against
adversarial perturbations through the lens of contractive dynamical systems.
Our method introduces graph neural layers based on differential equations with
contractive properties, which, as we show, improve the robustness of GNNs. A
distinctive feature of the proposed approach is the simultaneous learned
evolution of both the node features and the adjacency matrix, yielding an
intrinsic enhancement of model robustness to perturbations in the input
features and the connectivity of the graph. We mathematically derive the
underpinnings of our novel architecture and provide theoretical insights to
reason about its expected behavior. We demonstrate the efficacy of our method
through numerous real-world benchmarks, reading on par or improved performance
compared to existing methods.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06952" title="Abstract">arXiv:2311.06952</a> [<a href="/pdf/2311.06952" title="Download PDF">pdf</a>, <a href="/format/2311.06952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A GPU-Accelerated Moving-Horizon Algorithm for Training Deep  Classification Trees on Large Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jiayang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Osuna-Enciso%2C+V">Valent&#xed;n Osuna-Enciso</a>, 
<a href="/search/cs?searchtype=author&query=Okamoto%2C+M">Morimasa Okamoto</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Q">Qiangqiang Mao</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+C">Chaojie Ji</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Liang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+K">Kaixun Hua</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yankai Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages (13 pages for the main body, 23 pages for the appendix), 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Decision trees are essential yet NP-complete to train, prompting the
widespread use of heuristic methods such as CART, which suffers from
sub-optimal performance due to its greedy nature. Recently, breakthroughs in
finding optimal decision trees have emerged; however, these methods still face
significant computational costs and struggle with continuous features in
large-scale datasets and deep trees. To address these limitations, we introduce
a moving-horizon differential evolution algorithm for classification trees with
continuous features (MH-DEOCT). Our approach consists of a discrete tree
decoding method that eliminates duplicated searches between adjacent samples, a
GPU-accelerated implementation that significantly reduces running time, and a
moving-horizon strategy that iteratively trains shallow subtrees at each node
to balance the vision and optimizer capability. Comprehensive studies on 68 UCI
datasets demonstrate that our approach outperforms the heuristic method CART on
training and testing accuracy by an average of 3.44% and 1.71%, respectively.
Moreover, these numerical studies empirically demonstrate that MH-DEOCT
achieves near-optimal performance (only 0.38% and 0.06% worse than the global
optimal method on training and testing, respectively), while it offers
remarkable scalability for deep trees (e.g., depth=8) and large-scale datasets
(e.g., ten million samples).
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06954" title="Abstract">arXiv:2311.06954</a> [<a href="/pdf/2311.06954" title="Download PDF">pdf</a>, <a href="/format/2311.06954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Learning of Soft Robot Dynamics using Differentiable Filters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yifan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ikemoto%2C+S">Shuhei Ikemoto</a>, 
<a href="/search/cs?searchtype=author&query=Amor%2C+H+B">Heni Ben Amor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures, 5 tables, CoRL 2023 workshop Learning for Soft Robots
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Differentiable Filters, as recursive Bayesian estimators, possess the ability
to learn complex dynamics by deriving state transition and measurement models
exclusively from data. This data-driven approach eliminates the reliance on
explicit analytical models while maintaining the essential algorithmic
components of the filtering process. However, the gain mechanism remains
non-differentiable, limiting its adaptability to specific task requirements and
contextual variations. To address this limitation, this paper introduces an
innovative approach called {\alpha}-MDF (Attention-based Multimodal
Differentiable Filter). {\alpha}-MDF leverages modern attention mechanisms to
learn multimodal latent representations for accurate state estimation in soft
robots. By incorporating attention mechanisms, {\alpha}-MDF offers the
flexibility to tailor the gain mechanism to the unique nature of the task and
context. The effectiveness of {\alpha}-MDF is validated through real-world
state estimation tasks on soft robots. Our experimental results demonstrate
significant reductions in state estimation errors, consistently surpassing
differentiable filter baselines by up to 45% in the domain of soft robotics.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06956" title="Abstract">arXiv:2311.06956</a> [<a href="/pdf/2311.06956" title="Download PDF">pdf</a>, <a href="/format/2311.06956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SegReg: Segmenting OARs by Registering MR Images and CT Annotations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zeyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xuyin Qi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bowen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Biao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+H">Hien Le</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+B">Bora Jeong</a>, 
<a href="/search/cs?searchtype=author&query=To%2C+M">Minh-Son To</a>, 
<a href="/search/cs?searchtype=author&query=Hartley%2C+R">Richard Hartley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Contact: steve.zeyu.zhang@outlook.com
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Organ at risk (OAR) segmentation is a critical process in radiotherapy
treatment planning such as head and neck tumors. Nevertheless, in clinical
practice, radiation oncologists predominantly perform OAR segmentations
manually on CT scans. This manual process is highly time-consuming and
expensive, limiting the number of patients who can receive timely radiotherapy.
Additionally, CT scans offer lower soft-tissue contrast compared to MRI.
Despite MRI providing superior soft-tissue visualization, its time-consuming
nature makes it infeasible for real-time treatment planning. To address these
challenges, we propose a method called SegReg, which utilizes Elastic Symmetric
Normalization for registering MRI to perform OAR segmentation. SegReg
outperforms the CT-only baseline by 16.78% in mDSC and 18.77% in mIoU, showing
that it effectively combines the geometric accuracy of CT with the superior
soft-tissue contrast of MRI, making accurate automated OAR segmentation for
clinical practice become possible.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06957" title="Abstract">arXiv:2311.06957</a> [<a href="/pdf/2311.06957" title="Download PDF">pdf</a>, <a href="/format/2311.06957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simulating Public Administration Crisis: A Novel Generative Agent-Based  Simulation System to Lower Technology Barriers in Social Science Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+B">Bushi Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Ziyuan Yin</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Z">Zixuan Shan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 Pages, 14 figures. This paper was submitted to IEEE TCSS on November 12, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">This article proposes a social simulation paradigm based on the GPT-3.5 large
language model. It involves constructing Generative Agents that emulate human
cognition, memory, and decision-making frameworks, along with establishing a
virtual social system capable of stable operation and an insertion mechanism
for standardized public events. The project focuses on simulating a township
water pollution incident, enabling the comprehensive examination of a virtual
government's response to a specific public administration event. Controlled
variable experiments demonstrate that the stored memory in generative agents
significantly influences both individual decision-making and social networks.
<br />The Generative Agent-Based Simulation System introduces a novel approach to
social science and public administration research. Agents exhibit personalized
customization, and public events are seamlessly incorporated through natural
language processing. Its high flexibility and extensive social interaction
render it highly applicable in social science investigations. The system
effectively reduces the complexity associated with building intricate social
simulations while enhancing its interpretability.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06958" title="Abstract">arXiv:2311.06958</a> [<a href="/pdf/2311.06958" title="Download PDF">pdf</a>, <a href="/format/2311.06958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards probabilistic Weather Forecasting with Conditioned  Spatio-Temporal Normalizing Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Winkler%2C+C">Christina Winkler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generative normalizing flows are able to model multimodal spatial
distributions, and they have been shown to model temporal correlations
successfully as well. These models provide several benefits over other types of
generative models due to their training stability, invertibility and efficiency
in sampling and inference. This makes them a suitable candidate for stochastic
spatio-temporal prediction problems, which are omnipresent in many fields of
sciences, such as earth sciences, astrophysics or molecular sciences. In this
paper, we present conditional normalizing flows for stochastic spatio-temporal
modelling. The method is evaluated on the task of daily temperature and hourly
geopotential map prediction from ERA5 datasets. Experiments show that our
method is able to capture spatio-temporal correlations and extrapolates well
beyond the time horizon used during training.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06960" title="Abstract">arXiv:2311.06960</a> [<a href="/pdf/2311.06960" title="Download PDF">pdf</a>, <a href="/format/2311.06960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Regression over Averaged Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bertsimas%2C+D">Dimitris Bertsimas</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yu Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We propose a new formulation of robust regression by integrating all
realizations of the uncertainty set and taking an averaged approach to obtain
the optimal solution for the ordinary least-squared regression problem. We show
that this formulation surprisingly recovers ridge regression and establishes
the missing link between robust optimization and the mean squared error
approaches for existing regression problems. We first prove the equivalence for
four uncertainty sets: ellipsoidal, box, diamond, and budget, and provide
closed-form formulations of the penalty term as a function of the sample size,
feature size, as well as perturbation protection strength. We then show in
synthetic datasets with different levels of perturbations, a consistent
improvement of the averaged formulation over the existing worst-case
formulation in out-of-sample performance. Importantly, as the perturbation
level increases, the improvement increases, confirming our method's advantage
in high-noise environments. We report similar improvements in the out-of-sample
datasets in real-world regression problems obtained from UCI datasets.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06961" title="Abstract">arXiv:2311.06961</a> [<a href="/pdf/2311.06961" title="Download PDF">pdf</a>, <a href="/ps/2311.06961" title="Download PostScript">ps</a>, <a href="/format/2311.06961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empowering Learning: Standalone, Browser-Only Courses for Seamless  Education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moghadas%2C+B">Babak Moghadas</a>, 
<a href="/search/cs?searchtype=author&query=Caffo%2C+B+S">Brian S. Caffo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Massive Open Online Courses (MOOCs) have transformed the educational
landscape, offering scalable and flexible learning opportunities, particularly
in data-centric fields like data science and artificial intelligence.
Incorporating AI and data science into MOOCs is a potential means of enhancing
the learning experience through adaptive learning approaches. In this context,
we introduce PyGlide, a proof-of-concept open-source MOOC delivery system that
underscores autonomy, transparency, and collaboration in maintaining course
content. We provide a user-friendly, step-by-step guide for PyGlide,
emphasizing its distinct advantage of not requiring any local software
installation for students. Highlighting its potential to enhance accessibility,
inclusivity, and the manageability of course materials, we showcase PyGlide's
practical application in a continuous integration pipeline on GitHub. We
believe that PyGlide charts a promising course for the future of open-source
MOOCs, effectively addressing crucial challenges in online education.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06962" title="Abstract">arXiv:2311.06962</a> [<a href="/pdf/2311.06962" title="Download PDF">pdf</a>, <a href="/format/2311.06962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Atlas: Hybrid Cloud Migration Advisor for Interactive Microservices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chow%2C+K">Ka-Ho Chow</a>, 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+U">Umesh Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Deenadhayalan%2C+V">Veera Deenadhayalan</a>, 
<a href="/search/cs?searchtype=author&query=Seshadri%2C+S">Sangeetha Seshadri</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Ling Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at EuroSys 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Hybrid cloud provides an attractive solution to microservices for better
resource elasticity. A subset of application components can be offloaded from
the on-premises cluster to the cloud, where they can readily access additional
resources. However, the selection of this subset is challenging because of the
large number of possible combinations. A poor choice degrades the application
performance, disrupts the critical services, and increases the cost to the
extent of making the use of hybrid cloud unviable. This paper presents Atlas, a
hybrid cloud migration advisor. Atlas uses a data-driven approach to learn how
each user-facing API utilizes different components and their network footprints
to drive the migration decision. It learns to accelerate the discovery of
high-quality migration plans from millions and offers recommendations with
customizable trade-offs among three quality indicators: end-to-end latency of
user-facing APIs representing application performance, service availability,
and cloud hosting costs. Atlas continuously monitors the application even after
the migration for proactive recommendations. Our evaluation shows that Atlas
can achieve 21% better API performance (latency) and 11% cheaper cost with less
service disruption than widely used solutions.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06964" title="Abstract">arXiv:2311.06964</a> [<a href="/pdf/2311.06964" title="Download PDF">pdf</a>, <a href="/format/2311.06964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive recurrent vision performs zero-shot computation scaling to  unseen difficulty levels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Veerabadran%2C+V">Vijay Veerabadran</a>, 
<a href="/search/cs?searchtype=author&query=Ravishankar%2C+S">Srinivas Ravishankar</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yuan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Raina%2C+R">Ritik Raina</a>, 
<a href="/search/cs?searchtype=author&query=de+Sa%2C+V+R">Virginia R. de Sa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Humans solving algorithmic (or) reasoning problems typically exhibit solution
times that grow as a function of problem difficulty. Adaptive recurrent neural
networks have been shown to exhibit this property for various
language-processing tasks. However, little work has been performed to assess
whether such adaptive computation can also enable vision models to extrapolate
solutions beyond their training distribution's difficulty level, with prior
work focusing on very simple tasks. In this study, we investigate a critical
functional role of such adaptive processing using recurrent neural networks: to
dynamically scale computational resources conditional on input requirements
that allow for zero-shot generalization to novel difficulty levels not seen
during training using two challenging visual reasoning tasks: PathFinder and
Mazes. We combine convolutional recurrent neural networks (ConvRNNs) with a
learnable halting mechanism based on Graves (2016). We explore various
implementations of such adaptive ConvRNNs (AdRNNs) ranging from tying weights
across layers to more sophisticated biologically inspired recurrent networks
that possess lateral connections and gating. We show that 1) AdRNNs learn to
dynamically halt processing early (or late) to solve easier (or harder)
problems, 2) these RNNs zero-shot generalize to more difficult problem settings
not shown during training by dynamically increasing the number of recurrent
iterations at test time. Our study provides modeling evidence supporting the
hypothesis that recurrent processing enables the functional advantage of
adaptively allocating compute resources conditional on input requirements and
hence allowing generalization to harder difficulty levels of a visual reasoning
problem without training.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06965" title="Abstract">arXiv:2311.06965</a> [<a href="/pdf/2311.06965" title="Download PDF">pdf</a>, <a href="/format/2311.06965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anchor Data Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schneider%2C+N">Nora Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Goshtasbpour%2C+S">Shirin Goshtasbpour</a>, 
<a href="/search/cs?searchtype=author&query=Perez-Cruz%2C+F">Fernando Perez-Cruz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We propose a novel algorithm for data augmentation in nonlinear
over-parametrized regression. Our data augmentation algorithm borrows from the
literature on causality and extends the recently proposed Anchor regression
(AR) method for data augmentation, which is in contrast to the current
state-of-the-art domain-agnostic solutions that rely on the Mixup literature.
Our Anchor Data Augmentation (ADA) uses several replicas of the modified
samples in AR to provide more training examples, leading to more robust
regression predictions. We apply ADA to linear and nonlinear regression
problems using neural networks. ADA is competitive with state-of-the-art
C-Mixup solutions.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06968" title="Abstract">arXiv:2311.06968</a> [<a href="/pdf/2311.06968" title="Download PDF">pdf</a>, <a href="/format/2311.06968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Informed Data Denoising for Real-Life Sensing Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xiaohan Fu</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+D">Diyan Teng</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+C">Chengyu Dong</a>, 
<a href="/search/cs?searchtype=author&query=Vijayakumar%2C+K">Keerthivasan Vijayakumar</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiayun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+R+R">Ranak Roy Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Junsheng Han</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+D">Dezhi Hong</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+R">Rashmi Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+J">Jingbo Shang</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+R">Rajesh Gupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SenSys 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP); Machine Learning (stat.ML)

</div>
<p class="mathjax">Sensors measuring real-life physical processes are ubiquitous in today's
interconnected world. These sensors inherently bear noise that often adversely
affects performance and reliability of the systems they support. Classic
filtering-based approaches introduce strong assumptions on the time or
frequency characteristics of sensory measurements, while learning-based
denoising approaches typically rely on using ground truth clean data to train a
denoising model, which is often challenging or prohibitive to obtain for many
real-world applications. We observe that in many scenarios, the relationships
between different sensor measurements (e.g., location and acceleration) are
analytically described by laws of physics (e.g., second-order differential
equation). By incorporating such physics constraints, we can guide the
denoising process to improve even in the absence of ground truth data. In light
of this, we design a physics-informed denoising model that leverages the
inherent algebraic relationships between different measurements governed by the
underlying physics. By obviating the need for ground truth clean data, our
method offers a practical denoising solution for real-world applications. We
conducted experiments in various domains, including inertial navigation, CO2
monitoring, and HVAC control, and achieved state-of-the-art performance
compared with existing denoising methods. Our method can denoise data in real
time (4ms for a sequence of 1s) for low-cost noisy sensors and produces results
that closely align with those from high-precision, high-cost alternatives,
leading to an efficient, cost-effective approach for more accurate sensor-based
systems.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06972" title="Abstract">arXiv:2311.06972</a> [<a href="/pdf/2311.06972" title="Download PDF">pdf</a>, <a href="/format/2311.06972" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Expandable Machine Learning-Optimization Framework to Sequential  Decision-Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yilmaz%2C+D">Dogacan Yilmaz</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%BCy%C3%BCktahtak%C4%B1n%2C+%C4%B0+E">&#x130;. Esra B&#xfc;y&#xfc;ktahtak&#x131;n</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We present an integrated prediction-optimization (PredOpt) framework to
efficiently solve sequential decision-making problems by predicting the values
of binary decision variables in an optimal solution. We address the key issues
of sequential dependence, infeasibility, and generalization in machine learning
(ML) to make predictions for optimal solutions to combinatorial problems. The
sequential nature of the combinatorial optimization problems considered is
captured with recurrent neural networks and a sliding-attention window. We
integrate an attention-based encoder-decoder neural network architecture with
an infeasibility-elimination and generalization framework to learn high-quality
feasible solutions to time-dependent optimization problems. In this framework,
the required level of predictions is optimized to eliminate the infeasibility
of the ML predictions. These predictions are then fixed in mixed-integer
programming (MIP) problems to solve them quickly with the aid of a commercial
solver. We demonstrate our approach to tackling the two well-known dynamic
NP-Hard optimization problems: multi-item capacitated lot-sizing (MCLSP) and
multi-dimensional knapsack (MSMK). Our results show that models trained on
shorter and smaller-dimensional instances can be successfully used to predict
longer and larger-dimensional problems. The solution time can be reduced by
three orders of magnitude with an average optimality gap below 0.1%. We compare
PredOpt with various specially designed heuristics and show that our framework
outperforms them. PredOpt can be advantageous for solving dynamic MIP problems
that need to be solved instantly and repetitively.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06973" title="Abstract">arXiv:2311.06973</a> [<a href="/pdf/2311.06973" title="Download PDF">pdf</a>, <a href="/ps/2311.06973" title="Download PostScript">ps</a>, <a href="/format/2311.06973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analytical Verification of Deep Neural Network Performance for  Time-Synchronized Distribution System State Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azimian%2C+B">Behrouz Azimian</a>, 
<a href="/search/cs?searchtype=author&query=Moshtagh%2C+S">Shiva Moshtagh</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+A">Anamitra Pal</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shanshan Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Recently, we demonstrated success of a time-synchronized state estimator
using deep neural networks (DNNs) for real-time unobservable distribution
systems. In this letter, we provide analytical bounds on the performance of
that state estimator as a function of perturbations in the input measurements.
It has already been shown that evaluating performance based on only the test
dataset might not effectively indicate a trained DNN's ability to handle input
perturbations. As such, we analytically verify robustness and trustworthiness
of DNNs to input perturbations by treating them as mixed-integer linear
programming (MILP) problems. The ability of batch normalization in addressing
the scalability limitations of the MILP formulation is also highlighted. The
framework is validated by performing time-synchronized distribution system
state estimation for a modified IEEE 34-node system and a real-world large
distribution system, both of which are incompletely observed by micro-phasor
measurement units.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06974" title="Abstract">arXiv:2311.06974</a> [<a href="/pdf/2311.06974" title="Download PDF">pdf</a>, <a href="/format/2311.06974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Signed Permutations by Twisting Two-Sided Ribbons
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan">Yuan</a> (Friedrich)Qiu, 
<a href="/search/cs?searchtype=author&query=Williams%2C+A">Aaron Williams</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We provide a simple and natural solution to the problem of generating all
$2^n \cdot n!$ signed permutations of $[n] = \{1,2,\ldots,n\}$. Our solution
provides a pleasing generalization of the most famous ordering of permutations:
plain changes (Steinhaus-Johnson-Trotter algorithm). In plain changes, the $n!$
permutations of $[n]$ are ordered so that successive permutations differ by
swapping a pair of adjacent symbols, and the order is often visualized as a
weaving pattern involving $n$ ropes. Here we model a signed permutation using
$n$ ribbons with two distinct sides, and each successive configuration is
created by twisting (i.e., swapping and turning over) two neighboring ribbons
or a single ribbon. By greedily prioritizing $2$-twists of the largest symbol
before $1$-twists of the largest symbol, we create a signed version of plain
change's memorable zig-zag pattern. We provide a loopless algorithm (i.e.,
worst-case $\mathcal{O}(1)$-time per object) by extending the well-known
mixed-radix Gray code algorithm.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06976" title="Abstract">arXiv:2311.06976</a> [<a href="/pdf/2311.06976" title="Download PDF">pdf</a>, <a href="/format/2311.06976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CD-COCO: A Versatile Complex Distorted COCO Database for  Scene-Context-Aware Computer Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beghdadi%2C+A">Ayman Beghdadi</a>, 
<a href="/search/cs?searchtype=author&query=Beghdadi%2C+A">Azeddine Beghdadi</a>, 
<a href="/search/cs?searchtype=author&query=Mallem%2C+M">Malik Mallem</a>, 
<a href="/search/cs?searchtype=author&query=Beji%2C+L">Lotfi Beji</a>, 
<a href="/search/cs?searchtype=author&query=Cheikh%2C+F+A">Faouzi Alaya Cheikh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Databases (cs.DB)

</div>
<p class="mathjax">The recent development of deep learning methods applied to vision has enabled
their increasing integration into real-world applications to perform complex
Computer Vision (CV) tasks. However, image acquisition conditions have a major
impact on the performance of high-level image processing. A possible solution
to overcome these limitations is to artificially augment the training databases
or to design deep learning models that are robust to signal distortions. We opt
here for the first solution by enriching the database with complex and
realistic distortions which were ignored until now in the existing databases.
To this end, we built a new versatile database derived from the well-known
MS-COCO database to which we applied local and global photo-realistic
distortions. These new local distortions are generated by considering the scene
context of the images that guarantees a high level of photo-realism.
Distortions are generated by exploiting the depth information of the objects in
the scene as well as their semantics. This guarantees a high level of
photo-realism and allows to explore real scenarios ignored in conventional
databases dedicated to various CV applications. Our versatile database offers
an efficient solution to improve the robustness of various CV tasks such as
Object Detection (OD), scene segmentation, and distortion-type classification
methods. The image database, scene classification index, and distortion
generation codes are publicly available
\footnote{\url{https://github.com/Aymanbegh/CD-COCO}}
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06978" title="Abstract">arXiv:2311.06978</a> [<a href="/pdf/2311.06978" title="Download PDF">pdf</a>, <a href="/format/2311.06978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augmented Bridge Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Bortoli%2C+V">Valentin De Bortoli</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guan-Horng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianrong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Theodorou%2C+E+A">Evangelos A. Theodorou</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+W">Weilie Nie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
<p class="mathjax">Flow and bridge matching are a novel class of processes which encompass
diffusion models. One of the main aspect of their increased flexibility is that
these models can interpolate between arbitrary data distributions i.e. they
generalize beyond generative modeling and can be applied to learning stochastic
(and deterministic) processes of arbitrary transfer tasks between two given
distributions. In this paper, we highlight that while flow and bridge matching
processes preserve the information of the marginal distributions, they do
\emph{not} necessarily preserve the coupling information unless additional,
stronger optimality conditions are met. This can be problematic if one aims at
preserving the original empirical pairing. We show that a simple modification
of the matching process recovers this coupling by augmenting the velocity field
(or drift) with the information of the initial sample point. Doing so, we lose
the Markovian property of the process but preserve the coupling information
between distributions. We illustrate the efficiency of our augmentation in
learning mixture of image translation tasks.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06979" title="Abstract">arXiv:2311.06979</a> [<a href="/pdf/2311.06979" title="Download PDF">pdf</a>, <a href="/ps/2311.06979" title="Download PostScript">ps</a>, <a href="/format/2311.06979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing the Interpretability of Programmatic Policies with Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bashir%2C+Z">Zahra Bashir</a>, 
<a href="/search/cs?searchtype=author&query=Bowling%2C+M">Michael Bowling</a>, 
<a href="/search/cs?searchtype=author&query=Lelis%2C+L+H+S">Levi H. S. Lelis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is under-review for AAAI. The main file is arxiv.tex and I have a supplementary_materials.tex file as well
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Programming Languages (cs.PL); Software Engineering (cs.SE)

</div>
<p class="mathjax">Although the synthesis of programs encoding policies often carries the
promise of interpretability, systematic evaluations to assess the
interpretability of these policies were never performed, likely because of the
complexity of such an evaluation. In this paper, we introduce a novel metric
that uses large-language models (LLM) to assess the interpretability of
programmatic policies. For our metric, an LLM is given both a program and a
description of its associated programming language. The LLM then formulates a
natural language explanation of the program. This explanation is subsequently
fed into a second LLM, which tries to reconstruct the program from the natural
language explanation. Our metric measures the behavioral similarity between the
reconstructed program and the original. We validate our approach using
obfuscated programs that are used to solve classic programming problems. We
also assess our metric with programmatic policies synthesized for playing a
real-time strategy game, comparing the interpretability scores of programmatic
policies synthesized by an existing system to lightly obfuscated versions of
the same programs. Our LLM-based interpretability score consistently ranks less
interpretable programs lower and more interpretable ones higher. These findings
suggest that our metric could serve as a reliable and inexpensive tool for
evaluating the interpretability of programmatic policies.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06981" title="Abstract">arXiv:2311.06981</a> [<a href="/pdf/2311.06981" title="Download PDF">pdf</a>, <a href="/ps/2311.06981" title="Download PostScript">ps</a>, <a href="/format/2311.06981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Generative AI for Literature Searches and Scholarly Writing: Is  the Integrity of the Scientific Discourse in Jeopardy?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+P+G">Paul G. Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Meir%2C+A+J">Amnon J. Meir</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article, an expanded version of an open letter sent to the leadership of SIAM, AMS, and NSF-MPS on June 1, 2023, is accepted for publication in the Notices of the AMS. Supplementary material, including a comprehensive bibliography, is available at <a href="https://scholar.smu.edu/hum_sci_mathematics_research/9">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; General Mathematics (math.GM); History and Overview (math.HO)

</div>
<p class="mathjax">Ever since the public release of ChatGPT in November 2022, serious concerns
have been raised about the impact and potentially dire consequences of the
increasingly widespread use of generative AI tools for purposes of scientific
writing and publishing. We document the ongoing discussion in the science
community with a review of news articles, editorials, and position statements
by major scientific publishers; discuss the potential pitfalls of using
generative AI tools such as ChatGPT as aids in scholarly writing; furnish
evidence for the proposition that AI-induced contamination of the scientific
literature is not only a threat, but already a reality; and call upon leaders
in our field to develop policies and guidelines to stem the spread of such
contamination. Closing on a positive note, we provide a brief overview of
potentially useful capabilities and sensible applications of ChatGPT and
similar AI tools for purposes of scholarly writing.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06982" title="Abstract">arXiv:2311.06982</a> [<a href="/pdf/2311.06982" title="Download PDF">pdf</a>, <a href="/format/2311.06982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral stability and perturbation results for kernel differentiation  matrices on the sphere
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hangelbroek%2C+T">Thomas Hangelbroek</a>, 
<a href="/search/math?searchtype=author&query=Rieger%2C+C">Christian Rieger</a>, 
<a href="/search/math?searchtype=author&query=Wright%2C+G">Grady Wright</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We investigate the spectrum of differentiation matrices for certain operators
on the sphere that are generated from collocation at a set of scattered points
$X$ with positive definite and conditionally positive definite kernels. We
focus on the case where these matrices are constructed from collocation using
all the points in $X$ and from local subsets of points (or stencils) in $X$.
The former case is often referred to as the global, Kansa, or pseudospectral
method, while the latter is referred to as the local radial basis function
(RBF) finite difference (RBF-FD) method. Both techniques are used extensively
for numerically solving certain partial differential equations (PDEs) on
spheres (and other domains). For time-dependent PDEs on spheres like the
(surface) diffusion equation, the spectrum of the differentiation matrices and
their stability under perturbations are central to understanding the temporal
stability of the underlying numerical schemes.
<br />In the global case, we present a perturbation estimate for differentiation
matrices which discretize operators that commute with the Laplace-Beltrami
operator. In doing so, we demonstrate that if such an operator has negative
(non-positive) spectrum, then the differentiation matrix does, too (i.e., it is
Hurwitz stable). For conditionally positive definite kernels this is
particularly challenging since the differentiation matrices are not necessarily
diagonalizable. This perturbation theory is then used to obtain bounds on the
spectra of the local RBF-FD differentiation matrices based on the conditionally
positive definite surface spline kernels. Numerical results are presented to
confirm the theoretical estimates.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06983" title="Abstract">arXiv:2311.06983</a> [<a href="/pdf/2311.06983" title="Download PDF">pdf</a>, <a href="/format/2311.06983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Different View of Sigma-Delta Modulators Under the Lens of Pulse  Frequency Modulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Medina%2C+V">Victor Medina</a> (1), 
<a href="/search/eess?searchtype=author&query=Rombouts%2C+P">Pieter Rombouts</a> (2), 
<a href="/search/eess?searchtype=author&query=Hernandez%2C+L">Luis Hernandez</a> (1) ((1) Carlos III University, Madrid, Spain. (2) Ghent University, Belgium.)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 28 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The fact that VCO-ADCs produce noise-shaped quantization noise suggests that
a link between frequency modulation and Sigma-Delta modulation should exist.
The connection between a VCO-ADC and a first-order Sigma-Delta modulator has
been already explained using Pulse Frequency Modulation. In this paper, we
attempt to extend the theory based on Pulse Frequency Modulation to a generic
Sigma-Delta modulator. We show that this link between Sigma-Delta modulation
and Pulse Frequency Modulation relies in a sampling invariance property that
defines the equivalence between both entities. This novel point of view, allows
to go beyond the white quantization noise model of a Sigma-Delta modulator,
revealing the origin of some nonlinear phenomena. We first predict spurious
tones which cannot be explained by circuit non linearity. Multi-bit and single
bit modulators are shown to belong to a same generic class of systems. Finally,
quantizer overload is analyzed using our model. The results are applied to
Continuous-Time Sigma-Delta modulators of orders one, two and three and then
extended to a generic case.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06984" title="Abstract">arXiv:2311.06984</a> [<a href="/pdf/2311.06984" title="Download PDF">pdf</a>, <a href="/format/2311.06984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pipelines and Beyond: Graph Types for ADTs with Futures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rinaldi%2C+F">Francis Rinaldi</a>, 
<a href="/search/cs?searchtype=author&query=wunder%2C+j">june wunder</a>, 
<a href="/search/cs?searchtype=author&query=De+Amorim%2C+A+A">Arthur Aevedo De Amorim</a>, 
<a href="/search/cs?searchtype=author&query=Muller%2C+S+K">Stefan K. Muller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 65 pages, 41 figures, submitted to POPL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Parallel programs are frequently modeled as dependency or cost graphs, which
can be used to detect various bugs, or simply to visualize the parallel
structure of the code. However, such graphs reflect just one particular
execution and are typically constructed in a post-hoc manner. Graph types,
which were introduced recently to mitigate this problem, can be assigned
statically to a program by a type system and compactly represent the family of
all graphs that could result from the program. Unfortunately, prior work is
restricted in its treatment of futures, an increasingly common and especially
dynamic form of parallelism. In short, each instance of a future must be
statically paired with a vertex name. Previously, this led to the restriction
that futures could not be placed in collections or be used to construct data
structures. Doing so is not a niche exercise: such structures form the basis of
numerous algorithms that use forms of pipelining to achieve performance not
attainable without futures. All but the most limited of these examples are out
of reach of prior graph type systems. In this paper, we propose a graph type
system that allows for almost arbitrary combinations of futures and recursive
data types. We do so by indexing datatypes with a type-level vertex structure,
a codata structure that supplies unique vertex names to the futures in a data
structure. We prove the soundness of the system in a parallel core calculus
annotated with vertex structures and associated operations. Although the
calculus is annotated, this is merely for convenience in defining the type
system. We prove that it is possible to annotate arbitrary recursive types with
vertex structures, and show using a prototype inference engine that these
annotations can be inferred from OCaml-like source code for several complex
parallel algorithms.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06985" title="Abstract">arXiv:2311.06985</a> [<a href="/pdf/2311.06985" title="Download PDF">pdf</a>, <a href="/format/2311.06985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SELF-EXPLAIN: Teaching Large Language Models to Reason Complex Questions  by Themselves
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiachen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Z">Zonghai Yao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhichao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hong Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Workshop on robustness of zero/few-shot learning in foundation models @ NeurIPS 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Workshop on robustness of zero/few-shot learning in foundation
  models, NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) can generate intermediate reasoning steps. To
elicit the reliable reasoning, the common practice is to employ few-shot
chain-of-thought prompting, where several in-context demonstrations for
reasoning are prepended to the question. However, such chain-of-thought
examples are expensive to craft, especially for professional domains, and can
have high variance depending on human annotators. Therefore, this work
investigates whether LLMs can teach themselves to reason without human-crafted
demonstrations. We propose SELF-EXPLAIN to generate CoT examples by LLMs
inspired by "encoding specificity" in human memory retrieval. We find using
self-explanations makes LLMs more confident, more calibrated and less biased
when answering complex questions. Moreover, we find prompting with
self-explanations can even significantly outperform using human-crafted CoTs on
several complex question answering dataset.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06989" title="Abstract">arXiv:2311.06989</a> [<a href="/pdf/2311.06989" title="Download PDF">pdf</a>, <a href="/ps/2311.06989" title="Download PostScript">ps</a>, <a href="/format/2311.06989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Creating a Discipline-specific Commons for Infectious Disease  Epidemiology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wagner%2C+M+M">Michael M. Wagner</a>, 
<a href="/search/cs?searchtype=author&query=Hogan%2C+W">William Hogan</a>, 
<a href="/search/cs?searchtype=author&query=Levander%2C+J">John Levander</a>, 
<a href="/search/cs?searchtype=author&query=Darr%2C+A">Adam Darr</a>, 
<a href="/search/cs?searchtype=author&query=Diller%2C+M">Matt Diller</a>, 
<a href="/search/cs?searchtype=author&query=Sibilla%2C+M">Max Sibilla</a>, 
<a href="/search/cs?searchtype=author&query=Sperringer%2C+A+T+L+T">Alexander T. Loiacono. Terence Sperringer, Jr.</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+S+T">Shawn T. Brown</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Objective: To create a commons for infectious disease (ID) epidemiology in
which epidemiologists, public health officers, data producers, and software
developers can not only share data and software, but receive assistance in
improving their interoperability. Materials and Methods: We represented 586
datasets, 54 software, and 24 data formats in OWL 2 and then used logical
queries to infer potentially interoperable combinations of software and
datasets, as well as statistics about the FAIRness of the collection. We
represented the objects in DATS 2.2 and a software metadata schema of our own
design. We used these representations as the basis for the Content, Search,
FAIR-o-meter, and Workflow pages that constitute the MIDAS Digital Commons.
Results: Interoperability was limited by lack of standardization of input and
output formats of software. When formats existed, they were human-readable
specifications (22/24; 92%); only 3 formats (13%) had machine-readable
specifications. Nevertheless, logical search of a triple store based on named
data formats was able to identify scores of potentially interoperable
combinations of software and datasets. Discussion: We improved the findability
and availability of a sample of software and datasets and developed metrics for
assessing interoperability. The barriers to interoperability included poor
documentation of software input/output formats and little attention to
standardization of most types of data in this field. Conclusion: Centralizing
and formalizing the representation of digital objects within a commons promotes
FAIRness, enables its measurement over time and the identification of
potentially interoperable combinations of data and software.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06991" title="Abstract">arXiv:2311.06991</a> [<a href="/pdf/2311.06991" title="Download PDF">pdf</a>, <a href="/format/2311.06991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Managing Large Enclaves in a Data Center
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sandeep Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Sarangi%2C+S+R">Smruti R. Sarangi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Live migration of an application or VM is a well-known technique for load
balancing, performance optimization, and resource management. To minimize the
total downtime during migration, two popular methods -- pre-copy or post-copy
-- are used in practice. These methods scale to large VMs and applications
since the downtime is independent of the memory footprint of an application.
However, in a secure, trusted execution environment (TEE) like Intel's scalable
SGX, the state-of-the-art still uses the decade-old stop-and-copy method, where
the total downtime is proportional to the application's memory footprint. This
is primarily due to the fact that TEEs like Intel SGX do not expose memory and
page table accesses to the OS, quite unlike unsecure applications. However,
with modern TEE solutions that efficiently support large applications, such as
Intel's Scalable SGX and AMD's Epyc, it is high time that TEE migration methods
also evolve to enable live migration of large TEE applications with minimal
downtime (stop-and-copy cannot be used any more). We present OptMig, an
end-to-end solution for live migrating large memory footprints in TEE-enabled
applications. Our approach does not require a developer to modify the
application; however, we need a short, separate compilation pass and
specialized software library support. Our optimizations reduce the total
downtime by 98% for a representative microbenchmark that uses 20GB of secure
memory and by 90 -- 96% for a suite of Intel SGX applications that have
multi-GB memory footprints.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06992" title="Abstract">arXiv:2311.06992</a> [<a href="/pdf/2311.06992" title="Download PDF">pdf</a>, <a href="/format/2311.06992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ball-AR: Fostering Playful Co-Located Interaction Through  Environment-centric Physical Activity with AR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Arnav Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Monroy-Hern%C3%A1ndez%2C+A">Andr&#xe9;s Monroy-Hern&#xe1;ndez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">We present Ball-AR, an augmented reality (AR) game where two players in the
same physical space attempt to hit each other with virtual dodgeballs overlaid
on the physical world. Researchers have studied AR's potential for fostering
co-located interaction and physical activity; however, they have not
investigated the impacts of physical activity and physical environment on user
experiences and interaction. We created an AR dodgeball game centered around
encouraging physical activity and harnessing the physical environment. We then
evaluated the game with five dyads to analyze the impacts of these design
choices on the quality of gameplay and interaction between players. We found
that physical activity and the shared physical space created memorable
experiences and interactions among participants, although participants desired
a more augmented and immersive experience.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06993" title="Abstract">arXiv:2311.06993</a> [<a href="/pdf/2311.06993" title="Download PDF">pdf</a>, <a href="/format/2311.06993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> State-of-the-Art Review and Synthesis: A Requirement-based Roadmap for  Standardized Predictive Maintenance Automation Using Digital Twin  Technologies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Sizhe Ma</a>, 
<a href="/search/cs?searchtype=author&query=Flanigan%2C+K+A">Katherine A. Flanigan</a>, 
<a href="/search/cs?searchtype=author&query=Berg%C3%A9s%2C+M">Mario Berg&#xe9;s</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> (1)This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Recent digital advances have popularized predictive maintenance (PMx),
offering enhanced efficiency, automation, accuracy, cost savings, and
independence in maintenance. Yet, it continues to face numerous limitations
such as poor explainability, sample inefficiency of data-driven methods,
complexity of physics-based methods, and limited generalizability and
scalability of knowledge-based methods. This paper proposes leveraging Digital
Twins (DTs) to address these challenges and enable automated PMx adoption at
larger scales. While we argue that DTs have this transformative potential, they
have not yet reached the level of maturity needed to bridge these gaps in a
standardized way. Without a standard definition for such evolution, this
transformation lacks a solid foundation upon which to base its development.
This paper provides a requirement-based roadmap supporting standardized PMx
automation using DT technologies. A systematic approach comprising two primary
stages is presented. First, we methodically identify the Informational
Requirements (IRs) and Functional Requirements (FRs) for PMx, which serve as a
foundation from which any unified framework must emerge. Our approach to
defining and using IRs and FRs to form the backbone of any PMx DT is supported
by the track record of IRs and FRs being successfully used as blueprints in
other areas, such as for product development within the software industry.
Second, we conduct a thorough literature review spanning fields to determine
the ways in which these IRs and FRs are currently being used within DTs,
enabling us to point to the specific areas where further research is warranted
to support the progress and maturation of requirement-based PMx DTs.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06995" title="Abstract">arXiv:2311.06995</a> [<a href="/pdf/2311.06995" title="Download PDF">pdf</a>, <a href="/format/2311.06995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Delivery of Scalable Libraries and Tools: How ECP Delivered a  Software Ecosystem for Exascale and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heroux%2C+M+A">Michael A. Heroux</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures, submitted to IEEE Computing in Science and Engineering
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">The Exascale Computing Project (ECP) was one of the largest open-source
scientific software development projects ever. It supported approximately 1,000
staff from US Department of Energy laboratories, and university and industry
partners. About 250 staff contributed to 70 scientific libraries and tools to
support applications on multiple exascale computing systems that were also
under development.
<br />Funded as a construction project, ECP adopted an earned-value management
system, based on milestones. and a key performance parameter system based, in
part, on integrations. With accelerated delivery schedules and significant
project risk, we also emphasized software quality using community policies,
automated testing, and continuous integration. Software Development Kit teams
provided cross-team collaboration. Products were delivered via E4S, a curated
portfolio of libraries and tools.
<br />In this paper, we discuss the organizational and management elements that
enabled the efficient and effective delivery of ECP libraries and tools,
lessons learned and next steps.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06996" title="Abstract">arXiv:2311.06996</a> [<a href="/pdf/2311.06996" title="Download PDF">pdf</a>, <a href="/format/2311.06996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AGRAMPLIFIER: Defending Federated Learning Against Poisoning Attacks  Through Local Update Amplification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+Z">Zirui Gong</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Liyue Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L+Y">Leo Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+G">Guangdong Bai</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+Y">Yong Xiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The collaborative nature of federated learning (FL) poses a major threat in
the form of manipulation of local training data and local updates, known as the
Byzantine poisoning attack. To address this issue, many Byzantine-robust
aggregation rules (AGRs) have been proposed to filter out or moderate
suspicious local updates uploaded by Byzantine participants.
<br />This paper introduces a novel approach called AGRAMPLIFIER, aiming to
simultaneously improve the robustness, fidelity, and efficiency of the existing
AGRs. The core idea of AGRAMPLIFIER is to amplify the "morality" of local
updates by identifying the most repressive features of each gradient update,
which provides a clearer distinction between malicious and benign updates,
consequently improving the detection effect. To achieve this objective, two
approaches, namely AGRMP and AGRXAI, are proposed. AGRMP organizes local
updates into patches and extracts the largest value from each patch, while
AGRXAI leverages explainable AI methods to extract the gradient of the most
activated features. By equipping AGRAMPLIFIER with the existing
Byzantine-robust mechanisms, we successfully enhance the model's robustness,
maintaining its fidelity and improving overall efficiency.
<br />AGRAMPLIFIER is universally compatible with the existing Byzantine-robust
mechanisms. The paper demonstrates its effectiveness by integrating it with all
mainstream AGR mechanisms. Extensive evaluations conducted on seven datasets
from diverse domains against seven representative poisoning attacks
consistently show enhancements in robustness, fidelity, and efficiency, with
average gains of 40.08%, 39.18%, and 10.68%, respectively.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06998" title="Abstract">arXiv:2311.06998</a> [<a href="/pdf/2311.06998" title="Download PDF">pdf</a>, <a href="/format/2311.06998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Privacy Pillar -- A Conceptual Framework for Foundation Model-based  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bi%2C+T">Tingting Bi</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Guangsheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Q">Qinghua Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Van+Beest%2C+N">Nick Van Beest</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">AI and its relevant technologies, including machine learning, deep learning,
chatbots, virtual assistants, and others, are currently undergoing a profound
transformation of development and organizational processes within companies.
Foundation models present both significant challenges and incredible
opportunities. In this context, ensuring the quality attributes of foundation
model-based systems is of paramount importance, and with a particular focus on
the challenging issue of privacy due to the sensitive nature of the data and
information involved. However, there is currently a lack of consensus regarding
the comprehensive scope of both technical and non-technical issues that the
privacy evaluation process should encompass. Additionally, there is uncertainty
about which existing methods are best suited to effectively address these
privacy concerns. In response to this challenge, this paper introduces a novel
conceptual framework that integrates various responsible AI patterns from
multiple perspectives, with the specific aim of safeguarding privacy.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07001" title="Abstract">arXiv:2311.07001</a> [<a href="/pdf/2311.07001" title="Download PDF">pdf</a>, <a href="/format/2311.07001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling the impact of extreme summer drought on conventional and  renewable generation capacity: methods and a case study on the Eastern U.S.  power system
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shuai%2C+H">Hang Shuai</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+F">Fangxing Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+J">Jinxiang Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Tingen%2C+W+J">William Jerome Tingen II</a>, 
<a href="/search/eess?searchtype=author&query=Mukherjee%2C+S">Srijib Mukherjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The United States has witnessed a growing prevalence of droughts in recent
years, posing significant challenges to water supplies and power generation.
The resulting impacts on power systems, including reduced capacity and the
potential for power outages, underscore the need for accurate assessment
methods to ensure the reliable operation of the nation's energy infrastructure.
A critical step is to evaluate the usable capacity of a regional power system's
generation fleet, which is a complex undertaking and requires precise modeling
of the effects of hydrological and meteorological conditions on diverse
generating technologies. This paper proposes a systematic, analytical approach
for assessing the impacts of extreme summer drought events on the available
capacity of hydro, thermal, and renewable energy generators. More specifically,
the systematic framework provides plant-level capacity derating models for
hydroelectric, once-through cooling thermoelectric, recirculating cooling
thermoelectric, combustion turbine, solar PV, and wind turbine systems.
Application of the proposed impact assessment framework to the 2025 generation
fleet of the real-world power system in the PJM and SERC regions yields
insightful results. By examining the daily usable capacity of 6,055 at-risk
generators throughout the study region, we find that in the event of the
recurrence of the 2007 southeastern summer drought in the near future, the
usable capacity of all at-risk power plants may experience a substantial
decrease compared to a typical summer, falling within the range of 71% to 81%.
The sensitivity analysis reveals that the usable capacity would experience a
more pronounced decline under more severe drought conditions. The findings of
this study offer valuable insights, enabling stakeholders to enhance the
resilience of power systems against the potential effects of extreme drought in
the future.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07002" title="Abstract">arXiv:2311.07002</a> [<a href="/pdf/2311.07002" title="Download PDF">pdf</a>, <a href="/format/2311.07002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PICS in Pics: Physics Informed Contour Selection for Rapid Image  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dwivedi%2C+V">Vikas Dwivedi</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+B">Balaji Srinivasan</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamurthi%2C+G">Ganapathy Krishnamurthi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Effective training of deep image segmentation models is challenging due to
the need for abundant, high-quality annotations. Generating annotations is
laborious and time-consuming for human experts, especially in medical image
segmentation. To facilitate image annotation, we introduce Physics Informed
Contour Selection (PICS) - an interpretable, physics-informed algorithm for
rapid image segmentation without relying on labeled data. PICS draws
inspiration from physics-informed neural networks (PINNs) and an active contour
model called snake. It is fast and computationally lightweight because it
employs cubic splines instead of a deep neural network as a basis function. Its
training parameters are physically interpretable because they directly
represent control knots of the segmentation curve. Traditional snakes involve
minimization of the edge-based loss functionals by deriving the Euler-Lagrange
equation followed by its numerical solution. However, PICS directly minimizes
the loss functional, bypassing the Euler Lagrange equations. It is the first
snake variant to minimize a region-based loss function instead of traditional
edge-based loss functions. PICS uniquely models the three-dimensional (3D)
segmentation process with an unsteady partial differential equation (PDE),
which allows accelerated segmentation via transfer learning. To demonstrate its
effectiveness, we apply PICS for 3D segmentation of the left ventricle on a
publicly available cardiac dataset. While doing so, we also introduce a new
convexity-preserving loss term that encodes the shape information of the left
ventricle to enhance PICS's segmentation quality. Overall, PICS presents
several novelties in network architecture, transfer learning, and
physics-inspired losses for image segmentation, thereby showing promising
outcomes and potential for further refinement.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07004" title="Abstract">arXiv:2311.07004</a> [<a href="/pdf/2311.07004" title="Download PDF">pdf</a>, <a href="/ps/2311.07004" title="Download PostScript">ps</a>, <a href="/format/2311.07004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Task Scheduling for Virtual Machines in the Cloud based on the  Gravitational Search Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mamalis%2C+B">Basilis Mamalis</a>, 
<a href="/search/cs?searchtype=author&query=Perlitis%2C+M">Marios Perlitis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Computer Applications (IJCA), Vol. 184,
  No. 40, pp. 41-48, 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">The rapid and convenient provision of the available computing resources is a
crucial requirement in modern cloud computing environments. However, if only
the execution time is taken into account when the resources are scheduled, it
could lead to imbalanced workloads as well as to significant under-utilisation
of the involved Virtual Machines (VMs). In the present work a novel task
scheduling scheme is introduced, which is based on the proper adaptation of a
modern and quite effective evolutionary optimization method, the Gravitational
Search Algorithm (GSA). The proposed scheme aims at optimizing the entire
scheduling procedure, in terms of both the tasks execution time and the system
(VMs) resource utilisation. Moreover, the fitness function was properly
selected considering both the above factors in an appropriately weighted
function in order to obtain better results for large inputs. Sufficient
simulation experiments show the efficiency of the proposed scheme, as well as
its excellence over related approaches of the bibliography, with similar
objectives.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07006" title="Abstract">arXiv:2311.07006</a> [<a href="/pdf/2311.07006" title="Download PDF">pdf</a>, <a href="/format/2311.07006" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-dependent Instruction Tuning for Dialogue Response Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kwak%2C+J+M">Jin Myung Kwak</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minseon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+S+J">Sung Ju Hwang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in Progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent language models have achieved impressive performance in natural
language tasks by incorporating instructions with task input during
fine-tuning. Since all samples in the same natural language task can be
explained with the same task instructions, many instruction datasets only
provide a few instructions for the entire task, without considering the input
of each example in the task. However, this approach becomes ineffective in
complex multi-turn dialogue generation tasks, where the input varies highly
with each turn as the dialogue context changes, so that simple task
instructions cannot improve the generation performance. To address this
limitation, we introduce a context-based instruction fine-tuning framework for
each multi-turn dialogue which generates both responses and instructions based
on the previous context as input. During the evaluation, the model generates
instructions based on the previous context to self-guide the response. The
proposed framework produces comparable or even outstanding results compared to
the baselines by aligning instructions to the input during fine-tuning with the
instructions in quantitative evaluations on dialogue benchmark datasets with
reduced computation budget.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07007" title="Abstract">arXiv:2311.07007</a> [<a href="/pdf/2311.07007" title="Download PDF">pdf</a>, <a href="/ps/2311.07007" title="Download PostScript">ps</a>, <a href="/format/2311.07007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizations of Minimal Expected Length Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Congero%2C+S">Spencer Congero</a>, 
<a href="/search/cs?searchtype=author&query=Zeger%2C+K">Kenneth Zeger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">A property of prefix codes called strong monotonicity is introduced. Then it
is proven that for a prefix code $C$ for a given probability distribution, the
following are equivalent: (i) $C$ is expected length minimal; (ii) $C$ is
length equivalent to a Huffman code; and (iii) $C$ is complete and strongly
monotone. Also, three relations are introduced between prefix code trees called
same-parent, same-row, and same-probability swap equivalence, and it is shown
that for a given source, all Huffman codes are same-parent, same-probability
swap equivalent, and all expected length minimal prefix codes are same-row,
same-probability swap equivalent.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07009" title="Abstract">arXiv:2311.07009</a> [<a href="/pdf/2311.07009" title="Download PDF">pdf</a>, <a href="/ps/2311.07009" title="Download PostScript">ps</a>, <a href="/format/2311.07009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Competitive Advantage of Huffman and Shannon-Fano Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Congero%2C+S">Spencer Congero</a>, 
<a href="/search/cs?searchtype=author&query=Zeger%2C+K">Kenneth Zeger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">For any finite discrete source, the competitive advantage of prefix code
$C_1$ over prefix code $C_2$ is the probability $C_1$ produces a shorter
codeword than $C_2$, minus the probability $C_2$ produces a shorter codeword
than $C_1$. For any source, a prefix code is competitively optimal if it has a
nonnegative competitive advantage over all other prefix codes. In 1991, Cover
proved that Huffman codes are competitively optimal for all dyadic sources. We
prove the following asymptotic converse: As the source size grows, the
probability a Huffman code for a randomly chosen non-dyadic source is
competitively optimal converges to zero. We also prove: (i) For any source,
competitively optimal codes cannot exist unless a Huffman code is competitively
optimal; (ii) For any non-dyadic source, a Huffman code has a positive
competitive advantage over a Shannon-Fano code; (iii) For any source, the
competitive advantage of any prefix code over a Huffman code is strictly less
than $\frac{1}{3}$; (iv) For each integer $n&gt;3$, there exists a source of size
$n$ and some prefix code whose competitive advantage over a Huffman code is
arbitrarily close to $\frac{1}{3}$; and (v) For each positive integer $n$,
there exists a source of size $n$ and some prefix code whose competitive
advantage over a Shannon-Fano code becomes arbitrarily close to $1$ as
$n\longrightarrow\infty$.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07014" title="Abstract">arXiv:2311.07014</a> [<a href="/pdf/2311.07014" title="Download PDF">pdf</a>, <a href="/format/2311.07014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Teach me with a Whisper: Enhancing Large Language Models for Analyzing  Spoken Transcripts using Speech Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hasan%2C+F">Fatema Hasan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yulong Li</a>, 
<a href="/search/cs?searchtype=author&query=Foulds%2C+J">James Foulds</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shimei Pan</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharjee%2C+B">Bishwaranjan Bhattacharjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Speech data has rich acoustic and paralinguistic information with important
cues for understanding a speaker's tone, emotion, and intent, yet traditional
large language models such as BERT do not incorporate this information. There
has been an increased interest in multi-modal language models leveraging audio
and/or visual information and text. However, current multi-modal language
models require both text and audio/visual data streams during inference/test
time. In this work, we propose a methodology for training language models
leveraging spoken language audio data but without requiring the audio stream
during prediction time. This leads to an improved language model for analyzing
spoken transcripts while avoiding an audio processing overhead at test time. We
achieve this via an audio-language knowledge distillation framework, where we
transfer acoustic and paralinguistic information from a pre-trained speech
embedding (OpenAI Whisper) teacher model to help train a student language model
on an audio-text dataset. In our experiments, the student model achieves
consistent improvement over traditional language models on tasks analyzing
spoken transcripts.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07016" title="Abstract">arXiv:2311.07016</a> [<a href="/pdf/2311.07016" title="Download PDF">pdf</a>, <a href="/format/2311.07016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximum Flow on Highly Dynamic Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Juntong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Sallinen%2C+S">Scott Sallinen</a>, 
<a href="/search/cs?searchtype=author&query=Ripeanu%2C+M">Matei Ripeanu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Recent advances in dynamic graph processing have enabled the analysis of
highly dynamic graphs with change at rates as high as millions of edge changes
per second. Solutions in this domain, however, have been demonstrated only for
relatively simple algorithms like PageRank, breadth-first search, and connected
components. Expanding beyond this, we explore the maximum flow problem, a
fundamental, yet more complex problem, in graph analytics. We propose a novel,
distributed algorithm for max-flow on dynamic graphs, and implement it on top
of an asynchronous vertex-centric abstraction. We show that our algorithm can
process both additions and deletions of vertices and edges efficiently at scale
on fast-evolving graphs, and provide a comprehensive analysis by evaluating, in
addition to throughput, two criteria that are important when applied to
real-world problems: result latency and solution stability.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07022" title="Abstract">arXiv:2311.07022</a> [<a href="/pdf/2311.07022" title="Download PDF">pdf</a>, <a href="/format/2311.07022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ViLMA: A Zero-Shot Benchmark for Linguistic and Temporal Grounding in  Video-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kesen%2C+I">Ilker Kesen</a>, 
<a href="/search/cs?searchtype=author&query=Pedrotti%2C+A">Andrea Pedrotti</a>, 
<a href="/search/cs?searchtype=author&query=Dogan%2C+M">Mustafa Dogan</a>, 
<a href="/search/cs?searchtype=author&query=Cafagna%2C+M">Michele Cafagna</a>, 
<a href="/search/cs?searchtype=author&query=Acikgoz%2C+E+C">Emre Can Acikgoz</a>, 
<a href="/search/cs?searchtype=author&query=Parcalabescu%2C+L">Letitia Parcalabescu</a>, 
<a href="/search/cs?searchtype=author&query=Calixto%2C+I">Iacer Calixto</a>, 
<a href="/search/cs?searchtype=author&query=Frank%2C+A">Anette Frank</a>, 
<a href="/search/cs?searchtype=author&query=Gatt%2C+A">Albert Gatt</a>, 
<a href="/search/cs?searchtype=author&query=Erdem%2C+A">Aykut Erdem</a>, 
<a href="/search/cs?searchtype=author&query=Erdem%2C+E">Erkut Erdem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. 48 pages, 22 figures, 10 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">With the ever-increasing popularity of pretrained Video-Language Models
(VidLMs), there is a pressing need to develop robust evaluation methodologies
that delve deeper into their visio-linguistic capabilities. To address this
challenge, we present ViLMA (Video Language Model Assessment), a task-agnostic
benchmark that places the assessment of fine-grained capabilities of these
models on a firm footing. Task-based evaluations, while valuable, fail to
capture the complexities and specific temporal aspects of moving images that
VidLMs need to process. Through carefully curated counterfactuals, ViLMA offers
a controlled evaluation suite that sheds light on the true potential of these
models, as well as their performance gaps compared to human-level
understanding. ViLMA also includes proficiency tests, which assess basic
capabilities deemed essential to solving the main counterfactual tests. We show
that current VidLMs' grounding abilities are no better than those of
vision-language models which use static images. This is especially striking
once the performance on proficiency tests is factored in. Our benchmark serves
as a catalyst for future research on VidLMs, helping to highlight areas that
still need to be explored.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07025" title="Abstract">arXiv:2311.07025</a> [<a href="/pdf/2311.07025" title="Download PDF">pdf</a>, <a href="/format/2311.07025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Embarassingly Simple Dataset Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yunzhen%2C+F">Feng Yunzhen</a>, 
<a href="/search/cs?searchtype=author&query=Ramakrishna%2C+V">Vedantam Ramakrishna</a>, 
<a href="/search/cs?searchtype=author&query=Julia%2C+K">Kempe Julia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Short version appears at NeurIPS 2023 WANT workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Dataset distillation extracts a small set of synthetic training samples from
a large dataset with the goal of achieving competitive performance on test data
when trained on this sample. In this work, we tackle dataset distillation at
its core by treating it directly as a bilevel optimization problem.
Re-examining the foundational back-propagation through time method, we study
the pronounced variance in the gradients, computational burden, and long-term
dependencies. We introduce an improved method: Random Truncated Backpropagation
Through Time (RaT-BPTT) to address them. RaT-BPTT incorporates a truncation
coupled with a random window, effectively stabilizing the gradients and
speeding up the optimization while covering long dependencies. This allows us
to establish new state-of-the-art for a variety of standard dataset benchmarks.
A deeper dive into the nature of distilled data unveils pronounced
intercorrelation. In particular, subsets of distilled datasets tend to exhibit
much worse performance than directly distilled smaller datasets of the same
size. Leveraging RaT-BPTT, we devise a boosting mechanism that generates
distilled datasets that contain subsets with near optimal performance across
different data budgets.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07027" title="Abstract">arXiv:2311.07027</a> [<a href="/pdf/2311.07027" title="Download PDF">pdf</a>, <a href="/format/2311.07027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust softmax aggregation on blockchain based federated learning with  convergence guarantee
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Huiyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Klabjan%2C+D">Diego Klabjan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Blockchain based federated learning is a distributed learning scheme that
allows model training without participants sharing their local data sets, where
the blockchain components eliminate the need for a trusted central server
compared to traditional Federated Learning algorithms. In this paper we propose
a softmax aggregation blockchain based federated learning framework. First, we
propose a new blockchain based federated learning architecture that utilizes
the well-tested proof-of-stake consensus mechanism on an existing blockchain
network to select validators and miners to aggregate the participants' updates
and compute the blocks. Second, to ensure the robustness of the aggregation
process, we design a novel softmax aggregation method based on approximated
population loss values that relies on our specific blockchain architecture.
Additionally, we show our softmax aggregation technique converges to the global
minimum in the convex setting with non-restricting assumptions. Our
comprehensive experiments show that our framework outperforms existing robust
aggregation algorithms in various settings by large margins.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07029" title="Abstract">arXiv:2311.07029</a> [<a href="/pdf/2311.07029" title="Download PDF">pdf</a>, <a href="/ps/2311.07029" title="Download PostScript">ps</a>, <a href="/format/2311.07029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accurate Time-segmented Loss Model for SiC MOSFETs in Electro-thermal  Multi-Rate Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zheng%2C+J">Jialin Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+Z">Zhengming Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+H">Han Xu</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+W">Weicheng Liu</a>, 
<a href="/search/eess?searchtype=author&query=Zeng%2C+Y">Yangbin Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Compared with silicon (Si) power devices, Silicon carbide (SiC) devices have
the advantages of fast switching speed and low on-resistance. However, the
effects of non-ideal characteristics of SiC MOSFETs and stray parameters
(especially parasitic inductance) on switching losses need to be further
evaluated. In this paper, a transient loss model based on SiC MOSFET and SiC
Schottky barrier diode (SBD) switching pairs is proposed. The transient process
analysis is simplified by time segmentation of the transient process of power
switching devices. The electro-thermal simulation calculates the junction
temperature and updates the temperature-related parameters with the proposed
loss model and the thermal network model. A multi-rate data exchange strategy
is proposed to solve the problem of disparity in timescales between circuit
simulation and thermal network simulation. The CREE CMF20120D SiC MOSFET device
is used for the experimental verification. The experimental results verify the
accuracy of the model which provides guidance for the circuit design of SiC
MOSFETs. All the parameters of the loss model can be extracted from the
datasheet, which is practical in power electronics design.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07032" title="Abstract">arXiv:2311.07032</a> [<a href="/pdf/2311.07032" title="Download PDF">pdf</a>, <a href="/format/2311.07032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ExpNote: Black-box Large Language Models are Better Task Solvers with  Experience Notebook
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wangtao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xuanqing Yu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+S">Shizhu He</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Black-box Large Language Models (LLMs) have shown great power in solving
various tasks and are considered general problem solvers. However, LLMs still
fail in many specific tasks although understand the task instruction. In this
paper, we focus on the problem of boosting the ability of black-box LLMs to
solve downstream tasks. We propose ExpNote, an automated framework to help LLMs
better adapt to unfamiliar tasks through reflecting and noting experiences from
training data and retrieving them from external memory during testing. We
evaluate ExpNote on multiple tasks and the experimental results demonstrate
that the proposed method significantly improves the performance of black-box
LLMs. The data and code are available at
https://github.com/forangel2014/ExpNote
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07035" title="Abstract">arXiv:2311.07035</a> [<a href="/pdf/2311.07035" title="Download PDF">pdf</a>, <a href="/format/2311.07035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ContHutch++: Stochastic trace estimation for implicit integral operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zvonek%2C+J">Jennifer Zvonek</a>, 
<a href="/search/math?searchtype=author&query=Horning%2C+A">Andrew Horning</a>, 
<a href="/search/math?searchtype=author&query=Townsend%2C+A">Alex Townsend</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Hutchinson's estimator is a randomized algorithm that computes an
$\epsilon$-approximation to the trace of any positive semidefinite matrix using
$\mathcal{O}(1/\epsilon^2)$ matrix-vector products. An improvement of
Hutchinson's estimator, known as Hutch++, only requires
$\mathcal{O}(1/\epsilon)$ matrix-vector products. In this paper, we propose a
generalization of Hutch++, which we call ContHutch++, that uses
operator-function products to efficiently estimate the trace of any trace-class
integral operator. Our ContHutch++ estimates avoid spectral artifacts
introduced by discretization and are accompanied by rigorous high-probability
error bounds. We use ContHutch++ to derive a new high-order accurate algorithm
for quantum density-of-states and also show how it can estimate electromagnetic
fields induced by incoherent sources.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07036" title="Abstract">arXiv:2311.07036</a> [<a href="/pdf/2311.07036" title="Download PDF">pdf</a>, <a href="/ps/2311.07036" title="Download PostScript">ps</a>, <a href="/format/2311.07036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Event-Based Synchronization Framework for Controller  Hardware-in-the-loop Simulation of Electric Railway Power Electronics Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zheng%2C+J">Jialin Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Zeng%2C+Y">Yangbin Zeng</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+H">Han Xu</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+W">Weicheng Liu</a>, 
<a href="/search/eess?searchtype=author&query=Mou%2C+D">Di Mou</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+Z">Zhengming Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The Controller Hardware_in_the_loop (CHIL) simulation is gaining popularity
as a cost_effective, efficient, and reliable tool in the design and development
process of fast_growing electrified transportation power converters. However,
it is challenging to implement the conventional CHIL simulations on the railway
power converters with complex topologies and high switching frequencies due to
strict real_time constraints. Therefore, this paper proposes an event-based
synchronization CHIL (ES_CHIL) framework for high_fidelity simulation of these
electrified railway power converters. Different from conventional CHIL
simulations synchronized through the time axis, the ES_CHIL framework is
synchronized through the event axis. Therefore, it can ease the real_time
constraint and broaden the upper bound on the system size and switching
frequency. Besides, models and algorithms with higher accuracy, such as the
diode model with natural commutation processes, can be used in the ES-CHIL
framework. The proposed framework is validated for a 350 kW wireless power
transformer system containing 24 fully controlled devices and 36 diodes by
comparing it with Simulink and physical experiments. This research improves the
fidelity and application range of the power converters CHIL simulation. Thus,
it helps to accelerate the prototype design and performance evaluation process
for electrified railways and other applications with such complex converters.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07039" title="Abstract">arXiv:2311.07039</a> [<a href="/pdf/2311.07039" title="Download PDF">pdf</a>, <a href="/format/2311.07039" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-Optimal Control for High-Order Chain-of-Integrators Systems with  Full State Constraints and Arbitrary Terminal States
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yunan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+C">Chuxiong Hu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zeyang Li</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+S">Shize Lin</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+S">Suqin He</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Ze Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+Y">Yu Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Time-optimal control for high-order chain-of-integrators systems with full
state constraints and arbitrary given terminal states remains a challenging
problem in the optimal control theory domain, yet to be resolved. To enhance
further comprehension of the problem, this paper establishes a novel notation
system and theoretical framework, successfully providing the switching manifold
for high-order problems in the form of switching law. Through deriving
properties of switching laws on signs and dimension, this paper proposes a
definite condition for time-optimal control. Guided by the developed theory, a
trajectory planning method named the manifold-intercept method (MIM) is
developed. The proposed MIM can plan time-optimal jerk-limited trajectories
with full state constraints, and can also plan near-optimal higher-order
trajectories with negligible extra motion time. Numerical results indicate that
the proposed MIM outperforms all baselines in computational time, computational
accuracy, and trajectory quality by a large gap.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07041" title="Abstract">arXiv:2311.07041</a> [<a href="/pdf/2311.07041" title="Download PDF">pdf</a>, <a href="/format/2311.07041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Joint Source Channel Coding With Attention Modules Over MIMO  Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Weiran Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+B">Bo Ai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we propose two deep joint source and channel coding (DJSCC)
structures with attention modules for the multi-input multi-output (MIMO)
channel, including a serial structure and a parallel structure. With singular
value decomposition (SVD)-based precoding scheme, the MIMO channel can be
decomposed into various sub-channels, and the feature outputs will experience
sub-channels with different channel qualities. In the serial structure, one
single network is used at both the transmitter and the receiver to jointly
process data streams of all MIMO subchannels, while data steams of different
MIMO subchannels are processed independently via multiple sub-networks in the
parallel structure. The attention modules in both serial and parallel
architectures enable the system to adapt to varying channel qualities and
adjust the quantity of information outputs in accordance with the channel
qualities. Experimental results demonstrate the proposed DJSCC structures have
improved image transmission performance, and reveal the phenomenon via
non-parameter entropy estimation that the learned DJSCC transceivers tend to
transmit more information over better sub-channels.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07042" title="Abstract">arXiv:2311.07042</a> [<a href="/pdf/2311.07042" title="Download PDF">pdf</a>, <a href="/format/2311.07042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open-Vocabulary Video Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+P">Peng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xuerong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+G">Guansong Pang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yujia Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanning Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video anomaly detection (VAD) with weak supervision has achieved remarkable
performance in utilizing video-level labels to discriminate whether a video
frame is normal or abnormal. However, current approaches are inherently limited
to a closed-set setting and may struggle in open-world applications where there
can be anomaly categories in the test data unseen during training. A few recent
studies attempt to tackle a more realistic setting, open-set VAD, which aims to
detect unseen anomalies given seen anomalies and normal videos. However, such a
setting focuses on predicting frame anomaly scores, having no ability to
recognize the specific categories of anomalies, despite the fact that this
ability is essential for building more informed video surveillance systems.
This paper takes a step further and explores open-vocabulary video anomaly
detection (OVVAD), in which we aim to leverage pre-trained large models to
detect and categorize seen and unseen anomalies. To this end, we propose a
model that decouples OVVAD into two mutually complementary tasks --
class-agnostic detection and class-specific classification -- and jointly
optimizes both tasks. Particularly, we devise a semantic knowledge injection
module to introduce semantic knowledge from large language models for the
detection task, and design a novel anomaly synthesis module to generate pseudo
unseen anomaly videos with the help of large vision generation models for the
classification task. These semantic knowledge and synthesis anomalies
substantially extend our model's capability in detecting and categorizing a
variety of seen and unseen anomalies. Extensive experiments on three
widely-used benchmarks demonstrate our model achieves state-of-the-art
performance on OVVAD task.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07044" title="Abstract">arXiv:2311.07044</a> [<a href="/pdf/2311.07044" title="Download PDF">pdf</a>, <a href="/format/2311.07044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $L_0$-Sampler: An $L_{0}$ Model Guided Volume Sampling for NeRF
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Liangchen Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Juyong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://ustc3dv.github.io/L0-Sampler/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Since being proposed, Neural Radiance Fields (NeRF) have achieved great
success in related tasks, mainly adopting the hierarchical volume sampling
(HVS) strategy for volume rendering. However, the HVS of NeRF approximates
distributions using piecewise constant functions, which provides a relatively
rough estimation. Based on the observation that a well-trained weight function
$w(t)$ and the $L_0$ distance between points and the surface have very high
similarity, we propose $L_0$-Sampler by incorporating the $L_0$ model into
$w(t)$ to guide the sampling process. Specifically, we propose to use piecewise
exponential functions rather than piecewise constant functions for
interpolation, which can not only approximate quasi-$L_0$ weight distributions
along rays quite well but also can be easily implemented with few lines of code
without additional computational burden. Stable performance improvements can be
achieved by applying $L_0$-Sampler to NeRF and its related tasks like 3D
reconstruction. Code is available at https://ustc3dv.github.io/L0-Sampler/ .
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07049" title="Abstract">arXiv:2311.07049</a> [<a href="/pdf/2311.07049" title="Download PDF">pdf</a>, <a href="/ps/2311.07049" title="Download PostScript">ps</a>, <a href="/format/2311.07049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clifford Algebra-Based Iterated Extended Kalman Filter with Application  to Low-Cost INS/GNSS Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ouyang%2C+W">Wei Ouyang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yutian Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Y">Yuanxin Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The traditional GNSS-aided inertial navigation system (INS) usually exploits
the extended Kalman filter (EKF) for state estimation, and the initial attitude
accuracy is key to the filtering performance. To spare the reliance on the
initial attitude, this work generalizes the previously proposed trident
quaternion within the framework of Clifford algebra to represent the extended
pose, IMU biases and lever arms on the Lie group. Consequently, a
quasi-group-affine system is established for the low-cost INS/GNSS integrated
navigation system, and the right-error Clifford algebra-based EKF
(Clifford-RQEKF) is accordingly developed. The iterated filtering approach is
further applied to significantly improve the performances of the Clifford-RQEKF
and the previously proposed trident quaternion-based EKFs. Numerical
simulations and experiments show that all iterated filtering approaches fulfill
the fast and global convergence without the prior attitude information, whereas
the iterated Clifford-RQEKF performs much better than the others under
especially large IMU biases.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07050" title="Abstract">arXiv:2311.07050</a> [<a href="/pdf/2311.07050" title="Download PDF">pdf</a>, <a href="/format/2311.07050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancements in Enhancing Resilience of Electrical Distribution Systems:  A Review on Frameworks, Metrics, and Technological Innovations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dwivedi%2C+D">Divyanshi Dwivedi</a>, 
<a href="/search/cs?searchtype=author&query=Mitikiri%2C+S+B">Sagar Babu Mitikiri</a>, 
<a href="/search/cs?searchtype=author&query=Babu%2C+K+V+S+M">K. Victor Sam Moses Babu</a>, 
<a href="/search/cs?searchtype=author&query=Yemula%2C+P+K">Pradeep Kumar Yemula</a>, 
<a href="/search/cs?searchtype=author&query=Srininvas%2C+V+L">Vedantham Lakshmi Srininvas</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+P">Pratyush Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+M">Mayukha Pal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This comprehensive review paper explores power system resilience, emphasizing
its evolution, comparison with reliability, and conducting a thorough analysis
of the definition and characteristics of resilience. The paper presents the
resilience frameworks and the application of quantitative power system
resilience metrics to assess and quantify resilience. Additionally, it
investigates the relevance of complex network theory in the context of power
system resilience. An integral part of this review involves examining the
incorporation of data-driven techniques in enhancing power system resilience.
This includes the role of data-driven methods in enhancing power system
resilience and predictive analytics. Further, the paper explores the recent
techniques employed for resilience enhancement, which includes planning and
operational techniques. Also, a detailed explanation of microgrid (MG)
deployment, renewable energy integration, and peer-to-peer (P2P) energy trading
in fortifying power systems against disruptions is provided. An analysis of
existing research gaps and challenges is discussed for future directions toward
improvements in power system resilience. Thus, a comprehensive understanding of
power system resilience is provided, which helps in improving the ability of
distribution systems to withstand and recover from extreme events and
disruptions.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07052" title="Abstract">arXiv:2311.07052</a> [<a href="/pdf/2311.07052" title="Download PDF">pdf</a>, <a href="/format/2311.07052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards the Law of Capacity Gap in Distilling Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Dawei Song</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Zheyu Ye</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yan Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 8 figures, 12 tables, work in progress. Code and checkpoints are available at <a href="https://github.com/GeneZC/MiniMA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Language model (LM) distillation is a trending area that aims to distil the
knowledge resided in a large teacher LM to a small student one. While various
methods have been proposed to push the distillation to its limits, it is still
a pain distilling LMs when a large capacity gap is exhibited between the
teacher and the student LMs. The pain is mainly resulted by the curse of
capacity gap, which describes that a larger teacher LM cannot always lead to a
better student LM than one distilled from a smaller teacher LM due to the
affect of capacity gap increment. That is, there is likely an optimal point
yielding the best student LM along the scaling course of the teacher LM. Even
worse, the curse of capacity gap can be only partly yet not fully lifted as
indicated in previous studies.
<br />However, the tale is not ever one-sided. Although a larger teacher LM has
better performance than a smaller teacher LM, it is much more
resource-demanding especially in the context of recent large LMs (LLMs).
Consequently, instead of sticking to lifting the curse, leaving the curse as is
should be arguably fine. Even better, in this paper, we reveal that the optimal
capacity gap is almost consistent across different student scales and
architectures, fortunately turning the curse into the law of capacity gap. The
law later guides us to distil a 3B student LM (termed MiniMA) from a 7B teacher
LM (adapted LLaMA2-7B). MiniMA is demonstrated to yield a new
compute-performance pareto frontier among existing 3B LMs on commonly used
benchmarks, and its instruction-tuned version (termed MiniChat) outperforms a
wide range of 3B competitors in GPT4 evaluation and could even compete with
several 7B chat models.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07054" title="Abstract">arXiv:2311.07054</a> [<a href="/pdf/2311.07054" title="Download PDF">pdf</a>, <a href="/format/2311.07054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do LLMs Implicitly Exhibit User Discrimination in Recommendation? An  Empirical Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+L">Liang Pang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> No
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Recently, Large Language Models (LLMs) have enhanced user interaction,
enabling seamless information retrieval and recommendations. However, concerns
emerge as these LLMs have shown tendencies to display discrimination related to
users' sensitive characteristics (such as gender), leading to explicit user
unfairness. Furthermore, our analysis uncovers a more discreet variant of bias
in LLMs, defined as implicit user unfairness, wherein these models demonstrate
discriminatory recommendation behaviors based solely on non-sensitive user
details, like usernames or email addresses. This subtle form of unfairness,
while more pervasive, poses a significant threat to the ethical integrity and
rights of minority user groups. To comprehensively explore implicit user
unfairness, our analysis unfolds in three key steps: (1) We uncover the reasons
for this implicit user unfairness: LLMs can infer users' sensitive attributes
from non-sensitive attributes (e.g. user names) due to their extensive world
knowledge. (2) Our findings expose that the magnitude of implicit user
unfairness within LLMs surpasses the level of explicit user unfairness observed
in traditional recommender models, signifying a more alarming issue of
unfairness, i.e. some non-sensitive features of users like names may result in
more serious discrimination phenomena. (3) We analyze the long-term effect of
implicit user unfairness, identifying that it will reinforce information
bubbles at an accelerated rate compared to traditional RS. We emphasize the
need to identify and mitigate implicit user unfairness, aiming to avert the
potential human-LLMs recommendation systems deterioration.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07056" title="Abstract">arXiv:2311.07056</a> [<a href="/pdf/2311.07056" title="Download PDF">pdf</a>, <a href="/ps/2311.07056" title="Download PostScript">ps</a>, <a href="/format/2311.07056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effective In-vehicle Intrusion Detection via Multi-view Statistical  Graph Learning on CAN Messages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Q">Qiguang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bailing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongzheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yulei Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 8 figures, 6 tables, 27 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">As an important component of internet of vehicles (IoV), intelligent
connected vehicles (ICVs) have to communicate with external networks
frequently. In this case, the resource-constrained in-vehicle network (IVN) is
facing a wide variety of complex and changing external cyber-attacks,
especially the masquerade attack with high difficulty of detection while
serious damaging effects that few counter measures can identify successfully.
Moreover, only coarse-grained recognition can be achieved in current mainstream
intrusion detection mechanisms, i.e., whether a whole data flow observation
window contains attack labels rather than fine-grained recognition on every
single data item within this window. In this paper, we propose StatGraph: an
Effective Multi-view Statistical Graph Learning Intrusion Detection to
implement the fine-grained intrusion detection. Specifically, StatGraph
generates two statistical graphs, timing correlation graph (TCG) and coupling
relationship graph (CRG), based on data streams. In given message observation
windows, edge attributes in TCGs represent temporal correlation between
different message IDs, while edge attributes in CRGs denote the neighbour
relationship and contextual similarity. Besides, a lightweight shallow layered
GCN network is trained based graph property of TCGs and CRGs, which can learn
the universal laws of various patterns more effectively and further enhance the
performance of detection. To address the problem of insufficient attack types
in previous intrusion detection, we select two real in-vehicle CAN datasets
that cover four new attacks never investigated before. Experimental result
shows StatGraph improves both detection granularity and detection performance
over state-of-the-art intrusion detection methods.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07062" title="Abstract">arXiv:2311.07062</a> [<a href="/pdf/2311.07062" title="Download PDF">pdf</a>, <a href="/format/2311.07062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoupling and Interacting Multi-Task Learning Network for Joint Speech  and Accent Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+Q">Qijie Shao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+P">Pengcheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Jinghao Yan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+P">Pengfei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lei Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Audio, Speech and Language Processing (TASLP)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Accents, as variations from standard pronunciation, pose significant
challenges for speech recognition systems. Although joint automatic speech
recognition (ASR) and accent recognition (AR) training has been proven
effective in handling multi-accent scenarios, current multi-task ASR-AR
approaches overlook the granularity differences between tasks. Fine-grained
units capture pronunciation-related accent characteristics, while
coarse-grained units are better for learning linguistic information. Moreover,
an explicit interaction of two tasks can also provide complementary information
and improve the performance of each other, but it is rarely used by existing
approaches. In this paper, we propose a novel Decoupling and Interacting
Multi-task Network (DIMNet) for joint speech and accent recognition, which is
comprised of a connectionist temporal classification (CTC) branch, an AR
branch, an ASR branch, and a bottom feature encoder. Specifically, AR and ASR
are first decoupled by separated branches and two-granular modeling units to
learn task-specific representations. The AR branch is from our previously
proposed linguistic-acoustic bimodal AR model and the ASR branch is an
encoder-decoder based Conformer model. Then, for the task interaction, the CTC
branch provides aligned text for the AR task, while accent embeddings extracted
from our AR model are incorporated into the ASR branch's encoder and decoder.
Finally, during ASR inference, a cross-granular rescoring method is introduced
to fuse the complementary information from the CTC and attention decoder after
the decoupling. Our experiments on English and Chinese datasets demonstrate the
effectiveness of the proposed model, which achieves 21.45%/28.53% AR accuracy
relative improvement and 32.33%/14.55% ASR error rate relative reduction over a
published standard baseline, respectively.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07064" title="Abstract">arXiv:2311.07064</a> [<a href="/pdf/2311.07064" title="Download PDF">pdf</a>, <a href="/format/2311.07064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PROPANE: Prompt design as an inverse problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Melamed%2C+R">Rimon Melamed</a>, 
<a href="/search/cs?searchtype=author&query=McCabe%2C+L+H">Lucas H. McCabe</a>, 
<a href="/search/cs?searchtype=author&query=Wakhare%2C+T">Tanay Wakhare</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yejin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H+H">H. Howie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Boix-Adsera%2C+E">Enric Boix-Adsera</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 11 figures, preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Carefully-designed prompts are key to inducing desired behavior in Large
Language Models (LLMs). As a result, great effort has been dedicated to
engineering prompts that guide LLMs toward particular behaviors. In this work,
we propose an automatic prompt optimization framework, PROPANE, which aims to
find a prompt that induces semantically similar outputs to a fixed set of
examples without user intervention. We further demonstrate that PROPANE can be
used to (a) improve existing prompts, and (b) discover semantically obfuscated
prompts that transfer between models.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07065" title="Abstract">arXiv:2311.07065</a> [<a href="/pdf/2311.07065" title="Download PDF">pdf</a>, <a href="/ps/2311.07065" title="Download PostScript">ps</a>, <a href="/format/2311.07065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-approximability of constructive global $\mathcal{L}^2$ minimizers by  gradient descent in Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Thomas Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ewald%2C+P+M">Patricia Mu&#xf1;oz Ewald</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AMS Latex, 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Mathematical Physics (math-ph); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">We analyze geometric aspects of the gradient descent algorithm in Deep
Learning (DL) networks. In particular, we prove that the globally minimizing
weights and biases for the $\mathcal{L}^2$ cost obtained constructively in
[Chen-Munoz Ewald 2023] for underparametrized ReLU DL networks can generically
not be approximated via the gradient descent flow. We therefore conclude that
the method introduced in [Chen-Munoz Ewald 2023] is disjoint from the gradient
descent method.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07066" title="Abstract">arXiv:2311.07066</a> [<a href="/pdf/2311.07066" title="Download PDF">pdf</a>, <a href="/format/2311.07066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context Consistency between Training and Testing in Simultaneous Machine  Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+M">Meizhi Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lemao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kehai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Mingming Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Simultaneous Machine Translation (SiMT) aims to yield a real-time partial
translation with a monotonically growing the source-side context. However,
there is a counterintuitive phenomenon about the context usage between training
and testing: e.g., the wait-k testing model consistently trained with wait-k is
much worse than that model inconsistently trained with wait-k' (k' is not equal
to k) in terms of translation quality. To this end, we first investigate the
underlying reasons behind this phenomenon and uncover the following two
factors: 1) the limited correlation between translation quality and training
(cross-entropy) loss; 2) exposure bias between training and testing. Based on
both reasons, we then propose an effective training approach called context
consistency training accordingly, which makes consistent the context usage
between training and testing by optimizing translation quality and latency as
bi-objectives and exposing the predictions to the model during the training.
The experiments on three language pairs demonstrate our intuition: our system
encouraging context consistency outperforms that existing systems with context
inconsistency for the first time, with the help of our context consistency
training approach.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07068" title="Abstract">arXiv:2311.07068</a> [<a href="/pdf/2311.07068" title="Download PDF">pdf</a>, <a href="/format/2311.07068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shannon Theory for Wireless Communication in a Resonant Chamber
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Amritpal Singh</a>, 
<a href="/search/cs?searchtype=author&query=Marzetta%2C+T">Thomas Marzetta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 13 figures. To be published in IEEE Journal on Selected Areas in Communications Special Issue on Electromagnetic Signal and Information Theory
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP); Classical Physics (physics.class-ph)

</div>
<p class="mathjax">A closed electromagnetic resonant chamber (RC) is a highly favorable
artificial environment for wireless communication. A pair of antennas within
the chamber constitutes a two-port network described by an impedance matrix. We
analyze communication between the two antennas when the RC has perfectly
conducting walls and the impedance matrix is imaginary-valued. The transmit
antenna is driven by a current source, and the receive antenna is connected to
a load resistor whose voltage is measured by an infinite-impedance amplifier.
There are a countably infinite number of poles in the channel, associated with
resonance in the RC, which migrate towards the real frequency axis as the load
resistance increases. There are two sources of receiver noise: the Johnson
noise of the load resistor, and the internal amplifier noise. An application of
Shannon theory yields the capacity of the link, subject to bandwidth and power
constraints on the transmit current. For a constant transmit power, capacity
increases without bound as the load resistance increases. Surprisingly, the
capacity-attaining allocation of transmit power versus frequency avoids placing
power close to the resonant frequencies.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07069" title="Abstract">arXiv:2311.07069</a> [<a href="/pdf/2311.07069" title="Download PDF">pdf</a>, <a href="/format/2311.07069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Music ControlNet: Multiple Time-varying Controls for Music Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shih-Lun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Donahue%2C+C">Chris Donahue</a>, 
<a href="/search/cs?searchtype=author&query=Watanabe%2C+S">Shinji Watanabe</a>, 
<a href="/search/cs?searchtype=author&query=Bryan%2C+N+J">Nicholas J. Bryan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figure, 5 tables, Submitted to IEEE/ACM Transactions on Audio, Speech, and Language Processing (TASLP)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Text-to-music generation models are now capable of generating high-quality
music audio in broad styles. However, text control is primarily suitable for
the manipulation of global musical attributes like genre, mood, and tempo, and
is less suitable for precise control over time-varying attributes such as the
positions of beats in time or the changing dynamics of the music. We propose
Music ControlNet, a diffusion-based music generation model that offers multiple
precise, time-varying controls over generated audio. To imbue text-to-music
models with time-varying control, we propose an approach analogous to
pixel-wise control of the image-domain ControlNet method. Specifically, we
extract controls from training audio yielding paired data, and fine-tune a
diffusion-based conditional generative model over audio spectrograms given
melody, dynamics, and rhythm controls. While the image-domain Uni-ControlNet
method already allows generation with any subset of controls, we devise a new
strategy to allow creators to input controls that are only partially specified
in time. We evaluate both on controls extracted from audio and controls we
expect creators to provide, demonstrating that we can generate realistic music
that corresponds to control inputs in both settings. While few comparable music
generation models exist, we benchmark against MusicGen, a recent model that
accepts text and melody input, and show that our model generates music that is
49% more faithful to input melodies despite having 35x fewer parameters,
training on 11x less data, and enabling two additional forms of time-varying
control. Sound examples can be found at https://MusicControlNet.github.io/web/.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07070" title="Abstract">arXiv:2311.07070</a> [<a href="/pdf/2311.07070" title="Download PDF">pdf</a>, <a href="/format/2311.07070" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explain-then-Translate: An Analysis on Improving Program Translation  with Self-generated Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zilu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+M">Mayank Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Shypula%2C+A">Alex Shypula</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bailin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wijaya%2C+D">Derry Wijaya</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yoon Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures, 5 tables, 48 pages total. To be published in EMNLP Findings 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This work explores the use of self-generated natural language explanations as
an intermediate step for code-to-code translation with language models. Across
three types of explanations and 19 programming languages constructed from the
MultiPL-E dataset, we find the explanations to be particularly effective in the
zero-shot case, improving performance by 12% on average. Improvements with
natural language explanations are particularly pronounced on difficult
programs. We release our dataset, code, and canonical solutions in all 19
languages.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07073" title="Abstract">arXiv:2311.07073</a> [<a href="/pdf/2311.07073" title="Download PDF">pdf</a>, <a href="/ps/2311.07073" title="Download PostScript">ps</a>, <a href="/format/2311.07073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exposition on over-squashing problem on GNNs: Current Methods,  Benchmarks and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+D">Dai Shi</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+A">Andi Han</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Lequan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Junbin Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph-based message-passing neural networks (MPNNs) have achieved remarkable
success in both node and graph-level learning tasks. However, several
identified problems, including over-smoothing (OSM), limited expressive power,
and over-squashing (OSQ), still limit the performance of MPNNs. In particular,
OSQ serves as the latest identified problem, where MPNNs gradually lose their
learning accuracy when long-range dependencies between graph nodes are
required. In this work, we provide an exposition on the OSQ problem by
summarizing different formulations of OSQ from current literature, as well as
the three different categories of approaches for addressing the OSQ problem. In
addition, we also discuss the alignment between OSQ and expressive power and
the trade-off between OSQ and OSM. Furthermore, we summarize the empirical
methods leveraged from existing works to verify the efficiency of OSQ
mitigation approaches, with illustrations of their computational complexities.
Lastly, we list some open questions that are of interest for further
exploration of the OSQ problem along with potential directions from the best of
our knowledge.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07075" title="Abstract">arXiv:2311.07075</a> [<a href="/pdf/2311.07075" title="Download PDF">pdf</a>, <a href="/format/2311.07075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GazeForensics: DeepFake Detection via Gaze-guided Spatial Inconsistency  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Q">Qinlin He</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Chunlei Peng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dechuang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Nannan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xinbo Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">DeepFake detection is pivotal in personal privacy and public safety. With the
iterative advancement of DeepFake techniques, high-quality forged videos and
images are becoming increasingly deceptive. Prior research has seen numerous
attempts by scholars to incorporate biometric features into the field of
DeepFake detection. However, traditional biometric-based approaches tend to
segregate biometric features from general ones and freeze the biometric feature
extractor. These approaches resulted in the exclusion of valuable general
features, potentially leading to a performance decline and, consequently, a
failure to fully exploit the potential of biometric information in assisting
DeepFake detection. Moreover, insufficient attention has been dedicated to
scrutinizing gaze authenticity within the realm of DeepFake detection in recent
years. In this paper, we introduce GazeForensics, an innovative DeepFake
detection method that utilizes gaze representation obtained from a 3D gaze
estimation model to regularize the corresponding representation within our
DeepFake detection model, while concurrently integrating general features to
further enhance the performance of our model. Experiment results reveal that
our proposed GazeForensics outperforms the current state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07076" title="Abstract">arXiv:2311.07076</a> [<a href="/pdf/2311.07076" title="Download PDF">pdf</a>, <a href="/format/2311.07076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Discussion of Large Language Models: Symmetry of Agents and  Interplay with Prompts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qineng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Ying Su</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yangqiu Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Working in progress, and code will be released soon
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Two ways has been discussed to unlock the reasoning capability of a large
language model. The first one is prompt engineering and the second one is to
combine the multiple inferences of large language models, or the multi-agent
discussion. Theoretically, this paper justifies the multi-agent discussion
mechanisms from the symmetry of agents. Empirically, this paper reports the
empirical results of the interplay of prompts and discussion mechanisms,
revealing the empirical state-of-the-art performance of complex multi-agent
mechanisms can be approached by carefully developed prompt engineering. This
paper also proposes a scalable discussion mechanism based on conquer and merge,
providing a simple multi-agent discussion solution with simple prompts but
state-of-the-art performance.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07079" title="Abstract">arXiv:2311.07079</a> [<a href="/pdf/2311.07079" title="Download PDF">pdf</a>, <a href="/format/2311.07079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample Dominance Aware Framework via Non-Parametric Estimation for  Spontaneous Brain-Computer Interface
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+B">Byeong-Hoo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+B">Byoung-Hee Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seong-Whan Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Deep learning has shown promise in decoding brain signals, such as
electroencephalogram (EEG), in the field of brain-computer interfaces (BCIs).
However, the non-stationary characteristics of EEG signals pose challenges for
training neural networks to acquire appropriate knowledge. Inconsistent EEG
signals resulting from these non-stationary characteristics can lead to poor
performance. Therefore, it is crucial to investigate and address sample
inconsistency to ensure robust performance in spontaneous BCIs. In this study,
we introduce the concept of sample dominance as a measure of EEG signal
inconsistency and propose a method to modulate its effect on network training.
We present a two-stage dominance score estimation technique that compensates
for performance degradation caused by sample inconsistencies. Our proposed
method utilizes non-parametric estimation to infer sample inconsistency and
assigns each sample a dominance score. This score is then aggregated with the
loss function during training to modulate the impact of sample inconsistency.
Furthermore, we design a curriculum learning approach that gradually increases
the influence of inconsistent signals during training to improve overall
performance. We evaluate our proposed method using public spontaneous BCI
dataset. The experimental results confirm that our findings highlight the
importance of addressing sample dominance for achieving robust performance in
spontaneous BCIs.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07081" title="Abstract">arXiv:2311.07081</a> [<a href="/pdf/2311.07081" title="Download PDF">pdf</a>, <a href="/format/2311.07081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sensing Mutual Information with Random Signals in Gaussian Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lei Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhanyuan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zheng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shenghui Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Sensing performance is typically evaluated by classical metrics, such as
Cramer-Rao bound and signal-to-clutter-plus-noise ratio. The recent development
of the integrated sensing and communication (ISAC) framework motivated the
efforts to unify the metric for sensing and communication, where researchers
have proposed to utilize mutual information (MI) to measure the sensing
performance with deterministic signals. However, the need to communicate in
ISAC systems necessitates the use of random signals for sensing applications
and the closed-form evaluation for the sensing mutual information (SMI) with
random signals is not yet available in the literature. This paper investigates
the achievable performance and precoder design for sensing applications with
random signals. For that purpose, we first derive the closed-form expression
for the SMI with random signals by utilizing random matrix theory. The result
reveals some interesting physical insights regarding the relation between the
SMI with deterministic and random signals. The derived SMI is then utilized to
optimize the precoder by leveraging a manifold-based optimization approach. The
effectiveness of the proposed methods is validated by simulation results.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07082" title="Abstract">arXiv:2311.07082</a> [<a href="/pdf/2311.07082" title="Download PDF">pdf</a>, <a href="/format/2311.07082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Passing-through Control of Multi-Robot Systems in Cluttered  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+C">Chenggang Bai</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+Q">Quan Quan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This survey presents a comprehensive review of various methods and algorithms
related to passing-through control of multi-robot systems in cluttered
environments. Numerous studies have investigated this area, and we identify
several avenues for enhancing existing methods. This survey describes some
models of robots and commonly considered control objectives, followed by an
in-depth analysis of four types of algorithms that can be employed for
passing-through control: leader-follower formation control, multi-robot
trajectory planning, control-based methods, and virtual tube planning and
control. Furthermore, we conduct a comparative analysis of these techniques and
provide some subjective and general evaluations.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07090" title="Abstract">arXiv:2311.07090</a> [<a href="/pdf/2311.07090" title="Download PDF">pdf</a>, <a href="/format/2311.07090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLiF-VQA: Enhancing Video Quality Assessment by Incorporating High-Level  Semantic Information related to Human Feelings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mi%2C+Y">Yachun Mi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yu Li</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+Y">Yan Shu</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+C">Chen Hui</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Puchao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shaohui Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video Quality Assessment (VQA) aims to simulate the process of perceiving
video quality by the human visual system (HVS). The judgments made by HVS are
always influenced by human subjective feelings. However, most of the current
VQA research focuses on capturing various distortions in the spatial and
temporal domains of videos, while ignoring the impact of human feelings. In
this paper, we propose CLiF-VQA, which considers both features related to human
feelings and spatial features of videos. In order to effectively extract
features related to human feelings from videos, we explore the consistency
between CLIP and human feelings in video perception for the first time.
Specifically, we design multiple objective and subjective descriptions closely
related to human feelings as prompts. Further we propose a novel CLIP-based
semantic feature extractor (SFE) which extracts features related to human
feelings by sliding over multiple regions of the video frame. In addition, we
further capture the low-level-aware features of the video through a spatial
feature extraction module. The two different features are then aggregated
thereby obtaining the quality score of the video. Extensive experiments show
that the proposed CLiF-VQA exhibits excellent performance on several VQA
datasets.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07091" title="Abstract">arXiv:2311.07091</a> [<a href="/pdf/2311.07091" title="Download PDF">pdf</a>, <a href="/ps/2311.07091" title="Download PostScript">ps</a>, <a href="/format/2311.07091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Code-Aided Channel Estimation in LDPC-Coded MIMO Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Binghui Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yongpeng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+P">Peihong Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+D+W+K">Derrick Wing Kwan Ng</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+X">Xiang-Gen Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenjun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by IEEE Wireless Communications Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">For a multiple-input multiple-output (MIMO) system with unknown channel state
information (CSI), a novel low-density parity check (LDPC)-coded transmission
(LCT) scheme with joint pilot and data channel estimation is proposed. To
fine-tune the CSI, a method based on the constraints introduced by the coded
data from an LDPC code is designed such that the MIMO detector exploits the
fine-tuned CSI. For reducing the computational burden, a coordinate ascent
algorithm is employed along with several approximation methods, effectively
reducing the required times of MIMO detection and computational complexity to
achieve a satisfying performance. Simulation results utilizing WiMAX standard
LDPC codes and quadrature phase-shift keying (QPSK) modulation demonstrate
gains of up to 1.3 dB at a frame error rate (FER) of $10^{-4}$ compared to
pilot-assisted transmission (PAT) over Rayleigh block-fading channels.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07092" title="Abstract">arXiv:2311.07092</a> [<a href="/pdf/2311.07092" title="Download PDF">pdf</a>, <a href="/format/2311.07092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> To Tell The Truth: Language of Deception and Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Majumder%2C+B+P">Bodhisattwa Prasad Majumder</a>, 
<a href="/search/cs?searchtype=author&query=Hazra%2C+S">Sanchaita Hazra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Text-based misinformation permeates online discourses, yet evidence of
people's ability to discern truth from such deceptive textual content is
scarce. We analyze a novel TV game show data where conversations in a
high-stake environment between individuals with conflicting objectives result
in lies. We investigate the manifestation of potentially verifiable language
cues of deception in the presence of objective truth, a distinguishing feature
absent in previous text-based deception datasets. We show that there exists a
class of detectors (algorithms) that have similar truth detection performance
compared to human subjects, even when the former accesses only the language
cues while the latter engages in conversations with complete access to all
potential sources of cues (language and audio-visual). Our model, built on a
large language model, employs a bottleneck framework to learn discernible cues
to determine truth, an act of reasoning in which human subjects often perform
poorly, even with incentives. Our model detects novel but accurate language
cues in many cases where humans failed to detect deception, opening up the
possibility of humans collaborating with algorithms and ameliorating their
ability to detect the truth.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07093" title="Abstract">arXiv:2311.07093</a> [<a href="/pdf/2311.07093" title="Download PDF">pdf</a>, <a href="/format/2311.07093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Effectiveness of ASR Representations in Real-world Noisy Speech  Emotion Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xiaohan Shi</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiajun He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingfeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Toda%2C+T">Tomoki Toda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This paper proposes an efficient attempt to noisy speech emotion recognition
(NSER). Conventional NSER approaches have proven effective in mitigating the
impact of artificial noise sources, such as white Gaussian noise, but are
limited to non-stationary noises in real-world environments due to their
complexity and uncertainty. To overcome this limitation, we introduce a new
method for NSER by adopting the automatic speech recognition (ASR) model as a
noise-robust feature extractor to eliminate non-vocal information in noisy
speech. We first obtain intermediate layer information from the ASR model as a
feature representation for emotional speech and then apply this representation
for the downstream NSER task. Our experimental results show that 1) the
proposed method achieves better NSER performance compared with the conventional
noise reduction method, 2) outperforms self-supervised learning approaches, and
3) even outperforms text-based approaches using ASR transcription or the ground
truth transcription of noisy speech.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07096" title="Abstract">arXiv:2311.07096</a> [<a href="/pdf/2311.07096" title="Download PDF">pdf</a>, <a href="/format/2311.07096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Configuration of Reconfigurable Intelligent Surfaces with  Arbitrary Discrete Phase Shifts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hashemi%2C+S">Seyedkhashayar Hashemi</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Hai Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ardakani%2C+M">Masoud Ardakani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">We address the reflection optimization problem for a reconfigurable
intelligent surface (RIS), where the RIS elements feature a set of
non-uniformly spaced discrete phase shifts. This is motivated by the actual
behavior of practical RIS elements, where it is shown that a uniform phase
shift assumption is not realistic. A problem is formulated to find the optimal
refection amplitudes and reflection phase shifts of the RIS elements such that
the channel capacity of the target user is maximized. We first prove that in
the optimal configuration, each RIS element is either turned off or operates at
maximum amplitude. We then develop a method that finds the optimal reflection
amplitudes and phases with complexity linear in the number of RIS elements.
Some new and interesting insight into the reflection optimization problem is
also provided.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07099" title="Abstract">arXiv:2311.07099</a> [<a href="/pdf/2311.07099" title="Download PDF">pdf</a>, <a href="/format/2311.07099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explanation-aware Soft Ensemble Empowers Large Language Model In-context  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yue Yu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jiaming Shen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhen Qin</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J+N">Jing Nathan Yan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jialu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bendersky%2C+M">Michael Bendersky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) have shown remarkable capabilities in various
natural language understanding tasks. With only a few demonstration examples,
these LLMs can quickly adapt to target tasks without expensive gradient
updates. Common strategies to boost such 'in-context' learning ability are to
ensemble multiple model decoded results and require the model to generate an
explanation along with the prediction. However, these models often treat
different class predictions equally and neglect the potential discrepancy
between the explanations and predictions. To fully unleash the power of
explanations, we propose EASE, an Explanation-Aware Soft Ensemble framework to
empower in-context learning with LLMs. We design two techniques,
explanation-guided ensemble, and soft probability aggregation, to mitigate the
effect of unreliable explanations and improve the consistency between
explanations and final predictions. Experiments on seven natural language
understanding tasks and four varying-size LLMs demonstrate the effectiveness of
our proposed framework.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07100" title="Abstract">arXiv:2311.07100</a> [<a href="/pdf/2311.07100" title="Download PDF">pdf</a>, <a href="/format/2311.07100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative Planning for Catching and Transporting Objects in  Unstructured Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pei%2C+L">Liuao Pei</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Junxiao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhichao Han</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+L">Lun Quan</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yanjun Cao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+F">Fei Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Multi-robot teams have attracted attention from industry and academia for
their ability to perform collaborative tasks in unstructured environments, such
as wilderness rescue and collaborative transportation.In this paper, we propose
a trajectory planning method for a non-holonomic robotic team with
collaboration in unstructured environments.For the adaptive state collaboration
of a robot team to catch and transport targets to be rescued using a net, we
model the process of catching the falling target with a net in a continuous and
differentiable form.This enables the robot team to fully exploit the kinematic
potential, thereby adaptively catching the target in an appropriate
state.Furthermore, the size safety and topological safety of the net, resulting
from the collaborative support of the robots, are guaranteed through geometric
constraints.We integrate our algorithm on a car-like robot team and test it in
simulations and real-world experiments to validate our performance.Our method
is compared to state-of-the-art multi-vehicle trajectory planning methods,
demonstrating significant performance in efficiency and trajectory quality.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07102" title="Abstract">arXiv:2311.07102</a> [<a href="/pdf/2311.07102" title="Download PDF">pdf</a>, <a href="/format/2311.07102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fovea Transformer: Efficient Long-Context Modeling with Structured  Fine-to-Coarse Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Ziwei He</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jian Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Le Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Leng%2C+J">Jingwen Leng</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Bo Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The quadratic complexity of self-attention in Transformers has hindered the
processing of long text. To alleviate this problem, previous works have
proposed to sparsify the attention matrix, taking advantage of the observation
that crucial information about a token can be derived from its neighbors. These
methods typically combine one or another form of local attention and global
attention. Such combinations introduce abrupt changes in contextual granularity
when going from local to global, which may be undesirable. We believe that a
smoother transition could potentially enhance model's ability to capture
long-context dependencies. In this study, we introduce Fovea Transformer, a
long-context focused transformer that addresses the challenges of capturing
global dependencies while maintaining computational efficiency. To achieve
this, we construct a multi-scale tree from the input sequence, and use
representations of context tokens with a progressively coarser granularity in
the tree, as their distance to the query token increases. We evaluate our model
on three long-context summarization tasks\footnote{Our code is publicly
available at: \textit{https://github.com/ZiweiHe/Fovea-Transformer}}. It
achieves state-of-the-art performance on two of them, and competitive results
on the third with mixed improvement and setback of the evaluation metrics.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07104" title="Abstract">arXiv:2311.07104</a> [<a href="/pdf/2311.07104" title="Download PDF">pdf</a>, <a href="/ps/2311.07104" title="Download PostScript">ps</a>, <a href="/format/2311.07104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure Wireless Communication via Movable-Antenna Array
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+G">Guojie Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingqing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+J">Jiangbo Si</a>, 
<a href="/search/cs?searchtype=author&query=Al-Dhahir%2C+N">Naofal Al-Dhahir</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Movable antenna (MA) array is a novel technology recently developed where
positions of transmit/receive antennas can be flexibly adjusted in the
specified region to reconfigure the wireless channel and achieve a higher
capacity. In this letter, we, for the first time, investigate the MA
array-assisted physical-layer security where the confidential information is
transmitted from a MA array-enabled Alice to a single-antenna Bob, in the
presence of multiple single-antenna and colluding eavesdroppers. We aim to
maximize the achievable secrecy rate by jointly designing the transmit
beamforming and positions of all antennas at Alice subject to the transmit
power budget and specified regions for positions of all transmit antennas. The
resulting problem is highly non-convex, for which the projected gradient ascent
(PGA) and the alternating optimization methods are utilized to obtain a
high-quality suboptimal solution. Simulation results demonstrate that since the
additional spatial degree of freedom (DoF) can be fully exploited, the MA array
significantly enhances the secrecy rate compared to the conventional
fixed-position antenna (FPA) array.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07105" title="Abstract">arXiv:2311.07105</a> [<a href="/pdf/2311.07105" title="Download PDF">pdf</a>, <a href="/format/2311.07105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative Goal Tracking of Multiple Mobile Robots Based on Geometric  Graph Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Q">Qingquan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Weining Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Multi-robot systems are widely used in spatially distributed tasks, and their
collaborative path planning is of great significance for working efficiency.
Currently, different multi-robot collaborative path planning methods have been
proposed, but how to process the sensory information of neighboring robots at
different locations from a local perception perspective in real environment to
make better decisions is still a major difficulty. To address this problem,
this paper proposes a multi-robot collaborative path planning method based on
geometric graph neural network (GeoGNN). GeoGNN introduces the relative
position information of neighboring robots into each interaction layer of the
graph neural network to better integrate neighbor sensing information. An
expert data generation method is designed for the robot to advance in a single
step, by which expert data are generated in ROS to train the network.
Experimental results show that the accuracy of the proposed method is improved
by about 5% compared to the model based only on CNN on the expert data set. In
ROS simulation environment path planning test, the success rate is improved by
about 4% compared to CNN and flowtime increase is reduced about 8%, which
outperforms other graph neural network models.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07106" title="Abstract">arXiv:2311.07106</a> [<a href="/pdf/2311.07106" title="Download PDF">pdf</a>, <a href="/format/2311.07106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Tutorial on Coding Methods for DNA-based Molecular Communications and  Storage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiang%2C+L">Luping Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sirong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+K">Kang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenfeng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kun Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Exponential increase of data has motivated advances of data storage
technologies. As a promising storage media, DeoxyriboNucleic Acid (DNA) storage
provides a much higher data density and superior durability, compared with
state-of-the-art media. In this paper, we provide a tutorial on DNA storage and
its role in molecular communications. Firstly, we introduce fundamentals of
DNA-based molecular communications and storage (MCS), discussing the basic
process of performing DNA storage in MCS. Furthermore, we provide tutorials on
how conventional coding schemes that are used in wireless communications can be
applied to DNA-based MCS, along with numerical results. Finally, promising
research directions on DNA-based data storage in molecular communications are
introduced and discussed in this paper.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07107" title="Abstract">arXiv:2311.07107</a> [<a href="/pdf/2311.07107" title="Download PDF">pdf</a>, <a href="/format/2311.07107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Source Code Search: A 3-Dimensional Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weisong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Chunrong Fang</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yifei Ge</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yuling Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuchen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Quanjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+X">Xiuting Ge</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenyu Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to ACM Transactions on Software Engineering and Methodology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">(Source) code search is widely concerned by software engineering researchers
because it can improve the productivity and quality of software development.
Given a functionality requirement usually described in a natural language
sentence, a code search system can retrieve code snippets that satisfy the
requirement from a large-scale code corpus, e.g., GitHub. To realize effective
and efficient code search, many techniques have been proposed successively.
These techniques improve code search performance mainly by optimizing three
core components, including query understanding component, code understanding
component, and query-code matching component. In this paper, we provide a
3-dimensional perspective survey for code search. Specifically, we categorize
existing code search studies into query-end optimization techniques, code-end
optimization techniques, and match-end optimization techniques according to the
specific components they optimize. Considering that each end can be optimized
independently and contributes to the code search performance, we treat each end
as a dimension. Therefore, this survey is 3-dimensional in nature, and it
provides a comprehensive summary of each dimension in detail. To understand the
research trends of the three dimensions in existing code search studies, we
systematically review 68 relevant literatures. Different from existing code
search surveys that only focus on the query end or code end or introduce
various aspects shallowly (including codebase, evaluation metrics, modeling
technique, etc.), our survey provides a more nuanced analysis and review of the
evolution and development of the underlying techniques used in the three ends.
Based on a systematic review and summary of existing work, we outline several
open challenges and opportunities at the three ends that remain to be addressed
in future work.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07110" title="Abstract">arXiv:2311.07110</a> [<a href="/pdf/2311.07110" title="Download PDF">pdf</a>, <a href="/format/2311.07110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Purification for Data-Driven Power System Event Classifiers  with Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cheng%2C+Y">Yuanbin Cheng</a>, 
<a href="/search/eess?searchtype=author&query=Yamashita%2C+K">Koji Yamashita</a>, 
<a href="/search/eess?searchtype=author&query=Follum%2C+J">Jim Follum</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+N">Nanpeng Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">The global deployment of the phasor measurement units (PMUs) enables
real-time monitoring of the power system, which has stimulated considerable
research into machine learning-based models for event detection and
classification. However, recent studies reveal that machine learning-based
methods are vulnerable to adversarial attacks, which can fool the event
classifiers by adding small perturbations to the raw PMU data. To mitigate the
threats posed by adversarial attacks, research on defense strategies is
urgently needed. This paper proposes an effective adversarial purification
method based on the diffusion model to counter adversarial attacks on the
machine learning-based power system event classifier. The proposed method
includes two steps: injecting noise into the PMU data; and utilizing a
pre-trained neural network to eliminate the added noise while simultaneously
removing perturbations introduced by the adversarial attacks. The proposed
adversarial purification method significantly increases the accuracy of the
event classifier under adversarial attacks while satisfying the requirements of
real-time operations. In addition, the theoretical analysis reveals that the
proposed diffusion model-based adversarial purification method decreases the
distance between the original and compromised PMU data, which reduces the
impacts of adversarial attacks. The empirical results on a large-scale
real-world PMU dataset validate the effectiveness and computational efficiency
of the proposed adversarial purification method.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07113" title="Abstract">arXiv:2311.07113</a> [<a href="/pdf/2311.07113" title="Download PDF">pdf</a>, <a href="/format/2311.07113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpectralGPT: Spectral Foundation Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+D">Danfeng Hong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jing Yao</a>, 
<a href="/search/cs?searchtype=author&query=Yokoya%2C+N">Naoto Yokoya</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xiuping Jia</a>, 
<a href="/search/cs?searchtype=author&query=Plaza%2C+A">Antonio Plaza</a>, 
<a href="/search/cs?searchtype=author&query=Paolo%2C+G">Gamba Paolo</a>, 
<a href="/search/cs?searchtype=author&query=Benediktsson%2C+J+A">Jon Atli Benediktsson</a>, 
<a href="/search/cs?searchtype=author&query=Chanussot%2C+J">Jocelyn Chanussot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The foundation model has recently garnered significant attention due to its
potential to revolutionize the field of visual representation learning in a
self-supervised manner. While most foundation models are tailored to
effectively process RGB images for various visual tasks, there is a noticeable
gap in research focused on spectral data, which offers valuable information for
scene understanding, especially in remote sensing (RS) applications. To fill
this gap, we created for the first time a universal RS foundation model, named
SpectralGPT, which is purpose-built to handle spectral RS images using a novel
3D generative pretrained transformer (GPT). Compared to existing foundation
models, SpectralGPT 1) accommodates input images with varying sizes,
resolutions, time series, and regions in a progressive training fashion,
enabling full utilization of extensive RS big data; 2) leverages 3D token
generation for spatial-spectral coupling; 3) captures spectrally sequential
patterns via multi-target reconstruction; 4) trains on one million spectral RS
images, yielding models with over 600 million parameters. Our evaluation
highlights significant performance improvements with pretrained SpectralGPT
models, signifying substantial potential in advancing spectral RS big data
applications within the field of geoscience across four downstream tasks:
single/multi-label scene classification, semantic segmentation, and change
detection.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07115" title="Abstract">arXiv:2311.07115</a> [<a href="/pdf/2311.07115" title="Download PDF">pdf</a>, <a href="/format/2311.07115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gen-Z: Generative Zero-Shot Text Classification with Contextualized  Label Descriptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sachin Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+C+Y">Chan Young Park</a>, 
<a href="/search/cs?searchtype=author&query=Tsvetkov%2C+Y">Yulia Tsvetkov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Language model (LM) prompting--a popular paradigm for solving NLP tasks--has
been shown to be susceptible to miscalibration and brittleness to slight prompt
variations, caused by its discriminative prompting approach, i.e., predicting
the label given the input. To address these issues, we propose Gen-Z--a
generative prompting framework for zero-shot text classification. GEN-Z is
generative, as it measures the LM likelihood of input text, conditioned on
natural language descriptions of labels. The framework is multivariate, as
label descriptions allow us to seamlessly integrate additional contextual
information about the labels to improve task performance. On various standard
classification benchmarks, with six open-source LM families, we show that
zero-shot classification with simple contextualization of the data source of
the evaluation set consistently outperforms both zero-shot and few-shot
baselines while improving robustness to prompt variations. Further, our
approach enables personalizing classification in a zero-shot manner by
incorporating author, subject, or reader information in the label descriptions.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07120" title="Abstract">arXiv:2311.07120</a> [<a href="/pdf/2311.07120" title="Download PDF">pdf</a>, <a href="/ps/2311.07120" title="Download PostScript">ps</a>, <a href="/format/2311.07120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proceedings of the 21st International Overture Workshop
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Macedo%2C+H+D">Hugo Daniel Macedo</a>, 
<a href="/search/cs?searchtype=author&query=Pierce%2C+K">Ken Pierce</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">This volume contains the papers presented at the 21st International Overture
Workshop, held on the 10th of March 2023. This event was the latest in a series
of workshops around the Vienna Development Method (VDM), the open-source
project Overture, and related tools and formalisms. VDM is one of the longest
established formal methods for systems development. A lively community of
researchers and practitioners has grown up in academia and industry has grown
around the modelling languages (VDM-SL, VDM++, VDM-RT, CML) and tools
(VDMTools, Overture, Crescendo, Symphony, the INTO-CPS chain, and ViennaTalk).
Together, these provide a platform for work on modelling and analysis
technology that includes static and dynamic analysis, test generation,
execution support, and model checking. This workshop provided updates on the
emerging technology of VDM/Overture, including collaboration infrastructure,
collaborative modelling and co-simulation for Cyber-Physical Systems.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07125" title="Abstract">arXiv:2311.07125</a> [<a href="/pdf/2311.07125" title="Download PDF">pdf</a>, <a href="/format/2311.07125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention-Challenging Multiple Instance Learning for Whole Slide Image  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yunlong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Honglin Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuxuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Sunyi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chenglu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lin Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Overfitting remains a significant challenge in the application of Multiple
Instance Learning (MIL) methods for Whole Slide Image (WSI) analysis.
Visualizing heatmaps reveals that current MIL methods focus on a subset of
predictive instances, hindering effective model generalization. To tackle this,
we propose Attention-Challenging MIL (ACMIL), aimed at forcing the attention
mechanism to capture more challenging predictive instances. ACMIL incorporates
two techniques, Multiple Branch Attention (MBA) to capture richer predictive
instances and Stochastic Top-K Instance Masking (STKIM) to suppress simple
predictive instances. Evaluation on three WSI datasets outperforms
state-of-the-art methods. Additionally, through heatmap visualization, UMAP
visualization, and attention value statistics, this paper comprehensively
illustrates ACMIL's effectiveness in overcoming the overfitting challenge. The
source code is available at \url{https://github.com/dazhangyu123/ACMIL}.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07126" title="Abstract">arXiv:2311.07126</a> [<a href="/pdf/2311.07126" title="Download PDF">pdf</a>, <a href="/format/2311.07126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Do Machine Learning with Small Data? -- A Review from an  Industrial Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kraljevski%2C+I">Ivan Kraljevski</a>, 
<a href="/search/cs?searchtype=author&query=Ju%2C+Y+C">Yong Chul Ju</a>, 
<a href="/search/cs?searchtype=author&query=Ivanov%2C+D">Dmitrij Ivanov</a>, 
<a href="/search/cs?searchtype=author&query=Tsch%C3%B6pe%2C+C">Constanze Tsch&#xf6;pe</a>, 
<a href="/search/cs?searchtype=author&query=Wolff%2C+M">Matthias Wolff</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Artificial intelligence experienced a technological breakthrough in science,
industry, and everyday life in the recent few decades. The advancements can be
credited to the ever-increasing availability and miniaturization of
computational resources that resulted in exponential data growth. However,
because of the insufficient amount of data in some cases, employing machine
learning in solving complex tasks is not straightforward or even possible. As a
result, machine learning with small data experiences rising importance in data
science and application in several fields. The authors focus on interpreting
the general term of "small data" and their engineering and industrial
application role. They give a brief overview of the most important industrial
applications of machine learning and small data. Small data is defined in terms
of various characteristics compared to big data, and a machine learning
formalism was introduced. Five critical challenges of machine learning with
small data in industrial applications are presented: unlabeled data, imbalanced
data, missing data, insufficient data, and rare events. Based on those
definitions, an overview of the considerations in domain representation and
data acquisition is given along with a taxonomy of machine learning approaches
in the context of small data.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07127" title="Abstract">arXiv:2311.07127</a> [<a href="/pdf/2311.07127" title="Download PDF">pdf</a>, <a href="/format/2311.07127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Untargeted Black-box Attacks for Social Recommendations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+W">Wenqi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shijie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xiao-yong Wei</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+X">Xiaowei Mei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qing Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The rise of online social networks has facilitated the evolution of social
recommender systems, which incorporate social relations to enhance users'
decision-making process. With the great success of Graph Neural Networks in
learning node representations, GNN-based social recommendations have been
widely studied to model user-item interactions and user-user social relations
simultaneously. Despite their great successes, recent studies have shown that
these advanced recommender systems are highly vulnerable to adversarial
attacks, in which attackers can inject well-designed fake user profiles to
disrupt recommendation performances. While most existing studies mainly focus
on targeted attacks to promote target items on vanilla recommender systems,
untargeted attacks to degrade the overall prediction performance are less
explored on social recommendations under a black-box scenario. To perform
untargeted attacks on social recommender systems, attackers can construct
malicious social relationships for fake users to enhance the attack
performance. However, the coordination of social relations and item profiles is
challenging for attacking black-box social recommendations. To address this
limitation, we first conduct several preliminary studies to demonstrate the
effectiveness of cross-community connections and cold-start items in degrading
recommendations performance. Specifically, we propose a novel framework
Multiattack based on multi-agent reinforcement learning to coordinate the
generation of cold-start item profiles and cross-community social relations for
conducting untargeted attacks on black-box social recommendations.
Comprehensive experiments on various real-world datasets demonstrate the
effectiveness of our proposed attacking framework under the black-box setting.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07128" title="Abstract">arXiv:2311.07128</a> [<a href="/pdf/2311.07128" title="Download PDF">pdf</a>, <a href="/format/2311.07128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sum Rate Maximization under AoI Constraints for RIS-Assisted mmWave  Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Ziqi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+Y">Yong Niu</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+S">Shiwen Mao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Changming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Ning Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Z">Zhangdui Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+B">Bo Ai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The concept of age of information (AoI) has been proposed to quantify
information freshness, which is crucial for time-sensitive applications.
However, in millimeter wave (mmWave) communication systems, the link blockage
caused by obstacles and the severe path loss greatly impair the freshness of
information received by the user equipments (UEs). In this paper, we focus on
reconfigurable intelligent surface (RIS)-assisted mmWave communications, where
beamforming is performed at transceivers to provide directional beam gain and a
RIS is deployed to combat link blockage. We aim to maximize the system sum rate
while satisfying the information freshness requirements of UEs by jointly
optimizing the beamforming at transceivers, the discrete RIS reflection
coefficients, and the UE scheduling strategy. To facilitate a practical
solution, we decompose the problem into two subproblems. For the first per-UE
data rate maximization problem, we further decompose it into a beamforming
optimization subproblem and a RIS reflection coefficient optimization
subproblem. Considering the difficulty of channel estimation, we utilize the
hierarchical search method for the former and the local search method for the
latter, and then adopt the block coordinate descent (BCD) method to alternately
solve them. For the second scheduling strategy design problem, a low-complexity
heuristic scheduling algorithm is designed. Simulation results show that the
proposed algorithm can effectively improve the system sum rate while satisfying
the information freshness requirements of all UEs.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07132" title="Abstract">arXiv:2311.07132</a> [<a href="/pdf/2311.07132" title="Download PDF">pdf</a>, <a href="/format/2311.07132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Path Planning Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Halilovic%2C+A">Amar Halilovic</a>, 
<a href="/search/cs?searchtype=author&query=Krivic%2C+S">Senka Krivic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Navigation is a must-have skill for any mobile robot. A core challenge in
navigation is the need to account for an ample number of possible
configurations of environment and navigation contexts. We claim that a mobile
robot should be able to explain its navigational choices making its decisions
understandable to humans. In this paper, we briefly present our approach to
explaining navigational decisions of a robot through visual and textual
explanations. We propose a user study to test the understandability and
simplicity of the robot explanations and outline our further research agenda.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07134" title="Abstract">arXiv:2311.07134</a> [<a href="/pdf/2311.07134" title="Download PDF">pdf</a>, <a href="/format/2311.07134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance Analysis of Integrated Data and Energy Transfer Assisted by  Fluid Antenna Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xiao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Halvin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yizhe Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jie Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K">Kai-Kit Wong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Fluid antenna multiple access (FAMA) is capable of exploiting the high
spatial diversity of wireless channels to mitigate multi-user interference via
flexible port switching, which achieves a better performance than traditional
multi-input-multi-output (MIMO) systems. Moreover, integrated data and energy
transfer (IDET) is able to provide both the wireless data transfer (WDT) and
wireless energy transfer (WET) services towards low-power devices. In this
paper, a FAMA assisted IDET system is studied, where $N$ access points (APs)
provide dedicated IDET services towards $N$ user equipments (UEs). Each UE is
equipped with a single fluid antenna. The performance of WDT and WET ,
\textit{i.e.}, the WDT outage probability, the WET outage probability, the
reliable throughput and the average energy harvesting amount, are analysed
theoretically by using time switching (TS) between WDT and WET. Numerical
results validate our theoretical analysis, which reveals that the number of UEs
and TS ratio should be optimized to achieve a trade-off between the WDT and WET
performance. Moreover, FAMA assisted IDET achieves a better performance in
terms of both WDT and WET than traditional MIMO with the same antenna size.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07138" title="Abstract">arXiv:2311.07138</a> [<a href="/pdf/2311.07138" title="Download PDF">pdf</a>, <a href="/format/2311.07138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WaterBench: Towards Holistic Evaluation of Watermarks for Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tu%2C+S">Shangqing Tu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuliang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yushi Bai</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jifan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+L">Lei Hou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Juanzi Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">To mitigate the potential misuse of large language models (LLMs), recent
research has developed watermarking algorithms, which restrict the generation
process to leave an invisible trace for watermark detection. Due to the
two-stage nature of the task, most studies evaluate the generation and
detection separately, thereby presenting a challenge in unbiased, thorough, and
applicable evaluations. In this paper, we introduce WaterBench, the first
comprehensive benchmark for LLM watermarks, in which we design three crucial
factors: (1) For \textbf{benchmarking procedure}, to ensure an apples-to-apples
comparison, we first adjust each watermarking method's hyper-parameter to reach
the same watermarking strength, then jointly evaluate their generation and
detection performance. (2) For \textbf{task selection}, we diversify the input
and output length to form a five-category taxonomy, covering $9$ tasks. (3) For
\textbf{evaluation metric}, we adopt the GPT4-Judge for automatically
evaluating the decline of instruction-following abilities after watermarking.
We evaluate $4$ open-source watermarks on $2$ LLMs under $2$ watermarking
strengths and observe the common struggles for current methods on maintaining
the generation quality. The code and data are available at
\url{https://github.com/THU-KEG/WaterBench}.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07139" title="Abstract">arXiv:2311.07139</a> [<a href="/pdf/2311.07139" title="Download PDF">pdf</a>, <a href="/format/2311.07139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing and Predicting Low-Listenership Trends in a Large-Scale Mobile  Health Program: A Preliminary Investigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lalan%2C+A">Arshika Lalan</a>, 
<a href="/search/cs?searchtype=author&query=Verma%2C+S">Shresth Verma</a>, 
<a href="/search/cs?searchtype=author&query=Sudan%2C+K+M">Kumar Madhu Sudan</a>, 
<a href="/search/cs?searchtype=author&query=Mahale%2C+A">Amrita Mahale</a>, 
<a href="/search/cs?searchtype=author&query=Hegde%2C+A">Aparna Hegde</a>, 
<a href="/search/cs?searchtype=author&query=Tambe%2C+M">Milind Tambe</a>, 
<a href="/search/cs?searchtype=author&query=Taneja%2C+A">Aparna Taneja</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Data Science for Social Good Workshop, KDD 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Mobile health programs are becoming an increasingly popular medium for
dissemination of health information among beneficiaries in less privileged
communities. Kilkari is one of the world's largest mobile health programs which
delivers time sensitive audio-messages to pregnant women and new mothers. We
have been collaborating with ARMMAN, a non-profit in India which operates the
Kilkari program, to identify bottlenecks to improve the efficiency of the
program. In particular, we provide an initial analysis of the trajectories of
beneficiaries' interaction with the mHealth program and examine elements of the
program that can be potentially enhanced to boost its success. We cluster the
cohort into different buckets based on listenership so as to analyze
listenership patterns for each group that could help boost program success. We
also demonstrate preliminary results on using historical data in a time-series
prediction to identify beneficiary dropouts and enable NGOs in devising timely
interventions to strengthen beneficiary retention.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07140" title="Abstract">arXiv:2311.07140</a> [<a href="/pdf/2311.07140" title="Download PDF">pdf</a>, <a href="/format/2311.07140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Linear Parameter-Varying Approach to Data Predictive Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Verhoek%2C+C">Chris Verhoek</a>, 
<a href="/search/eess?searchtype=author&query=Berberich%2C+J">Julian Berberich</a>, 
<a href="/search/eess?searchtype=author&query=Haesaert%2C+S">Sofie Haesaert</a>, 
<a href="/search/eess?searchtype=author&query=T%C3%B3th%2C+R">Roland T&#xf3;th</a>, 
<a href="/search/eess?searchtype=author&query=Abbas%2C+H+S">Hossam S. Abbas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE-TAC. Extended version. 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">By means of the linear parameter-varying (LPV) Fundamental Lemma, we derive
novel data-driven predictive control (DPC) methods for LPV systems. In
particular, we present output-feedback and state-feedback-based LPV-DPC methods
with terminal ingredients, which guarantee exponential stability and recursive
feasibility. We provide methods for the data-based computation of these
terminal ingredients. Furthermore, an in-depth analysis of the properties and
implementation aspects of the LPV-DPC schemes is given, including alternative
recursive formulations, application for nonlinear systems and handling
noise-disturbed data. We demonstrate the performance of the proposed methods on
a simulation example involving a nonlinear unbalanced disc system.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07141" title="Abstract">arXiv:2311.07141</a> [<a href="/pdf/2311.07141" title="Download PDF">pdf</a>, <a href="/format/2311.07141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SABAF: Removing Strong Attribute Bias from Neural Networks with  Adversarial Filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiazhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Khayatkhoei%2C+M">Mahyar Khayatkhoei</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiageng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Hanchen Xie</a>, 
<a href="/search/cs?searchtype=author&query=Hussein%2C+M+E">Mohamed E. Hussein</a>, 
<a href="/search/cs?searchtype=author&query=AbdAlmageed%2C+W">Wael AbdAlmageed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 18 figures, 32 tables. Code will be released at <a href="https://github.com/jiazhi412/strong_attribute_bias.">this https URL</a> arXiv admin note: text overlap with <a href="/abs/2310.04955">arXiv:2310.04955</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Ensuring a neural network is not relying on protected attributes (e.g., race,
sex, age) for prediction is crucial in advancing fair and trustworthy AI. While
several promising methods for removing attribute bias in neural networks have
been proposed, their limitations remain under-explored. To that end, in this
work, we mathematically and empirically reveal the limitation of existing
attribute bias removal methods in presence of strong bias and propose a new
method that can mitigate this limitation. Specifically, we first derive a
general non-vacuous information-theoretical upper bound on the performance of
any attribute bias removal method in terms of the bias strength, revealing that
they are effective only when the inherent bias in the dataset is relatively
weak. Next, we derive a necessary condition for the existence of any method
that can remove attribute bias regardless of the bias strength. Inspired by
this condition, we then propose a new method using an adversarial objective
that directly filters out protected attributes in the input space while
maximally preserving all other attributes, without requiring any specific
target label. The proposed method achieves state-of-the-art performance in both
strong and moderate bias settings. We provide extensive experiments on
synthetic, image, and census datasets, to verify the derived theoretical bound
and its consequences in practice, and evaluate the effectiveness of the
proposed method in removing strong attribute bias.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07142" title="Abstract">arXiv:2311.07142</a> [<a href="/pdf/2311.07142" title="Download PDF">pdf</a>, <a href="/format/2311.07142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical integrator for highly oscillatory differential equations based  on the Neumann series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Perczy%C5%84ski%2C+R">Rafa&#x142; Perczy&#x144;ski</a>, 
<a href="/search/math?searchtype=author&query=Madejski%2C+G">Grzegorz Madejski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We propose a third-order numerical integrator based on the Neumann series and
the Filon quadrature, designed mainly for highly oscillatory partial
differential equations. The method can be applied to equations that exhibit
small or moderate oscillations; however, counter-intuitively, large
oscillations increase the accuracy of the scheme. With the proposed approach,
the convergence order of the method can be easily improved. Error analysis of
the method is also performed. We consider linear evolution equations involving
first- and second-time derivatives that feature elliptic differential
operators, such as the heat equation or the wave equation. Numerical
experiments consider the case in which the space dimension is greater than one
and confirm the theoretical study.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07143" title="Abstract">arXiv:2311.07143</a> [<a href="/pdf/2311.07143" title="Download PDF">pdf</a>, <a href="/format/2311.07143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Symmetrization for Equivariance with Orbit Distance  Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+D">Tien Dat Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jinwoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hongseok Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+S">Seunghoon Hong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We present a general framework for symmetrizing an arbitrary neural-network
architecture and making it equivariant with respect to a given group. We build
upon the proposals of Kim et al. (2023); Kaba et al. (2023) for symmetrization,
and improve them by replacing their conversion of neural features into group
representations, with an optimization whose loss intuitively measures the
distance between group orbits. This change makes our approach applicable to a
broader range of matrix groups, such as the Lorentz group O(1, 3), than these
two proposals. We experimentally show our method's competitiveness on the SO(2)
image classification task, and also its increased generality on the task with
O(1, 3). Our implementation will be made accessible at
https://github.com/tiendatnguyen-vision/Orbit-symmetrize.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07150" title="Abstract">arXiv:2311.07150</a> [<a href="/pdf/2311.07150" title="Download PDF">pdf</a>, <a href="/format/2311.07150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interaction is all You Need? A Study of Robots Ability to Understand and  Execute
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koshti%2C+K">Kushal Koshti</a>, 
<a href="/search/cs?searchtype=author&query=Bhavsar%2C+N">Nidhir Bhavsar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This paper aims to address a critical challenge in robotics, which is
enabling them to operate seamlessly in human environments through natural
language interactions. Our primary focus is to equip robots with the ability to
understand and execute complex instructions in coherent dialogs to facilitate
intricate task-solving scenarios. To explore this, we build upon the Execution
from Dialog History (EDH) task from the Teach benchmark. We employ a
multi-transformer model with BART LM. We observe that our best configuration
outperforms the baseline with a success rate score of 8.85 and a
goal-conditioned success rate score of 14.02. In addition, we suggest an
alternative methodology for completing this task. Moreover, we introduce a new
task by expanding the EDH task and making predictions about game plans instead
of individual actions. We have evaluated multiple BART models and an LLaMA2
LLM, which has achieved a ROGUE-L score of 46.77 for this task.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07152" title="Abstract">arXiv:2311.07152</a> [<a href="/pdf/2311.07152" title="Download PDF">pdf</a>, <a href="/format/2311.07152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting As Labeling: Rethinking LiDAR-camera Fusion in 3D Object  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Junjie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yun Ye</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Z">Zhujin Liang</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Yi Shan</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+D">Dalong Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D object Detection with LiDAR-camera encounters overfitting in algorithm
development which is derived from the violation of some fundamental rules. We
refer to the data annotation in dataset construction for theory complementing
and argue that the regression task prediction should not involve the feature
from the camera branch. By following the cutting-edge perspective of 'Detecting
As Labeling', we propose a novel paradigm dubbed DAL. With the most classical
elementary algorithms, a simple predicting pipeline is constructed by imitating
the data annotation process. Then we train it in the simplest way to minimize
its dependency and strengthen its portability. Though simple in construction
and training, the proposed DAL paradigm not only substantially pushes the
performance boundary but also provides a superior trade-off between speed and
accuracy among all existing methods. With comprehensive superiority, DAL is an
ideal baseline for both future work development and practical deployment. The
code has been released to facilitate future work on
https://github.com/HuangJunJie2017/BEVDet.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07155" title="Abstract">arXiv:2311.07155</a> [<a href="/pdf/2311.07155" title="Download PDF">pdf</a>, <a href="/format/2311.07155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sync Pure Counterfactual Regret Minimization in Incomplete Information  Extensive Form Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ju%2C+Q">Qi Ju</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Counterfactual Regret Minimization (CFR) and its variants developed based
upon Regret Matching (RM) have been considered to be the best method to solve
incomplete information extensive form games. In addition to RM and CFR,
Fictitious Play (FP) is another equilibrium computation algorithm in normal
form games. Previous experience has shown that the convergence rate of FP is
slower than RM and FP is difficult to use in extensive form games. However,
recent research has made improvements in both issues. Firstly, Abernethy
proposed a new FP variant sync FP, which has faster convergence rate than RM+.
Secondly, Qi introduced FP into extensive form games and proposed Pure CFR
(PCFR). This paper combines these two improvements, resulting in a new
algorithm sync PCFR. In our experiment, the convergence rate of sync PCFR is
approximately an order of magnitude faster than CFR+ (state-of-the-art
algorithm for equilibrium computation in incomplete information extensive form
games), while requiring less memory in an iteration.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07161" title="Abstract">arXiv:2311.07161</a> [<a href="/pdf/2311.07161" title="Download PDF">pdf</a>, <a href="/format/2311.07161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Developing a Named Entity Recognition Dataset for Tagalog
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miranda%2C+L+J+V">Lester James V. Miranda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in The First Workshop for Southeast Asian Language Processing 2023 at IJCNLP-AACL
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We present the development of a Named Entity Recognition (NER) dataset for
Tagalog. This corpus helps fill the resource gap present in Philippine
languages today, where NER resources are scarce. The texts were obtained from a
pretraining corpora containing news reports, and were labeled by native
speakers in an iterative fashion. The resulting dataset contains ~7.8k
documents across three entity types: Person, Organization, and Location. The
inter-annotator agreement, as measured by Cohen's $\kappa$, is 0.81. We also
conducted extensive empirical evaluation of state-of-the-art methods across
supervised and transfer learning settings. Finally, we released the data and
processing code publicly to inspire future work on Tagalog NLP.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07162" title="Abstract">arXiv:2311.07162</a> [<a href="/pdf/2311.07162" title="Download PDF">pdf</a>, <a href="/format/2311.07162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CycleGANAS: Differentiable Neural Architecture Search for CycleGAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=An%2C+T">Taegun An</a>, 
<a href="/search/cs?searchtype=author&query=Joo%2C+C">Changhee Joo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">We develop a Neural Architecture Search (NAS) framework for CycleGAN that
carries out unpaired image-to-image translation task. Extending previous NAS
techniques for Generative Adversarial Networks (GANs) to CycleGAN is not
straightforward due to the task difference and greater search space. We design
architectures that consist of a stack of simple ResNet-based cells and develop
a search method that effectively explore the large search space. We show that
our framework, called CycleGANAS, not only effectively discovers
high-performance architectures that either match or surpass the performance of
the original CycleGAN, but also successfully address the data imbalance by
individual architecture search for each translation direction. To our best
knowledge, it is the first NAS result for CycleGAN and shed light on NAS for
more complex structures.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07163" title="Abstract">arXiv:2311.07163</a> [<a href="/pdf/2311.07163" title="Download PDF">pdf</a>, <a href="/format/2311.07163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Lightweight Neural Networks for Small Object Detection in IoT  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boyle%2C+L">Liam Boyle</a>, 
<a href="/search/cs?searchtype=author&query=Baumann%2C+N">Nicolas Baumann</a>, 
<a href="/search/cs?searchtype=author&query=Heo%2C+S">Seonyeong Heo</a>, 
<a href="/search/cs?searchtype=author&query=Magno%2C+M">Michele Magno</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Advances in lightweight neural networks have revolutionized computer vision
in a broad range of IoT applications, encompassing remote monitoring and
process automation. However, the detection of small objects, which is crucial
for many of these applications, remains an underexplored area in current
computer vision research, particularly for embedded devices. To address this
gap, the paper proposes a novel adaptive tiling method that can be used on top
of any existing object detector including the popular FOMO network for object
detection on microcontrollers. Our experimental results show that the proposed
tiling method can boost the F1-score by up to 225% while reducing the average
object count error by up to 76%. Furthermore, the findings of this work suggest
that using a soft F1 loss over the popular binary cross-entropy loss can
significantly reduce the negative impact of imbalanced data. Finally, we
validate our approach by conducting experiments on the Sony Spresense
microcontroller, showcasing the proposed method's ability to strike a balance
between detection performance, low latency, and minimal memory consumption.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07164" title="Abstract">arXiv:2311.07164</a> [<a href="/pdf/2311.07164" title="Download PDF">pdf</a>, <a href="/format/2311.07164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pruning random resistive memory for optimizing analogue AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yi Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Songqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yaping Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shaocong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Woyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yangu He</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+N">Ning Lin</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+B">Binbin Cui</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Hao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+P">Peng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xumeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xiaojuan Qi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhongrui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaoxin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+D">Dashan Shang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+K">Kwang-Ting Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Ming Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR)

</div>
<p class="mathjax">The rapid advancement of artificial intelligence (AI) has been marked by the
large language models exhibiting human-like intelligence. However, these models
also present unprecedented challenges to energy consumption and environmental
sustainability. One promising solution is to revisit analogue computing, a
technique that predates digital computing and exploits emerging analogue
electronic devices, such as resistive memory, which features in-memory
computing, high scalability, and nonvolatility. However, analogue computing
still faces the same challenges as before: programming nonidealities and
expensive programming due to the underlying devices physics. Here, we report a
universal solution, software-hardware co-design using structural
plasticity-inspired edge pruning to optimize the topology of a randomly
weighted analogue resistive memory neural network. Software-wise, the topology
of a randomly weighted neural network is optimized by pruning connections
rather than precisely tuning resistive memory weights. Hardware-wise, we reveal
the physical origin of the programming stochasticity using transmission
electron microscopy, which is leveraged for large-scale and low-cost
implementation of an overparameterized random neural network containing
high-performance sub-networks. We implemented the co-design on a 40nm 256K
resistive memory macro, observing 17.3% and 19.9% accuracy improvements in
image and audio classification on FashionMNIST and Spoken digits datasets, as
well as 9.8% (2%) improvement in PR (ROC) in image segmentation on DRIVE
datasets, respectively. This is accompanied by 82.1%, 51.2%, and 99.8%
improvement in energy efficiency thanks to analogue in-memory computing. By
embracing the intrinsic stochasticity and in-memory computing, this work may
solve the biggest obstacle of analogue computing systems and thus unleash their
immense potential for next-generation AI hardware.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07166" title="Abstract">arXiv:2311.07166</a> [<a href="/pdf/2311.07166" title="Download PDF">pdf</a>, <a href="/format/2311.07166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NDDepth: Normal-Distance Assisted Monocular Depth Estimation and  Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+S">Shuwei Shao</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+Z">Zhongcai Pei</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weihai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P+C+Y">Peter C. Y. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhengguo Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extension of previous work <a href="/abs/2309.10592">arXiv:2309.10592</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Over the past few years, monocular depth estimation and completion have been
paid more and more attention from the computer vision community because of
their widespread applications. In this paper, we introduce novel physics
(geometry)-driven deep learning frameworks for these two tasks by assuming that
3D scenes are constituted with piece-wise planes. Instead of directly
estimating the depth map or completing the sparse depth map, we propose to
estimate the surface normal and plane-to-origin distance maps or complete the
sparse surface normal and distance maps as intermediate outputs. To this end,
we develop a normal-distance head that outputs pixel-level surface normal and
distance. Meanwhile, the surface normal and distance maps are regularized by a
developed plane-aware consistency constraint, which are then transformed into
depth maps. Furthermore, we integrate an additional depth head to strengthen
the robustness of the proposed frameworks. Extensive experiments on the
NYU-Depth-v2, KITTI and SUN RGB-D datasets demonstrate that our method exceeds
in performance prior state-of-the-art monocular depth estimation and completion
competitors. The source code will be available at
https://github.com/ShuweiShao/NDDepth.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07167" title="Abstract">arXiv:2311.07167</a> [<a href="/pdf/2311.07167" title="Download PDF">pdf</a>, <a href="/format/2311.07167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STEER: Unified Style Transfer with Expert Reinforcement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hallinan%2C+S">Skyler Hallinan</a>, 
<a href="/search/cs?searchtype=author&query=Brahman%2C+F">Faeze Brahman</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Ximing Lu</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+J">Jaehun Jung</a>, 
<a href="/search/cs?searchtype=author&query=Welleck%2C+S">Sean Welleck</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yejin Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> for associated code, see <a href="https://github.com/shallinan1/STEERStyleTransfer">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">While text style transfer has many applications across natural language
processing, the core premise of transferring from a single source style is
unrealistic in a real-world setting. In this work, we focus on arbitrary style
transfer: rewriting a text from an arbitrary, unknown style to a target style.
<br />We propose STEER: Unified Style Transfer with Expert Reinforcement, a unified
frame-work developed to overcome the challenge of limited parallel data for
style transfer. STEER involves automatically generating a corpus of
style-transfer pairs using a product of experts during decoding. The generated
offline data is then used to pre-train an initial policy before switching to
online, off-policy reinforcement learning for further improvements via
fine-grained reward signals. STEER is unified and can transfer to multiple
target styles from an arbitrary, unknown source style, making it particularly
flexible and efficient.
<br />Experimental results on a challenging dataset with text from a diverse set of
styles demonstrate state-of-the-art results compared to competitive baselines.
Remarkably, STEER outperforms the 175B parameter instruction-tuned GPT-3 on
overall style transfer quality, despite being 226 times smaller in size. We
also show STEER is robust, maintaining its style transfer capabilities on
out-of-domain data, and surpassing nearly all baselines across various styles.
The success of our method highlights the potential of RL algorithms when
augmented with controllable decoding to overcome the challenge of limited data
supervision.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07170" title="Abstract">arXiv:2311.07170</a> [<a href="/pdf/2311.07170" title="Download PDF">pdf</a>, <a href="/format/2311.07170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regenerating Arbitrary Video Sequences with Distillation Path-Finding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+T">Thi-Ngoc-Hanh Le</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+S">Sheng-Yi Yao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chun-Te Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+T">Tong-Yee Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted for publication on IEEE Transactions on Visualization and Computer Graphics (TVCG), January 2023. Project website: <a href="http://graphics.csie.ncku.edu.tw/SDPF">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">If the video has long been mentioned as a widespread visualization form, the
animation sequence in the video is mentioned as storytelling for people.
Producing an animation requires intensive human labor from skilled professional
artists to obtain plausible animation in both content and motion direction,
incredibly for animations with complex content, multiple moving objects, and
dense movement. This paper presents an interactive framework to generate new
sequences according to the users' preference on the starting frame. The
critical contrast of our approach versus prior work and existing commercial
applications is that novel sequences with arbitrary starting frame are produced
by our system with a consistent degree in both content and motion direction. To
achieve this effectively, we first learn the feature correlation on the
frameset of the given video through a proposed network called RSFNet. Then, we
develop a novel path-finding algorithm, SDPF, which formulates the knowledge of
motion directions of the source video to estimate the smooth and plausible
sequences. The extensive experiments show that our framework can produce new
animations on the cartoon and natural scenes and advance prior works and
commercial applications to enable users to obtain more predictable results.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07171" title="Abstract">arXiv:2311.07171</a> [<a href="/pdf/2311.07171" title="Download PDF">pdf</a>, <a href="/format/2311.07171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> calamanCy: A Tagalog Natural Language Processing Toolkit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miranda%2C+L+J+V">Lester James V. Miranda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in The Third Workshop for NLP-OSS at EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We introduce calamanCy, an open-source toolkit for constructing natural
language processing (NLP) pipelines for Tagalog. It is built on top of spaCy,
enabling easy experimentation and integration with other frameworks. calamanCy
addresses the development gap by providing a consistent API for building NLP
applications and offering general-purpose multitask models with out-of-the-box
support for dependency parsing, parts-of-speech (POS) tagging, and named entity
recognition (NER). calamanCy aims to accelerate the progress of Tagalog NLP by
consolidating disjointed resources in a unified framework. The calamanCy
toolkit is available on GitHub: https://github.com/ljvmiranda921/calamanCy.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07172" title="Abstract">arXiv:2311.07172</a> [<a href="/pdf/2311.07172" title="Download PDF">pdf</a>, <a href="/format/2311.07172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VerityMath: Advancing Mathematical Reasoning by Self-Verification  Through Unit Consistency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Toh%2C+V">Vernon Toh</a>, 
<a href="/search/cs?searchtype=author&query=Puduppully%2C+R">Ratish Puduppully</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+N+F">Nancy F. Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in Progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">Large Language Models (LLMs) combined with program-based solving techniques
are increasingly demonstrating proficiency in mathematical reasoning. However,
such progress is mostly demonstrated in closed-source models such as
OpenAI-GPT4 and Claude. In this paper, we seek to study the performance of
strong open-source LLMs. Specifically, we analyze the outputs of Code Llama
(7B) when applied to math word problems. We identify a category of problems
that pose a challenge for the model, particularly those involving quantities
that span multiple types or units. To address this issue, we propose a
systematic approach by defining units for each quantity and ensuring the
consistency of these units during mathematical operations. We developed Unit
Consistency Programs (UCPs), an annotated dataset of math word problems, each
paired with programs that contain unit specifications and unit verification
routines. Finally, we finetune the Code Llama (7B) model with UCPs to produce
VerityMath and present our preliminary findings.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07175" title="Abstract">arXiv:2311.07175</a> [<a href="/pdf/2311.07175" title="Download PDF">pdf</a>, <a href="/ps/2311.07175" title="Download PostScript">ps</a>, <a href="/format/2311.07175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Research and experimental verification on low-frequency long-range sound  propagation characteristics under ice-covered and range-dependent marine  environment in the Arctic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weng%2C+J">Jinbao Weng</a> (1), 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yubo Qi</a> (2), 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yanming Yang</a> (1), 
<a href="/search/cs?searchtype=author&query=Wen%2C+H">Hongtao Wen</a> (1), 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hongtao Zhou</a> (1), 
<a href="/search/cs?searchtype=author&query=Xue%2C+R">Ruichao Xue</a> (1) (1.Laboratory of Ocean acoustics and Remote Sensing, Institute of Oceanography, Ministry of Natural Resources, Xiamen, Fujian 361005, China, 2.State key laboratory of acoustics, Institute of Acoustics, Chinese Academy of Sciences, Beijing 100190, China)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 46 pages, 35 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Numerical Analysis (math.NA); Atmospheric and Oceanic Physics (physics.ao-ph); Applied Physics (physics.app-ph)

</div>
<p class="mathjax">At present, research on sound propagation under the Arctic ice mainly focuses
on modeling and experimental verification of sound propagation under sea ice
cover and unique sound velocity profiles. Among them, the main research object
of concern is sound transmission loss, and this article will delve into the
time-domain waveform and fine dispersion structure of low-frequency broadband
acoustic signals. Firstly, based on the theory of normal modes, this article
derives the horizontal wavenumber expression and warping transformation
operator for refractive normal modes in the Arctic deep-sea environment.
Subsequently, based on measured ocean environmental parameters and sound field
simulation calculations, this article studied the general laws of low-frequency
long-range sound propagation signals in the Arctic deep-sea environment, and
elucidated the impact mechanism of environmental factors such as seabed terrain
changes, horizontal changes in sound velocity profiles (SSPs), and sea ice
cover on low-frequency long-range sound propagation in the Arctic. This article
validates the above research viewpoint through a sound propagation experiment
conducted in the Arctic with a propagation distance exceeding 1000km. The
marine environment of this experiment has obvious horizontal variation
characteristics. At the same time, this article takes the lead in utilizing the
warping transformation of refractive normal waves in the Arctic waters to
achieve single hydrophone based separation of normal waves and extraction of
dispersion structures, which is conducive to future research on underwater
sound source localization and environmental parameter inversion based on
dispersion structures.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07178" title="Abstract">arXiv:2311.07178</a> [<a href="/pdf/2311.07178" title="Download PDF">pdf</a>, <a href="/format/2311.07178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Game Solving with Online Fine-Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Ti-Rong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Guei%2C+H">Hung Guei</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+T+H">Ting Han Wei</a>, 
<a href="/search/cs?searchtype=author&query=Shih%2C+C">Chung-Chin Shih</a>, 
<a href="/search/cs?searchtype=author&query=Chin%2C+J">Jui-Te Chin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+I">I-Chen Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG)

</div>
<p class="mathjax">Game solving is a similar, yet more difficult task than mastering a game.
Solving a game typically means to find the game-theoretic value (outcome given
optimal play), and optionally a full strategy to follow in order to achieve
that outcome. The AlphaZero algorithm has demonstrated super-human level play,
and its powerful policy and value predictions have also served as heuristics in
game solving. However, to solve a game and obtain a full strategy, a winning
response must be found for all possible moves by the losing player. This
includes very poor lines of play from the losing side, for which the AlphaZero
self-play process will not encounter. AlphaZero-based heuristics can be highly
inaccurate when evaluating these out-of-distribution positions, which occur
throughout the entire search. To address this issue, this paper investigates
applying online fine-tuning while searching and proposes two methods to learn
tailor-designed heuristics for game solving. Our experiments show that using
online fine-tuning can solve a series of challenging 7x7 Killall-Go problems,
using only 23.54% of computation time compared to the baseline without online
fine-tuning. Results suggest that the savings scale with problem size. Our
method can further be extended to any tree search algorithm for problem
solving. Our code is available at
https://rlg.iis.sinica.edu.tw/papers/neurips2023-online-fine-tuning-solver.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07179" title="Abstract">arXiv:2311.07179</a> [<a href="/pdf/2311.07179" title="Download PDF">pdf</a>, <a href="/format/2311.07179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SponTTS: modeling and transferring spontaneous style for TTS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hanzhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xinfa Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+L">Liumeng Xue</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yang Song</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yunlin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lei Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Spontaneous speaking style exhibits notable differences from other speaking
styles due to various spontaneous phenomena (e.g., filled pauses, prolongation)
and substantial prosody variation (e.g., diverse pitch and duration variation,
occasional non-verbal speech like smile), posing challenges to modeling and
prediction of spontaneous style. Moreover, the limitation of high-quality
spontaneous data constrains spontaneous speech generation for speakers without
spontaneous data. To address these problems, we propose SponTTS, a two-stage
approach based on bottleneck (BN) features to model and transfer spontaneous
style for TTS. In the first stage, we adopt a Conditional Variational
Autoencoder (CVAE) to capture spontaneous prosody from a BN feature and involve
the spontaneous phenomena by the constraint of spontaneous phenomena embedding
prediction loss. Besides, we introduce a flow-based predictor to predict a
latent spontaneous style representation from the text, which enriches the
prosody and context-specific spontaneous phenomena during inference. In the
second stage, we adopt a VITS-like module to transfer the spontaneous style
learned in the first stage to target speakers. Experiments demonstrate that
SponTTS is effective in modeling spontaneous style and transferring the style
to the target speakers, generating spontaneous speech with high naturalness,
expressiveness, and speaker similarity. The zero-shot spontaneous style TTS
test further verifies the generalization and robustness of SponTTS in
generating spontaneous speech for unseen speakers.
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07180" title="Abstract">arXiv:2311.07180</a> [<a href="/pdf/2311.07180" title="Download PDF">pdf</a>, <a href="/format/2311.07180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Graph Representations to enhance Intensive Care Time-Series  Predictions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+S">Samyak Jain</a>, 
<a href="/search/cs?searchtype=author&query=Burger%2C+M">Manuel Burger</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%A4tsch%2C+G">Gunnar R&#xe4;tsch</a>, 
<a href="/search/cs?searchtype=author&query=Kuznetsova%2C+R">Rita Kuznetsova</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2023, December 10th, 2023, New Orleans, United States, 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Intensive Care Units (ICU) require comprehensive patient data integration for
enhanced clinical outcome predictions, crucial for assessing patient
conditions. Recent deep learning advances have utilized patient time series
data, and fusion models have incorporated unstructured clinical reports,
improving predictive performance. However, integrating established medical
knowledge into these models has not yet been explored. The medical domain's
data, rich in structural relationships, can be harnessed through knowledge
graphs derived from clinical ontologies like the Unified Medical Language
System (UMLS) for better predictions. Our proposed methodology integrates this
knowledge with ICU data, improving clinical decision modeling. It combines
graph representations with vital signs and clinical reports, enhancing
performance, especially when data is missing. Additionally, our model includes
an interpretability component to understand how knowledge graph nodes affect
predictions.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07184" title="Abstract">arXiv:2311.07184</a> [<a href="/pdf/2311.07184" title="Download PDF">pdf</a>, <a href="/format/2311.07184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Axis Transformer with 2D Rotary Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Erickson%2C+L">Lily Erickson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Despite lagging behind their modal cousins in many respects, Vision
Transformers have provided an interesting opportunity to bridge the gap between
sequence modeling and image modeling. Up until now however, vision transformers
have largely been held back, due to both computational inefficiency, and lack
of proper handling of spatial dimensions. In this paper, we introduce the
Cross-Axis Transformer. CAT is a model inspired by both Axial Transformers, and
Microsoft's recent Retentive Network, that drastically reduces the required
number of floating point operations required to process an image, while
simultaneously converging faster and more accurately than the Vision
Transformers it replaces.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07185" title="Abstract">arXiv:2311.07185</a> [<a href="/pdf/2311.07185" title="Download PDF">pdf</a>, <a href="/ps/2311.07185" title="Download PostScript">ps</a>, <a href="/format/2311.07185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dedukti: a Logical Framework based on the $&#x3bb;$$&#x3a0;$-Calculus Modulo  Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Assaf%2C+A">Ali Assaf</a>, 
<a href="/search/cs?searchtype=author&query=Burel%2C+G">Guillaume Burel</a> (ENSIIE), 
<a href="/search/cs?searchtype=author&query=Cauderlier%2C+R">Rapha&#xeb;l Cauderlier</a>, 
<a href="/search/cs?searchtype=author&query=Delahaye%2C+D">David Delahaye</a> (CNAM), 
<a href="/search/cs?searchtype=author&query=Dowek%2C+G">Gilles Dowek</a>, 
<a href="/search/cs?searchtype=author&query=Dubois%2C+C">Catherine Dubois</a> (ENSIIE), 
<a href="/search/cs?searchtype=author&query=Gilbert%2C+F">Fr&#xe9;d&#xe9;ric Gilbert</a>, 
<a href="/search/cs?searchtype=author&query=Halmagrand%2C+P">Pierre Halmagrand</a>, 
<a href="/search/cs?searchtype=author&query=Hermant%2C+O">Olivier Hermant</a>, 
<a href="/search/cs?searchtype=author&query=Saillard%2C+R">Ronan Saillard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Dedukti is a Logical Framework based on the $\lambda$$\Pi$-Calculus Modulo
Theory. We show that many theories can be expressed in Dedukti: constructive
and classical predicate logic, Simple type theory, programming languages, Pure
type systems, the Calculus of inductive constructions with universes, etc. and
that permits to used it to check large libraries of proofs developed in other
proof systems: Zenon, iProver, FoCaLiZe, HOL Light, and Matita.
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07187" title="Abstract">arXiv:2311.07187</a> [<a href="/pdf/2311.07187" title="Download PDF">pdf</a>, <a href="/format/2311.07187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Inverse Obstacle Scattering Problem with Latent Surface  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+J">Junqing Chen</a>, 
<a href="/search/math?searchtype=author&query=Jin%2C+B">Bangti Jin</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+H">Haibo Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We propose a novel iterative numerical method to solve the three-dimensional
inverse obstacle scattering problem of recovering the shape of the obstacle
from far-field measurements. To address the inherent ill-posed nature of the
inverse problem, we advocate the use of a trained latent representation of
surfaces as the generative prior. This prior enjoys excellent expressivity
within the given class of shapes, and meanwhile, the latent dimensionality is
low, which greatly facilitates the computation. Thus, the admissible manifold
of surfaces is realistic and the resulting optimization problem is less
ill-posed. We employ the shape derivative to evolve the latent surface
representation, by minimizing the loss, and we provide a local convergence
analysis of a gradient descent type algorithm to a stationary point of the
loss. We present several numerical examples, including also backscattered and
phaseless data, to showcase the effectiveness of the proposed algorithm.
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07188" title="Abstract">arXiv:2311.07188</a> [<a href="/pdf/2311.07188" title="Download PDF">pdf</a>, <a href="/format/2311.07188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fitting tree model with CNN and geodesics to track vesselsand  application to Ultrasound Localization Microscopy data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bertrand%2C+T">Th&#xe9;o Bertrand</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+L+D">Laurent D. Cohen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Segmentation of tubular structures in vascular imaging is a well studied
task, although it is rare that we try to infuse knowledge of the tree-like
structure of the regions to be detected. Our work focuses on detecting the
important landmarks in the vascular network (via CNN performing both
localization and classification of the points of interest) and representing
vessels as the edges in some minimal distance tree graph. We leverage geodesic
methods relevant to the detection of vessels and their geometry, making use of
the space of positions and orientations so that 2D vessels can be accurately
represented as trees. We build our model to carry tracking on Ultrasound
Localization Microscopy (ULM) data, proposing to build a good cost function for
tracking on this type of data. We also test our framework on synthetic and eye
fundus data. Results show that scarcity of well annotated ULM data is an
obstacle to localization of vascular landmarks but the Orientation Score built
from ULM data yields good geodesics for tracking blood vessels.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07191" title="Abstract">arXiv:2311.07191</a> [<a href="/pdf/2311.07191" title="Download PDF">pdf</a>, <a href="/format/2311.07191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applying Large Language Models for Causal Structure Learning in Non  Small Cell Lung Cancer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naik%2C+N">Narmada Naik</a>, 
<a href="/search/cs?searchtype=author&query=Khandelwal%2C+A">Ayush Khandelwal</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+M">Mohit Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Atre%2C+M">Madhusudan Atre</a>, 
<a href="/search/cs?searchtype=author&query=Wright%2C+H">Hollis Wright</a>, 
<a href="/search/cs?searchtype=author&query=Kannan%2C+K">Kavya Kannan</a>, 
<a href="/search/cs?searchtype=author&query=Hill%2C+S">Scott Hill</a>, 
<a href="/search/cs?searchtype=author&query=Mamidipudi%2C+G">Giridhar Mamidipudi</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasa%2C+G">Ganapati Srinivasa</a>, 
<a href="/search/cs?searchtype=author&query=Bifulco%2C+C">Carlo Bifulco</a>, 
<a href="/search/cs?searchtype=author&query=Piening%2C+B">Brian Piening</a>, 
<a href="/search/cs?searchtype=author&query=Matlock%2C+K">Kevin Matlock</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Applications (stat.AP)

</div>
<p class="mathjax">Causal discovery is becoming a key part in medical AI research. These methods
can enhance healthcare by identifying causal links between biomarkers,
demographics, treatments and outcomes. They can aid medical professionals in
choosing more impactful treatments and strategies. In parallel, Large Language
Models (LLMs) have shown great potential in identifying patterns and generating
insights from text data. In this paper we investigate applying LLMs to the
problem of determining the directionality of edges in causal discovery.
Specifically, we test our approach on a deidentified set of Non Small Cell Lung
Cancer(NSCLC) patients that have both electronic health record and genomic
panel data. Graphs are validated using Bayesian Dirichlet estimators using
tabular data. Our result shows that LLMs can accurately predict the
directionality of edges in causal graphs, outperforming existing
state-of-the-art methods. These findings suggests that LLMs can play a
significant role in advancing causal discovery and help us better understand
complex systems.
</p>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07194" title="Abstract">arXiv:2311.07194</a> [<a href="/pdf/2311.07194" title="Download PDF">pdf</a>, <a href="/format/2311.07194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Dialogue Comprehension Ability of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=She%2C+S">Shuaijie She</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shujian Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xingyun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yanke Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiajun Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The recent emergence of large language models (LLMs) have attracted
considerable attention. LLMs may interact with users in the form of dialogue
and generate responses following their instructions, which naturally require
dialogue comprehension abilities. Without correct comprehension of the
dialogue, the model may inevitably generate incorrect responses. However,
dialogue comprehension is a general language ability which is hard to be
evaluated directly. In this work, we propose to perform the evaluation with the
help of the dialogue summarization task. Beside evaluating and analyzing the
dialogue summarization performance (DIAC-Sum), we also derive factual questions
from the generated summaries and use them as a more flexible measurement of
dialogue comprehension (DIAC-FactQA). Our evaluation shows that, on average,
27% of the summaries generated by LLMs contain factual inconsistency. Even
ChatGPT, the strongest evaluated model, has such errors in 16% of its
summaries. For answering the factual questions, which is more challenging, the
average accuracy of all evaluated LLMs is only 62.8%. Both results indicate
serious deficiencies. Detailed analysis shows that the understanding of
subject/object of the conversation is still the most challenging problem for
LLMs. Furthermore, to stimulate and enhance the dialogue comprehension ability
of LLMs, we propose a fine-tuning paradigm with auto-constructed multi-task
data. The experimental results demonstrate that our method achieved an accuracy
improvement of 8.9% on DIAC-FactQA.
</p>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07198" title="Abstract">arXiv:2311.07198</a> [<a href="/pdf/2311.07198" title="Download PDF">pdf</a>, <a href="/format/2311.07198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MonoDiffusion: Self-Supervised Monocular Depth Estimation Using  Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+S">Shuwei Shao</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+Z">Zhongcai Pei</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weihai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+D">Dingchi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P+C+Y">Peter C.Y.Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhengguo Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Over the past few years, self-supervised monocular depth estimation that does
not depend on ground-truth during the training phase has received widespread
attention. Most efforts focus on designing different types of network
architectures and loss functions or handling edge cases, e.g., occlusion and
dynamic objects. In this work, we introduce a novel self-supervised depth
estimation framework, dubbed MonoDiffusion, by formulating it as an iterative
denoising process. Because the depth ground-truth is unavailable in the
training phase, we develop a pseudo ground-truth diffusion process to assist
the diffusion in MonoDiffusion. The pseudo ground-truth diffusion gradually
adds noise to the depth map generated by a pre-trained teacher model.
Moreover,the teacher model allows applying a distillation loss to guide the
denoised depth. Further, we develop a masked visual condition mechanism to
enhance the denoising ability of model. Extensive experiments are conducted on
the KITTI and Make3D datasets and the proposed MonoDiffusion outperforms prior
state-of-the-art competitors. The source code will be available at
https://github.com/ShuweiShao/MonoDiffusion.
</p>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07202" title="Abstract">arXiv:2311.07202</a> [<a href="/pdf/2311.07202" title="Download PDF">pdf</a>, <a href="/format/2311.07202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Input Convex LSTM: A Convex Approach for Fast Lyapunov-Based Model  Predictive Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhe Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to 6th Annual Learning for Dynamics &amp; Control Conference (L4DC 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE); Systems and Control (eess.SY)

</div>
<p class="mathjax">Leveraging Input Convex Neural Networks (ICNNs), ICNN-based Model Predictive
Control (MPC) successfully attains globally optimal solutions by upholding
convexity within the MPC framework. However, current ICNN architectures
encounter the issue of vanishing gradients, which limits their ability to serve
as deep neural networks for complex tasks. Additionally, the current neural
network-based MPC, including conventional neural network-based MPC and
ICNN-based MPC, faces slower convergence speed when compared to MPC based on
first-principles models. In this study, we leverage the principles of ICNNs to
propose a novel Input Convex LSTM for Lyapunov-based MPC, with the specific
goal of reducing convergence time and mitigating the vanishing gradient problem
while ensuring closed-loop stability. From a simulation study of a nonlinear
chemical reactor, we observed a mitigation of vanishing gradient problem and a
reduction in convergence time, with a percentage decrease of 46.7%, 31.3%, and
20.2% compared to baseline plain RNN, plain LSTM, and Input Convex Recurrent
Neural Network, respectively.
</p>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07204" title="Abstract">arXiv:2311.07204</a> [<a href="/pdf/2311.07204" title="Download PDF">pdf</a>, <a href="/format/2311.07204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Elastic Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Benyou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Dawei Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 11 figures, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Large-scale pretrained language models have achieved compelling performance
in a wide range of language understanding and information retrieval tasks.
Knowledge distillation offers an opportunity to compress a large language model
to a small one, in order to reach a reasonable latency-performance tradeoff.
However, for scenarios where the number of requests (e.g., queries submitted to
a search engine) is highly variant, the static tradeoff attained by the
compressed language model might not always fit. Once a model is assigned with a
static tradeoff, it could be inadequate in that the latency is too high when
the number of requests is large or the performance is too low when the number
of requests is small. To this end, we propose an elastic language model
(ElasticLM) that elastically adjusts the tradeoff according to the request
stream. The basic idea is to introduce a compute elasticity to the compressed
language model, so that the tradeoff could vary on-the-fly along scalable and
controllable compute. Specifically, we impose an elastic structure to enable
ElasticLM with compute elasticity and design an elastic optimization to learn
ElasticLM under compute elasticity. To serve ElasticLM, we apply an elastic
schedule. Considering the specificity of information retrieval, we adapt
ElasticLM to dense retrieval and reranking and present ElasticDenser and
ElasticRanker respectively. Offline evaluation is conducted on a language
understanding benchmark GLUE; and several information retrieval tasks including
Natural Question, Trivia QA, and MS MARCO. The results show that ElasticLM
along with ElasticDenser and ElasticRanker can perform correctly and
competitively compared with an array of static baselines. Furthermore, online
simulation with concurrency is also carried out. The results demonstrate that
ElasticLM can provide elastic tradeoffs with respect to varying request stream.
</p>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07206" title="Abstract">arXiv:2311.07206</a> [<a href="/pdf/2311.07206" title="Download PDF">pdf</a>, <a href="/format/2311.07206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient adaptivity for simulating cardiac electrophysiology with  spectral deferred correction methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chegini%2C+F">Fatemeh Chegini</a>, 
<a href="/search/math?searchtype=author&query=Steinke%2C+T">Thomas Steinke</a>, 
<a href="/search/math?searchtype=author&query=Weiser%2C+M">Martin Weiser</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The locality of solution features in cardiac electrophysiology simulations
calls for adaptive methods. Due to the overhead incurred by established mesh
refinement and coarsening, however, such approaches failed in accelerating the
computations. Here we investigate a different route to spatial adaptivity that
is based on nested subset selection for algebraic degrees of freedom in
spectral deferred correction methods. This combination of algebraic adaptivity
and iterative solvers for higher order collocation time stepping realizes a
multirate integration with minimal overhead. This leads to moderate but
significant speedups in both monodomain and cell-by-cell models of cardiac
excitation, as demonstrated at four numerical examples.
</p>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07215" title="Abstract">arXiv:2311.07215</a> [<a href="/pdf/2311.07215" title="Download PDF">pdf</a>, <a href="/format/2311.07215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coffee: Boost Your Code LLMs by Fixing Bugs with Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moon%2C+S">Seungjun Moon</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yongho Song</a>, 
<a href="/search/cs?searchtype=author&query=Chae%2C+H">Hyungjoo Chae</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+D">Dongjin Kang</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+T">Taeyoon Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Ong%2C+K+T">Kai Tzu-iunn Ong</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+S">Seung-won Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Yeo%2C+J">Jinyoung Yeo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Code editing is an essential step towards reliable program synthesis to
automatically correct critical errors generated from code LLMs. Recent studies
have demonstrated that closed-source LLMs (i.e., ChatGPT and GPT-4) are capable
of generating corrective feedback to edit erroneous inputs. However, it remains
challenging for open-source code LLMs to generate feedback for code editing,
since these models tend to adhere to the superficial formats of feedback and
provide feedback with misleading information. Hence, the focus of our work is
to leverage open-source code LLMs to generate helpful feedback with correct
guidance for code editing. To this end, we present Coffee, a collected dataset
specifically designed for code fixing with feedback. Using this dataset, we
construct CoffeePots, a framework for COde Fixing with FEEdback via
Preference-Optimized Tuning and Selection. The proposed framework aims to
automatically generate helpful feedback for code editing while minimizing the
potential risk of superficial feedback. The combination of Coffee and
CoffeePots marks a significant advancement, achieving state-of-the-art
performance on HumanEvalFix benchmark. Codes and model checkpoints are publicly
available at https://github.com/Lune-Blue/COFFEE.
</p>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07216" title="Abstract">arXiv:2311.07216</a> [<a href="/pdf/2311.07216" title="Download PDF">pdf</a>, <a href="/format/2311.07216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few Shot Learning for the Classification of Confocal Laser  Endomicroscopy Images of Head and Neck Tumors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aubreville%2C+M">Marc Aubreville</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zhaoya Pan</a>, 
<a href="/search/cs?searchtype=author&query=Sievert%2C+M">Matti Sievert</a>, 
<a href="/search/cs?searchtype=author&query=Ammeling%2C+J">Jonas Ammeling</a>, 
<a href="/search/cs?searchtype=author&query=Ganz%2C+J">Jonathan Ganz</a>, 
<a href="/search/cs?searchtype=author&query=Oetter%2C+N">Nicolai Oetter</a>, 
<a href="/search/cs?searchtype=author&query=Stelzle%2C+F">Florian Stelzle</a>, 
<a href="/search/cs?searchtype=author&query=Frenken%2C+A">Ann-Kathrin Frenken</a>, 
<a href="/search/cs?searchtype=author&query=Breininger%2C+K">Katharina Breininger</a>, 
<a href="/search/cs?searchtype=author&query=Goncalves%2C+M">Miguel Goncalves</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The surgical removal of head and neck tumors requires safe margins, which are
usually confirmed intraoperatively by means of frozen sections. This method is,
in itself, an oversampling procedure, which has a relatively low sensitivity
compared to the definitive tissue analysis on paraffin-embedded sections.
Confocal laser endomicroscopy (CLE) is an in-vivo imaging technique that has
shown its potential in the live optical biopsy of tissue. An automated analysis
of this notoriously difficult to interpret modality would help surgeons.
However, the images of CLE show a wide variability of patterns, caused both by
individual factors but also, and most strongly, by the anatomical structures of
the imaged tissue, making it a challenging pattern recognition task. In this
work, we evaluate four popular few shot learning (FSL) methods towards their
capability of generalizing to unseen anatomical domains in CLE images. We
evaluate this on images of sinunasal tumors (SNT) from five patients and on
images of the vocal folds (VF) from 11 patients using a cross-validation
scheme. The best respective approach reached a median accuracy of 79.6% on the
rather homogeneous VF dataset, but only of 61.6% for the highly diverse SNT
dataset. Our results indicate that FSL on CLE images is viable, but strongly
affected by the number of patients, as well as the diversity of anatomical
patterns.
</p>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07217" title="Abstract">arXiv:2311.07217</a> [<a href="/pdf/2311.07217" title="Download PDF">pdf</a>, <a href="/format/2311.07217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Troubles and Failures in Interactional Language. Towards a  Linguistically Informed Taxonomy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wiltschko%2C+M">Martina Wiltschko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages, 3 figures, Part of WTF 23 workshop proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The goal of this talk is to introduce a systematic research agenda which aims
to understand the nature of interaction between humans and artificial
conversational agents (CA) (henceforth humanmachine interaction, HMI).
Specifically, we shall take an explicit linguistic perspective focusing on
linguistically defined variables that are known to influence the flow of
conversations among humans (henceforth human-human interaction, HHI).
</p>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07223" title="Abstract">arXiv:2311.07223</a> [<a href="/pdf/2311.07223" title="Download PDF">pdf</a>, <a href="/format/2311.07223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wasm SpecTec: Engineering a Formal Language Standard
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Breitner%2C+J">Joachim Breitner</a>, 
<a href="/search/cs?searchtype=author&query=Gardner%2C+P">Philippa Gardner</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaehyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lindley%2C+S">Sam Lindley</a>, 
<a href="/search/cs?searchtype=author&query=Pretnar%2C+M">Matija Pretnar</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+X">Xiaojia Rao</a>, 
<a href="/search/cs?searchtype=author&query=Rossberg%2C+A">Andreas Rossberg</a>, 
<a href="/search/cs?searchtype=author&query=Ryu%2C+S">Sukyoung Ryu</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+W">Wonho Shin</a>, 
<a href="/search/cs?searchtype=author&query=Watt%2C+C">Conrad Watt</a>, 
<a href="/search/cs?searchtype=author&query=Youn%2C+D">Dongjun Youn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">WebAssembly (Wasm) is a low-level bytecode language and virtual machine,
intended as a compilation target for a wide range of programming languages,
which is seeing increasing adoption across diverse ecosystems. As a young
technology, Wasm continues to evolve -- it reached version 2.0 last year and
another major update is expected soon.
<br />For a new feature to be standardised in Wasm, four key artefacts must be
presented: a formal (mathematical) specification of the feature, an
accompanying prose pseudocode description, an implementation in the official
reference interpreter, and a suite of unit tests. This rigorous process helps
to avoid errors in the design and implementation of new Wasm features, and
Wasm's distinctive formal specification in particular has facilitated
machine-checked proofs of various correctness properties for the language.
However, manually crafting all of these artefacts requires expert knowledge
combined with repetitive and tedious labor, which is a burden on the language's
standardization process and authoring of the specification.
<br />This paper presents Wasm SpecTec, a technology to express the formal
specification of Wasm through a domain-specific language. This DSL allows all
of Wasm's currently handwritten specification artefacts to be error-checked and
generated automatically from a single source of truth, and is designed to be
easy to write, read, compare, and review. We believe that Wasm SpecTec's
automation and meta-level error checking will significantly ease the current
burden of the language's specification authors. We demonstrate the current
capabilities of Wasm SpecTec by showcasing its proficiency in generating
various artefacts, and describe our work towards replacing the manually written
official Wasm specification document with specifications generated by Wasm
SpecTec.
</p>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07226" title="Abstract">arXiv:2311.07226</a> [<a href="/pdf/2311.07226" title="Download PDF">pdf</a>, <a href="/format/2311.07226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models for Robotics: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+F">Fanlong Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+W">Wensheng Gan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yongheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Ning Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S. Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. 4 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The human ability to learn, generalize, and control complex manipulation
tasks through multi-modality feedback suggests a unique capability, which we
refer to as dexterity intelligence. Understanding and assessing this
intelligence is a complex task. Amidst the swift progress and extensive
proliferation of large language models (LLMs), their applications in the field
of robotics have garnered increasing attention. LLMs possess the ability to
process and generate natural language, facilitating efficient interaction and
collaboration with robots. Researchers and engineers in the field of robotics
have recognized the immense potential of LLMs in enhancing robot intelligence,
human-robot interaction, and autonomy. Therefore, this comprehensive review
aims to summarize the applications of LLMs in robotics, delving into their
impact and contributions to key areas such as robot control, perception,
decision-making, and path planning. We first provide an overview of the
background and development of LLMs for robotics, followed by a description of
the benefits of LLMs for robotics and recent advancements in robotics models
based on LLMs. We then delve into the various techniques used in the model,
including those employed in perception, decision-making, control, and
interaction. Finally, we explore the applications of LLMs in robotics and some
potential challenges they may face in the near future. Embodied intelligence is
the future of intelligent science, and LLMs-based robotics is one of the
promising but challenging paths to achieve this.
</p>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07227" title="Abstract">arXiv:2311.07227</a> [<a href="/pdf/2311.07227" title="Download PDF">pdf</a>, <a href="/format/2311.07227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CARTOS: A Charging-Aware Real-Time Operating System for Intermittent  Batteryless Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karimi%2C+M">Mohsen Karimi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yidi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Youngbin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+Y">Yoojin Lim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyoseung Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Operating Systems (cs.OS)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper presents CARTOS, a charging-aware real-time operating system
designed to enhance the functionality of intermittently-powered batteryless
devices (IPDs) for various Internet of Things (IoT) applications. While IPDs
offer significant advantages such as extended lifespan and operability in
extreme environments, they pose unique challenges, including the need to ensure
forward progress of program execution amidst variable energy availability and
maintaining reliable real-time time behavior during power disruptions. To
address these challenges, CARTOS introduces a mixed-preemption scheduling model
that classifies tasks into computational and peripheral tasks, and ensures
their efficient and timely execution by adopting just-in-time checkpointing for
divisible computation tasks and uninterrupted execution for indivisible
peripheral tasks. CARTOS also supports processing chains of tasks with
precedence constraints and adapts its scheduling in response to environmental
changes to offer continuous execution under diverse conditions. CARTOS is
implemented with new APIs and components added to FreeRTOS but is designed for
portability to other embedded RTOSs. Through real hardware experiments and
simulations, CARTOS exhibits superior performance over state-of-the-art
methods, demonstrating that it can serve as a practical platform for developing
resilient, real-time sensing applications on IPDs.
</p>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07229" title="Abstract">arXiv:2311.07229</a> [<a href="/pdf/2311.07229" title="Download PDF">pdf</a>, <a href="/format/2311.07229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Influence of Data Characteristics on the Performance  of Point-of-Interest Recommendation Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dietz%2C+L+W">Linus W. Dietz</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez%2C+P">Pablo S&#xe1;nchez</a>, 
<a href="/search/cs?searchtype=author&query=Bellog%C3%ADn%2C+A">Alejandro Bellog&#xed;n</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">The performance of recommendation algorithms is closely tied to key
characteristics of the data sets they use, such as sparsity, popularity bias,
and preference distributions. In this paper, we conduct a comprehensive
explanatory analysis to shed light on the impact of a broad range of data
characteristics within the point-of-interest (POI) recommendation domain. To
accomplish this, we extend prior methodologies used to characterize traditional
recommendation problems by introducing new explanatory variables specifically
relevant to POI recommendation. We subdivide a POI recommendation data set on
New York City into domain-driven subsamples to measure the effect of varying
these characteristics on different state-of-the-art POI recommendation
algorithms in terms of accuracy, novelty, and item exposure. Our findings,
obtained through the application of an explanatory framework employing
multiple-regression models, reveal that the relevant independent variables
encompass all categories of data characteristics and account for as much as
$R^2 = $ 85-90\% of the accuracy and item exposure achieved by the algorithms.
Our study reaffirms the pivotal role of prominent data characteristics, such as
density, popularity bias, and the distribution of check-ins in POI
recommendation. Additionally, we unveil novel factors, such as the proximity of
user activity to the city center and the duration of user activity. In summary,
our work reveals why certain POI recommendation algorithms excel in specific
recommendation problems and, conversely, offers practical insights into which
data characteristics should be modified (or explicitly recognized) to achieve
better performance.
</p>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07230" title="Abstract">arXiv:2311.07230</a> [<a href="/pdf/2311.07230" title="Download PDF">pdf</a>, <a href="/format/2311.07230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How are Prompts Different in Terms of Sensitivity?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Sheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Schuff%2C+H">Hendrik Schuff</a>, 
<a href="/search/cs?searchtype=author&query=Gurevych%2C+I">Iryna Gurevych</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In-context learning (ICL) has become one of the most popular learning
paradigms. While there is a growing body of literature focusing on prompt
engineering, there is a lack of systematic analysis comparing the effects of
prompts across different models and tasks. To address this gap, we present a
comprehensive prompt analysis based on the sensitivity of a function. Our
analysis reveals that sensitivity is an unsupervised proxy for model
performance, as it exhibits a strong negative correlation with accuracy. We use
gradient-based saliency scores to empirically demonstrate how different prompts
affect the relevance of input tokens to the output, resulting in different
levels of sensitivity. Furthermore, we introduce sensitivity-aware decoding
which incorporates sensitivity estimation as a penalty term in the standard
greedy decoding. We show that this approach is particularly helpful when
information in the input is scarce. Our work provides a fresh perspective on
the analysis of prompts, and contributes to a better understanding of the
mechanism of ICL.
</p>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07233" title="Abstract">arXiv:2311.07233</a> [<a href="/pdf/2311.07233" title="Download PDF">pdf</a>, <a href="/ps/2311.07233" title="Download PostScript">ps</a>, <a href="/format/2311.07233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IASCAR: Incremental Answer Set Counting by Anytime Refinement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fichte%2C+J+K">Johannes K. Fichte</a>, 
<a href="/search/cs?searchtype=author&query=Gaggl%2C+S+A">Sarah Alice Gaggl</a>, 
<a href="/search/cs?searchtype=author&query=Hecher%2C+M">Markus Hecher</a>, 
<a href="/search/cs?searchtype=author&query=Rusovac%2C+D">Dominik Rusovac</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under consideration in Theory and Practice of Logic Programming (TPLP)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Answer set programming (ASP) is a popular declarative programming paradigm
with various applications. Programs can easily have many answer sets that
cannot be enumerated in practice, but counting still allows quantifying
solution spaces. If one counts under assumptions on literals, one obtains a
tool to comprehend parts of the solution space, so-called answer set
navigation. However, navigating through parts of the solution space requires
counting many times, which is expensive in theory. Knowledge compilation
compiles instances into representations on which counting works in polynomial
time. However, these techniques exist only for CNF formulas, and compiling ASP
programs into CNF formulas can introduce an exponential overhead. This paper
introduces a technique to iteratively count answer sets under assumptions on
knowledge compilations of CNFs that encode supported models. Our anytime
technique uses the inclusion-exclusion principle to improve bounds by over- and
undercounting systematically. In a preliminary empirical analysis, we
demonstrate promising results. After compiling the input (offline phase), our
approach quickly (re)counts.
</p>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07237" title="Abstract">arXiv:2311.07237</a> [<a href="/pdf/2311.07237" title="Download PDF">pdf</a>, <a href="/format/2311.07237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In Search of the Long-Tail: Systematic Generation of Long-Tail Knowledge  via Logical Rule Guided Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huihan Li</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+Y">Yuting Ning</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Z">Zeyi Liao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Siyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X+L">Xiang Lorraine Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Ximing Lu</a>, 
<a href="/search/cs?searchtype=author&query=Brahman%2C+F">Faeze Brahman</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wenting Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yejin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiang Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Since large language models have approached human-level performance on many
tasks, it has become increasingly harder for researchers to find tasks that are
still challenging to the models. Failure cases usually come from the long-tail
distribution - data that an oracle language model could assign a probability on
the lower end of its distribution. Current methodology such as prompt
engineering or crowdsourcing are insufficient for creating long-tail examples
because humans are constrained by cognitive bias. We propose a
Logic-Induced-Knowledge-Search (LINK) framework for systematically generating
long-tail knowledge statements. Grounded by a symbolic rule, we search for
long-tail values for each variable of the rule by first prompting a LLM, then
verifying the correctness of the values with a critic, and lastly pushing for
the long-tail distribution with a reranker. With this framework we construct a
dataset, Logic-Induced-Long-Tail (LINT), consisting of 200 symbolic rules and
50K knowledge statements spanning across four domains. Human annotations find
that 84% of the statements in LINT are factually correct. In contrast, ChatGPT
and GPT4 struggle with directly generating long-tail statements under the
guidance of logic rules, each only getting 56% and 78% of their statements
correct. Moreover, their "long-tail" generations in fact fall into the higher
likelihood range, and thus are not really long-tail. Our findings suggest that
LINK is effective for generating data in the long-tail distribution while
enforcing quality. LINT can be useful for systematically evaluating LLMs'
capabilities in the long-tail distribution. We challenge the models with a
simple entailment classification task using samples from LINT. We find that
ChatGPT and GPT4's capability in identifying incorrect knowledge drop by ~3% in
the long-tail distribution compared to head distribution.
</p>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07239" title="Abstract">arXiv:2311.07239</a> [<a href="/pdf/2311.07239" title="Download PDF">pdf</a>, <a href="/format/2311.07239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RESenv: A Realistic Earthquake Simulation Environment based on Unreal  Engine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yitong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hanchun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhejun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Diels%2C+C">Cyriel Diels</a>, 
<a href="/search/cs?searchtype=author&query=Asadipour%2C+A">Ali Asadipour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Earthquakes have a significant impact on societies and economies, driving the
need for effective search and rescue strategies. With the growing role of AI
and robotics in these operations, high-quality synthetic visual data becomes
crucial. Current simulation methods, mostly focusing on single building
damages, often fail to provide realistic visuals for complex urban settings. To
bridge this gap, we introduce an innovative earthquake simulation system using
the Chaos Physics System in Unreal Engine. Our approach aims to offer detailed
and realistic visual simulations essential for AI and robotic training in
rescue missions. By integrating real seismic waveform data, we enhance the
authenticity and relevance of our simulations, ensuring they closely mirror
real-world earthquake scenarios. Leveraging the advanced capabilities of Unreal
Engine, our system delivers not only high-quality visualisations but also
real-time dynamic interactions, making the simulated environments more
immersive and responsive. By providing advanced renderings, accurate physical
interactions, and comprehensive geological movements, our solution outperforms
traditional methods in efficiency and user experience. Our simulation
environment stands out in its detail and realism, making it a valuable tool for
AI tasks such as path planning and image recognition related to earthquake
responses. We validate our approach through three AI-based tasks: similarity
detection, path planning, and image segmentation.
</p>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07241" title="Abstract">arXiv:2311.07241</a> [<a href="/pdf/2311.07241" title="Download PDF">pdf</a>, <a href="/format/2311.07241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IndexMAC: A Custom RISC-V Vector Instruction to Accelerate  Structured-Sparse Matrix Multiplications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Titopoulos%2C+V">V. Titopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Alexandridis%2C+K">K. Alexandridis</a>, 
<a href="/search/cs?searchtype=author&query=Peltekis%2C+C">C. Peltekis</a>, 
<a href="/search/cs?searchtype=author&query=Nicopoulos%2C+C">C. Nicopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Dimitrakopoulos%2C+G">G. Dimitrakopoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> DATE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Structured sparsity has been proposed as an efficient way to prune the
complexity of modern Machine Learning (ML) applications and to simplify the
handling of sparse data in hardware. The acceleration of ML models - for both
training and inference - relies primarily on equivalent matrix multiplications
that can be executed efficiently on vector processors or custom matrix engines.
The goal of this work is to incorporate the simplicity of structured sparsity
into vector execution, thereby accelerating the corresponding matrix
multiplications. Toward this objective, a new vector index-multiply-accumulate
instruction is proposed, which enables the implementation of lowcost indirect
reads from the vector register file. This reduces unnecessary memory traffic
and increases data locality. The proposed new instruction was integrated in a
decoupled RISCV vector processor with negligible hardware cost. Extensive
evaluation demonstrates significant speedups of 1.80x-2.14x, as compared to
state-of-the-art vectorized kernels, when executing layers of varying sparsity
from state-of-the-art Convolutional Neural Networks (CNNs).
</p>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07242" title="Abstract">arXiv:2311.07242</a> [<a href="/pdf/2311.07242" title="Download PDF">pdf</a>, <a href="/ps/2311.07242" title="Download PostScript">ps</a>, <a href="/format/2311.07242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Slow Passage through a Saddle-Node Bifurcation in Discrete Dynamical  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chu%2C+J">Jay Chu</a>, 
<a href="/search/math?searchtype=author&query=Lin%2C+J">Jun-Jie Lin</a>, 
<a href="/search/math?searchtype=author&query=Tsai%2C+J">Je-Chiang Tsai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Chaotic Dynamics (nlin.CD)

</div>
<p class="mathjax">We study a discrete non-autonomous system whose autonomous counterpart (with
the frozen bifurcation parameter) admits a saddle-node bifurcation, and in
which the bifurcation parameter slowly changes in time and is characterized by
a sweep rate constant $\epsilon$. The discrete system is more appropriate for
modeling realistic systems since only time series data is available. We show
that in contrast to its autonomous counterpart, when the time mesh size $\Delta
t$ is less than the order $O(\epsilon)$, there is a bifurcation delay as the
bifurcation time-varying parameter is varied through the bifurcation point, and
the delay is proportional to the two-thirds power of the sweep rate constant
$\epsilon$. This bifurcation delay is significant in various realistic systems
since it allows one to take necessary action promptly before a sudden collapse
or shift to different states. On the other hand, when the time mesh size
$\Delta t$ is larger than the order $o(\epsilon)$, the dynamical behavior of
the solution is dramatically changed before the bifurcation point. This
behavior is not observed in the autonomous counterpart. Therefore, the
dynamical behavior of the system strongly depends on the time mesh size.
Finally. due to the very discrete feature of the system, there are no efficient
tools for the analytical study of the system. Our approach is elementary and
analytical.
</p>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07245" title="Abstract">arXiv:2311.07245</a> [<a href="/pdf/2311.07245" title="Download PDF">pdf</a>, <a href="/format/2311.07245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Transferring Tactile-based Continuous Force Control Policies  from Simulation to Robot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lach%2C+L">Luca Lach</a>, 
<a href="/search/cs?searchtype=author&query=Haschke%2C+R">Robert Haschke</a>, 
<a href="/search/cs?searchtype=author&query=Tateo%2C+D">Davide Tateo</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+J">Jan Peters</a>, 
<a href="/search/cs?searchtype=author&query=Ritter%2C+H">Helge Ritter</a>, 
<a href="/search/cs?searchtype=author&query=Borr%C3%A0s%2C+J">J&#xfa;lia Borr&#xe0;s</a>, 
<a href="/search/cs?searchtype=author&query=Torras%2C+C">Carme Torras</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The advent of tactile sensors in robotics has sparked many ideas on how
robots can leverage direct contact measurements of their environment
interactions to improve manipulation tasks. An important line of research in
this regard is that of grasp force control, which aims to manipulate objects
safely by limiting the amount of force exerted on the object. While prior works
have either hand-modeled their force controllers, employed model-based
approaches, or have not shown sim-to-real transfer, we propose a model-free
deep reinforcement learning approach trained in simulation and then transferred
to the robot without further fine-tuning. We therefore present a simulation
environment that produces realistic normal forces, which we use to train
continuous force control policies. An evaluation in which we compare against a
baseline and perform an ablation study shows that our approach outperforms the
hand-modeled baseline and that our proposed inductive bias and domain
randomization facilitate sim-to-real transfer. Code, models, and supplementary
videos are available on https://sites.google.com/view/rl-force-ctrl
</p>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07247" title="Abstract">arXiv:2311.07247</a> [<a href="/pdf/2311.07247" title="Download PDF">pdf</a>, <a href="/format/2311.07247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simultaneous Clutter Detection and Semantic Segmentation of Moving  Objects for Automotive Radar Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kopp%2C+J">Johannes Kopp</a>, 
<a href="/search/cs?searchtype=author&query=Kellner%2C+D">Dominik Kellner</a>, 
<a href="/search/cs?searchtype=author&query=Piroli%2C+A">Aldi Piroli</a>, 
<a href="/search/cs?searchtype=author&query=Dallabetta%2C+V">Vinzenz Dallabetta</a>, 
<a href="/search/cs?searchtype=author&query=Dietmayer%2C+K">Klaus Dietmayer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at IEEE International Conference of Intelligent Transportation Systems (ITSC), Bilbao, ESP, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">The unique properties of radar sensors, such as their robustness to adverse
weather conditions, make them an important part of the environment perception
system of autonomous vehicles. One of the first steps during the processing of
radar point clouds is often the detection of clutter, i.e. erroneous points
that do not correspond to real objects. Another common objective is the
semantic segmentation of moving road users. These two problems are handled
strictly separate from each other in literature. The employed neural networks
are always focused entirely on only one of the tasks. In contrast to this, we
examine ways to solve both tasks at the same time with a single jointly used
model. In addition to a new augmented multi-head architecture, we also devise a
method to represent a network's predictions for the two tasks with only one
output value. This novel approach allows us to solve the tasks simultaneously
with the same inference time as a conventional task-specific model. In an
extensive evaluation, we show that our setup is highly effective and
outperforms every existing network for semantic segmentation on the RadarScenes
dataset.
</p>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07251" title="Abstract">arXiv:2311.07251</a> [<a href="/pdf/2311.07251" title="Download PDF">pdf</a>, <a href="/format/2311.07251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Dynamics of a Bicycle on a Pump Track -- First Results on Modeling  and Optimal Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Golembiewski%2C+J">Julian Golembiewski</a>, 
<a href="/search/eess?searchtype=author&query=Schmidt%2C+M">Marcus Schmidt</a>, 
<a href="/search/eess?searchtype=author&query=Terschluse%2C+B">Benedikt Terschluse</a>, 
<a href="/search/eess?searchtype=author&query=Jaitner%2C+T">Thomas Jaitner</a>, 
<a href="/search/eess?searchtype=author&query=Liebig%2C+T">Thomas Liebig</a>, 
<a href="/search/eess?searchtype=author&query=Faulwasser%2C+T">Timm Faulwasser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We investigate the dynamics of a bicycle on an uneven mountain bike track
split into straight sections with small jumps (kickers) and banked corners. A
basic bike-rider model is proposed and used to derive equations of motion,
which capture the possibilities to accelerate the bicycle without pedaling.
Since this is a first approach to the problem, only corners connected by
straight lines are considered to compute optimal riding strategies. The
simulation is validated with experimental data obtained on a real pump track.
It is demonstrated that the model effectively captures the longitudinal bike
acceleration resulting from the relative vertical motion between the rider's
upper body and the bicycle. Our numerical results are in good analogy with real
rider's actions on similar tracks.
</p>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07257" title="Abstract">arXiv:2311.07257</a> [<a href="/pdf/2311.07257" title="Download PDF">pdf</a>, <a href="/format/2311.07257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bio-Inspired Grasping Controller for Sensorized 2-DoF Grippers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lach%2C+L">Luca Lach</a>, 
<a href="/search/cs?searchtype=author&query=Lemaignan%2C+S">S&#xe9;verin Lemaignan</a>, 
<a href="/search/cs?searchtype=author&query=Ferro%2C+F">Francesco Ferro</a>, 
<a href="/search/cs?searchtype=author&query=Ritter%2C+H">Helge Ritter</a>, 
<a href="/search/cs?searchtype=author&query=Haschke%2C+R">Robert Haschke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We present a holistic grasping controller, combining free-space position
control and in-contact force-control for reliable grasping given uncertain
object pose estimates. Employing tactile fingertip sensors, undesired object
displacement during grasping is minimized by pausing the finger closing motion
for individual joints on first contact until force-closure is established.
While holding an object, the controller is compliant with external forces to
avoid high internal object forces and prevent object damage. Gravity as an
external force is explicitly considered and compensated for, thus preventing
gravity-induced object drift. We evaluate the controller in two experiments on
the TIAGo robot and its parallel-jaw gripper proving the effectiveness of the
approach for robust grasping and minimizing object displacement. In a series of
ablation studies, we demonstrate the utility of the individual controller
components.
</p>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07260" title="Abstract">arXiv:2311.07260</a> [<a href="/pdf/2311.07260" title="Download PDF">pdf</a>, <a href="/format/2311.07260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TIAGo RL: Simulated Reinforcement Learning Environments with Tactile  Data for Mobile Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lach%2C+L">Luca Lach</a>, 
<a href="/search/cs?searchtype=author&query=Ferro%2C+F">Francesco Ferro</a>, 
<a href="/search/cs?searchtype=author&query=Haschke%2C+R">Robert Haschke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Tactile information is important for robust performance in robotic tasks that
involve physical interaction, such as object manipulation. However, with more
data included in the reasoning and control process, modeling behavior becomes
increasingly difficult. Deep Reinforcement Learning (DRL) produced promising
results for learning complex behavior in various domains, including
tactile-based manipulation in robotics. In this work, we present our
open-source reinforcement learning environments for the TIAGo service robot.
They produce tactile sensor measurements that resemble those of a real
sensorised gripper for TIAGo, encouraging research in transfer learning of DRL
policies. Lastly, we show preliminary training results of a learned force
control policy and compare it to a classical PI controller.
</p>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07261" title="Abstract">arXiv:2311.07261</a> [<a href="/pdf/2311.07261" title="Download PDF">pdf</a>, <a href="/format/2311.07261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sketch-based Video Object Segmentation: Benchmark and Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Ruolin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Da Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Conghui Hu</a>, 
<a href="/search/cs?searchtype=author&query=Hospedales%2C+T">Timothy Hospedales</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Honggang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yi-Zhe Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> BMVC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Reference-based video object segmentation is an emerging topic which aims to
segment the corresponding target object in each video frame referred by a given
reference, such as a language expression or a photo mask. However, language
expressions can sometimes be vague in conveying an intended concept and
ambiguous when similar objects in one frame are hard to distinguish by
language. Meanwhile, photo masks are costly to annotate and less practical to
provide in a real application. This paper introduces a new task of sketch-based
video object segmentation, an associated benchmark, and a strong baseline. Our
benchmark includes three datasets, Sketch-DAVIS16, Sketch-DAVIS17 and
Sketch-YouTube-VOS, which exploit human-drawn sketches as an informative yet
low-cost reference for video object segmentation. We take advantage of STCN, a
popular baseline of semi-supervised VOS task, and evaluate what the most
effective design for incorporating a sketch reference is. Experimental results
show sketch is more effective yet annotation-efficient than other references,
such as photo masks, language and scribble.
</p>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07263" title="Abstract">arXiv:2311.07263</a> [<a href="/pdf/2311.07263" title="Download PDF">pdf</a>, <a href="/format/2311.07263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LT-ViT: A Vision Transformer for multi-label Chest X-ray classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marikkar%2C+U">Umar Marikkar</a>, 
<a href="/search/cs?searchtype=author&query=Atito%2C+S">Sara Atito</a>, 
<a href="/search/cs?searchtype=author&query=Awais%2C+M">Muhammad Awais</a>, 
<a href="/search/cs?searchtype=author&query=Mahdi%2C+A">Adam Mahdi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Vision Transformers (ViTs) are widely adopted in medical imaging tasks, and
some existing efforts have been directed towards vision-language training for
Chest X-rays (CXRs). However, we envision that there still exists a potential
for improvement in vision-only training for CXRs using ViTs, by aggregating
information from multiple scales, which has been proven beneficial for
non-transformer networks. Hence, we have developed LT-ViT, a transformer that
utilizes combined attention between image tokens and randomly initialized
auxiliary tokens that represent labels. Our experiments demonstrate that LT-ViT
(1) surpasses the state-of-the-art performance using pure ViTs on two publicly
available CXR datasets, (2) is generalizable to other pre-training methods and
therefore is agnostic to model initialization, and (3) enables model
interpretability without grad-cam and its variants.
</p>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07264" title="Abstract">arXiv:2311.07264</a> [<a href="/pdf/2311.07264" title="Download PDF">pdf</a>, <a href="/format/2311.07264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Danish Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Enevoldsen%2C+K">Kenneth Enevoldsen</a>, 
<a href="/search/cs?searchtype=author&query=Hansen%2C+L">Lasse Hansen</a>, 
<a href="/search/cs?searchtype=author&query=Nielsen%2C+D+S">Dan S. Nielsen</a>, 
<a href="/search/cs?searchtype=author&query=Egeb%C3%A6k%2C+R+A+F">Rasmus A. F. Egeb&#xe6;k</a>, 
<a href="/search/cs?searchtype=author&query=Holm%2C+S+V">S&#xf8;ren V. Holm</a>, 
<a href="/search/cs?searchtype=author&query=Nielsen%2C+M+C">Martin C. Nielsen</a>, 
<a href="/search/cs?searchtype=author&query=Bernstorff%2C+M">Martin Bernstorff</a>, 
<a href="/search/cs?searchtype=author&query=Larsen%2C+R">Rasmus Larsen</a>, 
<a href="/search/cs?searchtype=author&query=J%C3%B8rgensen%2C+P+B">Peter B. J&#xf8;rgensen</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%B8jmark-Bertelsen%2C+M">Malte H&#xf8;jmark-Bertelsen</a>, 
<a href="/search/cs?searchtype=author&query=Vahlstrup%2C+P+B">Peter B. Vahlstrup</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%B8ldrup-Dalum%2C+P">Per M&#xf8;ldrup-Dalum</a>, 
<a href="/search/cs?searchtype=author&query=Nielbo%2C+K">Kristoffer Nielbo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models, sometimes referred to as foundation models, have
transformed multiple fields of research. However, smaller languages risk
falling behind due to high training costs and small incentives for large
companies to train these models. To combat this, the Danish Foundation Models
project seeks to provide and maintain open, well-documented, and high-quality
foundation models for the Danish language. This is achieved through broad
cooperation with public and private institutions, to ensure high data quality
and applicability of the trained models. We present the motivation of the
project, the current status, and future perspectives.
</p>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07268" title="Abstract">arXiv:2311.07268</a> [<a href="/pdf/2311.07268" title="Download PDF">pdf</a>, <a href="/format/2311.07268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ViKi-HyCo: A Hybrid-Control approach for complex car-like maneuvers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Velasco-S%C3%A1nchez%2C+E+P">Edison P. Velasco-S&#xe1;nchez</a>, 
<a href="/search/cs?searchtype=author&query=Mu%C3%B1oz-Ba%C3%B1%C3%B3n%2C+M+%C3%81">Miguel &#xc1;ngel Mu&#xf1;oz-Ba&#xf1;&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Candelas%2C+F+A">Francisco A. Candelas</a>, 
<a href="/search/cs?searchtype=author&query=Puente%2C+S+T">Santiago T. Puente</a>, 
<a href="/search/cs?searchtype=author&query=Torres%2C+F">Fernando Torres</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is under review at the journal "Applied Intelligence" (Springer)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper presents ViKi-HyCo (Visual servoing and Kinematic
Hybrid-Controller), an approach that generates the necessary maneuvers for the
complex positioning of a non-holonomic mobile robot in outdoor environments,
towards a target point based on the object detection, by combining an image
based visual servoing (IBVS) and a kinematic controller. The method avoids the
problems of the visual servoing controller when it loses the visual object
detection features by switching to a kinematic controller. We also present
object localization for outdoor environments employing the fusion of LiDAR and
RGB-D cameras that estimates the spatial location of a target point for the
kinematic controller, and also allows the dynamic calculation of a desired
bounding box of the detected object for the calculation of velocities in the
visual servoing controller. The presented approach does not require an object
tracking algorithm and is applicable to any visually tracking robotic task
where its kinematic model is known. The Hybrid-Control presents an error of
0.0428 \pm 0.0467 m in the X-axis and 0.0515 \pm 0.0323 m in the Y-axis at the
end of a complete positioning task.
</p>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07277" title="Abstract">arXiv:2311.07277</a> [<a href="/pdf/2311.07277" title="Download PDF">pdf</a>, <a href="/format/2311.07277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdaCCD: Adaptive Semantic Contrasts Discovery based Cross Lingual  Adaptation for Code Clone Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yangkai Du</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+T">Tengfei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lingfei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shouling Ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Code Clone Detection, which aims to retrieve functionally similar programs
from large code bases, has been attracting increasing attention. Modern
software often involves a diverse range of programming languages. However,
current code clone detection methods are generally limited to only a few
popular programming languages due to insufficient annotated data as well as
their own model design constraints. To address these issues, we present AdaCCD,
a novel cross-lingual adaptation method that can detect cloned codes in a new
language without any annotations in that language. AdaCCD leverages
language-agnostic code representations from pre-trained programming language
models and propose an Adaptively Refined Contrastive Learning framework to
transfer knowledge from resource-rich languages to resource-poor languages. We
evaluate the cross-lingual adaptation results of AdaCCD by constructing a
multilingual code clone detection benchmark consisting of 5 programming
languages. AdaCCD achieves significant improvements over other baselines, and
it is even comparable to supervised fine-tuning.
</p>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07283" title="Abstract">arXiv:2311.07283</a> [<a href="/pdf/2311.07283" title="Download PDF">pdf</a>, <a href="/format/2311.07283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predictive and Prescriptive Analytics for Multi-Site Modeling of Frail  and Elderly Patient Services
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Williams%2C+E">Elizabeth Williams</a>, 
<a href="/search/cs?searchtype=author&query=Gartner%2C+D">Daniel Gartner</a>, 
<a href="/search/cs?searchtype=author&query=Harper%2C+P">Paul Harper</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Recent research has highlighted the potential of linking predictive and
prescriptive analytics. However, it remains widely unexplored how both
paradigms could benefit from one another to address today's major challenges in
healthcare. One of these is smarter planning of resource capacities for frail
and elderly inpatient wards, addressing the societal challenge of an aging
population. Frail and elderly patients typically suffer from multimorbidity and
require more care while receiving medical treatment. The aim of this research
is to assess how various predictive and prescriptive analytical methods, both
individually and in tandem, contribute to addressing the operational challenges
within an area of healthcare that is growing in demand. Clinical and
demographic patient attributes are gathered from more than 165,000 patient
records and used to explain and predict length of stay. To that extent, we
employ Classification and Regression Trees (CART) analysis to establish this
relationship. On the prescriptive side, deterministic and two-stage stochastic
programs are developed to determine how to optimally plan for beds and ward
staff with the objective to minimize cost. Furthermore, the two analytical
methodologies are linked by generating demand for the prescriptive models using
the CART groupings. The results show the linked methodologies provided
different but similar results compared to using averages and in doing so,
captured a more realistic real-world variation in the patient length of stay.
Our research reveals that healthcare managers should consider using predictive
and prescriptive models to make more informed decisions. By combining
predictive and prescriptive analytics, healthcare managers can move away from
relying on averages and incorporate the unique characteristics of their
patients to create more robust planning decisions, mitigating risks caused by
variations in demand.
</p>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07284" title="Abstract">arXiv:2311.07284</a> [<a href="/pdf/2311.07284" title="Download PDF">pdf</a>, <a href="/ps/2311.07284" title="Download PostScript">ps</a>, <a href="/format/2311.07284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Arithmetic Formulas in the Presence of Noise: A General  Framework and Applications to Unsupervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chandra%2C+P">Pritam Chandra</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+A">Ankit Garg</a>, 
<a href="/search/cs?searchtype=author&query=Kayal%2C+N">Neeraj Kayal</a>, 
<a href="/search/cs?searchtype=author&query=Mittal%2C+K">Kunal Mittal</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+T">Tanmay Sinha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 85 pages, comments welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC); Machine Learning (cs.LG)

</div>
<p class="mathjax">We present a general framework for designing efficient algorithms for
unsupervised learning problems, such as mixtures of Gaussians and subspace
clustering. Our framework is based on a meta algorithm that learns arithmetic
circuits in the presence of noise, using lower bounds. This builds upon the
recent work of Garg, Kayal and Saha (FOCS 20), who designed such a framework
for learning arithmetic circuits without any noise. A key ingredient of our
meta algorithm is an efficient algorithm for a novel problem called Robust
Vector Space Decomposition. We show that our meta algorithm works well when
certain matrices have sufficiently large smallest non-zero singular values. We
conjecture that this condition holds for smoothed instances of our problems,
and thus our framework would yield efficient algorithms for these problems in
the smoothed setting.
</p>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07285" title="Abstract">arXiv:2311.07285</a> [<a href="/pdf/2311.07285" title="Download PDF">pdf</a>, <a href="/format/2311.07285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi Sentence Description of Complex Manipulation Action Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ziaeetabar%2C+F">Fatemeh Ziaeetabar</a>, 
<a href="/search/cs?searchtype=author&query=Safabakhsh%2C+R">Reza Safabakhsh</a>, 
<a href="/search/cs?searchtype=author&query=Momtazi%2C+S">Saeedeh Momtazi</a>, 
<a href="/search/cs?searchtype=author&query=Tamosiunaite%2C+M">Minija Tamosiunaite</a>, 
<a href="/search/cs?searchtype=author&query=W%C3%B6rg%C3%B6tter%2C+F">Florentin W&#xf6;rg&#xf6;tter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Automatic video description requires the generation of natural language
statements about the actions, events, and objects in the video. An important
human trait, when we describe a video, is that we are able to do this with
variable levels of detail. Different from this, existing approaches for
automatic video descriptions are mostly focused on single sentence generation
at a fixed level of detail. Instead, here we address video description of
manipulation actions where different levels of detail are required for being
able to convey information about the hierarchical structure of these actions
relevant also for modern approaches of robot learning. We propose one hybrid
statistical and one end-to-end framework to address this problem. The hybrid
method needs much less data for training, because it models statistically
uncertainties within the video clips, while in the end-to-end method, which is
more data-heavy, we are directly connecting the visual encoder to the language
decoder without any intermediate (statistical) processing step. Both frameworks
use LSTM stacks to allow for different levels of description granularity and
videos can be described by simple single-sentences or complex multiple-sentence
descriptions. In addition, quantitative results demonstrate that these methods
produce more realistic descriptions than other competing approaches.
</p>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07286" title="Abstract">arXiv:2311.07286</a> [<a href="/pdf/2311.07286" title="Download PDF">pdf</a>, <a href="/format/2311.07286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explaining black boxes with a SMILE: Statistical Model-agnostic  Interpretability with Local Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aslansefat%2C+K">Koorosh Aslansefat</a>, 
<a href="/search/cs?searchtype=author&query=Hashemian%2C+M">Mojgan Hashemian</a>, 
<a href="/search/cs?searchtype=author&query=Walker%2C+M">Martin Walker</a>, 
<a href="/search/cs?searchtype=author&query=Akram%2C+M+N">Mohammed Naveed Akram</a>, 
<a href="/search/cs?searchtype=author&query=Sorokos%2C+I">Ioannis Sorokos</a>, 
<a href="/search/cs?searchtype=author&query=Papadopoulos%2C+Y">Yiannis Papadopoulos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
<p class="mathjax">Machine learning is currently undergoing an explosion in capability,
popularity, and sophistication. However, one of the major barriers to
widespread acceptance of machine learning (ML) is trustworthiness: most ML
models operate as black boxes, their inner workings opaque and mysterious, and
it can be difficult to trust their conclusions without understanding how those
conclusions are reached. Explainability is therefore a key aspect of improving
trustworthiness: the ability to better understand, interpret, and anticipate
the behaviour of ML models. To this end, we propose SMILE, a new method that
builds on previous approaches by making use of statistical distance measures to
improve explainability while remaining applicable to a wide range of input data
domains.
</p>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07289" title="Abstract">arXiv:2311.07289</a> [<a href="/pdf/2311.07289" title="Download PDF">pdf</a>, <a href="/format/2311.07289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A probabilistic forecast methodology for volatile electricity prices in  the Australian National Electricity Market
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cornell%2C+C">Cameron Cornell</a>, 
<a href="/search/cs?searchtype=author&query=Dinh%2C+N+T">Nam Trong Dinh</a>, 
<a href="/search/cs?searchtype=author&query=Pourmousavi%2C+S+A">S. Ali Pourmousavi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This manuscript has been submitted to International Journal of Forecasting for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The South Australia region of the Australian National Electricity Market
(NEM) displays some of the highest levels of price volatility observed in
modern electricity markets. This paper outlines an approach to probabilistic
forecasting under these extreme conditions, including spike filtration and
several post-processing steps. We propose using quantile regression as an
ensemble tool for probabilistic forecasting, with our combined forecasts
achieving superior results compared to all constituent models. Within our
ensemble framework, we demonstrate that averaging models with varying training
length periods leads to a more adaptive model and increased prediction
accuracy. The applicability of the final model is evaluated by comparing our
median forecasts with the point forecasts available from the Australian NEM
operator, with our model outperforming these NEM forecasts by a significant
margin.
</p>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07291" title="Abstract">arXiv:2311.07291</a> [<a href="/pdf/2311.07291" title="Download PDF">pdf</a>, <a href="/format/2311.07291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LiLO: Lightweight and low-bias LiDAR Odometry method based on spherical  range image filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Velasco-S%C3%A1nchez%2C+E+P">Edison P. Velasco-S&#xe1;nchez</a>, 
<a href="/search/cs?searchtype=author&query=Mu%C3%B1oz-Ba%C3%B1%C3%B3n%2C+M+%C3%81">Miguel &#xc1;ngel Mu&#xf1;oz-Ba&#xf1;&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Candelas%2C+F+A">Francisco A. Candelas</a>, 
<a href="/search/cs?searchtype=author&query=Puente%2C+S+T">Santiago T. Puente</a>, 
<a href="/search/cs?searchtype=author&query=Torres%2C+F">Fernando Torres</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is under review at the journal "Autonomous Robots" (Springer)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In unstructured outdoor environments, robotics requires accurate and
efficient odometry with low computational time. Existing low-bias LiDAR
odometry methods are often computationally expensive. To address this problem,
we present a lightweight LiDAR odometry method that converts unorganized point
cloud data into a spherical range image (SRI) and filters out surface, edge,
and ground features in the image plane. This substantially reduces computation
time and the required features for odometry estimation in LOAM-based
algorithms. Our odometry estimation method does not rely on global maps or loop
closure algorithms, which further reduces computational costs. Experimental
results generate a translation and rotation error of 0.86\% and 0.0036{\deg}/m
on the KITTI dataset with an average runtime of 78ms. In addition, we tested
the method with our data, obtaining an average closed-loop error of 0.8m and a
runtime of 27ms over eight loops covering 3.5Km.
</p>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07296" title="Abstract">arXiv:2311.07296</a> [<a href="/pdf/2311.07296" title="Download PDF">pdf</a>, <a href="/ps/2311.07296" title="Download PostScript">ps</a>, <a href="/format/2311.07296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BIDRN: A Method of Bidirectional Recurrent Neural Network for Sentiment  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Muthusankar%2C+D+D">Dr. D Muthusankar</a>, 
<a href="/search/cs?searchtype=author&query=Kaladevi%2C+D+P">Dr. P Kaladevi</a>, 
<a href="/search/cs?searchtype=author&query=Sadasivam%2C+D+V+R">Dr. V R Sadasivam</a>, 
<a href="/search/cs?searchtype=author&query=Praveen%2C+R">R Praveen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Text mining research has grown in importance in recent years due to the
tremendous increase in the volume of unstructured textual data. This has
resulted in immense potential as well as obstacles in the sector, which may be
efficiently addressed with adequate analytical and study methods. Deep
Bidirectional Recurrent Neural Networks are used in this study to analyze
sentiment. The method is categorized as sentiment polarity analysis because it
may generate a dataset with sentiment labels. This dataset can be used to train
and evaluate sentiment analysis models capable of extracting impartial
opinions. This paper describes the Sentiment Analysis-Deep Bidirectional
Recurrent Neural Networks (SA-BDRNN) Scheme, which seeks to overcome the
challenges and maximize the potential of text mining in the context of Big
Data. The current study proposes a SA-DBRNN Scheme that attempts to give a
systematic framework for sentiment analysis in the context of student input on
institution choice. The purpose of this study is to compare the effectiveness
of the proposed SA- DBRNN Scheme to existing frameworks to establish a robust
deep neural network that might serve as an adequate classification model in the
field of sentiment analysis.
</p>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07298" title="Abstract">arXiv:2311.07298</a> [<a href="/pdf/2311.07298" title="Download PDF">pdf</a>, <a href="/format/2311.07298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy Complexity for Sorting Algorithms in Java
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carter%2C+K">Kristina Carter</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+S+M+G">Su Mei Gwen Ho</a>, 
<a href="/search/cs?searchtype=author&query=Larsen%2C+M+M+A">Mathias Marquar Arhipenko Larsen</a>, 
<a href="/search/cs?searchtype=author&query=Sundman%2C+M">Martin Sundman</a>, 
<a href="/search/cs?searchtype=author&query=Kirkeby%2C+M+H">Maja H. Kirkeby</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">This study extends the concept of time complexity to energy, i.e., energy
complexity, by showing a strong correlation between time complexity and energy
consumption for sorting algorithms: Bubble Sort, Counting Sort, Merge Sort and
Quick Sort, written in Java and run on single kernels. We investigate the
correlation between wall time and time complexity, as well as the correlation
between energy consumption and wall time. The primary finding is that time
complexity can be used as a guideline to estimate the energy consumption of
O(n*n), O(nlog(n)) and O(n + k) sorting algorithms. The secondary finding is
that the inputs producing the theoretical worst cases for Merge Sort and Bubble
Sort did not produce the worst case wall time nor the worst case energy
consumption.
</p>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07299" title="Abstract">arXiv:2311.07299</a> [<a href="/pdf/2311.07299" title="Download PDF">pdf</a>, <a href="/format/2311.07299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing NAC-ABE to Support Access Control for mHealth Applications and  Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dulal%2C+S">Saurab Dulal</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tianyuan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Siqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Thieme%2C+A+R">Adam Robert Thieme</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lixia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Name-based access control (NAC) over NDN provides fine-grained data
confidentiality and access control by encrypting and signing data at the time
of data production. NAC utilizes specially crafted naming conventions to define
and enforce access control policies. NAC-ABE, an extension to NAC, uses an
attribute-based encryption (ABE) scheme to support access control with improved
scalability and flexibility. However, existing NAC-ABE libraries are based on
ciphertext-policy ABE (CP-ABE), which requires knowledge of the access policy
when encrypting data packets. In some applications, including mHealth, the data
access policy is unknown at the time of data generation, while data attributes
and properties are known. In this paper, we present an extension to the
existing NDN-ABE library which can be used by mHealth and other applications to
enforce fine-granularity access control in data sharing. We also discuss the
challenges we encountered during the application deployment, and remaining open
issues together with potential solution directions.
</p>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07301" title="Abstract">arXiv:2311.07301</a> [<a href="/pdf/2311.07301" title="Download PDF">pdf</a>, <a href="/format/2311.07301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamically Weighted Factor-Graph for Feature-based Geo-localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mu%C3%B1oz-Ba%C3%B1%C3%B3n%2C+M+%C3%81">Miguel &#xc1;ngel Mu&#xf1;oz-Ba&#xf1;&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Olivas%2C+A">Alejandro Olivas</a>, 
<a href="/search/cs?searchtype=author&query=Velasco-S%C3%A1nchez%2C+E">Edison Velasco-S&#xe1;nchez</a>, 
<a href="/search/cs?searchtype=author&query=Candelas%2C+F+A">Francisco A. Candelas</a>, 
<a href="/search/cs?searchtype=author&query=Torres%2C+F">Fernando Torres</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is under review at the journal "IEEE Robotics and Automation Letters"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Feature-based geo-localization relies on associating features extracted from
aerial imagery with those detected by the vehicle's sensors. This requires that
the type of landmarks must be observable from both sources. This no-variety of
feature types generates poor representations that lead to outliers and
deviations, produced by ambiguities and lack of detections respectively. To
mitigate these drawbacks, in this paper, we present a dynamically weighted
factor graph model for the vehicle's trajectory estimation. The weight
adjustment in this implementation depends on information quantification in the
detections performed using a LiDAR sensor. Also, a prior (GNSS-based) error
estimation is included in the model. Then, when the representation becomes
ambiguous or sparse, the weights are dynamically adjusted to rely on the
corrected prior trajectory, mitigating in this way outliers and deviations. We
compare our method against state-of-the-art geo-localization ones in a
challenging ambiguous environment, where we also cause detection losses. We
demonstrate mitigation of the mentioned drawbacks where the other methods fail.
</p>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07306" title="Abstract">arXiv:2311.07306</a> [<a href="/pdf/2311.07306" title="Download PDF">pdf</a>, <a href="/format/2311.07306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Large Language Models Bring to Text-rich VQA?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuejing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+W">Wei Tang</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+X">Xinzhe Ni</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jinghui Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zechao Li</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+F">Fei Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-rich VQA, namely Visual Question Answering based on text recognition in
the images, is a cross-modal task that requires both image comprehension and
text recognition. In this work, we focus on investigating the advantages and
bottlenecks of LLM-based approaches in addressing this problem. To address the
above concern, we separate the vision and language modules, where we leverage
external OCR models to recognize texts in the image and Large Language Models
(LLMs) to answer the question given texts. The whole framework is training-free
benefiting from the in-context ability of LLMs. This pipeline achieved superior
performance compared to the majority of existing Multimodal Large Language
Models (MLLM) on four text-rich VQA datasets. Besides, based on the ablation
study, we find that LLM brings stronger comprehension ability and may introduce
helpful knowledge for the VQA problem. The bottleneck for LLM to address
text-rich VQA problems may primarily lie in visual part. We also combine the
OCR module with MLLMs and pleasantly find that the combination of OCR module
with MLLM also works. It's worth noting that not all MLLMs can comprehend the
OCR information, which provides insights into how to train an MLLM that
preserves the abilities of LLM.
</p>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07311" title="Abstract">arXiv:2311.07311</a> [<a href="/pdf/2311.07311" title="Download PDF">pdf</a>, <a href="/format/2311.07311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do large language models and humans have similar behaviors in causal  inference with script knowledge?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+X">Xudong Hong</a>, 
<a href="/search/cs?searchtype=author&query=Ryzhova%2C+M">Margarita Ryzhova</a>, 
<a href="/search/cs?searchtype=author&query=Biondi%2C+D+A">Daniel Adrian Biondi</a>, 
<a href="/search/cs?searchtype=author&query=Demberg%2C+V">Vera Demberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently, large pre-trained language models (LLMs) have demonstrated superior
language understanding abilities, including zero-shot causal reasoning.
However, it is unclear to what extent their capabilities are similar to human
ones. We here study the processing of an event $B$ in a script-based story,
which causally depends on a previous event $A$. In our manipulation, event $A$
is stated, negated, or omitted in an earlier section of the text. We first
conducted a self-paced reading experiment, which showed that humans exhibit
significantly longer reading times when causal conflicts exist ($\neg A
\rightarrow B$) than under logical conditions ($A \rightarrow B$). However,
reading times remain similar when cause A is not explicitly mentioned,
indicating that humans can easily infer event B from their script knowledge. We
then tested a variety of LLMs on the same data to check to what extent the
models replicate human behavior. Our experiments show that 1) only recent LLMs,
like GPT-3 or Vicuna, correlate with human behavior in the $\neg A \rightarrow
B$ condition. 2) Despite this correlation, all models still fail to predict
that $nil \rightarrow B$ is less surprising than $\neg A \rightarrow B$,
indicating that LLMs still have difficulties integrating script knowledge. Our
code and collected data set are available at
https://github.com/tony-hong/causal-script.
</p>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07312" title="Abstract">arXiv:2311.07312</a> [<a href="/pdf/2311.07312" title="Download PDF">pdf</a>, <a href="/format/2311.07312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> C-Procgen: Empowering Procgen with Controllable Contexts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zhenxiong Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kaixin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinchao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We present C-Procgen, an enhanced suite of environments on top of the Procgen
benchmark. C-Procgen provides access to over 200 unique game contexts across 16
games. It allows for detailed configuration of environments, ranging from game
mechanics to agent attributes. This makes the procedural generation process,
previously a black-box in Procgen, more transparent and adaptable for various
research needs.The upgrade enhances dynamic context management and
individualized assignments, while maintaining computational efficiency.
C-Procgen's controllable contexts make it applicable in diverse reinforcement
learning research areas, such as learning dynamics analysis, curriculum
learning, and transfer learning. We believe that C-Procgen will fill a gap in
the current literature and offer a valuable toolkit for future works.
</p>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07314" title="Abstract">arXiv:2311.07314</a> [<a href="/pdf/2311.07314" title="Download PDF">pdf</a>, <a href="/format/2311.07314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-automatic Data Enhancement for Document-Level Relation Extraction  with Distant Supervision from Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junpeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Z">Zixia Jia</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zilong Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Document-level Relation Extraction (DocRE), which aims to extract relations
from a long context, is a critical challenge in achieving fine-grained
structural comprehension and generating interpretable document representations.
Inspired by recent advances in in-context learning capabilities emergent from
large language models (LLMs), such as ChatGPT, we aim to design an automated
annotation method for DocRE with minimum human effort. Unfortunately, vanilla
in-context learning is infeasible for document-level relation extraction due to
the plenty of predefined fine-grained relation types and the uncontrolled
generations of LLMs. To tackle this issue, we propose a method integrating a
large language model (LLM) and a natural language inference (NLI) module to
generate relation triples, thereby augmenting document-level relation datasets.
We demonstrate the effectiveness of our approach by introducing an enhanced
dataset known as DocGNRE, which excels in re-annotating numerous long-tail
relation types. We are confident that our method holds the potential for
broader applications in domain-specific relation type definitions and offers
tangible benefits in advancing generalized language semantic comprehension.
</p>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07321" title="Abstract">arXiv:2311.07321</a> [<a href="/pdf/2311.07321" title="Download PDF">pdf</a>, <a href="/format/2311.07321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Connecting the Dots: Graph Neural Network Powered Ensemble and  Classification of Medical Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Aryan Singh</a>, 
<a href="/search/cs?searchtype=author&query=Van+de+Ven%2C+P">Pepijn Van de Ven</a>, 
<a href="/search/cs?searchtype=author&query=Eising%2C+C">Ciar&#xe1;n Eising</a>, 
<a href="/search/cs?searchtype=author&query=Denny%2C+P">Patrick Denny</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Our code is available at <a href="https://github.com/aryan-at-ul/AICS_2023_submission">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> AICS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep learning models have demonstrated remarkable results for various
computer vision tasks, including the realm of medical imaging. However, their
application in the medical domain is limited due to the requirement for large
amounts of training data, which can be both challenging and expensive to
obtain. To mitigate this, pre-trained models have been fine-tuned on
domain-specific data, but such an approach can suffer from inductive biases.
Furthermore, deep learning models struggle to learn the relationship between
spatially distant features and their importance, as convolution operations
treat all pixels equally. Pioneering a novel solution to this challenge, we
employ the Image Foresting Transform to optimally segment images into
superpixels. These superpixels are subsequently transformed into
graph-structured data, enabling the proficient extraction of features and
modeling of relationships using Graph Neural Networks (GNNs). Our method
harnesses an ensemble of three distinct GNN architectures to boost its
robustness. In our evaluations targeting pneumonia classification, our
methodology surpassed prevailing Deep Neural Networks (DNNs) in performance,
all while drastically cutting down on the parameter count. This not only trims
down the expenses tied to data but also accelerates training and minimizes
bias. Consequently, our proposition offers a sturdy, economically viable, and
scalable strategy for medical image classification, significantly diminishing
dependency on extensive training data sets.
</p>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07323" title="Abstract">arXiv:2311.07323</a> [<a href="/pdf/2311.07323" title="Download PDF">pdf</a>, <a href="/format/2311.07323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Voting Approach for Explainable Classification with Rule Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=N%C3%B6ssig%2C+A">Albert N&#xf6;ssig</a>, 
<a href="/search/cs?searchtype=author&query=Hell%2C+T">Tobias Hell</a>, 
<a href="/search/cs?searchtype=author&query=Moser%2C+G">Georg Moser</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">State-of-the-art results in typical classification tasks are mostly achieved
by unexplainable machine learning methods, like deep neural networks, for
instance. Contrarily, in this paper, we investigate the application of rule
learning methods in such a context. Thus, classifications become based on
comprehensible (first-order) rules, explaining the predictions made. In
general, however, rule-based classifications are less accurate than
state-of-the-art results (often significantly). As main contribution, we
introduce a voting approach combining both worlds, aiming to achieve comparable
results as (unexplainable) state-of-the-art methods, while still providing
explanations in the form of deterministic rules. Considering a variety of
benchmark data sets including a use case of significant interest to insurance
industries, we prove that our approach not only clearly outperforms ordinary
rule learning methods, but also yields results on a par with state-of-the-art
outcomes.
</p>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07324" title="Abstract">arXiv:2311.07324</a> [<a href="/pdf/2311.07324" title="Download PDF">pdf</a>, <a href="/format/2311.07324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DAGC: Data-Volume-Aware Adaptive Sparsification Gradient Compression for  Distributed Machine Learning in Mobile Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+R">Rongwei Lu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yutong Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yinan Mao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chen Tang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+L">Laizhong Cui</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Distributed machine learning (DML) in mobile environments faces significant
communication bottlenecks. Gradient compression has emerged as an effective
solution to this issue, offering substantial benefits in environments with
limited bandwidth and metered data. Yet, they encounter severe performance drop
in non-IID environments due to a one-size-fits-all compression approach, which
does not account for the varying data volumes across workers. Assigning varying
compression ratios to workers with distinct data distributions and volumes is
thus a promising solution. This study introduces an analysis of distributed SGD
with non-uniform compression, which reveals that the convergence rate
(indicative of the iterations needed to achieve a certain accuracy) is
influenced by compression ratios applied to workers with differing volumes.
Accordingly, we frame relative compression ratio assignment as an $n$-variables
chi-square nonlinear optimization problem, constrained by a fixed and limited
communication budget. We propose DAGC-R, which assigns the worker handling
larger data volumes the conservative compression. Recognizing the computational
limitations of mobile devices, we DAGC-A, which are computationally less
demanding and enhances the robustness of the absolute gradient compressor in
non-IID scenarios. Our experiments confirm that both the DAGC-A and DAGC-R can
achieve better performance when dealing with highly imbalanced data volume
distribution and restricted communication.
</p>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07326" title="Abstract">arXiv:2311.07326</a> [<a href="/pdf/2311.07326" title="Download PDF">pdf</a>, <a href="/format/2311.07326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MetaSymNet: A Dynamic Symbolic Regression Network Capable of Evolving  into Arbitrary Formulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weijun Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lina Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Min Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenqiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+M">Meilan Hao</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+S">Shu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yusong Deng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Mathematical formulas serve as the means of communication between humans and
nature, encapsulating the operational laws governing natural phenomena. The
concise formulation of these laws is a crucial objective in scientific research
and an important challenge for artificial intelligence (AI). While traditional
artificial neural networks (MLP) excel at data fitting, they often yield
uninterpretable black box results that hinder our understanding of the
relationship between variables x and predicted values y. Moreover, the fixed
network architecture in MLP often gives rise to redundancy in both network
structure and parameters. To address these issues, we propose MetaSymNet, a
novel neural network that dynamically adjusts its structure in real-time,
allowing for both expansion and contraction. This adaptive network employs the
PANGU meta function as its activation function, which is a unique type capable
of evolving into various basic functions during training to compose
mathematical formulas tailored to specific needs. We then evolve the neural
network into a concise, interpretable mathematical expression. To evaluate
MetaSymNet's performance, we compare it with four state-of-the-art symbolic
regression algorithms across more than 10 public datasets comprising 222
formulas. Our experimental results demonstrate that our algorithm outperforms
others consistently regardless of noise presence or absence. Furthermore, we
assess MetaSymNet against MLP and SVM regarding their fitting ability and
extrapolation capability, these are two essential aspects of machine learning
algorithms. The findings reveal that our algorithm excels in both areas.
Finally, we compared MetaSymNet with MLP using iterative pruning in network
structure complexity. The results show that MetaSymNet's network structure
complexity is obviously less than MLP under the same goodness of fit.
</p>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07329" title="Abstract">arXiv:2311.07329</a> [<a href="/pdf/2311.07329" title="Download PDF">pdf</a>, <a href="/format/2311.07329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Distributed Consensus Meets Wireless Connected Autonomous Systems:  A Review and A DAG-based Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Huanyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+C">Chentao Yue</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yonghui Li</a>, 
<a href="/search/cs?searchtype=author&query=Imran%2C+M+A">Muhammad Ali Imran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The connected and autonomous systems (CAS) and auto-driving era is coming
into our life. To support CAS applications such as AI-driven decision-making
and blockchain-based smart data management platform, data and message
exchange/dissemination is a fundamental element. The distributed message
broadcast and forward protocols in CAS, such as vehicular ad hoc networks
(VANET), can suffer from significant message loss and uncertain transmission
delay, and faulty nodes might disseminate fake messages to confuse the network.
Therefore, the consensus mechanism is essential in CAS with distributed
structure to guaranteed correct nodes agree on the same parameter and reach
consistency. However, due to the wireless nature of CAS, traditional consensus
cannot be directly deployed. This article reviews several existing consensus
mechanisms, including average/maximum/minimum estimation consensus mechanisms
that apply on quantity, Byzantine fault tolerance consensus for request, state
machine replication (SMR) and blockchain, as well as their implementations in
CAS. To deploy wireless-adapted consensus, we propose a Directed Acyclic Graph
(DAG)-based message structure to build a non-equivocation data dissemination
protocol for CAS, which has resilience against message loss and unpredictable
forwarding latency. Finally, we enhance this protocol by developing a
two-dimension DAG-based strategy to achieve partial order for blockchain and
total order for the distributed service model SMR.
</p>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07331" title="Abstract">arXiv:2311.07331</a> [<a href="/pdf/2311.07331" title="Download PDF">pdf</a>, <a href="/format/2311.07331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometric Tracking Control of a Multi-rotor UAV for Partially Known  Trajectories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kumar%2C+Y">Yogesh Kumar</a>, 
<a href="/search/eess?searchtype=author&query=Roy%2C+S+B">S.B. Roy</a>, 
<a href="/search/eess?searchtype=author&query=Sujit%2C+P+B">P.B. Sujit</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper presents a trajectory-tracking controller for multi-rotor unmanned
aerial vehicles (UAVs) in scenarios where only the desired position and heading
are known without the higher-order derivatives. The proposed solution modifies
the state-of-the-art geometric controller, effectively addressing challenges
related to the non-existence of the desired attitude and ensuring positive
total thrust input for all time. We tackle the additional challenge of the
non-availability of the higher derivatives of the trajectory by introducing
novel nonlinear filter structures. We formalize theoretically the effect of
these filter structures on the system error dynamics. Subsequently, through a
rigorous theoretical analysis, we demonstrate that the proposed controller
leads to uniformly ultimately bounded system error dynamics.
</p>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07335" title="Abstract">arXiv:2311.07335</a> [<a href="/pdf/2311.07335" title="Download PDF">pdf</a>, <a href="/format/2311.07335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Throughput Maximization in Multi-Band Optical Networks with Column  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Cao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+S">Shilin Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+F">Fen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tornatore%2C+M">Massimo Tornatore</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures, submitted to IEEE International Conference on Communications 2024 (ICC2024). (Note on arXiv: for beginners in the area of column generation, please refer to the example computation in the file &amp;lt;supplementary_4nodeExampleComputation.pdf&amp;gt;. I have uploaded it to this arXiv project along with other source files.)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Multi-band transmission is a promising technical direction for spectrum and
capacity expansion of existing optical networks. Due to the increase in the
number of usable wavelengths in multi-band optical networks, the complexity of
resource allocation problems becomes a major concern. Moreover, the
transmission performance, spectrum width, and cost constraint across optical
bands may be heterogeneous. Assuming a worst-case transmission margin in U, L,
and C-bands, this paper investigates the problem of throughput maximization in
multi-band optical networks, including the optimization of route, wavelength,
and band assignment. We propose a low-complexity decomposition approach based
on Column Generation (CG) to address the scalability issue faced by traditional
methodologies. We numerically compare the results obtained by our CG-based
approach to an integer linear programming model, confirming the near-optimal
network throughput. Our results also demonstrate the scalability of the
CG-based approach when the number of wavelengths increases, with the
computation time in the magnitude order of 10 s for cases varying from 75 to
1200 wavelength channels per link in a 14-node network.
</p>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07343" title="Abstract">arXiv:2311.07343</a> [<a href="/pdf/2311.07343" title="Download PDF">pdf</a>, <a href="/format/2311.07343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-Tuning the Retrieval Mechanism for Tabular Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Breejen%2C+F+d">Felix den Breejen</a>, 
<a href="/search/cs?searchtype=author&query=Bae%2C+S">Sangmin Bae</a>, 
<a href="/search/cs?searchtype=author&query=Cha%2C+S">Stephen Cha</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Tae-Young Kim</a>, 
<a href="/search/cs?searchtype=author&query=Koh%2C+S+H">Seoung Hyun Koh</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+S">Se-Young Yun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Table Representation Learning Workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">While interests in tabular deep learning has significantly grown,
conventional tree-based models still outperform deep learning methods. To
narrow this performance gap, we explore the innovative retrieval mechanism, a
methodology that allows neural networks to refer to other data points while
making predictions. Our experiments reveal that retrieval-based training,
especially when fine-tuning the pretrained TabPFN model, notably surpasses
existing methods. Moreover, the extensive pretraining plays a crucial role to
enhance the performance of the model. These insights imply that blending the
retrieval mechanism with pretraining and transfer learning schemes offers
considerable potential for advancing the field of tabular deep learning.
</p>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07344" title="Abstract">arXiv:2311.07344</a> [<a href="/pdf/2311.07344" title="Download PDF">pdf</a>, <a href="/format/2311.07344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Missing Value Imputation for Multi-attribute Sensor Data Streams via  Message Propagation (Extended Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huan Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hua Lu</a>, 
<a href="/search/cs?searchtype=author&query=Jensen%2C+C+S">Christian S. Jensen</a>, 
<a href="/search/cs?searchtype=author&query=Pandey%2C+V">Varun Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Markl%2C+V">Volker Markl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at VLDB 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Sensor data streams occur widely in various real-time applications in the
context of the Internet of Things (IoT). However, sensor data streams feature
missing values due to factors such as sensor failures, communication errors, or
depleted batteries. Missing values can compromise the quality of real-time
analytics tasks and downstream applications. Existing imputation methods either
make strong assumptions about streams or have low efficiency. In this study, we
aim to accurately and efficiently impute missing values in data streams that
satisfy only general characteristics in order to benefit real-time applications
more widely. First, we propose a message propagation imputation network (MPIN)
that is able to recover the missing values of data instances in a time window.
We give a theoretical analysis of why MPIN is effective. Second, we present a
continuous imputation framework that consists of data update and model update
mechanisms to enable MPIN to perform continuous imputation both effectively and
efficiently. Extensive experiments on multiple real datasets show that MPIN can
outperform the existing data imputers by wide margins and that the continuous
imputation framework is efficient and accurate.
</p>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07346" title="Abstract">arXiv:2311.07346</a> [<a href="/pdf/2311.07346" title="Download PDF">pdf</a>, <a href="/format/2311.07346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Goal-oriented Estimation of Multiple Markov Sources in  Resource-constrained Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Luo%2C+J">Jiping Luo</a>, 
<a href="/search/eess?searchtype=author&query=Pappas%2C+N">Nikolaos Pappas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">This paper investigates goal-oriented communication for remote estimation of
multiple Markov sources in resource-constrained networks. An agent selects the
update order of the sources and transmits the packet to a remote destination
over an unreliable delay channel. The destination is tasked with source
reconstruction for the purpose of actuation. We utilize the metric cost of
actuation error (CAE) to capture the significance (semantics) of error at the
point of actuation. We aim to find an optimal sampling policy that minimizes
the time-averaged CAE subject to average resource constraints. We formulate
this problem as an average-cost constrained Markov Decision Process (CMDP) and
transform it into an unconstrained MDP by utilizing Lyapunov drift techniques.
Then, we propose a low-complexity drift-plus-penalty(DPP) policy for systems
with known source/channel statistics and a Lyapunov optimization-based deep
reinforcement learning (LO-DRL) policy for unknown environments. Our policies
achieve near-optimal performance in CAE minimization and significantly reduce
the number of uninformative transmissions.
</p>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07349" title="Abstract">arXiv:2311.07349</a> [<a href="/pdf/2311.07349" title="Download PDF">pdf</a>, <a href="/format/2311.07349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vehicle-to-grid for car sharing -- A simulation study for 2030
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wiedemann%2C+N">Nina Wiedemann</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+Y">Yanan Xin</a>, 
<a href="/search/cs?searchtype=author&query=Medici%2C+V">Vasco Medici</a>, 
<a href="/search/cs?searchtype=author&query=Nespoli%2C+L">Lorenzo Nespoli</a>, 
<a href="/search/cs?searchtype=author&query=Suel%2C+E">Esra Suel</a>, 
<a href="/search/cs?searchtype=author&query=Raubal%2C+M">Martin Raubal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">The proliferation of car sharing services in recent years presents a
promising avenue for advancing sustainable transportation. Beyond merely
reducing car ownership rates, these systems can play a pivotal role in
bolstering grid stability through the provision of ancillary services via
vehicle-to-grid (V2G) technologies - a facet that has received limited
attention in previous research. In this study, we analyze the potential of V2G
in car sharing by designing future scenarios for a national-scale service in
Switzerland. We propose an agent-based simulation pipeline that considers
population changes as well as different business strategies of the car sharing
service, and we demonstrate its successful application for simulating scenarios
for 2030. To imitate car sharing user behavior, we develop a data-driven mode
choice model. Our analysis reveals important differences in the examined
scenarios, such as higher vehicle utilization rates for a reduced fleet size as
well as in a scenario featuring new car sharing stations. These disparities
translate into variations in the power flexibility of the fleet available for
ancillary services, ranging from 12 to 50 MW, depending on the scenario and the
time of the day. Furthermore, we conduct a case study involving a subset of the
car sharing fleet, incorporating real-world electricity pricing data. The case
study substantiates the existence of a sweet spot involving monetary gains for
both power grid operators and fleet owners. Our findings provide guidelines to
decision makers and underscore the pressing need for regulatory enhancements
concerning power trading within the realm of car sharing.
</p>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07355" title="Abstract">arXiv:2311.07355</a> [<a href="/pdf/2311.07355" title="Download PDF">pdf</a>, <a href="/format/2311.07355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ADAMM: Anomaly Detection of Attributed Multi-graphs with Metadata: A  Unified Neural Network Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sotiropoulos%2C+K">Konstantinos Sotiropoulos</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lingxiao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P+J">Pierre Jinghong Liang</a>, 
<a href="/search/cs?searchtype=author&query=Akoglu%2C+L">Leman Akoglu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE BigData 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Given a complex graph database of node- and edge-attributed multi-graphs as
well as associated metadata for each graph, how can we spot the anomalous
instances? Many real-world problems can be cast as graph inference tasks where
the graph representation could capture complex relational phenomena (e.g.,
transactions among financial accounts in a journal entry), along with metadata
reflecting tabular features (e.g. approver, effective date, etc.). While
numerous anomaly detectors based on Graph Neural Networks (GNNs) have been
proposed, none are capable of directly handling directed graphs with
multi-edges and self-loops. Furthermore, the simultaneous handling of
relational and tabular features remains an unexplored area. In this work we
propose ADAMM, a novel graph neural network model that handles directed
multi-graphs, providing a unified end-to-end architecture that fuses metadata
and graph-level representation learning through an unsupervised anomaly
detection objective. Experiments on datasets from two different domains,
namely, general-ledger journal entries from different firms (accounting) as
well as human GPS trajectories from thousands of individuals (urban mobility)
validate ADAMM's generality and detection effectiveness of expert-guided and
ground-truth anomalies. Notably, ADAMM outperforms existing baselines that
handle the two data modalities (graph and metadata) separately with post hoc
synthesis efforts.
</p>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07357" title="Abstract">arXiv:2311.07357</a> [<a href="/pdf/2311.07357" title="Download PDF">pdf</a>, <a href="/format/2311.07357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Registered and Segmented Deformable Object Reconstruction from a Single  View Point Cloud
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Henrich%2C+P">Pit Henrich</a>, 
<a href="/search/cs?searchtype=author&query=Gyenes%2C+B">Bal&#xe1;zs Gyenes</a>, 
<a href="/search/cs?searchtype=author&query=Scheikl%2C+P+M">Paul Maria Scheikl</a>, 
<a href="/search/cs?searchtype=author&query=Neumann%2C+G">Gerhard Neumann</a>, 
<a href="/search/cs?searchtype=author&query=Mathis-Ullrich%2C+F">Franziska Mathis-Ullrich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In deformable object manipulation, we often want to interact with specific
segments of an object that are only defined in non-deformed models of the
object. We thus require a system that can recognize and locate these segments
in sensor data of deformed real world objects. This is normally done using
deformable object registration, which is problem specific and complex to tune.
Recent methods utilize neural occupancy functions to improve deformable object
registration by registering to an object reconstruction. Going one step
further, we propose a system that in addition to reconstruction learns
segmentation of the reconstructed object. As the resulting output already
contains the information about the segments, we can skip the registration
process. Tested on a variety of deformable objects in simulation and the real
world, we demonstrate that our method learns to robustly find these segments.
We also introduce a simple sampling algorithm to generate better training data
for occupancy learning.
</p>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07361" title="Abstract">arXiv:2311.07361</a> [<a href="/pdf/2311.07361" title="Download PDF">pdf</a>, <a href="/format/2311.07361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impact of Large Language Models on Scientific Discovery: a  Preliminary Study using GPT-4
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=AI4Science%2C+M+R">Microsoft Research AI4Science</a>, 
<a href="/search/cs?searchtype=author&query=Quantum%2C+M+A">Microsoft Azure Quantum</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 230 pages report; 181 pages for main contents
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In recent years, groundbreaking advancements in natural language processing
have culminated in the emergence of powerful large language models (LLMs),
which have showcased remarkable capabilities across a vast array of domains,
including the understanding, generation, and translation of natural language,
and even tasks that extend beyond language processing. In this report, we delve
into the performance of LLMs within the context of scientific discovery,
focusing on GPT-4, the state-of-the-art language model. Our investigation spans
a diverse range of scientific areas encompassing drug discovery, biology,
computational chemistry (density functional theory (DFT) and molecular dynamics
(MD)), materials design, and partial differential equations (PDE). Evaluating
GPT-4 on scientific tasks is crucial for uncovering its potential across
various research domains, validating its domain-specific expertise,
accelerating scientific progress, optimizing resource allocation, guiding
future model development, and fostering interdisciplinary research. Our
exploration methodology primarily consists of expert-driven case assessments,
which offer qualitative insights into the model's comprehension of intricate
scientific concepts and relationships, and occasionally benchmark testing,
which quantitatively evaluates the model's capacity to solve well-defined
domain-specific problems. Our preliminary exploration indicates that GPT-4
exhibits promising potential for a variety of scientific applications,
demonstrating its aptitude for handling complex problem-solving and knowledge
integration tasks. Broadly speaking, we evaluate GPT-4's knowledge base,
scientific understanding, scientific numerical calculation abilities, and
various scientific prediction capabilities.
</p>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07362" title="Abstract">arXiv:2311.07362</a> [<a href="/pdf/2311.07362" title="Download PDF">pdf</a>, <a href="/format/2311.07362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Volcano: Mitigating Multimodal Hallucination through Self-Feedback  Guided Revision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seongyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S+H">Sue Hyun Park</a>, 
<a href="/search/cs?searchtype=author&query=Jo%2C+Y">Yongrae Jo</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+M">Minjoon Seo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Large multimodal models (LMMs) suffer from multimodal hallucination, where
they provide incorrect responses misaligned with the given visual information.
Recent works have conjectured that one of the reasons behind multimodal
hallucination might be due to the vision encoder failing to ground on the image
properly. To mitigate this issue, we propose a novel approach that leverages
self-feedback as visual cues. Building on this approach, we introduce Volcano,
a multimodal self-feedback guided revision model. Volcano generates natural
language feedback to its initial response based on the provided visual
information and utilizes this feedback to self-revise its initial response.
Volcano effectively reduces multimodal hallucination and achieves
state-of-the-art on MMHal-Bench, POPE, and GAVIE. It also improves on general
multimodal abilities and outperforms previous models on MM-Vet and MMBench.
Through a qualitative analysis, we show that Volcano's feedback is properly
grounded on the image than the initial response. This indicates that Volcano
can provide itself with richer visual information, helping alleviate multimodal
hallucination. We publicly release Volcano models of 7B and 13B sizes along
with the data and code at https://github.com/kaistAI/Volcano.
</p>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07363" title="Abstract">arXiv:2311.07363</a> [<a href="/pdf/2311.07363" title="Download PDF">pdf</a>, <a href="/format/2311.07363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient bandwidth extension of musical signals using a differentiable  harmonic plus noise mode
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grumiaux%2C+P">Pierre-Amaury Grumiaux</a>, 
<a href="/search/cs?searchtype=author&query=Lagrange%2C+M">Mathieu Lagrange</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepting for publication in EURASIP Journal on Audio, Speech, and Music Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The task of bandwidth extension addresses the generation of missing high
frequencies of audio signals based on knowledge of the low-frequency part of
the sound. This task applies to various problems, such as audio coding or audio
restoration. In this article, we focus on efficient bandwidth extension of
monophonic and polyphonic musical signals using a differentiable digital signal
processing (DDSP) model. Such a model is composed of a neural network part with
relatively few parameters trained to infer the parameters of a differentiable
digital signal processing model, which efficiently generates the output
full-band audio signal.
<br />We first address bandwidth extension of monophonic signals, and then propose
two methods to explicitely handle polyphonic signals. The benefits of the
proposed models are first demonstrated on monophonic and polyphonic synthetic
data against a baseline and a deep-learning-based resnet model. The models are
next evaluated on recorded monophonic and polyphonic data, for a wide variety
of instruments and musical genres. We show that all proposed models surpass a
higher complexity deep learning model for an objective metric computed in the
frequency domain. A MUSHRA listening test confirms the superiority of the
proposed approach in terms of perceptual quality.
</p>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07369" title="Abstract">arXiv:2311.07369</a> [<a href="/pdf/2311.07369" title="Download PDF">pdf</a>, <a href="/ps/2311.07369" title="Download PostScript">ps</a>, <a href="/format/2311.07369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unboxed data constructors -- or, how cpp decides a halting problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chataing%2C+N">Nicolas Chataing</a>, 
<a href="/search/cs?searchtype=author&query=Dolan%2C+S">Stephen Dolan</a>, 
<a href="/search/cs?searchtype=author&query=Scherer%2C+G">Gabriel Scherer</a>, 
<a href="/search/cs?searchtype=author&query=Yallop%2C+J">Jeremy Yallop</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Author version, to appear at POPL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">We propose a new language feature for ML-family languages, the ability to
selectively *unbox* certain data constructors, so that their runtime
representation gets compiled away to just the identity on their argument.
<br />Unboxing must be statically rejected when it could introduce *confusions*,
that is, distinct values with the same representation.
<br />We discuss the use-case of big numbers, where unboxing allows to write code
that is both efficient and safe, replacing either a safe but slow version or a
fast but unsafe version.
<br />We explain the static analysis necessary to reject incorrect unboxing
requests.
<br />We present our prototype implementation of this feature for the OCaml
programming language, discuss several design choices and the interaction with
advanced features such as Guarded Algebraic Datatypes.
<br />Our static analysis requires expanding type definitions in type expressions,
which is not necessarily normalizing in presence of recursive type definitions.
In other words, we must decide normalization of terms in the first-order
lambda-calculus with recursion. We provide an algorithm to detect
non-termination on-the-fly during reduction, with proofs of correctness and
completeness.
<br />Our termination-monitoring algorithm turns out to be closely related to the
normalization strategy for macro expansion in the `cpp` preprocessor.
</p>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07370" title="Abstract">arXiv:2311.07370</a> [<a href="/pdf/2311.07370" title="Download PDF">pdf</a>, <a href="/format/2311.07370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classification of developmental and brain disorders via graph  convolutional aggregation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salim%2C+I">Ibrahim Salim</a>, 
<a href="/search/cs?searchtype=author&query=Hamza%2C+A+B">A. Ben Hamza</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">While graph convolution based methods have become the de-facto standard for
graph representation learning, their applications to disease prediction tasks
remain quite limited, particularly in the classification of neurodevelopmental
and neurodegenerative brain disorders. In this paper, we introduce an
aggregator normalization graph convolutional network by leveraging aggregation
in graph sampling, as well as skip connections and identity mapping. The
proposed model learns discriminative graph node representations by
incorporating both imaging and non-imaging features into the graph nodes and
edges, respectively, with the aim of augmenting predictive capabilities and
providing a holistic perspective on the underlying mechanisms of brain
disorders. Skip connections enable the direct flow of information from the
input features to later layers of the network, while identity mapping helps
maintain the structural information of the graph during feature learning. We
benchmark our model against several recent baseline methods on two large
datasets, Autism Brain Imaging Data Exchange (ABIDE) and Alzheimer's Disease
Neuroimaging Initiative (ADNI), for the prediction of autism spectrum disorder
and Alzheimer's disease, respectively. Experimental results demonstrate the
competitive performance of our approach in comparison with recent baselines in
terms of several evaluation metrics, achieving relative improvements of 50% and
13.56% in classification accuracy over graph convolutional networks on ABIDE
and ADNI, respectively.
</p>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07377" title="Abstract">arXiv:2311.07377</a> [<a href="/pdf/2311.07377" title="Download PDF">pdf</a>, <a href="/format/2311.07377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Testing learning-enabled cyber-physical systems with Large-Language  Models: A Formal Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Mok%2C+A+K">Aloysius K. Mok</a>, 
<a href="/search/cs?searchtype=author&query=Piskac%2C+R">Ruzica Piskac</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y+J">Yong Jae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamachari%2C+B">Bhaskar Krishnamachari</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+D">Dakai Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Sokolsky%2C+O">Oleg Sokolsky</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+I">Insup Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Robotics (cs.RO)

</div>
<p class="mathjax">The integration of machine learning (ML) into cyber-physical systems (CPS)
offers significant benefits, including enhanced efficiency, predictive
capabilities, real-time responsiveness, and the enabling of autonomous
operations. This convergence has accelerated the development and deployment of
a range of real-world applications, such as autonomous vehicles, delivery
drones, service robots, and telemedicine procedures. However, the software
development life cycle (SDLC) for AI-infused CPS diverges significantly from
traditional approaches, featuring data and learning as two critical components.
Existing verification and validation techniques are often inadequate for these
new paradigms. In this study, we pinpoint the main challenges in ensuring
formal safety for learningenabled CPS.We begin by examining testing as the most
pragmatic method for verification and validation, summarizing the current
state-of-the-art methodologies. Recognizing the limitations in current testing
approaches to provide formal safety guarantees, we propose a roadmap to
transition from foundational probabilistic testing to a more rigorous approach
capable of delivering formal assurance.
</p>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07383" title="Abstract">arXiv:2311.07383</a> [<a href="/pdf/2311.07383" title="Download PDF">pdf</a>, <a href="/format/2311.07383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LM-Polygraph: Uncertainty Estimation for Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fadeeva%2C+E">Ekaterina Fadeeva</a>, 
<a href="/search/cs?searchtype=author&query=Vashurin%2C+R">Roman Vashurin</a>, 
<a href="/search/cs?searchtype=author&query=Tsvigun%2C+A">Akim Tsvigun</a>, 
<a href="/search/cs?searchtype=author&query=Vazhentsev%2C+A">Artem Vazhentsev</a>, 
<a href="/search/cs?searchtype=author&query=Petrakov%2C+S">Sergey Petrakov</a>, 
<a href="/search/cs?searchtype=author&query=Fedyanin%2C+K">Kirill Fedyanin</a>, 
<a href="/search/cs?searchtype=author&query=Vasilev%2C+D">Daniil Vasilev</a>, 
<a href="/search/cs?searchtype=author&query=Goncharova%2C+E">Elizaveta Goncharova</a>, 
<a href="/search/cs?searchtype=author&query=Panchenko%2C+A">Alexander Panchenko</a>, 
<a href="/search/cs?searchtype=author&query=Panov%2C+M">Maxim Panov</a>, 
<a href="/search/cs?searchtype=author&query=Baldwin%2C+T">Timothy Baldwin</a>, 
<a href="/search/cs?searchtype=author&query=Shelmanov%2C+A">Artem Shelmanov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advancements in the capabilities of large language models (LLMs) have
paved the way for a myriad of groundbreaking applications in various fields.
However, a significant challenge arises as these models often "hallucinate",
i.e., fabricate facts without providing users an apparent means to discern the
veracity of their statements. Uncertainty estimation (UE) methods are one path
to safer, more responsible, and more effective use of LLMs. However, to date,
research on UE methods for LLMs has been focused primarily on theoretical
rather than engineering contributions. In this work, we tackle this issue by
introducing LM-Polygraph, a framework with implementations of a battery of
state-of-the-art UE methods for LLMs in text generation tasks, with unified
program interfaces in Python. Additionally, it introduces an extendable
benchmark for consistent evaluation of UE techniques by researchers, and a demo
web application that enriches the standard chat dialog with confidence scores,
empowering end-users to discern unreliable responses. LM-Polygraph is
compatible with the most recent LLMs, including BLOOMz, LLaMA-2, ChatGPT, and
GPT-4, and is designed to support future releases of similarly-styled LMs.
</p>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07385" title="Abstract">arXiv:2311.07385</a> [<a href="/pdf/2311.07385" title="Download PDF">pdf</a>, <a href="/format/2311.07385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> P4-PSFP: P4-Based Per-Stream Filtering and Policing for Time-Sensitive  Networking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ihle%2C+F">Fabian Ihle</a>, 
<a href="/search/cs?searchtype=author&query=Lindner%2C+S">Steffen Lindner</a>, 
<a href="/search/cs?searchtype=author&query=Menth%2C+M">Michael Menth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Time-Sensitive Networking (TSN) extends Ethernet to enable real-time
communication, including the Credit-Based Shaper (CBS) for prioritized
scheduling and the Time-Aware Shaper (TAS) for scheduled traffic. Generally,
TSN requires streams to be explicitly admitted before being transmitted. To
ensure that admitted traffic conforms with the traffic descriptors indicated
for admission control, Per-Stream Filtering and Policing (PSFP) has been
defined. For credit-based metering, well-known token bucket policers are
applied. However, time-based metering requires time-dependent switch behavior
and time synchronization with sub-microsecond precision. While TSN-capable
switches support various TSN traffic shaping mechanisms, a full implementation
of PSFP is still not available. To bridge this gap, we present a P4-based
implementation of PSFP on a 100 Gb/s per port hardware switch. We explain the
most interesting aspects of the PSFP implementation whose code is available on
GitHub. We demonstrate credit-based and time-based policing and synchronization
capabilities to validate the functionality and effectiveness of P4-PSFP. The
implementation scales up to 35840 streams depending on the stream
identification method. P4-PSFP can be used in practice as long as appropriate
TSN switches lack this function. Moreover, its implementation may be helpful
for other P4-based hardware implementations that require time synchronization.
</p>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07387" title="Abstract">arXiv:2311.07387</a> [<a href="/pdf/2311.07387" title="Download PDF">pdf</a>, <a href="/format/2311.07387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing Logical Puzzle Solving in Large Language Models: Insights from  a Minesweeper Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yinghao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haorui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 5 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) have shown remarkable proficiency in language
understanding and have been successfully applied to a variety of real-world
tasks through task-specific fine-tuning or prompt engineering. Despite these
advancements, it remains an open question whether LLMs are fundamentally
capable of reasoning and planning, or if they primarily rely on recalling and
synthesizing information from their training data. In our research, we
introduce a novel task -- Minesweeper -- specifically designed in a format
unfamiliar to LLMs and absent from their training datasets. This task
challenges LLMs to identify the locations of mines based on numerical clues
provided by adjacent opened cells. Successfully completing this task requires
an understanding of each cell's state, discerning spatial relationships between
the clues and mines, and strategizing actions based on logical deductions drawn
from the arrangement of the cells. Our experiments, including trials with the
advanced GPT-4 model, indicate that while LLMs possess the foundational
abilities required for this task, they struggle to integrate these into a
coherent, multi-step logical reasoning process needed to solve Minesweeper.
These findings highlight the need for further research to understand and nature
of reasoning capabilities in LLMs under similar circumstances, and to explore
pathways towards more sophisticated AI reasoning and planning models.
</p>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07389" title="Abstract">arXiv:2311.07389</a> [<a href="/pdf/2311.07389" title="Download PDF">pdf</a>, <a href="/format/2311.07389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transpose Attack: Stealing Datasets with Bidirectional Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amit%2C+G">Guy Amit</a>, 
<a href="/search/cs?searchtype=author&query=Levy%2C+M">Mosh Levy</a>, 
<a href="/search/cs?searchtype=author&query=Mirsky%2C+Y">Yisroel Mirsky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NDSS24 paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Deep neural networks are normally executed in the forward direction. However,
in this work, we identify a vulnerability that enables models to be trained in
both directions and on different tasks. Adversaries can exploit this capability
to hide rogue models within seemingly legitimate models. In addition, in this
work we show that neural networks can be taught to systematically memorize and
retrieve specific samples from datasets. Together, these findings expose a
novel method in which adversaries can exfiltrate datasets from protected
learning environments under the guise of legitimate models. We focus on the
data exfiltration attack and show that modern architectures can be used to
secretly exfiltrate tens of thousands of samples with high fidelity, high
enough to compromise data privacy and even train new models. Moreover, to
mitigate this threat we propose a novel approach for detecting infected models.
</p>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07390" title="Abstract">arXiv:2311.07390</a> [<a href="/pdf/2311.07390" title="Download PDF">pdf</a>, <a href="/format/2311.07390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the Significance of Outdoor Advertising from Driver&#x27;s  Perspective Using Computer Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C4%8Cernekov%C3%A1%2C+Z">Zuzana &#x10c;ernekov&#xe1;</a>, 
<a href="/search/cs?searchtype=author&query=Haladov%C3%A1%2C+Z+B">Zuzana Berger Haladov&#xe1;</a>, 
<a href="/search/cs?searchtype=author&query=%C5%A0pirka%2C+J">J&#xe1;n &#x160;pirka</a>, 
<a href="/search/cs?searchtype=author&query=Kocur%2C+V">Viktor Kocur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pubslished in 2023 World Symposium on Digital Intelligence for Systems and Machines (DISA) Proceedings. Published version copyrighted by IEEE, pre-print released in accordance with the copyright agreement
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Outdoor advertising, such as roadside billboards, plays a significant role in
marketing campaigns but can also be a distraction for drivers, potentially
leading to accidents. In this study, we propose a pipeline for evaluating the
significance of roadside billboards in videos captured from a driver's
perspective. We have collected and annotated a new BillboardLamac dataset,
comprising eight videos captured by drivers driving through a predefined path
wearing eye-tracking devices. The dataset includes annotations of billboards,
including 154 unique IDs and 155 thousand bounding boxes, as well as eye
fixation data. We evaluate various object tracking methods in combination with
a YOLOv8 detector to identify billboard advertisements with the best approach
achieving 38.5 HOTA on BillboardLamac. Additionally, we train a random forest
classifier to classify billboards into three classes based on the length of
driver fixations achieving 75.8% test accuracy. An analysis of the trained
classifier reveals that the duration of billboard visibility, its saliency, and
size are the most influential features when assessing billboard significance.
</p>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07391" title="Abstract">arXiv:2311.07391</a> [<a href="/pdf/2311.07391" title="Download PDF">pdf</a>, <a href="/format/2311.07391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Layer Monitoring at the Edge for Vehicular Video Streaming: Field  Trials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yeregui%2C+I">Inhar Yeregui</a>, 
<a href="/search/cs?searchtype=author&query=Uriol%2C+J">Juncal Uriol</a>, 
<a href="/search/cs?searchtype=author&query=Viola%2C+R">Roberto Viola</a>, 
<a href="/search/cs?searchtype=author&query=Angueira%2C+P">Pablo Angueira</a>, 
<a href="/search/cs?searchtype=author&query=Astorga%2C+J">Jasone Astorga</a>, 
<a href="/search/cs?searchtype=author&query=Montalban%2C+J">Jon Montalban</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE International Symposium on Broadband Multimedia Systems
  and Broadcasting (BMSB), 2023, pp. 1-7
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">In an increasingly connected world, wireless networks' monitoring and
characterization are of vital importance. Service and application providers
need to have a detailed understanding of network performance to offer new
solutions tailored to the needs of today's society. In the context of mobility,
in-vehicle infotainment services are expected to stand out among other popular
connected vehicle services, so it is essential that communication networks are
able to satisfy the Quality of Service (QoS) and Quality of Experience (QoE)
requirements needed for these type of services. This paper investigates a
multi-layer network performance monitoring architecture at the edge providing
QoS, QoE, and localization information for vehicular video streaming
applications in real-time over 5G networks. In order to conduct field trials
and show test results, Mobile Network Operators (MNOs)' 5G Standalone (SA)
network and Multi-access Edge Computing (MEC) infrastructure are used to
provide connectivity and edge computing resources to a vehicle equipped with a
5G modem.
</p>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07395" title="Abstract">arXiv:2311.07395</a> [<a href="/pdf/2311.07395" title="Download PDF">pdf</a>, <a href="/ps/2311.07395" title="Download PostScript">ps</a>, <a href="/format/2311.07395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Continuous Locomotion Modes via Multidimensional Feature  Learning from sEMG
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+P">Peiwen Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+W">Wenjuan Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+W">Wenxuan Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yuzhou Lin</a>, 
<a href="/search/cs?searchtype=author&query=Tai%2C+Y">Yanlong Tai</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+L">Lin Meng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingming Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages,7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Walking-assistive devices require adaptive control methods to ensure smooth
transitions between various modes of locomotion. For this purpose, detecting
human locomotion modes (e.g., level walking or stair ascent) in advance is
crucial for improving the intelligence and transparency of such robotic
systems. This study proposes Deep-STF, a unified end-to-end deep learning model
designed for integrated feature extraction in spatial, temporal, and frequency
dimensions from surface electromyography (sEMG) signals. Our model enables
accurate and robust continuous prediction of nine locomotion modes and 15
transitions at varying prediction time intervals, ranging from 100 to 500 ms.
In addition, we introduced the concept of 'stable prediction time' as a
distinct metric to quantify prediction efficiency. This term refers to the
duration during which consistent and accurate predictions of mode transitions
are made, measured from the time of the fifth correct prediction to the
occurrence of the critical event leading to the task transition. This
distinction between stable prediction time and prediction time is vital as it
underscores our focus on the precision and reliability of mode transition
predictions. Experimental results showcased Deep-STP's cutting-edge prediction
performance across diverse locomotion modes and transitions, relying solely on
sEMG data. When forecasting 100 ms ahead, Deep-STF surpassed CNN and other
machine learning techniques, achieving an outstanding average prediction
accuracy of 96.48%. Even with an extended 500 ms prediction horizon, accuracy
only marginally decreased to 93.00%. The averaged stable prediction times for
detecting next upcoming transitions spanned from 28.15 to 372.21 ms across the
100-500 ms time advances.
</p>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07396" title="Abstract">arXiv:2311.07396</a> [<a href="/pdf/2311.07396" title="Download PDF">pdf</a>, <a href="/ps/2311.07396" title="Download PostScript">ps</a>, <a href="/format/2311.07396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Values in Museum Artifacts in the SPICE project: a Preliminary  Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kadastik%2C+N">Nele Kadastik</a>, 
<a href="/search/cs?searchtype=author&query=Pederson%2C+T+A">Thomas A. Pederson</a>, 
<a href="/search/cs?searchtype=author&query=Bruni%2C+L+E">Luis Emilio Bruni</a>, 
<a href="/search/cs?searchtype=author&query=Damiano%2C+R">Rossana Damiano</a>, 
<a href="/search/cs?searchtype=author&query=Lieto%2C+A">Antonio Lieto</a>, 
<a href="/search/cs?searchtype=author&query=Striani%2C+M">Manuel Striani</a>, 
<a href="/search/cs?searchtype=author&query=Kuflik%2C+T">Tsvi Kuflik</a>, 
<a href="/search/cs?searchtype=author&query=Wecker%2C+A">Alan Wecker</a>, 
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">This document describes the rationale, the implementation and a preliminary
evaluation of a semantic reasoning tool developed in the EU H2020 SPICE project
to enhance the diversity of perspectives experienced by museum visitors. The
tool, called DEGARI 2.0 for values, relies on the commonsense reasoning
framework TCL, and exploits an ontological model formalizingthe Haidt's theory
of moral values to associate museum items with combined values and emotions.
Within a museum exhibition, this tool can suggest cultural items that are
associated not only with the values of already experienced or preferred
objects, but also with novel items with different value stances, opening the
visit experience to more inclusive interpretations of cultural content. The
system has been preliminarily tested, in the context of the SPICE project, on
the collection of the Hecht Museum of Haifa.
</p>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07397" title="Abstract">arXiv:2311.07397</a> [<a href="/pdf/2311.07397" title="Download PDF">pdf</a>, <a href="/format/2311.07397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An LLM-free Multi-dimensional Benchmark for MLLMs Hallucination  Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuhang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Guohai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yukai Gu</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+H">Haitao Jia</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+M">Ming Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Ji Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sang%2C+J">Jitao Sang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Despite making significant progress in multi-modal tasks, current Multi-modal
Large Language Models (MLLMs) encounter the significant challenge of
hallucination, which may lead to harmful consequences. Therefore, evaluating
MLLMs' hallucinations is becoming increasingly important in model improvement
and practical application deployment. Previous works are limited in high
evaluation costs (e.g., relying on humans or advanced LLMs) and insufficient
evaluation dimensions (e.g., types of hallucination and task). In this paper,
we propose an LLM-free multi-dimensional benchmark AMBER, which can be used to
evaluate both generative task and discriminative task including object
existence, object attribute and object relation hallucination. Based on AMBER,
we design a low-cost and efficient evaluation pipeline. Additionally, we
conduct a comprehensive evaluation and detailed analysis of mainstream MLLMs
including GPT-4V(ision), and also give guideline suggestions for mitigating
hallucinations. The data and code of AMBER are available at
https://github.com/junyangwang0410/AMBER.
</p>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07398" title="Abstract">arXiv:2311.07398</a> [<a href="/pdf/2311.07398" title="Download PDF">pdf</a>, <a href="/format/2311.07398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Processing and Segmentation of Human Teeth from 2D Images using Weakly  Supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kunzo%2C+T">Tom&#xe1;&#x161; Kunzo</a>, 
<a href="/search/cs?searchtype=author&query=Kocur%2C+V">Viktor Kocur</a>, 
<a href="/search/cs?searchtype=author&query=Gajdo%C5%A1ech%2C+L">Luk&#xe1;&#x161; Gajdo&#x161;ech</a>, 
<a href="/search/cs?searchtype=author&query=Madaras%2C+M">Martin Madaras</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pubslished in 2023 World Symposium on Digital Intelligence for Systems and Machines (DISA) Proceedings. Published version copyrighted by IEEE, pre-print released in accordance with the copyright agreement
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Teeth segmentation is an essential task in dental image analysis for accurate
diagnosis and treatment planning. While supervised deep learning methods can be
utilized for teeth segmentation, they often require extensive manual annotation
of segmentation masks, which is time-consuming and costly. In this research, we
propose a weakly supervised approach for teeth segmentation that reduces the
need for manual annotation. Our method utilizes the output heatmaps and
intermediate feature maps from a keypoint detection network to guide the
segmentation process. We introduce the TriDental dataset, consisting of 3000
oral cavity images annotated with teeth keypoints, to train a teeth keypoint
detection network. We combine feature maps from different layers of the
keypoint detection network, enabling accurate teeth segmentation without
explicit segmentation annotations. The detected keypoints are also used for
further refinement of the segmentation masks. Experimental results on the
TriDental dataset demonstrate the superiority of our approach in terms of
accuracy and robustness compared to state-of-the-art segmentation methods. Our
method offers a cost-effective and efficient solution for teeth segmentation in
real-world dental applications, eliminating the need for extensive manual
annotation efforts.
</p>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07399" title="Abstract">arXiv:2311.07399</a> [<a href="/pdf/2311.07399" title="Download PDF">pdf</a>, <a href="/format/2311.07399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-Aware Adaptive Prefetching for DASH Streaming over 5G Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Uriol%2C+J">Juncal Uriol</a>, 
<a href="/search/cs?searchtype=author&query=Yeregui%2C+I">Inhar Yeregui</a>, 
<a href="/search/cs?searchtype=author&query=Gabilondo%2C+A">Alvaro Gabilondo</a>, 
<a href="/search/cs?searchtype=author&query=Viola%2C+R">Roberto Viola</a>, 
<a href="/search/cs?searchtype=author&query=Angueira%2C+P">Pablo Angueira</a>, 
<a href="/search/cs?searchtype=author&query=Montalban%2C+J">Jon Montalban</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE International Symposium on Broadband Multimedia Systems
  and Broadcasting (BMSB), 2023, pp. 1-6
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">The increasing consumption of video streams and the demand for higher-quality
content drive the evolution of telecommunication networks and the development
of new network accelerators to boost media delivery while optimizing network
usage. Multi-access Edge Computing (MEC) enables the possibility to enforce
media delivery by deploying caching instances at the network edge, close to the
Radio Access Network (RAN). Thus, the content can be prefetched and served from
the MEC host, reducing network traffic and increasing the Quality of Service
(QoS) and the Quality of Experience (QoE). This paper proposes a novel
mechanism to prefetch Dynamic Adaptive Streaming over HTTP (DASH) streams at
the MEC, employing a Machine Learning (ML) classification model to select the
media segments to prefetch. The model is trained with media session metrics to
improve the forecasts with application layer information. The proposal is
tested with Mobile Network Operators (MNOs)' 5G MEC and RAN and compared with
other strategies by assessing cache and player's performance metrics.
</p>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07407" title="Abstract">arXiv:2311.07407</a> [<a href="/pdf/2311.07407" title="Download PDF">pdf</a>, <a href="/format/2311.07407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Automatic Honey Bee Flower-Patch Assays with Paint Marking  Re-Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meyers%2C+L">Luke Meyers</a>, 
<a href="/search/cs?searchtype=author&query=Cordero%2C+J+R">Josu&#xe9; Rodr&#xed;guez Cordero</a>, 
<a href="/search/cs?searchtype=author&query=Bravo%2C+C+C">Carlos Corrada Bravo</a>, 
<a href="/search/cs?searchtype=author&query=Noel%2C+F">Fanfan Noel</a>, 
<a href="/search/cs?searchtype=author&query=Agosto-Rivera%2C+J">Jos&#xe9; Agosto-Rivera</a>, 
<a href="/search/cs?searchtype=author&query=Giray%2C+T">Tugrul Giray</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%A9gret%2C+R">R&#xe9;mi M&#xe9;gret</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper 17, workshop "CV4Animals: Computer Vision for Animal Behavior Tracking and Modeling", in conjunction with Computer Vision and Pattern Recognition (CVPR 2023), June 18, 2023, Vancouver, Canada
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we show that paint markings are a feasible approach to
automatize the analysis of behavioral assays involving honey bees in the field
where marking has to be as lightweight as possible. We contribute a novel
dataset for bees re-identification with paint-markings with 4392 images and 27
identities. Contrastive learning with a ResNet backbone and triplet loss led to
identity representation features with almost perfect recognition in closed
setting where identities are known in advance. Diverse experiments evaluate the
capability to generalize to separate IDs, and show the impact of using
different body parts for identification, such as using the unmarked abdomen
only. In addition, we show the potential to fully automate the visit detection
and provide preliminary results of compute time for future real-time deployment
in the field on an edge device.
</p>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07410" title="Abstract">arXiv:2311.07410</a> [<a href="/pdf/2311.07410" title="Download PDF">pdf</a>, <a href="/format/2311.07410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Optimal Psychological Functioning in AI-driven Software  Engineering Tasks: The SEWELL-CARE Assessment Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sghaier%2C+O+B">Oussama Ben Sghaier</a>, 
<a href="/search/cs?searchtype=author&query=Boudrias%2C+J">Jean-Sebastien Boudrias</a>, 
<a href="/search/cs?searchtype=author&query=Sahraoui%2C+H">Houari Sahraoui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">In the field of software engineering, there has been a shift towards
utilizing various artificial intelligence techniques to address challenges and
create innovative tools. These solutions are aimed at enhancing efficiency,
automating tasks, and providing valuable support to developers. While the
technical aspects are crucial, the well-being and psychology of the individuals
performing these tasks are often overlooked. This paper argues that a holistic
approach is essential, one that considers the technical, psychological, and
social aspects of software engineering tasks. To address this gap, we introduce
SEWELL-CARE, a conceptual framework designed to assess AI-driven software
engineering tasks from multiple perspectives, with the goal of customizing the
tools to improve the efficiency, well-being, and psychological functioning of
developers. By emphasizing both technical and human dimensions, our framework
provides a nuanced evaluation that goes beyond traditional technical metrics.
</p>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07414" title="Abstract">arXiv:2311.07414</a> [<a href="/pdf/2311.07414" title="Download PDF">pdf</a>, <a href="/format/2311.07414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FIRST: A Million-Entry Dataset for Text-Driven Fashion Synthesis and  Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yihao Li</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+D">Dong Pei</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiapeng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+X">Xuliang Ning</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jianlin Han</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiaoguang Han</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuejun Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-driven fashion synthesis and design is an extremely valuable part of
artificial intelligence generative content(AIGC), which has the potential to
propel a tremendous revolution in the traditional fashion industry. To advance
the research on text-driven fashion synthesis and design, we introduce a new
dataset comprising a million high-resolution fashion images with rich
structured textual(FIRST) descriptions. In the FIRST, there is a wide range of
attire categories and each image-paired textual description is organized at
multiple hierarchical levels. Experiments on prevalent generative models
trained over FISRT show the necessity of FIRST. We invite the community to
further develop more intelligent fashion synthesis and design systems that make
fashion design more creative and imaginative based on our dataset. The dataset
will be released soon.
</p>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07415" title="Abstract">arXiv:2311.07415</a> [<a href="/pdf/2311.07415" title="Download PDF">pdf</a>, <a href="/ps/2311.07415" title="Download PostScript">ps</a>, <a href="/format/2311.07415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially Private Approximate Pattern Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Steiner%2C+T+A">Teresa Anna Steiner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a full version of a paper accepted to ITCS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">In this paper, we consider the $k$-approximate pattern matching problem under
differential privacy, where the goal is to report or count all substrings of a
given string $S$ which have a Hamming distance at most $k$ to a pattern $P$, or
decide whether such a substring exists. In our definition of privacy,
individual positions of the string $S$ are protected. To be able to answer
queries under differential privacy, we allow some slack on $k$, i.e. we allow
reporting or counting substrings of $S$ with a distance at most
$(1+\gamma)k+\alpha$ to $P$, for a multiplicative error $\gamma$ and an
additive error $\alpha$. We analyze which values of $\alpha$ and $\gamma$ are
necessary or sufficient to solve the $k$-approximate pattern matching problem
while satisfying $\epsilon$-differential privacy. Let $n$ denote the length of
$S$. We give 1) an $\epsilon$-differentially private algorithm with an additive
error of $O(\epsilon^{-1}\log n)$ and no multiplicative error for the existence
variant; 2) an $\epsilon$-differentially private algorithm with an additive
error $O(\epsilon^{-1}\max(k,\log n)\cdot\log n)$ for the counting variant; 3)
an $\epsilon$-differentially private algorithm with an additive error of
$O(\epsilon^{-1}\log n)$ and multiplicative error $O(1)$ for the reporting
variant for a special class of patterns. The error bounds hold with high
probability. All of these algorithms return a witness, that is, if there exists
a substring of $S$ with distance at most $k$ to $P$, then the algorithm returns
a substring of $S$ with distance at most $(1+\gamma)k+\alpha$ to $P$. Further,
we complement these results by a lower bound, showing that any algorithm for
the existence variant which also returns a witness must have an additive error
of $\Omega(\epsilon^{-1}\log n)$ with constant probability.
</p>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07417" title="Abstract">arXiv:2311.07417</a> [<a href="/pdf/2311.07417" title="Download PDF">pdf</a>, <a href="/ps/2311.07417" title="Download PostScript">ps</a>, <a href="/format/2311.07417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Backdoors within Deep Neural Networks in Data-limited  Configuration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hashemifar%2C+S">Soroush Hashemifar</a>, 
<a href="/search/cs?searchtype=author&query=Parsa%2C+S">Saeed Parsa</a>, 
<a href="/search/cs?searchtype=author&query=Zakeri-Nasrabadi%2C+M">Morteza Zakeri-Nasrabadi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">As the capacity of deep neural networks (DNNs) increases, their need for huge
amounts of data significantly grows. A common practice is to outsource the
training process or collect more data over the Internet, which introduces the
risks of a backdoored DNN. A backdoored DNN shows normal behavior on clean data
while behaving maliciously once a trigger is injected into a sample at the test
time. In such cases, the defender faces multiple difficulties. First, the
available clean dataset may not be sufficient for fine-tuning and recovering
the backdoored DNN. Second, it is impossible to recover the trigger in many
real-world applications without information about it. In this paper, we
formulate some characteristics of poisoned neurons. This backdoor
suspiciousness score can rank network neurons according to their activation
values, weights, and their relationship with other neurons in the same layer.
Our experiments indicate the proposed method decreases the chance of attacks
being successful by more than 50% with a tiny clean dataset, i.e., ten clean
samples for the CIFAR-10 dataset, without significantly deteriorating the
model's performance. Moreover, the proposed method runs three times as fast as
baselines.
</p>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07418" title="Abstract">arXiv:2311.07418</a> [<a href="/pdf/2311.07418" title="Download PDF">pdf</a>, <a href="/format/2311.07418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speech-based Slot Filling using Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+G">Guangzhi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+S">Shutong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+D">Dongcheng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ga%C5%A1i%C4%87%2C+M">Milica Ga&#x161;i&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Woodland%2C+P+C">Philip C. Woodland</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Recently, advancements in large language models (LLMs) have shown an
unprecedented ability across various language tasks. This paper investigates
the potential application of LLMs to slot filling with noisy ASR
transcriptions, via both in-context learning and task-specific fine-tuning.
Dedicated prompt designs and fine-tuning approaches are proposed to improve the
robustness of LLMs for slot filling with noisy ASR transcriptions. Moreover, a
linearised knowledge injection (LKI) scheme is also proposed to integrate
dynamic external knowledge into LLMs. Experiments were performed on SLURP to
quantify the performance of LLMs, including GPT-3.5-turbo, GPT-4, LLaMA-13B and
Vicuna-13B (v1.1 and v1.5) with different ASR error rates. The use of the
proposed fine-tuning together with the LKI scheme for LLaMA-13B achieved an
8.3% absolute SLU-F1 improvement compared to the strong Flan-T5-base baseline
system on a limited data setup.
</p>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07421" title="Abstract">arXiv:2311.07421</a> [<a href="/pdf/2311.07421" title="Download PDF">pdf</a>, <a href="/format/2311.07421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust semi-supervised segmentation with timestep ensembling diffusion  models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rosnati%2C+M">Margherita Rosnati</a>, 
<a href="/search/cs?searchtype=author&query=Roschewitz%2C+M">Melanie Roschewitz</a>, 
<a href="/search/cs?searchtype=author&query=Glocker%2C+B">Ben Glocker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at Machine Learning for Health (ML4H) 2023, presented at Medical Imaging meets NeurIPS 2023 and Deep Generative Models for Health Workshop NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Medical image segmentation is a challenging task, made more difficult by many
datasets' limited size and annotations. Denoising diffusion probabilistic
models (DDPM) have recently shown promise in modelling the distribution of
natural images and were successfully applied to various medical imaging tasks.
This work focuses on semi-supervised image segmentation using diffusion models,
particularly addressing domain generalisation. Firstly, we demonstrate that
smaller diffusion steps generate latent representations that are more robust
for downstream tasks than larger steps. Secondly, we use this insight to
propose an improved esembling scheme that leverages information-dense small
steps and the regularising effect of larger steps to generate predictions. Our
model shows significantly better performance in domain-shifted settings while
retaining competitive performance in-domain. Overall, this work highlights the
potential of DDPMs for semi-supervised medical image segmentation and provides
insights into optimising their performance under domain shift.
</p>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07422" title="Abstract">arXiv:2311.07422</a> [<a href="/pdf/2311.07422" title="Download PDF">pdf</a>, <a href="/format/2311.07422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sidekick compilation with xDSL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fehr%2C+M">Mathieu Fehr</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+M">Michel Weber</a>, 
<a href="/search/cs?searchtype=author&query=Ulmann%2C+C">Christian Ulmann</a>, 
<a href="/search/cs?searchtype=author&query=Lopoukhine%2C+A">Alexandre Lopoukhine</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%BCcke%2C+M">Martin L&#xfc;cke</a>, 
<a href="/search/cs?searchtype=author&query=Degioanni%2C+T">Th&#xe9;o Degioanni</a>, 
<a href="/search/cs?searchtype=author&query=Steuwer%2C+M">Michel Steuwer</a>, 
<a href="/search/cs?searchtype=author&query=Grosser%2C+T">Tobias Grosser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Traditionally, compiler researchers either conduct experiments within an
existing production compiler or develop their own prototype compiler; both
options come with trade-offs. On one hand, prototyping in a production compiler
can be cumbersome, as they are often optimized for program compilation speed at
the expense of software simplicity and development speed. On the other hand,
the transition from a prototype compiler to production requires significant
engineering work. To bridge this gap, we introduce the concept of sidekick
compiler frameworks, an approach that uses multiple frameworks that
interoperate with each other by leveraging textual interchange formats and
declarative descriptions of abstractions. Each such compiler framework is
specialized for specific use cases, such as performance or prototyping.
Abstractions are by design shared across frameworks, simplifying the transition
from prototyping to production. We demonstrate this idea with xDSL, a sidekick
for MLIR focused on prototyping and teaching. xDSL interoperates with MLIR
through a shared textual IR and the exchange of IRs through an IR Definition
Language. The benefits of sidekick compiler frameworks are evaluated by showing
on three use cases how xDSL impacts their development: teaching, DSL
compilation, and rewrite system prototyping. We also investigate the trade-offs
that xDSL offers, and demonstrate how we simplify the transition between
frameworks using the IRDL dialect. With sidekick compilation, we envision a
future in which engineers minimize the cost of development by choosing a
framework built for their immediate needs, and later transitioning to
production with minimal overhead.
</p>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07424" title="Abstract">arXiv:2311.07424</a> [<a href="/pdf/2311.07424" title="Download PDF">pdf</a>, <a href="/format/2311.07424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hallucination Augmented Recitations for Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=K%C3%B6ksal%2C+A">Abdullatif K&#xf6;ksal</a>, 
<a href="/search/cs?searchtype=author&query=Aksitov%2C+R">Renat Aksitov</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+C">Chung-Ching Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Attribution is a key concept in large language models (LLMs) as it enables
control over information sources and enhances the factuality of LLMs. While
existing approaches utilize open book question answering to improve
attribution, factual datasets may reward language models to recall facts that
they already know from their pretraining data, not attribution. In contrast,
counterfactual open book QA datasets would further improve attribution because
the answer could only be grounded in the given text. We propose Hallucination
Augmented Recitations (HAR) for creating counterfactual datasets by utilizing
hallucination in LLMs to improve attribution. For open book QA as a case study,
we demonstrate that models finetuned with our counterfactual datasets improve
text grounding, leading to better open book QA performance, with up to an 8.0%
increase in F1 score. Our counterfactual dataset leads to significantly better
performance than using humanannotated factual datasets, even with 4x smaller
datasets and 4x smaller models. We observe that improvements are consistent
across various model sizes and datasets, including multi-hop, biomedical, and
adversarial QA datasets.
</p>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07425" title="Abstract">arXiv:2311.07425</a> [<a href="/pdf/2311.07425" title="Download PDF">pdf</a>, <a href="/ps/2311.07425" title="Download PostScript">ps</a>, <a href="/format/2311.07425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recurrence of Nonlinear Control Systems: Entropy and Bit Rates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sibai%2C+H">Hussein Sibai</a>, 
<a href="/search/eess?searchtype=author&query=Mallada%2C+E">Enrique Mallada</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this paper, we introduce the notion of recurrence entropy in the context
of nonlinear control systems. A set is said to be ($\tau$-)recurrent if every
trajectory that starts in the set returns to it (within at most $\tau$ units of
time). Recurrence entropy quantifies the complexity of making a set
$\tau$-recurrent measured by the average rate of growth, as time increases, of
the number of control signals required to achieve this goal. Our analysis
reveals that, compared to invariance, recurrence is quantitatively less
complex, meaning that the recurrence entropy of a set is no larger than, and
often strictly smaller than, the invariance entropy. Our results further offer
insights into the minimum data rate required for achieving recurrence. We also
present an algorithm for achieving recurrence asymptotically.
</p>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07426" title="Abstract">arXiv:2311.07426</a> [<a href="/pdf/2311.07426" title="Download PDF">pdf</a>, <a href="/format/2311.07426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimising Human-AI Collaboration by Learning Convincing Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chan%2C+A+J">Alex J. Chan</a>, 
<a href="/search/cs?searchtype=author&query=Huyuk%2C+A">Alihan Huyuk</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Schaar%2C+M">Mihaela van der Schaar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Machine learning models are being increasingly deployed to take, or assist in
taking, complicated and high-impact decisions, from quasi-autonomous vehicles
to clinical decision support systems. This poses challenges, particularly when
models have hard-to-detect failure modes and are able to take actions without
oversight. In order to handle this challenge, we propose a method for a
collaborative system that remains safe by having a human ultimately making
decisions, while giving the model the best opportunity to convince and debate
them with interpretable explanations. However, the most helpful explanation
varies among individuals and may be inconsistent across stated preferences. To
this end we develop an algorithm, Ardent, to efficiently learn a ranking
through interaction and best assist humans complete a task. By utilising a
collaborative approach, we can ensure safety and improve performance while
addressing transparency and accountability concerns. Ardent enables efficient
and effective decision-making by adapting to individual preferences for
explanations, which we validate through extensive simulations alongside a user
study involving a challenging image classification task, demonstrating
consistent improvement over competing systems.
</p>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07427" title="Abstract">arXiv:2311.07427</a> [<a href="/pdf/2311.07427" title="Download PDF">pdf</a>, <a href="/format/2311.07427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boolean Variation and Boolean Logic BackPropagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V+M">Van Minh Nguyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Discrete Mathematics (cs.DM); Logic in Computer Science (cs.LO); Optimization and Control (math.OC)

</div>
<p class="mathjax">The notion of variation is introduced for the Boolean set and based on which
Boolean logic backpropagation principle is developed. Using this concept, deep
models can be built with weights and activations being Boolean numbers and
operated with Boolean logic instead of real arithmetic. In particular, Boolean
deep models can be trained directly in the Boolean domain without latent
weights. No gradient but logic is synthesized and backpropagated through
layers.
</p>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07430" title="Abstract">arXiv:2311.07430</a> [<a href="/pdf/2311.07430" title="Download PDF">pdf</a>, <a href="/format/2311.07430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controlled Text Generation for Black-box Language Models via Score-based  Progressive Editor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Sangwon Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Changmin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hojin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+S">Sungroh Yoon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Despite recent progress in language models, generating constrained text for
specific domains remains a challenge, particularly when utilizing black-box
models that lack domain-specific knowledge. In this paper, we introduce ScoPE
(Score-based Progressive Editor) generation, a novel approach for controlled
text generation for black-box language models. We employ ScoPE to facilitate
text generation in the target domain by integrating it with language models
through a cascading approach. Trained to enhance the target domain score of the
edited text, ScoPE progressively edits intermediate output discrete tokens to
align with the target attributes throughout the auto-regressive generation
process of the language model. This iterative process guides subsequent steps
to produce desired output texts for the target domain. Our experimental results
on diverse controlled generations demonstrate that ScoPE effectively
facilitates controlled text generation for black-box language models in both
in-domain and out-of-domain conditions, which is challenging for existing
methods.
</p>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07432" title="Abstract">arXiv:2311.07432</a> [<a href="/pdf/2311.07432" title="Download PDF">pdf</a>, <a href="/format/2311.07432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Supersampling of Data from Structured-light Scanner with Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Melicher%C4%8D%C3%ADk%2C+M">Martin Melicher&#x10d;&#xed;k</a>, 
<a href="/search/cs?searchtype=author&query=Gajdo%C5%A1ech%2C+L">Luk&#xe1;&#x161; Gajdo&#x161;ech</a>, 
<a href="/search/cs?searchtype=author&query=Kocur%2C+V">Viktor Kocur</a>, 
<a href="/search/cs?searchtype=author&query=Madaras%2C+M">Martin Madaras</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pubslished in 2023 World Symposium on Digital Intelligence for Systems and Machines (DISA) Proceedings. Published version copyrighted by IEEE, pre-print released in accordance with the copyright agreement
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper focuses on increasing the resolution of depth maps obtained from
3D cameras using structured light technology. Two deep learning models FDSR and
DKN are modified to work with high-resolution data, and data pre-processing
techniques are implemented for stable training. The models are trained on our
custom dataset of 1200 3D scans. The resulting high-resolution depth maps are
evaluated using qualitative and quantitative metrics. The approach for depth
map upsampling offers benefits such as reducing the processing time of a
pipeline by first downsampling a high-resolution depth map, performing various
processing steps at the lower resolution and upsampling the resulting depth map
or increasing the resolution of a point cloud captured in lower resolution by a
cheaper device. The experiments demonstrate that the FDSR model excels in terms
of faster processing time, making it a suitable choice for applications where
speed is crucial. On the other hand, the DKN model provides results with higher
precision, making it more suitable for applications that prioritize accuracy.
</p>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07434" title="Abstract">arXiv:2311.07434</a> [<a href="/pdf/2311.07434" title="Download PDF">pdf</a>, <a href="/format/2311.07434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Users&#x27; Dissatisfaction with ChatGPT Responses: Types,  Resolving Tactics, and the Effect of Knowledge Level
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yoonsu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jueon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seoyoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jaehyuk Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Juho Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Large language models (LLMs) with chat-based capabilities, such as ChatGPT,
are widely used in various workflows. However, due to a limited understanding
of these large-scale models, users struggle to use this technology and
experience different kinds of dissatisfaction. Researchers have introduced
several methods such as prompt engineering to improve model responses. However,
they focus on crafting one prompt, and little has been investigated on how to
deal with the dissatisfaction the user encountered during the conversation.
Therefore, with ChatGPT as the case study, we examine end users'
dissatisfaction along with their strategies to address the dissatisfaction.
After organizing users' dissatisfaction with LLM into seven categories based on
a literature review, we collected 511 instances of dissatisfactory ChatGPT
responses from 107 users and their detailed recollections of dissatisfied
experiences, which we release as a publicly accessible dataset. Our analysis
reveals that users most frequently experience dissatisfaction when ChatGPT
fails to grasp their intentions, while they rate the severity of
dissatisfaction the highest with dissatisfaction related to accuracy. We also
identified four tactics users employ to address their dissatisfaction and their
effectiveness. We found that users often do not use any tactics to address
their dissatisfaction, and even when using tactics, 72% of dissatisfaction
remained unresolved. Moreover, we found that users with low knowledge regarding
LLMs tend to face more dissatisfaction on accuracy while they often put minimal
effort in addressing dissatisfaction. Based on these findings, we propose
design implications for minimizing user dissatisfaction and enhancing the
usability of chat-based LLM services.
</p>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07435" title="Abstract">arXiv:2311.07435</a> [<a href="/pdf/2311.07435" title="Download PDF">pdf</a>, <a href="/format/2311.07435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trajectories and Platoon-forming Algorithm for Intersections with  Heterogeneous Autonomous Traffic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Joshi%2C+P+C">P. C. Joshi</a>, 
<a href="/search/eess?searchtype=author&query=Boon%2C+M+A+A">M. A. A. Boon</a>, 
<a href="/search/eess?searchtype=author&query=Borst%2C+S+C">S. C. Borst</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 43 pages, 20 figures. 3D Animations included as ancillary files
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC); Probability (math.PR)

</div>
<p class="mathjax">The anticipated launch of fully autonomous vehicles presents an opportunity
to develop and implement novel traffic management systems. Intersections are
one of the bottlenecks for urban traffic, and thus offer tremendous potential
for performance improvements of traffic flow if managed efficiently.
Platoon-forming algorithms, in which vehicles are grouped together with short
inter-vehicular distances just before arriving at an intersection at high
speed, seem particularly promising in this aspect. In this work, we present an
intersection access control system based on platoon-forming for heterogeneous
autonomous traffic. The heterogeneity of traffic arises from vehicles with
different acceleration capabilities and safety constraints. We focus on
obtaining computationally fast and interpretable closed-form expressions for
safe and efficient vehicle trajectories that lead to platoon formation, and
show that these trajectories are solutions to certain classes of optimisation
problems. Additionally, we conduct a numerical study to obtain approximations
for intersection capacity as a result of such platoon formation.
</p>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07438" title="Abstract">arXiv:2311.07438</a> [<a href="/pdf/2311.07438" title="Download PDF">pdf</a>, <a href="/format/2311.07438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hardest Monotone Functions for Evolutionary Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaufmann%2C+M">Marc Kaufmann</a>, 
<a href="/search/cs?searchtype=author&query=Larcher%2C+M">Maxime Larcher</a>, 
<a href="/search/cs?searchtype=author&query=Lengler%2C+J">Johannes Lengler</a>, 
<a href="/search/cs?searchtype=author&query=Sieberling%2C+O">Oliver Sieberling</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Probability (math.PR)

</div>
<p class="mathjax">The study of hardest and easiest fitness landscapes is an active area of
research. Recently, Kaufmann, Larcher, Lengler and Zou conjectured that for the
self-adjusting $(1,\lambda)$-EA, Adversarial Dynamic BinVal (ADBV) is the
hardest dynamic monotone function to optimize. We introduce the function
Switching Dynamic BinVal (SDBV) which coincides with ADBV whenever the number
of remaining zeros in the search point is strictly less than $n/2$, where $n$
denotes the dimension of the search space. We show, using a combinatorial
argument, that for the $(1+1)$-EA with any mutation rate $p \in [0,1]$, SDBV is
drift-minimizing among the class of dynamic monotone functions. Our
construction provides the first explicit example of an instance of the
partially-ordered evolutionary algorithm (PO-EA) model with parameterized
pessimism introduced by Colin, Doerr and F\'erey, building on work of Jansen.
We further show that the $(1+1)$-EA optimizes SDBV in $\Theta(n^{3/2})$
generations. Our simulations demonstrate matching runtimes for both static and
self-adjusting $(1,\lambda)$ and $(1+\lambda)$-EA. We further show, using an
example of fixed dimension, that drift-minimization does not equal maximal
runtime.
</p>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07439" title="Abstract">arXiv:2311.07439</a> [<a href="/pdf/2311.07439" title="Download PDF">pdf</a>, <a href="/format/2311.07439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating Multi-Pivot Ensembling with Massively Multilingual Machine  Translation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohammadshahi%2C+A">Alireza Mohammadshahi</a>, 
<a href="/search/cs?searchtype=author&query=Vamvas%2C+J">Jannis Vamvas</a>, 
<a href="/search/cs?searchtype=author&query=Sennrich%2C+R">Rico Sennrich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Massively multilingual machine translation models allow for the translation
of a large number of languages with a single model, but have limited
performance on low- and very-low-resource translation directions. Pivoting via
high-resource languages remains a strong strategy for low-resource directions,
and in this paper we revisit ways of pivoting through multiple languages.
Previous work has used a simple averaging of probability distributions from
multiple paths, but we find that this performs worse than using a single pivot,
and exacerbates the hallucination problem because the same hallucinations can
be probable across different paths. As an alternative, we propose MaxEns, a
combination strategy that is biased towards the most confident predictions,
hypothesising that confident predictions are less prone to be hallucinations.
We evaluate different strategies on the FLORES benchmark for 20 low-resource
language directions, demonstrating that MaxEns improves translation quality for
low-resource languages while reducing hallucination in translations, compared
to both direct translation and an averaging approach. On average, multi-pivot
strategies still lag behind using English as a single pivot language, raising
the question of how to identify the best pivoting strategy for a given
translation direction.
</p>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07440" title="Abstract">arXiv:2311.07440</a> [<a href="/pdf/2311.07440" title="Download PDF">pdf</a>, <a href="/ps/2311.07440" title="Download PostScript">ps</a>, <a href="/format/2311.07440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal finite element approximation of unique continuation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Burman%2C+E">Erik Burman</a>, 
<a href="/search/math?searchtype=author&query=Nechita%2C+M">Mihai Nechita</a>, 
<a href="/search/math?searchtype=author&query=Oksanen%2C+L">Lauri Oksanen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">We consider finite element approximations of ill-posed elliptic problems with
conditional stability. The notion of {\emph{optimal error estimates}} is
defined including both convergence with respect to mesh parameter and
perturbations in data. The rate of convergence is determined by the conditional
stability of the underlying continuous problem and the polynomial order of the
finite element approximation space. A proof is given that no finite element
approximation can converge at a better rate than that given by the definition,
justifying the concept. A recently introduced class of finite element methods
with weakly consistent regularisation is recalled and the associated error
estimates are shown to be quasi optimal in the sense of our definition.
</p>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07444" title="Abstract">arXiv:2311.07444</a> [<a href="/pdf/2311.07444" title="Download PDF">pdf</a>, <a href="/format/2311.07444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Robustness of Neural Collapse and the Neural Collapse of  Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+J">Jingtong Su</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y+S">Ya Shi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tsilivis%2C+N">Nikolaos Tsilivis</a>, 
<a href="/search/cs?searchtype=author&query=Kempe%2C+J">Julia Kempe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Neural Collapse refers to the curious phenomenon in the end of training of a
neural network, where feature vectors and classification weights converge to a
very simple geometrical arrangement (a simplex). While it has been observed
empirically in various cases and has been theoretically motivated, its
connection with crucial properties of neural networks, like their
generalization and robustness, remains unclear. In this work, we study the
stability properties of these simplices. We find that the simplex structure
disappears under small adversarial attacks, and that perturbed examples "leap"
between simplex vertices. We further analyze the geometry of networks that are
optimized to be robust against adversarial perturbations of the input, and find
that Neural Collapse is a pervasive phenomenon in these cases as well, with
clean and perturbed representations forming aligned simplices, and giving rise
to a robust simple nearest-neighbor classifier. By studying the propagation of
the amount of collapse inside the network, we identify novel properties of both
robust and non-robust machine learning models, and show that earlier, unlike
later layers maintain reliable simplices on perturbed data.
</p>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07445" title="Abstract">arXiv:2311.07445</a> [<a href="/pdf/2311.07445" title="Download PDF">pdf</a>, <a href="/format/2311.07445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Think Before You Speak: Cultivating Communication Skills of Large  Language Models via Inner Monologue
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Junkai Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+L">Liang Pang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Huawei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xueqi Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The emergence of large language models (LLMs) further improves the
capabilities of open-domain dialogue systems and can generate fluent, coherent,
and diverse responses. However, LLMs still lack an important ability:
communication skills, which makes them more like information seeking tools than
anthropomorphic chatbots. To make LLMs more anthropomorphic and proactive
during the conversation, we add five communication skills to the response
generation process: topic transition, proactively asking questions, concept
guidance, empathy, and summarising often. The addition of communication skills
increases the interest of users in the conversation and attracts them to chat
for longer. To enable LLMs better understand and use communication skills, we
design and add the inner monologue to LLMs. The complete process is achieved
through prompt engineering and in-context learning. To evaluate communication
skills, we construct a benchmark named Cskills for evaluating various
communication skills, which can also more comprehensively evaluate the dialogue
generation ability of the model. Experimental results show that the proposed
CSIM strategy improves the backbone models and outperforms the baselines in
both automatic and human evaluations.
</p>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07446" title="Abstract">arXiv:2311.07446</a> [<a href="/pdf/2311.07446" title="Download PDF">pdf</a>, <a href="/format/2311.07446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Story-to-Motion: Synthesizing Infinite and Controllable Character  Animation from Long Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qing%2C+Z">Zhongfei Qing</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zhongang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhitao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lei Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Generating natural human motion from a story has the potential to transform
the landscape of animation, gaming, and film industries. A new and challenging
task, Story-to-Motion, arises when characters are required to move to various
locations and perform specific motions based on a long text description. This
task demands a fusion of low-level control (trajectories) and high-level
control (motion semantics). Previous works in character control and
text-to-motion have addressed related aspects, yet a comprehensive solution
remains elusive: character control methods do not handle text description,
whereas text-to-motion methods lack position constraints and often produce
unstable motions. In light of these limitations, we propose a novel system that
generates controllable, infinitely long motions and trajectories aligned with
the input text. (1) We leverage contemporary Large Language Models to act as a
text-driven motion scheduler to extract a series of (text, position, duration)
pairs from long text. (2) We develop a text-driven motion retrieval scheme that
incorporates motion matching with motion semantic and trajectory constraints.
(3) We design a progressive mask transformer that addresses common artifacts in
the transition motion such as unnatural pose and foot sliding. Beyond its
pioneering role as the first comprehensive solution for Story-to-Motion, our
system undergoes evaluation across three distinct sub-tasks: trajectory
following, temporal action composition, and motion blending, where it
outperforms previous state-of-the-art motion synthesis methods across the
board. Homepage: https://story2motion.github.io/.
</p>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07449" title="Abstract">arXiv:2311.07449</a> [<a href="/pdf/2311.07449" title="Download PDF">pdf</a>, <a href="/format/2311.07449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Grounded QFormer for Efficient Vision Language Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choraria%2C+M">Moulik Choraria</a>, 
<a href="/search/cs?searchtype=author&query=Sekhar%2C+N">Nitesh Sekhar</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Singhal%2C+P">Prateek Singhal</a>, 
<a href="/search/cs?searchtype=author&query=Varshney%2C+L+R">Lav R. Varshney</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large-scale pretraining and instruction tuning have been successful for
training general-purpose language models with broad competencies. However,
extending to general-purpose vision-language models is challenging due to the
distributional diversity in visual inputs. A recent line of work explores
vision-language instruction tuning, taking inspiration from the Query
Transformer (QFormer) approach proposed in BLIP-2 models for bridging frozen
modalities. However, these approaches rely heavily on large-scale multi-modal
pretraining for representation learning before eventual finetuning, incurring a
huge computational overhead, poor scaling, and limited accessibility. To that
end, we propose a more efficient method for QFormer-based vision-language
alignment and demonstrate the effectiveness of our strategy compared to
existing baselines in improving the efficiency of vision-language pretraining.
</p>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07453" title="Abstract">arXiv:2311.07453</a> [<a href="/pdf/2311.07453" title="Download PDF">pdf</a>, <a href="/format/2311.07453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChartCheck: An Evidence-Based Fact-Checking Dataset over Real-World  Chart Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akhtar%2C+M">Mubashara Akhtar</a>, 
<a href="/search/cs?searchtype=author&query=Subedi%2C+N">Nikesh Subedi</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+V">Vivek Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Tahmasebi%2C+S">Sahar Tahmasebi</a>, 
<a href="/search/cs?searchtype=author&query=Cocarascu%2C+O">Oana Cocarascu</a>, 
<a href="/search/cs?searchtype=author&query=Simperl%2C+E">Elena Simperl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Data visualizations are common in the real-world. We often use them in data
sources such as scientific documents, news articles, textbooks, and social
media to summarize key information in a visual form. Charts can also mislead
its audience by communicating false information or biasing them towards a
specific agenda. Verifying claims against charts is not a straightforward
process. It requires analyzing both the text and visual components of the
chart, considering characteristics such as colors, positions, and orientations.
Moreover, to determine if a claim is supported by the chart content often
requires different types of reasoning. To address this challenge, we introduce
ChartCheck, a novel dataset for fact-checking against chart images. ChartCheck
is the first large-scale dataset with 1.7k real-world charts and 10.5k
human-written claims and explanations. We evaluated the dataset on
state-of-the-art models and achieved an accuracy of 73.9 in the finetuned
setting. Additionally, we identified chart characteristics and reasoning types
that challenge the models.
</p>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07454" title="Abstract">arXiv:2311.07454</a> [<a href="/pdf/2311.07454" title="Download PDF">pdf</a>, <a href="/format/2311.07454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Discovery under Latent Class Confounding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mazaheri%2C+B">Bijan Mazaheri</a>, 
<a href="/search/cs?searchtype=author&query=Gordon%2C+S">Spencer Gordon</a>, 
<a href="/search/cs?searchtype=author&query=Rabani%2C+Y">Yuval Rabani</a>, 
<a href="/search/cs?searchtype=author&query=Schulman%2C+L">Leonard Schulman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Complexity (cs.CC); Statistics Theory (math.ST)

</div>
<p class="mathjax">Directed acyclic graphs are used to model the causal structure of a system.
``Causal discovery'' describes the problem of learning this structure from
data. When data is an aggregate from multiple sources (populations or
environments), global confounding obscures conditional independence properties
that drive many causal discovery algorithms. For this reason, existing causal
discovery algorithms are not suitable for the multiple-source setting. We
demonstrate that, if the confounding is of bounded cardinality (i.e. the data
comes from a limited number of sources), causal discovery can still be
achieved. The feasibility of this problem is governed by a trade-off between
the cardinality of the global confounder, the cardinalities of the observed
variables, and the sparsity of the causal structure.
</p>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07458" title="Abstract">arXiv:2311.07458</a> [<a href="/pdf/2311.07458" title="Download PDF">pdf</a>, <a href="/ps/2311.07458" title="Download PostScript">ps</a>, <a href="/format/2311.07458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trust in Queer Human-Robot Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Korpan%2C+R">Raj Korpan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In SCRITA 2023 Workshop Proceedings (<a href="/abs/2311.05401">arXiv:2311.05401</a>) held in conjunction with 32nd IEEE International Conference on Robot &amp; Human Interactive Communication, 28/08 - 31/08 2023, Busan (Korea)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Human-robot interaction (HRI) systems need to build trust with people of
diverse identities. This position paper argues that queer (LGBTQIA+) people
must be included in the design and evaluation of HRI systems to ensure their
trust in and acceptance of robots. Queer people have faced discrimination and
harm from artificial intelligence and robotic systems. Despite calls for
increased diversity and inclusion, HRI has not systemically addressed queer
issues. This paper suggests three approaches to address trust in queer HRI:
diversifying human-subject pools, centering queer people in HRI studies, and
contextualizing measures of trust.
</p>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07460" title="Abstract">arXiv:2311.07460</a> [<a href="/pdf/2311.07460" title="Download PDF">pdf</a>, <a href="/format/2311.07460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KnowSafe: Combined Knowledge and Data Driven Hazard Mitigation in  Artificial Pancreas Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xugui Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Kouzel%2C+M">Maxfield Kouzel</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+C">Chloe Smith</a>, 
<a href="/search/cs?searchtype=author&query=Alemzadeh%2C+H">Homa Alemzadeh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 10 figures, 9 tables, submitted to the IEEE for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">Significant progress has been made in anomaly detection and run-time
monitoring to improve the safety and security of cyber-physical systems (CPS).
However, less attention has been paid to hazard mitigation. This paper proposes
a combined knowledge and data driven approach, KnowSafe, for the design of
safety engines that can predict and mitigate safety hazards resulting from
safety-critical malicious attacks or accidental faults targeting a CPS
controller. We integrate domain-specific knowledge of safety constraints and
context-specific mitigation actions with machine learning (ML) techniques to
estimate system trajectories in the far and near future, infer potential
hazards, and generate optimal corrective actions to keep the system safe.
Experimental evaluation on two realistic closed-loop testbeds for artificial
pancreas systems (APS) and a real-world clinical trial dataset for diabetes
treatment demonstrates that KnowSafe outperforms the state-of-the-art by
achieving higher accuracy in predicting system state trajectories and potential
hazards, a low false positive rate, and no false negatives. It also maintains
the safe operation of the simulated APS despite faults or attacks without
introducing any new hazards, with a hazard mitigation success rate of 92.8%,
which is at least 76% higher than solely rule-based (50.9%) and data-driven
(52.7%) methods.
</p>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07461" title="Abstract">arXiv:2311.07461</a> [<a href="/pdf/2311.07461" title="Download PDF">pdf</a>, <a href="/format/2311.07461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Self-Supervised Dynamic Incremental Regularised Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghobrial%2C+A">Abanoub Ghobrial</a>, 
<a href="/search/cs?searchtype=author&query=Eder%2C+K">Kerstin Eder</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this paper, we overview a recent method for dynamic domain adaptation
named DIRA, which relies on a few samples in addition to a regularisation
approach named elastic weight consolidation to achieve state-of-the-art (SOTA)
domain adaptation results. DIRA has been previously shown to perform
competitively with SOTA unsupervised adaption techniques. However, a limitation
of DIRA is that it relies on labels to be provided for the few samples used in
adaption. This makes it a supervised technique. In this paper, we discuss a
proposed alteration to the DIRA method to make it self-supervised i.e. remove
the need for providing labels. Experiments on our proposed alteration will be
provided in future work.
</p>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07462" title="Abstract">arXiv:2311.07462</a> [<a href="/pdf/2311.07462" title="Download PDF">pdf</a>, <a href="/format/2311.07462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating Robustness in Cyber-Physical Systems:  Specification-Centric Analysis in the face of System Deviations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+C">Changjian Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Kapoor%2C+P">Parv Kapoor</a>, 
<a href="/search/eess?searchtype=author&query=Meira-Goes%2C+R">Romulo Meira-Goes</a>, 
<a href="/search/eess?searchtype=author&query=Garlan%2C+D">David Garlan</a>, 
<a href="/search/eess?searchtype=author&query=Kang%2C+E">Eunsuk Kang</a>, 
<a href="/search/eess?searchtype=author&query=Ganlath%2C+A">Akila Ganlath</a>, 
<a href="/search/eess?searchtype=author&query=Mishra%2C+S">Shatadal Mishra</a>, 
<a href="/search/eess?searchtype=author&query=Ammar%2C+N">Nejib Ammar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Logic in Computer Science (cs.LO); Software Engineering (cs.SE)

</div>
<p class="mathjax">The adoption of cyber-physical systems (CPS) is on the rise in complex
physical environments, encompassing domains such as autonomous vehicles, the
Internet of Things (IoT), and smart cities. A critical attribute of CPS is
robustness, denoting its capacity to operate safely despite potential
disruptions and uncertainties in the operating environment. This paper proposes
a novel specification-based robustness, which characterizes the effectiveness
of a controller in meeting a specified system requirement, articulated through
Signal Temporal Logic (STL) while accounting for possible deviations in the
system. This paper also proposes the robustness falsification problem based on
the definition, which involves identifying minor deviations capable of
violating the specified requirement. We present an innovative two-layer
simulation-based analysis framework designed to identify subtle robustness
violations. To assess our methodology, we devise a series of benchmark problems
wherein system parameters can be adjusted to emulate various forms of
uncertainties and disturbances. Initial evaluations indicate that our
falsification approach proficiently identifies robustness violations, providing
valuable insights for comparing robustness between conventional and
reinforcement learning (RL)-based controllers
</p>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07463" title="Abstract">arXiv:2311.07463</a> [<a href="/pdf/2311.07463" title="Download PDF">pdf</a>, <a href="/format/2311.07463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MEGAVERSE: Benchmarking Large Language Models Across Languages,  Modalities, Models and Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahuja%2C+S">Sanchit Ahuja</a>, 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+D">Divyanshu Aggarwal</a>, 
<a href="/search/cs?searchtype=author&query=Gumma%2C+V">Varun Gumma</a>, 
<a href="/search/cs?searchtype=author&query=Watts%2C+I">Ishaan Watts</a>, 
<a href="/search/cs?searchtype=author&query=Sathe%2C+A">Ashutosh Sathe</a>, 
<a href="/search/cs?searchtype=author&query=Ochieng%2C+M">Millicent Ochieng</a>, 
<a href="/search/cs?searchtype=author&query=Hada%2C+R">Rishav Hada</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+P">Prachi Jain</a>, 
<a href="/search/cs?searchtype=author&query=Axmed%2C+M">Maxamed Axmed</a>, 
<a href="/search/cs?searchtype=author&query=Bali%2C+K">Kalika Bali</a>, 
<a href="/search/cs?searchtype=author&query=Sitaram%2C+S">Sunayana Sitaram</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 30 figures and 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recently, there has been a rapid advancement in research on Large Language
Models (LLMs), resulting in significant progress in several Natural Language
Processing (NLP) tasks. Consequently, there has been a surge in LLM evaluation
research to comprehend the models' capabilities and limitations. However, much
of this research has been confined to the English language, leaving LLM
building and evaluation for non-English languages relatively unexplored. There
has been an introduction of several new LLMs, necessitating their evaluation on
non-English languages. This study aims to expand our MEGA benchmarking suite by
including six new datasets to form the MEGAVERSE benchmark. The benchmark
comprises 22 datasets covering 81 languages, including low-resource African
languages. We evaluate several state-of-the-art LLMs like GPT-3.5-Turbo, GPT4,
PaLM2, and Llama2 on the MEGAVERSE datasets. Additionally, we include two
multimodal datasets in the benchmark and assess the performance of the
LLaVa-v1.5 model. Our experiments suggest that GPT4 and PaLM2 outperform the
Llama models on various tasks, notably on low-resource languages, with GPT4
outperforming PaLM2 on more datasets than vice versa. However, issues such as
data contamination must be addressed to obtain an accurate assessment of LLM
performance on non-English languages.
</p>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07466" title="Abstract">arXiv:2311.07466</a> [<a href="/pdf/2311.07466" title="Download PDF">pdf</a>, <a href="/format/2311.07466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Measuring Faithfulness of Natural Language Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parcalabescu%2C+L">Letitia Parcalabescu</a>, 
<a href="/search/cs?searchtype=author&query=Frank%2C+A">Anette Frank</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 main paper pages, 17 appendix pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) can explain their own predictions, through
post-hoc or Chain-of-Thought (CoT) explanations. However the LLM could make up
reasonably sounding explanations that are unfaithful to its underlying
reasoning. Recent work has designed tests that aim to judge the faithfulness of
either post-hoc or CoT explanations. In this paper we argue that existing
faithfulness tests are not actually measuring faithfulness in terms of the
models' inner workings, but only evaluate their self-consistency on the output
level. The aims of our work are two-fold. i) We aim to clarify the status of
existing faithfulness tests in terms of model explainability, characterising
them as self-consistency tests instead. This assessment we underline by
constructing a Comparative Consistency Bank for self-consistency tests that for
the first time compares existing tests on a common suite of 11 open-source LLMs
and 5 datasets -- including ii) our own proposed self-consistency measure
CC-SHAP. CC-SHAP is a new fine-grained measure (not test) of LLM
self-consistency that compares a model's input contributions to answer
prediction and generated explanation. With CC-SHAP, we aim to take a step
further towards measuring faithfulness with a more interpretable and
fine-grained method. Code available at
\url{https://github.com/Heidelberg-NLP/CC-SHAP}
</p>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07468" title="Abstract">arXiv:2311.07468</a> [<a href="/pdf/2311.07468" title="Download PDF">pdf</a>, <a href="/format/2311.07468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are We Falling in a Middle-Intelligence Trap? An Analysis and Mitigation  of the Reversal Curse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lv%2C+A">Ang Lv</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaiyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Shufang Xie</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Q">Quan Tu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuhan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Ji-Rong Wen</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Rui Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent studies have highlighted a phenomenon in large language models (LLMs)
known as "the reversal curse," in which the order of knowledge entities in the
training data biases the models' comprehension. For example, if a model is
trained on sentences where entity A consistently appears before entity B, it
can respond to queries about A by providing B. However, it may encounter
confusion when presented with questions concerning B. We contend that the
reversal curse is partially a result of specific model training objectives,
particularly evident in the prevalent use of the next-token prediction within
most causal language models. For the next-token prediction, models solely focus
on a token's preceding context, resulting in a restricted comprehension of the
input. In contrast, we illustrate that the GLM, trained using the
autoregressive blank infilling objective where tokens to be predicted have
access to the entire context, exhibits better resilience against the reversal
curse. We propose a novel training method, BIdirectional Casual language
modeling Optimization (BICO), designed to mitigate the reversal curse when
fine-tuning pretrained causal language models on new data. BICO modifies the
causal attention mechanism to function bidirectionally and employs a mask
denoising optimization. In the task designed to assess the reversal curse, our
approach improves Llama's accuracy from the original 0% to around 70%. We hope
that more attention can be focused on exploring and addressing these inherent
weaknesses of the current LLMs, in order to achieve a higher level of
intelligence.
</p>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07469" title="Abstract">arXiv:2311.07469</a> [<a href="/pdf/2311.07469" title="Download PDF">pdf</a>, <a href="/format/2311.07469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InCA: Rethinking In-Car Conversational System Assessment Leveraging  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Friedl%2C+K+E">Ken E. Friedl</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A+G">Abbas Goher Khan</a>, 
<a href="/search/cs?searchtype=author&query=Sahoo%2C+S+R">Soumya Ranjan Sahoo</a>, 
<a href="/search/cs?searchtype=author&query=Rony%2C+M+R+A+H">Md Rashad Al Hasan Rony</a>, 
<a href="/search/cs?searchtype=author&query=Germies%2C+J">Jana Germies</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%BC%C3%9F%2C+C">Christian S&#xfc;&#xdf;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The assessment of advanced generative large language models (LLMs) poses a
significant challenge, given their heightened complexity in recent
developments. Furthermore, evaluating the performance of LLM-based applications
in various industries, as indicated by Key Performance Indicators (KPIs), is a
complex undertaking. This task necessitates a profound understanding of
industry use cases and the anticipated system behavior. Within the context of
the automotive industry, existing evaluation metrics prove inadequate for
assessing in-car conversational question answering (ConvQA) systems. The unique
demands of these systems, where answers may relate to driver or car safety and
are confined within the car domain, highlight the limitations of current
metrics. To address these challenges, this paper introduces a set of KPIs
tailored for evaluating the performance of in-car ConvQA systems, along with
datasets specifically designed for these KPIs. A preliminary and comprehensive
empirical evaluation substantiates the efficacy of our proposed approach.
Furthermore, we investigate the impact of employing varied personas in prompts
and found that it enhances the model's capacity to simulate diverse viewpoints
in assessments, mirroring how individuals with different backgrounds perceive a
topic.
</p>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07470" title="Abstract">arXiv:2311.07470</a> [<a href="/pdf/2311.07470" title="Download PDF">pdf</a>, <a href="/format/2311.07470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding and Editing Multi-Modal Neurons in Pre-Trained Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+H">Haowen Pan</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yixin Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaozhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xun Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Multi-modal large language models (LLM) have achieved powerful capabilities
for visual semantic understanding in recent years. However, little is known
about how LLMs comprehend visual information and interpret different modalities
of features. In this paper, we propose a new method for identifying multi-modal
neurons in transformer-based multi-modal LLMs. Through a series of experiments,
We highlight three critical properties of multi-modal neurons by four
well-designed quantitative evaluation metrics. Furthermore, we introduce a
knowledge editing method based on the identified multi-modal neurons, for
modifying a specific token to another designative token. We hope our findings
can inspire further explanatory researches on understanding mechanisms of
multi-modal LLMs.
</p>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07475" title="Abstract">arXiv:2311.07475</a> [<a href="/pdf/2311.07475" title="Download PDF">pdf</a>, <a href="/format/2311.07475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masked Face Dataset Generation and Masked Face Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+R">Rui Cai</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+X">Xuying Ning</a>, 
<a href="/search/cs?searchtype=author&query=Belhumeur%2C+P+N">Peter N. Belhumeur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A good demonstration of masked face dataset generation method and masked face recognition method
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the post-pandemic era, wearing face masks has posed great challenge to the
ordinary face recognition. In the previous study, researchers has applied
pretrained VGG16, and ResNet50 to extract features on the elaborate curated
existing masked face recognition (MFR) datasets, RMFRD and SMFRD. To make the
model more adaptable to the real world situation where the sample size is
smaller and the camera environment has greater changes, we created a more
challenging masked face dataset ourselves, by selecting 50 identities with 1702
images from Labelled Faces in the Wild (LFW) Dataset, and simulated face masks
through key point detection. The another part of our study is to solve the
masked face recognition problem, and we chose models by referring to the former
state of the art results, instead of directly using pretrained models, we fine
tuned the model on our new dataset and use the last linear layer to do the
classification directly. Furthermore, we proposed using data augmentation
strategy to further increase the test accuracy, and fine tuned a new networks
beyond the former study, one of the most SOTA networks, Inception ResNet v1.
The best test accuracy on 50 identity MFR has achieved 95%.
</p>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07477" title="Abstract">arXiv:2311.07477</a> [<a href="/pdf/2311.07477" title="Download PDF">pdf</a>, <a href="/format/2311.07477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal Performance Prediction for Deep Convolutional Long Short-Term  Memory Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fieback%2C+L">Laura Fieback</a> (1), 
<a href="/search/cs?searchtype=author&query=Dash%2C+B">Bidya Dash</a> (1), 
<a href="/search/cs?searchtype=author&query=Spiegelberg%2C+J">Jakob Spiegelberg</a> (1), 
<a href="/search/cs?searchtype=author&query=Gottschalk%2C+H">Hanno Gottschalk</a> (2) ((1) Volkswagen AG, (2) TU Berlin)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 4 figures, this work is related to <a href="/abs/1811.00648">arXiv:1811.00648</a> and <a href="/abs/1911.05075">arXiv:1911.05075</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Quantifying predictive uncertainty of deep semantic segmentation networks is
essential in safety-critical tasks. In applications like autonomous driving,
where video data is available, convolutional long short-term memory networks
are capable of not only providing semantic segmentations but also predicting
the segmentations of the next timesteps. These models use cell states to
broadcast information from previous data by taking a time series of inputs to
predict one or even further steps into the future. We present a temporal
postprocessing method which estimates the prediction performance of
convolutional long short-term memory networks by either predicting the
intersection over union of predicted and ground truth segments or classifying
between intersection over union being equal to zero or greater than zero. To
this end, we create temporal cell state-based input metrics per segment and
investigate different models for the estimation of the predictive quality based
on these metrics. We further study the influence of the number of considered
cell states for the proposed metrics.
</p>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07479" title="Abstract">arXiv:2311.07479</a> [<a href="/pdf/2311.07479" title="Download PDF">pdf</a>, <a href="/format/2311.07479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Robotic Tree Manipulation: Leveraging Graph Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+C+H">Chung Hee Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Moonyoung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kroemer%2C+O">Oliver Kroemer</a>, 
<a href="/search/cs?searchtype=author&query=Kantor%2C+G">George Kantor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">There is growing interest in automating agricultural tasks that require
intricate and precise interaction with specialty crops, such as trees and
vines. However, developing robotic solutions for crop manipulation remains a
difficult challenge due to complexities involved in modeling their deformable
behavior. In this study, we present a framework for learning the deformation
behavior of tree-like crops under contact interaction. Our proposed method
involves encoding the state of a spring-damper modeled tree crop as a graph.
This representation allows us to employ graph networks to learn both a forward
model for predicting resulting deformations, and a contact policy for inferring
actions to manipulate tree crops. We conduct a comprehensive set of experiments
in a simulated environment and demonstrate generalizability of our method on
previously unseen trees. Videos can be found on the project website:
https://kantor-lab.github.io/tree_gnn
</p>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07480" title="Abstract">arXiv:2311.07480</a> [<a href="/pdf/2311.07480" title="Download PDF">pdf</a>, <a href="/ps/2311.07480" title="Download PostScript">ps</a>, <a href="/format/2311.07480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Qualifying System F-sub
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+E">Edward Lee</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yaoyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+J">James You</a>, 
<a href="/search/cs?searchtype=author&query=Satheeskumar%2C+K">Kavin Satheeskumar</a>, 
<a href="/search/cs?searchtype=author&query=Lhot%C3%A1k%2C+O">Ond&#x159;ej Lhot&#xe1;k</a>, 
<a href="/search/cs?searchtype=author&query=Brachth%C3%A4user%2C+J">Jonathan Brachth&#xe4;user</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Type qualifiers offer a lightweight mechanism for enriching existing type
systems to enforce additional, desirable, program invariants. They do so by
offering a restricted but effective form of subtyping. While the theory of type
qualifiers is well understood and present in many programming languages today,
polymorphism over type qualifiers is an area that is less examined. We explore
how such a polymorphic system could arise by constructing a calculus System
F&lt;:Q which combines the higher-rank bounded polymorphism of System F&lt;: with the
theory of type qualifiers. We explore how the ideas used to construct System
F&lt;:Q can be reused in situations where type qualifiers naturally arise -- in
reference immutability, function colouring, and capture checking. Finally, we
re-examine other qualifier systems in the literature in light of the
observations presented while developing System F&lt;:Q.
</p>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07482" title="Abstract">arXiv:2311.07482</a> [<a href="/pdf/2311.07482" title="Download PDF">pdf</a>, <a href="/format/2311.07482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quieting the Static: A Study of Static Analysis Alert Suppressions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liargkovas%2C+G">Georgios Liargkovas</a>, 
<a href="/search/cs?searchtype=author&query=Panourgia%2C+E">Evangelia Panourgia</a>, 
<a href="/search/cs?searchtype=author&query=Spinellis%2C+D">Diomidis Spinellis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Static analysis tools are commonly used to detect defects before the code is
released. Previous research has focused on their overall effectiveness and
their ability to detect defects. However, little is known about the usage
patterns of warning suppressions: the configurations developers set up in order
to prevent the appearance of specific warnings. We address this gap by
analyzing how often are warning suppression features used, which warning
suppression features are used and for what purpose, and also how could the use
of warning suppression annotations be avoided. To answer these questions we
examine 1\,425 open-source Java-based projects that utilize Findbugs or
Spotbugs for warning-suppressing configurations and source code annotations. We
find that although most warnings are suppressed, only a small portion of them
get frequently suppressed. Contrary to expectations, false positives account
for a minor proportion of suppressions. A significant number of suppressions
introduce technical debt, suggesting potential disregard for code quality or a
lack of appropriate guidance from the tool. Misleading suggestions and
incorrect assumptions also lead to suppressions. Findings underscore the need
for better communication and education related to the use of static analysis
tools, improved bug pattern definitions, and better code annotation. Future
research can extend these findings to other static analysis tools, and apply
them to improve the effectiveness of static analysis.
</p>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07484" title="Abstract">arXiv:2311.07484</a> [<a href="/pdf/2311.07484" title="Download PDF">pdf</a>, <a href="/format/2311.07484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Psychometric Predictive Power of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuribayashi%2C+T">Tatsuki Kuribayashi</a>, 
<a href="/search/cs?searchtype=author&query=Oseki%2C+Y">Yohei Oseki</a>, 
<a href="/search/cs?searchtype=author&query=Baldwin%2C+T">Timothy Baldwin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Next-word probabilities from language models have been shown to successfully
simulate human reading behavior. Building on this, we show that, interestingly,
instruction-tuned large language models (LLMs) yield worse psychometric
predictive power (PPP) for human reading behavior than base LLMs with
equivalent perplexities. In other words, instruction tuning, which helps LLMs
provide human-preferred responses, does not always make them human-like from
the computational psycholinguistics perspective. In addition, we explore
prompting methodologies in simulating human reading behavior with LLMs, showing
that prompts reflecting a particular linguistic hypothesis lead LLMs to exhibit
better PPP but are still worse than base LLMs. These highlight that recent
instruction tuning and prompting do not offer better estimates than direct
probability measurements from base LLMs in cognitive modeling.
</p>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07485" title="Abstract">arXiv:2311.07485</a> [<a href="/pdf/2311.07485" title="Download PDF">pdf</a>, <a href="/format/2311.07485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EvoFed: Leveraging Evolutionary Strategies for Communication-Efficient  Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahimi%2C+M+M">Mohammad Mahdi Rahimi</a>, 
<a href="/search/cs?searchtype=author&query=Bhatti%2C+H+I">Hasnain Irshad Bhatti</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+Y">Younghyun Park</a>, 
<a href="/search/cs?searchtype=author&query=Kousar%2C+H">Humaira Kousar</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+J">Jaekyun Moon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Federated Learning (FL) is a decentralized machine learning paradigm that
enables collaborative model training across dispersed nodes without having to
force individual nodes to share data. However, its broad adoption is hindered
by the high communication costs of transmitting a large number of model
parameters. This paper presents EvoFed, a novel approach that integrates
Evolutionary Strategies (ES) with FL to address these challenges. EvoFed
employs a concept of 'fitness-based information sharing', deviating
significantly from the conventional model-based FL. Rather than exchanging the
actual updated model parameters, each node transmits a distance-based
similarity measure between the locally updated model and each member of the
noise-perturbed model population. Each node, as well as the server, generates
an identical population set of perturbed models in a completely synchronized
fashion using the same random seeds. With properly chosen noise variance and
population size, perturbed models can be combined to closely reflect the actual
model updated using the local dataset, allowing the transmitted similarity
measures (or fitness values) to carry nearly the complete information about the
model parameters. As the population size is typically much smaller than the
number of model parameters, the savings in communication load is large. The
server aggregates these fitness values and is able to update the global model.
This global fitness vector is then disseminated back to the nodes, each of
which applies the same update to be synchronized to the global model. Our
analysis shows that EvoFed converges, and our experimental results validate
that at the cost of increased local processing loads, EvoFed achieves
performance comparable to FedAvg while reducing overall communication
requirements drastically in various practical settings.
</p>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07490" title="Abstract">arXiv:2311.07490</a> [<a href="/pdf/2311.07490" title="Download PDF">pdf</a>, <a href="/format/2311.07490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Guide to Evaluating the Experience of Media and Arts Technology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bryan-Kinns%2C+N">Nick Bryan-Kinns</a>, 
<a href="/search/cs?searchtype=author&query=Reed%2C+C+N">Courtney N. Reed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. Chapter to appear in "Creating Digitally. Shifting Boundaries: Arts and Technologies - Contemporary Applications and Concepts", Anthony L. Brooks (Editor), Springer. <a href="https://link.springer.com/book/9783031313592">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Evaluation is essential to understanding the value that digital creativity
brings to people's experience, for example in terms of their enjoyment,
creativity, and engagement. There is a substantial body of research on how to
design and evaluate interactive arts and digital creativity applications. There
is also extensive Human-Computer Interaction (HCI) literature on how to
evaluate user interfaces and user experiences. However, it can be difficult for
artists, practitioners, and researchers to navigate such a broad and disparate
collection of materials when considering how to evaluate technology they create
that is at the intersection of art and interaction. This chapter provides a
guide to designing robust user studies of creative applications at the
intersection of art, technology and interaction, which we refer to as Media and
Arts Technology (MAT). We break MAT studies down into two main kinds:
proof-of-concept and comparative studies. As MAT studies are exploratory in
nature, their evaluation requires the collection and analysis of both
qualitative data such as free text questionnaire responses, interviews, and
observations, and also quantitative data such as questionnaires, number of
interactions, and length of time spent interacting. This chapter draws on over
15 years of experience of designing and evaluating novel interactive systems to
provide a concrete template on how to structure a study to evaluate MATs that
is both rigorous and repeatable, and how to report study results that are
publishable and accessible to a wide readership in art and science communities
alike.
</p>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07491" title="Abstract">arXiv:2311.07491</a> [<a href="/pdf/2311.07491" title="Download PDF">pdf</a>, <a href="/format/2311.07491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Step Closer to Comprehensive Answers: Constrained Multi-Stage Question  Decomposition with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">Hejing Cao</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+Z">Zhenwei An</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiazhan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liwei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dongyan Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">While large language models exhibit remarkable performance in the Question
Answering task, they are susceptible to hallucinations. Challenges arise when
these models grapple with understanding multi-hop relations in complex
questions or lack the necessary knowledge for a comprehensive response. To
address this issue, we introduce the "Decompose-and-Query" framework (D&amp;Q).
This framework guides the model to think and utilize external knowledge similar
to ReAct, while also restricting its thinking to reliable information,
effectively mitigating the risk of hallucinations. Experiments confirm the
effectiveness of D&amp;Q: On our ChitChatQA dataset, D&amp;Q does not lose to ChatGPT
in 67% of cases; on the HotPotQA question-only setting, D&amp;Q achieved an F1
score of 59.6%. Our code is available at
https://github.com/alkaidpku/DQ-ToolQA.
</p>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07492" title="Abstract">arXiv:2311.07492</a> [<a href="/pdf/2311.07492" title="Download PDF">pdf</a>, <a href="/format/2311.07492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Physicality Enables Trust: A New Era of Trust-Centered Cyberphysical  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gil%2C+S">Stephanie Gil</a>, 
<a href="/search/cs?searchtype=author&query=Yemini%2C+M">Michal Yemini</a>, 
<a href="/search/cs?searchtype=author&query=Chorti%2C+A">Arsenia Chorti</a>, 
<a href="/search/cs?searchtype=author&query=Nedi%C4%87%2C+A">Angelia Nedi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Poor%2C+H+V">H. Vincent Poor</a>, 
<a href="/search/cs?searchtype=author&query=Goldsmith%2C+A+J">Andrea J. Goldsmith</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Multiagent Systems (cs.MA); Networking and Internet Architecture (cs.NI); Systems and Control (eess.SY)

</div>
<p class="mathjax">Multi-agent cyberphysical systems enable new capabilities in efficiency,
resilience, and security. The unique characteristics of these systems prompt a
reevaluation of their security concepts, including their vulnerabilities, and
mechanisms to mitigate these vulnerabilities. This survey paper examines how
advancement in wireless networking, coupled with the sensing and computing in
cyberphysical systems, can foster novel security capabilities. This study
delves into three main themes related to securing multi-agent cyberphysical
systems. First, we discuss the threats that are particularly relevant to
multi-agent cyberphysical systems given the potential lack of trust between
agents. Second, we present prospects for sensing, contextual awareness, and
authentication, enabling the inference and measurement of ``inter-agent trust"
for these systems. Third, we elaborate on the application of quantifiable trust
notions to enable ``resilient coordination," where ``resilient" signifies
sustained functionality amid attacks on multiagent cyberphysical systems. We
refer to the capability of cyberphysical systems to self-organize, and
coordinate to achieve a task as autonomy. This survey unveils the cyberphysical
character of future interconnected systems as a pivotal catalyst for realizing
robust, trust-centered autonomy in tomorrow's world.
</p>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07493" title="Abstract">arXiv:2311.07493</a> [<a href="/pdf/2311.07493" title="Download PDF">pdf</a>, <a href="/format/2311.07493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ara2: Exploring Single- and Multi-Core Vector Processing with an  Efficient RVV1.0 Compliant Open-Source Processor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Perotti%2C+M">Matteo Perotti</a>, 
<a href="/search/cs?searchtype=author&query=Cavalcante%2C+M">Matheus Cavalcante</a>, 
<a href="/search/cs?searchtype=author&query=Andri%2C+R">Renzo Andri</a>, 
<a href="/search/cs?searchtype=author&query=Cavigelli%2C+L">Lukas Cavigelli</a>, 
<a href="/search/cs?searchtype=author&query=Benini%2C+L">Luca Benini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Vector processing is highly effective in boosting processor performance and
efficiency for data-parallel workloads. In this paper, we present Ara2, the
first fully open-source vector processor to support the RISC-V V 1.0 frozen
ISA. We evaluate Ara2's performance on a diverse set of data-parallel kernels
for various problem sizes and vector-unit configurations, achieving an average
functional-unit utilization of 95% on the most computationally intensive
kernels. We pinpoint performance boosters and bottlenecks, including the scalar
core, memories, and vector architecture, providing insights into the main
vector architecture's performance drivers. Leveraging the openness of the
design, we implement Ara2 in a 22nm technology, characterize its PPA metrics on
various configurations (2-16 lanes), and analyze its microarchitecture and
implementation bottlenecks. Ara2 achieves a state-of-the-art energy efficiency
of 37.8 DP-GFLOPS/W (0.8V) and 1.35GHz of clock frequency (critical path: ~40
FO4 gates). Finally, we explore the performance and energy-efficiency
trade-offs of multi-core vector processors: we find that multiple vector cores
help overcome the scalar core issue-rate bound that limits short-vector
performance. For example, a cluster of eight 2-lane Ara2 (16 FPUs) achieves
more than 3x better performance than a 16-lane single-core Ara2 (16 FPUs) when
executing a 32x32x32 matrix multiplication, with 1.5x improved energy
efficiency.
</p>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07495" title="Abstract">arXiv:2311.07495</a> [<a href="/pdf/2311.07495" title="Download PDF">pdf</a>, <a href="/format/2311.07495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Last Decade in Review: Tracing the Evolution of Safety Assurance  Cases through a Comprehensive Bibliometric Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sivakumar%2C+M">Mithila Sivakumar</a>, 
<a href="/search/cs?searchtype=author&query=Belle%2C+A+B">Alvine Boaye Belle</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+J">Jinjun Shan</a>, 
<a href="/search/cs?searchtype=author&query=Adesina%2C+O">Opeyemi Adesina</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Song Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chechik%2C+M">Marsha Chechik</a>, 
<a href="/search/cs?searchtype=author&query=Fokaefs%2C+M">Marios Fokaefs</a>, 
<a href="/search/cs?searchtype=author&query=Shahandashti%2C+K+K">Kimya Khakzad Shahandashti</a>, 
<a href="/search/cs?searchtype=author&query=Odu%2C+O">Oluwafemi Odu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Safety assurance is of paramount importance across various domains, including
automotive, aerospace, and nuclear energy, where the reliability and
acceptability of mission-critical systems are imperative. This assurance is
effectively realized through the utilization of Safety Assurance Cases. The use
of safety assurance cases allows for verifying the correctness of the created
systems capabilities, preventing system failure. The latter may result in loss
of life, severe injuries, large-scale environmental damage, property
destruction, and major economic loss. Still, the emergence of complex
technologies such as cyber-physical systems (CPSs), characterized by their
heterogeneity, autonomy, machine learning capabilities, and the uncertainty of
their operational environments poses significant challenges for safety
assurance activities. Several papers have tried to propose solutions to tackle
these challenges, but to the best of our knowledge, no secondary study
investigates the trends, patterns, and relationships characterizing the safety
case scientific literature. This makes it difficult to have a holistic view of
the safety case landscape and to identify the most promising future research
directions. In this paper, we, therefore, rely on state-of-the-art bibliometric
tools(e.g., VosViewer) to conduct a bibliometric analysis that allows us to
generate valuable insights, identify key authors and venues, and gain a birds
eye view of the current state of research in the safety assurance area. By
revealing knowledge gaps and highlighting potential avenues for future
research, our analysis provides an essential foundation for researchers,
corporate safety analysts, and regulators seeking to embrace or enhance safety
practices that align with their specific needs and objectives.
</p>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07497" title="Abstract">arXiv:2311.07497</a> [<a href="/pdf/2311.07497" title="Download PDF">pdf</a>, <a href="/format/2311.07497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multilingual Nonce Dependency Treebanks: Understanding how LLMs  represent and process syntactic structure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arps%2C+D">David Arps</a>, 
<a href="/search/cs?searchtype=author&query=Kallmeyer%2C+L">Laura Kallmeyer</a>, 
<a href="/search/cs?searchtype=author&query=Samih%2C+Y">Younes Samih</a>, 
<a href="/search/cs?searchtype=author&query=Sajjad%2C+H">Hassan Sajjad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Our software is available at <a href="https://github.com/davidarps/spud">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We introduce SPUD (Semantically Perturbed Universal Dependencies), a
framework for creating nonce treebanks for the multilingual Universal
Dependencies (UD) corpora. SPUD data satisfies syntactic argument structure,
provides syntactic annotations, and ensures grammaticality via
language-specific rules. We create nonce data in Arabic, English, French,
German, and Russian, and demonstrate two use cases of SPUD treebanks. First, we
investigate the effect of nonce data on word co-occurrence statistics, as
measured by perplexity scores of autoregressive (ALM) and masked language
models (MLM). We find that ALM scores are significantly more affected by nonce
data than MLM scores. Second, we show how nonce data affects the performance of
syntactic dependency probes. We replicate the findings of M\"uller-Eberstein et
al. (2022) on nonce test data and show that the performance declines on both
MLMs and ALMs wrt. original test data. However, a majority of the performance
is kept, suggesting that the probe indeed learns syntax independently from
semantics.
</p>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07498" title="Abstract">arXiv:2311.07498</a> [<a href="/pdf/2311.07498" title="Download PDF">pdf</a>, <a href="/format/2311.07498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reducing the Need for Backpropagation and Discovering Better Optima With  Explicit Optimizations of Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Williams%2C+J+R">Jake Ryland Williams</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Haoran Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Probability (math.PR); Data Analysis, Statistics and Probability (physics.data-an); Machine Learning (stat.ML)

</div>
<p class="mathjax">Iterative differential approximation methods that rely upon backpropagation
have enabled the optimization of neural networks; however, at present, they
remain computationally expensive, especially when training models at scale. In
this paper, we propose a computationally efficient alternative for optimizing
neural networks that can both reduce the costs of scaling neural networks and
provide high-efficiency optimizations for low-resource applications. We derive
an explicit solution to a simple feed-forward language model (LM) by
mathematically analyzing its gradients. This solution generalizes from
single-layer LMs to the class of all single-layer feed-forward
softmax-activated neural models trained on positive-valued features, as is
demonstrated by our extension of this solution application to MNIST digit
classification. For both LM and digit classifiers, we find computationally that
explicit solutions perform near-optimality in experiments showing that 1)
iterative optimization only marginally improves the explicit solution
parameters and 2) randomly initialized parameters iteratively optimize towards
the explicit solution. We also preliminarily apply the explicit solution
locally by layer in multi-layer networks and discuss how the solution's
computational savings increase with model complexity -- for both single- and
mult-layer applications of the explicit solution, we emphasize that the optima
achieved cannot be reached by backpropagation alone, i.e., better optima appear
discoverable only after explicit solutions are applied. Finally, we discuss the
solution's computational savings alongside its impact on model interpretability
and suggest future directions for the derivation of explicit solutions to
complex- and multi-layer architectures.
</p>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07499" title="Abstract">arXiv:2311.07499</a> [<a href="/pdf/2311.07499" title="Download PDF">pdf</a>, <a href="/format/2311.07499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging the Sim-to-Real Gap with Dynamic Compliance Tuning for  Industrial Insertion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tomizuka%2C+M">Masayoshi Tomizuka</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hui Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Contact-rich manipulation tasks often exhibit a large sim-to-real gap. For
instance, industrial assembly tasks frequently involve tight insertions where
the clearance is less than \(0.1\) mm and can even be negative when dealing
with a deformable receptacle. This narrow clearance leads to complex contact
dynamics that are difficult to model accurately in simulation, making it
challenging to transfer simulation-learned policies to real-world robots. In
this paper, we propose a novel framework for robustly learning manipulation
skills for real-world tasks using only the simulated data. Our framework
consists of two main components: the ``Force Planner'' and the ``Gain Tuner''.
The Force Planner is responsible for planning both the robot motion and desired
contact forces, while the Gain Tuner dynamically adjusts the compliance control
gains to accurately track the desired contact forces during task execution. The
key insight of this work is that by adaptively adjusting the robot's compliance
control gains during task execution, we can modulate contact forces in the new
environment, thereby generating trajectories similar to those trained in
simulation and narrows the sim-to-real gap. Experimental results show that our
method, trained in simulation on a generic square peg-and-hole task, can
generalize to a variety of real-world insertion tasks involving narrow or even
negative clearances, all without requiring any fine-tuning.
</p>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07502" title="Abstract">arXiv:2311.07502</a> [<a href="/pdf/2311.07502" title="Download PDF">pdf</a>, <a href="/format/2311.07502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ARWalker: A Virtual Walking Companion Application
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wijesooriya%2C+P">Pubudu Wijesooriya</a>, 
<a href="/search/cs?searchtype=author&query=Likens%2C+A">Aaron Likens</a>, 
<a href="/search/cs?searchtype=author&query=Stergiou%2C+N">Nick Stergiou</a>, 
<a href="/search/cs?searchtype=author&query=Mastorakis%2C+S">Spyridon Mastorakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Extended Reality (XR) technologies, including Augmented Reality (AR), have
attracted significant attention over the past few years and have been utilized
in several fields, including education, healthcare, and manufacturing. In this
paper, we aim to explore the use of AR in the field of biomechanics and human
movement through the development of ARWalker, which is an AR application that
features virtual walking companions (avatars). Research participants walk in
close synchrony with the virtual companions, whose gait exhibits properties
found in the gait of young and healthy adults. As a result, research
participants can train their gait to the gait of the avatar, thus regaining the
healthy properties of their gait and reducing the risk of falls. ARWalker can
especially help older adults and individuals with diseases, who exhibit
pathological gait thus being more prone to falls. We implement a prototype of
ARWalker and evaluate its systems performance while running on a Microsoft
Hololens 2 headset.
</p>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07504" title="Abstract">arXiv:2311.07504</a> [<a href="/pdf/2311.07504" title="Download PDF">pdf</a>, <a href="/format/2311.07504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STEM Rebalance: A Novel Approach for Tackling Imbalanced Datasets using  SMOTE, Edited Nearest Neighbour, and Mixup
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hasan%2C+Y">Yumnah Hasan</a>, 
<a href="/search/cs?searchtype=author&query=Amerehi%2C+F">Fatemeh Amerehi</a>, 
<a href="/search/cs?searchtype=author&query=Healy%2C+P">Patrick Healy</a>, 
<a href="/search/cs?searchtype=author&query=Ryan%2C+C">Conor Ryan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures, International Conference on Intelligent Computer Communication and Processing
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE ICCP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Imbalanced datasets in medical imaging are characterized by skewed class
proportions and scarcity of abnormal cases. When trained using such data,
models tend to assign higher probabilities to normal cases, leading to biased
performance. Common oversampling techniques such as SMOTE rely on local
information and can introduce marginalization issues. This paper investigates
the potential of using Mixup augmentation that combines two training examples
along with their corresponding labels to generate new data points as a generic
vicinal distribution. To this end, we propose STEM, which combines SMOTE-ENN
and Mixup at the instance level. This integration enables us to effectively
leverage the entire distribution of minority classes, thereby mitigating both
between-class and within-class imbalances. We focus on the breast cancer
problem, where imbalanced datasets are prevalent. The results demonstrate the
effectiveness of STEM, which achieves AUC values of 0.96 and 0.99 in the
Digital Database for Screening Mammography and Wisconsin Breast Cancer
(Diagnostics) datasets, respectively. Moreover, this method shows promising
potential when applied with an ensemble of machine learning (ML) classifiers.
</p>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07509" title="Abstract">arXiv:2311.07509</a> [<a href="/pdf/2311.07509" title="Download PDF">pdf</a>, <a href="/format/2311.07509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Benchmark to Understand the Role of Knowledge Graphs on Large Language  Model&#x27;s Accuracy for Question Answering on Enterprise SQL Databases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sequeda%2C+J">Juan Sequeda</a>, 
<a href="/search/cs?searchtype=author&query=Allemang%2C+D">Dean Allemang</a>, 
<a href="/search/cs?searchtype=author&query=Jacob%2C+B">Bryon Jacob</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Databases (cs.DB)

</div>
<p class="mathjax">Enterprise applications of Large Language Models (LLMs) hold promise for
question answering on enterprise SQL databases. However, the extent to which
LLMs can accurately respond to enterprise questions in such databases remains
unclear, given the absence of suitable Text-to-SQL benchmarks tailored to
enterprise settings. Additionally, the potential of Knowledge Graphs (KGs) to
enhance LLM-based question answering by providing business context is not well
understood. This study aims to evaluate the accuracy of LLM-powered question
answering systems in the context of enterprise questions and SQL databases,
while also exploring the role of knowledge graphs in improving accuracy. To
achieve this, we introduce a benchmark comprising an enterprise SQL schema in
the insurance domain, a range of enterprise queries encompassing reporting to
metrics, and a contextual layer incorporating an ontology and mappings that
define a knowledge graph. Our primary finding reveals that question answering
using GPT-4, with zero-shot prompts directly on SQL databases, achieves an
accuracy of 16%. Notably, this accuracy increases to 54% when questions are
posed over a Knowledge Graph representation of the enterprise SQL database.
Therefore, investing in Knowledge Graph provides higher accuracy for LLM
powered question answering systems.
</p>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07510" title="Abstract">arXiv:2311.07510</a> [<a href="/pdf/2311.07510" title="Download PDF">pdf</a>, <a href="/format/2311.07510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explicit Foundation Model Optimization with Self-Attentive Feed-Forward  Neural Units
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Williams%2C+J+R">Jake Ryland Williams</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Haoran Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Probability (math.PR); Data Analysis, Statistics and Probability (physics.data-an); Machine Learning (stat.ML)

</div>
<p class="mathjax">Iterative approximation methods using backpropagation enable the optimization
of neural networks, but they remain computationally expensive, especially when
used at scale. This paper presents an efficient alternative for optimizing
neural networks that reduces the costs of scaling neural networks and provides
high-efficiency optimizations for low-resource applications. We will discuss a
general result about feed-forward neural networks and then extend this solution
to compositional (mult-layer) networks, which are applied to a simplified
transformer block containing feed-forward and self-attention layers. These
models are used to train highly-specified and complex multi-layer neural
architectures that we refer to as self-attentive feed-forward unit (SAFFU)
layers, which we use to develop a transformer that appears to generalize well
over small, cognitively-feasible, volumes of data. Testing demonstrates
explicit solutions outperform models optimized by backpropagation alone.
Moreover, further application of backpropagation after explicit solutions leads
to better optima from smaller scales of data, training effective models from
much less data is enabled by explicit solution warm starts. We then carry out
ablation experiments training a roadmap of about 250 transformer models over
1-million tokens to determine ideal settings. We find that multiple different
architectural variants produce highly-performant models, and discover from this
ablation that some of the best are not the most parameterized. This appears to
indicate well-generalized models could be reached using less data by using
explicit solutions, and that architectural exploration using explicit solutions
pays dividends in guiding the search for efficient variants with fewer
parameters, and which could be incorporated into low-resource hardware where AI
might be embodied.
</p>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07514" title="Abstract">arXiv:2311.07514</a> [<a href="/pdf/2311.07514" title="Download PDF">pdf</a>, <a href="/format/2311.07514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VGSG: Vision-Guided Semantic-Group Network for Text-based Person Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+S">Shuting He</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Hao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xudong Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+H">Henghui Ding</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE TIP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-based Person Search (TBPS) aims to retrieve images of target pedestrian
indicated by textual descriptions. It is essential for TBPS to extract
fine-grained local features and align them crossing modality. Existing methods
utilize external tools or heavy cross-modal interaction to achieve explicit
alignment of cross-modal fine-grained features, which is inefficient and
time-consuming. In this work, we propose a Vision-Guided Semantic-Group Network
(VGSG) for text-based person search to extract well-aligned fine-grained visual
and textual features. In the proposed VGSG, we develop a Semantic-Group Textual
Learning (SGTL) module and a Vision-guided Knowledge Transfer (VGKT) module to
extract textual local features under the guidance of visual local clues. In
SGTL, in order to obtain the local textual representation, we group textual
features from the channel dimension based on the semantic cues of language
expression, which encourages similar semantic patterns to be grouped implicitly
without external tools. In VGKT, a vision-guided attention is employed to
extract visual-related textual features, which are inherently aligned with
visual cues and termed vision-guided textual features. Furthermore, we design a
relational knowledge transfer, including a vision-language similarity transfer
and a class probability transfer, to adaptively propagate information of the
vision-guided textual features to semantic-group textual features. With the
help of relational knowledge transfer, VGKT is capable of aligning
semantic-group textual features with corresponding visual features without
external tools and complex pairwise interaction. Experimental results on two
challenging benchmarks demonstrate its superiority over state-of-the-art
methods.
</p>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07532" title="Abstract">arXiv:2311.07532</a> [<a href="/pdf/2311.07532" title="Download PDF">pdf</a>, <a href="/format/2311.07532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> It&#x27;s Not Easy Being Wrong: Evaluating Process of Elimination Reasoning  in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balepur%2C+N">Nishant Balepur</a>, 
<a href="/search/cs?searchtype=author&query=Palta%2C+S">Shramay Palta</a>, 
<a href="/search/cs?searchtype=author&query=Rudinger%2C+R">Rachel Rudinger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In progress preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Chain-of-thought (COT) prompting can help large language models (LLMs) reason
toward correct answers, but its efficacy in reasoning toward incorrect answers
is unexplored. This strategy of process of elimination (PoE), when used with
COT, has the potential to enhance interpretability in tasks like medical
diagnoses of exclusion. Thus, we propose PoE with COT, a new task where LLMs
must reason toward incorrect options on multiple-choice questions. We evaluate
the ability of GPT-3.5, LLaMA-2, and Falcon to perform PoE with COT on 2-choice
commonsense and scientific reasoning datasets. We show that PoE consistently
underperforms directly choosing the correct answer. The agreement of these
strategies is also lower than the self-consistency of each strategy. To study
these issues further, we conduct an error analysis and give suggestions for
future work.
</p>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07534" title="Abstract">arXiv:2311.07534</a> [<a href="/pdf/2311.07534" title="Download PDF">pdf</a>, <a href="/format/2311.07534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Musical Object Discovery from Audio
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gha%2C+J">Joonsu Gha</a>, 
<a href="/search/cs?searchtype=author&query=Herrmann%2C+V">Vincent Herrmann</a>, 
<a href="/search/cs?searchtype=author&query=Grewe%2C+B">Benjamin Grewe</a>, 
<a href="/search/cs?searchtype=author&query=Schmidhuber%2C+J">J&#xfc;rgen Schmidhuber</a>, 
<a href="/search/cs?searchtype=author&query=Gopalakrishnan%2C+A">Anand Gopalakrishnan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Machine Learning for Audio, NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Current object-centric learning models such as the popular SlotAttention
architecture allow for unsupervised visual scene decomposition. Our novel
MusicSlots method adapts SlotAttention to the audio domain, to achieve
unsupervised music decomposition. Since concepts of opacity and occlusion in
vision have no auditory analogues, the softmax normalization of alpha masks in
the decoders of visual object-centric models is not well-suited for decomposing
audio objects. MusicSlots overcomes this problem. We introduce a
spectrogram-based multi-object music dataset tailored to evaluate
object-centric learning on western tonal music. MusicSlots achieves good
performance on unsupervised note discovery and outperforms several established
baselines on supervised note property prediction tasks.
</p>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07535" title="Abstract">arXiv:2311.07535</a> [<a href="/pdf/2311.07535" title="Download PDF">pdf</a>, <a href="/format/2311.07535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causality Diagrams using Hybrid Vector Clocks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lagwankar%2C+I">Ishaan Lagwankar</a>, 
<a href="/search/cs?searchtype=author&query=Wijewardena%2C+K">Kanishka Wijewardena</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Causality in distributed systems is a concept that has long been explored and
numerous approaches have been made to use causality as a way to trace
distributed system execution. Traditional approaches usually used system
profiling and newer approaches profiled clocks of systems to detect failures
and construct timelines that caused those failures. Since the advent of logical
clocks, these profiles have become more and more accurate with ways to
characterize concurrency and distributions, with accurate diagrams for message
passing. Vector clocks addressed the shortcomings of using traditional logical
clocks, by storing information about other processes in the system as well.
Hybrid vector clocks are a novel approach to this concept where clocks need not
store all the process information. Rather, we store information of processes
within an acceptable skew of the focused process. This gives us an efficient
way of profiling with substantially reduced costs to the system. Building on
this idea, we propose the idea of building causal traces using information
generated from the hybrid vector clock. The hybrid vector clock would provide
us with a strong sense of concurrency and distribution, and we theorize that
all the information generated from the clock is sufficient to develop a causal
trace for debugging. We post-process and parse the clocks generated from an
execution trace to develop a swimlane on a web interface, that traces the
points of failure of a distributed system. We also provide an API to reuse this
concept for any generic distributed system framework.
</p>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07536" title="Abstract">arXiv:2311.07536</a> [<a href="/pdf/2311.07536" title="Download PDF">pdf</a>, <a href="/format/2311.07536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Evaluation of GPT-4V on Knowledge-Intensive Visual  Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Longyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Baotian Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+W">Wanqi Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+C">Chenyang Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 13pages; working in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The emergence of multimodal large models (MLMs) has significantly advanced
the field of visual understanding, offering remarkable capabilities in the
realm of visual question answering (VQA). Yet, the true challenge lies in the
domain of knowledge-intensive VQA tasks, which necessitate not just recognition
of visual elements, but also a deep comprehension of the visual information in
conjunction with a vast repository of learned knowledge. To uncover such
capabilities of MLMs, particularly the newly introduced GPT-4V, we provide an
in-depth evaluation from three perspectives: 1) Commonsense Knowledge, which
assesses how well models can understand visual cues and connect to general
knowledge; 2) Fine-grained World Knowledge, which tests the model's skill in
reasoning out specific knowledge from images, showcasing their proficiency
across various specialized fields; 3) Comprehensive Knowledge with
Decision-making Rationales, which examines model's capability to provide
logical explanations for its inference, facilitating a deeper analysis from the
interpretability perspective. Extensive experiments indicate that GPT-4V
achieves SOTA performance on above three tasks. Interestingly, we find that: a)
GPT-4V demonstrates enhanced reasoning and explanation when using composite
images as few-shot; b) GPT-4V produces severe hallucinations when dealing with
world knowledge, highlighting the future need for advancements in this research
direction.
</p>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07538" title="Abstract">arXiv:2311.07538</a> [<a href="/pdf/2311.07538" title="Download PDF">pdf</a>, <a href="/format/2311.07538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Multiple Teachers for Test-Time Adaptation of Language-Guided  Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+K">Kangda Wei</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Sayan Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Menon%2C+R+R">Rakesh R. Menon</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+S">Shashank Srivastava</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent approaches have explored language-guided classifiers capable of
classifying examples from novel tasks when provided with task-specific natural
language explanations, instructions or prompts (Sanh et al., 2022; R. Menon et
al., 2022). While these classifiers can generalize in zero-shot settings, their
task performance often varies substantially between different language
explanations in unpredictable ways (Lu et al., 2022; Gonen et al., 2022). Also,
current approaches fail to leverage unlabeled examples that may be available in
many scenarios. Here, we introduce TALC, a framework that uses data programming
to adapt a language-guided classifier for a new task during inference when
provided with explanations from multiple teachers and unlabeled test examples.
Our results show that TALC consistently outperforms a competitive baseline from
prior work by an impressive 9.3% (relative improvement). Further, we
demonstrate the robustness of TALC to variations in the quality and quantity of
provided explanations, highlighting its potential in scenarios where learning
from multiple teachers or a crowd is involved. Our code is available at:
https://github.com/WeiKangda/TALC.git.
</p>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07540" title="Abstract">arXiv:2311.07540</a> [<a href="/pdf/2311.07540" title="Download PDF">pdf</a>, <a href="/format/2311.07540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding planted cliques using Markov chain Monte Carlo
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gheissari%2C+R">Reza Gheissari</a>, 
<a href="/search/cs?searchtype=author&query=Jagannath%2C+A">Aukosh Jagannath</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yiming Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Probability (math.PR); Statistics Theory (math.ST)

</div>
<p class="mathjax">The planted clique problem is a paradigmatic model of
statistical-to-computational gaps: the planted clique is
information-theoretically detectable if its size $k\ge 2\log_2 n$ but
polynomial-time algorithms only exist for the recovery task when $k=
\Omega(\sqrt{n})$. By now, there are many simple and fast algorithms that
succeed as soon as $k = \Omega(\sqrt{n})$. Glaringly, however, no MCMC approach
to the problem had been shown to work, including the Metropolis process on
cliques studied by Jerrum since 1992. In fact, Chen, Mossel, and Zadik recently
showed that any Metropolis process whose state space is the set of cliques
fails to find any sub-linear sized planted clique in polynomial time if
initialized naturally from the empty set. Here, we redeem MCMC performance for
the planted clique problem by relaxing the state space to all vertex subsets
and adding a corresponding energy penalty for missing edges. With that, we
prove that energy-minimizing Markov chains (gradient descent and a
low-temperature relaxation of it) succeed at recovering planted cliques of size
$k = \Omega(\sqrt{n})$ if initialized from the full graph. Importantly,
initialized from the empty set, the relaxation still does not help the gradient
descent find sub-linear planted cliques. We also demonstrate robustness of
these Markov chain approaches under a natural contamination model.
</p>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07541" title="Abstract">arXiv:2311.07541</a> [<a href="/pdf/2311.07541" title="Download PDF">pdf</a>, <a href="/ps/2311.07541" title="Download PostScript">ps</a>, <a href="/format/2311.07541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> mlscorecheck: Testing the consistency of reported performance scores and  experiments in machine learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kov%C3%A1cs%2C+G">Gy&#xf6;rgy Kov&#xe1;cs</a>, 
<a href="/search/cs?searchtype=author&query=Fazekas%2C+A">Attila Fazekas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Addressing the reproducibility crisis in artificial intelligence through the
validation of reported experimental results is a challenging task. It
necessitates either the reimplementation of techniques or a meticulous
assessment of papers for deviations from the scientific method and best
statistical practices. To facilitate the validation of reported results, we
have developed numerical techniques capable of identifying inconsistencies
between reported performance scores and various experimental setups in machine
learning problems, including binary/multiclass classification and regression.
These consistency tests are integrated into the open-source package
mlscorecheck, which also provides specific test bundles designed to detect
systematically recurring flaws in various fields, such as retina image
processing and synthetic minority oversampling.
</p>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07547" title="Abstract">arXiv:2311.07547</a> [<a href="/pdf/2311.07547" title="Download PDF">pdf</a>, <a href="/format/2311.07547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPT-4V(ision) as A Social Media Analysis Engine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+H">Hanjia Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jinfa Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Daoan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yongsheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Mou%2C+X">Xinyi Mou</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jinsheng Pan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhengyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhongyu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jiebo Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multimedia (cs.MM)

</div>
<p class="mathjax">Recent research has offered insights into the extraordinary capabilities of
Large Multimodal Models (LMMs) in various general vision and language tasks.
There is growing interest in how LMMs perform in more specialized domains.
Social media content, inherently multimodal, blends text, images, videos, and
sometimes audio. Understanding social multimedia content remains a challenging
problem for contemporary machine learning frameworks. In this paper, we explore
GPT-4V(ision)'s capabilities for social multimedia analysis. We select five
representative tasks, including sentiment analysis, hate speech detection, fake
news identification, demographic inference, and political ideology detection,
to evaluate GPT-4V. Our investigation begins with a preliminary quantitative
analysis for each task using existing benchmark datasets, followed by a careful
review of the results and a selection of qualitative samples that illustrate
GPT-4V's potential in understanding multimodal social media content. GPT-4V
demonstrates remarkable efficacy in these tasks, showcasing strengths such as
joint understanding of image-text pairs, contextual and cultural awareness, and
extensive commonsense knowledge. Despite the overall impressive capacity of
GPT-4V in the social media domain, there remain notable challenges. GPT-4V
struggles with tasks involving multilingual social multimedia comprehension and
has difficulties in generalizing to the latest trends in social media.
Additionally, it exhibits a tendency to generate erroneous information in the
context of evolving celebrity and politician knowledge, reflecting the known
hallucination problem. The insights gleaned from our findings underscore a
promising future for LMMs in enhancing our comprehension of social media
content and its users through the analysis of multimodal information.
</p>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07548" title="Abstract">arXiv:2311.07548</a> [<a href="/pdf/2311.07548" title="Download PDF">pdf</a>, <a href="/format/2311.07548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable Fine-Tuning for Graph Neural Network Surrogate Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barwey%2C+S">Shivam Barwey</a>, 
<a href="/search/cs?searchtype=author&query=Maulik%2C+R">Romit Maulik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Physics (physics.comp-ph); Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">Data-based surrogate modeling has surged in capability in recent years with
the emergence of graph neural networks (GNNs), which can operate directly on
mesh-based representations of data. The goal of this work is to introduce an
interpretable fine-tuning strategy for GNNs, with application to unstructured
mesh-based fluid dynamics modeling. The end result is a fine-tuned GNN that
adds interpretability to a pre-trained baseline GNN through an adaptive
sub-graph sampling strategy that isolates regions in physical space
intrinsically linked to the forecasting task, while retaining the predictive
capability of the baseline. The structures identified by the fine-tuned GNNs,
which are adaptively produced in the forward pass as explicit functions of the
input, serve as an accessible link between the baseline model architecture, the
optimization goal, and known problem-specific physics. Additionally, through a
regularization procedure, the fine-tuned GNNs can also be used to identify,
during inference, graph nodes that correspond to a majority of the anticipated
forecasting error, adding a novel interpretable error-tagging capability to
baseline models. Demonstrations are performed using unstructured flow data
sourced from flow over a backward-facing step at high Reynolds numbers.
</p>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07550" title="Abstract">arXiv:2311.07550</a> [<a href="/pdf/2311.07550" title="Download PDF">pdf</a>, <a href="/format/2311.07550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tabdoor: Backdoor Vulnerabilities in Transformer-based Neural Networks  for Tabular Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pleiter%2C+B">Bart Pleiter</a>, 
<a href="/search/cs?searchtype=author&query=Tajalli%2C+B">Behrad Tajalli</a>, 
<a href="/search/cs?searchtype=author&query=Koffas%2C+S">Stefanos Koffas</a>, 
<a href="/search/cs?searchtype=author&query=Abad%2C+G">Gorka Abad</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Larson%2C+M">Martha Larson</a>, 
<a href="/search/cs?searchtype=author&query=Picek%2C+S">Stjepan Picek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep neural networks (DNNs) have shown great promise in various domains.
Alongside these developments, vulnerabilities associated with DNN training,
such as backdoor attacks, are a significant concern. These attacks involve the
subtle insertion of triggers during model training, allowing for manipulated
predictions. More recently, DNNs for tabular data have gained increasing
attention due to the rise of transformer models.
<br />Our research presents a comprehensive analysis of backdoor attacks on tabular
data using DNNs, particularly focusing on transformer-based networks. Given the
inherent complexities of tabular data, we explore the challenges of embedding
backdoors. Through systematic experimentation across benchmark datasets, we
uncover that transformer-based DNNs for tabular data are highly susceptible to
backdoor attacks, even with minimal feature value alterations. Our results
indicate nearly perfect attack success rates (approx100%) by introducing novel
backdoor attack strategies to tabular data. Furthermore, we evaluate several
defenses against these attacks, identifying Spectral Signatures as the most
effective one. Our findings highlight the urgency to address such
vulnerabilities and provide insights into potential countermeasures for
securing DNN models against backdoors on tabular data.
</p>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07553" title="Abstract">arXiv:2311.07553</a> [<a href="/pdf/2311.07553" title="Download PDF">pdf</a>, <a href="/format/2311.07553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Extensive Study on Adversarial Attack against Pre-trained Models of  Code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xiaohu Du</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+M">Ming Wen</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zichao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shangwen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Hai Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ESEC/FSE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Transformer-based pre-trained models of code (PTMC) have been widely utilized
and have achieved state-of-the-art performance in many mission-critical
applications. However, they can be vulnerable to adversarial attacks through
identifier substitution or coding style transformation, which can significantly
degrade accuracy and may further incur security concerns. Although several
approaches have been proposed to generate adversarial examples for PTMC, the
effectiveness and efficiency of such approaches, especially on different code
intelligence tasks, has not been well understood. To bridge this gap, this
study systematically analyzes five state-of-the-art adversarial attack
approaches from three perspectives: effectiveness, efficiency, and the quality
of generated examples. The results show that none of the five approaches
balances all these perspectives. Particularly, approaches with a high attack
success rate tend to be time-consuming; the adversarial code they generate
often lack naturalness, and vice versa. To address this limitation, we explore
the impact of perturbing identifiers under different contexts and find that
identifier substitution within for and if statements is the most effective.
Based on these findings, we propose a new approach that prioritizes different
types of statements for various tasks and further utilizes beam search to
generate adversarial examples. Evaluation results show that it outperforms the
state-of-the-art ALERT in terms of both effectiveness and efficiency while
preserving the naturalness of the generated adversarial examples.
</p>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07554" title="Abstract">arXiv:2311.07554</a> [<a href="/pdf/2311.07554" title="Download PDF">pdf</a>, <a href="/format/2311.07554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast and Space-Efficient Parallel Algorithms for Influence Maximization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Letong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+X">Xiangyun Ding</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yan Gu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yihan Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Influence Maximization (IM) is a crucial problem in data science. The goal is
to find a fixed-size set of highly-influential seed vertices on a network to
maximize the influence spread along the edges. While IM is NP-hard on
commonly-used diffusion models, a greedy algorithm can achieve
$(1-1/e)$-approximation, repeatedly selecting the vertex with the highest
marginal gain in influence as the seed. Due to theoretical guarantees, rich
literature focuses on improving the performance of the greedy algorithm. To
estimate the marginal gain, existing work either runs Monte Carlo (MC)
simulations of influence spread or pre-stores hundreds of sketches (usually
per-vertex information). However, these approaches can be inefficient in time
(MC simulation) or space (storing sketches), preventing the ideas from scaling
to today's large-scale graphs.
<br />This paper significantly improves the scalability of IM using two key
techniques. The first is a sketch-compression technique for the independent
cascading model on undirected graphs. It allows combining the simulation and
sketching approaches to achieve a time-space tradeoff. The second technique
includes new data structures for parallel seed selection. Using our new
approaches, we implemented PaC-IM: Parallel and Compressed IM.
<br />We compare PaC-IM with state-of-the-art parallel IM systems on a 96-core
machine with 1.5TB memory. PaC-IM can process large-scale graphs with up to
900M vertices and 74B edges in about 2 hours. On average across all tested
graphs, our uncompressed version is 5--18$\times$ faster and about 1.4$\times$
more space-efficient than existing parallel IM systems. Using compression
further saves 3.8$\times$ space with only 70% overhead in time on average.
</p>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07555" title="Abstract">arXiv:2311.07555</a> [<a href="/pdf/2311.07555" title="Download PDF">pdf</a>, <a href="/format/2311.07555" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Bounding and Approximating Functions of Multiple Expectations using  Quasi-Monte Carlo
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sorokin%2C+A+G">Aleksei G. Sorokin</a>, 
<a href="/search/math?searchtype=author&query=Rathinavel%2C+J">Jagadeeswaran Rathinavel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Monte Carlo and Quasi-Monte Carlo methods present a convenient approach for
approximating the expected value of a random variable. Algorithms exist to
adaptively sample the random variable until a user defined absolute error
tolerance is satisfied with high probability. This work describes an extension
of such methods which supports adaptive sampling to satisfy general error
criteria for functions of a common array of expectations. Although several
functions involving multiple expectations are being evaluated, only one random
sequence is required, albeit sometimes of larger dimension than the underlying
randomness. These enhanced Monte Carlo and Quasi-Monte Carlo algorithms are
implemented in the QMCPy Python package with support for economic and parallel
function evaluation. We exemplify these capabilities on problems from machine
learning and global sensitivity analysis.
</p>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07556" title="Abstract">arXiv:2311.07556</a> [<a href="/pdf/2311.07556" title="Download PDF">pdf</a>, <a href="/format/2311.07556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Natural Language Explanations to Improve Robustness of In-context  Learning for Natural Language Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xuanli He</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuxiang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Camburu%2C+O">Oana-Maria Camburu</a>, 
<a href="/search/cs?searchtype=author&query=Minervini%2C+P">Pasquale Minervini</a>, 
<a href="/search/cs?searchtype=author&query=Stenetorp%2C+P">Pontus Stenetorp</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> pre-print
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent studies have demonstrated that large language models (LLMs) excel in
diverse tasks through in-context learning (ICL) facilitated by task-specific
prompts and examples. However, the existing literature shows that ICL
encounters performance deterioration when exposed to adversarial inputs.
Enhanced performance has been observed when ICL is augmented with natural
language explanations (NLEs) (we refer to it as X-ICL). Thus, this work
investigates whether X-ICL can improve the robustness of LLMs on a suite of
seven adversarial and challenging natural language inference datasets.
Moreover, we introduce a new approach to X-ICL by prompting an LLM (ChatGPT in
our case) with few human-generated NLEs to produce further NLEs (we call it
ChatGPT few-shot), which we show superior to both ChatGPT zero-shot and
human-generated NLEs alone. We evaluate five popular LLMs (GPT3.5-turbo,
LLaMa2, Vicuna, Zephyr, Mistral) and show that X-ICL with ChatGPT few-shot
yields over 6% improvement over ICL. Furthermore, while prompt selection
strategies were previously shown to significantly improve ICL on
in-distribution test sets, we show that these strategies do not match the
efficacy of the X-ICL paradigm in robustness-oriented evaluations.
</p>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07558" title="Abstract">arXiv:2311.07558</a> [<a href="/pdf/2311.07558" title="Download PDF">pdf</a>, <a href="/format/2311.07558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Efficient Task Generalization via Probabilistic Model-based Meta  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhardwaj%2C+A">Arjun Bhardwaj</a>, 
<a href="/search/cs?searchtype=author&query=Rothfuss%2C+J">Jonas Rothfuss</a>, 
<a href="/search/cs?searchtype=author&query=Sukhija%2C+B">Bhavya Sukhija</a>, 
<a href="/search/cs?searchtype=author&query=As%2C+Y">Yarden As</a>, 
<a href="/search/cs?searchtype=author&query=Hutter%2C+M">Marco Hutter</a>, 
<a href="/search/cs?searchtype=author&query=Coros%2C+S">Stelian Coros</a>, 
<a href="/search/cs?searchtype=author&query=Krause%2C+A">Andreas Krause</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">We introduce PACOH-RL, a novel model-based Meta-Reinforcement Learning
(Meta-RL) algorithm designed to efficiently adapt control policies to changing
dynamics. PACOH-RL meta-learns priors for the dynamics model, allowing swift
adaptation to new dynamics with minimal interaction data. Existing Meta-RL
methods require abundant meta-learning data, limiting their applicability in
settings such as robotics, where data is costly to obtain. To address this,
PACOH-RL incorporates regularization and epistemic uncertainty quantification
in both the meta-learning and task adaptation stages. When facing new dynamics,
we use these uncertainty estimates to effectively guide exploration and data
collection. Overall, this enables positive transfer, even when access to data
from prior tasks or dynamic settings is severely limited. Our experiment
results demonstrate that PACOH-RL outperforms model-based RL and model-based
Meta-RL baselines in adapting to new dynamic conditions. Finally, on a real
robotic car, we showcase the potential for efficient RL policy adaptation in
diverse, data-scarce conditions.
</p>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07559" title="Abstract">arXiv:2311.07559</a> [<a href="/pdf/2311.07559" title="Download PDF">pdf</a>, <a href="/ps/2311.07559" title="Download PostScript">ps</a>, <a href="/format/2311.07559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sound Gradual Verification with Symbolic Execution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zimmerman%2C+C">Conrad Zimmerman</a>, 
<a href="/search/cs?searchtype=author&query=DiVincenzo%2C+J">Jenna DiVincenzo</a>, 
<a href="/search/cs?searchtype=author&query=Aldrich%2C+J">Jonathan Aldrich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Supplementary material; to be published by Principles of Programming Languages 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Gradual verification, which supports explicitly partial specifications and
verifies them with a combination of static and dynamic checks, makes
verification more incremental and provides earlier feedback to developers.
While an abstract, weakest precondition-based approach to gradual verification
was previously proven sound, the approach did not provide sufficient guidance
for implementation and optimization of the required run-time checks. More
recently, gradual verification was implemented using symbolic execution
techniques, but the soundness of the approach (as with related static checkers
based on implicit dynamic frames) was an open question. This paper puts
practical gradual verification on a sound footing with a formalization of
symbolic execution, optimized run-time check generation, and run time
execution. We prove our approach is sound; our proof also covers a core subset
of the Viper tool, for which we are aware of no previous soundness result. Our
formalization enabled us to find a soundness bug in an implemented gradual
verification tool and describe the fix necessary to make it sound.
</p>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07561" title="Abstract">arXiv:2311.07561</a> [<a href="/pdf/2311.07561" title="Download PDF">pdf</a>, <a href="/ps/2311.07561" title="Download PostScript">ps</a>, <a href="/format/2311.07561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Normalized Cross-Correlation for Template Matching with Rotations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Almira%2C+J+M">Jos&#xe9; Mar&#xed;a Almira</a>, 
<a href="/search/cs?searchtype=author&query=Phelippeau%2C+H">Harold Phelippeau</a>, 
<a href="/search/cs?searchtype=author&query=Martinez-Sanchez%2C+A">Antonio Martinez-Sanchez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; General Mathematics (math.GM)

</div>
<p class="mathjax">Normalized cross-correlation is the reference approach to carry out template
matching on images. When it is computed in Fourier space, it can handle
efficiently template translations but it cannot do so with template rotations.
Including rotations requires sampling the whole space of rotations, repeating
the computation of the correlation each time.
<br />This article develops an alternative mathematical theory to handle
efficiently, at the same time, rotations and translations. Our proposal has a
reduced computational complexity because it does not require to repeatedly
sample the space of rotations. To do so, we integrate the information relative
to all rotated versions of the template into a unique symmetric tensor template
-which is computed only once per template-. Afterward, we demonstrate that the
correlation between the image to be processed with the independent tensor
components of the tensorial template contains enough information to recover
template instance positions and rotations.
<br />Our proposed method has the potential to speed up conventional template
matching computations by a factor of several magnitude orders for the case of
3D images.
</p>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07562" title="Abstract">arXiv:2311.07562</a> [<a href="/pdf/2311.07562" title="Download PDF">pdf</a>, <a href="/format/2311.07562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPT-4V in Wonderland: Large Multimodal Models for Zero-Shot Smartphone  GUI Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+A">An Yan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhengyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wanrong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+K">Kevin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Linjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianwei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yiwu Zhong</a>, 
<a href="/search/cs?searchtype=author&query=McAuley%2C+J">Julian McAuley</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jianfeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zicheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lijuan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present MM-Navigator, a GPT-4V-based agent for the smartphone graphical
user interface (GUI) navigation task. MM-Navigator can interact with a
smartphone screen as human users, and determine subsequent actions to fulfill
given instructions. Our findings demonstrate that large multimodal models
(LMMs), specifically GPT-4V, excel in zero-shot GUI navigation through its
advanced screen interpretation, action reasoning, and precise action
localization capabilities. We first benchmark MM-Navigator on our collected iOS
screen dataset. According to human assessments, the system exhibited a 91\%
accuracy rate in generating reasonable action descriptions and a 75\% accuracy
rate in executing the correct actions for single-step instructions on iOS.
Additionally, we evaluate the model on a subset of an Android screen navigation
dataset, where the model outperforms previous GUI navigators in a zero-shot
fashion. Our benchmark and detailed analyses aim to lay a robust groundwork for
future research into the GUI navigation task. The project page is at
https://github.com/zzxslp/MM-Navigator.
</p>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07564" title="Abstract">arXiv:2311.07564</a> [<a href="/pdf/2311.07564" title="Download PDF">pdf</a>, <a href="/format/2311.07564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Authorship Attribution Models Distinguish Speakers in Speech  Transcripts?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aggazzotti%2C+C">Cristina Aggazzotti</a>, 
<a href="/search/cs?searchtype=author&query=Andrews%2C+N">Nicholas Andrews</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+E+A">Elizabeth Allyn Smith</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Authorship verification is the problem of determining if two distinct writing
samples share the same author and is typically concerned with the attribution
of written text. In this paper, we explore the attribution of transcribed
speech, which poses novel challenges. The main challenge is that many stylistic
features, such as punctuation and capitalization, are not available or
reliable. Therefore, we expect a priori that transcribed speech is a more
challenging domain for attribution. On the other hand, other stylistic
features, such as speech disfluencies, may enable more successful attribution
but, being specific to speech, require special purpose models. To better
understand the challenges of this setting, we contribute the first systematic
study of speaker attribution based solely on transcribed speech. Specifically,
we propose a new benchmark for speaker attribution focused on conversational
speech transcripts. To control for spurious associations of speakers with
topic, we employ both conversation prompts and speakers' participating in the
same conversation to construct challenging verification trials of varying
difficulties. We establish the state of the art on this new benchmark by
comparing a suite of neural and non-neural baselines, finding that although
written text attribution models achieve surprisingly good performance in
certain settings, they struggle in the hardest settings we consider.
</p>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07565" title="Abstract">arXiv:2311.07565</a> [<a href="/pdf/2311.07565" title="Download PDF">pdf</a>, <a href="/format/2311.07565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploration via linearly perturbed loss minimisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Janz%2C+D">David Janz</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ayoub%2C+A">Alex Ayoub</a>, 
<a href="/search/cs?searchtype=author&query=Szepesv%C3%A1ri%2C+C">Csaba Szepesv&#xe1;ri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We introduce exploration via linear loss perturbations (EVILL), a randomised
exploration method for structured stochastic bandit problems that works by
solving for the minimiser of a linearly perturbed regularised negative
log-likelihood function. We show that, for the case of generalised linear
bandits, EVILL reduces to perturbed history exploration (PHE), a method where
exploration is done by training on randomly perturbed rewards. In doing so, we
provide a simple and clean explanation of when and why random reward
perturbations give rise to good bandit algorithms. With the data-dependent
perturbations we propose, not present in previous PHE-type methods, EVILL is
shown to match the performance of Thompson-sampling-style
parameter-perturbation methods, both in theory and in practice. Moreover, we
show an example outside of generalised linear bandits where PHE leads to
inconsistent estimates, and thus linear regret, while EVILL remains performant.
Like PHE, EVILL can be implemented in just a few lines of code.
</p>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07568" title="Abstract">arXiv:2311.07568</a> [<a href="/pdf/2311.07568" title="Download PDF">pdf</a>, <a href="/format/2311.07568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature emergence via margin maximization: case studies in algebraic  tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morwani%2C+D">Depen Morwani</a>, 
<a href="/search/cs?searchtype=author&query=Edelman%2C+B+L">Benjamin L. Edelman</a>, 
<a href="/search/cs?searchtype=author&query=Oncescu%2C+C">Costin-Andrei Oncescu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rosie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Kakade%2C+S">Sham Kakade</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Understanding the internal representations learned by neural networks is a
cornerstone challenge in the science of machine learning. While there have been
significant recent strides in some cases towards understanding how neural
networks implement specific target functions, this paper explores a
complementary question -- why do networks arrive at particular computational
strategies? Our inquiry focuses on the algebraic learning tasks of modular
addition, sparse parities, and finite group operations. Our primary theoretical
findings analytically characterize the features learned by stylized neural
networks for these algebraic tasks. Notably, our main technique demonstrates
how the principle of margin maximization alone can be used to fully specify the
features learned by the network. Specifically, we prove that the trained
networks utilize Fourier features to perform modular addition and employ
features corresponding to irreducible group-theoretic representations to
perform compositions in general groups, aligning closely with the empirical
observations of Nanda et al. and Chughtai et al. More generally, we hope our
techniques can help to foster a deeper understanding of why neural networks
adopt specific computational strategies.
</p>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07569" title="Abstract">arXiv:2311.07569</a> [<a href="/pdf/2311.07569" title="Download PDF">pdf</a>, <a href="/format/2311.07569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Load Shedding for Public Safety Power Shutoffs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rao%2C+A+R">Aniruddha Rajendra Rao</a>, 
<a href="/search/eess?searchtype=author&query=Venkatraman%2C+C">Chandrasekar Venkatraman</a>, 
<a href="/search/eess?searchtype=author&query=Ellis%2C+R">Robert Ellis</a>, 
<a href="/search/eess?searchtype=author&query=Gupta%2C+C">Chetan Gupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures, 3 Tables. Accepted at IEEE ETFG 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Public utilities are faced with situations where high winds can bring trees
and debris into contact with energized power lines and other equipments, which
could ignite wildfires. As a result, they need to turn off power during severe
weather to help prevent wildfires. This is called Public Safety Power Shutoff
(PSPS). We present a method for load reduction using a multi-step genetic
algorithm for Public Safety Power Shutoff events. The proposed method optimizes
load shedding using partial load shedding based on load importance (critical
loads like hospitals, fire stations, etc). The multi-step genetic algorithm
optimizes load shedding while minimizing the impact on important loads and
preserving grid stability. The effectiveness of the method is demonstrated
through network examples. The results show that the proposed method achieves
minimal load shedding while maintaining the critical loads at acceptable
levels. This approach will help utilities to effectively manage PSPS events and
reduce the risk of wildfires caused by the power lines.
</p>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07573" title="Abstract">arXiv:2311.07573</a> [<a href="/pdf/2311.07573" title="Download PDF">pdf</a>, <a href="/format/2311.07573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Realizability of Free Spaces of Curves
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akitaya%2C+H+A">Hugo A. Akitaya</a>, 
<a href="/search/cs?searchtype=author&query=Buchin%2C+M">Maike Buchin</a>, 
<a href="/search/cs?searchtype=author&query=Mirzanezhad%2C+M">Majid Mirzanezhad</a>, 
<a href="/search/cs?searchtype=author&query=Ryvkin%2C+L">Leonie Ryvkin</a>, 
<a href="/search/cs?searchtype=author&query=Wenk%2C+C">Carola Wenk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 12 figures, 1 table, International Symposium on Algorithms And Computations (ISAAC 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">The free space diagram is a popular tool to compute the well-known Fr\'echet
distance. As the Fr\'echet distance is used in many different fields, many
variants have been established to cover the specific needs of these
applications. Often, the question arises whether a certain pattern in the free
space diagram is "realizable", i.e., whether there exists a pair of polygonal
chains whose free space diagram corresponds to it. The answer to this question
may help in deciding the computational complexity of these distance measures,
as well as allowing to design more efficient algorithms for restricted input
classes that avoid certain free space patterns. Therefore, we study the inverse
problem: Given a potential free space diagram, do there exist curves that
generate this diagram?
<br />Our problem of interest is closely tied to the classic Distance Geometry
problem. We settle the complexity of Distance Geometry in $\mathbb{R}^{&gt; 2}$,
showing $\exists\mathbb{R}$-hardness. We use this to show that for curves in
$\mathbb{R}^{\ge 2}$, the realizability problem is
$\exists\mathbb{R}$-complete, both for continuous and for discrete Fr\'echet
distance. We prove that the continuous case in $\mathbb{R}^1$ is only weakly
NP-hard, and we provide a pseudo-polynomial time algorithm and show that it is
fixed-parameter tractable. Interestingly, for the discrete case in
$\mathbb{R}^1$, we show that the problem becomes solvable in polynomial time.
</p>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07574" title="Abstract">arXiv:2311.07574</a> [<a href="/pdf/2311.07574" title="Download PDF">pdf</a>, <a href="/format/2311.07574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> To See is to Believe: Prompting GPT-4V for Better Visual Instruction  Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junke Wang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+L">Lingchen Meng</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+Z">Zejia Weng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+B">Bo He</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zuxuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yu-Gang Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> techical report; work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing visual instruction tuning methods typically prompt large language
models with textual descriptions to generate instruction-following data.
Despite the promising performance achieved, these descriptions are derived from
image annotations, which are oftentimes coarse-grained. Furthermore, the
instructions might even contradict the visual content without observing the
entire visual context. To address this challenge, we introduce a fine-grained
visual instruction dataset, LVIS-Instruct4V, which contains 220K visually
aligned and context-aware instructions produced by prompting the powerful
GPT-4V with images from LVIS. Through experimental validation and case studies,
we demonstrate that high-quality visual instructional data could improve the
performance of LLaVA-1.5, a state-of-the-art large multimodal model, across a
wide spectrum of benchmarks by clear margins. Notably, by simply replacing the
LLaVA-Instruct with our LVIS-Instruct4V, we achieve better results than LLaVA
on most challenging LMM benchmarks, e.g., LLaVA$^w$ (76.7 vs. 70.7) and MM-Vet
(40.2 vs. 35.4). We release our data and model at
https://github.com/X2FD/LVIS-INSTRUCT4V.
</p>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07575" title="Abstract">arXiv:2311.07575</a> [<a href="/pdf/2311.07575" title="Download PDF">pdf</a>, <a href="/format/2311.07575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPHINX: The Joint Mixing of Weights, Tasks, and Visual Embeddings for  Multi-modal Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Ziyi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chris Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Renrui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+P">Peng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+L">Longtian Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+H">Han Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+H">Han Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+W">Wenqi Shao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Keqin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jiaming Han</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Siyuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yichi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xuming He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress. Code and demos are released at <a href="https://github.com/Alpha-VLLM/LLaMA2-Accessory">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">We present SPHINX, a versatile multi-modal large language model (MLLM) with a
joint mixing of model weights, tuning tasks, and visual embeddings. First, for
stronger vision-language alignment, we unfreeze the large language model (LLM)
during pre-training, and introduce a weight mix strategy between LLMs trained
by real-world and synthetic data. By directly integrating the weights from two
domains, the mixed LLM can efficiently incorporate diverse semantics with
favorable robustness. Then, to enable multi-purpose capabilities, we mix a
variety of tasks for joint visual instruction tuning, and design task-specific
instructions to avoid inter-task conflict. In addition to the basic visual
question answering, we include more challenging tasks such as region-level
understanding, caption grounding, document layout detection, and human pose
estimation, contributing to mutual enhancement over different scenarios.
Additionally, we propose to extract comprehensive visual embeddings from
various network architectures, pre-training paradigms, and information
granularity, providing language models with more robust image representations.
Based on our proposed joint mixing, SPHINX exhibits superior multi-modal
understanding capabilities on a wide range of applications. On top of this, we
further propose an efficient strategy aiming to better capture fine-grained
appearances of high-resolution images. With a mixing of different scales and
high-resolution sub-images, SPHINX attains exceptional visual parsing and
reasoning performance on existing evaluation benchmarks. We hope our work may
cast a light on the exploration of joint mixing in future MLLM research. Code
is released at https://github.com/Alpha-VLLM/LLaMA2-Accessory.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Tue, 14 Nov 23</h3>
<dl>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17368" title="Abstract">arXiv:2309.17368</a> (cross-list from quant-ph) [<a href="/pdf/2309.17368" title="Download PDF">pdf</a>, <a href="/format/2309.17368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning for Practical Quantum Error Mitigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Liao%2C+H">Haoran Liao</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+D+S">Derek S. Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sitdikov%2C+I">Iskandar Sitdikov</a>, 
<a href="/search/quant-ph?searchtype=author&query=Salcedo%2C+C">Ciro Salcedo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Seif%2C+A">Alireza Seif</a>, 
<a href="/search/quant-ph?searchtype=author&query=Minev%2C+Z+K">Zlatko K. Minev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures (main text) + 4 pages, 2 figures (appendices)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Quantum computers are actively competing to surpass classical supercomputers,
but quantum errors remain their chief obstacle. The key to overcoming these on
near-term devices has emerged through the field of quantum error mitigation,
enabling improved accuracy at the cost of additional runtime. In practice,
however, the success of mitigation is limited by a generally exponential
overhead. Can classical machine learning address this challenge on today's
quantum computers? Here, through both simulations and experiments on
state-of-the-art quantum computers using up to 100 qubits, we demonstrate that
machine learning for quantum error mitigation (ML-QEM) can drastically reduce
overheads, maintain or even surpass the accuracy of conventional methods, and
yield near noise-free results for quantum algorithms. We benchmark a variety of
machine learning models -- linear regression, random forests, multi-layer
perceptrons, and graph neural networks -- on diverse classes of quantum
circuits, over increasingly complex device-noise profiles, under interpolation
and extrapolation, and for small and large quantum circuits. These tests employ
the popular digital zero-noise extrapolation method as an added reference. We
further show how to scale ML-QEM to classically intractable quantum circuits by
mimicking the results of traditional mitigation results, while significantly
reducing overhead. Our results highlight the potential of classical machine
learning for practical quantum computation.
</p>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06251" title="Abstract">arXiv:2311.06251</a> (cross-list from q-fin.GN) [<a href="/pdf/2311.06251" title="Download PDF">pdf</a>, <a href="/ps/2311.06251" title="Download PostScript">ps</a>, <a href="/format/2311.06251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI for Investment: A Platform Disruption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Rasouli%2C+M">Mohammad Rasouli</a>, 
<a href="/search/q-fin?searchtype=author&query=Chiruvolu%2C+R">Ravi Chiruvolu</a>, 
<a href="/search/q-fin?searchtype=author&query=Risheh%2C+A">Ali Risheh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Finance (q-fin.GN)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the investment landscape becoming more competitive, efficiently scaling
deal sourcing and improving deal insights have become a dominant strategy for
funds. While funds are already spending significant efforts on these two tasks,
they cannot be scaled with traditional approaches; hence, there is a surge in
automating them. Many third party software providers have emerged recently to
address this need with productivity solutions, but they fail due to a lack of
personalization for the fund, privacy constraints, and natural limits of
software use cases. Therefore, most major funds and many smaller funds have
started developing their in-house AI platforms: a game changer for the
industry. These platforms grow smarter by direct interactions with the fund and
can be used to provide personalized use cases. Recent developments in large
language models, e.g. ChatGPT, have provided an opportunity for other funds to
also develop their own AI platforms. While not having an AI platform now is not
a competitive disadvantage, it will be in two years. Funds require a practical
plan and corresponding risk assessments for such AI platforms.
</p>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06253" title="Abstract">arXiv:2311.06253</a> (cross-list from physics.ao-ph) [<a href="/pdf/2311.06253" title="Download PDF">pdf</a>, <a href="/format/2311.06253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Parsimonious Deep Learning Weather Prediction using the  HEALPix Mesh
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Karlbauer%2C+M">Matthias Karlbauer</a>, 
<a href="/search/physics?searchtype=author&query=Cresswell-Clay%2C+N">Nathaniel Cresswell-Clay</a>, 
<a href="/search/physics?searchtype=author&query=Moreno%2C+R+A">Raul A. Moreno</a>, 
<a href="/search/physics?searchtype=author&query=Durran%2C+D+R">Dale R. Durran</a>, 
<a href="/search/physics?searchtype=author&query=Kurth%2C+T">Thorsten Kurth</a>, 
<a href="/search/physics?searchtype=author&query=Butz%2C+M+V">Martin V. Butz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We present a parsimonious deep learning weather prediction model on the
Hierarchical Equal Area isoLatitude Pixelization (HEALPix) to forecast seven
atmospheric variables for arbitrarily long lead times on a global approximately
110 km mesh at 3h time resolution. In comparison to state-of-the-art machine
learning weather forecast models, such as Pangu-Weather and GraphCast, our
DLWP-HPX model uses coarser resolution and far fewer prognostic variables. Yet,
at one-week lead times its skill is only about one day behind the
state-of-the-art numerical weather prediction model from the European Centre
for Medium-Range Weather Forecasts. We report successive forecast improvements
resulting from model design and data-related decisions, such as switching from
the cubed sphere to the HEALPix mesh, inverting the channel depth of the U-Net,
and introducing gated recurrent units (GRU) on each level of the U-Net
hierarchy. The consistent east-west orientation of all cells on the HEALPix
mesh facilitates the development of location-invariant convolution kernels that
are successfully applied to propagate global weather patterns across our
planet. Without any loss of spectral power after two days, the model can be
unrolled autoregressively for hundreds of steps into the future to generate
stable and realistic states of the atmosphere that respect seasonal trends, as
showcased in one-year simulations. Our parsimonious DLWP-HPX model is
research-friendly and potentially well-suited for sub-seasonal and seasonal
forecasting.
</p>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06256" title="Abstract">arXiv:2311.06256</a> (cross-list from q-fin.ST) [<a href="/pdf/2311.06256" title="Download PDF">pdf</a>, <a href="/format/2311.06256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Deep Filtering to Deep Econometrics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Stok%2C+R">Robert Stok</a>, 
<a href="/search/q-fin?searchtype=author&query=Bilokon%2C+P">Paul Bilokon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO); Econometrics (econ.EM); Computational Finance (q-fin.CP)

</div>
<p class="mathjax">Calculating true volatility is an essential task for option pricing and risk
management. However, it is made difficult by market microstructure noise.
Particle filtering has been proposed to solve this problem as it favorable
statistical properties, but relies on assumptions about underlying market
dynamics. Machine learning methods have also been proposed but lack
interpretability, and often lag in performance. In this paper we implement the
SV-PF-RNN: a hybrid neural network and particle filter architecture. Our
SV-PF-RNN is designed specifically with stochastic volatility estimation in
mind. We then show that it can improve on the performance of a basic particle
filter.
</p>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06276" title="Abstract">arXiv:2311.06276</a> (cross-list from eess.IV) [<a href="/pdf/2311.06276" title="Download PDF">pdf</a>, <a href="/format/2311.06276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing the machine vision performance with multi-spectral light  sources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+F">Feng Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Bao%2C+R">Rui Bao</a>, 
<a href="/search/eess?searchtype=author&query=Dai%2C+C">Congqi Dai</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+W">Wanlu Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+S">Shu Liu</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+R">Ruiqian Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This study mainly focuses on the performance of different multi-spectral
light sources on different object colors in machine vision and tries to enhance
machine vision with multi-spectral light sources. Using different color pencils
as samples, by recognizing the collected images with two classical neural
networks, AlexNet and VGG19, the performance was investigated under 35
different multi-spectral light sources. The results show that for both models
there are always some non-pure white light sources, whose accuracy is better
than pure white light, which suggests the potential of multi-spectral light
sources to further enhance the effectiveness of machine vision. The comparison
of both models is also performed, and surprised to find that the overall
performance of VGG19 is lower than that of AlexNet, which shows that the
importance of the choice of multi-spectral light sources and models.
</p>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06278" title="Abstract">arXiv:2311.06278</a> (cross-list from q-fin.ST) [<a href="/pdf/2311.06278" title="Download PDF">pdf</a>, <a href="/ps/2311.06278" title="Download PostScript">ps</a>, <a href="/format/2311.06278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Stock Price Prediction with Anticipated Macro Policy Changes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Haque%2C+M+S">Md Sabbirul Haque</a>, 
<a href="/search/q-fin?searchtype=author&query=Amin%2C+M+S">Md Shahedul Amin</a>, 
<a href="/search/q-fin?searchtype=author&query=Miah%2C+J">Jonayet Miah</a>, 
<a href="/search/q-fin?searchtype=author&query=Cao%2C+D+M">Duc Minh Cao</a>, 
<a href="/search/q-fin?searchtype=author&query=Ahmed%2C+A+H">Ashiqul Haque Ahmed</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Mathematics and Statistics Studies, 4(3), 29-34 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Prediction of stock prices plays a significant role in aiding the
decision-making of investors. Considering its importance, a growing literature
has emerged trying to forecast stock prices with improved accuracy. In this
study, we introduce an innovative approach for forecasting stock prices with
greater accuracy. We incorporate external economic environment-related
information along with stock prices. In our novel approach, we improve the
performance of stock price prediction by taking into account variations due to
future expected macroeconomic policy changes as investors adjust their current
behavior ahead of time based on expected future macroeconomic policy changes.
Furthermore, we incorporate macroeconomic variables along with historical stock
prices to make predictions. Results from this strongly support the inclusion of
future economic policy changes along with current macroeconomic information. We
confirm the supremacy of our method over the conventional approach using
several tree-based machine-learning algorithms. Results are strongly conclusive
across various machine learning models. Our preferred model outperforms the
conventional approach with an RMSE value of 1.61 compared to an RMSE value of
1.75 from the conventional approach.
</p>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06280" title="Abstract">arXiv:2311.06280</a> (cross-list from q-fin.ST) [<a href="/pdf/2311.06280" title="Download PDF">pdf</a>, <a href="/format/2311.06280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Data-driven Deep Learning Approach for Bitcoin Price Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Modi%2C+P+D">Parth Daxesh Modi</a>, 
<a href="/search/q-fin?searchtype=author&query=Arshi%2C+K">Kamyar Arshi</a>, 
<a href="/search/q-fin?searchtype=author&query=Kunz%2C+P+J">Pertami J. Kunz</a>, 
<a href="/search/q-fin?searchtype=author&query=Zoubir%2C+A+M">Abdelhak M. Zoubir</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">Bitcoin as a cryptocurrency has been one of the most important digital coins
and the first decentralized digital currency. Deep neural networks, on the
other hand, has shown promising results recently; however, we require huge
amount of high-quality data to leverage their power. There are some techniques
such as augmentation that can help us with increasing the dataset size, but we
cannot exploit them on historical bitcoin data. As a result, we propose a
shallow Bidirectional-LSTM (Bi-LSTM) model, fed with feature engineered data
using our proposed method to forecast bitcoin closing prices in a daily time
frame. We compare the performance with that of other forecasting methods, and
show that with the help of the proposed feature engineering method, a shallow
deep neural network outperforms other popular price forecasting models.
</p>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06284" title="Abstract">arXiv:2311.06284</a> (cross-list from physics.comp-ph) [<a href="/pdf/2311.06284" title="Download PDF">pdf</a>, <a href="/format/2311.06284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Generation of Multimodal Fluid Simulation Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Baieri%2C+D">Daniele Baieri</a>, 
<a href="/search/physics?searchtype=author&query=Crisostomi%2C+D">Donato Crisostomi</a>, 
<a href="/search/physics?searchtype=author&query=Esposito%2C+S">Stefano Esposito</a>, 
<a href="/search/physics?searchtype=author&query=Maggioli%2C+F">Filippo Maggioli</a>, 
<a href="/search/physics?searchtype=author&query=Rodol%C3%A0%2C+E">Emanuele Rodol&#xe0;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Graphics (cs.GR); Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">Applying the representational power of machine learning to the prediction of
complex fluid dynamics has been a relevant subject of study for years. However,
the amount of available fluid simulation data does not match the notoriously
high requirements of machine learning methods. Researchers have typically
addressed this issue by generating their own datasets, preventing a consistent
evaluation of their proposed approaches. Our work introduces a generation
procedure for synthetic multi-modal fluid simulations datasets. By leveraging a
GPU implementation, our procedure is also efficient enough that no data needs
to be exchanged between users, except for configuration files required to
reproduce the dataset. Furthermore, our procedure allows multiple modalities
(generating both geometry and photorealistic renderings) and is general enough
for it to be applied to various tasks in data-driven fluid simulation. We then
employ our framework to generate a set of thoughtfully designed benchmark
datasets, which attempt to span specific fluid simulation scenarios in a
meaningful way. The properties of our contributions are demonstrated by
evaluating recently published algorithms for the neural fluid simulation and
fluid inverse rendering tasks using our benchmark datasets. Our contribution
aims to fulfill the community's need for standardized benchmarks, fostering
research that is more reproducible and robust than previous endeavors.
</p>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06292" title="Abstract">arXiv:2311.06292</a> (cross-list from q-fin.ST) [<a href="/pdf/2311.06292" title="Download PDF">pdf</a>, <a href="/format/2311.06292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a data-driven debt collection strategy based on an advanced  machine learning framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Sancarlos%2C+A">Abel Sancarlos</a>, 
<a href="/search/q-fin?searchtype=author&query=Bahilo%2C+E">Edgar Bahilo</a>, 
<a href="/search/q-fin?searchtype=author&query=Mozo%2C+P">Pablo Mozo</a>, 
<a href="/search/q-fin?searchtype=author&query=Norman%2C+L">Lukas Norman</a>, 
<a href="/search/q-fin?searchtype=author&query=Rehma%2C+O+U">Obaid Ur Rehma</a>, 
<a href="/search/q-fin?searchtype=author&query=Anufrijevs%2C+M">Mihails Anufrijevs</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The European debt purchase market as measured by the total book value of
purchased debt approached 25bn euros in 2020 and it was growing at double-digit
rates. This is an example of how big the debt collection and debt purchase
industry has grown and the important impact it has in the financial sector.
However, in order to ensure an adequate return during the debt collection
process, a good estimation of the propensity to pay and/or the expected
cashflow is crucial. These estimations can be employed, for instance, to create
different strategies during the amicable collection to maximize quality
standards and revenues. And not only that, but also to prioritize the cases in
which a legal process is necessary when debtors are unreachable for an amicable
negotiation. This work offers a solution for these estimations. Specifically, a
new machine learning modelling pipeline is presented showing how outperforms
current strategies employed in the sector. The solution contains a
pre-processing pipeline and a model selector based on the best model
calibration. Performance is validated with real historical data of the debt
industry.
</p>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06293" title="Abstract">arXiv:2311.06293</a> (cross-list from quant-ph) [<a href="/pdf/2311.06293" title="Download PDF">pdf</a>, <a href="/ps/2311.06293" title="Download PostScript">ps</a>, <a href="/format/2311.06293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Neural Networks for Power Flow Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Kaseb%2C+Z">Zeynab Kaseb</a>, 
<a href="/search/quant-ph?searchtype=author&query=Moller%2C+M">Matthias Moller</a>, 
<a href="/search/quant-ph?searchtype=author&query=Balducci%2C+G+T">Giorgio Tosti Balducci</a>, 
<a href="/search/quant-ph?searchtype=author&query=Palensky%2C+P">Peter Palensky</a>, 
<a href="/search/quant-ph?searchtype=author&query=Vergara%2C+P+P">Pedro P. Vergara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper explores the potential application of quantum and hybrid
quantum-classical neural networks in power flow analysis. Experiments are
conducted using two small-size datasets based on the IEEE 4-bus and 33-bus test
systems. A systematic performance comparison is also conducted among quantum,
hybrid quantum-classical, and classical neural networks. The comparison is
based on (i) generalization ability, (ii) robustness, (iii) training dataset
size needed, (iv) training error. (v) training computational time, and (vi)
training process stability. The results show that the developed
quantum-classical neural network outperforms both quantum and classical neural
networks, and hence can improve deep learning-based power flow analysis in the
noisy-intermediate-scale quantum (NISQ) era.
</p>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06295" title="Abstract">arXiv:2311.06295</a> (cross-list from physics.chem-ph) [<a href="/pdf/2311.06295" title="Download PDF">pdf</a>, <a href="/format/2311.06295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradual Optimization Learning for Conformational Energy Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Tsypin%2C+A">Artem Tsypin</a>, 
<a href="/search/physics?searchtype=author&query=Ugadiarov%2C+L">Leonid Ugadiarov</a>, 
<a href="/search/physics?searchtype=author&query=Khrabrov%2C+K">Kuzma Khrabrov</a>, 
<a href="/search/physics?searchtype=author&query=Avetisian%2C+M">Manvel Avetisian</a>, 
<a href="/search/physics?searchtype=author&query=Telepov%2C+A">Alexander Telepov</a>, 
<a href="/search/physics?searchtype=author&query=Rumiantsev%2C+E">Egor Rumiantsev</a>, 
<a href="/search/physics?searchtype=author&query=Skrynnik%2C+A">Alexey Skrynnik</a>, 
<a href="/search/physics?searchtype=author&query=Panov%2C+A+I">Aleksandr I. Panov</a>, 
<a href="/search/physics?searchtype=author&query=Vetrov%2C+D">Dmitry Vetrov</a>, 
<a href="/search/physics?searchtype=author&query=Tutubalina%2C+E">Elena Tutubalina</a>, 
<a href="/search/physics?searchtype=author&query=Kadurin%2C+A">Artur Kadurin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Molecular conformation optimization is crucial to computer-aided drug
discovery and materials design. Traditional energy minimization techniques rely
on iterative optimization methods that use molecular forces calculated by a
physical simulator (oracle) as anti-gradients. However, this is a
computationally expensive approach that requires many interactions with a
physical simulator. One way to accelerate this procedure is to replace the
physical simulator with a neural network. Despite recent progress in neural
networks for molecular conformation energy prediction, such models are prone to
distribution shift, leading to inaccurate energy minimization. We find that the
quality of energy minimization with neural networks can be improved by
providing optimization trajectories as additional training data. Still, it
takes around $5 \times 10^5$ additional conformations to match the physical
simulator's optimization quality. In this work, we present the Gradual
Optimization Learning Framework (GOLF) for energy minimization with neural
networks that significantly reduces the required additional data. The framework
consists of an efficient data-collecting scheme and an external optimizer. The
external optimizer utilizes gradients from the energy prediction model to
generate optimization trajectories, and the data-collecting scheme selects
additional training data to be processed by the physical simulator. Our results
demonstrate that the neural network trained with GOLF performs on par with the
oracle on a benchmark of diverse drug-like molecules using $50$x less
additional data.
</p>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06297" title="Abstract">arXiv:2311.06297</a> (cross-list from physics.chem-ph) [<a href="/pdf/2311.06297" title="Download PDF">pdf</a>, <a href="/format/2311.06297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STRIDE: Structure-guided Generation for Inverse Design of Molecules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Zaman%2C+S">Shehtab Zaman</a>, 
<a href="/search/physics?searchtype=author&query=Akhiyarov%2C+D">Denis Akhiyarov</a>, 
<a href="/search/physics?searchtype=author&query=Araya-Polo%2C+M">Mauricio Araya-Polo</a>, 
<a href="/search/physics?searchtype=author&query=Chiu%2C+K">Kenneth Chiu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Machine learning and especially deep learning has had an increasing impact on
molecule and materials design. In particular, given the growing access to an
abundance of high-quality small molecule data for generative modeling for drug
design, results for drug discovery have been promising. However, for many
important classes of materials such as catalysts, antioxidants, and
metal-organic frameworks, such large datasets are not available. Such families
of molecules with limited samples and structural similarities are especially
prevalent for industrial applications. As is well-known, retraining and even
fine-tuning are challenging on such small datasets. Novel, practically
applicable molecules are most often derivatives of well-known molecules,
suggesting approaches to addressing data scarcity. To address this problem, we
introduce $\textbf{STRIDE}$, a generative molecule workflow that generates
novel molecules with an unconditional generative model guided by known
molecules without any retraining. We generate molecules outside of the training
data from a highly specialized set of antioxidant molecules. Our generated
molecules have on average 21.7% lower synthetic accessibility scores and also
reduce ionization potential by 5.9% of generated molecules via guiding.
</p>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06303" title="Abstract">arXiv:2311.06303</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2311.06303" title="Download PDF">pdf</a>, <a href="/format/2311.06303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MatNexus: A Comprehensive Text Mining and Analysis Suite for Materials  Discover
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Stricker%2C+M">Markus Stricker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 6 figures, submission to SoftwareX
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Computation and Language (cs.CL); Chemical Physics (physics.chem-ph)

</div>
<p class="mathjax">MatNexus is a specialized software for the automated collection, processing,
and analysis of text from scientific articles. Through an integrated suite of
modules, the MatNexus facilitates the retrieval of scientific articles,
processes textual data for insights, generates vector representations suitable
for machine learning, and offers visualization capabilities for word
embeddings. With the vast volume of scientific publications, MatNexus stands
out as an end-to-end tool for researchers aiming to gain insights from
scientific literature in material science, making the exploration of materials,
such as the electrocatalyst examples we show here, efficient and insightful.
</p>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06310" title="Abstract">arXiv:2311.06310</a> (cross-list from physics.soc-ph) [<a href="/pdf/2311.06310" title="Download PDF">pdf</a>, <a href="/format/2311.06310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $\textit{Labor Space}$: A Unifying Representation of the Labor Market  via Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Kim%2C+S">Seongwoon Kim</a>, 
<a href="/search/physics?searchtype=author&query=Ahn%2C+Y">Yong-Yeol Ahn</a>, 
<a href="/search/physics?searchtype=author&query=Park%2C+J">Jaehyuk Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The labor market is a complex ecosystem comprising diverse, interconnected
entities, such as industries, occupations, skills, and firms. Due to the lack
of a systematic method to map these heterogeneous entities together, each
entity has been analyzed in isolation or only through pairwise relationships,
inhibiting comprehensive understanding of the whole ecosystem. Here, we
introduce $\textit{Labor Space}$, a vector-space embedding of heterogeneous
labor market entities, derived through applying a large language model with
fine-tuning. Labor Space exposes the complex relational fabric of various labor
market constituents, facilitating coherent integrative analysis of industries,
occupations, skills, and firms, while retaining type-specific clustering. We
demonstrate its unprecedented analytical capacities, including positioning
heterogeneous entities on an economic axes, such as
`Manufacturing--Healthcare'. Furthermore, by allowing vector arithmetic of
these entities, Labor Space enables the exploration of complex inter-unit
relations, and subsequently the estimation of the ramifications of economic
shocks on individual units and their ripple effect across the labor market. We
posit that Labor Space provides policymakers and business leaders with a
comprehensive unifying framework for labor market analysis and simulation,
fostering more nuanced and effective strategic decision-making.
</p>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06374" title="Abstract">arXiv:2311.06374</a> (cross-list from math.OC) [<a href="/pdf/2311.06374" title="Download PDF">pdf</a>, <a href="/format/2311.06374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Higher-Order Newton Methods with Polynomial Work per Iteration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ahmadi%2C+A+A">Amir Ali Ahmadi</a>, 
<a href="/search/math?searchtype=author&query=Chaudhry%2C+A">Abraar Chaudhry</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+J">Jeffrey Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We present generalizations of Newton's method that incorporate derivatives of
an arbitrary order $d$ but maintain a polynomial dependence on dimension in
their cost per iteration. At each step, our $d^{\text{th}}$-order method uses
semidefinite programming to construct and minimize a sum of squares-convex
approximation to the $d^{\text{th}}$-order Taylor expansion of the function we
wish to minimize. We prove that our $d^{\text{th}}$-order method has local
convergence of order $d$. This results in lower oracle complexity compared to
the classical Newton method. We show on numerical examples that basins of
attraction around local minima can get larger as $d$ increases. Under
additional assumptions, we present a modified algorithm, again with polynomial
cost per iteration, which is globally convergent and has local convergence of
order $d$.
</p>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06394" title="Abstract">arXiv:2311.06394</a> (cross-list from eess.IV) [<a href="/pdf/2311.06394" title="Download PDF">pdf</a>, <a href="/ps/2311.06394" title="Download PostScript">ps</a>, <a href="/format/2311.06394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A design of Convolutional Neural Network model for the Diagnosis of the  COVID-19
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Song%2C+X">Xinyuan Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">With the spread of COVID-19 around the globe over the past year, the usage of
artificial intelligence (AI) algorithms and image processing methods to analyze
the X-ray images of patients' chest with COVID-19 has become essential. The
COVID-19 virus recognition in the lung area of a patient is one of the basic
and essential needs of clicical centers and hospitals. Most research in this
field has been devoted to papers on the basis of deep learning methods
utilizing CNNs (Convolutional Neural Network), which mainly deal with the
screening of sick and healthy people.In this study, a new structure of a
19-layer CNN has been recommended for accurately recognition of the COVID-19
from the X-ray pictures of chest. The offered CNN is developed to serve as a
precise diagnosis system for a three class (viral pneumonia, Normal, COVID) and
a four classclassification (Lung opacity, Normal, COVID-19, and pneumonia). A
comparison is conducted among the outcomes of the offered procedure and some
popular pretrained networks, including Inception, Alexnet, ResNet50,
Squeezenet, and VGG19 and based on Specificity, Accuracy, Precision,
Sensitivity, Confusion Matrix, and F1-score. The experimental results of the
offered CNN method specify its dominance over the existing published
procedures. This method can be a useful tool for clinicians in deciding
properly about COVID-19.
</p>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06395" title="Abstract">arXiv:2311.06395</a> (cross-list from stat.ML) [<a href="/pdf/2311.06395" title="Download PDF">pdf</a>, <a href="/format/2311.06395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A statistical perspective on algorithm unrolling models for inverse  problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Atchade%2C+Y">Yves Atchade</a>, 
<a href="/search/stat?searchtype=author&query=Liu%2C+X">Xinru Liu</a>, 
<a href="/search/stat?searchtype=author&query=Zhu%2C+Q">Qiuyun Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We consider inverse problems where the conditional distribution of the
observation ${\bf y}$ given the latent variable of interest ${\bf x}$ (also
known as the forward model) is known, and we have access to a data set in which
multiple instances of ${\bf x}$ and ${\bf y}$ are both observed. In this
context, algorithm unrolling has become a very popular approach for designing
state-of-the-art deep neural network architectures that effectively exploit the
forward model. We analyze the statistical complexity of the gradient descent
network (GDN), an algorithm unrolling architecture driven by proximal gradient
descent. We show that the unrolling depth needed for the optimal statistical
performance of GDNs is of order $\log(n)/\log(\varrho_n^{-1})$, where $n$ is
the sample size, and $\varrho_n$ is the convergence rate of the corresponding
gradient descent algorithm. We also show that when the negative log-density of
the latent variable ${\bf x}$ has a simple proximal operator, then a GDN
unrolled at depth $D'$ can solve the inverse problem at the parametric rate
$O(D'/\sqrt{n})$. Our results thus also suggest that algorithm unrolling models
are prone to overfitting as the unrolling depth $D'$ increases. We provide
several examples to illustrate these results.
</p>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06404" title="Abstract">arXiv:2311.06404</a> (cross-list from math.OC) [<a href="/pdf/2311.06404" title="Download PDF">pdf</a>, <a href="/format/2311.06404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augmented Lagrangian Methods as Layered Control Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Srikanthan%2C+A">Anusha Srikanthan</a>, 
<a href="/search/math?searchtype=author&query=Kumar%2C+V">Vijay Kumar</a>, 
<a href="/search/math?searchtype=author&query=Matni%2C+N">Nikolai Matni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">For optimal control problems that involve planning and following a
trajectory, two degree of freedom (2DOF) controllers are a ubiquitously used
control architecture that decomposes the problem into a trajectory generation
layer and a feedback control layer. However, despite the broad use and
practical success of this layered control architecture, it remains a design
choice that must be imposed $a\ priori$ on the control policy. To address this
gap, this paper seeks to initiate a principled study of the design of layered
control architectures, with an initial focus on the 2DOF controller. We show
that applying the Alternating Direction Method of Multipliers (ADMM) algorithm
to solve a strategically rewritten optimal control problem results in solutions
that are naturally layered, and composed of a trajectory generation layer and a
feedback control layer. Furthermore, these layers are coupled via Lagrange
multipliers that ensure dynamic feasibility of the planned trajectory. We
instantiate this framework in the context of deterministic and stochastic
linear optimal control problems, and show how our approach automatically yields
a feedforward/feedback-based control policy that exactly solves the original
problem. We then show that the simplicity of the resulting controller structure
suggests natural heuristic algorithms for approximately solving nonlinear
optimal control problems. We empirically demonstrate improved performance of
these layered nonlinear optimal controllers as compared to iLQR, and highlight
their flexibility by incorporating both convex and nonconvex constraints.
</p>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06489" title="Abstract">arXiv:2311.06489</a> (cross-list from math-ph) [<a href="/pdf/2311.06489" title="Download PDF">pdf</a>, <a href="/ps/2311.06489" title="Download PostScript">ps</a>, <a href="/format/2311.06489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lattice sums of $I$-Bessel functions, theta functions, linear codes and  heat equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math-ph?searchtype=author&query=Hasegawa%2C+T">Takehiro Hasegawa</a>, 
<a href="/search/math-ph?searchtype=author&query=Saigo%2C+H">Hayato Saigo</a>, 
<a href="/search/math-ph?searchtype=author&query=Saito%2C+S">Seiken Saito</a>, 
<a href="/search/math-ph?searchtype=author&query=Sugiyama%2C+S">Shingo Sugiyama</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Physics (math-ph)</span>; Information Theory (cs.IT); Number Theory (math.NT)

</div>
<p class="mathjax">We extend a certain type of identities on sums of $I$-Bessel functions on
lattices, previously given by G. Chinta, J. Jorgenson, A Karlsson and M.
Neuhauser. Moreover we prove that, with continuum limit, the transformation
formulas of theta functions such as the Dedekind eta function can be given by
$I$-Bessel lattice sum identities with characters. We consider analogues of
theta functions of lattices coming from linear codes and show that sums of
$I$-Bessel functions defined by linear codes can be expressed by complete
weight enumerators. We also prove that $I$-Bessel lattice sums appear as
solutions of heat equations on general lattices. As a further application, we
obtain an explicit solution of the heat equation on $\mathbb{Z}^n$ whose
initial condition is given by a linear code.
</p>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06510" title="Abstract">arXiv:2311.06510</a> (cross-list from eess.IV) [<a href="/pdf/2311.06510" title="Download PDF">pdf</a>, <a href="/format/2311.06510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Band-wise Hyperspectral Image Pansharpening using CNN Model Propagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Guarino%2C+G">Giuseppe Guarino</a>, 
<a href="/search/eess?searchtype=author&query=Ciotola%2C+M">Matteo Ciotola</a>, 
<a href="/search/eess?searchtype=author&query=Vivone%2C+G">Gemine Vivone</a>, 
<a href="/search/eess?searchtype=author&query=Scarpa%2C+G">Giuseppe Scarpa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Hyperspectral pansharpening is receiving a growing interest since the last
few years as testified by a large number of research papers and challenges. It
consists in a pixel-level fusion between a lower-resolution hyperspectral
datacube and a higher-resolution single-band image, the panchromatic image,
with the goal of providing a hyperspectral datacube at panchromatic resolution.
Thanks to their powerful representational capabilities, deep learning models
have succeeded to provide unprecedented results on many general purpose image
processing tasks. However, when moving to domain specific problems, as in this
case, the advantages with respect to traditional model-based approaches are
much lesser clear-cut due to several contextual reasons. Scarcity of training
data, lack of ground-truth, data shape variability, are some such factors that
limit the generalization capacity of the state-of-the-art deep learning
networks for hyperspectral pansharpening. To cope with these limitations, in
this work we propose a new deep learning method which inherits a simple
single-band unsupervised pansharpening model nested in a sequential band-wise
adaptive scheme, where each band is pansharpened refining the model tuned on
the preceding one. By doing so, a simple model is propagated along the
wavelength dimension, adaptively and flexibly, with no need to have a fixed
number of spectral bands, and, with no need to dispose of large, expensive and
labeled training datasets. The proposed method achieves very good results on
our datasets, outperforming both traditional and deep learning reference
methods. The implementation of the proposed method can be found on
https://github.com/giu-guarino/R-PNN
</p>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06528" title="Abstract">arXiv:2311.06528</a> (cross-list from math.OC) [<a href="/pdf/2311.06528" title="Download PDF">pdf</a>, <a href="/format/2311.06528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inertial control of a spinning flat disk
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jaulin%2C+L">Luc Jaulin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">This paper proposes a Lyapunov based approach to control the rotation of a
flat disk spinning in the space without external forces. The motion of the disk
is governed by the Euler's rotation equation for spinning objects. The control
is made through the inertia matrix of the disk.
</p>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06552" title="Abstract">arXiv:2311.06552</a> (cross-list from eess.IV) [<a href="/pdf/2311.06552" title="Download PDF">pdf</a>, <a href="/format/2311.06552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stain Consistency Learning: Handling Stain Variation for Automatic  Digital Pathology Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yeung%2C+M">Michael Yeung</a>, 
<a href="/search/eess?searchtype=author&query=Watts%2C+T">Todd Watts</a>, 
<a href="/search/eess?searchtype=author&query=Tan%2C+S+Y">Sean YW Tan</a>, 
<a href="/search/eess?searchtype=author&query=Ferreira%2C+P+F">Pedro F. Ferreira</a>, 
<a href="/search/eess?searchtype=author&query=Scott%2C+A+D">Andrew D. Scott</a>, 
<a href="/search/eess?searchtype=author&query=Nielles-Vallespin%2C+S">Sonia Nielles-Vallespin</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+G">Guang Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Stain variation is a unique challenge associated with automated analysis of
digital pathology. Numerous methods have been developed to improve the
robustness of machine learning methods to stain variation, but comparative
studies have demonstrated limited benefits to performance. Moreover, methods to
handle stain variation were largely developed for H&amp;E stained data, with
evaluation generally limited to classification tasks. Here we propose Stain
Consistency Learning, a novel framework combining stain-specific augmentation
with a stain consistency loss function to learn stain colour invariant
features. We perform the first, extensive comparison of methods to handle stain
variation for segmentation tasks, comparing ten methods on Masson's trichrome
and H&amp;E stained cell and nuclei datasets, respectively. We observed that stain
normalisation methods resulted in equivalent or worse performance, while stain
augmentation or stain adversarial methods demonstrated improved performance,
with the best performance consistently achieved by our proposed approach. The
code is available at: https://github.com/mlyg/stain_consistency_learning
</p>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06557" title="Abstract">arXiv:2311.06557</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2311.06557" title="Download PDF">pdf</a>, <a href="/format/2311.06557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identification of vortex in unstructured mesh with graph neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Wang%2C+L">Lianfa Wang</a>, 
<a href="/search/physics?searchtype=author&query=Fournier%2C+Y">Yvan Fournier</a>, 
<a href="/search/physics?searchtype=author&query=Wald%2C+J">Jean-Francois Wald</a>, 
<a href="/search/physics?searchtype=author&query=Mesri%2C+Y">Youssef Mesri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the journal Computers &amp; Fluids
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computers and fluids, Volume 268, (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Deep learning has been employed to identify flow characteristics from
Computational Fluid Dynamics (CFD) databases to assist the researcher to better
understand the flow field, to optimize the geometry design and to select the
correct CFD configuration for corresponding flow characteristics. Convolutional
Neural Network (CNN) is one of the most popular algorithms used to extract and
identify flow features. However its use, without any additional flow field
interpolation, is limited to the simple domain geometry and regular meshes
which limits its application to real industrial cases where complex geometry
and irregular meshes are usually used. Aiming at the aforementioned problems,
we present a Graph Neural Network (GNN) based model with U-Net architecture to
identify the vortex in CFD results on unstructured meshes. The graph generation
and graph hierarchy construction using algebraic multigrid method from CFD
meshes are introduced. A vortex auto-labeling method is proposed to label
vortex regions in 2D CFD meshes. We precise our approach by firstly optimizing
the input set on CNNs, then benchmarking current GNN kernels against CNN model
and evaluating the performances of GNN kernels in terms of classification
accuracy, training efficiency and identified vortex morphology. Finally, we
demonstrate the adaptability of our approach to unstructured meshes and
generality to unseen cases with different turbulence models at different
Reynolds numbers.
</p>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06572" title="Abstract">arXiv:2311.06572</a> (cross-list from eess.IV) [<a href="/pdf/2311.06572" title="Download PDF">pdf</a>, <a href="/format/2311.06572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Swin UNETR++: Advancing Transformer-Based Dense Dose Prediction Towards  Fully Automated Radiation Oncology Treatments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+K">Kuancheng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Tan%2C+H+S">Hai Siong Tan</a>, 
<a href="/search/eess?searchtype=author&query=Mcbeth%2C+R">Rafe Mcbeth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2023, December 10th, 2023, New Orleans, United States, 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The field of Radiation Oncology is uniquely positioned to benefit from the
use of artificial intelligence to fully automate the creation of radiation
treatment plans for cancer therapy. This time-consuming and specialized task
combines patient imaging with organ and tumor segmentation to generate a 3D
radiation dose distribution to meet clinical treatment goals, similar to
voxel-level dense prediction. In this work, we propose Swin UNETR++, that
contains a lightweight 3D Dual Cross-Attention (DCA) module to capture the
intra and inter-volume relationships of each patient's unique anatomy, which
fully convolutional neural networks lack. Our model was trained, validated, and
tested on the Open Knowledge-Based Planning dataset. In addition to metrics of
Dose Score $\overline{S_{\text{Dose}}}$ and DVH Score
$\overline{S_{\text{DVH}}}$ that quantitatively measure the difference between
the predicted and ground-truth 3D radiation dose distribution, we propose the
qualitative metrics of average volume-wise acceptance rate
$\overline{R_{\text{VA}}}$ and average patient-wise clinical acceptance rate
$\overline{R_{\text{PA}}}$ to assess the clinical reliability of the
predictions. Swin UNETR++ demonstrates near-state-of-the-art performance on
validation and test dataset (validation: $\overline{S_{\text{DVH}}}$=1.492 Gy,
$\overline{S_{\text{Dose}}}$=2.649 Gy, $\overline{R_{\text{VA}}}$=88.58%,
$\overline{R_{\text{PA}}}$=100.0%; test: $\overline{S_{\text{DVH}}}$=1.634 Gy,
$\overline{S_{\text{Dose}}}$=2.757 Gy, $\overline{R_{\text{VA}}}$=90.50%,
$\overline{R_{\text{PA}}}$=98.0%), establishing a basis for future studies to
translate 3D dose predictions into a deliverable treatment plan, facilitating
full automation.
</p>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06573" title="Abstract">arXiv:2311.06573</a> (cross-list from quant-ph) [<a href="/pdf/2311.06573" title="Download PDF">pdf</a>, <a href="/format/2311.06573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Generalized Space-Efficient Algorithm for Quantum Bit String  Comparators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Shahzad%2C+K">Khuram Shahzad</a>, 
<a href="/search/quant-ph?searchtype=author&query=Khan%2C+O+U">Omar Usman Khan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Quantum Bit String Comparators (QBSC) operate on two sequences of n-qubits,
enabling the determination of their relationships, such as equality, greater
than, or less than. This is analogous to the way conditional statements are
used in programming languages. Consequently, QBSCs play a crucial role in
various algorithms that can be executed or adapted for quantum computers. The
development of efficient and generalized comparators for any $n$-qubit length
has long posed a challenge, as they have a high-cost footprint and lead to
quantum delays. Comparators that are efficient are associated with inputs of
fixed length. As a result, comparators without a generalized circuit cannot be
employed at a higher level, though they are well-suited for problems with
limited size requirements. In this paper, we introduce a generalized design for
the comparison of two $n$-qubit logic states using just two ancillary bits. The
design is examined on the basis of qubit requirements, ancillary bit usage,
quantum cost, quantum delay, gate operations, and circuit complexity, and is
tested comprehensively on various input lengths. The work allows for sufficient
flexibility in the design of quantum algorithms, which can accelerate quantum
algorithm development.
</p>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06631" title="Abstract">arXiv:2311.06631</a> (cross-list from eess.IV) [<a href="/pdf/2311.06631" title="Download PDF">pdf</a>, <a href="/format/2311.06631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A 3D Conditional Diffusion Model for Image Quality Transfer -- An  Application to Low-Field MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kim%2C+S">Seunghoi Kim</a>, 
<a href="/search/eess?searchtype=author&query=Tregidgo%2C+H+F+J">Henry F. J. Tregidgo</a>, 
<a href="/search/eess?searchtype=author&query=Eldaly%2C+A+K">Ahmed K. Eldaly</a>, 
<a href="/search/eess?searchtype=author&query=Figini%2C+M">Matteo Figini</a>, 
<a href="/search/eess?searchtype=author&query=Alexander%2C+D+C">Daniel C. Alexander</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Low-field (LF) MRI scanners (&lt;1T) are still prevalent in settings with
limited resources or unreliable power supply. However, they often yield images
with lower spatial resolution and contrast than high-field (HF) scanners. This
quality disparity can result in inaccurate clinician interpretations. Image
Quality Transfer (IQT) has been developed to enhance the quality of images by
learning a mapping function between low and high-quality images. Existing IQT
models often fail to restore high-frequency features, leading to blurry output.
In this paper, we propose a 3D conditional diffusion model to improve 3D
volumetric data, specifically LF MR images. Additionally, we incorporate a
cross-batch mechanism into the self-attention and padding of our network,
ensuring broader contextual awareness even under small 3D patches. Experiments
on the publicly available Human Connectome Project (HCP) dataset for IQT and
brain parcellation demonstrate that our model outperforms existing methods both
quantitatively and qualitatively. The code is publicly available at
\url{https://github.com/edshkim98/DiffusionIQT}.
</p>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06632" title="Abstract">arXiv:2311.06632</a> (cross-list from stat.ML) [<a href="/pdf/2311.06632" title="Download PDF">pdf</a>, <a href="/ps/2311.06632" title="Download PostScript">ps</a>, <a href="/format/2311.06632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Exact Determinant of a Specific Class of Sparse Positive Definite  Matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Molkaraie%2C+M">Mehdi Molkaraie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proc. of the 2023 IEEE International Symposium on Information Theory (ISIT), Taipei, Taiwan
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
<p class="mathjax">For a specific class of sparse Gaussian graphical models, we provide a
closed-form solution for the determinant of the covariance matrix. In our
framework, the graphical interaction model (i.e., the covariance selection
model) is equal to replacement product of $\mathcal{K}_{n}$ and
$\mathcal{K}_{n-1}$, where $\mathcal{K}_n$ is the complete graph with $n$
vertices. Our analysis is based on taking the Fourier transform of the local
factors of the model, which can be viewed as an application of the Normal
Factor Graph Duality Theorem and holographic algorithms. The closed-form
expression is obtained by applying the Matrix Determinant Lemma on the
transformed graphical model. In this context, we will also define a notion of
equivalence between two Gaussian graphical models.
</p>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06634" title="Abstract">arXiv:2311.06634</a> (cross-list from eess.IV) [<a href="/pdf/2311.06634" title="Download PDF">pdf</a>, <a href="/ps/2311.06634" title="Download PostScript">ps</a>, <a href="/format/2311.06634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Back to Basics: Fast Denoising Iterative Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pereg%2C+D">Deborah Pereg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We introduce Back to Basics (BTB), a fast iterative algorithm for noise
reduction. Our method is computationally efficient, does not require training
or ground truth data, and can be applied in the presence of independent noise,
as well as correlated (coherent) noise, where the noise level is unknown. We
examine three study cases: natural image denoising in the presence of additive
white Gaussian noise, Poisson-distributed image denoising, and speckle
suppression in optical coherence tomography (OCT). Experimental results
demonstrate that the proposed approach can effectively improve image quality,
in challenging noise settings. Theoretical guarantees are provided for
convergence stability.
</p>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06641" title="Abstract">arXiv:2311.06641</a> (cross-list from econ.TH) [<a href="/pdf/2311.06641" title="Download PDF">pdf</a>, <a href="/ps/2311.06641" title="Download PostScript">ps</a>, <a href="/format/2311.06641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Best Complete Approximations of Preference Relations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Nishimura%2C+H">Hiroki Nishimura</a>, 
<a href="/search/econ?searchtype=author&query=Ok%2C+E+A">Efe A. Ok</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
<p class="mathjax">We investigate the problem of approximating an incomplete preference relation
$\succsim$ on a finite set by a complete preference relation. We aim to obtain
this approximation in such a way that the choices on the basis of two
preferences, one incomplete, the other complete, have the smallest possible
discrepancy in the aggregate. To this end, we use the top-difference metric on
preferences, and define a best complete approximation of $\succsim$ as a
complete preference relation nearest to $\succsim$ relative to this metric. We
prove that such an approximation must be a maximal completion of $\succsim$,
and that it is, in fact, any one completion of $\succsim$ with the largest
index. Finally, we use these results to provide a sufficient condition for the
best complete approximation of a preference to be its canonical completion.
This leads to closed-form solutions to the best approximation problem in the
case of several incomplete preference relations of interest.
</p>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06642" title="Abstract">arXiv:2311.06642</a> (cross-list from cond-mat.mes-hall) [<a href="/pdf/2311.06642" title="Download PDF">pdf</a>, <a href="/format/2311.06642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Double-Free-Layer Stochastic Magnetic Tunnel Junctions with Synthetic  Antiferromagnets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Selcuk%2C+K">Kemal Selcuk</a>, 
<a href="/search/cond-mat?searchtype=author&query=Kanai%2C+S">Shun Kanai</a>, 
<a href="/search/cond-mat?searchtype=author&query=Ota%2C+R">Rikuto Ota</a>, 
<a href="/search/cond-mat?searchtype=author&query=Ohno%2C+H">Hideo Ohno</a>, 
<a href="/search/cond-mat?searchtype=author&query=Fukami%2C+S">Shunsuke Fukami</a>, 
<a href="/search/cond-mat?searchtype=author&query=Camsari%2C+K+Y">Kerem Y. Camsari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mesoscale and Nanoscale Physics (cond-mat.mes-hall)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Stochastic magnetic tunnel junctions (sMTJ) using low-barrier nanomagnets
have shown promise as fast, energy-efficient, and scalable building blocks for
probabilistic computing. Despite recent experimental and theoretical progress,
sMTJs exhibiting the ideal characteristics necessary for probabilistic bits
(p-bit) are still lacking. Ideally, the sMTJs should have (a) voltage bias
independence preventing read disturbance (b) uniform randomness in the
magnetization angle between the free layers, and (c) fast fluctuations without
requiring external magnetic fields while being robust to magnetic field
perturbations. Here, we propose a new design satisfying all of these
requirements, using double-free-layer sMTJs with synthetic antiferromagnets
(SAF). We evaluate the proposed sMTJ design with experimentally benchmarked
spin-circuit models accounting for transport physics, coupled with the
stochastic Landau-Lifshitz-Gilbert equation for magnetization dynamics. We find
that the use of low-barrier SAF layers reduces dipolar coupling, achieving
uncorrelated fluctuations at zero-magnetic field surviving up to diameters
exceeding ($D\approx 100$ nm) if the nanomagnets can be made thin enough
($\approx 1$-$2$ nm). The double-free-layer structure retains bias-independence
and the circular nature of the nanomagnets provides near-uniform randomness
with fast fluctuations. Combining our full sMTJ model with advanced transistor
models, we estimate the energy to generate a random bit as $\approx$ 3.6 fJ,
with fluctuation rates of $\approx$ 3.3 GHz per p-bit. Our results will guide
the experimental development of superior stochastic magnetic tunnel junctions
for large-scale and energy-efficient probabilistic computation for problems
relevant to machine learning and artificial intelligence.
</p>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06650" title="Abstract">arXiv:2311.06650</a> (cross-list from math.OC) [<a href="/pdf/2311.06650" title="Download PDF">pdf</a>, <a href="/format/2311.06650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heuristic Optimal Transport in Branching Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Andrecut%2C+M">M. Andrecut</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Optimal transport aims to learn a mapping of sources to targets by minimizing
the cost, which is typically defined as a function of distance. The solution to
this problem consists of straight line segments optimally connecting sources to
targets, and it does not exhibit branching. These optimal solutions are in
stark contrast with both natural, and man-made transportation networks, where
branching structures are prevalent. Here we discuss a fast heuristic branching
method for optimal transport in networks, and we provide several applications.
</p>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06679" title="Abstract">arXiv:2311.06679</a> (cross-list from quant-ph) [<a href="/pdf/2311.06679" title="Download PDF">pdf</a>, <a href="/format/2311.06679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Theory of Compression Channels for Post-selected Metrology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Yang%2C+J">Jing Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6+10 pages,2 figures. Comments are welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT); Optimization and Control (math.OC); Statistics Theory (math.ST)

</div>
<p class="mathjax">Post-selected metrology, also known as probabilistic metrology, can be
employed as an efficient filter or compression channel to compress the number
of samples without significant loss of precision. This metrological scheme is
especially advantageous when the final measurements are either very noisy or
expensive in practical experiments. In this work, we put forward a general
theory on the compression channels in post-selected metrology. We define the
basic notations characterizing the compression quality and illuminate the
underlying structure. Previous experiments on post-selected optical phase
estimation and weak-value amplification are shown to be particular cases of
this general theory. Furthermore, we discover that for two categories of
bipartite systems, the compression loss can be made arbitrarily small even when
the compression channel is restricted to one subsystem. These findings can be
employed to distribute quantum measurements so that the measurement noise and
cost are dramatically reduced. Therefore, we expect they will find immediate
applications in quantum technology.
</p>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06680" title="Abstract">arXiv:2311.06680</a> (cross-list from math.OC) [<a href="/pdf/2311.06680" title="Download PDF">pdf</a>, <a href="/format/2311.06680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extremum Seeking for Stefan PDE with Moving Boundary
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Galvao%2C+M+L">Mauricio Linhares Galvao</a>, 
<a href="/search/math?searchtype=author&query=Oliveira%2C+T+R">Tiago Roux Oliveira</a>, 
<a href="/search/math?searchtype=author&query=Krstic%2C+M">Miroslav Krstic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages and 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY); Analysis of PDEs (math.AP)

</div>
<p class="mathjax">This paper presents the design and analysis of the extremum seeking for
static maps with input passed through a partial differential equation (PDE) of
the diffusion type defined on a time-varying spatial domain whose boundary
position is governed by an ordinary differential equation (ODE). This is the
first effort to pursue an extension of extremum seeking from the heat PDE to
the Stefan PDE. We compensate the average-based actuation dynamics by a
controller via backstepping transformation for the moving boundary, which is
utilized to transform the original coupled PDE-ODE into a target system whose
exponential stability of the average equilibrium of the average system is
proved. The discussion for the delay-compensated extremum seeking control of
the Stefan problem is also presented and illustrated with numerical
simulations.
</p>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06699" title="Abstract">arXiv:2311.06699</a> (cross-list from q-bio.GN) [<a href="/pdf/2311.06699" title="Download PDF">pdf</a>, <a href="/ps/2311.06699" title="Download PostScript">ps</a>, <a href="/format/2311.06699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Investigation of Hepatitis B Virus Genome using Markov Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Khadijeh">Khadijeh</a> (Hoda)
<a href="/search/q-bio?searchtype=author&query=Jahanian">Jahanian</a>, 
<a href="/search/q-bio?searchtype=author&query=Shalbafian%2C+E">Elnaz Shalbafian</a>, 
<a href="/search/q-bio?searchtype=author&query=Saberi%2C+M">Morteza Saberi</a>, 
<a href="/search/q-bio?searchtype=author&query=Alizadehsani%2C+R">Roohallah Alizadehsani</a>, 
<a href="/search/q-bio?searchtype=author&query=Dehzangi%2C+I">Iman Dehzangi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The human genome encodes a family of editing enzymes known as APOBEC3
(apolipoprotein B mRNA editing enzyme, catalytic polypeptide-like 3). Several
family members, such as APO-BEC3G, APOBEC3F, and APOBEC3H haplotype II, exhibit
activity against viruses such as HIV. These enzymes induce C-to-U mutations in
the negative strand of viral genomes, resulting in multiple G-to-A changes,
commonly referred to as 'hypermutation.' Mutations catalyzed by these enzymes
are sequence context-dependent in the HIV genome; for instance, APOBEC3G
preferen-tially mutates G within GG, TGG, and TGGG contexts, while other
members mutate G within GA, TGA, and TGAA contexts. However, the same sequence
context has not been explored in relation to these enzymes and HBV. In this
study, our objective is to identify the mutational footprint of APOBEC3 enzymes
in the HBV genome. To achieve this, we employ a multivariable data analytics
technique to investigate motif preferences and potential sequence hierarchies
of mutation by APOBEC3 enzymes using full genome HBV sequences from a diverse
range of naturally infected patients. This approach allows us to distinguish
between normal and hypermutated sequences based on the representation of mono-
to tetra-nucleotide motifs. Additionally, we aim to identify motifs associated
with hypermutation induced by different APOBEC3 enzymes in HBV genomes. Our
analyses reveal that either APOBEC3 enzymes are not active against HBV, or the
induction of G-to-A mutations by these enzymes is not sequence
context-dependent in the HBV genome.
</p>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06708" title="Abstract">arXiv:2311.06708</a> (cross-list from physics.chem-ph) [<a href="/pdf/2311.06708" title="Download PDF">pdf</a>, <a href="/format/2311.06708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReactionT5: a large-scale pre-trained model towards application of  limited reaction data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Sagawa%2C+T">Tatsuya Sagawa</a>, 
<a href="/search/physics?searchtype=author&query=Kojima%2C+R">Ryosuke Kojima</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Transformer-based deep neural networks have revolutionized the field of
molecular-related prediction tasks by treating molecules as symbolic sequences.
These models have been successfully applied in various organic chemical
applications by pretraining them with extensive compound libraries and
subsequently fine-tuning them with smaller in-house datasets for specific
tasks. However, many conventional methods primarily focus on single molecules,
with limited exploration of pretraining for reactions involving multiple
molecules. In this paper, we propose ReactionT5, a novel model that leverages
pretraining on the Open Reaction Database (ORD), a publicly available
large-scale resource. We further fine-tune this model for yield prediction and
product prediction tasks, demonstrating its impressive performance even with
limited fine-tuning data compared to traditional models. The pre-trained
ReactionT5 model is publicly accessible on the Hugging Face platform.
</p>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06748" title="Abstract">arXiv:2311.06748</a> (cross-list from stat.ML) [<a href="/pdf/2311.06748" title="Download PDF">pdf</a>, <a href="/format/2311.06748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How do Minimum-Norm Shallow Denoisers Look in Function Space?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zeno%2C+C">Chen Zeno</a>, 
<a href="/search/stat?searchtype=author&query=Ongie%2C+G">Greg Ongie</a>, 
<a href="/search/stat?searchtype=author&query=Blumenfeld%2C+Y">Yaniv Blumenfeld</a>, 
<a href="/search/stat?searchtype=author&query=Weinberger%2C+N">Nir Weinberger</a>, 
<a href="/search/stat?searchtype=author&query=Soudry%2C+D">Daniel Soudry</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Thirty-seventh Conference on Neural Information Processing Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Neural network (NN) denoisers are an essential building block in many common
tasks, ranging from image reconstruction to image generation. However, the
success of these models is not well understood from a theoretical perspective.
In this paper, we aim to characterize the functions realized by shallow ReLU NN
denoisers -- in the common theoretical setting of interpolation (i.e., zero
training loss) with a minimal representation cost (i.e., minimal $\ell^2$ norm
weights). First, for univariate data, we derive a closed form for the NN
denoiser function, find it is contractive toward the clean data points, and
prove it generalizes better than the empirical MMSE estimator at a low noise
level. Next, for multivariate data, we find the NN denoiser functions in a
closed form under various geometric assumptions on the training data: data
contained in a low-dimensional subspace, data contained in a union of one-sided
rays, or several types of simplexes. These functions decompose into a sum of
simple rank-one piecewise linear interpolations aligned with edges and/or faces
connecting training samples. We empirically verify this alignment phenomenon on
synthetic data and real images.
</p>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06780" title="Abstract">arXiv:2311.06780</a> (cross-list from econ.TH) [<a href="/pdf/2311.06780" title="Download PDF">pdf</a>, <a href="/ps/2311.06780" title="Download PostScript">ps</a>, <a href="/format/2311.06780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Strategyproof Mechanism for Ownership Restructuring in Privately Owned  Assets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Danino%2C+G">Gal Danino</a>, 
<a href="/search/econ?searchtype=author&query=Koren%2C+M">Moran Koren</a>, 
<a href="/search/econ?searchtype=author&query=Madmon%2C+O">Omer Madmon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">It is unclear how to restructure ownership when an asset is privately held,
and there is uncertainty about the owners' subjective valuations. When
ownership is divided equally between two owners, a commonly used mechanism is
called a BMBY mechanism. This mechanism works as follows: each owner can
initiate a BMBY by naming her price. Once an owner declares a price, the other
chooses to sell his holdings or buy the shares of the initiator at the given
price. This mechanism is simple and tractable; however, it does not elicit
actual owner valuations, does not guarantee an efficient allocation, and, most
importantly, is limited to an equal partnership of two owners. In this paper,
we extend this rationale to a multi-owner setting. Our proposed mechanism
elicits owner valuations truthfully. Additionally, our proposed mechanism
exhibits several desirable traits: it is easy to implement, budget balanced,
robust to collusion (weakly group strategyproof), individually rational, and
ex-post efficient.
</p>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06834" title="Abstract">arXiv:2311.06834</a> (cross-list from eess.IV) [<a href="/pdf/2311.06834" title="Download PDF">pdf</a>, <a href="/format/2311.06834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Osteoporosis Prediction from Hand and Wrist X-rays using Image  Segmentation and Self-Supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lee%2C+H">Hyungeun Lee</a>, 
<a href="/search/eess?searchtype=author&query=Hwang%2C+U">Ung Hwang</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+S">Seungwon Yu</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+C">Chang-Hun Lee</a>, 
<a href="/search/eess?searchtype=author&query=Yoon%2C+K">Kijung Yoon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2023, December 10th, 2023, New Orleans, United States, 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Osteoporosis is a widespread and chronic metabolic bone disease that often
remains undiagnosed and untreated due to limited access to bone mineral density
(BMD) tests like Dual-energy X-ray absorptiometry (DXA). In response to this
challenge, current advancements are pivoting towards detecting osteoporosis by
examining alternative indicators from peripheral bone areas, with the goal of
increasing screening rates without added expenses or time. In this paper, we
present a method to predict osteoporosis using hand and wrist X-ray images,
which are both widely accessible and affordable, though their link to DXA-based
data is not thoroughly explored. Initially, our method segments the ulnar,
radius, and metacarpal bones using a foundational model for image segmentation.
Then, we use a self-supervised learning approach to extract meaningful
representations without the need for explicit labels, and move on to classify
osteoporosis in a supervised manner. Our method is evaluated on a dataset with
192 individuals, cross-referencing their verified osteoporosis conditions
against the standard DXA test. With a notable classification score (AUC=0.83),
our model represents a pioneering effort in leveraging vision-based techniques
for osteoporosis identification from the peripheral skeleton sites.
</p>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06849" title="Abstract">arXiv:2311.06849</a> (cross-list from math.CA) [<a href="/pdf/2311.06849" title="Download PDF">pdf</a>, <a href="/ps/2311.06849" title="Download PostScript">ps</a>, <a href="/format/2311.06849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analytic regularity for a singularly perturbed fourth order  reaction-diffusion boundary value problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Constantinou%2C+P">P. Constantinou</a>, 
<a href="/search/math?searchtype=author&query=Xenophontos%2C+C">C. Xenophontos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Classical Analysis and ODEs (math.CA)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">We consider a fourth order, reaction-diffusion type, singularly perturbed
boundary value problem, and the regularity of its solution. Specifically, we
provide estimates for arbitrary order derivatves, which are explicit in the
singular perturbation parameter as well as the differentiation order. Such
estimates are needed for the numerical analysis of high order methods, e.g.hp
Finite Element Method (FEM).
</p>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06872" title="Abstract">arXiv:2311.06872</a> (cross-list from math.CO) [<a href="/pdf/2311.06872" title="Download PDF">pdf</a>, <a href="/format/2311.06872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ramsey theorem for trees with successor operation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Balko%2C+M">Martin Balko</a>, 
<a href="/search/math?searchtype=author&query=Chodounsk%C3%BD%2C+D">David Chodounsk&#xfd;</a>, 
<a href="/search/math?searchtype=author&query=Dobrinen%2C+N">Natasha Dobrinen</a>, 
<a href="/search/math?searchtype=author&query=Hubi%C4%8Dka%2C+J">Jan Hubi&#x10d;ka</a>, 
<a href="/search/math?searchtype=author&query=Kone%C4%8Dn%C3%BD%2C+M">Mat&#x11b;j Kone&#x10d;n&#xfd;</a>, 
<a href="/search/math?searchtype=author&query=Ne%C5%A1et%C5%99il%2C+J">Jaroslav Ne&#x161;et&#x159;il</a>, 
<a href="/search/math?searchtype=author&query=Zucker%2C+A">Andy Zucker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Logic (math.LO)

</div>
<p class="mathjax">We prove a general Ramsey theorem for trees with a successor operation. This
theorem is a common generalization of the Carlson-Simpson Theorem and the
Milliken Tree Theorem for regularly branching trees.
<br />Our theorem has a number of applications both in finite and infinite
combinatorics. For example, we give a short proof of the unrestricted
Ne\v{s}et\v{r}il-R\"odl theorem, and we recover the Graham-Rothschild theorem.
Our original motivation came from the study of big Ramsey degrees - various
trees used in the study can be viewed as trees with a successor operation. To
illustrate this, we give a non-forcing proof of a theorem of Zucker on big
Ramsey degrees.
</p>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06875" title="Abstract">arXiv:2311.06875</a> (cross-list from math.CO) [<a href="/pdf/2311.06875" title="Download PDF">pdf</a>, <a href="/ps/2311.06875" title="Download PostScript">ps</a>, <a href="/format/2311.06875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modularity of very dense graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=McDiarmid%2C+C">Colin McDiarmid</a>, 
<a href="/search/math?searchtype=author&query=Skerman%2C+F">Fiona Skerman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">It is known that complete graphs and complete bipartite graphs have
modularity zero. We show that the least number of edges we may delete from the
complete graph $K_n$ to obtain a graph with non-zero modularity is $\lfloor
n/2\rfloor +1$. Similarly we determine the least number of edges we may delete
from or add to a complete bipartite graph to reach non-zero modularity.
<br />We also analyse the modularity of very dense random graphs, and in particular
we find that there is a transition to modularity zero when the average degree
of the complementary graph drops below 1.
</p>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06906" title="Abstract">arXiv:2311.06906</a> (cross-list from math.OC) [<a href="/pdf/2311.06906" title="Download PDF">pdf</a>, <a href="/ps/2311.06906" title="Download PostScript">ps</a>, <a href="/format/2311.06906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An EnKF-based algorithm for stochastic optimal control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Reich%2C+S">Sebastian Reich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">The solution to a stochastic optimal control problem can be determined by
computing the value function from a discretisation of the associated
Hamilton-Jacobi-Bellman equation. Alternatively, the problem can be
reformulated in terms of a pair of forward-backward SDEs, which makes
Monte-Carlo techniques applicable. More recently, the problem has also been
viewed from the perspective of forward and reverse time SDEs and their
associated Fokker-Planck equations. This approach is closely related to
techniques used in score generative models. Forward and reverse time
formulations express the value function as the ratio of two probability
functions; one stemming from a forward SDE and another one from a reverse time
SDE. In this note, we extend this approach to a more general class of
stochastic optimal control problems and combine it with ensemble Kalman filter
type approximation techniques in order to obtain an efficient and robust
numerical scheme.
</p>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06999" title="Abstract">arXiv:2311.06999</a> (cross-list from quant-ph) [<a href="/pdf/2311.06999" title="Download PDF">pdf</a>, <a href="/format/2311.06999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum and classical query complexities of functions of matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Montanaro%2C+A">Ashley Montanaro</a>, 
<a href="/search/quant-ph?searchtype=author&query=Shao%2C+C">Changpeng Shao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">Let $A$ be a sparse Hermitian matrix, $f(x)$ be a univariate function, and
$i, j$ be two indices. In this work, we investigate the query complexity of
approximating $\bra{i} f(A) \ket{j}$. We show that for any continuous function
$f(x):[-1,1]\rightarrow [-1,1]$, the quantum query complexity of computing
$\bra{i} f(A) \ket{j}\pm \varepsilon/4$ is lower bounded by
$\Omega(\widetilde{\deg}_\varepsilon(f))$. The upper bound is at most quadratic
in $\widetilde{\deg}_\varepsilon(f)$ and is linear in
$\widetilde{\deg}_\varepsilon(f)$ under certain mild assumptions on $A$. Here
the approximate degree $\widetilde{\deg}_\varepsilon(f)$ is the minimum degree
such that there is a polynomial of that degree approximating $f$ up to additive
error $\varepsilon$ in the interval $[-1,1]$. We also show that the classical
query complexity is lower bounded by
$\widetilde{\Omega}(2^{\widetilde{\deg}_{2\varepsilon}(f)/6})$. Our results
show that the quantum and classical separation is exponential for any
continuous function of sparse Hermitian matrices, and also imply the optimality
of implementing smooth functions of sparse Hermitian matrices by quantum
singular value transformation. The main techniques we used are the dual
polynomial method for functions over the reals, linear semi-infinite
programming, and tridiagonal matrices.
</p>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07013" title="Abstract">arXiv:2311.07013</a> (cross-list from stat.ML) [<a href="/pdf/2311.07013" title="Download PDF">pdf</a>, <a href="/ps/2311.07013" title="Download PostScript">ps</a>, <a href="/format/2311.07013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A PAC-Bayesian Perspective on the Interpolating Information Criterion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Hodgkinson%2C+L">Liam Hodgkinson</a>, 
<a href="/search/stat?searchtype=author&query=van+der+Heide%2C+C">Chris van der Heide</a>, 
<a href="/search/stat?searchtype=author&query=Salomone%2C+R">Robert Salomone</a>, 
<a href="/search/stat?searchtype=author&query=Roosta%2C+F">Fred Roosta</a>, 
<a href="/search/stat?searchtype=author&query=Mahoney%2C+M+W">Michael W. Mahoney</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep learning is renowned for its theory-practice gap, whereby principled
theory typically fails to provide much beneficial guidance for implementation
in practice. This has been highlighted recently by the benign overfitting
phenomenon: when neural networks become sufficiently large to interpolate the
dataset perfectly, model performance appears to improve with increasing model
size, in apparent contradiction with the well-known bias-variance tradeoff.
While such phenomena have proven challenging to theoretically study for general
models, the recently proposed Interpolating Information Criterion (IIC)
provides a valuable theoretical framework to examine performance for
overparameterized models. Using the IIC, a PAC-Bayes bound is obtained for a
general class of models, characterizing factors which influence generalization
performance in the interpolating regime. From the provided bound, we quantify
how the test error for overparameterized models achieving effectively zero
training error depends on the quality of the implicit regularization imposed by
e.g. the combination of model, optimizer, and parameter-initialization scheme;
the spectrum of the empirical neural tangent kernel; curvature of the loss
landscape; and noise present in the data.
</p>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07015" title="Abstract">arXiv:2311.07015</a> (cross-list from quant-ph) [<a href="/pdf/2311.07015" title="Download PDF">pdf</a>, <a href="/format/2311.07015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QudCom: Towards Quantum Compilation for Qudit Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Volya%2C+D">Daniel Volya</a>, 
<a href="/search/quant-ph?searchtype=author&query=Mishra%2C+P">Prabhat Mishra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Qudit-based quantum computation offers unique advantages over qubit-based
systems in terms of noise mitigation capabilities as well as algorithmic
complexity improvements. However, the software ecosystem for multi-state
quantum systems is severely limited. In this paper, we highlight a quantum
workflow for describing and compiling qudit systems. We investigate the design
and implementation of a quantum compiler for qudit systems. We also explore
several key theoretical properties of qudit computing as well as efficient
optimization techniques. Finally, we provide demonstrations using physical
quantum computers as well as simulations of the proposed quantum toolchain.
</p>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07033" title="Abstract">arXiv:2311.07033</a> (cross-list from eess.IV) [<a href="/pdf/2311.07033" title="Download PDF">pdf</a>, <a href="/format/2311.07033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TTMFN: Two-stream Transformer-based Multimodal Fusion Network for  Survival Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ge%2C+R">Ruiquan Ge</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+X">Xiangyang Hu</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+R">Rungen Huang</a>, 
<a href="/search/eess?searchtype=author&query=Jia%2C+G">Gangyong Jia</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yaqi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Gu%2C+R">Renshu Gu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+C">Changmiao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Ahmed%2C+E">Elazab Ahmed</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+L">Linyan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Ye%2C+J">Juan Ye</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Ye Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Survival prediction plays a crucial role in assisting clinicians with the
development of cancer treatment protocols. Recent evidence shows that
multimodal data can help in the diagnosis of cancer disease and improve
survival prediction. Currently, deep learning-based approaches have experienced
increasing success in survival prediction by integrating pathological images
and gene expression data. However, most existing approaches overlook the
intra-modality latent information and the complex inter-modality correlations.
Furthermore, existing modalities do not fully exploit the immense
representational capabilities of neural networks for feature aggregation and
disregard the importance of relationships between features. Therefore, it is
highly recommended to address these issues in order to enhance the prediction
performance by proposing a novel deep learning-based method. We propose a novel
framework named Two-stream Transformer-based Multimodal Fusion Network for
survival prediction (TTMFN), which integrates pathological images and gene
expression data. In TTMFN, we present a two-stream multimodal co-attention
transformer module to take full advantage of the complex relationships between
different modalities and the potential connections within the modalities.
Additionally, we develop a multi-head attention pooling approach to effectively
aggregate the feature representations of the two modalities. The experiment
results on four datasets from The Cancer Genome Atlas demonstrate that TTMFN
can achieve the best performance or competitive results compared to the
state-of-the-art methods in predicting the overall survival of patients.
</p>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07037" title="Abstract">arXiv:2311.07037</a> (cross-list from eess.AS) [<a href="/pdf/2311.07037" title="Download PDF">pdf</a>, <a href="/format/2311.07037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Phonological Level wav2vec2-based Mispronunciation Detection and  Diagnosis Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shahin%2C+M">Mostafa Shahin</a>, 
<a href="/search/eess?searchtype=author&query=Epps%2C+J">Julien Epps</a>, 
<a href="/search/eess?searchtype=author&query=Ahmed%2C+B">Beena Ahmed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">The automatic identification and analysis of pronunciation errors, known as
Mispronunciation Detection and Diagnosis (MDD) plays a crucial role in Computer
Aided Pronunciation Learning (CAPL) tools such as Second-Language (L2) learning
or speech therapy applications. Existing MDD methods relying on analysing
phonemes can only detect categorical errors of phonemes that have an adequate
amount of training data to be modelled. With the unpredictable nature of the
pronunciation errors of non-native or disordered speakers and the scarcity of
training datasets, it is unfeasible to model all types of mispronunciations.
Moreover, phoneme-level MDD approaches have a limited ability to provide
detailed diagnostic information about the error made. In this paper, we propose
a low-level MDD approach based on the detection of speech attribute features.
Speech attribute features break down phoneme production into elementary
components that are directly related to the articulatory system leading to more
formative feedback to the learner. We further propose a multi-label variant of
the Connectionist Temporal Classification (CTC) approach to jointly model the
non-mutually exclusive speech attributes using a single model. The pre-trained
wav2vec2 model was employed as a core model for the speech attribute detector.
The proposed method was applied to L2 speech corpora collected from English
learners from different native languages. The proposed speech attribute MDD
method was further compared to the traditional phoneme-level MDD and achieved a
significantly lower False Acceptance Rate (FAR), False Rejection Rate (FRR),
and Diagnostic Error Rate (DER) over all speech attributes compared to the
phoneme-level equivalent.
</p>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07071" title="Abstract">arXiv:2311.07071</a> (cross-list from econ.GN) [<a href="/pdf/2311.07071" title="Download PDF">pdf</a>, <a href="/format/2311.07071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impact of Generative Artificial Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Zhang%2C+K">Kaichen Zhang</a>, 
<a href="/search/econ?searchtype=author&query=Kwon%2C+O">Ohchan Kwon</a>, 
<a href="/search/econ?searchtype=author&query=Xiong%2C+H">Hui Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Economics (econ.GN)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The rise of generative artificial intelligence (AI) has sparked concerns
about its potential influence on unemployment and market depression. This study
addresses this concern by examining the impact of generative AI on product
markets. To overcome the challenge of causal inference, given the inherent
limitations of conducting controlled experiments, this paper identifies an
unanticipated and sudden leak of a highly proficient image-generative AI as a
novel instance of a "natural experiment". This AI leak spread rapidly,
significantly reducing the cost of generating anime-style images compared to
other styles, creating an opportunity for comparative assessment. We collect
real-world data from an artwork outsourcing platform. Surprisingly, our results
show that while generative AI lowers average prices, it substantially boosts
order volume and overall revenue. This counterintuitive finding suggests that
generative AI confers benefits upon artists rather than detriments. The study
further offers theoretical economic explanations to elucidate this unexpected
phenomenon. By furnishing empirical evidence, this paper dispels the notion
that generative AI might engender depression, instead underscoring its
potential to foster market prosperity. These findings carry significant
implications for practitioners, policymakers, and the broader AI community.
</p>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07089" title="Abstract">arXiv:2311.07089</a> (cross-list from eess.SP) [<a href="/pdf/2311.07089" title="Download PDF">pdf</a>, <a href="/ps/2311.07089" title="Download PostScript">ps</a>, <a href="/format/2311.07089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recursive and non-recursive filters for sequential smoothing and  prediction with instantaneous phase and frequency estimation applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kennedy%2C+H+L">Hugh Lachlan Kennedy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">A simple procedure for the design of recursive digital filters with an
infinite impulse response (IIR) and non-recursive digital filters with a finite
impulse response (FIR) is described. The fixed-lag smoothing filters are
designed to track an approximately polynomial signal of specified degree
without bias at steady state, while minimizing the gain of high-frequency
(coloured) noise with a specified power spectral density. For the IIR variant,
the procedure determines the optimal lag (i.e. the passband group delay)
yielding a recursive low-complexity smoother of low order, with a specified
bandwidth, and excellent passband phase linearity. The filters are applied to
the problem of instantaneous frequency estimation, e.g. for Doppler-shift
measurement, for a complex exponential with polynomial phase progression in
additive white noise. For this classical problem, simulations show that the
incorporation of a prediction filter (with a one-sample lead) reduces the
incidence of (phase or frequency) angle unwrapping errors, particularly for
signals with high rates of angle change, which are known to limit the
performance of standard FIR estimators at low SNR. This improvement allows the
instantaneous phase of low-frequency signals to be estimated, e.g. for
time-delay measurement, and/or the instantaneous frequency of
frequency-modulated signals, down to a lower SNR. In the absence of unwrapping
errors, the error variance of the IIR estimators (with the optimal phase lag)
reaches the FIR lower bound, at a significantly lower computational cost.
Guidelines for configuring and tuning both FIR and IIR filters are provided.
</p>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07111" title="Abstract">arXiv:2311.07111</a> (cross-list from quant-ph) [<a href="/pdf/2311.07111" title="Download PDF">pdf</a>, <a href="/ps/2311.07111" title="Download PostScript">ps</a>, <a href="/format/2311.07111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semidefinite programming bounds on the size of entanglement-assisted  codeword stabilized quantum codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Lai%2C+C">Ching-Yi Lai</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tseng%2C+P">Pin-Chieh Tseng</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yu%2C+W">Wei-Hsuan Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">In this paper, we explore the application of semidefinite programming to the
realm of quantum codes, specifically focusing on codeword stabilized (CWS)
codes with entanglement assistance. Notably, we utilize the isotropic subgroup
of the CWS group and the set of word operators of a CWS-type quantum code to
derive an upper bound on the minimum distance. Furthermore, this
characterization can be incorporated into the associated distance enumerators,
enabling us to construct semidefinite constraints that lead to SDP bounds on
the minimum distance or size of CWS-type quantum codes. We illustrate several
instances where SDP bounds outperform LP bounds, and there are even cases where
LP fails to yield meaningful results, while SDP consistently provides tight and
relevant bounds. Finally, we also provide interpretations of the Shor-Laflamme
weight enumerators and shadow enumerators for codeword stabilized codes,
enhancing our understanding of quantum codes.
</p>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07114" title="Abstract">arXiv:2311.07114</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2311.07114" title="Download PDF">pdf</a>, <a href="/ps/2311.07114" title="Download PostScript">ps</a>, <a href="/format/2311.07114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Novel models for fatigue life prediction under wideband random loads  based on machine learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Sun%2C+H">Hong Sun</a>, 
<a href="/search/cond-mat?searchtype=author&query=Qiu%2C+Y">Yuanying Qiu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Li%2C+J">Jing Li</a>, 
<a href="/search/cond-mat?searchtype=author&query=Bai%2C+J">Jin Bai</a>, 
<a href="/search/cond-mat?searchtype=author&query=Peng%2C+M">Ming Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Machine Learning (cs.LG)

</div>
<p class="mathjax">Machine learning as a data-driven solution has been widely applied in the
field of fatigue lifetime prediction. In this paper, three models for wideband
fatigue life prediction are built based on three machine learning models, i.e.
support vector machine (SVM), Gaussian process regression (GPR) and artificial
neural network (ANN). The generalization ability of the models is enhanced by
employing numerous power spectra samples with different bandwidth parameters
and a variety of material properties related to fatigue life. Sufficient Monte
Carlo numerical simulations demonstrate that the newly developed machine
learning models are superior to the traditional frequency-domain models in
terms of life prediction accuracy and the ANN model has the best overall
performance among the three developed machine learning models.
</p>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07129" title="Abstract">arXiv:2311.07129</a> (cross-list from eess.SP) [<a href="/pdf/2311.07129" title="Download PDF">pdf</a>, <a href="/format/2311.07129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Point Method using Effective Demodulation and Decomposition  Techniques allowing Identification of Disturbing Loads in Power Grids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kuwa%C5%82ek%2C+P">Piotr Kuwa&#x142;ek</a>, 
<a href="/search/eess?searchtype=author&query=Wiczy%C5%84ski%2C+G">Grzegorz Wiczy&#x144;ski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures, under review, submitted to IEEE Transactions
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">The paper presents an innovative approach to the identification of sources of
voltage fluctuations in power networks, also considering the localization
understood as the indication of supply points of disturbing loads. The
presented approach considers disturbance sources that change their operating
state with a frequency higher than the power frequency. Implementation of the
proposed solution is also proposed in such a way that its implementation in the
smart meter infrastructure allows for automatic localization of disturbance
sources without additional expert knowledge. In the proposed approach, the
modulation signal is estimated using a carrier signal estimator, which allows
for the estimation of modulation signal with a frequency higher than the power
frequency. The estimated modulating signal is decomposed into component signals
associated with individual disturbing loads by decomposition by approximation
using pulse waves. The decomposition process allows for the estimation of
selected parameters associated with disturbing loads, on the basis of which the
assessment of propagation of voltage fluctuations associated with the impact of
individual disturbance sources is performed, which allows for the indication of
their supply point. The proposed approach was verified in numerical simulation
studies using MATLAB/SIMULINK and in experimental studies carried out in a real
low-voltage power grid.
</p>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07130" title="Abstract">arXiv:2311.07130</a> (cross-list from math.CO) [<a href="/pdf/2311.07130" title="Download PDF">pdf</a>, <a href="/format/2311.07130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconfiguration of basis pairs in regular matroids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=B%C3%A9rczi%2C+K">Krist&#xf3;f B&#xe9;rczi</a>, 
<a href="/search/math?searchtype=author&query=M%C3%A1trav%C3%B6lgyi%2C+B">Bence M&#xe1;trav&#xf6;lgyi</a>, 
<a href="/search/math?searchtype=author&query=Schwarcz%2C+T">Tam&#xe1;s Schwarcz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">In recent years, combinatorial reconfiguration problems have attracted great
attention due to their connection to various topics such as optimization,
counting, enumeration, or sampling. One of the most intriguing open questions
concerns the exchange distance of two matroid basis sequences, a problem that
appears in several areas of computer science and mathematics. In 1980, White
proposed a conjecture for the characterization of two basis sequences being
reachable from each other by symmetric exchanges, which received a significant
interest also in algebra due to its connection to toric ideals and Gr\"obner
bases. In this work, we verify White's conjecture for basis sequences of length
two in regular matroids, a problem that was formulated as a separate question
by Farber, Richter, and Shan and Andres, Hochst\"attler, and Merkel. Most of
previous work on White's conjecture has not considered the question from an
algorithmic perspective. We study the problem from an optimization point of
view: our proof implies a polynomial algorithm for determining a sequence of
symmetric exchanges that transforms a basis pair into another, thus providing
the first polynomial upper bound on the exchange distance of basis pairs in
regular matroids. As a byproduct, we verify a conjecture of Gabow from 1976 on
the serial symmetric exchange property of matroids for the regular case.
</p>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07148" title="Abstract">arXiv:2311.07148</a> (cross-list from astro-ph.SR) [<a href="/pdf/2311.07148" title="Download PDF">pdf</a>, <a href="/format/2311.07148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variation of the electron flux spectrum along a solar flare loop as  inferred from STIX hard X-ray observations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Volpara%2C+A">Anna Volpara</a>, 
<a href="/search/astro-ph?searchtype=author&query=Massa%2C+P">Paolo Massa</a>, 
<a href="/search/astro-ph?searchtype=author&query=Krucker%2C+S">Sam Krucker</a>, 
<a href="/search/astro-ph?searchtype=author&query=Emslie%2C+A+G">A Gordon Emslie</a>, 
<a href="/search/astro-ph?searchtype=author&query=Piana%2C+M">Michele Piana</a>, 
<a href="/search/astro-ph?searchtype=author&query=Massone%2C+A+M">Anna Maria Massone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Solar and Stellar Astrophysics (astro-ph.SR)</span>; Numerical Analysis (math.NA); Space Physics (physics.space-ph)

</div>
<p class="mathjax">Regularized imaging spectroscopy was introduced for the construction of
electron flux images at different energies from count visibilities recorded by
the Reuven Ramaty High Energy Solar Spectroscopic Imager (RHESSI). In this work
we seek to extend this approach to data from the Spectrometer/Telescope for
Imaging X-rays (STIX) on-board the Solar Orbiter mission. Our aims are to
demonstrate the feasibility of regularized imaging spectroscopy as a method for
analysis of STIX data, and also to show how such analysis can lead to insights
into the physical processes affecting the nonthermal electrons responsible for
the hard X-ray emission observed by STIX. STIX records imaging data in an
intrinsically different manner from RHESSI. Rather than sweeping the angular
frequency plane in a set of concentric circles (one circle per detector), STIX
uses $30$ collimators, each corresponding to a specific angular frequency. In
this paper we derive an appropriate modification of the previous computational
approach for the analysis of the visibilities observed by STIX. This approach
also allows for the observed count data to be placed into non-uniformly-spaced
energy bins. We show that the regularized imaging spectroscopy approach is not
only feasible for analysis of the visibilities observed by STIX, but also more
reliable. Application of the regularized imaging spectroscopy technique to
several well-observed flares reveals details of the variation of the electron
flux spectrum throughout the flare sources. We conclude that the
visibility-based regularized imaging spectroscopy approach is well-suited to
analysis of STIX data. We also use STIX electron flux spectral images to track,
for the first time, the behavior of the accelerated electrons during their path
from the acceleration site in the solar corona toward the chromosphere
</p>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07174" title="Abstract">arXiv:2311.07174</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2311.07174" title="Download PDF">pdf</a>, <a href="/format/2311.07174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The High-dimensional Phase Diagram and the Large CALPHAD Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Liu%2C+Z">Zhengdi Liu</a>, 
<a href="/search/cond-mat?searchtype=author&query=An%2C+X">Xulong An</a>, 
<a href="/search/cond-mat?searchtype=author&query=Sun%2C+W">Wenwen Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">When alloy systems comprise more than three elements, the visualization of
the entire phase space becomes not only daunting but is also accompanied by a
data surge. Addressing this complexity, we delve into the FeNiCrMn alloy system
and introduce the Large CALPHAD Model (LCM). The LCM acts as a computational
conduit, capturing the entire phase space. Subsequently, this enormous data is
systematically structured using a high-dimensional phase diagram, aided by hash
tables and Depth-first Search (DFS), rendering it both digestible and
programmatically accessible. Remarkably, the LCM boasts a 97% classification
accuracy and a mean square error of 4.80*10-5 in phase volume prediction. Our
methodology successfully delineates 51 unique phase spaces in the FeNiCrMn
system, exemplifying its efficacy with the design of all 439 eutectic alloys.
This pioneering methodology signifies a monumental shift in alloy design
techniques or even multi-variable problems.
</p>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07189" title="Abstract">arXiv:2311.07189</a> (cross-list from math.LO) [<a href="/pdf/2311.07189" title="Download PDF">pdf</a>, <a href="/ps/2311.07189" title="Download PostScript">ps</a>, <a href="/format/2311.07189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $&#x3a0;_{2}$-Rule Systems and Inductive Classes of G&#xf6;del Algebras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Almeida%2C+R+N">Rodrigo Nicolau Almeida</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">In this paper we present a general theory of $\Pi_{2}$-rules for systems of
intuitionistic and modal logic. We introduce the notions of $\Pi_{2}$-rule
system and of an Inductive Class, and provide model-theoretic and algebraic
completeness theorems, which serve as our basic tools. As an illustration of
the general theory, we analyse the structure of inductive classes of G\"{o}del
algebras, from a structure theoretic and logical point of view. We show that
unlike other well-studied settings (such as logics, or single-conclusion rule
systems), there are continuum many $\Pi_{2}$-rule systems extending
$\mathsf{LC}=\mathsf{IPC}+(p\rightarrow q)\vee (q\rightarrow p)$, and show how
our methods allow easy proofs of the admissibility of the well-known
Takeuti-Titani rule. Our final results concern general questions admissibility
in $\mathsf{LC}$: (1) we present a full classification of those inductive
classes which are inductively complete, i.e., where all $\Pi_{2}$-rules which
are admissible are derivable, and (2) show that the problem of admissibility of
$\Pi_{2}$-rules over $\mathsf{LC}$ is decidable.
</p>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07203" title="Abstract">arXiv:2311.07203</a> (cross-list from quant-ph) [<a href="/pdf/2311.07203" title="Download PDF">pdf</a>, <a href="/format/2311.07203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optical Quantum Sensing for Agnostic Environments via Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Zhou%2C+Z">Zeqiao Zhou</a>, 
<a href="/search/quant-ph?searchtype=author&query=Du%2C+Y">Yuxuan Du</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yin%2C+X">Xu-Fei Yin</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhao%2C+S">Shanshan Zhao</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tian%2C+X">Xinmei Tian</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Optics (physics.optics)

</div>
<p class="mathjax">Optical quantum sensing promises measurement precision beyond classical
sensors termed the Heisenberg limit (HL). However, conventional methodologies
often rely on prior knowledge of the target system to achieve HL, presenting
challenges in practical applications. Addressing this limitation, we introduce
an innovative Deep Learning-based Quantum Sensing scheme (DQS), enabling
optical quantum sensors to attain HL in agnostic environments. DQS incorporates
two essential components: a Graph Neural Network (GNN) predictor and a
trigonometric interpolation algorithm. Operating within a data-driven paradigm,
DQS utilizes the GNN predictor, trained on offline data, to unveil the
intrinsic relationships between the optical setups employed in preparing the
probe state and the resulting quantum Fisher information (QFI) after
interaction with the agnostic environment. This distilled knowledge facilitates
the identification of optimal optical setups associated with maximal QFI.
Subsequently, DQS employs a trigonometric interpolation algorithm to recover
the unknown parameter estimates for the identified optical setups. Extensive
experiments are conducted to investigate the performance of DQS under different
settings up to eight photons. Our findings not only offer a new lens through
which to accelerate optical quantum sensing tasks but also catalyze future
research integrating deep learning and quantum mechanics.
</p>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07213" title="Abstract">arXiv:2311.07213</a> (cross-list from eess.IV) [<a href="/pdf/2311.07213" title="Download PDF">pdf</a>, <a href="/ps/2311.07213" title="Download PostScript">ps</a>, <a href="/format/2311.07213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A method for quantifying sectoral optic disc pallor in fundus  photographs and its association with peripapillary RNFL thickness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gibbon%2C+S">Samuel Gibbon</a>, 
<a href="/search/eess?searchtype=author&query=Muniz-Terrera%2C+G">Graciela Muniz-Terrera</a>, 
<a href="/search/eess?searchtype=author&query=Yii%2C+F+S">Fabian SL Yii</a>, 
<a href="/search/eess?searchtype=author&query=Hamid%2C+C">Charlene Hamid</a>, 
<a href="/search/eess?searchtype=author&query=Cox%2C+S">Simon Cox</a>, 
<a href="/search/eess?searchtype=author&query=Maccormick%2C+I+J">Ian JC Maccormick</a>, 
<a href="/search/eess?searchtype=author&query=Tatham%2C+A+J">Andrew J Tatham</a>, 
<a href="/search/eess?searchtype=author&query=Ritchie%2C+C">Craig Ritchie</a>, 
<a href="/search/eess?searchtype=author&query=Trucco%2C+E">Emanuele Trucco</a>, 
<a href="/search/eess?searchtype=author&query=Dhillon%2C+B">Baljean Dhillon</a>, 
<a href="/search/eess?searchtype=author&query=MacGillivray%2C+T+J">Thomas J MacGillivray</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 20 figures, 7 tables, submitted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Purpose: To develop an automatic method of quantifying optic disc pallor in
fundus photographs and determine associations with peripapillary retinal nerve
fibre layer (pRNFL) thickness.
<br />Methods: We used deep learning to segment the optic disc, fovea, and vessels
in fundus photographs, and measured pallor. We assessed the relationship
between pallor and pRNFL thickness derived from optical coherence tomography
scans in 118 participants. Separately, we used images diagnosed by clinical
inspection as pale (N=45) and assessed how measurements compared to healthy
controls (N=46). We also developed automatic rejection thresholds, and tested
the software for robustness to camera type, image format, and resolution.
<br />Results: We developed software that automatically quantified disc pallor
across several zones in fundus photographs. Pallor was associated with pRNFL
thickness globally (\b{eta} = -9.81 (SE = 3.16), p &lt; 0.05), in the temporal
inferior zone (\b{eta} = -29.78 (SE = 8.32), p &lt; 0.01), with the nasal/temporal
ratio (\b{eta} = 0.88 (SE = 0.34), p &lt; 0.05), and in the whole disc (\b{eta} =
-8.22 (SE = 2.92), p &lt; 0.05). Furthermore, pallor was significantly higher in
the patient group. Lastly, we demonstrate the analysis to be robust to camera
type, image format, and resolution.
<br />Conclusions: We developed software that automatically locates and quantifies
disc pallor in fundus photographs and found associations between pallor
measurements and pRNFL thickness.
<br />Translational relevance: We think our method will be useful for the
identification, monitoring and progression of diseases characterized by disc
pallor/optic atrophy, including glaucoma, compression, and potentially in
neurodegenerative disorders.
</p>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07219" title="Abstract">arXiv:2311.07219</a> (cross-list from math.CO) [<a href="/pdf/2311.07219" title="Download PDF">pdf</a>, <a href="/format/2311.07219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Blockers and Transversals of Maximum Independent Sets in  Co-Comparability Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lucke%2C+F">Felicia Lucke</a>, 
<a href="/search/math?searchtype=author&query=Ries%2C+B">Bernard Ries</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">In this paper, we consider the following two problems: (i) Deletion
Blocker($\alpha$) where we are given an undirected graph $G=(V,E)$ and two
integers $k,d\geq 1$ and ask whether there exists a subset of vertices
$S\subseteq V$ with $|S|\leq k$ such that $\alpha(G-S) \leq \alpha(G)-d$, that
is the independence number of $G$ decreases by at least $d$ after having
removed the vertices from $S$; (ii) Transversal($\alpha$) where we are given an
undirected graph $G=(V,E)$ and two integers $k,d\geq 1$ and ask whether there
exists a subset of vertices $S\subseteq V$ with $|S|\leq k$ such that for every
maximum independent set $I$ we have $|I\cap S| \geq d$. We show that both
problems are polynomial-time solvable in the class of co-comparability graphs
by reducing them to the well-known Vertex Cut problem. Our results generalize a
result of [Chang et al., Maximum clique transversals, Lecture Notes in Computer
Science 2204, pp. 32-43, WG 2001] and a recent result of [Hoang et al.,
Assistance and interdiction problems on interval graphs, Discrete Applied
Mathematics 340, pp. 153-170, 2023].
</p>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07222" title="Abstract">arXiv:2311.07222</a> (cross-list from physics.ao-ph) [<a href="/pdf/2311.07222" title="Download PDF">pdf</a>, <a href="/format/2311.07222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural General Circulation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Kochkov%2C+D">Dmitrii Kochkov</a>, 
<a href="/search/physics?searchtype=author&query=Yuval%2C+J">Janni Yuval</a>, 
<a href="/search/physics?searchtype=author&query=Langmore%2C+I">Ian Langmore</a>, 
<a href="/search/physics?searchtype=author&query=Norgaard%2C+P">Peter Norgaard</a>, 
<a href="/search/physics?searchtype=author&query=Smith%2C+J">Jamie Smith</a>, 
<a href="/search/physics?searchtype=author&query=Mooers%2C+G">Griffin Mooers</a>, 
<a href="/search/physics?searchtype=author&query=Lottes%2C+J">James Lottes</a>, 
<a href="/search/physics?searchtype=author&query=Rasp%2C+S">Stephan Rasp</a>, 
<a href="/search/physics?searchtype=author&query=D%C3%BCben%2C+P">Peter D&#xfc;ben</a>, 
<a href="/search/physics?searchtype=author&query=Kl%C3%B6wer%2C+M">Milan Kl&#xf6;wer</a>, 
<a href="/search/physics?searchtype=author&query=Hatfield%2C+S">Sam Hatfield</a>, 
<a href="/search/physics?searchtype=author&query=Battaglia%2C+P">Peter Battaglia</a>, 
<a href="/search/physics?searchtype=author&query=Sanchez-Gonzalez%2C+A">Alvaro Sanchez-Gonzalez</a>, 
<a href="/search/physics?searchtype=author&query=Willson%2C+M">Matthew Willson</a>, 
<a href="/search/physics?searchtype=author&query=Brenner%2C+M+P">Michael P. Brenner</a>, 
<a href="/search/physics?searchtype=author&query=Hoyer%2C+S">Stephan Hoyer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 67 pages, 34 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">General circulation models (GCMs) are the foundation of weather and climate
prediction. GCMs are physics-based simulators which combine a numerical solver
for large-scale dynamics with tuned representations for small-scale processes
such as cloud formation. Recently, machine learning (ML) models trained on
reanalysis data achieved comparable or better skill than GCMs for deterministic
weather forecasting. However, these models have not demonstrated improved
ensemble forecasts, or shown sufficient stability for long-term weather and
climate simulations. Here we present the first GCM that combines a
differentiable solver for atmospheric dynamics with ML components, and show
that it can generate forecasts of deterministic weather, ensemble weather and
climate on par with the best ML and physics-based methods. NeuralGCM is
competitive with ML models for 1-10 day forecasts, and with the European Centre
for Medium-Range Weather Forecasts ensemble prediction for 1-15 day forecasts.
With prescribed sea surface temperature, NeuralGCM can accurately track climate
metrics such as global mean temperature for multiple decades, and climate
forecasts with 140 km resolution exhibit emergent phenomena such as realistic
frequency and trajectories of tropical cyclones. For both weather and climate,
our approach offers orders of magnitude computational savings over conventional
GCMs. Our results show that end-to-end deep learning is compatible with tasks
performed by conventional GCMs, and can enhance the large-scale physical
simulations that are essential for understanding and predicting the Earth
system.
</p>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07231" title="Abstract">arXiv:2311.07231</a> (cross-list from q-fin.CP) [<a href="/pdf/2311.07231" title="Download PDF">pdf</a>, <a href="/format/2311.07231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error Analysis of Option Pricing via Deep PDE Solvers: Empirical Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Assabumrungrat%2C+R">Rawin Assabumrungrat</a>, 
<a href="/search/q-fin?searchtype=author&query=Minami%2C+K">Kentaro Minami</a>, 
<a href="/search/q-fin?searchtype=author&query=Hirano%2C+M">Masanori Hirano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Finance (q-fin.CP)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Option pricing, a fundamental problem in finance, often requires solving
non-linear partial differential equations (PDEs). When dealing with multi-asset
options, such as rainbow options, these PDEs become high-dimensional, leading
to challenges posed by the curse of dimensionality. While deep learning-based
PDE solvers have recently emerged as scalable solutions to this
high-dimensional problem, their empirical and quantitative accuracy remains not
well-understood, hindering their real-world applicability. In this study, we
aimed to offer actionable insights into the utility of Deep PDE solvers for
practical option pricing implementation. Through comparative experiments, we
assessed the empirical performance of these solvers in high-dimensional
contexts. Our investigation identified three primary sources of errors in Deep
PDE solvers: (i) errors inherent in the specifications of the target option and
underlying assets, (ii) errors originating from the asset model simulation
methods, and (iii) errors stemming from the neural network training. Through
ablation studies, we evaluated the individual impact of each error source. Our
results indicate that the Deep BSDE method (DBSDE) is superior in performance
and exhibits robustness against variations in option specifications. In
contrast, some other methods are overly sensitive to option specifications,
such as time to expiration. We also find that the performance of these methods
improves inversely proportional to the square root of batch size and the number
of time steps. This observation can aid in estimating computational resources
for achieving desired accuracies with Deep PDE solvers.
</p>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07234" title="Abstract">arXiv:2311.07234</a> (cross-list from eess.IV) [<a href="/pdf/2311.07234" title="Download PDF">pdf</a>, <a href="/format/2311.07234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-task learning for joint weakly-supervised segmentation and aortic  arch anomaly classification in fetal cardiac MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ramirez%2C+P">Paula Ramirez</a>, 
<a href="/search/eess?searchtype=author&query=Uus%2C+A">Alena Uus</a>, 
<a href="/search/eess?searchtype=author&query=van+Poppel%2C+M+P+M">Milou P.M. van Poppel</a>, 
<a href="/search/eess?searchtype=author&query=Grigorescu%2C+I">Irina Grigorescu</a>, 
<a href="/search/eess?searchtype=author&query=Steinweg%2C+J+K">Johannes K. Steinweg</a>, 
<a href="/search/eess?searchtype=author&query=Lloyd%2C+D+F+A">David F.A. Lloyd</a>, 
<a href="/search/eess?searchtype=author&query=Pushparajah%2C+K">Kuberan Pushparajah</a>, 
<a href="/search/eess?searchtype=author&query=King%2C+A+P">Andrew P. King</a>, 
<a href="/search/eess?searchtype=author&query=Deprez%2C+M">Maria Deprez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) <a href="https://melba-journal.org/2023:015">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Machine.Learning.for.Biomedical.Imaging. 2 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Congenital Heart Disease (CHD) is a group of cardiac malformations present
already during fetal life, representing the prevailing category of birth
defects globally. Our aim in this study is to aid 3D fetal vessel topology
visualisation in aortic arch anomalies, a group which encompasses a range of
conditions with significant anatomical heterogeneity. We present a multi-task
framework for automated multi-class fetal vessel segmentation from 3D black
blood T2w MRI and anomaly classification. Our training data consists of binary
manual segmentation masks of the cardiac vessels' region in individual subjects
and fully-labelled anomaly-specific population atlases. Our framework combines
deep learning label propagation using VoxelMorph with 3D Attention U-Net
segmentation and DenseNet121 anomaly classification. We target 11 cardiac
vessels and three distinct aortic arch anomalies, including double aortic arch,
right aortic arch, and suspected coarctation of the aorta. We incorporate an
anomaly classifier into our segmentation pipeline, delivering a multi-task
framework with the primary motivation of correcting topological inaccuracies of
the segmentation. The hypothesis is that the multi-task approach will encourage
the segmenter network to learn anomaly-specific features. As a secondary
motivation, an automated diagnosis tool may have the potential to enhance
diagnostic confidence in a decision support setting. Our results showcase that
our proposed training strategy significantly outperforms label propagation and
a network trained exclusively on propagated labels. Our classifier outperforms
a classifier trained exclusively on T2w volume images, with an average balanced
accuracy of 0.99 (0.01) after joint training. Adding a classifier improves the
anatomical and topological accuracy of all correctly classified double aortic
arch subjects.
</p>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07235" title="Abstract">arXiv:2311.07235</a> (cross-list from eess.IV) [<a href="/pdf/2311.07235" title="Download PDF">pdf</a>, <a href="/format/2311.07235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepMetricEye: Metric Depth Estimation in Periocular VR Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sun%2C+Y">Yitong Sun</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Z">Zijian Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Diels%2C+C">Cyriel Diels</a>, 
<a href="/search/eess?searchtype=author&query=Asadipour%2C+A">Ali Asadipour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Despite the enhanced realism and immersion provided by VR headsets, users
frequently encounter adverse effects such as digital eye strain (DES), dry eye,
and potential long-term visual impairment due to excessive eye stimulation from
VR displays and pressure from the mask. Recent VR headsets are increasingly
equipped with eye-oriented monocular cameras to segment ocular feature maps.
Yet, to compute the incident light stimulus and observe periocular condition
alterations, it is imperative to transform these relative measurements into
metric dimensions. To bridge this gap, we propose a lightweight framework
derived from the U-Net 3+ deep learning backbone that we re-optimised, to
estimate measurable periocular depth maps. Compatible with any VR headset
equipped with an eye-oriented monocular camera, our method reconstructs
three-dimensional periocular regions, providing a metric basis for related
light stimulus calculation protocols and medical guidelines. Navigating the
complexities of data collection, we introduce a Dynamic Periocular Data
Generation (DPDG) environment based on UE MetaHuman, which synthesises
thousands of training images from a small quantity of human facial scan data.
Evaluated on a sample of 36 participants, our method exhibited notable efficacy
in the periocular global precision evaluation experiment, and the pupil
diameter measurement.
</p>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07236" title="Abstract">arXiv:2311.07236</a> (cross-list from physics.app-ph) [<a href="/pdf/2311.07236" title="Download PDF">pdf</a>, <a href="/format/2311.07236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A micro-mechanics based extension of the GTN continuum model accounting  for random void distributions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Holte%2C+I">I. Holte</a>, 
<a href="/search/physics?searchtype=author&query=Nielsen%2C+K+L">K.L. Nielsen</a>, 
<a href="/search/physics?searchtype=author&query=Mart%C3%ADnez-Pa%C3%B1eda%2C+E">E. Mart&#xed;nez-Pa&#xf1;eda</a>, 
<a href="/search/physics?searchtype=author&query=Niordson%2C+C+F">C.F. Niordson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applied Physics (physics.app-ph)</span>; Materials Science (cond-mat.mtrl-sci); Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">Randomness in the void distribution within a ductile metal complicates
quantitative modeling of damage following the void growth to coalescence
failure process. Though the sequence of micro-mechanisms leading to ductile
failure is known from unit cell models, often based on assumptions of a regular
distribution of voids, the effect of randomness remains a challenge. In the
present work, mesoscale unit cell models, each containing an ensemble of four
voids of equal size that are randomly distributed, are used to find statistical
effects on the yield surface of the homogenized material. A yield locus is
found based on a mean yield surface and a standard deviation of yield points
obtained from 15 realizations of the four-void unit cells. It is found that the
classical GTN model very closely agrees with the mean of the yield points
extracted from the unit cell calculations with random void distributions, while
the standard deviation $\textbf{S}$ varies with the imposed stress state. It is
shown that the standard deviation is nearly zero for stress triaxialities
$T\leq1/3$, while it rapidly increases for triaxialities above $T\approx 1$,
reaching maximum values of about $\textbf{S}/\sigma_0\approx0.1$ at $T \approx
4$. At even higher triaxialities it decreases slightly. The results indicate
that the dependence of the standard deviation on the stress state follows from
variations in the deformation mechanism since a well-correlated variation is
found for the volume fraction of the unit cell that deforms plastically at
yield. Thus, the random void distribution activates different complex
localization mechanisms at high stress triaxialities that differ from the
ligament thinning mechanism forming the basis for the classical GTN model. A
method for introducing the effect of randomness into the GTN continuum model is
presented, and an excellent comparison to the unit cell yield locus is
achieved.
</p>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07259" title="Abstract">arXiv:2311.07259</a> (cross-list from stat.ML) [<a href="/pdf/2311.07259" title="Download PDF">pdf</a>, <a href="/ps/2311.07259" title="Download PostScript">ps</a>, <a href="/format/2311.07259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Bounding Causal Effects under Markov Equivalence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bellot%2C+A">Alexis Bellot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Predicting the effect of unseen interventions is a fundamental research
question across the data sciences. It is well established that, in general,
such questions cannot be answered definitively from observational data, e.g.,
as a consequence of unobserved confounding. A generalization of this task is to
determine non-trivial bounds on causal effects induced by the data, also known
as the task of partial causal identification. In the literature, several
algorithms have been developed for solving this problem. Most, however, require
a known parametric form or a fully specified causal diagram as input, which is
usually not available in practical applications. In this paper, we assume as
input a less informative structure known as a Partial Ancestral Graph, which
represents a Markov equivalence class of causal diagrams and is learnable from
observational data. In this more "data-driven" setting, we provide a systematic
algorithm to derive bounds on causal effects that can be computed analytically.
</p>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07265" title="Abstract">arXiv:2311.07265</a> (cross-list from quant-ph) [<a href="/pdf/2311.07265" title="Download PDF">pdf</a>, <a href="/format/2311.07265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quotient Space Quantum Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Xia%2C+J">JingLei Xia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Quantum error-correcting codes are crucial for quantum computing and
communication. Currently, these codes are mainly categorized into additive,
non-additive, and surface codes. Additive and non-additive codes utilize one or
more invariant subspaces of the stabilizer G to construct quantum codes.
Therefore, the selection of these invariant subspaces is a key issue. In this
paper, we propose a solution to this problem by introducing quotient space
codes and a construction method for quotient space quantum codes. This new
framework unifies additive and non-additive quantum codes. We demonstrate the
codeword stabilizer codes as a special case within this framework and
supplement its error-correction distance. Furthermore, we provide a simple
proof of the Singleton bound for this quantum code by establishing the code
bound of quotient space codes and discuss the code bounds for pure and impure
codes. The quotient space approach offers a concise and clear mathematical form
for the study of quantum codes.
</p>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07266" title="Abstract">arXiv:2311.07266</a> (cross-list from quant-ph) [<a href="/pdf/2311.07266" title="Download PDF">pdf</a>, <a href="/format/2311.07266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-testing of true multipartite entangled states
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Adhikary%2C+R">Ranendu Adhikary</a>, 
<a href="/search/quant-ph?searchtype=author&query=Mishra%2C+A">Abhishek Mishra</a>, 
<a href="/search/quant-ph?searchtype=author&query=Rahaman%2C+R">Ramij Rahaman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, one figure, comments are welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Self-testing is a method to certify quantum states and measurements in a
device-independent way. The device-independent certification of quantum
properties is purely based on input-output measurement statistics of the
involved devices with minimal knowledge about their internal workings.
Bipartite pure entangled states can be self-tested, but, in the case of
multipartite pure entangled states, the answer is not so straightforward.
Nevertheless, \v{S}upi\'{c} et al. recently introduced a novel self-testing
method for any pure entangled quantum state, which leverages network assistance
and relies on bipartite entangled measurements. Hence, their scheme loses the
true device-independent flavor of self-testing. In this regard, we provide a
self-testing scheme for genuine multipartite pure entangle states in the true
sense by employing a generalized Hardy-type non-local argument. It is important
to note that our approach involves only local operations and classical
communications and it does not depend on bipartite entangled measurements and
is free from any network assistance. In addition, we provide the
device-independent bound of the maximum probability of success of the
generalized Hardy-type nonlocality test.
</p>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07310" title="Abstract">arXiv:2311.07310</a> (cross-list from math.OC) [<a href="/pdf/2311.07310" title="Download PDF">pdf</a>, <a href="/format/2311.07310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Optimization on Quantum Hardware: Feasibility for a Process  Industry Use Case
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Nenno%2C+D+M">Dennis Michael Nenno</a>, 
<a href="/search/math?searchtype=author&query=Caspari%2C+A">Adrian Caspari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">The quest for real-time dynamic optimization solutions in the process
industry represents a formidable computational challenge, particularly within
the realm of applications like model predictive control where rapid and
reliable computations are critical. Conventional methods can struggle to
surmount the complexities of such tasks. Quantum computing and quantum
annealing emerge as avant-garde contenders to transcend conventional
computational constraints. We convert a dynamic optimization problem,
characterized by a system of differential equations, into a Quadratic
Unconstrained Binary Optimization problem, enabling quantum computational
approaches. The empirical findings synthesized from classical methods,
simulated annealing, quantum annealing via D-Wave's quantum annealer, and
hybrid solver methodologies, illuminate the intricate landscape of
computational prowess essential for tackling complex and high-dimensional
dynamic optimization problems. Our findings suggest that while quantum
annealing is a maturing technology that currently does not outperform
state-of-the-art classical solvers, continuous improvements could eventually
aid in increasing efficiency within the chemical process industry.
</p>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07315" title="Abstract">arXiv:2311.07315</a> (cross-list from q-bio.NC) [<a href="/pdf/2311.07315" title="Download PDF">pdf</a>, <a href="/format/2311.07315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An introduction to reinforcement learning for neuroscience
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Jensen%2C+K+T">Kristopher T. Jensen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code available at: <a href="https://colab.research.google.com/drive/1kWOz2Uxn0cf2c4YizqIXQKWyxeYd6wvL?usp=sharing">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Reinforcement learning has a rich history in neuroscience, from early work on
dopamine as a reward prediction error signal for temporal difference learning
(Schultz et al., 1997) to recent work suggesting that dopamine could implement
a form of 'distributional reinforcement learning' popularized in deep learning
(Dabney et al., 2020). Throughout this literature, there has been a tight link
between theoretical advances in reinforcement learning and neuroscientific
experiments and findings. As a result, the theories describing our experimental
data have become increasingly complex and difficult to navigate. In this
review, we cover the basic theory underlying classical work in reinforcement
learning and build up to an introductory overview of methods used in modern
deep reinforcement learning that have found applications in systems
neuroscience. We start with an overview of the reinforcement learning problem
and classical temporal difference algorithms, followed by a discussion of
'model-free' and 'model-based' reinforcement learning together with methods
such as DYNA and successor representations that fall in between these two
categories. Throughout these sections, we highlight the close parallels between
the machine learning methods and related work in both experimental and
theoretical neuroscience. We then provide an introduction to deep reinforcement
learning with examples of how these methods have been used to model different
learning phenomena in the systems neuroscience literature, such as
meta-reinforcement learning (Wang et al., 2018) and distributional
reinforcement learning (Dabney et al., 2020). Code that implements the methods
discussed in this work and generates the figures is also provided.
</p>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07338" title="Abstract">arXiv:2311.07338</a> (cross-list from math.OC) [<a href="/pdf/2311.07338" title="Download PDF">pdf</a>, <a href="/format/2311.07338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the mathematical replication of the MacKay effect from redundant  stimulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tamekue%2C+C">Cyprien Tamekue</a>, 
<a href="/search/math?searchtype=author&query=Prandi%2C+D">Dario Prandi</a>, 
<a href="/search/math?searchtype=author&query=Chitour%2C+Y">Yacine Chitour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Analysis of PDEs (math.AP); Numerical Analysis (math.NA); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">In this study, we investigate the intricate connection between visual
perception and the mathematical modelling of neural activity in the primary
visual cortex (V1), focusing on replicating the MacKay effect [Mackay, Nature
1957]. While bifurcation theory has been a prominent mathematical approach for
addressing issues in neuroscience, especially in describing spontaneous pattern
formations in V1 due to parameter changes, it faces challenges in scenarios
with localised sensory inputs. This is evident, for instance, in Mackay's
psychophysical experiments, where the redundancy of visual stimuli information
results in irregular shapes, making bifurcation theory and multi-scale analysis
less effective. To address this, we follow a mathematical viewpoint based on
the input-output controllability of an Amari-type neural fields model. This
framework views the sensory input as a control function, cortical
representation via the retino-cortical map of the visual stimulus that captures
the distinct features of the stimulus, specifically the central redundancy in
MacKay's funnel pattern ``MacKay rays''. From a control theory point of view,
the exact controllability property of the Amari-type equation is discussed both
for linear and nonlinear response functions. Then, applied to the MacKay effect
replication, we adjust the parameter representing intra-neuron connectivity to
ensure that, in the absence of sensory input, cortical activity exponentially
stabilises to the stationary state that we perform quantitative and qualitative
studies to show that it captures all the essential features of the induced
after-image reported by MacKay
</p>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07345" title="Abstract">arXiv:2311.07345</a> (cross-list from eess.AS) [<a href="/pdf/2311.07345" title="Download PDF">pdf</a>, <a href="/format/2311.07345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot Duet Singing Voices Separation with Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yu%2C+C">Chin-Yun Yu</a>, 
<a href="/search/eess?searchtype=author&query=Postolache%2C+E">Emilian Postolache</a>, 
<a href="/search/eess?searchtype=author&query=Rodol%C3%A0%2C+E">Emanuele Rodol&#xe0;</a>, 
<a href="/search/eess?searchtype=author&query=Fazekas%2C+G">Gy&#xf6;rgy Fazekas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 1 figure. Published at Sound Demixing Workshop 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">In recent studies, diffusion models have shown promise as priors for solving
audio inverse problems. These models allow us to sample from the posterior
distribution of a target signal given an observed signal by manipulating the
diffusion process. However, when separating audio sources of the same type,
such as duet singing voices, the prior learned by the diffusion process may not
be sufficient to maintain the consistency of the source identity in the
separated audio. For example, the singer may change from one to another
occasionally. Tackling this problem will be useful for separating sources in a
choir, or a mixture of multiple instruments with similar timbre, without
acquiring large amounts of paired data. In this paper, we examine this problem
in the context of duet singing voices separation, and propose a method to
enforce the coherency of singer identity by splitting the mixture into
overlapping segments and performing posterior sampling in an auto-regressive
manner, conditioning on the previous segment. We evaluate the proposed method
on the MedleyVox dataset and show that the proposed method outperforms the
naive posterior sampling baseline. Our source code and the pre-trained model
are publicly available at https://github.com/yoyololicon/duet-svs-diffusion.
</p>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07348" title="Abstract">arXiv:2311.07348</a> (cross-list from eess.IV) [<a href="/pdf/2311.07348" title="Download PDF">pdf</a>, <a href="/ps/2311.07348" title="Download PostScript">ps</a>, <a href="/format/2311.07348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deformable Groupwise Registration Using a Locally Low-Rank Dissimilarity  Metric for Myocardial Strain Estimation from Cardiac Cine MRI Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+H">Haiyang Chen</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+J">Juan Gao</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+C">Chenxi Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Objective: Cardiovascular magnetic resonance-feature tracking (CMR-FT)
represents a group of methods for myocardial strain estimation from cardiac
cine MRI images. Established CMR-FT methods are mainly based on optical flow or
pairwise registration. However, these methods suffer from either inaccurate
estimation of large motion or drift effect caused by accumulative tracking
errors. In this work, we propose a deformable groupwise registration method
using a locally low-rank (LLR) dissimilarity metric for CMR-FT. Methods: The
proposed method (Groupwise-LLR) tracks the feature points by a groupwise
registration-based two-step strategy. Unlike the globally low-rank (GLR)
dissimilarity metric, the proposed LLR metric imposes low-rankness on local
image patches rather than the whole image. We quantitatively compared
Groupwise-LLR with the Farneback optical flow, a pairwise registration method,
and a GLR-based groupwise registration method on simulated and in vivo
datasets. Results: Results from the simulated dataset showed that Groupwise-LLR
achieved more accurate tracking and strain estimation compared with the other
methods. Results from the in vivo dataset showed that Groupwise-LLR achieved
more accurate tracking and elimination of the drift effect in late-diastole.
Inter-observer reproducibility of strain estimates was similar between all
studied methods. Conclusion: The proposed method estimates myocardial strains
more accurately due to the application of a groupwise registration-based
tracking strategy and an LLR-based dissimilarity metric. Significance: The
proposed CMR-FT method may facilitate more accurate estimation of myocardial
strains, especially in diastole, for clinical assessments of cardiac
dysfunction.
</p>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07366" title="Abstract">arXiv:2311.07366</a> (cross-list from stat.ML) [<a href="/pdf/2311.07366" title="Download PDF">pdf</a>, <a href="/format/2311.07366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> arfpy: A python package for density estimation and generative modeling  with adversarial random forests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Blesch%2C+K">Kristin Blesch</a>, 
<a href="/search/stat?searchtype=author&query=Wright%2C+M+N">Marvin N. Wright</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The software is available at <a href="https://github.com/bips-hb/arfpy">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper introduces $\textit{arfpy}$, a python implementation of
Adversarial Random Forests (ARF) (Watson et al., 2023), which is a lightweight
procedure for synthesizing new data that resembles some given data. The
software $\textit{arfpy}$ equips practitioners with straightforward
functionalities for both density estimation and generative modeling. The method
is particularly useful for tabular data and its competitive performance is
demonstrated in previous literature. As a major advantage over the mostly deep
learning based alternatives, $\textit{arfpy}$ combines the method's reduced
requirements in tuning efforts and computational resources with a user-friendly
python interface. This supplies audiences across scientific fields with
software to generate data effortlessly.
</p>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07372" title="Abstract">arXiv:2311.07372</a> (cross-list from quant-ph) [<a href="/pdf/2311.07372" title="Download PDF">pdf</a>, <a href="/format/2311.07372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multidimensional Electrical Networks and their Application to  Exponential Speedups for Graph Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+J">Jianqiang Li</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zur%2C+S">Sebastian Zur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">Recently, Apers and Piddock [TQC '23] strengthened the natural connection
between quantum walks and electrical networks by considering Kirchhoff's Law
and Ohm's Law. In this work, we develop the multidimensional electrical network
by defining Kirchhoff's Alternative Law and Ohm's Alternative Law based on the
novel multidimensional quantum walk framework by Jeffery and Zur [STOC '23].
This multidimensional electrical network allows us to sample from the
electrical flow obtained via a multidimensional quantum walk algorithm and
achieve exponential quantum-classical separations for certain graph problems.
<br />We first use this framework to find a marked vertex in one-dimensional random
hierarchical graphs as defined by Balasubramanian, Li, and Harrow [arXiv '23].
In this work, they generalised the well known exponential quantum-classical
separation of the welded tree problem by Childs, Cleve, Deotto, Farhi, Gutmann,
and Spielman [STOC '03] to random hierarchical graphs. Our result partially
recovers their results with an arguably simpler analysis. Furthermore, by
constructing a $3$-regular graph based on welded trees, this framework also
allows us to show an exponential speedup for the pathfinding problem. This
solves one of the open problems by Li [arXiv '23], where they construct a
non-regular graph and use the degree information to achieve a similar speedup.
<br />In analogy to the connection between the (edge-vertex) incidence matrix of a
graph and Kirchhoff's Law and Ohm's Law in an electrical network, we also
rebuild the connection between the alternative incidence matrix and Kirchhoff's
Alternative Law and Ohm's Alternative Law. By establishing this connection, we
expect that the multidimensional electrical network could have more
applications beyond quantum walks.
</p>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07404" title="Abstract">arXiv:2311.07404</a> (cross-list from math.OC) [<a href="/pdf/2311.07404" title="Download PDF">pdf</a>, <a href="/format/2311.07404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast convergence of trust-regions for non-isolated minima via analysis  of CG on indefinite matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Rebjock%2C+Q">Quentin Rebjock</a>, 
<a href="/search/math?searchtype=author&query=Boumal%2C+N">Nicolas Boumal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Trust-region methods (TR) can converge quadratically to minima where the
Hessian is positive definite. However, if the minima are not isolated, then the
Hessian there cannot be positive definite. The weaker
Polyak$\unicode{x2013}${\L}ojasiewicz (P{\L}) condition is compatible with
non-isolated minima, and it is enough for many algorithms to preserve good
local behavior. Yet, TR with an $\textit{exact}$ subproblem solver lacks even
basic features such as a capture theorem under P{\L}.
<br />In practice, a popular $\textit{inexact}$ subproblem solver is the truncated
conjugate gradient method (tCG). Empirically, TR-tCG exhibits super-linear
convergence under P{\L}. We confirm this theoretically.
<br />The main mathematical obstacle is that, under P{\L}, at points arbitrarily
close to minima, the Hessian has vanishingly small, possibly negative
eigenvalues. Thus, tCG is applied to ill-conditioned, indefinite systems. Yet,
the core theory underlying tCG is that of CG, which assumes a positive definite
operator. Accordingly, we develop new tools to analyze the dynamics of CG in
the presence of small eigenvalues of any sign, for the regime of interest to
TR-tCG.
</p>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07416" title="Abstract">arXiv:2311.07416</a> (cross-list from physics.geo-ph) [<a href="/pdf/2311.07416" title="Download PDF">pdf</a>, <a href="/ps/2311.07416" title="Download PostScript">ps</a>, <a href="/format/2311.07416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Three-dimensional granular flow simulation using graph neural  network-based learned simulator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Choi%2C+Y">Yongjin Choi</a>, 
<a href="/search/physics?searchtype=author&query=Kumar%2C+K">Krishna Kumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geophysics (physics.geo-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Reliable evaluations of geotechnical hazards like landslides and debris flow
require accurate simulation of granular flow dynamics. Traditional numerical
methods can simulate the complex behaviors of such flows that involve
solid-like to fluid-like transitions, but they are computationally intractable
when simulating large-scale systems. Surrogate models based on statistical or
machine learning methods are a viable alternative, but they are typically
empirical and rely on a confined set of parameters in evaluating associated
risks. Due to their permutation-dependent learning, conventional machine
learning models require an unreasonably large amount of training data for
building generalizable surrogate models. We employ a graph neural network
(GNN), a novel deep learning technique, to develop a GNN-based simulator (GNS)
for granular flows to address these issues. Graphs represent the state of
granular flows and interactions, like the exchange of energy and momentum
between grains, and GNN learns the local interaction law. GNS takes the current
state of the granular flow and estimates the next state using Euler explicit
integration. We train GNS on a limited set of granular flow trajectories and
evaluate its performance in a three-dimensional granular column collapse
domain. GNS successfully reproduces the overall behaviors of column collapses
with various aspect ratios that were not encountered during training. The
computation speed of GNS outperforms high-fidelity numerical simulators by 300
times.
</p>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07452" title="Abstract">arXiv:2311.07452</a> (cross-list from stat.ML) [<a href="/pdf/2311.07452" title="Download PDF">pdf</a>, <a href="/format/2311.07452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable Boosting Machines with Sparsity -- Maintaining  Explainability in High-Dimensional Settings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Greenwell%2C+B+M">Brandon M. Greenwell</a>, 
<a href="/search/stat?searchtype=author&query=Dahlmann%2C+A">Annika Dahlmann</a>, 
<a href="/search/stat?searchtype=author&query=Dhoble%2C+S">Saurabh Dhoble</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Compared to "black-box" models, like random forests and deep neural networks,
explainable boosting machines (EBMs) are considered "glass-box" models that can
be competitively accurate while also maintaining a higher degree of
transparency and explainability. However, EBMs become readily less transparent
and harder to interpret in high-dimensional settings with many predictor
variables; they also become more difficult to use in production due to
increases in scoring time. We propose a simple solution based on the least
absolute shrinkage and selection operator (LASSO) that can help introduce
sparsity by reweighting the individual model terms and removing the less
relevant ones, thereby allowing these models to maintain their transparency and
relatively fast scoring times in higher-dimensional settings. In short,
post-processing a fitted EBM with many (i.e., possibly hundreds or thousands)
of terms using the LASSO can help reduce the model's complexity and drastically
improve scoring time. We illustrate the basic idea using two real-world
examples with code.
</p>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07474" title="Abstract">arXiv:2311.07474</a> (cross-list from stat.ML) [<a href="/pdf/2311.07474" title="Download PDF">pdf</a>, <a href="/format/2311.07474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Federated Data Fusion-Based Prognostic Model for Applications with  Multi-Stream Incomplete Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Arabi%2C+M">Madi Arabi</a>, 
<a href="/search/stat?searchtype=author&query=Fang%2C+X">Xiaolei Fang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP); Methodology (stat.ME)

</div>
<p class="mathjax">Most prognostic methods require a decent amount of data for model training.
In reality, however, the amount of historical data owned by a single
organization might be small or not large enough to train a reliable prognostic
model. To address this challenge, this article proposes a federated prognostic
model that allows multiple users to jointly construct a failure time prediction
model using their multi-stream, high-dimensional, and incomplete data while
keeping each user's data local and confidential. The prognostic model first
employs multivariate functional principal component analysis to fuse the
multi-stream degradation signals. Then, the fused features coupled with the
times-to-failure are utilized to build a (log)-location-scale regression model
for failure prediction. To estimate parameters using distributed datasets and
keep the data privacy of all participants, we propose a new federated algorithm
for feature extraction. Numerical studies indicate that the performance of the
proposed model is the same as that of classic non-federated prognostic models
and is better than that of the models constructed by each user itself.
</p>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07476" title="Abstract">arXiv:2311.07476</a> (cross-list from quant-ph) [<a href="/pdf/2311.07476" title="Download PDF">pdf</a>, <a href="/ps/2311.07476" title="Download PostScript">ps</a>, <a href="/format/2311.07476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimal Equational Theories for Quantum Circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Cl%C3%A9ment%2C+A">Alexandre Cl&#xe9;ment</a>, 
<a href="/search/quant-ph?searchtype=author&query=Delorme%2C+N">No&#xe9; Delorme</a>, 
<a href="/search/quant-ph?searchtype=author&query=Perdrix%2C+S">Simon Perdrix</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">We introduce the first minimal and complete equational theory for quantum
circuits. Hence, we show that any true equation on quantum circuits can be
derived from simple rules, all of them being standard except a novel but
intuitive one which states that a multi-control $2\pi$ rotation is nothing but
the identity. Our work improves on the recent complete equational theories for
quantum circuits, by getting rid of several rules including a fairly
unpractical one. One of our main contributions is to prove the minimality of
the equational theory, i.e. none of the rules can be derived from the other
ones. More generally, we demonstrate that any complete equational theory on
quantum circuits (when all gates are unitary) requires rules acting on an
unbounded number of qubits. Finally, we also simplify the complete equational
theories for quantum circuits with ancillary qubits and/or qubit discarding.
</p>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07487" title="Abstract">arXiv:2311.07487</a> (cross-list from eess.SP) [<a href="/pdf/2311.07487" title="Download PDF">pdf</a>, <a href="/format/2311.07487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vertiport Navigation Requirements and Multisensor Architecture  Considerations for Urban Air Mobility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Crespillo%2C+O+G">Omar Garcia Crespillo</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+C">Chen Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Simonetti%2C+M">Maximilian Simonetti</a>, 
<a href="/search/eess?searchtype=author&query=Gerbeth%2C+D">Daniel Gerbeth</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+Y">Young-Hee Lee</a>, 
<a href="/search/eess?searchtype=author&query=Hao%2C+W">Wenhan Hao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Communication, Navigation and Surveillance (CNS) technologies are key
enablers for future safe operation of drones in urban environments. However,
the design of navigation technologies for these new applications is more
challenging compared to e.g., civil aviation. On the one hand, the use cases
and operations in urban environments are expected to have stringent
requirements in terms of accuracy, integrity, continuity and availability. On
the other hand, airborne sensors may not be based on high-quality equipment as
in civil aviation and solutions need to rely on tighter multisensor solutions,
whose safety is difficult to assess. In this work, we first provide some
initial navigation requirements related to precision approach operations based
on recently proposed vertiport designs. Then, we provide an overview of a
possible multisensor navigation architecture solution able to support these
types of operations and we comment on the challenges of each of the subsystems.
Finally, initial proof of concept for some navigation sensor subsystems is
presented based on flight trials performed during the German Aerospace Center
(DLR) project HorizonUAM.
</p>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07511" title="Abstract">arXiv:2311.07511</a> (cross-list from stat.ML) [<a href="/pdf/2311.07511" title="Download PDF">pdf</a>, <a href="/ps/2311.07511" title="Download PostScript">ps</a>, <a href="/format/2311.07511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine learning for uncertainty estimation in fusing precipitation  observations from satellites and ground-based gauges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Papacharalampous%2C+G">Georgia Papacharalampous</a>, 
<a href="/search/stat?searchtype=author&query=Tyralis%2C+H">Hristos Tyralis</a>, 
<a href="/search/stat?searchtype=author&query=Doulamis%2C+N">Nikolaos Doulamis</a>, 
<a href="/search/stat?searchtype=author&query=Doulamis%2C+A">Anastasios Doulamis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Atmospheric and Oceanic Physics (physics.ao-ph); Applications (stat.AP); Methodology (stat.ME)

</div>
<p class="mathjax">To form precipitation datasets that are accurate and, at the same time, have
high spatial densities, data from satellites and gauges are often merged in the
literature. However, uncertainty estimates for the data acquired in this manner
are scarcely provided, although the importance of uncertainty quantification in
predictive modelling is widely recognized. Furthermore, the benefits that
machine learning can bring to the task of providing such estimates have not
been broadly realized and properly explored through benchmark experiments. The
present study aims at filling in this specific gap by conducting the first
benchmark tests on the topic. On a large dataset that comprises 15-year-long
monthly data spanning across the contiguous United States, we extensively
compared six learners that are, by their construction, appropriate for
predictive uncertainty quantification. These are the quantile regression (QR),
quantile regression forests (QRF), generalized random forests (GRF), gradient
boosting machines (GBM), light gradient boosting machines (LightGBM) and
quantile regression neural networks (QRNN). The comparison referred to the
competence of the learners in issuing predictive quantiles at nine levels that
facilitate a good approximation of the entire predictive probability
distribution, and was primarily based on the quantile and continuous ranked
probability skill scores. Three types of predictor variables (i.e., satellite
precipitation variables, distances between a point of interest and satellite
grid points, and elevation at a point of interest) were used in the comparison
and were additionally compared with each other. This additional comparison was
based on the explainable machine learning concept of feature importance. The
results suggest that the order from the best to the worst of the learners for
the task investigated is the following: LightGBM, QRF, GRF, GBM, QRNN and QR...
</p>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07513" title="Abstract">arXiv:2311.07513</a> (cross-list from q-fin.GN) [<a href="/pdf/2311.07513" title="Download PDF">pdf</a>, <a href="/ps/2311.07513" title="Download PostScript">ps</a>, <a href="/format/2311.07513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hypothesis on Good Practices for AI-based Systems for Financial Time  Series Forecasting: Towards Domain-Driven XAI Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Misheva%2C+B+H">Branka Hadji Misheva</a>, 
<a href="/search/q-fin?searchtype=author&query=Osterrieder%2C+J">Joerg Osterrieder</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Finance (q-fin.GN)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Machine learning and deep learning have become increasingly prevalent in
financial prediction and forecasting tasks, offering advantages such as
enhanced customer experience, democratising financial services, improving
consumer protection, and enhancing risk management. However, these complex
models often lack transparency and interpretability, making them challenging to
use in sensitive domains like finance. This has led to the rise of eXplainable
Artificial Intelligence (XAI) methods aimed at creating models that are easily
understood by humans. Classical XAI methods, such as LIME and SHAP, have been
developed to provide explanations for complex models. While these methods have
made significant contributions, they also have limitations, including
computational complexity, inherent model bias, sensitivity to data sampling,
and challenges in dealing with feature dependence. In this context, this paper
explores good practices for deploying explainability in AI-based systems for
finance, emphasising the importance of data quality, audience-specific methods,
consideration of data properties, and the stability of explanations. These
practices aim to address the unique challenges and requirements of the
financial industry and guide the development of effective XAI tools.
</p>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07518" title="Abstract">arXiv:2311.07518</a> (cross-list from stat.ML) [<a href="/pdf/2311.07518" title="Download PDF">pdf</a>, <a href="/format/2311.07518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FEMDA: a unified framework for discriminant analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Houdouin%2C+P">Pierre Houdouin</a>, 
<a href="/search/stat?searchtype=author&query=Jonckheere%2C+M">Matthieu Jonckheere</a>, 
<a href="/search/stat?searchtype=author&query=Pascal%2C+F">Frederic Pascal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Although linear and quadratic discriminant analysis are widely recognized
classical methods, they can encounter significant challenges when dealing with
non-Gaussian distributions or contaminated datasets. This is primarily due to
their reliance on the Gaussian assumption, which lacks robustness. We first
explain and review the classical methods to address this limitation and then
present a novel approach that overcomes these issues. In this new approach, the
model considered is an arbitrary Elliptically Symmetrical (ES) distribution per
cluster with its own arbitrary scale parameter. This flexible model allows for
potentially diverse and independent samples that may not follow identical
distributions. By deriving a new decision rule, we demonstrate that
maximum-likelihood parameter estimation and classification are simple,
efficient, and robust compared to state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07519" title="Abstract">arXiv:2311.07519</a> (cross-list from physics.acc-ph) [<a href="/pdf/2311.07519" title="Download PDF">pdf</a>, <a href="/format/2311.07519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning For Beamline Steering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Kante%2C+I">Isaac Kante</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Accelerator Physics (physics.acc-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Beam steering is the process involving the calibration of the angle and
position at which a particle accelerator's electron beam is incident upon the
x-ray target with respect to the rotation axis of the collimator. Beam Steering
is an essential task for light sources. In the case under study, the LINAC To
Undulator (LTU) section of the beamline is difficult to aim. Each use of the
accelerator requires re-calibration of the magnets in this section. This
involves a substantial amount of time and effort from human operators, while
reducing scientific throughput of the light source. We investigate the use of
deep neural networks to assist in this task. The deep learning models are
trained on archival data and then validated on simulation data. The performance
of the deep learning model is contrasted against that of trained human
operators.
</p>
</div>
</dd>
<dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07527" title="Abstract">arXiv:2311.07527</a> (cross-list from stat.ML) [<a href="/pdf/2311.07527" title="Download PDF">pdf</a>, <a href="/format/2311.07527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Identification of Driving Maneuver Patterns using a Robust  Hidden Semi-Markov Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Aguirre%2C+M">Matthew Aguirre</a>, 
<a href="/search/stat?searchtype=author&query=Sun%2C+W">Wenbo Sun</a>, 
<a href="/search/stat?searchtype=author&query=Jionghua">Jionghua</a> (Judy)Jin, 
<a href="/search/stat?searchtype=author&query=Chen%2C+Y">Yang Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Applications (stat.AP)

</div>
<p class="mathjax">There is an increase in interest to model driving maneuver patterns via the
automatic unsupervised clustering of naturalistic sequential kinematic driving
data. The patterns learned are often used in transportation research areas such
as eco-driving, road safety, and intelligent vehicles. One such model capable
of modeling these patterns is the Hierarchical Dirichlet Process Hidden
Semi-Markov Model (HDP-HSMM), as it is often used to estimate data
segmentation, state duration, and transition probabilities. While this model is
a powerful tool for automatically clustering observed sequential data, the
existing HDP-HSMM estimation suffers from an inherent tendency to overestimate
the number of states. This can result in poor estimation, which can potentially
impact impact transportation research through incorrect inference of driving
patterns. In this paper, a new robust HDP-HSMM (rHDP-HSMM) method is proposed
to reduce the number of redundant states and improve the consistency of the
model's estimation. Both a simulation study and a case study using naturalistic
driving data are presented to demonstrate the effectiveness of the proposed
rHDP-HSMM in identifying and inference of driving maneuver patterns.
</p>
</div>
</dd>
<dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07537" title="Abstract">arXiv:2311.07537</a> (cross-list from stat.ML) [<a href="/pdf/2311.07537" title="Download PDF">pdf</a>, <a href="/ps/2311.07537" title="Download PostScript">ps</a>, <a href="/format/2311.07537" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimating optical vegetation indices with Sentinel-1 SAR data and  AutoML
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Paluba%2C+D">Daniel Paluba</a>, 
<a href="/search/stat?searchtype=author&query=Saux%2C+B+L">Bertrand Le Saux</a>, 
<a href="/search/stat?searchtype=author&query=Sarti%2C+F">Francesco Sarti</a>, 
<a href="/search/stat?searchtype=author&query=Stych%2C+P">P&#x159;emysl Stych</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full research article. 30 pages, 13 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Applications (stat.AP)

</div>
<p class="mathjax">Current optical vegetation indices (VIs) for monitoring forest ecosystems are
widely used in various applications. However, continuous monitoring based on
optical satellite data can be hampered by atmospheric effects such as clouds.
On the contrary, synthetic aperture radar (SAR) data can offer insightful and
systematic forest monitoring with complete time series due to signal
penetration through clouds and day and night acquisitions. The goal of this
work is to overcome the issues affecting optical data with SAR data and serve
as a substitute for estimating optical VIs for forests using machine learning.
Time series of four VIs (LAI, FAPAR, EVI and NDVI) were estimated using
multitemporal Sentinel-1 SAR and ancillary data. This was enabled by creating a
paired multi-temporal and multi-modal dataset in Google Earth Engine (GEE),
including temporally and spatially aligned Sentinel-1, Sentinel-2, digital
elevation model (DEM), weather and land cover datasets (MMT-GEE). The use of
ancillary features generated from DEM and weather data improved the results.
The open-source Automatic Machine Learning (AutoML) approach, auto-sklearn,
outperformed Random Forest Regression for three out of four VIs, while a 1-hour
optimization length was enough to achieve sufficient results with an R2 of
69-84% low errors (0.05-0.32 of MAE depending on VI). Great agreement was also
found for selected case studies in the time series analysis and in the spatial
comparison between the original and estimated SAR-based VIs. In general,
compared to VIs from currently freely available optical satellite data and
available global VI products, a better temporal resolution (up to 240
measurements/year) and a better spatial resolution (20 m) were achieved using
estimated SAR-based VIs. A great advantage of the SAR-based VI is the ability
to detect abrupt forest changes with a sub-weekly temporal accuracy.
</p>
</div>
</dd>
<dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07563" title="Abstract">arXiv:2311.07563</a> (cross-list from math.OC) [<a href="/pdf/2311.07563" title="Download PDF">pdf</a>, <a href="/format/2311.07563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Control Policies of Hodgkin-Huxley Neuronal Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Madondo%2C+M">Malvern Madondo</a>, 
<a href="/search/math?searchtype=author&query=Verma%2C+D">Deepanshu Verma</a>, 
<a href="/search/math?searchtype=author&query=Ruthotto%2C+L">Lars Ruthotto</a>, 
<a href="/search/math?searchtype=author&query=Yong%2C+N+A">Nicholas Au Yong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2023, December 10th, 2023, New Orleans, United States, 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We present a neural network approach for closed-loop deep brain stimulation
(DBS). We cast the problem of finding an optimal neurostimulation strategy as a
control problem. In this setting, control policies aim to optimize therapeutic
outcomes by tailoring the parameters of a DBS system, typically via electrical
stimulation, in real time based on the patient's ongoing neuronal activity. We
approximate the value function offline using a neural network to enable
generating controls (stimuli) in real time via the feedback form. The neuronal
activity is characterized by a nonlinear, stiff system of differential
equations as dictated by the Hodgkin-Huxley model. Our training process
leverages the relationship between Pontryagin's maximum principle and
Hamilton-Jacobi-Bellman equations to update the value function estimates
simultaneously. Our numerical experiments illustrate the accuracy of our
approach for out-of-distribution samples and the robustness to moderate shocks
and disturbances in the system.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Tue, 14 Nov 23</h3>
<dl>
<dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1810.03361" title="Abstract">arXiv:1810.03361</a> (replaced) [<a href="/pdf/1810.03361" title="Download PDF">pdf</a>, <a href="/ps/1810.03361" title="Download PostScript">ps</a>, <a href="/format/1810.03361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Conditional Cooperation Model Predictive Control of  Interconnected Microgrids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sampathirao%2C+A+K">A. K. Sampathirao</a>, 
<a href="/search/cs?searchtype=author&query=Hofmann%2C+S">S. Hofmann</a>, 
<a href="/search/cs?searchtype=author&query=Raisch%2C+J">J. Raisch</a>, 
<a href="/search/cs?searchtype=author&query=Hans%2C+C+A">C. A. Hans</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Automatica, vol. 157, p. 111258, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1902.11122" title="Abstract">arXiv:1902.11122</a> (replaced) [<a href="/pdf/1902.11122" title="Download PDF">pdf</a>, <a href="/format/1902.11122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning in Cardiology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bizopoulos%2C+P">Paschalis Bizopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Koutsouris%2C+D">Dimitrios Koutsouris</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 2 figures, 10 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Reviews in Biomedical Engineering 12 (2019): 168-193
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item637">[637]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1908.09363" title="Abstract">arXiv:1908.09363</a> (replaced) [<a href="/pdf/1908.09363" title="Download PDF">pdf</a>, <a href="/format/1908.09363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hypocoercivity properties of adaptive Langevin dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Leimkuhler%2C+B">Benedict Leimkuhler</a>, 
<a href="/search/math?searchtype=author&query=Sachs%2C+M">Matthias Sachs</a>, 
<a href="/search/math?searchtype=author&query=Stoltz%2C+G">Gabriel Stoltz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Functional Analysis (math.FA); Numerical Analysis (math.NA); Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item638">[638]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1912.00042" title="Abstract">arXiv:1912.00042</a> (replaced) [<a href="/pdf/1912.00042" title="Download PDF">pdf</a>, <a href="/format/1912.00042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Likelihoods with Conditional Normalizing Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Winkler%2C+C">Christina Winkler</a>, 
<a href="/search/cs?searchtype=author&query=Worrall%2C+D">Daniel Worrall</a>, 
<a href="/search/cs?searchtype=author&query=Hoogeboom%2C+E">Emiel Hoogeboom</a>, 
<a href="/search/cs?searchtype=author&query=Welling%2C+M">Max Welling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 8 Tables, 9 Figures, Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item639">[639]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2008.12876" title="Abstract">arXiv:2008.12876</a> (replaced) [<a href="/pdf/2008.12876" title="Download PDF">pdf</a>, <a href="/ps/2008.12876" title="Download PostScript">ps</a>, <a href="/format/2008.12876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Alternating minimization algorithms for graph regularized tensor  completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Guan%2C+Y">Yu Guan</a>, 
<a href="/search/math?searchtype=author&query=Dong%2C+S">Shuyu Dong</a>, 
<a href="/search/math?searchtype=author&query=Gao%2C+B">Bin Gao</a>, 
<a href="/search/math?searchtype=author&query=Absil%2C+P+-">P.-A. Absil</a>, 
<a href="/search/math?searchtype=author&query=Glineur%2C+F">Fran&#xe7;ois Glineur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item640">[640]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2011.10496" title="Abstract">arXiv:2011.10496</a> (replaced) [<a href="/pdf/2011.10496" title="Download PDF">pdf</a>, <a href="/format/2011.10496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> State Estimation of Continuous-time Dynamical Systems with Uncertain  Inputs with Bounded Variation: Entropy, Bit Rates, and Relation with Switched  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sibai%2C+H">Hussein Sibai</a>, 
<a href="/search/eess?searchtype=author&query=Mitra%2C+S">Sayan Mitra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item641">[641]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2011.13132" title="Abstract">arXiv:2011.13132</a> (replaced) [<a href="/e-print/2011.13132" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Learning of Heterogeneous Tail Dependence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiangqian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xing Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qi Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Major technical flaws in theoretical aspects
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Risk Management (q-fin.RM)

</div>
</div>
</dd>
<dt><a name="item642">[642]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2012.08026" title="Abstract">arXiv:2012.08026</a> (replaced) [<a href="/pdf/2012.08026" title="Download PDF">pdf</a>, <a href="/ps/2012.08026" title="Download PostScript">ps</a>, <a href="/format/2012.08026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classification of Smoking and Calling using Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Miaowei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mohacey%2C+A+W">Alexander William Mohacey</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Apfel%2C+J">James Apfel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item643">[643]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2012.09376" title="Abstract">arXiv:2012.09376</a> (replaced) [<a href="/pdf/2012.09376" title="Download PDF">pdf</a>, <a href="/ps/2012.09376" title="Download PostScript">ps</a>, <a href="/format/2012.09376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Algorithm for Lexicographically Minimal String Rotation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+Q">Qisheng Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ying%2C+M">Mingsheng Ying</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Final version, with minor revision. 44 pages, 6 algorithms, 4 tables, 1 figure
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Theory of Computing Systems, Early Access, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item644">[644]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2102.10773" title="Abstract">arXiv:2102.10773</a> (replaced) [<a href="/pdf/2102.10773" title="Download PDF">pdf</a>, <a href="/format/2102.10773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Slowly Varying Regression under Sparsity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bertsimas%2C+D">Dimitris Bertsimas</a>, 
<a href="/search/cs?searchtype=author&query=Digalakis%2C+V">Vassilis Digalakis Jr</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M+L">Michael Linghzi Li</a>, 
<a href="/search/cs?searchtype=author&query=Lami%2C+O+S">Omar Skali Lami</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Operations Research. First submission: 02/2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Computation (stat.CO); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item645">[645]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.13823" title="Abstract">arXiv:2106.13823</a> (replaced) [<a href="/pdf/2106.13823" title="Download PDF">pdf</a>, <a href="/ps/2106.13823" title="Download PostScript">ps</a>, <a href="/format/2106.13823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Data Compression and Quantum Cross Entropy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Shangnan%2C+Z">Zhou Shangnan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submission to Physical Review Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Statistical Mechanics (cond-mat.stat-mech); Information Theory (cs.IT); Machine Learning (cs.LG); High Energy Physics - Theory (hep-th)

</div>
</div>
</dd>
<dt><a name="item646">[646]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.01909" title="Abstract">arXiv:2108.01909</a> (replaced) [<a href="/pdf/2108.01909" title="Download PDF">pdf</a>, <a href="/format/2108.01909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strong convergence of adaptive time-stepping schemes for the stochastic  Allen--Cahn equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+C">Chuchu Chen</a>, 
<a href="/search/math?searchtype=author&query=Dang%2C+T">Tonghe Dang</a>, 
<a href="/search/math?searchtype=author&query=Hong%2C+J">Jialin Hong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item647">[647]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.01440" title="Abstract">arXiv:2110.01440</a> (replaced) [<a href="/pdf/2110.01440" title="Download PDF">pdf</a>, <a href="/ps/2110.01440" title="Download PostScript">ps</a>, <a href="/format/2110.01440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Arithmetic Average Density Fusion -- Part I: Some Statistic and  Information-theoretic Results
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+T">Tiancheng Li</a>, 
<a href="/search/math?searchtype=author&query=Song%2C+Y">Yan Song</a>, 
<a href="/search/math?searchtype=author&query=Song%2C+E">Enbin Song</a>, 
<a href="/search/math?searchtype=author&query=Fan%2C+H">Hongqi Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 14 figures, 3 tables. Information Fusion, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item648">[648]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.14003" title="Abstract">arXiv:2110.14003</a> (replaced) [<a href="/pdf/2110.14003" title="Download PDF">pdf</a>, <a href="/format/2110.14003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Connected greedy colourings of perfect graphs and other classes: the  good, the bad and the ugly
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beaudou%2C+L">Laurent Beaudou</a>, 
<a href="/search/cs?searchtype=author&query=Brosse%2C+C">Caroline Brosse</a>, 
<a href="/search/cs?searchtype=author&query=Defrain%2C+O">Oscar Defrain</a>, 
<a href="/search/cs?searchtype=author&query=Foucaud%2C+F">Florent Foucaud</a>, 
<a href="/search/cs?searchtype=author&query=Lagoutte%2C+A">Aur&#xe9;lie Lagoutte</a>, 
<a href="/search/cs?searchtype=author&query=Limouzy%2C+V">Vincent Limouzy</a>, 
<a href="/search/cs?searchtype=author&query=Pastor%2C+L">Lucas Pastor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures. Algorithms to find the good connected orderings added to this version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item649">[649]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.14041" title="Abstract">arXiv:2111.14041</a> (replaced) [<a href="/pdf/2111.14041" title="Download PDF">pdf</a>, <a href="/ps/2111.14041" title="Download PostScript">ps</a>, <a href="/format/2111.14041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Quantum Finite Automata with Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Qiu%2C+D">Daowen Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25pages; comments are welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item650">[650]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.05456" title="Abstract">arXiv:2112.05456</a> (replaced) [<a href="/pdf/2112.05456" title="Download PDF">pdf</a>, <a href="/format/2112.05456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monitoring and Adapting the Physical State of a Camera for Autonomous  Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wischow%2C+M">Maik Wischow</a>, 
<a href="/search/cs?searchtype=author&query=Gallego%2C+G">Guillermo Gallego</a>, 
<a href="/search/cs?searchtype=author&query=Ernst%2C+I">Ines Ernst</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%B6rner%2C+A">Anko B&#xf6;rner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 20 figures, <a href="https://github.com/MaikWischow/Camera-Condition-Monitoring">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Intelligent Transportation Systems (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item651">[651]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.09963" title="Abstract">arXiv:2112.09963</a> (replaced) [<a href="/pdf/2112.09963" title="Download PDF">pdf</a>, <a href="/format/2112.09963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Kolmogorov Superposition Theorem can Break the Curse of  Dimensionality When Approximating High Dimensional Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lai%2C+M">Ming-Jun Lai</a>, 
<a href="/search/math?searchtype=author&query=Shen%2C+Z">Zhaiming Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item652">[652]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.13254" title="Abstract">arXiv:2112.13254</a> (replaced) [<a href="/pdf/2112.13254" title="Download PDF">pdf</a>, <a href="/format/2112.13254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Dynamic Pricing with Covariates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hanzhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Talluri%2C+K">Kalyan Talluri</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaocheng Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item653">[653]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.11239" title="Abstract">arXiv:2201.11239</a> (replaced) [<a href="/pdf/2201.11239" title="Download PDF">pdf</a>, <a href="/format/2201.11239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diagnosing AI Explanation Methods with Folk Concepts of Behavior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jacovi%2C+A">Alon Jacovi</a>, 
<a href="/search/cs?searchtype=author&query=Bastings%2C+J">Jasmijn Bastings</a>, 
<a href="/search/cs?searchtype=author&query=Gehrmann%2C+S">Sebastian Gehrmann</a>, 
<a href="/search/cs?searchtype=author&query=Goldberg%2C+Y">Yoav Goldberg</a>, 
<a href="/search/cs?searchtype=author&query=Filippova%2C+K">Katja Filippova</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the Journal of Artificial Intelligence (JAIR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item654">[654]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.07798" title="Abstract">arXiv:2202.07798</a> (replaced) [<a href="/pdf/2202.07798" title="Download PDF">pdf</a>, <a href="/format/2202.07798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BB-ML: Basic Block Performance Prediction using Machine Learning  Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdelkhalik%2C+H">Hamdy Abdelkhalik</a>, 
<a href="/search/cs?searchtype=author&query=Aktar%2C+S">Shamminuj Aktar</a>, 
<a href="/search/cs?searchtype=author&query=Arafa%2C+Y">Yehia Arafa</a>, 
<a href="/search/cs?searchtype=author&query=Barai%2C+A">Atanu Barai</a>, 
<a href="/search/cs?searchtype=author&query=Chennupati%2C+G">Gopinath Chennupati</a>, 
<a href="/search/cs?searchtype=author&query=Santhi%2C+N">Nandakishore Santhi</a>, 
<a href="/search/cs?searchtype=author&query=Panda%2C+N">Nishant Panda</a>, 
<a href="/search/cs?searchtype=author&query=Prajapati%2C+N">Nirmal Prajapati</a>, 
<a href="/search/cs?searchtype=author&query=Turja%2C+N+H">Nazmul Haque Turja</a>, 
<a href="/search/cs?searchtype=author&query=Eidenbenz%2C+S">Stephan Eidenbenz</a>, 
<a href="/search/cs?searchtype=author&query=Badawy%2C+A">Abdel-Hameed Badawy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 29th IEEE International Conference on Parallel and Distributed Systems (ICPADS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item655">[655]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.09551" title="Abstract">arXiv:2202.09551</a> (replaced) [<a href="/pdf/2202.09551" title="Download PDF">pdf</a>, <a href="/ps/2202.09551" title="Download PostScript">ps</a>, <a href="/format/2202.09551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implementing Boolean Functions with switching lattice networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Datta%2C+R+K">Rajesh Kumar Datta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>

</div>
</div>
</dd>
<dt><a name="item656">[656]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.03691" title="Abstract">arXiv:2203.03691</a> (replaced) [<a href="/pdf/2203.03691" title="Download PDF">pdf</a>, <a href="/format/2203.03691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyperMixer: An MLP-based Low Cost Alternative to Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mai%2C+F">Florian Mai</a>, 
<a href="/search/cs?searchtype=author&query=Pannatier%2C+A">Arnaud Pannatier</a>, 
<a href="/search/cs?searchtype=author&query=Fehr%2C+F">Fabio Fehr</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haolin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Marelli%2C+F">Francois Marelli</a>, 
<a href="/search/cs?searchtype=author&query=Fleuret%2C+F">Francois Fleuret</a>, 
<a href="/search/cs?searchtype=author&query=Henderson%2C+J">James Henderson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at ACL 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 61st Annual Meeting of the Association for
  Computational Linguistics (Volume 1: Long Papers), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item657">[657]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.00281" title="Abstract">arXiv:2204.00281</a> (replaced) [<a href="/pdf/2204.00281" title="Download PDF">pdf</a>, <a href="/format/2204.00281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> i-Razor: A Differentiable Neural Input Razor for Feature Selection and  Dimension Search in DNN-Based Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yao Yao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bin Liu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+H">Haoxun He</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+D">Dakui Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Ke Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+L">Li Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">Huanhuan Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Knowledge and Data Engineering (TKDE)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item658">[658]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.01269" title="Abstract">arXiv:2205.01269</a> (replaced) [<a href="/pdf/2205.01269" title="Download PDF">pdf</a>, <a href="/format/2205.01269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MP and MT properties of fuzzy inference with aggregation function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+D">Dechao Li</a>, 
<a href="/search/math?searchtype=author&query=He%2C+M">Mengying He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item659">[659]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.15680" title="Abstract">arXiv:2205.15680</a> (replaced) [<a href="/pdf/2205.15680" title="Download PDF">pdf</a>, <a href="/format/2205.15680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simulator-Based Inference with Waldo: Confidence Regions by Leveraging  Prediction Algorithms and Posterior Estimators for Inverse Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Masserano%2C+L">Luca Masserano</a>, 
<a href="/search/stat?searchtype=author&query=Dorigo%2C+T">Tommaso Dorigo</a>, 
<a href="/search/stat?searchtype=author&query=Izbicki%2C+R">Rafael Izbicki</a>, 
<a href="/search/stat?searchtype=author&query=Kuusela%2C+M">Mikael Kuusela</a>, 
<a href="/search/stat?searchtype=author&query=Lee%2C+A+B">Ann B. Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 10 figures, code available at <a href="https://github.com/lee-group-cmu/lf2i">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item660">[660]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.15935" title="Abstract">arXiv:2205.15935</a> (replaced) [<a href="/pdf/2205.15935" title="Download PDF">pdf</a>, <a href="/format/2205.15935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bias-inducing geometries: an exactly solvable data model with fairness  implications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mannelli%2C+S+S">Stefano Sarao Mannelli</a>, 
<a href="/search/cs?searchtype=author&query=Gerace%2C+F">Federica Gerace</a>, 
<a href="/search/cs?searchtype=author&query=Rostamzadeh%2C+N">Negar Rostamzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Saglietti%2C+L">Luca Saglietti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages + methods + SI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item661">[661]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.02536" title="Abstract">arXiv:2206.02536</a> (replaced) [<a href="/pdf/2206.02536" title="Download PDF">pdf</a>, <a href="/format/2206.02536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The impact of spatio-temporal travel distance on epidemics using an  interpretable attention-based sequence-to-sequence model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Jiang%2C+Y">Yukang Jiang</a>, 
<a href="/search/physics?searchtype=author&query=Tian%2C+T">Ting Tian</a>, 
<a href="/search/physics?searchtype=author&query=Xie%2C+H">Huajun Xie</a>, 
<a href="/search/physics?searchtype=author&query=Guo%2C+H">Hailiang Guo</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+X">Xueqin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Artificial Intelligence (cs.AI); Populations and Evolution (q-bio.PE); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item662">[662]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.03062" title="Abstract">arXiv:2206.03062</a> (replaced) [<a href="/pdf/2206.03062" title="Download PDF">pdf</a>, <a href="/format/2206.03062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Object Scan Context: Object-centric Spatial Descriptor for Place  Recognition within 3D Point Cloud Map
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Haodong Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yudong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+S">Shengyin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xue Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jian Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item663">[663]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.07234" title="Abstract">arXiv:2206.07234</a> (replaced) [<a href="/pdf/2206.07234" title="Download PDF">pdf</a>, <a href="/format/2206.07234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Brownian Noise Reduction: Maximizing Privacy Subject to Accuracy  Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Whitehouse%2C+J">Justin Whitehouse</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z+S">Zhiwei Steven Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ramdas%2C+A">Aaditya Ramdas</a>, 
<a href="/search/cs?searchtype=author&query=Rogers%2C+R">Ryan Rogers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Data Structures and Algorithms (cs.DS); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item664">[664]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.11303" title="Abstract">arXiv:2206.11303</a> (replaced) [<a href="/pdf/2206.11303" title="Download PDF">pdf</a>, <a href="/format/2206.11303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Community Recovery in the Geometric Block Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Galhotra%2C+S">Sainyam Galhotra</a>, 
<a href="/search/cs?searchtype=author&query=Mazumdar%2C+A">Arya Mazumdar</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+S">Soumyabrata Pal</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+B">Barna Saha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 60 pages, 18 figures. Accepted at the Journal of Machine Learning Research (JMLR). Shorter versions accepted in AAAI 2018 (see <a href="/abs/1709.05510">arXiv:1709.05510</a>) and RANDOM 2019 (see <a href="/abs/1804.05013">arXiv:1804.05013</a>)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Machine Learning Research (JMLR) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Discrete Mathematics (cs.DM); Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item665">[665]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.13086" title="Abstract">arXiv:2206.13086</a> (replaced) [<a href="/pdf/2206.13086" title="Download PDF">pdf</a>, <a href="/format/2206.13086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RankSEG: A Consistent Ranking-based Framework for Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Dai%2C+B">Ben Dai</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+C">Chunlin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 50 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Machine Learning Research, 24(224), 1-50 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item666">[666]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.13422" title="Abstract">arXiv:2206.13422</a> (replaced) [<a href="/pdf/2206.13422" title="Download PDF">pdf</a>, <a href="/ps/2206.13422" title="Download PostScript">ps</a>, <a href="/format/2206.13422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Two Color Map Theorem -- Complete Theorem of Robust Gait  Plan for a Tilt-rotor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zhe Shen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yudong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Tsuchiya%2C+T">Takeshi Tsuchiya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item667">[667]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.15215" title="Abstract">arXiv:2206.15215</a> (replaced) [<a href="/pdf/2206.15215" title="Download PDF">pdf</a>, <a href="/format/2206.15215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning nonparametric ordinary differential equations from noisy data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Lahouel%2C+K">Kamel Lahouel</a>, 
<a href="/search/stat?searchtype=author&query=Wells%2C+M">Michael Wells</a>, 
<a href="/search/stat?searchtype=author&query=Rielly%2C+V">Victor Rielly</a>, 
<a href="/search/stat?searchtype=author&query=Lew%2C+E">Ethan Lew</a>, 
<a href="/search/stat?searchtype=author&query=Lovitz%2C+D">David Lovitz</a>, 
<a href="/search/stat?searchtype=author&query=Jedynak%2C+B+M">Bruno M. Jedynak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item668">[668]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.01678" title="Abstract">arXiv:2207.01678</a> (replaced) [<a href="/pdf/2207.01678" title="Download PDF">pdf</a>, <a href="/format/2207.01678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FACT: High-Dimensional Random Forests Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Chi%2C+C">Chien-Ming Chi</a>, 
<a href="/search/stat?searchtype=author&query=Fan%2C+Y">Yingying Fan</a>, 
<a href="/search/stat?searchtype=author&query=Lv%2C+J">Jinchi Lv</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item669">[669]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.04734" title="Abstract">arXiv:2207.04734</a> (replaced) [<a href="/pdf/2207.04734" title="Download PDF">pdf</a>, <a href="/format/2207.04734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cut finite element method for divergence free approximation of  incompressible flow: a Lagrange multiplier approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Burman%2C+E">Erik Burman</a>, 
<a href="/search/math?searchtype=author&query=Hansbo%2C+P">Peter Hansbo</a>, 
<a href="/search/math?searchtype=author&query=Larson%2C+M+G">Mats G. Larson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item670">[670]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.06484" title="Abstract">arXiv:2207.06484</a> (replaced) [<a href="/pdf/2207.06484" title="Download PDF">pdf</a>, <a href="/ps/2207.06484" title="Download PostScript">ps</a>, <a href="/format/2207.06484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Recovery of Structured Signals Using Atomic Norm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuemei Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Functional Analysis (math.FA)

</div>
</div>
</dd>
<dt><a name="item671">[671]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.08253" title="Abstract">arXiv:2207.08253</a> (replaced) [<a href="/pdf/2207.08253" title="Download PDF">pdf</a>, <a href="/ps/2207.08253" title="Download PostScript">ps</a>, <a href="/format/2207.08253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rationality-Robust Information Design: Bayesian Persuasion under Quantal  Response
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yiding Feng</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+C">Chien-Ju Ho</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+W">Wei Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item672">[672]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.13358" title="Abstract">arXiv:2207.13358</a> (replaced) [<a href="/pdf/2207.13358" title="Download PDF">pdf</a>, <a href="/format/2207.13358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Managing DRAM: A Low-Cost Framework for Enabling Autonomous and  Efficient in-DRAM Operations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hassan%2C+H">Hasan Hassan</a>, 
<a href="/search/cs?searchtype=author&query=Olgun%2C+A">Ataberk Olgun</a>, 
<a href="/search/cs?searchtype=author&query=Yaglikci%2C+A+G">A. Giray Yaglikci</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Haocong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+O">Onur Mutlu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item673">[673]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.05263" title="Abstract">arXiv:2208.05263</a> (replaced) [<a href="/pdf/2208.05263" title="Download PDF">pdf</a>, <a href="/ps/2208.05263" title="Download PostScript">ps</a>, <a href="/format/2208.05263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhanced Low-Redundancy Restricted Array for Direction of Arrival  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shidong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhengchun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+G">Guolong Cui</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xiaohu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+P">Pingzhi Fan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item674">[674]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.10434" title="Abstract">arXiv:2208.10434</a> (replaced) [<a href="/pdf/2208.10434" title="Download PDF">pdf</a>, <a href="/format/2208.10434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A simple learning agent interacting with an agent-based market model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Dicks%2C+M">Matthew Dicks</a>, 
<a href="/search/q-fin?searchtype=author&query=Paskaramoorthy%2C+A">Andrew Paskaramoorthy</a>, 
<a href="/search/q-fin?searchtype=author&query=Gebbie%2C+T">Tim Gebbie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 7 figures. Accepted: Physica A
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Trading and Market Microstructure (q-fin.TR)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item675">[675]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.11450" title="Abstract">arXiv:2208.11450</a> (replaced) [<a href="/pdf/2208.11450" title="Download PDF">pdf</a>, <a href="/format/2208.11450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Fusion Based Interpretable Multimodal Emotion Recognition with  Limited Labelled Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+P">Puneet Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Malik%2C+S">Sarthak Malik</a>, 
<a href="/search/cs?searchtype=author&query=Raman%2C+B">Balasubramanian Raman</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaobai Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item676">[676]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.14673" title="Abstract">arXiv:2208.14673</a> (replaced) [<a href="/pdf/2208.14673" title="Download PDF">pdf</a>, <a href="/format/2208.14673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incremental Learning in Diagonal Linear Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berthier%2C+R">Rapha&#xeb;l Berthier</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Machine Learning Research, 2023, 24 (171), pp.1-26
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item677">[677]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.08355" title="Abstract">arXiv:2209.08355</a> (replaced) [<a href="/pdf/2209.08355" title="Download PDF">pdf</a>, <a href="/format/2209.08355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Connectivity-Aware Pulmonary Airway Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Minghui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guang-Zhong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yun Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item678">[678]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.14750" title="Abstract">arXiv:2209.14750</a> (replaced) [<a href="/pdf/2209.14750" title="Download PDF">pdf</a>, <a href="/format/2209.14750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-contrastive representation learning for intervals from well logs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marusov%2C+A">Alexander Marusov</a>, 
<a href="/search/cs?searchtype=author&query=Zaytsev%2C+A">Alexey Zaytsev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Geoscience and Remote Sensing Letters (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item679">[679]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.03461" title="Abstract">arXiv:2210.03461</a> (replaced) [<a href="/pdf/2210.03461" title="Download PDF">pdf</a>, <a href="/format/2210.03461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FastCLIPstyler: Optimisation-free Text-based Image Style Transfer Using  Style Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suresh%2C+A+P">Ananda Padhmanabhan Suresh</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+S">Sanjana Jain</a>, 
<a href="/search/cs?searchtype=author&query=Noinongyao%2C+P">Pavit Noinongyao</a>, 
<a href="/search/cs?searchtype=author&query=Ganguly%2C+A">Ankush Ganguly</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 2024 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item680">[680]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.06650" title="Abstract">arXiv:2210.06650</a> (replaced) [<a href="/pdf/2210.06650" title="Download PDF">pdf</a>, <a href="/format/2210.06650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpreting Neural Policies with Disentangled Tree Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tsun-Hsuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+W">Wei Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Seyde%2C+T">Tim Seyde</a>, 
<a href="/search/cs?searchtype=author&query=Hasani%2C+R">Ramin Hasani</a>, 
<a href="/search/cs?searchtype=author&query=Rus%2C+D">Daniela Rus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Robotics (cs.RO); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item681">[681]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.15785" title="Abstract">arXiv:2210.15785</a> (replaced) [<a href="/pdf/2210.15785" title="Download PDF">pdf</a>, <a href="/format/2210.15785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Supply Chain Characteristics as Predictors of Cyber Risk: A  Machine-Learning Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Hu%2C+K">Kevin Hu</a> (1), 
<a href="/search/q-fin?searchtype=author&query=Levi%2C+R">Retsef Levi</a> (1), 
<a href="/search/q-fin?searchtype=author&query=Yahalom%2C+R">Raphael Yahalom</a> (1), 
<a href="/search/q-fin?searchtype=author&query=Zerhouni%2C+E+G">El Ghali Zerhouni</a> (1) ((1) Massachusetts Institute of Technology)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Risk Management (q-fin.RM)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item682">[682]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.16458" title="Abstract">arXiv:2210.16458</a> (replaced) [<a href="/pdf/2210.16458" title="Download PDF">pdf</a>, <a href="/format/2210.16458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reformulating van Rijsbergen&#x27;s $F_&#x3b2;$ metric for weighted binary  cross-entropy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ramdhani%2C+S">Satesh Ramdhani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item683">[683]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.01258" title="Abstract">arXiv:2211.01258</a> (replaced) [<a href="/pdf/2211.01258" title="Download PDF">pdf</a>, <a href="/format/2211.01258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instance-Dependent Generalization Bounds via Optimal Transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Hou%2C+S">Songyan Hou</a>, 
<a href="/search/stat?searchtype=author&query=Kassraie%2C+P">Parnian Kassraie</a>, 
<a href="/search/stat?searchtype=author&query=Kratsios%2C+A">Anastasis Kratsios</a>, 
<a href="/search/stat?searchtype=author&query=Krause%2C+A">Andreas Krause</a>, 
<a href="/search/stat?searchtype=author&query=Rothfuss%2C+J">Jonas Rothfuss</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Journal of Machine Learning Research (JMLR), 51 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item684">[684]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.03831" title="Abstract">arXiv:2211.03831</a> (replaced) [<a href="/pdf/2211.03831" title="Download PDF">pdf</a>, <a href="/format/2211.03831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Head Adapter Routing for Cross-Task Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caccia%2C+L">Lucas Caccia</a>, 
<a href="/search/cs?searchtype=author&query=Ponti%2C+E">Edoardo Ponti</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Z">Zhan Su</a>, 
<a href="/search/cs?searchtype=author&query=Pereira%2C+M">Matheus Pereira</a>, 
<a href="/search/cs?searchtype=author&query=Roux%2C+N+L">Nicolas Le Roux</a>, 
<a href="/search/cs?searchtype=author&query=Sordoni%2C+A">Alessandro Sordoni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023. Code is available at <a href="https://github.com/microsoft/mttl">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item685">[685]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.13308" title="Abstract">arXiv:2211.13308</a> (replaced) [<a href="/pdf/2211.13308" title="Download PDF">pdf</a>, <a href="/format/2211.13308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SciRepEval: A Multi-Format Benchmark for Scientific Document  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Amanpreet Singh</a>, 
<a href="/search/cs?searchtype=author&query=D%27Arcy%2C+M">Mike D&#x27;Arcy</a>, 
<a href="/search/cs?searchtype=author&query=Cohan%2C+A">Arman Cohan</a>, 
<a href="/search/cs?searchtype=author&query=Downey%2C+D">Doug Downey</a>, 
<a href="/search/cs?searchtype=author&query=Feldman%2C+S">Sergey Feldman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 2 figures, 11 tables. Accepted in EMNLP 2023 Main Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item686">[686]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.13790" title="Abstract">arXiv:2211.13790</a> (replaced) [<a href="/pdf/2211.13790" title="Download PDF">pdf</a>, <a href="/format/2211.13790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximating the chromatic polynomial is as hard as computing it  exactly
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bencs%2C+F">Ferenc Bencs</a>, 
<a href="/search/cs?searchtype=author&query=Huijben%2C+J">Jeroen Huijben</a>, 
<a href="/search/cs?searchtype=author&query=Regts%2C+G">Guus Regts</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 47 pages; minor changes based on referee comments. The number of pages has gone up significantly because we used a different document class, namely cc. Accepted for publication in Computational Complexity
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item687">[687]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.14468" title="Abstract">arXiv:2211.14468</a> (replaced) [<a href="/pdf/2211.14468" title="Download PDF">pdf</a>, <a href="/format/2211.14468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Similarity-based cooperative equilibrium
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oesterheld%2C+C">Caspar Oesterheld</a>, 
<a href="/search/cs?searchtype=author&query=Treutlein%2C+J">Johannes Treutlein</a>, 
<a href="/search/cs?searchtype=author&query=Grosse%2C+R">Roger Grosse</a>, 
<a href="/search/cs?searchtype=author&query=Conitzer%2C+V">Vincent Conitzer</a>, 
<a href="/search/cs?searchtype=author&query=Foerster%2C+J">Jakob Foerster</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at NeurIPS 2023. 32 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item688">[688]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01368" title="Abstract">arXiv:2212.01368</a> (replaced) [<a href="/pdf/2212.01368" title="Download PDF">pdf</a>, <a href="/format/2212.01368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Non-Rigid Radiance Fields from Monocularized Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kappel%2C+M">Moritz Kappel</a>, 
<a href="/search/cs?searchtype=author&query=Golyanik%2C+V">Vladislav Golyanik</a>, 
<a href="/search/cs?searchtype=author&query=Castillo%2C+S">Susana Castillo</a>, 
<a href="/search/cs?searchtype=author&query=Theobalt%2C+C">Christian Theobalt</a>, 
<a href="/search/cs?searchtype=author&query=Magnor%2C+M">Marcus Magnor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 14 figures; project page: <a href="https://graphics.tu-bs.de/publications/kappel2022fast">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item689">[689]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01382" title="Abstract">arXiv:2212.01382</a> (replaced) [<a href="/pdf/2212.01382" title="Download PDF">pdf</a>, <a href="/format/2212.01382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Welfare and Fairness in Multi-objective Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zimeng Fan</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+N">Nianli Peng</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+M">Muhang Tian</a>, 
<a href="/search/cs?searchtype=author&query=Fain%2C+B">Brandon Fain</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item690">[690]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.04155" title="Abstract">arXiv:2212.04155</a> (replaced) [<a href="/pdf/2212.04155" title="Download PDF">pdf</a>, <a href="/format/2212.04155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Graph Representations for Critical View of Safety Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Murali%2C+A">Aditya Murali</a>, 
<a href="/search/cs?searchtype=author&query=Alapatt%2C+D">Deepak Alapatt</a>, 
<a href="/search/cs?searchtype=author&query=Mascagni%2C+P">Pietro Mascagni</a>, 
<a href="/search/cs?searchtype=author&query=Vardazaryan%2C+A">Armine Vardazaryan</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+A">Alain Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Okamoto%2C+N">Nariaki Okamoto</a>, 
<a href="/search/cs?searchtype=author&query=Mutter%2C+D">Didier Mutter</a>, 
<a href="/search/cs?searchtype=author&query=Padoy%2C+N">Nicolas Padoy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item691">[691]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.04673" title="Abstract">arXiv:2212.04673</a> (replaced) [<a href="/pdf/2212.04673" title="Download PDF">pdf</a>, <a href="/format/2212.04673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MSI: Maximize Support-Set Information for Few-Shot Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moon%2C+S">Seonghyeon Moon</a>, 
<a href="/search/cs?searchtype=author&query=Sohn%2C+S+S">Samuel S. Sohn</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Honglu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+S">Sejong Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Pavlovic%2C+V">Vladimir Pavlovic</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+M+H">Muhammad Haris Khan</a>, 
<a href="/search/cs?searchtype=author&query=Kapadia%2C+M">Mubbasir Kapadia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item692">[692]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.05402" title="Abstract">arXiv:2212.05402</a> (replaced) [<a href="/pdf/2212.05402" title="Download PDF">pdf</a>, <a href="/ps/2212.05402" title="Download PostScript">ps</a>, <a href="/format/2212.05402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic First-Order Learning for Large-Scale Flexibly Tied Gaussian  Mixture Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pasande%2C+M">Mohammad Pasande</a>, 
<a href="/search/cs?searchtype=author&query=Hosseini%2C+R">Reshad Hosseini</a>, 
<a href="/search/cs?searchtype=author&query=Araabi%2C+B+N">Babak Nadjar Araabi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item693">[693]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.08487" title="Abstract">arXiv:2212.08487</a> (replaced) [<a href="/pdf/2212.08487" title="Download PDF">pdf</a>, <a href="/format/2212.08487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantics-Empowered Communication: A Tutorial-cum-Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhilin Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rongpeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+K">Kun Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xianfu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hossain%2C+E">Ekram Hossain</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhifeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Honggang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted for publication in the IEEE Communications Surveys and Tutorials
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item694">[694]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.10477" title="Abstract">arXiv:2212.10477</a> (replaced) [<a href="/pdf/2212.10477" title="Download PDF">pdf</a>, <a href="/ps/2212.10477" title="Download PostScript">ps</a>, <a href="/format/2212.10477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Simultaneous Perturbation-based Gradient Search with Reduced  Estimator Bias
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pachal%2C+S">Soumen Pachal</a>, 
<a href="/search/cs?searchtype=author&query=Bhatnagar%2C+S">Shalabh Bhatnagar</a>, 
<a href="/search/cs?searchtype=author&query=Prashanth%2C+L+A">L.A. Prashanth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The material in this paper was presented in part at the Conference on Information Sciences and Systems (CISS) in March 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item695">[695]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.11146" title="Abstract">arXiv:2212.11146</a> (replaced) [<a href="/pdf/2212.11146" title="Download PDF">pdf</a>, <a href="/ps/2212.11146" title="Download PostScript">ps</a>, <a href="/format/2212.11146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Challenges of HTR Model Training: Feedback from the Project Donner  le gout de l&#x27;archive a l&#x27;ere numerique
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Couture%2C+B">Beatrice Couture</a> (Universit&#xe9; de Montr&#xe9;al), 
<a href="/search/cs?searchtype=author&query=Verret%2C+F">Farah Verret</a> (Universit&#xe9; de Montr&#xe9;al), 
<a href="/search/cs?searchtype=author&query=Gohier%2C+M">Maxime Gohier</a> (Universit&#xe9; du Qu&#xe9;bec &#xe0; Rimouski), 
<a href="/search/cs?searchtype=author&query=Deslandres%2C+D">Dominique Deslandres</a> (Universit&#xe9; de Montr&#xe9;al)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item696">[696]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.13020" title="Abstract">arXiv:2212.13020</a> (replaced) [<a href="/pdf/2212.13020" title="Download PDF">pdf</a>, <a href="/ps/2212.13020" title="Download PostScript">ps</a>, <a href="/format/2212.13020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Track Before Detect of Low SNR Objects in a Sequence of Image Frames  Using Particle Filter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rezaie%2C+R">Reza Rezaie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item697">[697]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.01041" title="Abstract">arXiv:2301.01041</a> (replaced) [<a href="/pdf/2301.01041" title="Download PDF">pdf</a>, <a href="/format/2301.01041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Numerical Integration of Singular Initial and Boundary Value  Problems for Generalised Lane-Emden and Thomas-Fermi Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Seiler%2C+W+M">Werner M. Seiler</a>, 
<a href="/search/math?searchtype=author&query=Seiss%2C+M">Matthias Seiss</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph); Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item698">[698]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.01590" title="Abstract">arXiv:2301.01590</a> (replaced) [<a href="/pdf/2301.01590" title="Download PDF">pdf</a>, <a href="/format/2301.01590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FATE in AI: Towards Algorithmic Inclusivity and Accessibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Inuwa-Dutse%2C+I">Isa Inuwa-Dutse</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 6 figures, 7 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item699">[699]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.03468" title="Abstract">arXiv:2301.03468</a> (replaced) [<a href="/pdf/2301.03468" title="Download PDF">pdf</a>, <a href="/format/2301.03468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge-Aware Semantic Communication System Design and Data Allocation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kadam%2C+S">Sachin Kadam</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+D+I">Dong In Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at IEEE Transactions on Vehicular Technology. It is an expanded version of the conference paper, which was presented at the IEEE ICC 2023. DOI: 10.1109/ICC45041.2023.10278770
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item700">[700]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.05206" title="Abstract">arXiv:2301.05206</a> (replaced) [<a href="/pdf/2301.05206" title="Download PDF">pdf</a>, <a href="/format/2301.05206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ImMesh: An Immediate LiDAR Localization and Meshing Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jiarong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Chongjiang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yixi Cai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haotian Li</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yunfan Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Y">Yuying Zou</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+X">Xiaoping Hong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fu Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item701">[701]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.07085" title="Abstract">arXiv:2301.07085</a> (replaced) [<a href="/pdf/2301.07085" title="Download PDF">pdf</a>, <a href="/format/2301.07085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are Language Models Worse than Humans at Following Prompts? It&#x27;s  Complicated
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Webson%2C+A">Albert Webson</a>, 
<a href="/search/cs?searchtype=author&query=Loo%2C+A+M">Alyssa Marie Loo</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qinan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Pavlick%2C+E">Ellie Pavlick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item702">[702]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.07669" title="Abstract">arXiv:2301.07669</a> (replaced) [<a href="/pdf/2301.07669" title="Download PDF">pdf</a>, <a href="/format/2301.07669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-Time Viewport-Aware Optical Flow Estimation in 360-degree Videos  for Visually-Induced Motion Sickness Mitigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zekun Cao</a>, 
<a href="/search/cs?searchtype=author&query=Kopper%2C+R">Regis Kopper</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item703">[703]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.08611" title="Abstract">arXiv:2301.08611</a> (replaced) [<a href="/e-print/2301.08611" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Verification of crossbar-based lattice through modeling technique
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Datta%2C+R+K">Rajesh Kumar Datta</a> (Dept. of Electrical and Computer Engineering University of Texas at Dallas Dallas, Texas, USA)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Due to incomplete results it was withdrawn
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>

</div>
</div>
</dd>
<dt><a name="item704">[704]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10743" title="Abstract">arXiv:2301.10743</a> (replaced) [<a href="/pdf/2301.10743" title="Download PDF">pdf</a>, <a href="/format/2301.10743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tighter Bounds on the Expressivity of Transformer Encoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chiang%2C+D">David Chiang</a>, 
<a href="/search/cs?searchtype=author&query=Cholak%2C+P">Peter Cholak</a>, 
<a href="/search/cs?searchtype=author&query=Pillay%2C+A">Anand Pillay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at ICML 2023. Typo corrections in Appendix B and Section 8.1
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Formal Languages and Automata Theory (cs.FL); Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item705">[705]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11975" title="Abstract">arXiv:2301.11975</a> (replaced) [<a href="/pdf/2301.11975" title="Download PDF">pdf</a>, <a href="/format/2301.11975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Byte Pair Encoding for Symbolic Music
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fradet%2C+N">Nathan Fradet</a>, 
<a href="/search/cs?searchtype=author&query=Gutowski%2C+N">Nicolas Gutowski</a>, 
<a href="/search/cs?searchtype=author&query=Chhel%2C+F">Fabien Chhel</a>, 
<a href="/search/cs?searchtype=author&query=Briot%2C+J">Jean-Pierre Briot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023, source code: <a href="https://github.com/Natooz/BPE-Symbolic-Music">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item706">[706]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.00290" title="Abstract">arXiv:2302.00290</a> (replaced) [<a href="/pdf/2302.00290" title="Download PDF">pdf</a>, <a href="/format/2302.00290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MS-DETR: Multispectral Pedestrian Detection Transformer with Loosely  Coupled Fusion and Modality-Balanced Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xing%2C+Y">Yinghui Xing</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Song Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shizhou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+G">Guoqiang Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiuwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanning Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item707">[707]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01602" title="Abstract">arXiv:2302.01602</a> (replaced) [<a href="/pdf/2302.01602" title="Download PDF">pdf</a>, <a href="/ps/2302.01602" title="Download PostScript">ps</a>, <a href="/format/2302.01602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Feature Selection Method for Driver Stress Detection Using Heart Rate  Variability and Breathing Rate
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parsi%2C+A">Ashkan Parsi</a>, 
<a href="/search/cs?searchtype=author&query=O%27Callaghan%2C+D">David O&#x27;Callaghan</a>, 
<a href="/search/cs?searchtype=author&query=Lemley%2C+J">Joseph Lemley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings of the 15th International Conference on Machine Vision (ICMV), Rome, Italy, 18-20 November 2022. arXiv admin note: text overlap with <a href="/abs/2206.03222">arXiv:2206.03222</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item708">[708]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02083" title="Abstract">arXiv:2302.02083</a> (replaced) [<a href="/pdf/2302.02083" title="Download PDF">pdf</a>, <a href="/ps/2302.02083" title="Download PostScript">ps</a>, <a href="/format/2302.02083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Theory of Mind Might Have Spontaneously Emerged in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kosinski%2C+M">Michal Kosinski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> TRY RUNNING ToM EXPERIMENTS ON YOUR OWN: The code and tasks used in this study are available at Colab (<a href="https://colab.research.google.com/drive/1ZRtmw87CdA4xp24DNS_Ik_uA2ypaRnoU">this https URL</a>). Don't worry if you are not an expert coder, you should be able to run this code with no-to-minimum Python skills. Or copy-paste the tasks to ChatGPT's web interface
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item709">[709]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02118" title="Abstract">arXiv:2302.02118</a> (replaced) [<a href="/pdf/2302.02118" title="Download PDF">pdf</a>, <a href="/format/2302.02118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpotLess: Concurrent Rotational Consensus Made Practical through Rapid  View Synchronization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+D">Dakai Kang</a>, 
<a href="/search/cs?searchtype=author&query=Rahnama%2C+S">Sajjad Rahnama</a>, 
<a href="/search/cs?searchtype=author&query=Hellings%2C+J">Jelle Hellings</a>, 
<a href="/search/cs?searchtype=author&query=Sadoghi%2C+M">Mohammad Sadoghi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item710">[710]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02392" title="Abstract">arXiv:2302.02392</a> (replaced) [<a href="/pdf/2302.02392" title="Download PDF">pdf</a>, <a href="/ps/2302.02392" title="Download PostScript">ps</a>, <a href="/format/2302.02392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Offline Minimax Soft-Q-learning Under Realizability and Partial Coverage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Uehara%2C+M">Masatoshi Uehara</a>, 
<a href="/search/cs?searchtype=author&query=Kallus%2C+N">Nathan Kallus</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+D">Jason D. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wen Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The original title of this paper was "Refined Value-Based Offline RL under Realizability and Partial Coverage," but it was later changed. This paper has been accepted for NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item711">[711]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.03223" title="Abstract">arXiv:2302.03223</a> (replaced) [<a href="/pdf/2302.03223" title="Download PDF">pdf</a>, <a href="/format/2302.03223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Tightly Coupled Bi-Level Coordination Framework for CAVs at Road  Intersections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Donglin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tingting Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jiping Luo</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+T">Tianhao Liang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+B">Bin Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xuanli Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qinyu Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item712">[712]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.03995" title="Abstract">arXiv:2302.03995</a> (replaced) [<a href="/pdf/2302.03995" title="Download PDF">pdf</a>, <a href="/format/2302.03995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regularity and numerical approximation of fractional elliptic  differential equations on compact metric graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bolin%2C+D">David Bolin</a>, 
<a href="/search/math?searchtype=author&query=Kov%C3%A1cs%2C+M">Mih&#xe1;ly Kov&#xe1;cs</a>, 
<a href="/search/math?searchtype=author&query=Kumar%2C+V">Vivek Kumar</a>, 
<a href="/search/math?searchtype=author&query=Simas%2C+A+B">Alexandre B. Simas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in Mathematics of Computation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item713">[713]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.07202" title="Abstract">arXiv:2302.07202</a> (replaced) [<a href="/pdf/2302.07202" title="Download PDF">pdf</a>, <a href="/format/2302.07202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are sketch-and-precondition least squares solvers numerically stable?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Meier%2C+M">Maike Meier</a>, 
<a href="/search/math?searchtype=author&query=Nakatsukasa%2C+Y">Yuji Nakatsukasa</a>, 
<a href="/search/math?searchtype=author&query=Townsend%2C+A">Alex Townsend</a>, 
<a href="/search/math?searchtype=author&query=Webb%2C+M">Marcus Webb</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item714">[714]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09526" title="Abstract">arXiv:2302.09526</a> (replaced) [<a href="/pdf/2302.09526" title="Download PDF">pdf</a>, <a href="/format/2302.09526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixed Semi-Supervised Generalized-Linear-Regression with applications to  Deep-Learning and Interpolators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Yuval%2C+O">Oren Yuval</a>, 
<a href="/search/stat?searchtype=author&query=Rosset%2C+S">Saharon Rosset</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item715">[715]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11728" title="Abstract">arXiv:2302.11728</a> (replaced) [<a href="/pdf/2302.11728" title="Download PDF">pdf</a>, <a href="/format/2302.11728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Convolutional-Transformer Network for Crack Segmentation with Boundary  Awareness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+H">Huaqi Tao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bingxi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Jinqiang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICIP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item716">[716]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.12403" title="Abstract">arXiv:2302.12403</a> (replaced) [<a href="/pdf/2302.12403" title="Download PDF">pdf</a>, <a href="/format/2302.12403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Plume: A Framework for High Performance Deep RL Network Controllers via  Prioritized Trace Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patel%2C+S">Sagar Patel</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jyothi%2C+S+A">Sangeetha Abdu Jyothi</a>, 
<a href="/search/cs?searchtype=author&query=Narodytska%2C+N">Nina Narodytska</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item717">[717]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.12990" title="Abstract">arXiv:2302.12990</a> (replaced) [<a href="/pdf/2302.12990" title="Download PDF">pdf</a>, <a href="/ps/2302.12990" title="Download PostScript">ps</a>, <a href="/format/2302.12990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fully Composable and Adequate Verified Compilation with Direct  Refinements between Open Modules (Technical Report)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Ling Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuting Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jinhua Wu</a>, 
<a href="/search/cs?searchtype=author&query=Koenig%2C+J">J&#xe9;r&#xe9;mie Koenig</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Z">Zhong Shao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item718">[718]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13262" title="Abstract">arXiv:2302.13262</a> (replaced) [<a href="/pdf/2302.13262" title="Download PDF">pdf</a>, <a href="/format/2302.13262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modulated Neural ODEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Auzina%2C+I+A">Ilze Amanda Auzina</a>, 
<a href="/search/cs?searchtype=author&query=Y%C4%B1ld%C4%B1z%2C+%C3%87">&#xc7;a&#x11f;atay Y&#x131;ld&#x131;z</a>, 
<a href="/search/cs?searchtype=author&query=Magliacane%2C+S">Sara Magliacane</a>, 
<a href="/search/cs?searchtype=author&query=Bethge%2C+M">Matthias Bethge</a>, 
<a href="/search/cs?searchtype=author&query=Gavves%2C+E">Efstratios Gavves</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item719">[719]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13439" title="Abstract">arXiv:2302.13439</a> (replaced) [<a href="/pdf/2302.13439" title="Download PDF">pdf</a>, <a href="/format/2302.13439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigating the Grey Area: How Expressions of Uncertainty and  Overconfidence Affect Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kaitlyn Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Jurafsky%2C+D">Dan Jurafsky</a>, 
<a href="/search/cs?searchtype=author&query=Hashimoto%2C+T">Tatsunori Hashimoto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item720">[720]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13608" title="Abstract">arXiv:2302.13608</a> (replaced) [<a href="/pdf/2302.13608" title="Download PDF">pdf</a>, <a href="/format/2302.13608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepSeq: Deep Sequential Circuit Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+S">Sadaf Khan</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhengyuan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Min Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qiang Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item721">[721]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14043" title="Abstract">arXiv:2302.14043</a> (replaced) [<a href="/pdf/2302.14043" title="Download PDF">pdf</a>, <a href="/format/2302.14043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single-Call Stochastic Extragradient Methods for Structured Non-monotone  Variational Inequalities: Improved Analysis under Weaker Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Choudhury%2C+S">Sayantan Choudhury</a>, 
<a href="/search/math?searchtype=author&query=Gorbunov%2C+E">Eduard Gorbunov</a>, 
<a href="/search/math?searchtype=author&query=Loizou%2C+N">Nicolas Loizou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item722">[722]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00908" title="Abstract">arXiv:2303.00908</a> (replaced) [<a href="/pdf/2303.00908" title="Download PDF">pdf</a>, <a href="/format/2303.00908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive Text Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Faltings%2C+F">Felix Faltings</a>, 
<a href="/search/cs?searchtype=author&query=Galley%2C+M">Michel Galley</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Baolin Peng</a>, 
<a href="/search/cs?searchtype=author&query=Brantley%2C+K">Kiant&#xe9; Brantley</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+W">Weixin Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yizhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jianfeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Dolan%2C+B">Bill Dolan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item723">[723]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02581" title="Abstract">arXiv:2303.02581</a> (replaced) [<a href="/pdf/2303.02581" title="Download PDF">pdf</a>, <a href="/format/2303.02581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Rolling Over to Walking: Enabling Humanoid Robots to Develop  Complex Motor Skills
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+F">Fanxing Meng</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jing Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 9 figures. Submitted to IEEE Robotics and Automation Letters. Video available at <a href="https://youtu.be/d0RqrW1EzjQ">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item724">[724]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.04878" title="Abstract">arXiv:2303.04878</a> (replaced) [<a href="/pdf/2303.04878" title="Download PDF">pdf</a>, <a href="/format/2303.04878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepGD: A Multi-Objective Black-Box Test Selection Approach for Deep  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aghababaeyan%2C+Z">Zohreh Aghababaeyan</a>, 
<a href="/search/cs?searchtype=author&query=Abdellatif%2C+M">Manel Abdellatif</a>, 
<a href="/search/cs?searchtype=author&query=Dadkhah%2C+M">Mahboubeh Dadkhah</a>, 
<a href="/search/cs?searchtype=author&query=Briand%2C+L">Lionel Briand</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Performance (cs.PF); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item725">[725]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05621" title="Abstract">arXiv:2303.05621</a> (replaced) [<a href="/pdf/2303.05621" title="Download PDF">pdf</a>, <a href="/ps/2303.05621" title="Download PostScript">ps</a>, <a href="/format/2303.05621" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformation of social ties in COVID-19 America: Remote communication  preventing social isolation may amplify political echo chambers in close  relationships
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+B">Byungkyu Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kangsan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hartmann%2C+B">Benjamin Hartmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item726">[726]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06234" title="Abstract">arXiv:2303.06234</a> (replaced) [<a href="/pdf/2303.06234" title="Download PDF">pdf</a>, <a href="/format/2303.06234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal and Private Learning from Human Response Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D">Duc Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A+Y">Anderson Y. Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Conference on Artificial Intelligence and Statistics (AISTATS) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item727">[727]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06532" title="Abstract">arXiv:2303.06532</a> (replaced) [<a href="/pdf/2303.06532" title="Download PDF">pdf</a>, <a href="/format/2303.06532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Design of Metaheuristic Algorithms: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Q">Qiqi Duan</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+B">Bai Yan</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Shi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yuhui Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item728">[728]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.07271" title="Abstract">arXiv:2303.07271</a> (replaced) [<a href="/pdf/2303.07271" title="Download PDF">pdf</a>, <a href="/format/2303.07271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provably Convergent Plug-and-Play Quasi-Newton Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tan%2C+H+Y">Hong Ye Tan</a>, 
<a href="/search/math?searchtype=author&query=Mukherjee%2C+S">Subhadip Mukherjee</a>, 
<a href="/search/math?searchtype=author&query=Tang%2C+J">Junqi Tang</a>, 
<a href="/search/math?searchtype=author&query=Sch%C3%B6nlieb%2C+C">Carola-Bibiane Sch&#xf6;nlieb</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item729">[729]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08232" title="Abstract">arXiv:2303.08232</a> (replaced) [<a href="/pdf/2303.08232" title="Download PDF">pdf</a>, <a href="/format/2303.08232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Humanoid Multi-Contact through Feasibility Visualization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McCrory%2C+S">Stephen McCrory</a>, 
<a href="/search/cs?searchtype=author&query=Bertrand%2C+S">Sylvain Bertrand</a>, 
<a href="/search/cs?searchtype=author&query=Mohan%2C+A">Achintya Mohan</a>, 
<a href="/search/cs?searchtype=author&query=Calvert%2C+D">Duncan Calvert</a>, 
<a href="/search/cs?searchtype=author&query=Pratt%2C+J">Jerry Pratt</a>, 
<a href="/search/cs?searchtype=author&query=Griffin%2C+R">Robert Griffin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item730">[730]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08553" title="Abstract">arXiv:2303.08553</a> (replaced) [<a href="/pdf/2303.08553" title="Download PDF">pdf</a>, <a href="/ps/2303.08553" title="Download PostScript">ps</a>, <a href="/format/2303.08553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Image of the Process Interpretation of Regular Expressions is Not  Closed under Bisimulation Collapse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grabmayer%2C+C">Clemens Grabmayer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Report (14 p. + 10 p. app) written for a submission in Jan 2021 (now with added explanation of relation with subsequent work that was published earlier) concerning the crucial observation underlying the crystallization process in <a href="/abs/2209.12188">arXiv:2209.12188</a> version 2: extension of Prop. 2.12 to "under star 1-free" expressions, and correction in its proof (added termination subterm to extraction function)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item731">[731]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09401" title="Abstract">arXiv:2303.09401</a> (replaced) [<a href="/pdf/2303.09401" title="Download PDF">pdf</a>, <a href="/ps/2303.09401" title="Download PostScript">ps</a>, <a href="/format/2303.09401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Arithmetic Average Density Fusion -- Part III: Heterogeneous Unlabeled  and Labeled RFS Filter Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+T">Tiancheng Li</a>, 
<a href="/search/eess?searchtype=author&query=Yan%2C+R">Ruibo Yan</a>, 
<a href="/search/eess?searchtype=author&query=Da%2C+K">Kai Da</a>, 
<a href="/search/eess?searchtype=author&query=Fan%2C+H">Hongqi Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 14 figures. IEEE Transactions on Aerospace and Electronics Systems, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item732">[732]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09447" title="Abstract">arXiv:2303.09447</a> (replaced) [<a href="/pdf/2303.09447" title="Download PDF">pdf</a>, <a href="/format/2303.09447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Steering Prototypes with Prompt-tuning for Rehearsal-free Continual  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuowei Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Long Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zizhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Han Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Di Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Ting Liu</a>, 
<a href="/search/cs?searchtype=author&query=Metaxas%2C+D+N">Dimitris N. Metaxas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accept to WACV 2024. Code is available at <a href="https://github.com/LzVv123456/Contrastive-Prototypical-Prompt">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item733">[733]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10180" title="Abstract">arXiv:2303.10180</a> (replaced) [<a href="/pdf/2303.10180" title="Download PDF">pdf</a>, <a href="/format/2303.10180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Real-World Applications of Personalized Anesthesia Using Policy  Constraint Q Learning for Propofol Infusion Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xiuding Cai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yaoyao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Beimin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yu Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item734">[734]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12816" title="Abstract">arXiv:2303.12816</a> (replaced) [<a href="/pdf/2303.12816" title="Download PDF">pdf</a>, <a href="/format/2303.12816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Wide to Deep: Dimension Lifting Network for Parameter-efficient  Knowledge Graph Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+B">Borui Cai</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+Y">Yong Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Longxiang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Di Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">He Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+J">Jiong Jin</a>, 
<a href="/search/cs?searchtype=author&query=Luan%2C+T">Tom Luan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item735">[735]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13525" title="Abstract">arXiv:2303.13525</a> (replaced) [<a href="/pdf/2303.13525" title="Download PDF">pdf</a>, <a href="/format/2303.13525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forecasting Workload in Cloud Computing: Towards Uncertainty-Aware  Predictions and Transfer Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rossi%2C+A">Andrea Rossi</a>, 
<a href="/search/cs?searchtype=author&query=Visentin%2C+A">Andrea Visentin</a>, 
<a href="/search/cs?searchtype=author&query=Carraro%2C+D">Diego Carraro</a>, 
<a href="/search/cs?searchtype=author&query=Prestwich%2C+S">Steven Prestwich</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+K+N">Kenneth N. Brown</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item736">[736]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16445" title="Abstract">arXiv:2303.16445</a> (replaced) [<a href="/pdf/2303.16445" title="Download PDF">pdf</a>, <a href="/format/2303.16445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Larger Probes Tell a Different Story: Extending Psycholinguistic  Datasets Via In-Context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shivagunde%2C+N">Namrata Shivagunde</a>, 
<a href="/search/cs?searchtype=author&query=Lialin%2C+V">Vladislav Lialin</a>, 
<a href="/search/cs?searchtype=author&query=Rumshisky%2C+A">Anna Rumshisky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 6 figures. Published as a conference paper at EMNLP 20223 (short). The datasets and code are available on this $\href{<a href="https://github.com/text-machine-lab/extending_psycholinguistic_dataset">this https URL</a>}{URL}$
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item737">[737]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00466" title="Abstract">arXiv:2304.00466</a> (replaced) [<a href="/pdf/2304.00466" title="Download PDF">pdf</a>, <a href="/format/2304.00466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Robust Medical Image Segmentation from Multi-source Annotations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yifeng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Luo%2C+L">Luyang Luo</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+M">Mingxiang Wu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Q">Qiong Wang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+H">Hao Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item738">[738]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00477" title="Abstract">arXiv:2304.00477</a> (replaced) [<a href="/pdf/2304.00477" title="Download PDF">pdf</a>, <a href="/format/2304.00477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demonstration of InsightPilot: An LLM-Empowered Automated Data  Exploration System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+P">Pingchuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+R">Rui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Shi Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongmei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item739">[739]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.02603" title="Abstract">arXiv:2304.02603</a> (replaced) [<a href="/pdf/2304.02603" title="Download PDF">pdf</a>, <a href="/format/2304.02603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Checklist to Publish Collections as Data in GLAM Institutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Candela%2C+G">Gustavo Candela</a>, 
<a href="/search/cs?searchtype=author&query=Gabri%C3%ABls%2C+N">Nele Gabri&#xeb;ls</a>, 
<a href="/search/cs?searchtype=author&query=Chambers%2C+S">Sally Chambers</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+T">Thuy-An Pham</a>, 
<a href="/search/cs?searchtype=author&query=Ames%2C+S">Sarah Ames</a>, 
<a href="/search/cs?searchtype=author&query=Fitzgerald%2C+N">Neil Fitzgerald</a>, 
<a href="/search/cs?searchtype=author&query=Hofmann%2C+K">Katrine Hofmann</a>, 
<a href="/search/cs?searchtype=author&query=Harbo%2C+V">Victor Harbo</a>, 
<a href="/search/cs?searchtype=author&query=Potter%2C+A">Abigail Potter</a>, 
<a href="/search/cs?searchtype=author&query=Ferriter%2C+M">Meghan Ferriter</a>, 
<a href="/search/cs?searchtype=author&query=Manchester%2C+E">Eileen Manchester</a>, 
<a href="/search/cs?searchtype=author&query=Irollo%2C+A">Alba Irollo</a>, 
<a href="/search/cs?searchtype=author&query=Van+Keer%2C+E">Ellen Van Keer</a>, 
<a href="/search/cs?searchtype=author&query=Mahey%2C+M">Mahendra Mahey</a>, 
<a href="/search/cs?searchtype=author&query=Holownia%2C+O">Olga Holownia</a>, 
<a href="/search/cs?searchtype=author&query=Dobreva%2C+M">Milena Dobreva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is an original manuscript of an article published by Emerald Publishing Limited in Global Knowledge, Memory and Communication on 9 November 2023, available online: <a href="https://doi.org/10.1108/GKMC-06-2023-0195">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
</div>
</dd>
<dt><a name="item740">[740]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.02725" title="Abstract">arXiv:2304.02725</a> (replaced) [<a href="/pdf/2304.02725" title="Download PDF">pdf</a>, <a href="/format/2304.02725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FMG-Net and W-Net: Multigrid Inspired Deep Learning Architectures For  Medical Imaging Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Celaya%2C+A">Adrian Celaya</a>, 
<a href="/search/eess?searchtype=author&query=Riviere%2C+B">Beatrice Riviere</a>, 
<a href="/search/eess?searchtype=author&query=Fuentes%2C+D">David Fuentes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in LatinX in AI (LXAI) Research Workshop @ NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item741">[741]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.02848" title="Abstract">arXiv:2304.02848</a> (replaced) [<a href="/e-print/2304.02848" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Patch-aware Batch Normalization for Improving Cross-domain Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+L">Lei Qi</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dongjia Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yinghuan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+X">Xin Geng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We are revising this paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item742">[742]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03738" title="Abstract">arXiv:2304.03738</a> (replaced) [<a href="/pdf/2304.03738" title="Download PDF">pdf</a>, <a href="/ps/2304.03738" title="Download PostScript">ps</a>, <a href="/format/2304.03738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Should ChatGPT be Biased? Challenges and Risks of Bias in Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferrara%2C+E">Emilio Ferrara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published on First Monday <a href="https://firstmonday.org/ojs/index.php/fm/article/view/13346/11365">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> First Monday, Volume 28, Number 11 - 6 November 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item743">[743]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05175" title="Abstract">arXiv:2304.05175</a> (replaced) [<a href="/pdf/2304.05175" title="Download PDF">pdf</a>, <a href="/ps/2304.05175" title="Download PostScript">ps</a>, <a href="/format/2304.05175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sufficient Conditions for the Exact Relaxation of Complementarity  Constraints for Storages in Multi-period OPF Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+Q">Qi Wang</a>, 
<a href="/search/math?searchtype=author&query=Wu%2C+W">Wenchuan Wu</a>, 
<a href="/search/math?searchtype=author&query=Lin%2C+C">Chenhui Lin</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+S">Shuwei Xu</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+X">Xueliang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item744">[744]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06835" title="Abstract">arXiv:2304.06835</a> (replaced) [<a href="/pdf/2304.06835" title="Download PDF">pdf</a>, <a href="/format/2304.06835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Translation and Accelerated Solving of Differential Equations  on Multiple GPU Platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Utkarsh%2C+U">Utkarsh Utkarsh</a>, 
<a href="/search/cs?searchtype=author&query=Churavy%2C+V">Valentin Churavy</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yingbo Ma</a>, 
<a href="/search/cs?searchtype=author&query=Besard%2C+T">Tim Besard</a>, 
<a href="/search/cs?searchtype=author&query=Srisuma%2C+P">Prakitr Srisuma</a>, 
<a href="/search/cs?searchtype=author&query=Gymnich%2C+T">Tim Gymnich</a>, 
<a href="/search/cs?searchtype=author&query=Gerlach%2C+A+R">Adam R. Gerlach</a>, 
<a href="/search/cs?searchtype=author&query=Edelman%2C+A">Alan Edelman</a>, 
<a href="/search/cs?searchtype=author&query=Barbastathis%2C+G">George Barbastathis</a>, 
<a href="/search/cs?searchtype=author&query=Braatz%2C+R+D">Richard D. Braatz</a>, 
<a href="/search/cs?searchtype=author&query=Rackauckas%2C+C">Christopher Rackauckas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Mathematical Software (cs.MS); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item745">[745]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.09402" title="Abstract">arXiv:2304.09402</a> (replaced) [<a href="/pdf/2304.09402" title="Download PDF">pdf</a>, <a href="/format/2304.09402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MixPro: Simple yet Effective Data Augmentation for Prompt-based Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bohan Li</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+L">Longxu Dou</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yutai Hou</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yunlong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+H">Honglin Mu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qingfu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Qinghua Sun</a>, 
<a href="/search/cs?searchtype=author&query=Che%2C+W">Wanxiang Che</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 5 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item746">[746]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12559" title="Abstract">arXiv:2304.12559</a> (replaced) [<a href="/pdf/2304.12559" title="Download PDF">pdf</a>, <a href="/ps/2304.12559" title="Download PostScript">ps</a>, <a href="/format/2304.12559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attraction by ingroup coherence explains the emergence of ideological  sorting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Zimmerman%2C+F">Federico Zimmerman</a>, 
<a href="/search/physics?searchtype=author&query=Pedraza%2C+L">Luc&#xed;a Pedraza</a>, 
<a href="/search/physics?searchtype=author&query=Navajas%2C+J">Joaqu&#xed;n Navajas</a>, 
<a href="/search/physics?searchtype=author&query=Balenzuela%2C+P">Pablo Balenzuela</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item747">[747]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13231" title="Abstract">arXiv:2304.13231</a> (replaced) [<a href="/pdf/2304.13231" title="Download PDF">pdf</a>, <a href="/ps/2304.13231" title="Download PostScript">ps</a>, <a href="/format/2304.13231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance of the Gittins Policy in the G/G/1 and G/G/k, With and  Without Setup Times
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+Y">Yige Hong</a>, 
<a href="/search/cs?searchtype=author&query=Scully%2C+Z">Ziv Scully</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Performance Evaluation 163 (2024), 102377
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>; Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item748">[748]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14701" title="Abstract">arXiv:2304.14701</a> (replaced) [<a href="/pdf/2304.14701" title="Download PDF">pdf</a>, <a href="/ps/2304.14701" title="Download PostScript">ps</a>, <a href="/format/2304.14701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Permissionless Consensus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lewis-Pye%2C+A">Andrew Lewis-Pye</a>, 
<a href="/search/cs?searchtype=author&query=Roughgarden%2C+T">Tim Roughgarden</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a journal version of the paper that subsumes earlier (conference) versions "Byzantine Generals in the Permissionless Setting" and "Resource Pools and the CAP Theorem"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item749">[749]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.00876" title="Abstract">arXiv:2305.00876</a> (replaced) [<a href="/pdf/2305.00876" title="Download PDF">pdf</a>, <a href="/ps/2305.00876" title="Download PostScript">ps</a>, <a href="/format/2305.00876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exactly Tight Information-Theoretic Generalization Error Bound for the  Quadratic Gaussian Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+R">Ruida Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+C">Chao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tie Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item750">[750]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03626" title="Abstract">arXiv:2305.03626</a> (replaced) [<a href="/pdf/2305.03626" title="Download PDF">pdf</a>, <a href="/format/2305.03626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Verifiable Learning for Robust Tree Ensembles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Calzavara%2C+S">Stefano Calzavara</a>, 
<a href="/search/cs?searchtype=author&query=Cazzaro%2C+L">Lorenzo Cazzaro</a>, 
<a href="/search/cs?searchtype=author&query=Pibiri%2C+G+E">Giulio Ermanno Pibiri</a>, 
<a href="/search/cs?searchtype=author&query=Prezza%2C+N">Nicola Prezza</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 5 figures; full version of the revised paper accepted at ACM CCS 2023 with corrected typo in footnote 1
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Logic in Computer Science (cs.LO); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item751">[751]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04608" title="Abstract">arXiv:2305.04608</a> (replaced) [<a href="/pdf/2305.04608" title="Download PDF">pdf</a>, <a href="/format/2305.04608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inferring Object Boundaries and their Roughness with Uncertainty  Quantification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Afkham%2C+B+M">Babak Maboudi Afkham</a>, 
<a href="/search/math?searchtype=author&query=Riis%2C+N+A+B">Nicolai Andr&#xe9; Brogaard Riis</a>, 
<a href="/search/math?searchtype=author&query=Dong%2C+Y">Yiqiu Dong</a>, 
<a href="/search/math?searchtype=author&query=Hansen%2C+P+C">Per Christian Hansen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item752">[752]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06899" title="Abstract">arXiv:2305.06899</a> (replaced) [<a href="/pdf/2305.06899" title="Download PDF">pdf</a>, <a href="/format/2305.06899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized signals on simplicial complexes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ji%2C+F">Feng Ji</a>, 
<a href="/search/eess?searchtype=author&query=Jian%2C+X">Xingchao Jian</a>, 
<a href="/search/eess?searchtype=author&query=Tay%2C+W+P">Wee Peng Tay</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+M">Maosheng Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item753">[753]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08946" title="Abstract">arXiv:2305.08946</a> (replaced) [<a href="/pdf/2305.08946" title="Download PDF">pdf</a>, <a href="/format/2305.08946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Matching by Bare Homography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bellavia%2C+F">Fabio Bellavia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> major revision update - fixed bars in Fig. 10 and further typos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item754">[754]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10607" title="Abstract">arXiv:2305.10607</a> (replaced) [<a href="/pdf/2305.10607" title="Download PDF">pdf</a>, <a href="/format/2305.10607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to train your demon to do fast information erasure without heat  production
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Whitelam%2C+S">Stephen Whitelam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Mechanics (cond-mat.stat-mech)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item755">[755]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11650" title="Abstract">arXiv:2305.11650</a> (replaced) [<a href="/pdf/2305.11650" title="Download PDF">pdf</a>, <a href="/format/2305.11650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Moment Matching Denoising Gibbs Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhang%2C+M">Mingtian Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Hawkins-Hooker%2C+A">Alex Hawkins-Hooker</a>, 
<a href="/search/stat?searchtype=author&query=Paige%2C+B">Brooks Paige</a>, 
<a href="/search/stat?searchtype=author&query=Barber%2C+D">David Barber</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item756">[756]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11755" title="Abstract">arXiv:2305.11755</a> (replaced) [<a href="/pdf/2305.11755" title="Download PDF">pdf</a>, <a href="/format/2305.11755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visualization for Recommendation Explainability: A Survey and New  Perspectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chatti%2C+M+A">Mohamed Amine Chatti</a>, 
<a href="/search/cs?searchtype=author&query=Guesmi%2C+M">Mouadh Guesmi</a>, 
<a href="/search/cs?searchtype=author&query=Muslim%2C+A">Arham Muslim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated version Nov. 2023, 36 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item757">[757]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12082" title="Abstract">arXiv:2305.12082</a> (replaced) [<a href="/pdf/2305.12082" title="Download PDF">pdf</a>, <a href="/format/2305.12082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SneakyPrompt: Jailbreaking Text-to-image Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuchen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+B">Bo Hui</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Haolin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+N">Neil Gong</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yinzhi Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the Proceedings of the IEEE Symposium on Security and Privacy (Oakland), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item758">[758]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12171" title="Abstract">arXiv:2305.12171</a> (replaced) [<a href="/pdf/2305.12171" title="Download PDF">pdf</a>, <a href="/format/2305.12171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Co-Policy for Synergistic Human-Robot Collaborative Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ng%2C+E">Eley Ng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kennedy%2C+M">Monroe Kennedy III</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Robotics and Automation Letters (RA-L), 2023. 8 pages, 7 figures, 3 tables. Supplementary material at <a href="https://sites.google.com/view/diffusion-co-policy-hrc">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item759">[759]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12297" title="Abstract">arXiv:2305.12297</a> (replaced) [<a href="/pdf/2305.12297" title="Download PDF">pdf</a>, <a href="/format/2305.12297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The theory of percolation on hypergraphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Bianconi%2C+G">Ginestra Bianconi</a>, 
<a href="/search/physics?searchtype=author&query=Dorogovtsev%2C+S+N">Sergey N. Dorogovtsev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> (12 pages, 4 figures)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Statistical Mechanics (cond-mat.stat-mech); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item760">[760]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12433" title="Abstract">arXiv:2305.12433</a> (replaced) [<a href="/pdf/2305.12433" title="Download PDF">pdf</a>, <a href="/format/2305.12433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ParticleWNN: a Novel Neural Networks Framework for Solving Partial  Differential Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zang%2C+Y">Yaohua Zang</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+G">Gang Bao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item761">[761]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12751" title="Abstract">arXiv:2305.12751</a> (replaced) [<a href="/pdf/2305.12751" title="Download PDF">pdf</a>, <a href="/format/2305.12751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Testing of Deep Reinforcement Learning Agents with Surrogate Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Biagiola%2C+M">Matteo Biagiola</a>, 
<a href="/search/cs?searchtype=author&query=Tonella%2C+P">Paolo Tonella</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item762">[762]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13169" title="Abstract">arXiv:2305.13169</a> (replaced) [<a href="/pdf/2305.13169" title="Download PDF">pdf</a>, <a href="/format/2305.13169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Pretrainer&#x27;s Guide to Training Data: Measuring the Effects of Data  Age, Domain Coverage, Quality, &amp; Toxicity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Longpre%2C+S">Shayne Longpre</a>, 
<a href="/search/cs?searchtype=author&query=Yauney%2C+G">Gregory Yauney</a>, 
<a href="/search/cs?searchtype=author&query=Reif%2C+E">Emily Reif</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Katherine Lee</a>, 
<a href="/search/cs?searchtype=author&query=Roberts%2C+A">Adam Roberts</a>, 
<a href="/search/cs?searchtype=author&query=Zoph%2C+B">Barret Zoph</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Denny Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jason Wei</a>, 
<a href="/search/cs?searchtype=author&query=Robinson%2C+K">Kevin Robinson</a>, 
<a href="/search/cs?searchtype=author&query=Mimno%2C+D">David Mimno</a>, 
<a href="/search/cs?searchtype=author&query=Ippolito%2C+D">Daphne Ippolito</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item763">[763]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13528" title="Abstract">arXiv:2305.13528</a> (replaced) [<a href="/pdf/2305.13528" title="Download PDF">pdf</a>, <a href="/format/2305.13528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transfer-Free Data-Efficient Multilingual Slot Labeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Razumovskaia%2C+E">Evgeniia Razumovskaia</a>, 
<a href="/search/cs?searchtype=author&query=Vuli%C4%87%2C+I">Ivan Vuli&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Korhonen%2C+A">Anna Korhonen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item764">[764]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13583" title="Abstract">arXiv:2305.13583</a> (replaced) [<a href="/pdf/2305.13583" title="Download PDF">pdf</a>, <a href="/format/2305.13583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Attention is Not Enough: Incongruity-Aware Dynamic Hierarchical  Fusion for Multimodal Affect Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaoting Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanchao Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P+P">Paul Pu Liang</a>, 
<a href="/search/cs?searchtype=author&query=Morency%2C+L">Louis-Philippe Morency</a>, 
<a href="/search/cs?searchtype=author&query=Bell%2C+P">Peter Bell</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+C">Catherine Lai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> *First two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Multimedia (cs.MM); Audio and Speech Processing (eess.AS); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item765">[765]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13749" title="Abstract">arXiv:2305.13749</a> (replaced) [<a href="/pdf/2305.13749" title="Download PDF">pdf</a>, <a href="/format/2305.13749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Goal-Driven Explainable Clustering via Language Descriptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+J">Jingbo Shang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+R">Ruiqi Zhong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item766">[766]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14053" title="Abstract">arXiv:2305.14053</a> (replaced) [<a href="/pdf/2305.14053" title="Download PDF">pdf</a>, <a href="/format/2305.14053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parts of Speech-Grounded Subspaces in Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oldfield%2C+J">James Oldfield</a>, 
<a href="/search/cs?searchtype=author&query=Tzelepis%2C+C">Christos Tzelepis</a>, 
<a href="/search/cs?searchtype=author&query=Panagakis%2C+Y">Yannis Panagakis</a>, 
<a href="/search/cs?searchtype=author&query=Nicolaou%2C+M+A">Mihalis A. Nicolaou</a>, 
<a href="/search/cs?searchtype=author&query=Patras%2C+I">Ioannis Patras</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item767">[767]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14291" title="Abstract">arXiv:2305.14291</a> (replaced) [<a href="/pdf/2305.14291" title="Download PDF">pdf</a>, <a href="/format/2305.14291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of African American Language Bias in Natural Language  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deas%2C+N">Nicholas Deas</a>, 
<a href="/search/cs?searchtype=author&query=Grieser%2C+J">Jessi Grieser</a>, 
<a href="/search/cs?searchtype=author&query=Kleiner%2C+S">Shana Kleiner</a>, 
<a href="/search/cs?searchtype=author&query=Patton%2C+D">Desmond Patton</a>, 
<a href="/search/cs?searchtype=author&query=Turcan%2C+E">Elsbeth Turcan</a>, 
<a href="/search/cs?searchtype=author&query=McKeown%2C+K">Kathleen McKeown</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 Camera-Ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item768">[768]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14575" title="Abstract">arXiv:2305.14575</a> (replaced) [<a href="/pdf/2305.14575" title="Download PDF">pdf</a>, <a href="/format/2305.14575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Early Prediction of Human iPSC Reprogramming Success
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Abhineet Singh</a>, 
<a href="/search/cs?searchtype=author&query=Jasra%2C+I">Ila Jasra</a>, 
<a href="/search/cs?searchtype=author&query=Mouhammed%2C+O">Omar Mouhammed</a>, 
<a href="/search/cs?searchtype=author&query=Dadheech%2C+N">Nidheesh Dadheech</a>, 
<a href="/search/cs?searchtype=author&query=Ray%2C+N">Nilanjan Ray</a>, 
<a href="/search/cs?searchtype=author&query=Shapiro%2C+J">James Shapiro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) <a href="https://melba-journal.org/2023:014">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Machine.Learning.for.Biomedical.Imaging. 2 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item769">[769]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15003" title="Abstract">arXiv:2305.15003</a> (replaced) [<a href="/pdf/2305.15003" title="Download PDF">pdf</a>, <a href="/format/2305.15003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feasible Action-Space Reduction as a Metric of Causal Responsibility in  Multi-Agent Spatial Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=George%2C+A">Ashwin George</a>, 
<a href="/search/cs?searchtype=author&query=Siebert%2C+L+C">Luciano Cavalcante Siebert</a>, 
<a href="/search/cs?searchtype=author&query=Abbink%2C+D">David Abbink</a>, 
<a href="/search/cs?searchtype=author&query=Zgonnikov%2C+A">Arkady Zgonnikov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
</div>
</dd>
<dt><a name="item770">[770]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15047" title="Abstract">arXiv:2305.15047</a> (replaced) [<a href="/pdf/2305.15047" title="Download PDF">pdf</a>, <a href="/format/2305.15047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ghostbuster: Detecting Text Ghostwritten by Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Verma%2C+V">Vivek Verma</a>, 
<a href="/search/cs?searchtype=author&query=Fleisig%2C+E">Eve Fleisig</a>, 
<a href="/search/cs?searchtype=author&query=Tomlin%2C+N">Nicholas Tomlin</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+D">Dan Klein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item771">[771]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15616" title="Abstract">arXiv:2305.15616</a> (replaced) [<a href="/pdf/2305.15616" title="Download PDF">pdf</a>, <a href="/format/2305.15616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reversible and irreversible bracket-based dynamics for deep graph neural  networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gruber%2C+A">Anthony Gruber</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kookjin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Trask%2C+N">Nathaniel Trask</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item772">[772]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15778" title="Abstract">arXiv:2305.15778</a> (replaced) [<a href="/pdf/2305.15778" title="Download PDF">pdf</a>, <a href="/format/2305.15778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Root Cause Analysis via Large Language Models for Cloud  Incidents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yinfang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Huaibing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+M">Minghua Ma</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yu Kang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+L">Liu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yunjie Cao</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xuedong Gao</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Hao Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+M">Ming Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+J">Jun Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Supriyo Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuchao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chaoyun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Q">Qingwei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Rajmohan%2C+S">Saravan Rajmohan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongmei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tianyin Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item773">[773]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15889" title="Abstract">arXiv:2305.15889</a> (replaced) [<a href="/pdf/2305.15889" title="Download PDF">pdf</a>, <a href="/format/2305.15889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantitatively Measuring and Contrastively Exploring Heterogeneity for  Domain Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tong%2C+Y">Yunze Tong</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Junkun Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+D">Didi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Keli Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Kuang%2C+K">Kun Kuang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by KDD 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item774">[774]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16963" title="Abstract">arXiv:2305.16963</a> (replaced) [<a href="/pdf/2305.16963" title="Download PDF">pdf</a>, <a href="/format/2305.16963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic segmentation of sparse irregular point clouds for leaf/wood  discrimination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yuchen Bai</a>, 
<a href="/search/cs?searchtype=author&query=Durand%2C+J">Jean-Baptiste Durand</a>, 
<a href="/search/cs?searchtype=author&query=Forbes%2C+F">Florence Forbes</a>, 
<a href="/search/cs?searchtype=author&query=Vincent%2C+G">Gr&#xe9;goire Vincent</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 37th Conference on Neural Information
  Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item775">[775]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17600" title="Abstract">arXiv:2305.17600</a> (replaced) [<a href="/pdf/2305.17600" title="Download PDF">pdf</a>, <a href="/format/2305.17600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NashFormer: Leveraging Local Nash Equilibria for Semantically Diverse  Trajectory Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lidard%2C+J">Justin Lidard</a>, 
<a href="/search/cs?searchtype=author&query=So%2C+O">Oswin So</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanxia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=DeCastro%2C+J">Jonathan DeCastro</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+X">Xiongyi Cui</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Kuo%2C+Y">Yen-Ling Kuo</a>, 
<a href="/search/cs?searchtype=author&query=Leonard%2C+J">John Leonard</a>, 
<a href="/search/cs?searchtype=author&query=Balachandran%2C+A">Avinash Balachandran</a>, 
<a href="/search/cs?searchtype=author&query=Leonard%2C+N">Naomi Leonard</a>, 
<a href="/search/cs?searchtype=author&query=Rosman%2C+G">Guy Rosman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Computer Science and Game Theory (cs.GT); Robotics (cs.RO); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item776">[776]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18259" title="Abstract">arXiv:2305.18259</a> (replaced) [<a href="/pdf/2305.18259" title="Download PDF">pdf</a>, <a href="/format/2305.18259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GlyphControl: Glyph Conditional Control for Visual Text Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yukang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+D">Dongnan Gui</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yuhui Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+W">Weicong Liang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+H">Haisong Ding</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Han Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023. The codes have been released at <a href="https://github.com/AIGText/GlyphControl-release">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item777">[777]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18414" title="Abstract">arXiv:2305.18414</a> (replaced) [<a href="/pdf/2305.18414" title="Download PDF">pdf</a>, <a href="/format/2305.18414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StEik: Stabilizing the Optimization of Neural Signed Distance Functions  and Finer Shape Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Huizong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuxin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Sundaramoorthi%2C+G">Ganesh Sundaramoorthi</a>, 
<a href="/search/cs?searchtype=author&query=Yezzi%2C+A">Anthony Yezzi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item778">[778]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18427" title="Abstract">arXiv:2305.18427</a> (replaced) [<a href="/pdf/2305.18427" title="Download PDF">pdf</a>, <a href="/format/2305.18427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable Reward Redistribution in Reinforcement Learning: A Causal  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yudi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yali Du</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Biwei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziyan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+M">Meng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Pechenizkiy%2C+M">Mykola Pechenizkiy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 camera-ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item779">[779]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18450" title="Abstract">arXiv:2305.18450</a> (replaced) [<a href="/pdf/2305.18450" title="Download PDF">pdf</a>, <a href="/format/2305.18450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GBG++: A Fast and Stable Granular Ball Generation Method for  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+Q">Qin Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qinghua Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Shuyin Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+F">Fan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chengying Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guoyin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+W">Weiping Ding</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item780">[780]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18831" title="Abstract">arXiv:2305.18831</a> (replaced) [<a href="/pdf/2305.18831" title="Download PDF">pdf</a>, <a href="/format/2305.18831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convolutional Monge Mapping Normalization for learning on sleep data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gnassounou%2C+T">Th&#xe9;o Gnassounou</a>, 
<a href="/search/eess?searchtype=author&query=Flamary%2C+R">R&#xe9;mi Flamary</a>, 
<a href="/search/eess?searchtype=author&query=Gramfort%2C+A">Alexandre Gramfort</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item781">[781]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19452" title="Abstract">arXiv:2305.19452</a> (replaced) [<a href="/pdf/2305.19452" title="Download PDF">pdf</a>, <a href="/format/2305.19452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bigger, Better, Faster: Human-level Atari with human-level efficiency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schwarzer%2C+M">Max Schwarzer</a>, 
<a href="/search/cs?searchtype=author&query=Obando-Ceron%2C+J">Johan Obando-Ceron</a>, 
<a href="/search/cs?searchtype=author&query=Courville%2C+A">Aaron Courville</a>, 
<a href="/search/cs?searchtype=author&query=Bellemare%2C+M">Marc Bellemare</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+R">Rishabh Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Castro%2C+P+S">Pablo Samuel Castro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICML 2023, revised version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item782">[782]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19915" title="Abstract">arXiv:2305.19915</a> (replaced) [<a href="/pdf/2305.19915" title="Download PDF">pdf</a>, <a href="/format/2305.19915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Source Code Data Augmentation for Deep Learning: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhuo%2C+T+Y">Terry Yue Zhuo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhou Yang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhensu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yufei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Li Li</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xiaoning Du</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Z">Zhenchang Xing</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+D">David Lo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ongoing work; 89 publications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item783">[783]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00074" title="Abstract">arXiv:2306.00074</a> (replaced) [<a href="/pdf/2306.00074" title="Download PDF">pdf</a>, <a href="/format/2306.00074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human-Aligned Calibration for AI-Assisted Decision Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Benz%2C+N+L+C">Nina L. Corvelo Benz</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+M+G">Manuel Gomez Rodriguez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item784">[784]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02500" title="Abstract">arXiv:2306.02500</a> (replaced) [<a href="/pdf/2306.02500" title="Download PDF">pdf</a>, <a href="/format/2306.02500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Systematic Visual Reasoning through Object-Centric Relational  Abstraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Webb%2C+T+W">Taylor W. Webb</a>, 
<a href="/search/cs?searchtype=author&query=Mondal%2C+S+S">Shanka Subhra Mondal</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+J+D">Jonathan D. Cohen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item785">[785]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03289" title="Abstract">arXiv:2306.03289</a> (replaced) [<a href="/pdf/2306.03289" title="Download PDF">pdf</a>, <a href="/format/2306.03289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Role of AI Assistants in Computer Science Education:  Methods, Implications, and Instructor Perspectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianjia Wang</a>, 
<a href="/search/cs?searchtype=author&query=Vargas-D%C3%ADaz%2C+D">Daniel Vargas-D&#xed;az</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+C">Chris Brown</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yan Chen</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE Symposium on Visual Languages and Human-Centric
  Computing (VL/HCC), Washington, DC, USA, 2023, pp. 92-102
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item786">[786]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06874" title="Abstract">arXiv:2306.06874</a> (replaced) [<a href="/pdf/2306.06874" title="Download PDF">pdf</a>, <a href="/format/2306.06874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VillanDiffusion: A Unified Backdoor Attack Framework for Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chou%2C+S">Sheng-Yen Chou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pin-Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+T">Tsung-Yi Ho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023, NeurIPS 2023 BUGS Workshop Oral
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item787">[787]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08144" title="Abstract">arXiv:2306.08144</a> (replaced) [<a href="/pdf/2306.08144" title="Download PDF">pdf</a>, <a href="/format/2306.08144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Correct-by-Construction Design of Contextual Robotic Missions Using  Contracts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mallozzi%2C+P">Piergiuseppe Mallozzi</a>, 
<a href="/search/cs?searchtype=author&query=Nuzzo%2C+P">Pierluigi Nuzzo</a>, 
<a href="/search/cs?searchtype=author&query=Piterman%2C+N">Nir Piterman</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+G">Gerardo Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Pelliccione%2C+P">Patrizio Pelliccione</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item788">[788]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08233" title="Abstract">arXiv:2306.08233</a> (replaced) [<a href="/pdf/2306.08233" title="Download PDF">pdf</a>, <a href="/format/2306.08233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OT-Net: A Reusable Neural Optimal Transport Solver
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zezeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shenghao Li</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Lianbao Jin</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+N">Na Lei</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zhongxuan Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item789">[789]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08495" title="Abstract">arXiv:2306.08495</a> (replaced) [<a href="/pdf/2306.08495" title="Download PDF">pdf</a>, <a href="/format/2306.08495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single-board Device Individual Authentication based on Hardware  Performance and Autoencoder Transformer Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez%2C+P+M+S">Pedro Miguel S&#xe1;nchez S&#xe1;nchez</a>, 
<a href="/search/cs?searchtype=author&query=Celdr%C3%A1n%2C+A+H">Alberto Huertas Celdr&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=Bovet%2C+G">G&#xe9;r&#xf4;me Bovet</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+G+M">Gregorio Mart&#xed;nez P&#xe9;rez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item790">[790]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08698" title="Abstract">arXiv:2306.08698</a> (replaced) [<a href="/pdf/2306.08698" title="Download PDF">pdf</a>, <a href="/ps/2306.08698" title="Download PostScript">ps</a>, <a href="/format/2306.08698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Phase Transitions of Civil Unrest across Countries and Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Braha%2C+D">Dan Braha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Main paper (57 pages); Supporting Information (144 pages) will be available upon request. To appear in npj Complexity
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Machine Learning (cs.LG); Adaptation and Self-Organizing Systems (nlin.AO)

</div>
</div>
</dd>
<dt><a name="item791">[791]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09338" title="Abstract">arXiv:2306.09338</a> (replaced) [<a href="/pdf/2306.09338" title="Download PDF">pdf</a>, <a href="/format/2306.09338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Optimization of Deep Learning via Jacobian Matrix and  Lipschitz Constant
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xianbiao Qi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Digital Economy Academy (IDEA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item792">[792]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10065" title="Abstract">arXiv:2306.10065</a> (replaced) [<a href="/pdf/2306.10065" title="Download PDF">pdf</a>, <a href="/format/2306.10065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taming Diffusion Models for Music-driven Conducting Motion Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhao%2C+Z">Zhuoran Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Bai%2C+J">Jinbin Bai</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+D">Delong Chen</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+D">Debang Wang</a>, 
<a href="/search/eess?searchtype=author&query=Pan%2C+Y">Yubo Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2023 Summer Symposium with Best Paper Award
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item793">[793]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10532" title="Abstract">arXiv:2306.10532</a> (replaced) [<a href="/pdf/2306.10532" title="Download PDF">pdf</a>, <a href="/format/2306.10532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personalized Elastic Embedding Learning for On-Device Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+R">Ruiqi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+L">Liang Qu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+K">Kai Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yuhui Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hongzhi Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item794">[794]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11816" title="Abstract">arXiv:2306.11816</a> (replaced) [<a href="/pdf/2306.11816" title="Download PDF">pdf</a>, <a href="/format/2306.11816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Generate Better Than Your LLM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+J+D">Jonathan D. Chang</a>, 
<a href="/search/cs?searchtype=author&query=Brantley%2C+K">Kiante Brantley</a>, 
<a href="/search/cs?searchtype=author&query=Ramamurthy%2C+R">Rajkumar Ramamurthy</a>, 
<a href="/search/cs?searchtype=author&query=Misra%2C+D">Dipendra Misra</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wen Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 5 figures, 7 tables, 4 algorithms
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item795">[795]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11977" title="Abstract">arXiv:2306.11977</a> (replaced) [<a href="/pdf/2306.11977" title="Download PDF">pdf</a>, <a href="/ps/2306.11977" title="Download PostScript">ps</a>, <a href="/format/2306.11977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Encoding Enhanced Complex CNN for Accurate and Highly Accelerated MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zimeng Li</a>, 
<a href="/search/eess?searchtype=author&query=Xiao%2C+S">Sa Xiao</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+C">Cheng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+H">Haidong Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+X">Xiuchao Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Duan%2C+C">Caohui Duan</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Q">Qian Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Rao%2C+Q">Qiuchen Rao</a>, 
<a href="/search/eess?searchtype=author&query=Fang%2C+Y">Yuan Fang</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+J">Junshuai Xie</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+L">Lei Shi</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+F">Fumin Guo</a>, 
<a href="/search/eess?searchtype=author&query=Ye%2C+C">Chaohui Ye</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+X">Xin Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item796">[796]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12177" title="Abstract">arXiv:2306.12177</a> (replaced) [<a href="/pdf/2306.12177" title="Download PDF">pdf</a>, <a href="/ps/2306.12177" title="Download PostScript">ps</a>, <a href="/format/2306.12177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Condition numbers for the Moore-Penrose inverse and the least squares  problem involving rank-structured matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ahmad%2C+S+S">Sk. Safique Ahmad</a>, 
<a href="/search/math?searchtype=author&query=Khatun%2C+P">Pinki Khatun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item797">[797]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13268" title="Abstract">arXiv:2306.13268</a> (replaced) [<a href="/pdf/2306.13268" title="Download PDF">pdf</a>, <a href="/format/2306.13268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GICI-LIB: A GNSS/INS/Camera Integrated Navigation Library
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chi%2C+C">Cheng Chi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiahui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yulong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zihao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+X">Xingqun Zhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Open-source: <a href="https://github.com/chichengcn/gici-open.">this https URL</a> Preprint version on Robotics and Automation Letters (RAL)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item798">[798]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13478" title="Abstract">arXiv:2306.13478</a> (replaced) [<a href="/pdf/2306.13478" title="Download PDF">pdf</a>, <a href="/ps/2306.13478" title="Download PostScript">ps</a>, <a href="/format/2306.13478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Proof of the Weak Simplex Conjecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pastore%2C+A">Adriano Pastore</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, submitted for peer review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Metric Geometry (math.MG)

</div>
</div>
</dd>
<dt><a name="item799">[799]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13761" title="Abstract">arXiv:2306.13761</a> (replaced) [<a href="/pdf/2306.13761" title="Download PDF">pdf</a>, <a href="/format/2306.13761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CeBed: A Benchmark for Deep Data-Driven OFDM Channel Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feriani%2C+A">Amal Feriani</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Di Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Steve Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dudek%2C+G">Greg Dudek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item800">[800]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13948" title="Abstract">arXiv:2306.13948</a> (replaced) [<a href="/pdf/2306.13948" title="Download PDF">pdf</a>, <a href="/format/2306.13948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unleashing Realistic Air Quality Forecasting: Introducing the  Ready-to-Use PurpleAirSF Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zuo%2C+J">Jingwei Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenbin Li</a>, 
<a href="/search/cs?searchtype=author&query=Baldo%2C+M">Michele Baldo</a>, 
<a href="/search/cs?searchtype=author&query=Hacid%2C+H">Hakim Hacid</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM SIGSPATIAL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item801">[801]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16045" title="Abstract">arXiv:2306.16045</a> (replaced) [<a href="/pdf/2306.16045" title="Download PDF">pdf</a>, <a href="/ps/2306.16045" title="Download PostScript">ps</a>, <a href="/format/2306.16045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenNDD: Open Set Recognition for Neurodevelopmental Disorders Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jiaming Yu</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+Z">Zihao Guan</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xinyue Chang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shujie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhenshan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiumei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Changcai Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Riqing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+L">Lanyan Xue</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+L">Lifang Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item802">[802]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16830" title="Abstract">arXiv:2306.16830</a> (replaced) [<a href="/pdf/2306.16830" title="Download PDF">pdf</a>, <a href="/format/2306.16830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sampling weights of deep neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bolager%2C+E+L">Erik Lien Bolager</a>, 
<a href="/search/cs?searchtype=author&query=Burak%2C+I">Iryna Burak</a>, 
<a href="/search/cs?searchtype=author&query=Datar%2C+C">Chinmay Datar</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Qing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Dietrich%2C+F">Felix Dietrich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages incl. references and appendix, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item803">[803]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17010" title="Abstract">arXiv:2306.17010</a> (replaced) [<a href="/pdf/2306.17010" title="Download PDF">pdf</a>, <a href="/format/2306.17010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> milliFlow: Scene Flow Estimation on mmWave Radar Point Cloud for Human  Motion Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+F">Fangqiang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zhen Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Peijun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C+X">Chris Xiaoxuan Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item804">[804]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00562" title="Abstract">arXiv:2307.00562</a> (replaced) [<a href="/pdf/2307.00562" title="Download PDF">pdf</a>, <a href="/format/2307.00562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A MIL Approach for Anomaly Detection in Surveillance Videos from  Multiple Camera Views
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pereira%2C+S+S+L">Silas Santiago Lopes Pereira</a>, 
<a href="/search/cs?searchtype=author&query=Maia%2C+J+E+B">Jos&#xe9; Everardo Bessa Maia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 Pages, 4 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item805">[805]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00971" title="Abstract">arXiv:2307.00971</a> (replaced) [<a href="/pdf/2307.00971" title="Download PDF">pdf</a>, <a href="/format/2307.00971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fishing For Better Constants: The Prophet Secretary Via Poissonization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harb%2C+E">Elfarouk Harb</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Major revision. 35 pages, several new results/figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item806">[806]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01097" title="Abstract">arXiv:2307.01097</a> (replaced) [<a href="/pdf/2307.01097" title="Download PDF">pdf</a>, <a href="/format/2307.01097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MVDiffusion: Enabling Holistic Multi-view Image Generation with  Correspondence-Aware Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Shitao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fuyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiacheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Furukawa%2C+Y">Yasutaka Furukawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page, <a href="https://mvdiffusion.github.io">this https URL</a>, camera ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item807">[807]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01231" title="Abstract">arXiv:2307.01231</a> (replaced) [<a href="/pdf/2307.01231" title="Download PDF">pdf</a>, <a href="/format/2307.01231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Critical Re-evaluation of Benchmark Datasets for (Deep) Learning-Based  Matching Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Papadakis%2C+G">George Papadakis</a>, 
<a href="/search/cs?searchtype=author&query=Kirielle%2C+N">Nishadi Kirielle</a>, 
<a href="/search/cs?searchtype=author&query=Christen%2C+P">Peter Christen</a>, 
<a href="/search/cs?searchtype=author&query=Palpanas%2C+T">Themis Palpanas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item808">[808]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01465" title="Abstract">arXiv:2307.01465</a> (replaced) [<a href="/pdf/2307.01465" title="Download PDF">pdf</a>, <a href="/format/2307.01465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdAM: Few-Shot Image Generation via Adaptation-Aware Kernel Modulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yunqing Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chandrasegaran%2C+K">Keshigeyan Chandrasegaran</a>, 
<a href="/search/cs?searchtype=author&query=Abdollahzadeh%2C+M">Milad Abdollahzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+C">Chao Du</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+T">Tianyu Pang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruoteng Li</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+H">Henghui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+N">Ngai-Man Cheung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, update additional information, discussion, and experimental sections compared to NeurIPS-22 version: <a href="/abs/2210.16559">arXiv:2210.16559</a>. arXiv admin note: substantial text overlap with <a href="/abs/2210.16559">arXiv:2210.16559</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item809">[809]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02881" title="Abstract">arXiv:2307.02881</a> (replaced) [<a href="/pdf/2307.02881" title="Download PDF">pdf</a>, <a href="/format/2307.02881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic and Semantic Descriptions of Image Manifolds and Their  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tu%2C+P">Peter Tu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhaoyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hartley%2C+R">Richard Hartley</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yiwei Fu</a>, 
<a href="/search/cs?searchtype=author&query=Campbell%2C+D">Dylan Campbell</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+J">Jaskirat Singh</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianyu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 17 figures, 1 table, accepted to Frontiers in Computer Science, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item810">[810]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02928" title="Abstract">arXiv:2307.02928</a> (replaced) [<a href="/pdf/2307.02928" title="Download PDF">pdf</a>, <a href="/format/2307.02928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AllSight: A Low-Cost and High-Resolution Round Tactile Sensor with  Zero-Shot Learning Capability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azulay%2C+O">Osher Azulay</a>, 
<a href="/search/cs?searchtype=author&query=Curtis%2C+N">Nimrod Curtis</a>, 
<a href="/search/cs?searchtype=author&query=Sokolovsky%2C+R">Rotem Sokolovsky</a>, 
<a href="/search/cs?searchtype=author&query=Levitski%2C+G">Guy Levitski</a>, 
<a href="/search/cs?searchtype=author&query=Slomovik%2C+D">Daniel Slomovik</a>, 
<a href="/search/cs?searchtype=author&query=Lilling%2C+G">Guy Lilling</a>, 
<a href="/search/cs?searchtype=author&query=Sintov%2C+A">Avishai Sintov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item811">[811]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03025" title="Abstract">arXiv:2307.03025</a> (replaced) [<a href="/pdf/2307.03025" title="Download PDF">pdf</a>, <a href="/format/2307.03025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Style Over Substance: Evaluation Biases for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Minghao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Aji%2C+A+F">Alham Fikri Aji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress, 15 pages, 5 tables, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item812">[812]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04349" title="Abstract">arXiv:2307.04349</a> (replaced) [<a href="/pdf/2307.04349" title="Download PDF">pdf</a>, <a href="/format/2307.04349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RLTF: Reinforcement Learning from Unit Test Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiate Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yiqin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+K">Kaiwen Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Q">Qiang Fu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiao Han</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+D">Deheng Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by TMLR
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item813">[813]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06440" title="Abstract">arXiv:2307.06440</a> (replaced) [<a href="/pdf/2307.06440" title="Download PDF">pdf</a>, <a href="/format/2307.06440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> No Train No Gain: Revisiting Efficient Training Algorithms For  Transformer-based Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaddour%2C+J">Jean Kaddour</a>, 
<a href="/search/cs?searchtype=author&query=Key%2C+O">Oscar Key</a>, 
<a href="/search/cs?searchtype=author&query=Nawrot%2C+P">Piotr Nawrot</a>, 
<a href="/search/cs?searchtype=author&query=Minervini%2C+P">Pasquale Minervini</a>, 
<a href="/search/cs?searchtype=author&query=Kusner%2C+M+J">Matt J. Kusner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Neural and Evolutionary Computing (cs.NE); Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item814">[814]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07735" title="Abstract">arXiv:2307.07735</a> (replaced) [<a href="/pdf/2307.07735" title="Download PDF">pdf</a>, <a href="/ps/2307.07735" title="Download PostScript">ps</a>, <a href="/format/2307.07735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster Algorithms for Structured Linear and Kernel Support Vector  Machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gu%2C+Y">Yuzhou Gu</a>, 
<a href="/search/math?searchtype=author&query=Song%2C+Z">Zhao Song</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+L">Lichen Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> New results: almost-linear time algorithm for Gaussian kernel SVM and complementary lower bounds. Abstract shortened to meet arxiv requirement
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item815">[815]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08286" title="Abstract">arXiv:2307.08286</a> (replaced) [<a href="/pdf/2307.08286" title="Download PDF">pdf</a>, <a href="/format/2307.08286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Going Beyond Linear Mode Connectivity: The Layerwise Linear Feature  Connectivity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhanpeng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yongyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaojiang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wei Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 23 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Thirty-seventh Conference on Neural Information Processing Systems
  (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item816">[816]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08570" title="Abstract">arXiv:2307.08570</a> (replaced) [<a href="/pdf/2307.08570" title="Download PDF">pdf</a>, <a href="/format/2307.08570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SkiVis: Visual Exploration and Route Planning in Ski Resorts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rauscher%2C+J">Julius Rauscher</a>, 
<a href="/search/cs?searchtype=author&query=Buchm%C3%BCller%2C+R">Raphael Buchm&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Keim%2C+D+A">Daniel A. Keim</a>, 
<a href="/search/cs?searchtype=author&query=Miller%2C+M">Matthias Miller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item817">[817]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10317" title="Abstract">arXiv:2307.10317</a> (replaced) [<a href="/pdf/2307.10317" title="Download PDF">pdf</a>, <a href="/format/2307.10317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedBug: A Bottom-Up Gradual Unfreezing Framework for Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kao%2C+C">Chia-Hsiang Kao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y+F">Yu-Chiang Frank Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item818">[818]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10455" title="Abstract">arXiv:2307.10455</a> (replaced) [<a href="/pdf/2307.10455" title="Download PDF">pdf</a>, <a href="/format/2307.10455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Step Towards Worldwide Biodiversity Assessment: The BIOSCAN-1M Insect  Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gharaee%2C+Z">Zahra Gharaee</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Z">ZeMing Gong</a>, 
<a href="/search/cs?searchtype=author&query=Pellegrino%2C+N">Nicholas Pellegrino</a>, 
<a href="/search/cs?searchtype=author&query=Zarubiieva%2C+I">Iuliia Zarubiieva</a>, 
<a href="/search/cs?searchtype=author&query=Haurum%2C+J+B">Joakim Bruslund Haurum</a>, 
<a href="/search/cs?searchtype=author&query=Lowe%2C+S+C">Scott C. Lowe</a>, 
<a href="/search/cs?searchtype=author&query=McKeown%2C+J+T+A">Jaclyn T.A. McKeown</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+C+C+Y">Chris C.Y. Ho</a>, 
<a href="/search/cs?searchtype=author&query=McLeod%2C+J">Joschka McLeod</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y+C">Yi-Yun C Wei</a>, 
<a href="/search/cs?searchtype=author&query=Agda%2C+J">Jireh Agda</a>, 
<a href="/search/cs?searchtype=author&query=Ratnasingham%2C+S">Sujeevan Ratnasingham</a>, 
<a href="/search/cs?searchtype=author&query=Steinke%2C+D">Dirk Steinke</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+A+X">Angel X. Chang</a>, 
<a href="/search/cs?searchtype=author&query=Taylor%2C+G+W">Graham W. Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Fieguth%2C+P">Paul Fieguth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item819">[819]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10499" title="Abstract">arXiv:2307.10499</a> (replaced) [<a href="/e-print/2307.10499" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mining Conditional Part Semantics with Occluded Extrapolation for  Human-Object Interaction Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guangzhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yangyang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Kankanhalli%2C+M">Mohan Kankanhalli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under huge modification
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item820">[820]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10684" title="Abstract">arXiv:2307.10684</a> (replaced) [<a href="/pdf/2307.10684" title="Download PDF">pdf</a>, <a href="/format/2307.10684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A second order directional split exponential integrator for systems of  advection--diffusion--reaction equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Caliari%2C+M">Marco Caliari</a>, 
<a href="/search/math?searchtype=author&query=Cassini%2C+F">Fabio Cassini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item821">[821]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10981" title="Abstract">arXiv:2307.10981</a> (replaced) [<a href="/pdf/2307.10981" title="Download PDF">pdf</a>, <a href="/format/2307.10981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PATROL: Privacy-Oriented Pruning for Collaborative Inference Against  Model Inversion Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+S">Shiwei Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+M">Miao Pan</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xiaoyong Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item822">[822]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11254" title="Abstract">arXiv:2307.11254</a> (replaced) [<a href="/pdf/2307.11254" title="Download PDF">pdf</a>, <a href="/ps/2307.11254" title="Download PostScript">ps</a>, <a href="/format/2307.11254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An In-Depth Evaluation of Federated Learning on Biomedical Natural  Language Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+L">Le Peng</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+G">Gaoxiang Luo</a>, 
<a href="/search/cs?searchtype=author&query=zhou%2C+s">sicheng zhou</a>, 
<a href="/search/cs?searchtype=author&query=chen%2C+j">jiandong chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Ziyue Xu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Ju Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by KDD 2023 Workshop FL4Data-Mining
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item823">[823]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11772" title="Abstract">arXiv:2307.11772</a> (replaced) [<a href="/pdf/2307.11772" title="Download PDF">pdf</a>, <a href="/format/2307.11772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoAlign: Fully Automatic and Effective Knowledge Graph Alignment  enabled by Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yixin Su</a>, 
<a href="/search/cs?searchtype=author&query=Trisedya%2C+B+D">Bayu Distiawan Trisedya</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiaoyan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Min Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hong Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+J">Jianzhong Qi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 figures, 4 tables, IEEE Transactions on Knowledge and Data Engineering
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item824">[824]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12166" title="Abstract">arXiv:2307.12166</a> (replaced) [<a href="/pdf/2307.12166" title="Download PDF">pdf</a>, <a href="/ps/2307.12166" title="Download PostScript">ps</a>, <a href="/format/2307.12166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Imitation Game: Detecting Human and AI-Generated Texts in the Era of  ChatGPT and BARD
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hayawi%2C+K">Kadhim Hayawi</a>, 
<a href="/search/cs?searchtype=author&query=Shahriar%2C+S">Sakib Shahriar</a>, 
<a href="/search/cs?searchtype=author&query=Mathew%2C+S+S">Sujith Samuel Mathew</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item825">[825]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12306" title="Abstract">arXiv:2307.12306</a> (replaced) [<a href="/pdf/2307.12306" title="Download PDF">pdf</a>, <a href="/format/2307.12306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tackling the Curse of Dimensionality with Physics-Informed Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zheyuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Shukla%2C+K">Khemraj Shukla</a>, 
<a href="/search/cs?searchtype=author&query=Karniadakis%2C+G+E">George Em Karniadakis</a>, 
<a href="/search/cs?searchtype=author&query=Kawaguchi%2C+K">Kenji Kawaguchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Dynamical Systems (math.DS); Numerical Analysis (math.NA); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item826">[826]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12847" title="Abstract">arXiv:2307.12847</a> (replaced) [<a href="/pdf/2307.12847" title="Download PDF">pdf</a>, <a href="/format/2307.12847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Securing Bystander Privacy in Mixed Reality While Protecting the User  Experience
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Corbett%2C+M">Matthew Corbett</a>, 
<a href="/search/cs?searchtype=author&query=David-John%2C+B">Brendan David-John</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+J">Jiacheng Shang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y+C">Y. Charlie Hu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+B">Bo Ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 1 Figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item827">[827]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12897" title="Abstract">arXiv:2307.12897</a> (replaced) [<a href="/pdf/2307.12897" title="Download PDF">pdf</a>, <a href="/format/2307.12897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anytime Model Selection in Linear Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Kassraie%2C+P">Parnian Kassraie</a>, 
<a href="/search/stat?searchtype=author&query=Emmenegger%2C+N">Nicolas Emmenegger</a>, 
<a href="/search/stat?searchtype=author&query=Krause%2C+A">Andreas Krause</a>, 
<a href="/search/stat?searchtype=author&query=Pacchiano%2C+A">Aldo Pacchiano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023, 37 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item828">[828]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13137" title="Abstract">arXiv:2307.13137</a> (replaced) [<a href="/pdf/2307.13137" title="Download PDF">pdf</a>, <a href="/format/2307.13137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying Women&#x27;s Marginalisation in Ibero-American Film Culture  During the First Half of the Twentieth Century: A Network-Science Proposal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Clariana-Rodagut%2C+A">Ainamar Clariana-Rodagut</a>, 
<a href="/search/physics?searchtype=author&query=Cardillo%2C+A">Alessio Cardillo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 3 figures. Updated version (submitted for publication)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Digital Libraries (cs.DL)

</div>
</div>
</dd>
<dt><a name="item829">[829]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14949" title="Abstract">arXiv:2307.14949</a> (replaced) [<a href="/pdf/2307.14949" title="Download PDF">pdf</a>, <a href="/format/2307.14949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Analysis of Displacement Processes in Porous Media using  Spatio-Temporal Flow Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Straub%2C+A">Alexander Straub</a>, 
<a href="/search/cs?searchtype=author&query=Karadimitriou%2C+N">Nikolaos Karadimitriou</a>, 
<a href="/search/cs?searchtype=author&query=Reina%2C+G">Guido Reina</a>, 
<a href="/search/cs?searchtype=author&query=Frey%2C+S">Steffen Frey</a>, 
<a href="/search/cs?searchtype=author&query=Steeb%2C+H">Holger Steeb</a>, 
<a href="/search/cs?searchtype=author&query=Ertl%2C+T">Thomas Ertl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Fluid Dynamics (physics.flu-dyn)

</div>
</div>
</dd>
<dt><a name="item830">[830]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15202" title="Abstract">arXiv:2307.15202</a> (replaced) [<a href="/pdf/2307.15202" title="Download PDF">pdf</a>, <a href="/format/2307.15202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Robot Multi-Room Exploration with Geometric Cue Extraction and  Circular Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seungchan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Corah%2C+M">Micah Corah</a>, 
<a href="/search/cs?searchtype=author&query=Keller%2C+J">John Keller</a>, 
<a href="/search/cs?searchtype=author&query=Best%2C+G">Graeme Best</a>, 
<a href="/search/cs?searchtype=author&query=Scherer%2C+S">Sebastian Scherer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item831">[831]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15269" title="Abstract">arXiv:2307.15269</a> (replaced) [<a href="/pdf/2307.15269" title="Download PDF">pdf</a>, <a href="/format/2307.15269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reducing Latency of DAG-based Consensus in the Asynchronous Setting via  the UTXO Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Keyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jourenko%2C+M">Maxim Jourenko</a>, 
<a href="/search/cs?searchtype=author&query=Larangeira%2C+M">Mario Larangeira</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ISPA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item832">[832]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15691" title="Abstract">arXiv:2307.15691</a> (replaced) [<a href="/pdf/2307.15691" title="Download PDF">pdf</a>, <a href="/format/2307.15691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ODTlearn: A Package for Learning Optimal Decision Trees for Prediction  and Prescription
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Vossler%2C+P">Patrick Vossler</a>, 
<a href="/search/stat?searchtype=author&query=Aghaei%2C+S">Sina Aghaei</a>, 
<a href="/search/stat?searchtype=author&query=Justin%2C+N">Nathan Justin</a>, 
<a href="/search/stat?searchtype=author&query=Jo%2C+N">Nathanael Jo</a>, 
<a href="/search/stat?searchtype=author&query=G%C3%B3mez%2C+A">Andr&#xe9;s G&#xf3;mez</a>, 
<a href="/search/stat?searchtype=author&query=Vayanos%2C+P">Phebe Vayanos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item833">[833]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16532" title="Abstract">arXiv:2307.16532</a> (replaced) [<a href="/pdf/2307.16532" title="Download PDF">pdf</a>, <a href="/format/2307.16532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Echoes Beyond Points: Unleashing the Power of Raw Radar Data in  Multi-modality Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Feng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Naiyan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoxiang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item834">[834]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16833" title="Abstract">arXiv:2307.16833</a> (replaced) [<a href="/pdf/2307.16833" title="Download PDF">pdf</a>, <a href="/format/2307.16833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Augmentation for Neural Machine Translation using Generative  Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oh%2C+S">Seokjin Oh</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S+A">Su Ah Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+W">Woohwan Jung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item835">[835]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01412" title="Abstract">arXiv:2308.01412</a> (replaced) [<a href="/pdf/2308.01412" title="Download PDF">pdf</a>, <a href="/format/2308.01412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Achieving state-of-the-art performance in the Medical  Out-of-Distribution (MOOD) challenge using plausible synthetic anomalies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marimont%2C+S+N">Sergio Naval Marimont</a>, 
<a href="/search/cs?searchtype=author&query=Tarroni%2C+G">Giacomo Tarroni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item836">[836]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01436" title="Abstract">arXiv:2308.01436</a> (replaced) [<a href="/pdf/2308.01436" title="Download PDF">pdf</a>, <a href="/format/2308.01436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Price-Aware Deep Learning for Electricity Markets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dvorkin%2C+V">Vladimir Dvorkin</a>, 
<a href="/search/cs?searchtype=author&query=Fioretto%2C+F">Ferdinando Fioretto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item837">[837]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01671" title="Abstract">arXiv:2308.01671</a> (replaced) [<a href="/pdf/2308.01671" title="Download PDF">pdf</a>, <a href="/format/2308.01671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconstruction of graph colourings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Demidovich%2C+Y">Yury Demidovich</a>, 
<a href="/search/math?searchtype=author&query=Panichkin%2C+Y">Yaroslav Panichkin</a>, 
<a href="/search/math?searchtype=author&query=Zhukovskii%2C+M">Maksim Zhukovskii</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item838">[838]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02896" title="Abstract">arXiv:2308.02896</a> (replaced) [<a href="/pdf/2308.02896" title="Download PDF">pdf</a>, <a href="/format/2308.02896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Fast, Adaptive, and Hardware-Assisted User-Space Scheduling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lisa">Lisa</a> (Yueying)Li, 
<a href="/search/cs?searchtype=author&query=Lazarev%2C+N">Nikita Lazarev</a>, 
<a href="/search/cs?searchtype=author&query=Koufaty%2C+D">David Koufaty</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yijun Yin</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+A">Andy Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiru Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Suh%2C+E">Edward Suh</a>, 
<a href="/search/cs?searchtype=author&query=Kaffes%2C+K">Kostis Kaffes</a>, 
<a href="/search/cs?searchtype=author&query=Delimitrou%2C+C">Christina Delimitrou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by HPCA2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Hardware Architecture (cs.AR); Networking and Internet Architecture (cs.NI); Operating Systems (cs.OS)

</div>
</div>
</dd>
<dt><a name="item839">[839]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03543" title="Abstract">arXiv:2308.03543</a> (replaced) [<a href="/pdf/2308.03543" title="Download PDF">pdf</a>, <a href="/format/2308.03543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Slepian spatiospectral concentration problem on the $d$-dimensional ball  for different notions of bandwidth
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gerhards%2C+C">Christian Gerhards</a>, 
<a href="/search/math?searchtype=author&query=Huang%2C+X">Xinpeng Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Functional Analysis (math.FA)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item840">[840]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03940" title="Abstract">arXiv:2308.03940</a> (replaced) [<a href="/pdf/2308.03940" title="Download PDF">pdf</a>, <a href="/ps/2308.03940" title="Download PostScript">ps</a>, <a href="/format/2308.03940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simulating the Software Development Lifecycle: The Waterfall Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saravanos%2C+A">Antonios Saravanos</a> (1), 
<a href="/search/cs?searchtype=author&query=Curinga%2C+M+X">Matthew X. Curinga</a> (2) ((1) New York University, (2) MIXI Institute for STEM and the Imagination, Adelphi University)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item841">[841]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05345" title="Abstract">arXiv:2308.05345</a> (replaced) [<a href="/pdf/2308.05345" title="Download PDF">pdf</a>, <a href="/format/2308.05345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RTLLM: An Open-Source Benchmark for Design RTL Generation with Large  Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qijun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhiyao Xie</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Asia and South Pacific Design Automation Conference (ASP-DAC) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Hardware Architecture (cs.AR)

</div>
</div>
</dd>
<dt><a name="item842">[842]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06744" title="Abstract">arXiv:2308.06744</a> (replaced) [<a href="/pdf/2308.06744" title="Download PDF">pdf</a>, <a href="/format/2308.06744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Token-Scaled Logit Distillation for Ternary Weight Generative Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minsoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sihwa Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Janghwan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+S">Sukjin Hong</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+D">Du-Seong Chang</a>, 
<a href="/search/cs?searchtype=author&query=Sung%2C+W">Wonyong Sung</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jungwook Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Camera Ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item843">[843]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07336" title="Abstract">arXiv:2308.07336</a> (replaced) [<a href="/pdf/2308.07336" title="Download PDF">pdf</a>, <a href="/format/2308.07336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morishita%2C+T">Terufumi Morishita</a>, 
<a href="/search/cs?searchtype=author&query=Morio%2C+G">Gaku Morio</a>, 
<a href="/search/cs?searchtype=author&query=Yamaguchi%2C+A">Atsuki Yamaguchi</a>, 
<a href="/search/cs?searchtype=author&query=Sogawa%2C+Y">Yasuhiro Sogawa</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 40th International Conference on Machine
  Learning, PMLR 202:25254-25274, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item844">[844]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08104" title="Abstract">arXiv:2308.08104</a> (replaced) [<a href="/pdf/2308.08104" title="Download PDF">pdf</a>, <a href="/format/2308.08104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConservationBots: Autonomous Aerial Robot for Fast Robust Wildlife  Tracking in Complex Terrains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Fei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Van+Nguyen%2C+H">Hoa Van Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Taggart%2C+D+A">David A. Taggart</a>, 
<a href="/search/cs?searchtype=author&query=Falkner%2C+K">Katrina Falkner</a>, 
<a href="/search/cs?searchtype=author&query=Rezatofighi%2C+S+H">S. Hamid Rezatofighi</a>, 
<a href="/search/cs?searchtype=author&query=Ranasinghe%2C+D+C">Damith C. Ranasinghe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to The Journal of Field Robotics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item845">[845]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09289" title="Abstract">arXiv:2308.09289</a> (replaced) [<a href="/pdf/2308.09289" title="Download PDF">pdf</a>, <a href="/format/2308.09289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preference-conditioned Pixel-based AI Agent For Game Testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdelfattah%2C+S">Sherif Abdelfattah</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+A">Adrian Brown</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pushi Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the IEEE Conference on Games (CoG) 2023, Boston, MA, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item846">[846]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09561" title="Abstract">arXiv:2308.09561</a> (replaced) [<a href="/pdf/2308.09561" title="Download PDF">pdf</a>, <a href="/format/2308.09561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ShockHash: Towards Optimal-Space Minimal Perfect Hashing Beyond  Brute-Force
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lehmann%2C+H">Hans-Peter Lehmann</a>, 
<a href="/search/cs?searchtype=author&query=Sanders%2C+P">Peter Sanders</a>, 
<a href="/search/cs?searchtype=author&query=Walzer%2C+S">Stefan Walzer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item847">[847]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10248" title="Abstract">arXiv:2308.10248</a> (replaced) [<a href="/pdf/2308.10248" title="Download PDF">pdf</a>, <a href="/format/2308.10248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Activation Addition: Steering Language Models Without Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Turner%2C+A+M">Alexander Matt Turner</a>, 
<a href="/search/cs?searchtype=author&query=Thiergart%2C+L">Lisa Thiergart</a>, 
<a href="/search/cs?searchtype=author&query=Udell%2C+D">David Udell</a>, 
<a href="/search/cs?searchtype=author&query=Leech%2C+G">Gavin Leech</a>, 
<a href="/search/cs?searchtype=author&query=Mini%2C+U">Ulisse Mini</a>, 
<a href="/search/cs?searchtype=author&query=MacDiarmid%2C+M">Monte MacDiarmid</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item848">[848]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10407" title="Abstract">arXiv:2308.10407</a> (replaced) [<a href="/pdf/2308.10407" title="Download PDF">pdf</a>, <a href="/format/2308.10407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning for Connected and Automated Vehicles: A Survey of  Existing Approaches and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chellapandi%2C+V+P">Vishnu Pandi Chellapandi</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Liangqi Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Brinton%2C+C+G">Christopher G. Brinton</a>, 
<a href="/search/cs?searchtype=author&query=Zak%2C+S+H">Stanislaw H Zak</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziran Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Transactions on Intelligent Vehicles
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item849">[849]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11630" title="Abstract">arXiv:2308.11630</a> (replaced) [<a href="/pdf/2308.11630" title="Download PDF">pdf</a>, <a href="/format/2308.11630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Addressing Data Scarcity in Optical Matrix Multiplier Modeling Using  Transfer Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cem%2C+A">Ali Cem</a>, 
<a href="/search/cs?searchtype=author&query=Jovanovic%2C+O">Ognjen Jovanovic</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Siqi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yunhong Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zibar%2C+D">Darko Zibar</a>, 
<a href="/search/cs?searchtype=author&query=Da+Ros%2C+F">Francesco Da Ros</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optics (physics.optics)

</div>
</div>
</dd>
<dt><a name="item850">[850]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11821" title="Abstract">arXiv:2308.11821</a> (replaced) [<a href="/pdf/2308.11821" title="Download PDF">pdf</a>, <a href="/format/2308.11821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-temporal decomposition for elastoplastic ratcheting solids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ulloa%2C+J">Jacinto Ulloa</a>, 
<a href="/search/math?searchtype=author&query=Degrande%2C+G">Geert Degrande</a>, 
<a href="/search/math?searchtype=author&query=Andrade%2C+J+E">Jos&#xe9; E. Andrade</a>, 
<a href="/search/math?searchtype=author&query=Fran%C3%A7ois%2C+S">Stijn Fran&#xe7;ois</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Version accepted for publication in Computer Methods in Applied Mechanics and Engineering
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Materials Science (cond-mat.mtrl-sci)

</div>
</div>
</dd>
<dt><a name="item851">[851]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12469" title="Abstract">arXiv:2308.12469</a> (replaced) [<a href="/pdf/2308.12469" title="Download PDF">pdf</a>, <a href="/format/2308.12469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffuse, Attend, and Segment: Unsupervised Zero-Shot Segmentation using  Stable Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Junjiao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+L">Lavisha Aggarwal</a>, 
<a href="/search/cs?searchtype=author&query=Colaco%2C+A">Andrea Colaco</a>, 
<a href="/search/cs?searchtype=author&query=Kira%2C+Z">Zsolt Kira</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez-Franco%2C+M">Mar Gonzalez-Franco</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item852">[852]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13488" title="Abstract">arXiv:2308.13488</a> (replaced) [<a href="/pdf/2308.13488" title="Download PDF">pdf</a>, <a href="/format/2308.13488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal Uncertainty Localization to Enable Human-in-the-loop Analysis  of Dynamic Contrast-enhanced Cardiac MRI Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yalcinkaya%2C+D+M">Dilek M. Yalcinkaya</a>, 
<a href="/search/eess?searchtype=author&query=Youssef%2C+K">Khalid Youssef</a>, 
<a href="/search/eess?searchtype=author&query=Heydari%2C+B">Bobak Heydari</a>, 
<a href="/search/eess?searchtype=author&query=Simonetti%2C+O">Orlando Simonetti</a>, 
<a href="/search/eess?searchtype=author&query=Dharmakumar%2C+R">Rohan Dharmakumar</a>, 
<a href="/search/eess?searchtype=author&query=Raman%2C+S">Subha Raman</a>, 
<a href="/search/eess?searchtype=author&query=Sharif%2C+B">Behzad Sharif</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in MICCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Medical Physics (physics.med-ph)

</div>
</div>
</dd>
<dt><a name="item853">[853]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14189" title="Abstract">arXiv:2308.14189</a> (replaced) [<a href="/pdf/2308.14189" title="Download PDF">pdf</a>, <a href="/format/2308.14189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topology and dynamics of higher-order multiplex networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/nlin?searchtype=author&query=Krishnagopal%2C+S">Sanjukta Krishnagopal</a>, 
<a href="/search/nlin?searchtype=author&query=Bianconi%2C+G">Ginestra Bianconi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> (35 pages, 8 figures)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Adaptation and Self-Organizing Systems (nlin.AO)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Social and Information Networks (cs.SI); Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item854">[854]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14522" title="Abstract">arXiv:2308.14522</a> (replaced) [<a href="/pdf/2308.14522" title="Download PDF">pdf</a>, <a href="/format/2308.14522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Meets LLMs: Towards Large Graph Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zeyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yijian Qin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenwu Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023 New Frontiers in Graph Learning Workshop. Comments are welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item855">[855]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14714" title="Abstract">arXiv:2308.14714</a> (replaced) [<a href="/pdf/2308.14714" title="Download PDF">pdf</a>, <a href="/format/2308.14714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Stochastic Surveillance Stackelberg Game: Co-Optimizing Defense  Placement and Patrol Strategy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=John%2C+Y">Yohan John</a>, 
<a href="/search/eess?searchtype=author&query=Diaz-Garcia%2C+G">Gilberto Diaz-Garcia</a>, 
<a href="/search/eess?searchtype=author&query=Duan%2C+X">Xiaoming Duan</a>, 
<a href="/search/eess?searchtype=author&query=Marden%2C+J+R">Jason R. Marden</a>, 
<a href="/search/eess?searchtype=author&query=Bullo%2C+F">Francesco Bullo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 1 figure, jointly submitted to the IEEE Control Systems Letters and the 2024 American Control Conference. Replaced in response to reviewer feedback
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Computer Science and Game Theory (cs.GT); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item856">[856]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15991" title="Abstract">arXiv:2308.15991</a> (replaced) [<a href="/pdf/2308.15991" title="Download PDF">pdf</a>, <a href="/format/2308.15991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DRL-Based Trajectory Tracking for Motion-Related Modules in Autonomous  Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yinda Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lidong Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item857">[857]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00312" title="Abstract">arXiv:2309.00312</a> (replaced) [<a href="/pdf/2309.00312" title="Download PDF">pdf</a>, <a href="/ps/2309.00312" title="Download PostScript">ps</a>, <a href="/format/2309.00312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Insights Into the Nutritional Prevention of Macular Degeneration based  on a Comparative Topic Modeling Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jacaruso%2C+L+C">Lucas Cassiel Jacaruso</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item858">[858]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03179" title="Abstract">arXiv:2309.03179</a> (replaced) [<a href="/pdf/2309.03179" title="Download PDF">pdf</a>, <a href="/format/2309.03179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SLiMe: Segment Like Me
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khani%2C+A">Aliasghar Khani</a>, 
<a href="/search/cs?searchtype=author&query=Taghanaki%2C+S+A">Saeid Asgari Taghanaki</a>, 
<a href="/search/cs?searchtype=author&query=Sanghi%2C+A">Aditya Sanghi</a>, 
<a href="/search/cs?searchtype=author&query=Amiri%2C+A+M">Ali Mahdavi Amiri</a>, 
<a href="/search/cs?searchtype=author&query=Hamarneh%2C+G">Ghassan Hamarneh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item859">[859]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03493" title="Abstract">arXiv:2309.03493</a> (replaced) [<a href="/pdf/2309.03493" title="Download PDF">pdf</a>, <a href="/format/2309.03493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAM3D: Segment Anything Model in Volumetric Medical Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bui%2C+N">Nhat-Tan Bui</a>, 
<a href="/search/eess?searchtype=author&query=Hoang%2C+D">Dinh-Hieu Hoang</a>, 
<a href="/search/eess?searchtype=author&query=Tran%2C+M">Minh-Triet Tran</a>, 
<a href="/search/eess?searchtype=author&query=Doretto%2C+G">Gianfranco Doretto</a>, 
<a href="/search/eess?searchtype=author&query=Adjeroh%2C+D">Donald Adjeroh</a>, 
<a href="/search/eess?searchtype=author&query=Patel%2C+B">Brijesh Patel</a>, 
<a href="/search/eess?searchtype=author&query=Choudhary%2C+A">Arabinda Choudhary</a>, 
<a href="/search/eess?searchtype=author&query=Le%2C+N">Ngan Le</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item860">[860]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06865" title="Abstract">arXiv:2309.06865</a> (replaced) [<a href="/pdf/2309.06865" title="Download PDF">pdf</a>, <a href="/format/2309.06865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Short reasons for long vectors in HPC CPUs: a study based on RISC-V
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vizcaino%2C+P">Pablo Vizcaino</a>, 
<a href="/search/cs?searchtype=author&query=Ieronymakis%2C+G">Georgios Ieronymakis</a>, 
<a href="/search/cs?searchtype=author&query=Dimou%2C+N">Nikolaos Dimou</a>, 
<a href="/search/cs?searchtype=author&query=Papaefstathiou%2C+V">Vassilis Papaefstathiou</a>, 
<a href="/search/cs?searchtype=author&query=Labarta%2C+J">Jesus Labarta</a>, 
<a href="/search/cs?searchtype=author&query=Mantovani%2C+F">Filippo Mantovani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SC-W 2023: Workshops of The International Conference on High Performance Computing, Network, Storage, and Analysis Denver CO USA November 12 - 17, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Hardware Architecture (cs.AR)

</div>
</div>
</dd>
<dt><a name="item861">[861]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08534" title="Abstract">arXiv:2309.08534</a> (replaced) [<a href="/pdf/2309.08534" title="Download PDF">pdf</a>, <a href="/format/2309.08534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Last-layer Retraining for Group Robustness with Fewer  Annotations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=LaBonte%2C+T">Tyler LaBonte</a>, 
<a href="/search/cs?searchtype=author&query=Muthukumar%2C+V">Vidya Muthukumar</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Abhishek Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item862">[862]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09660" title="Abstract">arXiv:2309.09660</a> (replaced) [<a href="/pdf/2309.09660" title="Download PDF">pdf</a>, <a href="/ps/2309.09660" title="Download PostScript">ps</a>, <a href="/format/2309.09660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A family of stabilizer-free virtual elements on triangular meshes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Xu%2C+X">Xuejun Xu</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+S">Shangyou Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item863">[863]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10736" title="Abstract">arXiv:2309.10736</a> (replaced) [<a href="/pdf/2309.10736" title="Download PDF">pdf</a>, <a href="/format/2309.10736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixture Weight Estimation and Model Prediction in Multi-source  Multi-target Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yuyang Deng</a>, 
<a href="/search/cs?searchtype=author&query=Kuzborskij%2C+I">Ilja Kuzborskij</a>, 
<a href="/search/cs?searchtype=author&query=Mahdavi%2C+M">Mehrdad Mahdavi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item864">[864]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10987" title="Abstract">arXiv:2309.10987</a> (replaced) [<a href="/pdf/2309.10987" title="Download PDF">pdf</a>, <a href="/format/2309.10987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpikingNeRF: Making Bio-inspired Neural Networks See through the Real  World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+X">Xingting Yao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qinghao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tielong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Mo%2C+Z">Zitao Mo</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zeyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhuge%2C+Z">Zhengyang Zhuge</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jian Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item865">[865]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11373" title="Abstract">arXiv:2309.11373</a> (replaced) [<a href="/pdf/2309.11373" title="Download PDF">pdf</a>, <a href="/ps/2309.11373" title="Download PostScript">ps</a>, <a href="/format/2309.11373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning and DiSentangling Patient Static Information from Time-series  Electronic HEalth Record (STEER)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+W">Wei Liao</a>, 
<a href="/search/cs?searchtype=author&query=Voldman%2C+J">Joel Voldman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item866">[866]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13690" title="Abstract">arXiv:2309.13690</a> (replaced) [<a href="/pdf/2309.13690" title="Download PDF">pdf</a>, <a href="/format/2309.13690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable data concentrator with baseline interconnection network for  triggerless data acquisition systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zabo%C5%82otny%2C+W+M">Wojciech M. Zabo&#x142;otny</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
</div>
</dd>
<dt><a name="item867">[867]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14303" title="Abstract">arXiv:2309.14303</a> (replaced) [<a href="/pdf/2309.14303" title="Download PDF">pdf</a>, <a href="/format/2309.14303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dataset Diffusion: Diffusion-based Synthetic Dataset Generation for  Pixel-Level Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q">Quang Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+T">Truong Vu</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+A">Anh Tran</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+K">Khoi Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023. Our project page: <a href="https://dataset-diffusion.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item868">[868]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16521" title="Abstract">arXiv:2309.16521</a> (replaced) [<a href="/pdf/2309.16521" title="Download PDF">pdf</a>, <a href="/format/2309.16521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Personalized Insulin Treatments Strategies with Deep  Conditional Generative Time Series Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Sch%C3%BCrch%2C+M">Manuel Sch&#xfc;rch</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/stat?searchtype=author&query=Allam%2C+A">Ahmed Allam</a>, 
<a href="/search/stat?searchtype=author&query=Rathmes%2C+G">Giulia Rathmes</a>, 
<a href="/search/stat?searchtype=author&query=Mollaysa%2C+A">Amina Mollaysa</a>, 
<a href="/search/stat?searchtype=author&query=Cavelti-Weder%2C+C">Claudia Cavelti-Weder</a>, 
<a href="/search/stat?searchtype=author&query=Krauthammer%2C+M">Michael Krauthammer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2023, December 10th, 2023, New Orleans, United States, 17 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Machine Learning for Health (ML4H) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item869">[869]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17105" title="Abstract">arXiv:2309.17105</a> (replaced) [<a href="/pdf/2309.17105" title="Download PDF">pdf</a>, <a href="/format/2309.17105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Action Assessment via Task-Consistent Score-Discriminative  Feature Distribution Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuan-Ming Li</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+L">Ling-An Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+J">Jing-Ke Meng</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Wei-Shi Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item870">[870]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00023" title="Abstract">arXiv:2310.00023</a> (replaced) [<a href="/pdf/2310.00023" title="Download PDF">pdf</a>, <a href="/format/2310.00023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> De-SaTE: Denoising Self-attention Transformer Encoders for Li-ion  Battery Health Prognostics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shinde%2C+G">Gaurav Shinde</a>, 
<a href="/search/cs?searchtype=author&query=Mohapatra%2C+R">Rohan Mohapatra</a>, 
<a href="/search/cs?searchtype=author&query=Krishan%2C+P">Pooja Krishan</a>, 
<a href="/search/cs?searchtype=author&query=Sengupta%2C+S">Saptarshi Sengupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item871">[871]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00057" title="Abstract">arXiv:2310.00057</a> (replaced) [<a href="/pdf/2310.00057" title="Download PDF">pdf</a>, <a href="/format/2310.00057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A multi-fidelity deep operator network (DeepONet) for fusing simulation  and monitoring data: Application to real-time settlement prediction during  tunnel construction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+B+T">Ba Trung Cao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yong Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Meschke%2C+G">G&#xfc;nther Meschke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item872">[872]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00723" title="Abstract">arXiv:2310.00723</a> (replaced) [<a href="/pdf/2310.00723" title="Download PDF">pdf</a>, <a href="/format/2310.00723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HOH: Markerless Multimodal Human-Object-Human Handover Dataset with  Large Object Count
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wiederhold%2C+N">Noah Wiederhold</a>, 
<a href="/search/cs?searchtype=author&query=Megyeri%2C+A">Ava Megyeri</a>, 
<a href="/search/cs?searchtype=author&query=Paris%2C+D">DiMaggio Paris</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+S">Sean Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+N+K">Natasha Kholgade Banerjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Datasets and Benchmarks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item873">[873]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00725" title="Abstract">arXiv:2310.00725</a> (replaced) [<a href="/pdf/2310.00725" title="Download PDF">pdf</a>, <a href="/ps/2310.00725" title="Download PostScript">ps</a>, <a href="/format/2310.00725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Averaging Property of Wedge Product and Naturality in Discrete Exterior  Calculus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Schubel%2C+M+D">Mark D. Schubel</a>, 
<a href="/search/math?searchtype=author&query=Berwick-Evans%2C+D">Daniel Berwick-Evans</a>, 
<a href="/search/math?searchtype=author&query=Hirani%2C+A+N">Anil N. Hirani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2104.10277">arXiv:2104.10277</a>. Note from authors in response to arXiv admin note: The material in this submission was split off from <a href="/abs/2104.10277">arXiv:2104.10277</a> and version 2 of <a href="/abs/2104.10277">arXiv:2104.10277</a> does not contain the material in this submission. This revision includes material about cochain product using Whitney forms and connection to C-infinity algebras
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Differential Geometry (math.DG)

</div>
</div>
</dd>
<dt><a name="item874">[874]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01220" title="Abstract">arXiv:2310.01220</a> (replaced) [<a href="/pdf/2310.01220" title="Download PDF">pdf</a>, <a href="/ps/2310.01220" title="Download PostScript">ps</a>, <a href="/format/2310.01220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The benefits and costs of explainable artificial intelligence in visual  quality control: Evidence from fault detection performance and eye movements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+R">Romy M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Reindel%2C+D+F">David F. Reindel</a>, 
<a href="/search/cs?searchtype=author&query=Stadtfeld%2C+Y+D">Yannick D. Stadtfeld</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item875">[875]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02021" title="Abstract">arXiv:2310.02021</a> (replaced) [<a href="/pdf/2310.02021" title="Download PDF">pdf</a>, <a href="/format/2310.02021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessment of the CRD approximation for the observer&#x27;s frame RIII  redistribution matrix
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Riva%2C+S">Simone Riva</a>, 
<a href="/search/astro-ph?searchtype=author&query=Guerreiro%2C+N">Nuno Guerreiro</a>, 
<a href="/search/astro-ph?searchtype=author&query=Janett%2C+G">Gioele Janett</a>, 
<a href="/search/astro-ph?searchtype=author&query=Rossinelli%2C+D">Diego Rossinelli</a>, 
<a href="/search/astro-ph?searchtype=author&query=Benedusi%2C+P">Pietro Benedusi</a>, 
<a href="/search/astro-ph?searchtype=author&query=Krause%2C+R">Rolf Krause</a>, 
<a href="/search/astro-ph?searchtype=author&query=Belluzzi%2C+L">Luca Belluzzi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Solar and Stellar Astrophysics (astro-ph.SR)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
</div>
</dd>
<dt><a name="item876">[876]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03059" title="Abstract">arXiv:2310.03059</a> (replaced) [<a href="/pdf/2310.03059" title="Download PDF">pdf</a>, <a href="/format/2310.03059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Point-PEFT: Parameter-Efficient Fine-Tuning for 3D Pre-trained Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+I">Ivan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ray Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zoey Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages. The specialized PEFT framework for 3D pre-trained models, which achieves competitive performance to full fine-tuning, and significantly reduces the computational resources. Project page: <a href="https://github.com/Even-JK/PEFT-3D">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item877">[877]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03184" title="Abstract">arXiv:2310.03184</a> (replaced) [<a href="/pdf/2310.03184" title="Download PDF">pdf</a>, <a href="/format/2310.03184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrieval-augmented Generation to Improve Math Question-Answering:  Trade-offs Between Groundedness and Human Preference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Levonian%2C+Z">Zachary Levonian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenglu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wangda Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Gade%2C+A">Anoushka Gade</a>, 
<a href="/search/cs?searchtype=author&query=Henkel%2C+O">Owen Henkel</a>, 
<a href="/search/cs?searchtype=author&query=Postle%2C+M">Millie-Ellen Postle</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+W">Wanli Xing</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, presented at NeurIPS'23 Workshop on Generative AI for Education (GAIED)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item878">[878]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03252" title="Abstract">arXiv:2310.03252</a> (replaced) [<a href="/pdf/2310.03252" title="Download PDF">pdf</a>, <a href="/ps/2310.03252" title="Download PostScript">ps</a>, <a href="/format/2310.03252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring age-related patterns in internet access: Insights from a  secondary analysis of New Zealand survey data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pacheco%2C+E">Edgar Pacheco</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item879">[879]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03529" title="Abstract">arXiv:2310.03529</a> (replaced) [<a href="/pdf/2310.03529" title="Download PDF">pdf</a>, <a href="/format/2310.03529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Ridgelet Transform: Voice with Koopman Operator Proves Universality  of Formal Deep Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sonoda%2C+S">Sho Sonoda</a>, 
<a href="/search/cs?searchtype=author&query=Hashimoto%2C+Y">Yuka Hashimoto</a>, 
<a href="/search/cs?searchtype=author&query=Ishikawa%2C+I">Isao Ishikawa</a>, 
<a href="/search/cs?searchtype=author&query=Ikeda%2C+M">Masahiro Ikeda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurReps 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item880">[880]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03530" title="Abstract">arXiv:2310.03530</a> (replaced) [<a href="/pdf/2310.03530" title="Download PDF">pdf</a>, <a href="/format/2310.03530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Group Invariant Functions on Data-Parameter Domain Induce  Universal Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sonoda%2C+S">Sho Sonoda</a>, 
<a href="/search/cs?searchtype=author&query=Ishi%2C+H">Hideyuki Ishi</a>, 
<a href="/search/cs?searchtype=author&query=Ishikawa%2C+I">Isao Ishikawa</a>, 
<a href="/search/cs?searchtype=author&query=Ikeda%2C+M">Masahiro Ikeda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurReps 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item881">[881]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03533" title="Abstract">arXiv:2310.03533</a> (replaced) [<a href="/pdf/2310.03533" title="Download PDF">pdf</a>, <a href="/format/2310.03533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models for Software Engineering: Survey and Open Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+A">Angela Fan</a>, 
<a href="/search/cs?searchtype=author&query=Gokkaya%2C+B">Beliz Gokkaya</a>, 
<a href="/search/cs?searchtype=author&query=Harman%2C+M">Mark Harman</a>, 
<a href="/search/cs?searchtype=author&query=Lyubarskiy%2C+M">Mitya Lyubarskiy</a>, 
<a href="/search/cs?searchtype=author&query=Sengupta%2C+S">Shubho Sengupta</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+S">Shin Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J+M">Jie M. Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item882">[882]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04313" title="Abstract">arXiv:2310.04313</a> (replaced) [<a href="/pdf/2310.04313" title="Download PDF">pdf</a>, <a href="/format/2310.04313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KoMultiText: Large-Scale Korean Text Dataset for Classifying Biased  Speech in Real-World Online Services
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+D">Dasol Choi</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jooyoung Song</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+E">Eunsun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+J">Jinwoo Seo</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+H">Heejune Park</a>, 
<a href="/search/cs?searchtype=author&query=Na%2C+D">Dongbin Na</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the NeurIPS 2023 Workshop on Socially Responsible Language Modelling Research (SoLaR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item883">[883]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04793" title="Abstract">arXiv:2310.04793</a> (replaced) [<a href="/pdf/2310.04793" title="Download PDF">pdf</a>, <a href="/format/2310.04793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FinGPT: Instruction Tuning Benchmark for Open-Source Large Language  Models in Financial Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Neng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hongyang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C+D">Christina Dan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Workshop on Instruction Tuning and Instruction Following at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Trading and Market Microstructure (q-fin.TR)

</div>
</div>
</dd>
<dt><a name="item884">[884]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04816" title="Abstract">arXiv:2310.04816</a> (replaced) [<a href="/pdf/2310.04816" title="Download PDF">pdf</a>, <a href="/format/2310.04816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hacking Generative Models with Differentiable Network Bending
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aldegheri%2C+G">Giacomo Aldegheri</a>, 
<a href="/search/cs?searchtype=author&query=Rogalska%2C+A">Alina Rogalska</a>, 
<a href="/search/cs?searchtype=author&query=Youssef%2C+A">Ahmed Youssef</a>, 
<a href="/search/cs?searchtype=author&query=Iofinova%2C+E">Eugenia Iofinova</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 10 figures, Machine Learning for Creativity and Design Workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item885">[885]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05163" title="Abstract">arXiv:2310.05163</a> (replaced) [<a href="/pdf/2310.05163" title="Download PDF">pdf</a>, <a href="/format/2310.05163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Investigation of LLMs&#x27; Inefficacy in Understanding Converse Relations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+C">Chengwen Qi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bowen Li</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+B">Binyuan Hui</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bailin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jinwang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Laili%2C+Y">Yuanjun Laili</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item886">[886]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05317" title="Abstract">arXiv:2310.05317</a> (replaced) [<a href="/pdf/2310.05317" title="Download PDF">pdf</a>, <a href="/format/2310.05317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task-Adaptive Tokenization: Enhancing Long-Form Text Generation Efficacy  in Mental Health and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Siyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+N">Naihao Deng</a>, 
<a href="/search/cs?searchtype=author&query=Sabour%2C+S">Sahand Sabour</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Y">Yilin Jia</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Minlie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Mihalcea%2C+R">Rada Mihalcea</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the main conference of The 2023 Conference on Empirical Methods in Natural Language Processing; 8 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The 2023 Conference on Empirical Methods in Natural Language
  Processing (EMNLP 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item887">[887]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05375" title="Abstract">arXiv:2310.05375</a> (replaced) [<a href="/pdf/2310.05375" title="Download PDF">pdf</a>, <a href="/format/2310.05375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IPDreamer: Appearance-Controllable 3D Object Generation with Image  Prompts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+B">Bohan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shanglin Li</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yutang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hong Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Sicheng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huaxia Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianzhuang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Baochang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item888">[888]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06403" title="Abstract">arXiv:2310.06403</a> (replaced) [<a href="/pdf/2310.06403" title="Download PDF">pdf</a>, <a href="/format/2310.06403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boundary Discretization and Reliable Classification Network for Temporal  Action Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhenying Fang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, Source code: <a href="https://github.com/zhenyingfang/BDRC-Net">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item889">[889]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06552" title="Abstract">arXiv:2310.06552</a> (replaced) [<a href="/pdf/2310.06552" title="Download PDF">pdf</a>, <a href="/format/2310.06552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated clinical coding using off-the-shelf large language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boyle%2C+J+S">Joseph S. Boyle</a>, 
<a href="/search/cs?searchtype=author&query=Kascenas%2C+A">Antanas Kascenas</a>, 
<a href="/search/cs?searchtype=author&query=Lok%2C+P">Pat Lok</a>, 
<a href="/search/cs?searchtype=author&query=Liakata%2C+M">Maria Liakata</a>, 
<a href="/search/cs?searchtype=author&query=O%27Neil%2C+A+Q">Alison Q. O&#x27;Neil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the NeurIPS 2023 workshop Deep Generative Models For Health (DGM4H). 9 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item890">[890]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07422" title="Abstract">arXiv:2310.07422</a> (replaced) [<a href="/pdf/2310.07422" title="Download PDF">pdf</a>, <a href="/ps/2310.07422" title="Download PostScript">ps</a>, <a href="/format/2310.07422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Improved Composition Theorem of a Universal Relation and Most  Functions via Effective Restriction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hao Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> change to previous version 1.fix typos and improve presentation of the paper 2.change all the letter $\Theta$ for trace to $\Psi$, to avoid confusion due to that the same letter $\Theta$ is used for the notation in asymtotics. 3.add more discussion in Section 5
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
</div>
</dd>
<dt><a name="item891">[891]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07838" title="Abstract">arXiv:2310.07838</a> (replaced) [<a href="/pdf/2310.07838" title="Download PDF">pdf</a>, <a href="/format/2310.07838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards the Fundamental Limits of Knowledge Transfer over Finite Domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qingyue Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Banghua Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages, 2 figures; add discussions on function approximation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item892">[892]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08660" title="Abstract">arXiv:2310.08660</a> (replaced) [<a href="/pdf/2310.08660" title="Download PDF">pdf</a>, <a href="/format/2310.08660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning RL-Policies for Joint Beamforming Without Exploration: A Batch  Constrained Off-Policy Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Heasung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ankireddy%2C+S+K">Sravan Kumar Ankireddy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item893">[893]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09008" title="Abstract">arXiv:2310.09008</a> (replaced) [<a href="/pdf/2310.09008" title="Download PDF">pdf</a>, <a href="/format/2310.09008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Lower Bounds for Reachability in Vector Addition Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Czerwi%C5%84ski%2C+W">Wojciech Czerwi&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Jecker%2C+I">Isma&#xeb;l Jecker</a>, 
<a href="/search/cs?searchtype=author&query=Lasota%2C+S">S&#x142;awomir Lasota</a>, 
<a href="/search/cs?searchtype=author&query=Leroux%2C+J">J&#xe9;r&#xf4;me Leroux</a>, 
<a href="/search/cs?searchtype=author&query=Orlikowski%2C+%C5%81">&#x141;ukasz Orlikowski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item894">[894]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09017" title="Abstract">arXiv:2310.09017</a> (replaced) [<a href="/pdf/2310.09017" title="Download PDF">pdf</a>, <a href="/format/2310.09017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dont Add, dont Miss: Effective Content Preserving Generation from  Pre-Selected Text Spans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Slobodkin%2C+A">Aviv Slobodkin</a>, 
<a href="/search/cs?searchtype=author&query=Caciularu%2C+A">Avi Caciularu</a>, 
<a href="/search/cs?searchtype=author&query=Hirsch%2C+E">Eran Hirsch</a>, 
<a href="/search/cs?searchtype=author&query=Dagan%2C+I">Ido Dagan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023, findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item895">[895]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09624" title="Abstract">arXiv:2310.09624</a> (replaced) [<a href="/pdf/2310.09624" title="Download PDF">pdf</a>, <a href="/format/2310.09624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ASSERT: Automated Safety Scenario Red Teaming for Evaluating the  Robustness of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mei%2C+A">Alex Mei</a>, 
<a href="/search/cs?searchtype=author&query=Levy%2C+S">Sharon Levy</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W+Y">William Yang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Findings of the 2023 Conference on Empirical Methods in Natural Language Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item896">[896]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09889" title="Abstract">arXiv:2310.09889</a> (replaced) [<a href="/pdf/2310.09889" title="Download PDF">pdf</a>, <a href="/format/2310.09889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Capacity Region of Information Theoretic Secure Aggregation with  Uncoded Groupwise Keys
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+K">Kai Wan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hua Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+M">Mingyue Ji</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+T">Tiebin Mi</a>, 
<a href="/search/cs?searchtype=author&query=Caire%2C+G">Giuseppe Caire</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item897">[897]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09933" title="Abstract">arXiv:2310.09933</a> (replaced) [<a href="/pdf/2310.09933" title="Download PDF">pdf</a>, <a href="/format/2310.09933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantitative Stability Conditions for Grid-Forming Converters With  Complex Droop Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=He%2C+X">Xiuqiang He</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+L">Linbin Huang</a>, 
<a href="/search/eess?searchtype=author&query=Suboti%C4%87%2C+I">Irina Suboti&#x107;</a>, 
<a href="/search/eess?searchtype=author&query=H%C3%A4berle%2C+V">Verena H&#xe4;berle</a>, 
<a href="/search/eess?searchtype=author&query=D%C3%B6rfler%2C+F">Florian D&#xf6;rfler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item898">[898]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10072" title="Abstract">arXiv:2310.10072</a> (replaced) [<a href="/pdf/2310.10072" title="Download PDF">pdf</a>, <a href="/format/2310.10072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-tuning ChatGPT for Automatic Scoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Latif%2C+E">Ehsan Latif</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xiaoming Zhai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Computers and Education: Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item899">[899]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10418" title="Abstract">arXiv:2310.10418</a> (replaced) [<a href="/pdf/2310.10418" title="Download PDF">pdf</a>, <a href="/format/2310.10418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reading Books is Great, But Not if You Are Driving! Visually Grounded  Reasoning about Defeasible Commonsense Norms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Seungju Han</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Junhyeok Kim</a>, 
<a href="/search/cs?searchtype=author&query=Hessel%2C+J">Jack Hessel</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Liwei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+J">Jiwan Chung</a>, 
<a href="/search/cs?searchtype=author&query=Son%2C+Y">Yejin Son</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yejin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Youngjae Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a conference paper at EMNLP 2023 (long)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item900">[900]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10705" title="Abstract">arXiv:2310.10705</a> (replaced) [<a href="/pdf/2310.10705" title="Download PDF">pdf</a>, <a href="/ps/2310.10705" title="Download PostScript">ps</a>, <a href="/format/2310.10705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning Classification Techniques for Identifying the Defective  Patterns in Semiconductor Wafer Maps: A Survey, Empirical, and Experimental  Evaluations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taha%2C+K">Kamal Taha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item901">[901]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10988" title="Abstract">arXiv:2310.10988</a> (replaced) [<a href="/pdf/2310.10988" title="Download PDF">pdf</a>, <a href="/ps/2310.10988" title="Download PostScript">ps</a>, <a href="/format/2310.10988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HCI in e-Government and e-Democracy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+T">Tianmu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item902">[902]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11670" title="Abstract">arXiv:2310.11670</a> (replaced) [<a href="/pdf/2310.11670" title="Download PDF">pdf</a>, <a href="/format/2310.11670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prototype-based HyperAdapter for Sample-Efficient Multi-task Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhaofeng He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item903">[903]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11676" title="Abstract">arXiv:2310.11676</a> (replaced) [<a href="/pdf/2310.11676" title="Download PDF">pdf</a>, <a href="/format/2310.11676" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PREM: A Simple Yet Effective Approach for Node-Level Graph Anomaly  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Junjun Pan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yixin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yizhen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shirui Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE International Conference of Data Mining 2023 (ICDM 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item904">[904]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11689" title="Abstract">arXiv:2310.11689</a> (replaced) [<a href="/pdf/2310.11689" title="Download PDF">pdf</a>, <a href="/format/2310.11689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptation with Self-Evaluation to Improve Selective Prediction in LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiefeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+J">Jinsung Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Ebrahimi%2C+S">Sayna Ebrahimi</a>, 
<a href="/search/cs?searchtype=author&query=Arik%2C+S+O">Sercan O Arik</a>, 
<a href="/search/cs?searchtype=author&query=Pfister%2C+T">Tomas Pfister</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+S">Somesh Jha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper published at Findings of the Association for Computational Linguistics: EMNLP, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item905">[905]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11715" title="Abstract">arXiv:2310.11715</a> (replaced) [<a href="/pdf/2310.11715" title="Download PDF">pdf</a>, <a href="/format/2310.11715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Low-resource Fine-grained Named Entity Recognition by  Leveraging Coarse-grained Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S+A">Su Ah Lee</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+S">Seokjin Oh</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+W">Woohwan Jung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item906">[906]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11864" title="Abstract">arXiv:2310.11864</a> (replaced) [<a href="/pdf/2310.11864" title="Download PDF">pdf</a>, <a href="/format/2310.11864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VQ-NeRF: Neural Reflectance Decomposition and Editing with Vector  Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+H">Hongliang Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jingbo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+J">Jing Liao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by TVCG. Project Page: <a href="https://jtbzhl.github.io/VQ-NeRF.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item907">[907]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11877" title="Abstract">arXiv:2310.11877</a> (replaced) [<a href="/pdf/2310.11877" title="Download PDF">pdf</a>, <a href="/format/2310.11877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Curious Case of Hallucinatory (Un)answerability: Finding Truths in  the Hidden States of Over-Confident Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Slobodkin%2C+A">Aviv Slobodkin</a>, 
<a href="/search/cs?searchtype=author&query=Goldman%2C+O">Omer Goldman</a>, 
<a href="/search/cs?searchtype=author&query=Caciularu%2C+A">Avi Caciularu</a>, 
<a href="/search/cs?searchtype=author&query=Dagan%2C+I">Ido Dagan</a>, 
<a href="/search/cs?searchtype=author&query=Ravfogel%2C+S">Shauli Ravfogel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item908">[908]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12467" title="Abstract">arXiv:2310.12467</a> (replaced) [<a href="/pdf/2310.12467" title="Download PDF">pdf</a>, <a href="/format/2310.12467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Learning for Inference in Dialogue
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ishii%2C+E">Etsuko Ishii</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wilie%2C+B">Bryan Wilie</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Z">Ziwei Ji</a>, 
<a href="/search/cs?searchtype=author&query=Lovenia%2C+H">Holy Lovenia</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+W">Willy Chung</a>, 
<a href="/search/cs?searchtype=author&query=Fung%2C+P">Pascale Fung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item909">[909]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13135" title="Abstract">arXiv:2310.13135</a> (replaced) [<a href="/pdf/2310.13135" title="Download PDF">pdf</a>, <a href="/format/2310.13135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LeTFuser: Light-weight End-to-end Transformer-Based Sensor Fusion for  Autonomous Driving with Multi-Task Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agand%2C+P">Pedram Agand</a>, 
<a href="/search/cs?searchtype=author&query=Mahdavian%2C+M">Mohammad Mahdavian</a>, 
<a href="/search/cs?searchtype=author&query=Savva%2C+M">Manolis Savva</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mo Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 2 figures, 3 tables. CVPR Workshops (VCAD). 2023. arXiv admin note: text overlap with <a href="/abs/2204.05513">arXiv:2204.05513</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item910">[910]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14303" title="Abstract">arXiv:2310.14303</a> (replaced) [<a href="/pdf/2310.14303" title="Download PDF">pdf</a>, <a href="/format/2310.14303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Model Unalignment: Parametric Red-Teaming to Expose Hidden  Harms and Biases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhardwaj%2C+R">Rishabh Bhardwaj</a>, 
<a href="/search/cs?searchtype=author&query=Poria%2C+S">Soujanya Poria</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item911">[911]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14328" title="Abstract">arXiv:2310.14328</a> (replaced) [<a href="/pdf/2310.14328" title="Download PDF">pdf</a>, <a href="/format/2310.14328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Key Leasing for PKE and FHE with a Classical Lessor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chardouvelis%2C+O">Orestis Chardouvelis</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+V">Vipul Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+A">Aayush Jain</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiahui Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item912">[912]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14338" title="Abstract">arXiv:2310.14338</a> (replaced) [<a href="/pdf/2310.14338" title="Download PDF">pdf</a>, <a href="/format/2310.14338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Chaos to Clarity: Claim Normalization to Empower Fact-Checking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sundriyal%2C+M">Megha Sundriyal</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+T">Tanmoy Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Nakov%2C+P">Preslav Nakov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Findings EMNLP2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item913">[913]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14450" title="Abstract">arXiv:2310.14450</a> (replaced) [<a href="/pdf/2310.14450" title="Download PDF">pdf</a>, <a href="/format/2310.14450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TATA: Stance Detection via Topic-Agnostic and Topic-Aware Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hanley%2C+H+W+A">Hans W. A. Hanley</a>, 
<a href="/search/cs?searchtype=author&query=Durumeric%2C+Z">Zakir Durumeric</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item914">[914]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15064" title="Abstract">arXiv:2310.15064</a> (replaced) [<a href="/pdf/2310.15064" title="Download PDF">pdf</a>, <a href="/format/2310.15064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New constructions for $3$-free and $3^+$-free binary morphisms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Shallit%2C+J">Jeffrey Shallit</a>, 
<a href="/search/math?searchtype=author&query=Shur%2C+A+M">Arseny M. Shur</a>, 
<a href="/search/math?searchtype=author&query=Zorcic%2C+S">Stefan Zorcic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item915">[915]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15590" title="Abstract">arXiv:2310.15590</a> (replaced) [<a href="/pdf/2310.15590" title="Download PDF">pdf</a>, <a href="/format/2310.15590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Facial Data Minimization: Shallow Model as Your Privacy Filter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pu%2C+Y">Yuwen Pu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiahao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jiayu Pan</a>, 
<a href="/search/cs?searchtype=author&query=li%2C+H">Hao li</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+D">Diqun Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shouling Ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item916">[916]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16452" title="Abstract">arXiv:2310.16452</a> (replaced) [<a href="/pdf/2310.16452" title="Download PDF">pdf</a>, <a href="/format/2310.16452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faithful Path Language Modelling for Explainable Recommendation over  Knowledge Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balloccu%2C+G">Giacomo Balloccu</a>, 
<a href="/search/cs?searchtype=author&query=Boratto%2C+L">Ludovico Boratto</a>, 
<a href="/search/cs?searchtype=author&query=Cancedda%2C+C">Christian Cancedda</a>, 
<a href="/search/cs?searchtype=author&query=Fenu%2C+G">Gianni Fenu</a>, 
<a href="/search/cs?searchtype=author&query=Marras%2C+M">Mirko Marras</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item917">[917]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16607" title="Abstract">arXiv:2310.16607</a> (replaced) [<a href="/pdf/2310.16607" title="Download PDF">pdf</a>, <a href="/format/2310.16607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Interplay between Fairness and Explainability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brandl%2C+S">Stephanie Brandl</a>, 
<a href="/search/cs?searchtype=author&query=Bugliarello%2C+E">Emanuele Bugliarello</a>, 
<a href="/search/cs?searchtype=author&query=Chalkidis%2C+I">Ilias Chalkidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages (incl Appendix), 4 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item918">[918]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16908" title="Abstract">arXiv:2310.16908</a> (replaced) [<a href="/pdf/2310.16908" title="Download PDF">pdf</a>, <a href="/ps/2310.16908" title="Download PostScript">ps</a>, <a href="/format/2310.16908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SequenceLab: A Comprehensive Benchmark of Computational Methods for  Comparing Genomic Sequences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Rumpf%2C+M">Maximilian-David Rumpf</a>, 
<a href="/search/q-bio?searchtype=author&query=Alser%2C+M">Mohammed Alser</a>, 
<a href="/search/q-bio?searchtype=author&query=Gollwitzer%2C+A+E">Arvid E. Gollwitzer</a>, 
<a href="/search/q-bio?searchtype=author&query=Lindegger%2C+J">Joel Lindegger</a>, 
<a href="/search/q-bio?searchtype=author&query=Almadhoun%2C+N">Nour Almadhoun</a>, 
<a href="/search/q-bio?searchtype=author&query=Firtina%2C+C">Can Firtina</a>, 
<a href="/search/q-bio?searchtype=author&query=Mangul%2C+S">Serghei Mangul</a>, 
<a href="/search/q-bio?searchtype=author&query=Mutlu%2C+O">Onur Mutlu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Hardware Architecture (cs.AR); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item919">[919]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16945" title="Abstract">arXiv:2310.16945</a> (replaced) [<a href="/pdf/2310.16945" title="Download PDF">pdf</a>, <a href="/format/2310.16945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Q-Aggregation for CATE Model Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Lan%2C+H">Hui Lan</a>, 
<a href="/search/stat?searchtype=author&query=Syrgkanis%2C+V">Vasilis Syrgkanis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The main text is 9 pages, and we include the Appendix at the end (totaling 51 pages)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Econometrics (econ.EM); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item920">[920]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17688" title="Abstract">arXiv:2310.17688</a> (replaced) [<a href="/pdf/2310.17688" title="Download PDF">pdf</a>, <a href="/format/2310.17688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Managing AI Risks in an Era of Rapid Progress
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bengio%2C+Y">Yoshua Bengio</a>, 
<a href="/search/cs?searchtype=author&query=Hinton%2C+G">Geoffrey Hinton</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+A">Andrew Yao</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Dawn Song</a>, 
<a href="/search/cs?searchtype=author&query=Abbeel%2C+P">Pieter Abbeel</a>, 
<a href="/search/cs?searchtype=author&query=Harari%2C+Y+N">Yuval Noah Harari</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Ya-Qin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+L">Lan Xue</a>, 
<a href="/search/cs?searchtype=author&query=Shalev-Shwartz%2C+S">Shai Shalev-Shwartz</a>, 
<a href="/search/cs?searchtype=author&query=Hadfield%2C+G">Gillian Hadfield</a>, 
<a href="/search/cs?searchtype=author&query=Clune%2C+J">Jeff Clune</a>, 
<a href="/search/cs?searchtype=author&query=Maharaj%2C+T">Tegan Maharaj</a>, 
<a href="/search/cs?searchtype=author&query=Hutter%2C+F">Frank Hutter</a>, 
<a href="/search/cs?searchtype=author&query=Baydin%2C+A+G">At&#x131;l&#x131;m G&#xfc;ne&#x15f; Baydin</a>, 
<a href="/search/cs?searchtype=author&query=McIlraith%2C+S">Sheila McIlraith</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Q">Qiqi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Acharya%2C+A">Ashwin Acharya</a>, 
<a href="/search/cs?searchtype=author&query=Krueger%2C+D">David Krueger</a>, 
<a href="/search/cs?searchtype=author&query=Dragan%2C+A">Anca Dragan</a>, 
<a href="/search/cs?searchtype=author&query=Torr%2C+P">Philip Torr</a>, 
<a href="/search/cs?searchtype=author&query=Russell%2C+S">Stuart Russell</a>, 
<a href="/search/cs?searchtype=author&query=Kahneman%2C+D">Daniel Kahneman</a>, 
<a href="/search/cs?searchtype=author&query=Brauner%2C+J">Jan Brauner</a>, 
<a href="/search/cs?searchtype=author&query=Mindermann%2C+S">S&#xf6;ren Mindermann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item921">[921]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17743" title="Abstract">arXiv:2310.17743</a> (replaced) [<a href="/pdf/2310.17743" title="Download PDF">pdf</a>, <a href="/format/2310.17743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StyleBART: Decorate Pretrained Model with Style Adapters for  Unsupervised Stylistic Headline Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hanqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yajing Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+B">Boya Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guanhua Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yun Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item922">[922]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18122" title="Abstract">arXiv:2310.18122</a> (replaced) [<a href="/pdf/2310.18122" title="Download PDF">pdf</a>, <a href="/format/2310.18122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpinSummEval: Revisiting Automated Evaluation for Opinion Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yuchen Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+X">Xiaojun Wan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint, included 2 more metrics compared with the previous submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item923">[923]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18128" title="Abstract">arXiv:2310.18128</a> (replaced) [<a href="/pdf/2310.18128" title="Download PDF">pdf</a>, <a href="/format/2310.18128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Dynamic Time Warping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bringmann%2C+K">Karl Bringmann</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+N">Nick Fischer</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Hoog%2C+I">Ivor van der Hoog</a>, 
<a href="/search/cs?searchtype=author&query=Kipouridis%2C+E">Evangelos Kipouridis</a>, 
<a href="/search/cs?searchtype=author&query=Kociumaka%2C+T">Tomasz Kociumaka</a>, 
<a href="/search/cs?searchtype=author&query=Rotenberg%2C+E">Eva Rotenberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at SODA24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
</div>
</dd>
<dt><a name="item924">[924]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18424" title="Abstract">arXiv:2310.18424</a> (replaced) [<a href="/pdf/2310.18424" title="Download PDF">pdf</a>, <a href="/ps/2310.18424" title="Download PostScript">ps</a>, <a href="/format/2310.18424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Machine Learning Method with Vector Embedding on Orthonormal Basis  and Spectral Transform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+L+Y">Louis Yu Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> update 9. Strategies for managing large data volumes with 9.1. Using incremental SVD
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item925">[925]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18458" title="Abstract">arXiv:2310.18458</a> (replaced) [<a href="/pdf/2310.18458" title="Download PDF">pdf</a>, <a href="/format/2310.18458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do Not Harm Protected Groups in Debiasing Language Representation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C+Q">Chloe Qinyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Stureborg%2C+R">Rickard Stureborg</a>, 
<a href="/search/cs?searchtype=author&query=Fain%2C+B">Brandon Fain</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item926">[926]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19056" title="Abstract">arXiv:2310.19056</a> (replaced) [<a href="/pdf/2310.19056" title="Download PDF">pdf</a>, <a href="/format/2310.19056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MILL: Mutual Verification with Large Language Models for Zero-Shot Query  Expansion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+P">Pengyue Jia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yiding Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiangyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaopeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+C">Changying Hao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuaiqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+D">Dawei Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item927">[927]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19514" title="Abstract">arXiv:2310.19514</a> (replaced) [<a href="/pdf/2310.19514" title="Download PDF">pdf</a>, <a href="/format/2310.19514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximate Earth Mover&#x27;s Distance in Truly-Subquadratic Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beretta%2C+L">Lorenzo Beretta</a>, 
<a href="/search/cs?searchtype=author&query=Rubinstein%2C+A">Aviad Rubinstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Geometry (cs.CG)

</div>
</div>
</dd>
<dt><a name="item928">[928]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19542" title="Abstract">arXiv:2310.19542</a> (replaced) [<a href="/pdf/2310.19542" title="Download PDF">pdf</a>, <a href="/format/2310.19542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Image-Related Inductive Biases in Single-Branch Visual  Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chuanming Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kai Wang</a>, 
<a href="/search/cs?searchtype=author&query=van+de+Weijer%2C+J">Joost van de Weijer</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianlin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yongmei Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item929">[929]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19680" title="Abstract">arXiv:2310.19680</a> (replaced) [<a href="/pdf/2310.19680" title="Download PDF">pdf</a>, <a href="/format/2310.19680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating Pre-trained Language Model into Neural Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hwang%2C+S">Soon-Jae Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+C">Chang-Sung Jeong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item930">[930]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19914" title="Abstract">arXiv:2310.19914</a> (replaced) [<a href="/pdf/2310.19914" title="Download PDF">pdf</a>, <a href="/format/2310.19914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient entanglement purification based on noise guessing decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Roque%2C+A">Andr&#xe9; Roque</a>, 
<a href="/search/quant-ph?searchtype=author&query=Cruz%2C+D">Diogo Cruz</a>, 
<a href="/search/quant-ph?searchtype=author&query=Monteiro%2C+F+A">Francisco A. Monteiro</a>, 
<a href="/search/quant-ph?searchtype=author&query=Coutinho%2C+B+C">Bruno C. Coutinho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item931">[931]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20228" title="Abstract">arXiv:2310.20228</a> (replaced) [<a href="/pdf/2310.20228" title="Download PDF">pdf</a>, <a href="/format/2310.20228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconstructing Human Pose from Inertial Measurements: A Generative  Model-based Compressive Sensing Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hieu%2C+N+Q">Nguyen Quang Hieu</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+D+T">Dinh Thai Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+N">Diep N. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Alsheikh%2C+M+A">Mohammad Abu Alsheikh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item932">[932]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00282" title="Abstract">arXiv:2311.00282</a> (replaced) [<a href="/pdf/2311.00282" title="Download PDF">pdf</a>, <a href="/format/2311.00282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TLMCM Network for Medical Image Hierarchical Multi-Label Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Meng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Siyan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qiyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wenbin Ouyang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item933">[933]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00334" title="Abstract">arXiv:2311.00334</a> (replaced) [<a href="/pdf/2311.00334" title="Download PDF">pdf</a>, <a href="/format/2311.00334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MetisFL: An Embarrassingly Parallelized Controller for Scalable &amp;  Efficient Federated Learning Workflows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stripelis%2C+D">Dimitris Stripelis</a>, 
<a href="/search/cs?searchtype=author&query=Anastasiou%2C+C">Chrysovalantis Anastasiou</a>, 
<a href="/search/cs?searchtype=author&query=Toral%2C+P">Patrick Toral</a>, 
<a href="/search/cs?searchtype=author&query=Asghar%2C+A">Armaghan Asghar</a>, 
<a href="/search/cs?searchtype=author&query=Ambite%2C+J+L">Jose Luis Ambite</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 11 figures, Accepted at DistributedML '23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item934">[934]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00562" title="Abstract">arXiv:2311.00562</a> (replaced) [<a href="/pdf/2311.00562" title="Download PDF">pdf</a>, <a href="/format/2311.00562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MNN: Mixed Nearest-Neighbors for Self-Supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Long%2C+X">Xianzhong Long</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Chen Peng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yun Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 7 figures, source code and pretrained models are available <a href="https://github.com/pc-cp/MNN">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item935">[935]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00567" title="Abstract">arXiv:2311.00567</a> (replaced) [<a href="/pdf/2311.00567" title="Download PDF">pdf</a>, <a href="/ps/2311.00567" title="Download PostScript">ps</a>, <a href="/format/2311.00567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Robust Deep Learning Method with Uncertainty Estimation for the  Pathological Classification of Renal Cell Carcinoma based on CT Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yao%2C+N">Ni Yao</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+H">Hang Hu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+K">Kaicong Chen</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+C">Chen Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+Y">Yuan Guo</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+B">Boya Li</a>, 
<a href="/search/eess?searchtype=author&query=Nan%2C+J">Jiaofen Nan</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yanting Li</a>, 
<a href="/search/eess?searchtype=author&query=Han%2C+C">Chuang Han</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+F">Fubao Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+W">Weihua Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Tian%2C+L">Li Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Medical Physics (physics.med-ph); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item936">[936]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00797" title="Abstract">arXiv:2311.00797</a> (replaced) [<a href="/pdf/2311.00797" title="Download PDF">pdf</a>, <a href="/format/2311.00797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tipping Points of Evolving Epidemiological Networks: Machine  Learning-Assisted, Data-Driven Effective Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Evangelou%2C+N">Nikolaos Evangelou</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+T">Tianqi Cui</a>, 
<a href="/search/cs?searchtype=author&query=Bello-Rivas%2C+J+M">Juan M. Bello-Rivas</a>, 
<a href="/search/cs?searchtype=author&query=Makeev%2C+A">Alexei Makeev</a>, 
<a href="/search/cs?searchtype=author&query=Kevrekidis%2C+I+G">Ioannis G. Kevrekidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Dynamical Systems (math.DS); Populations and Evolution (q-bio.PE)

</div>
</div>
</dd>
<dt><a name="item937">[937]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00974" title="Abstract">arXiv:2311.00974</a> (replaced) [<a href="/pdf/2311.00974" title="Download PDF">pdf</a>, <a href="/format/2311.00974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CloudSim Express: A Novel Framework for Rapid Low Code Simulation of  Cloud Computing Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hewage%2C+T+B">Tharindu B. Hewage</a>, 
<a href="/search/cs?searchtype=author&query=Ilager%2C+S">Shashikant Ilager</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+M+A">Maria A. Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Buyya%2C+R">Rajkumar Buyya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item938">[938]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01012" title="Abstract">arXiv:2311.01012</a> (replaced) [<a href="/pdf/2311.01012" title="Download PDF">pdf</a>, <a href="/format/2311.01012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COPAL-ID: Indonesian Language Reasoning with Local Culture and Nuances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wibowo%2C+H+A">Haryo Akbarianto Wibowo</a>, 
<a href="/search/cs?searchtype=author&query=Fuadi%2C+E+H">Erland Hilman Fuadi</a>, 
<a href="/search/cs?searchtype=author&query=Nityasya%2C+M+N">Made Nindyatama Nityasya</a>, 
<a href="/search/cs?searchtype=author&query=Prasojo%2C+R+E">Radityo Eko Prasojo</a>, 
<a href="/search/cs?searchtype=author&query=Aji%2C+A+F">Alham Fikri Aji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item939">[939]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01073" title="Abstract">arXiv:2311.01073</a> (replaced) [<a href="/pdf/2311.01073" title="Download PDF">pdf</a>, <a href="/format/2311.01073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fourier Analysis of Signals on Directed Acyclic Graphs (DAG) Using Graph  Zero-Padding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stankovic%2C+L">Ljubisa Stankovic</a>, 
<a href="/search/cs?searchtype=author&query=Dakovic%2C+M">Milos Dakovic</a>, 
<a href="/search/cs?searchtype=author&query=Bardi%2C+A+B">Ali Bagheri Bardi</a>, 
<a href="/search/cs?searchtype=author&query=Brajovic%2C+M">Milos Brajovic</a>, 
<a href="/search/cs?searchtype=author&query=Stankovic%2C+I">Isidora Stankovic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item940">[940]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01305" title="Abstract">arXiv:2311.01305</a> (replaced) [<a href="/pdf/2311.01305" title="Download PDF">pdf</a>, <a href="/format/2311.01305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AWEQ: Post-Training Quantization with Activation-Weight Equalization for  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Baisong Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xingwang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haixiao Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item941">[941]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01351" title="Abstract">arXiv:2311.01351</a> (replaced) [<a href="/pdf/2311.01351" title="Download PDF">pdf</a>, <a href="/format/2311.01351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simplicial Models for the Epistemic Logic of Faulty Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goubault%2C+E">Eric Goubault</a>, 
<a href="/search/cs?searchtype=author&query=Kniazev%2C+R">Roman Kniazev</a>, 
<a href="/search/cs?searchtype=author&query=Ledent%2C+J">Jeremy Ledent</a>, 
<a href="/search/cs?searchtype=author&query=Rajsbaum%2C+S">Sergio Rajsbaum</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Algebraic Topology (math.AT)

</div>
</div>
</dd>
<dt><a name="item942">[942]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01455" title="Abstract">arXiv:2311.01455</a> (replaced) [<a href="/pdf/2311.01455" title="Download PDF">pdf</a>, <a href="/format/2311.01455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RoboGen: Towards Unleashing Infinite Data for Automated Robot Learning  via Generative Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yufei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xian%2C+Z">Zhou Xian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Feng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tsun-Hsuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Erickson%2C+Z">Zackory Erickson</a>, 
<a href="/search/cs?searchtype=author&query=Held%2C+D">David Held</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+C">Chuang Gan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item943">[943]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01544" title="Abstract">arXiv:2311.01544</a> (replaced) [<a href="/pdf/2311.01544" title="Download PDF">pdf</a>, <a href="/format/2311.01544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Divergent Token Metrics: Measuring degradation to prune away LLM  components -- and optimize quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deiseroth%2C+B">Bj&#xf6;rn Deiseroth</a>, 
<a href="/search/cs?searchtype=author&query=Meuer%2C+M">Max Meuer</a>, 
<a href="/search/cs?searchtype=author&query=Gritsch%2C+N">Nikolas Gritsch</a>, 
<a href="/search/cs?searchtype=author&query=Eichenberg%2C+C">Constantin Eichenberg</a>, 
<a href="/search/cs?searchtype=author&query=Schramowski%2C+P">Patrick Schramowski</a>, 
<a href="/search/cs?searchtype=author&query=A%C3%9Fenmacher%2C+M">Matthias A&#xdf;enmacher</a>, 
<a href="/search/cs?searchtype=author&query=Kersting%2C+K">Kristian Kersting</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item944">[944]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01568" title="Abstract">arXiv:2311.01568</a> (replaced) [<a href="/pdf/2311.01568" title="Download PDF">pdf</a>, <a href="/format/2311.01568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anytime-Competitive Reinforcement Learning with Policy Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pengfei Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tongxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Wierman%2C+A">Adam Wierman</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Shaolei Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item945">[945]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01732" title="Abstract">arXiv:2311.01732</a> (replaced) [<a href="/pdf/2311.01732" title="Download PDF">pdf</a>, <a href="/format/2311.01732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proto-lm: A Prototypical Network-Based Framework for Built-in  Interpretability in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Sean Xie</a>, 
<a href="/search/cs?searchtype=author&query=Vosoughi%2C+S">Soroush Vosoughi</a>, 
<a href="/search/cs?searchtype=author&query=Hassanpour%2C+S">Saeed Hassanpour</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item946">[946]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02332" title="Abstract">arXiv:2311.02332</a> (replaced) [<a href="/pdf/2311.02332" title="Download PDF">pdf</a>, <a href="/format/2311.02332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Machine Learning in Image-Based and Clinical Biomedicine:  Survey and Prospects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Warner%2C+E">Elisa Warner</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Joonsang Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+W">William Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Syeda-Mahmood%2C+T">Tanveer Syeda-Mahmood</a>, 
<a href="/search/cs?searchtype=author&query=Kahn%2C+C">Charles Kahn</a>, 
<a href="/search/cs?searchtype=author&query=Gevaert%2C+O">Olivier Gevaert</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+A">Arvind Rao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item947">[947]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02358" title="Abstract">arXiv:2311.02358</a> (replaced) [<a href="/pdf/2311.02358" title="Download PDF">pdf</a>, <a href="/ps/2311.02358" title="Download PostScript">ps</a>, <a href="/format/2311.02358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Transfer in Latent Space (DTLS) Wins on Image Super-Resolution  $-$ a Non-Denoising Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hui%2C+C">Chun-Chuen Hui</a>, 
<a href="/search/eess?searchtype=author&query=Siu%2C+W">Wan-Chi Siu</a>, 
<a href="/search/eess?searchtype=author&query=Law%2C+N">Ngai-Fong Law</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item948">[948]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02408" title="Abstract">arXiv:2311.02408</a> (replaced) [<a href="/pdf/2311.02408" title="Download PDF">pdf</a>, <a href="/format/2311.02408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Citance-Contextualized Summarization of Scientific Papers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Syed%2C+S">Shahbaz Syed</a>, 
<a href="/search/cs?searchtype=author&query=Hakimi%2C+A+D">Ahmad Dawar Hakimi</a>, 
<a href="/search/cs?searchtype=author&query=Al-Khatib%2C+K">Khalid Al-Khatib</a>, 
<a href="/search/cs?searchtype=author&query=Potthast%2C+M">Martin Potthast</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP 2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item949">[949]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02520" title="Abstract">arXiv:2311.02520</a> (replaced) [<a href="/pdf/2311.02520" title="Download PDF">pdf</a>, <a href="/ps/2311.02520" title="Download PostScript">ps</a>, <a href="/format/2311.02520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single-Source Shortest Paths with Negative Real Weights in  $\tilde{O}(mn^{8/9})$ Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fineman%2C+J+T">Jeremy T. Fineman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item950">[950]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02577" title="Abstract">arXiv:2311.02577</a> (replaced) [<a href="/pdf/2311.02577" title="Download PDF">pdf</a>, <a href="/format/2311.02577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Steady-State Analysis and Online Learning for Queues with Hawkes  Arrivals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+X">Xinyun Chen</a>, 
<a href="/search/math?searchtype=author&query=Hong%2C+G">Guiyu Hong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item951">[951]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02651" title="Abstract">arXiv:2311.02651</a> (replaced) [<a href="/pdf/2311.02651" title="Download PDF">pdf</a>, <a href="/ps/2311.02651" title="Download PostScript">ps</a>, <a href="/format/2311.02651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compute at Scale -- A Broad Investigation into the Data Center Industry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pilz%2C+K">Konstantin Pilz</a>, 
<a href="/search/cs?searchtype=author&query=Heim%2C+L">Lennart Heim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Compressed pdf
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item952">[952]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02775" title="Abstract">arXiv:2311.02775</a> (replaced) [<a href="/pdf/2311.02775" title="Download PDF">pdf</a>, <a href="/format/2311.02775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChaTA: Towards an Intelligent Question-Answer Teaching Assistant using  Open-Source LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hicke%2C+Y">Yann Hicke</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+A">Anmol Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Q">Qianou Ma</a>, 
<a href="/search/cs?searchtype=author&query=Denny%2C+P">Paul Denny</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updates for camera-ready submission
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS Workshop on Generative AI for Education (GAIED), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item953">[953]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02782" title="Abstract">arXiv:2311.02782</a> (replaced) [<a href="/pdf/2311.02782" title="Download PDF">pdf</a>, <a href="/format/2311.02782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Generic Anomaly Detection and Understanding: Large-scale  Visual-linguistic Model (GPT-4V) Takes the Lead
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yunkang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaohao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Chen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaonan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Weiming Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress. Evaluated GPT-4V on 4 modalities, 9 tasks, and 15 datasets. The first three authors contribute equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item954">[954]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02877" title="Abstract">arXiv:2311.02877</a> (replaced) [<a href="/pdf/2311.02877" title="Download PDF">pdf</a>, <a href="/format/2311.02877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inner-IoU: More Effective Intersection over Union Loss with Auxiliary  Bounding Box
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Cong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuaijie Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item955">[955]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02901" title="Abstract">arXiv:2311.02901</a> (replaced) [<a href="/pdf/2311.02901" title="Download PDF">pdf</a>, <a href="/format/2311.02901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pseudorandom Isometries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Ananth%2C+P">Prabhanjan Ananth</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gulati%2C+A">Aditya Gulati</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kaleoglu%2C+F">Fatih Kaleoglu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lin%2C+Y">Yao-Ting Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item956">[956]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02921" title="Abstract">arXiv:2311.02921</a> (replaced) [<a href="/pdf/2311.02921" title="Download PDF">pdf</a>, <a href="/format/2311.02921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Edge2Node: Reducing Edge Prediction to Node Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahmati%2C+Z">Zahed Rahmati</a>, 
<a href="/search/cs?searchtype=author&query=Rahmati%2C+A">Ali Rahmati</a>, 
<a href="/search/cs?searchtype=author&query=Kazemi%2C+D">Dariush Kazemi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item957">[957]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02957" title="Abstract">arXiv:2311.02957</a> (replaced) [<a href="/pdf/2311.02957" title="Download PDF">pdf</a>, <a href="/format/2311.02957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe and Efficient Trajectory Optimization for Autonomous Vehicles using  B-spline with Incremental Path Flattening
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jongseo Choi</a>, 
<a href="/search/cs?searchtype=author&query=Chin%2C+H">Hyuntai Chin</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+H">Hyunwoo Park</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+D">Daehyeok Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sanghyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Baek%2C+D">Doosan Baek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 21 figures, 4 tables, 3 algorithms
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item958">[958]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03114" title="Abstract">arXiv:2311.03114</a> (replaced) [<a href="/pdf/2311.03114" title="Download PDF">pdf</a>, <a href="/format/2311.03114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ignoring Time Dependence in Software Engineering Data. A Mistake
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Robredo%2C+M">Mikel Robredo</a>, 
<a href="/search/cs?searchtype=author&query=Saarimaki%2C+N">Nyyti Saarimaki</a>, 
<a href="/search/cs?searchtype=author&query=Penaloza%2C+R">Rafael Penaloza</a>, 
<a href="/search/cs?searchtype=author&query=Lenarduzzi%2C+V">Valentina Lenarduzzi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item959">[959]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03148" title="Abstract">arXiv:2311.03148</a> (replaced) [<a href="/pdf/2311.03148" title="Download PDF">pdf</a>, <a href="/format/2311.03148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collision Avoidance using Iterative Dynamic and Nonlinear Programming  with Adaptive Grid Refinements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Richter%2C+R">Rebecca Richter</a>, 
<a href="/search/math?searchtype=author&query=De+Marchi%2C+A">Alberto De Marchi</a>, 
<a href="/search/math?searchtype=author&query=Gerdts%2C+M">Matthias Gerdts</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fixed typo in Reference [5]
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item960">[960]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03255" title="Abstract">arXiv:2311.03255</a> (replaced) [<a href="/pdf/2311.03255" title="Download PDF">pdf</a>, <a href="/format/2311.03255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimal Arrangements of Spherical Geodesics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Viglietta%2C+G">Giovanni Viglietta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Geometry (cs.CG)

</div>
</div>
</dd>
<dt><a name="item961">[961]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03612" title="Abstract">arXiv:2311.03612</a> (replaced) [<a href="/pdf/2311.03612" title="Download PDF">pdf</a>, <a href="/format/2311.03612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BlockEmulator: An Emulator Enabling to Test Blockchain Sharding  Protocols
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Huawei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+G">Guang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qinde Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhaokang Yin</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiaofei Luo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jianru Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Taotao Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qinglin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zibin Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item962">[962]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03758" title="Abstract">arXiv:2311.03758</a> (replaced) [<a href="/pdf/2311.03758" title="Download PDF">pdf</a>, <a href="/format/2311.03758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Model based Long-tail Query Rewriting in Taobao Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Wenjun Peng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guiyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yue Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zilong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ou%2C+D">Dan Ou</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xiaoyi Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Derong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tongxu">Tongxu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+E">Enhong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WWW Industry Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item963">[963]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03764" title="Abstract">arXiv:2311.03764</a> (replaced) [<a href="/pdf/2311.03764" title="Download PDF">pdf</a>, <a href="/format/2311.03764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neuro-GPT: Developing A Foundation Model for EEG
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+W">Wenhui Cui</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+W">Woojae Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Th%C3%B6lke%2C+P">Philipp Th&#xf6;lke</a>, 
<a href="/search/cs?searchtype=author&query=Medani%2C+T">Takfarinas Medani</a>, 
<a href="/search/cs?searchtype=author&query=Jerbi%2C+K">Karim Jerbi</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+A+A">Anand A. Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Leahy%2C+R+M">Richard M. Leahy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item964">[964]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04150" title="Abstract">arXiv:2311.04150</a> (replaced) [<a href="/e-print/2311.04150" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Makes a Fantastic Passenger-Car Driver in Urban Contexts?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yueteng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+Z">Zhijie Yi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xinyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+M">Mengdi Chu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Junrong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xiang Chang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yiyao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+J">Jingli Qin</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Ye Jin</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jialin Song</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+X">Xingrui Gu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jirui Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Guyue Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+J">Jiangtao Gong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Part of the content of the paper will be modified. One of the authors has recommended its withdrawal due to personal reasons
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item965">[965]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04254" title="Abstract">arXiv:2311.04254</a> (replaced) [<a href="/pdf/2311.04254" title="Download PDF">pdf</a>, <a href="/format/2311.04254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Everything of Thoughts: Defying the Law of Penrose Triangle for Thought  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+R">Ruomeng Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chaoyun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+M">Minghua Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+S">Si Qin</a>, 
<a href="/search/cs?searchtype=author&query=Rajmohan%2C+S">Saravan Rajmohan</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Q">Qingwei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongmei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item966">[966]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04306" title="Abstract">arXiv:2311.04306</a> (replaced) [<a href="/pdf/2311.04306" title="Download PDF">pdf</a>, <a href="/ps/2311.04306" title="Download PostScript">ps</a>, <a href="/format/2311.04306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Order Numerical Method for 1D Non-local Diffusive Equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Do%2C+D">D. Do</a>, 
<a href="/search/math?searchtype=author&query=Matin%2C+H+N+Z">H. Nick Zinat Matin</a>, 
<a href="/search/math?searchtype=author&query=Monache%2C+M+L+D">M. L. Delle Monache</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages and 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item967">[967]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04414" title="Abstract">arXiv:2311.04414</a> (replaced) [<a href="/pdf/2311.04414" title="Download PDF">pdf</a>, <a href="/format/2311.04414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning the What and How of Annotation in Video Object Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Delatolas%2C+T">Thanos Delatolas</a>, 
<a href="/search/cs?searchtype=author&query=Kalogeiton%2C+V">Vicky Kalogeiton</a>, 
<a href="/search/cs?searchtype=author&query=Papadopoulos%2C+D+P">Dim P. Papadopoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item968">[968]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04418" title="Abstract">arXiv:2311.04418</a> (replaced) [<a href="/pdf/2311.04418" title="Download PDF">pdf</a>, <a href="/format/2311.04418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-accelerated Discovery of Altermagnetic Materials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Gao%2C+Z">Ze-Feng Gao</a>, 
<a href="/search/cond-mat?searchtype=author&query=Qu%2C+S">Shuai Qu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zeng%2C+B">Bocheng Zeng</a>, 
<a href="/search/cond-mat?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Wen%2C+J">Ji-Rong Wen</a>, 
<a href="/search/cond-mat?searchtype=author&query=Sun%2C+H">Hao Sun</a>, 
<a href="/search/cond-mat?searchtype=author&query=Guo%2C+P">Peng-Jie Guo</a>, 
<a href="/search/cond-mat?searchtype=author&query=Lu%2C+Z">Zhong-Yi Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages; 22 figures; 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Artificial Intelligence (cs.AI); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item969">[969]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04498" title="Abstract">arXiv:2311.04498</a> (replaced) [<a href="/pdf/2311.04498" title="Download PDF">pdf</a>, <a href="/format/2311.04498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NExT-Chat: An LMM for Chat, Detection and Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Ao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+W">Wei Ji</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report (project page: <a href="https://next-chatv.github.io/">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item970">[970]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04584" title="Abstract">arXiv:2311.04584</a> (replaced) [<a href="/pdf/2311.04584" title="Download PDF">pdf</a>, <a href="/format/2311.04584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly-supervised deepfake localization in diffusion-generated images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tantaru%2C+D">Dragos Tantaru</a>, 
<a href="/search/cs?searchtype=author&query=Oneata%2C+E">Elisabeta Oneata</a>, 
<a href="/search/cs?searchtype=author&query=Oneata%2C+D">Dan Oneata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item971">[971]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04678" title="Abstract">arXiv:2311.04678</a> (replaced) [<a href="/pdf/2311.04678" title="Download PDF">pdf</a>, <a href="/format/2311.04678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly supervised cross-modal learning in high-content screening
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gabriel%2C+W">Watkinson Gabriel</a>, 
<a href="/search/cs?searchtype=author&query=Ethan%2C+C">Cohen Ethan</a>, 
<a href="/search/cs?searchtype=author&query=Nicolas%2C+B">Bourriez Nicolas</a>, 
<a href="/search/cs?searchtype=author&query=Ihab%2C+B">Bendidi Ihab</a>, 
<a href="/search/cs?searchtype=author&query=Guillaume%2C+B">Bollot Guillaume</a>, 
<a href="/search/cs?searchtype=author&query=Auguste%2C+G">Genovesio Auguste</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item972">[972]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04766" title="Abstract">arXiv:2311.04766</a> (replaced) [<a href="/pdf/2311.04766" title="Download PDF">pdf</a>, <a href="/format/2311.04766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DualTalker: A Cross-Modal Dual Learning Approach for Speech-Driven 3D  Facial Animation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+G">Guinan Su</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yanwu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhifeng Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item973">[973]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04850" title="Abstract">arXiv:2311.04850</a> (replaced) [<a href="/pdf/2311.04850" title="Download PDF">pdf</a>, <a href="/format/2311.04850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Benchmark and Contamination for Language Models with  Rephrased Samples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chiang%2C+W">Wei-Lin Chiang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Lianmin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+J+E">Joseph E. Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Stoica%2C+I">Ion Stoica</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item974">[974]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04881" title="Abstract">arXiv:2311.04881</a> (replaced) [<a href="/pdf/2311.04881" title="Download PDF">pdf</a>, <a href="/ps/2311.04881" title="Download PostScript">ps</a>, <a href="/format/2311.04881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Transmit Signal and Beamforming Design for Integrated Sensing and  Power Transfer Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mayer%2C+K+M">Kenneth MacSporran Mayer</a>, 
<a href="/search/cs?searchtype=author&query=Shanin%2C+N">Nikita Shanin</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Z">Zhenlong You</a>, 
<a href="/search/cs?searchtype=author&query=Lotter%2C+S">Sebastian Lotter</a>, 
<a href="/search/cs?searchtype=author&query=Br%C3%BCckner%2C+S">Stefan Br&#xfc;ckner</a>, 
<a href="/search/cs?searchtype=author&query=Vossiek%2C+M">Martin Vossiek</a>, 
<a href="/search/cs?searchtype=author&query=Cottatellucci%2C+L">Laura Cottatellucci</a>, 
<a href="/search/cs?searchtype=author&query=Schober%2C+R">Robert Schober</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures, six page version of this paper has been submitted to IEEE ICC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item975">[975]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04913" title="Abstract">arXiv:2311.04913</a> (replaced) [<a href="/pdf/2311.04913" title="Download PDF">pdf</a>, <a href="/ps/2311.04913" title="Download PostScript">ps</a>, <a href="/format/2311.04913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Improved Transformer-based Model for Detecting Phishing, Spam, and  Ham: A Large Language Model Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jamal%2C+S">Suhaima Jamal</a>, 
<a href="/search/cs?searchtype=author&query=Wimmer%2C+H">Hayden Wimmer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item976">[976]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04943" title="Abstract">arXiv:2311.04943</a> (replaced) [<a href="/pdf/2311.04943" title="Download PDF">pdf</a>, <a href="/format/2311.04943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MathNAS: If Blocks Have a Role in Mathematical Architecture Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qinsi%2C+W">Wang Qinsi</a>, 
<a href="/search/cs?searchtype=author&query=Jinghan%2C+K">Ke Jinghan</a>, 
<a href="/search/cs?searchtype=author&query=Zhi%2C+L">Liang Zhi</a>, 
<a href="/search/cs?searchtype=author&query=Sihai%2C+Z">Zhang Sihai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item977">[977]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05012" title="Abstract">arXiv:2311.05012</a> (replaced) [<a href="/pdf/2311.05012" title="Download PDF">pdf</a>, <a href="/ps/2311.05012" title="Download PostScript">ps</a>, <a href="/format/2311.05012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frequency-Based Reduced Models from Purely Time-Domain Data via Data  Informativity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ackermann%2C+M+S">Michael S. Ackermann</a>, 
<a href="/search/math?searchtype=author&query=Gugercin%2C+S">Serkan Gugercin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item978">[978]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05101" title="Abstract">arXiv:2311.05101</a> (replaced) [<a href="/pdf/2311.05101" title="Download PDF">pdf</a>, <a href="/format/2311.05101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrated Sensing and Communication for Network-Assisted Full-Duplex  Cell-Free Distributed Massive MIMO Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+F">Fan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jingxuan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiamin Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Feiyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dongming Wang</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+X">Xiaohu You</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures,submit to China Communication February 28, 2023, date of major revision July 09, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item979">[979]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05304" title="Abstract">arXiv:2311.05304</a> (replaced) [<a href="/pdf/2311.05304" title="Download PDF">pdf</a>, <a href="/format/2311.05304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Valuation and Detections in Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenqian Li</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+S">Shuran Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fengrui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+Y">Yan Pang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fixed some experimental errors and typos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item980">[980]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05372" title="Abstract">arXiv:2311.05372</a> (replaced) [<a href="/pdf/2311.05372" title="Download PDF">pdf</a>, <a href="/format/2311.05372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Angle and Delay Cram&#xe9;r-Rao Bound Optimization for Integrated  Sensing and Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+L">Ling Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been submitted to IEEE TVT
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item981">[981]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05553" title="Abstract">arXiv:2311.05553</a> (replaced) [<a href="/pdf/2311.05553" title="Download PDF">pdf</a>, <a href="/format/2311.05553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Removing RLHF Protections in GPT-4 via Fine-Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Q">Qiusi Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+R">Richard Fang</a>, 
<a href="/search/cs?searchtype=author&query=Bindu%2C+R">Rohan Bindu</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Akul Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Hashimoto%2C+T">Tatsunori Hashimoto</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+D">Daniel Kang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item982">[982]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05698" title="Abstract">arXiv:2311.05698</a> (replaced) [<a href="/pdf/2311.05698" title="Download PDF">pdf</a>, <a href="/format/2311.05698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mirasol3B: A Multimodal Autoregressive model for time-aligned and  contextual modalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Piergiovanni%2C+A">AJ Piergiovanni</a>, 
<a href="/search/cs?searchtype=author&query=Noble%2C+I">Isaac Noble</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dahun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ryoo%2C+M+S">Michael S. Ryoo</a>, 
<a href="/search/cs?searchtype=author&query=Gomes%2C+V">Victor Gomes</a>, 
<a href="/search/cs?searchtype=author&query=Angelova%2C+A">Anelia Angelova</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item983">[983]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05823" title="Abstract">arXiv:2311.05823</a> (replaced) [<a href="/pdf/2311.05823" title="Download PDF">pdf</a>, <a href="/format/2311.05823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recurrent Dynamic Message Passing with Loops for Epidemics on Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Gao%2C+F">Fei Gao</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+J">Jing Liu</a>, 
<a href="/search/physics?searchtype=author&query=Zhao%2C+Y">Yaqian Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted, 14 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item984">[984]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05919" title="Abstract">arXiv:2311.05919</a> (replaced) [<a href="/pdf/2311.05919" title="Download PDF">pdf</a>, <a href="/format/2311.05919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inter-object Discriminative Graph Modeling for Indoor Scene Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+C">Chuanxin Song</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hanbo Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xin Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item985">[985]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05927" title="Abstract">arXiv:2311.05927</a> (replaced) [<a href="/pdf/2311.05927" title="Download PDF">pdf</a>, <a href="/format/2311.05927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Sperm Assessment Framework and Neural Network Specialized for  Sperm Video Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fujii%2C+T">Takuro Fujii</a>, 
<a href="/search/cs?searchtype=author&query=Nakagawa%2C+H">Hayato Nakagawa</a>, 
<a href="/search/cs?searchtype=author&query=Takeshima%2C+T">Teppei Takeshima</a>, 
<a href="/search/cs?searchtype=author&query=Yumura%2C+Y">Yasushi Yumura</a>, 
<a href="/search/cs?searchtype=author&query=Hamagami%2C+T">Tomoki Hamagami</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Winter Conference on Applications of Computer Vision (WACV) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item986">[986]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06115" title="Abstract">arXiv:2311.06115</a> (replaced) [<a href="/pdf/2311.06115" title="Download PDF">pdf</a>, <a href="/format/2311.06115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient and Scalable Kernel Matrix Approximations using Hierarchical  Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gaddameedi%2C+K">Keerthi Gaddameedi</a>, 
<a href="/search/math?searchtype=author&query=Reiz%2C+S">Severin Reiz</a>, 
<a href="/search/math?searchtype=author&query=Neckel%2C+T">Tobias Neckel</a>, 
<a href="/search/math?searchtype=author&query=Bungartz%2C+H">Hans-Joachim Bungartz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> *Equal contribution, joint first author. Accepted for IC 2023 held in conjunction with the BenchCouncil <a href="https://www.benchcouncil.org/ic2023/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item987">[987]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06237" title="Abstract">arXiv:2311.06237</a> (replaced) [<a href="/pdf/2311.06237" title="Download PDF">pdf</a>, <a href="/format/2311.06237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Summon a Demon and Bind it: A Grounded Theory of LLM Red Teaming in the  Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Inie%2C+N">Nanna Inie</a>, 
<a href="/search/cs?searchtype=author&query=Stray%2C+J">Jonathan Stray</a>, 
<a href="/search/cs?searchtype=author&query=Derczynski%2C+L">Leon Derczynski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item548">Cross-lists</a></li>
<li><a href="#item635">Replacements</a></li>
</ul>
<small>[ total of 987 entries:  <b>1-987</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2311">2311</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
