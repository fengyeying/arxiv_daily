<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Wed  8 Nov 23  to  Thu  9 Nov 23, announced Fri, 10 Nov 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item277">Cross-lists</a></li>
<li><a href="#item317">Replacements</a></li>
</ul>
<small>[ total of 512 entries:  <b>1-512</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Fri, 10 Nov 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04904" title="Abstract">arXiv:2311.04904</a> [<a href="/pdf/2311.04904" title="Download PDF">pdf</a>, <a href="/ps/2311.04904" title="Download PostScript">ps</a>, <a href="/format/2311.04904" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SciDataFlow: A Tool for Improving the Flow of Data through Science
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Buffalo%2C+V">Vince Buffalo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages, no figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Managing data and code in open scientific research is complicated by two key
problems: large datasets often cannot be stored alongside code in repository
platforms like GitHub, and iterative analysis can lead to unnoticed changes to
data, increasing the risk that analyses are based on older versions of data.
Here, I introduce SciDataFlow: a fast, concurrent command-line tool paired with
a simple Data Manifest specification. SciDataFlow streamlines tracking data
changes, uploading data to remote repositories, and pulling in all data
necessary to reproduce a computational analysis.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04905" title="Abstract">arXiv:2311.04905</a> [<a href="/pdf/2311.04905" title="Download PDF">pdf</a>, <a href="/format/2311.04905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Relevant Information in High-Volume Chat Logs: Keyphrase  Extraction for Grooming and Drug Dealing Forensic Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alves%2C+J+H">Jeovane Hon&#xf3;rio Alves</a>, 
<a href="/search/cs?searchtype=author&query=Pedroso%2C+H+A+C+G">Hor&#xe1;cio A. C. G. Pedroso</a>, 
<a href="/search/cs?searchtype=author&query=Venetikides%2C+R+H">Rafael Honorio Venetikides</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6ster%2C+J+E+M">Joel E. M. K&#xf6;ster</a>, 
<a href="/search/cs?searchtype=author&query=Grochocki%2C+L+R">Luiz Rodrigo Grochocki</a>, 
<a href="/search/cs?searchtype=author&query=Freitas%2C+C+O+A">Cinthia O. A. Freitas</a>, 
<a href="/search/cs?searchtype=author&query=Barddal%2C+J+P">Jean Paul Barddal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation at the 22nd IEEE International Conference on Machine Learning and Applications (ICMLA) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The growing use of digital communication platforms has given rise to various
criminal activities, such as grooming and drug dealing, which pose significant
challenges to law enforcement and forensic experts. This paper presents a
supervised keyphrase extraction approach to detect relevant information in
high-volume chat logs involving grooming and drug dealing for forensic
analysis. The proposed method, JointKPE++, builds upon the JointKPE keyphrase
extractor by employing improvements to handle longer texts effectively. We
evaluate JointKPE++ using BERT-based pre-trained models on grooming and drug
dealing datasets, including BERT, RoBERTa, SpanBERT, and BERTimbau. The results
show significant improvements over traditional approaches and demonstrate the
potential for JointKPE++ to aid forensic experts in efficiently detecting
keyphrases related to criminal activities.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04906" title="Abstract">arXiv:2311.04906</a> [<a href="/pdf/2311.04906" title="Download PDF">pdf</a>, <a href="/format/2311.04906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlaCGEC: A Chinese Grammatical Error Correction Dataset with  Fine-grained Linguistic Annotation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Hanyue Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yike Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qingyuan Tian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiani Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+Y">Yunshi Lan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xuesong Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Chinese Grammatical Error Correction (CGEC) has been attracting growing
attention from researchers recently. In spite of the fact that multiple CGEC
datasets have been developed to support the research, these datasets lack the
ability to provide a deep linguistic topology of grammar errors, which is
critical for interpreting and diagnosing CGEC approaches. To address this
limitation, we introduce FlaCGEC, which is a new CGEC dataset featured with
fine-grained linguistic annotation. Specifically, we collect raw corpus from
the linguistic schema defined by Chinese language experts, conduct edits on
sentences via rules, and refine generated samples manually, which results in
10k sentences with 78 instantiated grammar points and 3 types of edits. We
evaluate various cutting-edge CGEC methods on the proposed FlaCGEC dataset and
their unremarkable results indicate that this dataset is challenging in
covering a large range of grammatical errors. In addition, we also treat
FlaCGEC as a diagnostic dataset for testing generalization skills and conduct a
thorough evaluation of existing CGEC models.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04907" title="Abstract">arXiv:2311.04907</a> [<a href="/pdf/2311.04907" title="Download PDF">pdf</a>, <a href="/ps/2311.04907" title="Download PostScript">ps</a>, <a href="/format/2311.04907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In nomine patris... Elements for a semantics of medieval paternity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Perreaux%2C+N">Nicolas Perreaux</a> (LAMOP)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in French language
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> L{\'e}o Dumont, Octave Julien et St{\'e}phane Lamass{\'e} (dir.),
  Histoire de mots. Saisir le pass{\'e} gr{\^a}ce aux donn{\'e}es textuelles,
  {\'E}ditions de la Sorbonne, Paris, 2023, {\'E}ditions de la Sorbonne, A
  para{\^i}tre
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">This article examines medieval concepts of paternity and father-son
relationships through the digital analysis of medieval textual corpora.
Although historians have access to enormous digital collections in 2023, they
have rarely fully exploited these resources. The author proposes a historical
semantic approach to this theme, using modeling tools and text mining in
general, to analyze the evolution of terms related to paternity. The study
proposes three conclusions: 1. a semantic break occurred in the semantic field
of paternity at the turn of Antiquity and the Early Middle Ages. The meaning of
pater and its derivatives changed radically over the course of the 4th-6th
centuries, particularly as a result of the influence of the dogma of the
Christian Trinity. Medieval fatherhood was multidimensional, encompassing both
biological and spiritual aspects, in other words, complex relationships between
multiple carnal and spiritual (i.e. divine) fathers. 2. The role of spiritual
kinship is crucial to understanding medieval fatherhood, as the work of Anita
Guerreau-Jalabert and J{\'e}r{\^o}me Baschet has already shown. Initially
attributed to God, this ''ideal paternity'' (paternitas) gradually extended to
members of the Church (popes, bishops, abbots), underlining at the same time
the growing importance of spiritual kinship over biological kinship over the
centuries studied. 3. To reveal these structures, invisible to the naked eye,
an interdisciplinary approach is rigorously required. Complementary
investigations into the lemmas mater, filia, frater and other family terms are
required. The use of digital tools and historical semantic analysis opens up
new perspectives for researchers in history, anthropology, linguistics and data
mining, enabling them to explore the representation systems of ancient
societies in depth and with nuance.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04908" title="Abstract">arXiv:2311.04908</a> [<a href="/pdf/2311.04908" title="Download PDF">pdf</a>, <a href="/format/2311.04908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Education journal rankings: A diversity-based Author Affiliation Index  assessment methodology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yan-Hong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Y">Ying-Hui Shao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">Determining the reputation of academic journals is an crucial issue. The
Author Affiliation Index (AAI) was proposed as a novel indicator for judging
journal quality in many academic disciplines. Nevertheless, the original AAI
has several potential limitations, some of which have been discussed and
addressed in previous studies. In this paper, we modified the original AAI by
incorporating diversity of top-notch institutions, namely the AAID, exploring
how institutional diversity is related to journal quality assessment. We
further conducted a quality assessment of 263 education journals indexed in the
Social Sciences Citation Index (SSCI) by applying the AAID, AAI and weighted
AAI. We find that the AAID ranking possesses a low correlation coefficient with
the Journal Impact Factor (JIF) and Eigenfactor Score (ES). That is to say, the
AAID rating has not reached a good agreement with the most popular ranking
indicators JIF and ES for journals in the field of education. Moreover, we
analyze the reasons for the highest AAID from the structure of complex
networks. Overall, the AAID is an alternative indicator for evaluating the
prestige of journals from a new perspective.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04909" title="Abstract">arXiv:2311.04909</a> [<a href="/pdf/2311.04909" title="Download PDF">pdf</a>, <a href="/ps/2311.04909" title="Download PostScript">ps</a>, <a href="/format/2311.04909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Streetlight Effect in Post-Publication Peer Review: Are Open Access  Publications More Scrutinized?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maddi%2C+A">Abdelghani Maddi</a> (GEMASS), 
<a href="/search/cs?searchtype=author&query=Monneau%2C+E">Emmanuel Monneau</a> (GEMASS), 
<a href="/search/cs?searchtype=author&query=Gaspare%2C+C">Catherine Gaspare</a> (GEMASS), 
<a href="/search/cs?searchtype=author&query=Gargiulo%2C+F">Floriana Gargiulo</a> (GEMASS), 
<a href="/search/cs?searchtype=author&query=Dubois%2C+M">Michel Dubois</a> (GEMASS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">The Streetlight Effect represents an observation bias that occurs when
individuals search for something only where it is easiest to look. Despite the
significant development of Post-Publication Peer Review (PPPR) in recent years,
facilitated in part by platforms such as PubPeer, existing literature has not
examined whether PPPR is affected by this type of bias. In other words, if the
PPPR mainly concerns publications to which researchers have direct access (eg
to analyze image duplications, etc.). In this study, we compare the Open Access
(OA) structures of publishers and journals among 51,882 publications commented
on PubPeer to those indexed in OpenAlex database (\#156,700,177). Our findings
indicate that OA journals are 33% more prevalent in PubPeer than in the global
total (52% for the most commented journals). This result can be attributed to
disciplinary bias in PubPeer, with overrepresentation of medical and biological
research (which exhibits higher levels of openness). However, after
normalization, the results reveal that PPPR does not exhibit a Streetlight
Effect, as OA publications, within the same discipline, are on average 16% less
prevalent in PubPeer than in the global total. These results suggest that the
process of scientific self-correction operates independently of publication
access status.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04910" title="Abstract">arXiv:2311.04910</a> [<a href="/pdf/2311.04910" title="Download PDF">pdf</a>, <a href="/ps/2311.04910" title="Download PostScript">ps</a>, <a href="/format/2311.04910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ontology-Driven Processing of Transdisciplinary Domain Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Palagin%2C+O">Oleksandr Palagin</a>, 
<a href="/search/cs?searchtype=author&query=Petrenko%2C+M">Mykola Petrenko</a>, 
<a href="/search/cs?searchtype=author&query=Kryvyi%2C+S">Sergii Kryvyi</a>, 
<a href="/search/cs?searchtype=author&query=Boyko%2C+M">Mykola Boyko</a>, 
<a href="/search/cs?searchtype=author&query=Malakhov%2C+K">Kyrylo Malakhov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MONOGRAPH Scientific publication (issue). Published By Iowa State University Digital Press; ISBN 978-1-958291-06-1; 189 pages; The text of this monograph is in Ukrainian. Published July 14, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">The monograph discusses certain aspects of modern real-world problems facing
humanity, which are much more challenging than scientific ones. Modern science
is unable to solve them in a fundamental way. Vernadsky's noosphere thesis, in
fact, appeals to the scientific worldview that needs to be built in a way that
overcomes the interdisciplinary barriers and increases the effectiveness of
interdisciplinary interaction and modern science overall. We are talking about
the general transdisciplinary knowledge. In world practice, there is still no
systematic methodology and a specific form of generally accepted valid
scientific theory that would provide transdisciplinary knowledge. Non-linear
interdisciplinary interaction is the standard of evolution of modern science.
At the same time, a new transdisciplinary theory (domain of scientific
research) is being de facto created and the process is repeated many times:
from an individual or group of disciplines, through interdisciplinary
interaction, in a direction that brings us closer to creating a holistic
general scientific worldview.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04911" title="Abstract">arXiv:2311.04911</a> [<a href="/pdf/2311.04911" title="Download PDF">pdf</a>, <a href="/format/2311.04911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Text to Structure: Using Large Language Models to Support the  Development of Legal Expert Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Janatian%2C+S">Samyar Janatian</a>, 
<a href="/search/cs?searchtype=author&query=Westermann%2C+H">Hannes Westermann</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+J">Jinzhe Tan</a>, 
<a href="/search/cs?searchtype=author&query=Savelka%2C+J">Jaromir Savelka</a>, 
<a href="/search/cs?searchtype=author&query=Benyekhlef%2C+K">Karim Benyekhlef</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in the proceedings of the 36th International Conference on Legal Knowledge and Information Systems (JURIX 2023). Code and prompt available at <a href="https://github.com/samyarj/JCAPG-JURIX2023">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Encoding legislative text in a formal representation is an important
prerequisite to different tasks in the field of AI &amp; Law. For example,
rule-based expert systems focused on legislation can support laypeople in
understanding how legislation applies to them and provide them with helpful
context and information. However, the process of analyzing legislation and
other sources to encode it in the desired formal representation can be
time-consuming and represents a bottleneck in the development of such systems.
Here, we investigate to what degree large language models (LLMs), such as
GPT-4, are able to automatically extract structured representations from
legislation. We use LLMs to create pathways from legislation, according to the
JusticeBot methodology for legal decision support systems, evaluate the
pathways and compare them to manually created pathways. The results are
promising, with 60% of generated pathways being rated as equivalent or better
than manually created ones in a blind comparison. The approach suggests a
promising path to leverage the capabilities of LLMs to ease the costly
development of systems based on symbolic approaches that are transparent and
explainable.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04912" title="Abstract">arXiv:2311.04912</a> [<a href="/pdf/2311.04912" title="Download PDF">pdf</a>, <a href="/ps/2311.04912" title="Download PostScript">ps</a>, <a href="/format/2311.04912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ezBIDS: Guided standardization of neuroimaging data interoperable with  major data archives and platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Levitas%2C+D">Daniel Levitas</a>, 
<a href="/search/cs?searchtype=author&query=Hayashi%2C+S">Soichi Hayashi</a>, 
<a href="/search/cs?searchtype=author&query=Vinci-Booher%2C+S">Sophia Vinci-Booher</a>, 
<a href="/search/cs?searchtype=author&query=Heinsfeld%2C+A">Anibal Heinsfeld</a>, 
<a href="/search/cs?searchtype=author&query=Bhatia%2C+D">Dheeraj Bhatia</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+N">Nicholas Lee</a>, 
<a href="/search/cs?searchtype=author&query=Galassi%2C+A">Anthony Galassi</a>, 
<a href="/search/cs?searchtype=author&query=Niso%2C+G">Guiomar Niso</a>, 
<a href="/search/cs?searchtype=author&query=Pestilli%2C+F">Franco Pestilli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Data standardization has become one of the leading methods neuroimaging
researchers rely on for data sharing and reproducibility. Data standardization
promotes a common framework through which researchers can utilize others' data.
Yet, as of today, formatting datasets that adhere to community best practices
requires technical expertise involving coding and considerable knowledge of
file formats and standards. We describe ezBIDS, a tool for converting
neuroimaging data and associated metadata to the Brain Imaging Data Structure
(BIDS) standard. ezBIDS provides four unique features: (1) No installation or
programming requirements. (2) Handling of both imaging and task events data and
metadata. (3) Automated inference and guidance for adherence to BIDS. (4)
Multiple data management options: download BIDS data to local system, or
transfer to OpenNeuro.org or brainlife.io. In sum, ezBIDS requires neither
coding proficiency nor knowledge of BIDS and is the first BIDS tool to offer
guided standardization, support for task events conversion, and
interoperability with OpenNeuro and brainlife.io.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04913" title="Abstract">arXiv:2311.04913</a> [<a href="/pdf/2311.04913" title="Download PDF">pdf</a>, <a href="/ps/2311.04913" title="Download PostScript">ps</a>, <a href="/format/2311.04913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Improved Transformer-based Model for Detecting Phishing, Spam, and  Ham: A Large Language Model Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jamal%2C+S">Suhaima Jamal</a>, 
<a href="/search/cs?searchtype=author&query=Wimmer%2C+H">Hayden Wimmer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Phishing and spam detection is long standing challenge that has been the
subject of much academic research. Large Language Models (LLM) have vast
potential to transform society and provide new and innovative approaches to
solve well-established challenges. Phishing and spam have caused financial
hardships and lost time and resources to email users all over the world and
frequently serve as an entry point for ransomware threat actors. While
detection approaches exist, especially heuristic-based approaches, LLMs offer
the potential to venture into a new unexplored area for understanding and
solving this challenge. LLMs have rapidly altered the landscape from business,
consumers, and throughout academia and demonstrate transformational potential
for the potential of society. Based on this, applying these new and innovative
approaches to email detection is a rational next step in academic research. In
this work, we present IPSDM, our model based on fine-tuning the BERT family of
models to specifically detect phishing and spam email. We demonstrate our
fine-tuned version, IPSDM, is able to better classify emails in both unbalanced
and balanced datasets. This work serves as an important first step towards
employing LLMs to improve the security of our information systems.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04915" title="Abstract">arXiv:2311.04915</a> [<a href="/pdf/2311.04915" title="Download PDF">pdf</a>, <a href="/ps/2311.04915" title="Download PostScript">ps</a>, <a href="/format/2311.04915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chain of Empathy: Enhancing Empathetic Response of Large Language Models  Based on Psychotherapy Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y+K">Yoon Kyung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+I">Inju Lee</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+M">Minjung Shin</a>, 
<a href="/search/cs?searchtype=author&query=Bae%2C+S">Seoyeon Bae</a>, 
<a href="/search/cs?searchtype=author&query=Hahn%2C+S">Sowon Hahn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">We present a novel method, the Chain of Empathy (CoE) prompting, that
utilizes insights from psychotherapy to induce Large Language Models (LLMs) to
reason about human emotional states. This method is inspired by various
psychotherapy approaches including Cognitive Behavioral Therapy (CBT),
Dialectical Behavior Therapy (DBT), Person Centered Therapy (PCT), and Reality
Therapy (RT), each leading to different patterns of interpreting clients'
mental states. LLMs without reasoning generated predominantly exploratory
responses. However, when LLMs used CoE reasoning, we found a more comprehensive
range of empathetic responses aligned with the different reasoning patterns of
each psychotherapy model. The CBT based CoE resulted in the most balanced
generation of empathetic responses. The findings underscore the importance of
understanding the emotional context and how it affects human and AI
communication. Our research contributes to understanding how psychotherapeutic
models can be incorporated into LLMs, facilitating the development of
context-specific, safer, and empathetic AI.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04916" title="Abstract">arXiv:2311.04916</a> [<a href="/pdf/2311.04916" title="Download PDF">pdf</a>, <a href="/format/2311.04916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable Identification of Hate Speech towards Islam using Graph  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wasi%2C+A+T">Azmine Toushik Wasi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages, 2 figures; NeurIPS 2023 Workshop Muslims in ML. Openreview forum: <a href="https://openreview.net/forum?id=jG3Y7bA94N">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Islamophobic language is a prevalent challenge on online social interaction
platforms. Identifying and eliminating such hatred is a crucial step towards a
future of harmony and peace. This study presents a novel paradigm for
identifying and explaining hate speech towards Islam using graph neural
networks. Utilizing the intrinsic ability of graph neural networks to find,
extract, and use relationships across disparate data points, our model
consistently achieves outstanding performance while offering explanations for
the underlying correlations and causation.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04917" title="Abstract">arXiv:2311.04917</a> [<a href="/pdf/2311.04917" title="Download PDF">pdf</a>, <a href="/format/2311.04917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapting Fake News Detection to the Era of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+J">Jinyan Su</a>, 
<a href="/search/cs?searchtype=author&query=Cardie%2C+C">Claire Cardie</a>, 
<a href="/search/cs?searchtype=author&query=Nakov%2C+P">Preslav Nakov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the age of large language models (LLMs) and the widespread adoption of
AI-driven content creation, the landscape of information dissemination has
witnessed a paradigm shift. With the proliferation of both human-written and
machine-generated real and fake news, robustly and effectively discerning the
veracity of news articles has become an intricate challenge. While substantial
research has been dedicated to fake news detection, this either assumes that
all news articles are human-written or abruptly assumes that all
machine-generated news are fake. Thus, a significant gap exists in
understanding the interplay between machine-(paraphrased) real news,
machine-generated fake news, human-written fake news, and human-written real
news. In this paper, we study this gap by conducting a comprehensive evaluation
of fake news detectors trained in various scenarios. Our primary objectives
revolve around the following pivotal question: How to adapt fake news detectors
to the era of LLMs? Our experiments reveal an interesting pattern that
detectors trained exclusively on human-written articles can indeed perform well
at detecting machine-generated fake news, but not vice versa. Moreover, due to
the bias of detectors against machine-generated texts \cite{su2023fake}, they
should be trained on datasets with a lower machine-generated news ratio than
the test set. Building on our findings, we provide a practical strategy for the
development of robust fake news detectors.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04918" title="Abstract">arXiv:2311.04918</a> [<a href="/pdf/2311.04918" title="Download PDF">pdf</a>, <a href="/format/2311.04918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Resource Named Entity Recognition: Can One-vs-All AUC Maximization  Help?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+N+D">Ngoc Dang Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+W">Wei Tan</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+L">Lan Du</a>, 
<a href="/search/cs?searchtype=author&query=Buntine%2C+W">Wray Buntine</a>, 
<a href="/search/cs?searchtype=author&query=Beare%2C+R">Richard Beare</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Changyou Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures, ICDM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Named entity recognition (NER), a task that identifies and categorizes named
entities such as persons or organizations from text, is traditionally framed as
a multi-class classification problem. However, this approach often overlooks
the issues of imbalanced label distributions, particularly in low-resource
settings, which is common in certain NER contexts, like biomedical NER
(bioNER). To address these issues, we propose an innovative reformulation of
the multi-class problem as a one-vs-all (OVA) learning problem and introduce a
loss function based on the area under the receiver operating characteristic
curve (AUC). To enhance the efficiency of our OVA-based approach, we propose
two training strategies: one groups labels with similar linguistic
characteristics, and another employs meta-learning. The superiority of our
approach is confirmed by its performance, which surpasses traditional NER
learning in varying NER settings.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04919" title="Abstract">arXiv:2311.04919</a> [<a href="/pdf/2311.04919" title="Download PDF">pdf</a>, <a href="/format/2311.04919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impact of Preference Agreement in Reinforcement Learning from Human  Feedback: A Case Study in Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gooding%2C+S">Sian Gooding</a>, 
<a href="/search/cs?searchtype=author&query=Mansoor%2C+H">Hassan Mansoor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Reinforcement Learning from Human Feedback (RLHF) can be used to capture
complex and nuanced properties of text generation quality. As a result, the
task of text summarization has been identified as a good candidate for this
process. In this paper, we explore how preference agreement impacts the
efficacy of RLHF for summarization. We show that sampling human preferences to
include a range of annotator agreement results in (1) higher accuracy reward
models and (2) alters the characteristics of quality captured. We additionally
show improvements in downstream generation when using a reward model trained
with a range of preference agreements. Our contributions have implications for
the design of synthetic datasets as well as the importance of considering
quality differentials in comparison-based data.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04921" title="Abstract">arXiv:2311.04921</a> [<a href="/pdf/2311.04921" title="Download PDF">pdf</a>, <a href="/format/2311.04921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Successor Features for Efficient Multisubject Controlled Text Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+M">Meng Cao</a>, 
<a href="/search/cs?searchtype=author&query=Fatemi%2C+M">Mehdi Fatemi</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+J+C+K">Jackie Chi Kit Cheung</a>, 
<a href="/search/cs?searchtype=author&query=Shabanian%2C+S">Samira Shabanian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">While large language models (LLMs) have achieved impressive performance in
generating fluent and realistic text, controlling the generated text so that it
exhibits properties such as safety, factuality, and non-toxicity remains
challenging. % such as DExperts, GeDi, and rectification Existing
decoding-based methods are static in terms of the dimension of control; if the
target subject is changed, they require new training. Moreover, it can quickly
become prohibitive to concurrently control multiple subjects. In this work, we
introduce SF-GEN, which is grounded in two primary concepts: successor features
(SFs) to decouple the LLM's dynamics from task-specific rewards, and language
model rectification to proportionally adjust the probability of selecting a
token based on the likelihood that the finished text becomes undesired. SF-GEN
seamlessly integrates the two to enable dynamic steering of text generation
with no need to alter the LLM's parameters. Thanks to the decoupling effect
induced by successor features, our method proves to be memory-wise and
computationally efficient for training as well as decoding, especially when
dealing with multiple target subjects. To the best of our knowledge, our
research represents the first application of successor features in text
generation. In addition to its computational efficiency, the resultant language
produced by our method is comparable to the SOTA (and outperforms baselines) in
both control measures as well as language quality, which we demonstrate through
a series of experiments in various controllable text generation tasks.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04922" title="Abstract">arXiv:2311.04922</a> [<a href="/pdf/2311.04922" title="Download PDF">pdf</a>, <a href="/format/2311.04922" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are cascade dialogue state tracking models speaking out of turn in  spoken dialogues?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Druart%2C+L">Lucas Druart</a> (LIA), 
<a href="/search/cs?searchtype=author&query=Jacqmin%2C+L">L&#xe9;o Jacqmin</a> (LIS), 
<a href="/search/cs?searchtype=author&query=Favre%2C+B">Beno&#xee;t Favre</a> (LIS), 
<a href="/search/cs?searchtype=author&query=Rojas-Barahona%2C+L+M">Lina Maria Rojas-Barahona</a>, 
<a href="/search/cs?searchtype=author&query=Vielzeuf%2C+V">Valentin Vielzeuf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE ICASSP 2024{\copyright} 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">In Task-Oriented Dialogue (TOD) systems, correctly updating the system's
understanding of the user's needs is key to a smooth interaction. Traditionally
TOD systems are composed of several modules that interact with one another.
While each of these components is the focus of active research communities,
their behavior in interaction can be overlooked. This paper proposes a
comprehensive analysis of the errors of state of the art systems in complex
settings such as Dialogue State Tracking which highly depends on the dialogue
context. Based on spoken MultiWoz, we identify that errors on non-categorical
slots' values are essential to address in order to bridge the gap between
spoken and chat-based dialogue systems. We explore potential solutions to
improve transcriptions and help dialogue state tracking generative models
correct such errors.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04923" title="Abstract">arXiv:2311.04923</a> [<a href="/pdf/2311.04923" title="Download PDF">pdf</a>, <a href="/format/2311.04923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is one brick enough to break the wall of spoken dialogue state tracking?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Druart%2C+L">Lucas Druart</a> (LIA), 
<a href="/search/cs?searchtype=author&query=Vielzeuf%2C+V">Valentin Vielzeuf</a>, 
<a href="/search/cs?searchtype=author&query=Est%C3%A8ve%2C+Y">Yannick Est&#xe8;ve</a> (LIA)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE ICASSP 2024{\copyright} 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">In Task-Oriented Dialogue (TOD) systems, correctly updating the system's
understanding of the user's needs (a.k.a dialogue state tracking) is key to a
smooth interaction. Traditionally, TOD systems perform this update in three
steps: transcription of the user's utterance, semantic extraction of the key
concepts, and contextualization with the previously identified concepts. Such
cascade approaches suffer from cascading errors and separate optimization.
End-to-End approaches have been proved helpful up to the semantic extraction
step. This paper goes one step further paving the path towards completely
neural spoken dialogue state tracking by comparing three approaches: (1) a
state of the art cascade approach, (2) a locally E2E approach with rule-based
contextualization and (3) a completely neural approach. Our study highlights
that although they all outperform the recent DSTC11 best model, especially with
a filtering post-processing step, (1) remains the most accurate approach.
Indeed, both (2) and (3) have trouble propagating context as dialogues unfold
showing that context propagation in completely neural approaches is an open
challenge.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04924" title="Abstract">arXiv:2311.04924</a> [<a href="/pdf/2311.04924" title="Download PDF">pdf</a>, <a href="/ps/2311.04924" title="Download PostScript">ps</a>, <a href="/format/2311.04924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tuning-less Object Naming with a Foundation Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lucny%2C+A">Andrej Lucny</a>, 
<a href="/search/cs?searchtype=author&query=Petrovic%2C+P">Pavel Petrovic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://github.com/andylucny/whatisthis">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> http://people.elfa.sk/~fejedelems/DISA2023_conference_proceedings.pdf
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We implement a real-time object naming system that enables learning a set of
named entities never seen. Our approach employs an existing foundation model
that we consider ready to see anything before starting. It turns seen images
into relatively small feature vectors that we associate with index to a
gradually built vocabulary without any training of fine-tuning of the model.
Our contribution is using the association mechanism known from transformers as
attention. It has features that support generalization from irrelevant
information for distinguishing the entities and potentially enable associating
with much more than indices to vocabulary. As a result, the system can work in
a one-shot manner and correctly name objects named in different contents. We
also outline implementation details of the system modules integrated by a
blackboard architecture. Finally, we investigate the system's quality, mainly
how many objects it can handle in this way.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04925" title="Abstract">arXiv:2311.04925</a> [<a href="/pdf/2311.04925" title="Download PDF">pdf</a>, <a href="/ps/2311.04925" title="Download PostScript">ps</a>, <a href="/format/2311.04925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating Deep-Learning NLP for Automating the Extraction of  Oncology Efficacy Endpoints from Scientific Literature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gendrin-Brokmann%2C+A">Aline Gendrin-Brokmann</a>, 
<a href="/search/cs?searchtype=author&query=Harrison%2C+E">Eden Harrison</a>, 
<a href="/search/cs?searchtype=author&query=Noveras%2C+J">Julianne Noveras</a>, 
<a href="/search/cs?searchtype=author&query=Souliotis%2C+L">Leonidas Souliotis</a>, 
<a href="/search/cs?searchtype=author&query=Vince%2C+H">Harris Vince</a>, 
<a href="/search/cs?searchtype=author&query=Smit%2C+I">Ines Smit</a>, 
<a href="/search/cs?searchtype=author&query=Costa%2C+F">Francisco Costa</a>, 
<a href="/search/cs?searchtype=author&query=Milward%2C+D">David Milward</a>, 
<a href="/search/cs?searchtype=author&query=Dimitrievska%2C+S">Sashka Dimitrievska</a>, 
<a href="/search/cs?searchtype=author&query=Metcalfe%2C+P">Paul Metcalfe</a>, 
<a href="/search/cs?searchtype=author&query=Louvet%2C+E">Emilie Louvet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Benchmarking drug efficacy is a critical step in clinical trial design and
planning. The challenge is that much of the data on efficacy endpoints is
stored in scientific papers in free text form, so extraction of such data is
currently a largely manual task. Our objective is to automate this task as much
as possible. In this study we have developed and optimised a framework to
extract efficacy endpoints from text in scientific papers, using a machine
learning approach. Our machine learning model predicts 25 classes associated
with efficacy endpoints and leads to high F1 scores (harmonic mean of precision
and recall) of 96.4% on the test set, and 93.9% and 93.7% on two case studies.
These methods were evaluated against - and showed strong agreement with -
subject matter experts and show significant promise in the future of automating
the extraction of clinical endpoints from free text. Clinical information
extraction from text data is currently a laborious manual task which scales
poorly and is prone to human error. Demonstrating the ability to extract
efficacy endpoints automatically shows great promise for accelerating clinical
trial design moving forwards.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04926" title="Abstract">arXiv:2311.04926</a> [<a href="/pdf/2311.04926" title="Download PDF">pdf</a>, <a href="/format/2311.04926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> More Robots are Coming: Large Multimodal Models (ChatGPT) can Solve  Visually Diverse Images of Parsons Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+I">Irene Hou</a>, 
<a href="/search/cs?searchtype=author&query=Man%2C+O">Owen Man</a>, 
<a href="/search/cs?searchtype=author&query=Mettille%2C+S">Sophie Mettille</a>, 
<a href="/search/cs?searchtype=author&query=Gutierrez%2C+S">Sebastian Gutierrez</a>, 
<a href="/search/cs?searchtype=author&query=Angelikas%2C+K">Kenneth Angelikas</a>, 
<a href="/search/cs?searchtype=author&query=MacNeil%2C+S">Stephen MacNeil</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The advent of large language models is reshaping computing education. Recent
research has demonstrated that these models can produce better explanations
than students, answer multiple-choice questions at or above the class average,
and generate code that can pass automated tests in introductory courses. These
capabilities have prompted instructors to rapidly adapt their courses and
assessment methods to accommodate changes in learning objectives and the
potential for academic integrity violations. While some scholars have advocated
for the integration of visual problems as a safeguard against the capabilities
of language models, new multimodal language models now have vision and language
capabilities that may allow them to analyze and solve visual problems. In this
paper, we evaluate the performance of two large multimodal models on visual
assignments, with a specific focus on Parsons problems presented across diverse
visual representations. Our results show that GPT-4V solved 96.7\% of these
visual problems, struggling minimally with a single Parsons problem.
Conversely, Bard performed poorly by only solving 69.2\% of problems,
struggling with common issues like hallucinations and refusals. These findings
suggest that merely transitioning to visual programming problems might not be a
panacea to issues of academic integrity in the generative AI era.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04927" title="Abstract">arXiv:2311.04927</a> [<a href="/pdf/2311.04927" title="Download PDF">pdf</a>, <a href="/format/2311.04927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contextualizing the Limits of Model &amp; Evaluation Dataset Curation on  Semantic Similarity Classification Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Theron%2C+D">Daniel Theron</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in EMNLP 2023 GEM Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper demonstrates how the limitations of pre-trained models and open
evaluation datasets factor into assessing the performance of binary semantic
similarity classification tasks. As (1) end-user-facing documentation around
the curation of these datasets and pre-trained model training regimes is often
not easily accessible and (2) given the lower friction and higher demand to
quickly deploy such systems in real-world contexts, our study reinforces prior
work showing performance disparities across datasets, embedding techniques and
distance metrics, while highlighting the importance of understanding how data
is collected, curated and analyzed in semantic similarity classification.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04928" title="Abstract">arXiv:2311.04928</a> [<a href="/pdf/2311.04928" title="Download PDF">pdf</a>, <a href="/format/2311.04928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Large Language Models for Collective Decision-Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Papachristou%2C+M">Marios Papachristou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Longqi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+C">Chin-Chia Hsu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">In various work contexts, such as meeting scheduling, collaborating, and
project planning, collective decision-making is essential but often challenging
due to diverse individual preferences, varying work focuses, and power dynamics
among members. To address this, we propose a system leveraging Large Language
Models (LLMs) to facilitate group decision-making by managing conversations and
balancing preferences among individuals. Our system extracts individual
preferences and suggests options that satisfy a significant portion of the
members. We apply this system to corporate meeting scheduling. We create
synthetic employee profiles and simulate conversations at scale, leveraging
LLMs to evaluate the system. Our results indicate efficient coordination with
reduced interactions between members and the LLM-based system. The system also
effectively refines proposed options over time, ensuring their quality and
equity. Finally, we conduct a survey study involving human participants to
assess our system's ability to aggregate preferences and reasoning. Our
findings show that the system exhibits strong performance in both dimensions.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04929" title="Abstract">arXiv:2311.04929</a> [<a href="/pdf/2311.04929" title="Download PDF">pdf</a>, <a href="/format/2311.04929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Interdisciplinary Outlook on Large Language Models for Scientific  Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boyko%2C+J">James Boyko</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+J">Joseph Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Fox%2C+N">Nathan Fox</a>, 
<a href="/search/cs?searchtype=author&query=Veiga%2C+M+H">Maria Han Veiga</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J+I">Jennifer I-Hsiu Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Modenesi%2C+B">Bernardo Modenesi</a>, 
<a href="/search/cs?searchtype=author&query=Rauch%2C+A+H">Andreas H. Rauch</a>, 
<a href="/search/cs?searchtype=author&query=Reid%2C+K+N">Kenneth N. Reid</a>, 
<a href="/search/cs?searchtype=author&query=Tribedi%2C+S">Soumi Tribedi</a>, 
<a href="/search/cs?searchtype=author&query=Visheratina%2C+A">Anastasia Visheratina</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xin Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Digital Libraries (cs.DL); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we describe the capabilities and constraints of Large Language
Models (LLMs) within disparate academic disciplines, aiming to delineate their
strengths and limitations with precision. We examine how LLMs augment
scientific inquiry, offering concrete examples such as accelerating literature
review by summarizing vast numbers of publications, enhancing code development
through automated syntax correction, and refining the scientific writing
process. Simultaneously, we articulate the challenges LLMs face, including
their reliance on extensive and sometimes biased datasets, and the potential
ethical dilemmas stemming from their use. Our critical discussion extends to
the varying impacts of LLMs across fields, from the natural sciences, where
they help model complex biological sequences, to the social sciences, where
they can parse large-scale qualitative data. We conclude by offering a nuanced
perspective on how LLMs can be both a boon and a boundary to scientific
progress.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04930" title="Abstract">arXiv:2311.04930</a> [<a href="/pdf/2311.04930" title="Download PDF">pdf</a>, <a href="/format/2311.04930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large language models implicitly learn to straighten neural sentence  trajectories to construct a predictive representation of natural language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hosseini%2C+E+A">Eghbal A. Hosseini</a>, 
<a href="/search/cs?searchtype=author&query=Fedorenko%2C+E">Evelina Fedorenko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37th Conference on Neural Information Processing Systems (NeurIPS 2023). 20 pages, 5 main figures, 7 supplementary figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Predicting upcoming events is critical to our ability to interact with our
environment. Transformer models, trained on next-word prediction, appear to
construct representations of linguistic input that can support diverse
downstream tasks. But how does a predictive objective shape such
representations? Inspired by recent work in vision (Henaff et al., 2019), we
test a hypothesis about predictive representations of autoregressive
transformers. In particular, we test whether the neural trajectory of a
sentence becomes progressively straighter as it passes through the network
layers. The key insight is that straighter trajectories should facilitate
prediction via linear extrapolation. We quantify straightness using a
1-dimensional curvature metric, and present four findings in support of the
trajectory straightening hypothesis: i) In trained models, the curvature
decreases from the early to the deeper layers of the network. ii) Models that
perform better on the next-word prediction objective exhibit greater decreases
in curvature, suggesting that this improved ability to straighten sentence
trajectories may be the driver of better language modeling performance. iii)
Given the same linguistic context, the sequences that are generated by the
model have lower curvature than the actual continuations observed in a language
corpus, suggesting that the model favors straighter trajectories for making
predictions. iv) A consistent relationship holds between the average curvature
and the average surprisal of sentences in the deep model layers, such that
sentences with straighter trajectories also have lower surprisal. Importantly,
untrained models do not exhibit these behaviors. In tandem, these results
support the trajectory straightening hypothesis and provide a possible
mechanism for how the geometry of the internal representations of
autoregressive models supports next word prediction.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04931" title="Abstract">arXiv:2311.04931</a> [<a href="/pdf/2311.04931" title="Download PDF">pdf</a>, <a href="/format/2311.04931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPT4All: An Ecosystem of Open Source Compressed Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anand%2C+Y">Yuvanesh Anand</a>, 
<a href="/search/cs?searchtype=author&query=Nussbaum%2C+Z">Zach Nussbaum</a>, 
<a href="/search/cs?searchtype=author&query=Treat%2C+A">Adam Treat</a>, 
<a href="/search/cs?searchtype=author&query=Miller%2C+A">Aaron Miller</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+R">Richard Guo</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+B">Ben Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Community%2C+G">GPT4All Community</a>, 
<a href="/search/cs?searchtype=author&query=Duderstadt%2C+B">Brandon Duderstadt</a>, 
<a href="/search/cs?searchtype=author&query=Mulyar%2C+A">Andriy Mulyar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NLP-OSS at EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) have recently achieved human-level performance
on a range of professional and academic benchmarks. The accessibility of these
models has lagged behind their performance. State-of-the-art LLMs require
costly infrastructure; are only accessible via rate-limited, geo-locked, and
censored web interfaces; and lack publicly available code and technical
reports. In this paper, we tell the story of GPT4All, a popular open source
repository that aims to democratize access to LLMs. We outline the technical
details of the original GPT4All model family, as well as the evolution of the
GPT4All project from a single model into a fully fledged open source ecosystem.
It is our hope that this paper acts as both a technical overview of the
original GPT4All models as well as a case study on the subsequent growth of the
GPT4All open source ecosystem.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04932" title="Abstract">arXiv:2311.04932</a> [<a href="/pdf/2311.04932" title="Download PDF">pdf</a>, <a href="/format/2311.04932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GC-VTON: Predicting Globally Consistent and Occlusion Aware Local Flows  with Neighborhood Integrity Preservation for Virtual Try-on
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rawal%2C+H">Hamza Rawal</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+M+J">Muhammad Junaid Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Zaman%2C+F">Farooq Zaman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Flow based garment warping is an integral part of image-based virtual try-on
networks. However, optimizing a single flow predicting network for simultaneous
global boundary alignment and local texture preservation results in sub-optimal
flow fields. Moreover, dense flows are inherently not suited to handle
intricate conditions like garment occlusion by body parts or by other garments.
Forcing flows to handle the above issues results in various distortions like
texture squeezing, and stretching. In this work, we propose a novel approach
where we disentangle the global boundary alignment and local texture preserving
tasks via our GlobalNet and LocalNet modules. A consistency loss is then
employed between the two modules which harmonizes the local flows with the
global boundary alignment. Additionally, we explicitly handle occlusions by
predicting body-parts visibility mask, which is used to mask out the occluded
regions in the warped garment. The masking prevents the LocalNet from
predicting flows that distort texture to compensate for occlusions. We also
introduce a novel regularization loss (NIPR), that defines a criteria to
identify the regions in the warped garment where texture integrity is violated
(squeezed or stretched). NIPR subsequently penalizes the flow in those regions
to ensure regular and coherent warps that preserve the texture in local
neighborhoods. Evaluation on a widely used virtual try-on dataset demonstrates
strong performance of our network compared to the current SOTA methods.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04933" title="Abstract">arXiv:2311.04933</a> [<a href="/pdf/2311.04933" title="Download PDF">pdf</a>, <a href="/ps/2311.04933" title="Download PostScript">ps</a>, <a href="/format/2311.04933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Large Language Models in Ophthalmology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Holmes%2C+J">Jason Holmes</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+S">Shuyuan Ye</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shi-Nan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zihao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jinyu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Huan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Hong Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">Jie Zou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Y">Yi Shao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Purpose: The performance of three different large language models (LLMS)
(GPT-3.5, GPT-4, and PaLM2) in answering ophthalmology professional questions
was evaluated and compared with that of three different professional
populations (medical undergraduates, medical masters, and attending
physicians). Methods: A 100-item ophthalmology single-choice test was
administered to three different LLMs (GPT-3.5, GPT-4, and PaLM2) and three
different professional levels (medical undergraduates, medical masters, and
attending physicians), respectively. The performance of LLM was comprehensively
evaluated and compared with the human group in terms of average score,
stability, and confidence. Results: Each LLM outperformed undergraduates in
general, with GPT-3.5 and PaLM2 being slightly below the master's level, while
GPT-4 showed a level comparable to that of attending physicians. In addition,
GPT-4 showed significantly higher answer stability and confidence than GPT-3.5
and PaLM2. Conclusion: Our study shows that LLM represented by GPT-4 performs
better in the field of ophthalmology. With further improvements, LLM will bring
unexpected benefits in medical education and clinical decision making in the
near future.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04934" title="Abstract">arXiv:2311.04934</a> [<a href="/pdf/2311.04934" title="Download PDF">pdf</a>, <a href="/format/2311.04934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt Cache: Modular Attention Reuse for Low-Latency Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gim%2C+I">In Gim</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guojun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seung-seob Lee</a>, 
<a href="/search/cs?searchtype=author&query=Sarda%2C+N">Nikhil Sarda</a>, 
<a href="/search/cs?searchtype=author&query=Khandelwal%2C+A">Anurag Khandelwal</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+L">Lin Zhong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present Prompt Cache, an approach for accelerating inference for large
language models (LLM) by reusing attention states across different LLM prompts.
Many input prompts have overlapping text segments, such as system messages,
prompt templates, and documents provided for context. Our key insight is that
by precomputing and storing the attention states of these frequently occurring
text segments on the inference server, we can efficiently reuse them when these
segments appear in user prompts. Prompt Cache employs a schema to explicitly
define such reusable text segments, called prompt modules. The schema ensures
positional accuracy during attention state reuse and provides users with an
interface to access cached states in their prompt. Using a prototype
implementation, we evaluate Prompt Cache across several LLMs. We show that
Prompt Cache significantly reduce latency in time-to-first-token, especially
for longer prompts such as document-based question answering and
recommendations. The improvements range from 8x for GPU-based inference to 60x
for CPU-based inference, all while maintaining output accuracy and without the
need for model parameter modifications.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04935" title="Abstract">arXiv:2311.04935</a> [<a href="/pdf/2311.04935" title="Download PDF">pdf</a>, <a href="/format/2311.04935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Node-Bound Communities for Partition of Unity Interpolation on Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cavoretto%2C+R">Roberto Cavoretto</a>, 
<a href="/search/math?searchtype=author&query=De+Rossi%2C+A">Alessandra De Rossi</a>, 
<a href="/search/math?searchtype=author&query=Lancellotti%2C+S">Sandro Lancellotti</a>, 
<a href="/search/math?searchtype=author&query=Romaniello%2C+F">Federico Romaniello</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures. arXiv admin note: text overlap with <a href="/abs/2311.04299">arXiv:2311.04299</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Graph signal processing benefits significantly from the direct and highly
adaptable supplementary techniques offered by partition of unity methods (PUMs)
on graphs. In our approach, we demonstrate the generation of a partition of
unity solely based on the underlying graph structure, employing an algorithm
that relies exclusively on centrality measures and modularity, without
requiring the input of the number of subdomains. Subsequently, we integrate
PUMs with a local graph basis function (GBF) approximation method to develop
cost-effective global interpolation schemes. We also discuss numerical
experiments conducted on both synthetic and real datasets to assess the
performance of this presented technique.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04936" title="Abstract">arXiv:2311.04936</a> [<a href="/pdf/2311.04936" title="Download PDF">pdf</a>, <a href="/ps/2311.04936" title="Download PostScript">ps</a>, <a href="/format/2311.04936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A comparative analysis between Conformer-Transducer, Whisper, and  wav2vec2 for improving the child speech recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barcovschi%2C+A">Andrei Barcovschi</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+R">Rishabh Jain</a>, 
<a href="/search/cs?searchtype=author&query=Corcoran%2C+P">Peter Corcoran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at SpeD 23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Automatic Speech Recognition (ASR) systems have progressed significantly in
their performance on adult speech data; however, transcribing child speech
remains challenging due to the acoustic differences in the characteristics of
child and adult voices. This work aims to explore the potential of adapting
state-of-the-art Conformer-transducer models to child speech to improve child
speech recognition performance. Furthermore, the results are compared with
those of self-supervised wav2vec2 models and semi-supervised multi-domain
Whisper models that were previously finetuned on the same data. We demonstrate
that finetuning Conformer-transducer models on child speech yields significant
improvements in ASR performance on child speech, compared to the non-finetuned
models. We also show Whisper and wav2vec2 adaptation on different child speech
datasets. Our detailed comparative analysis shows that wav2vec2 provides the
most consistent performance improvements among the three methods studied.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04937" title="Abstract">arXiv:2311.04937</a> [<a href="/pdf/2311.04937" title="Download PDF">pdf</a>, <a href="/format/2311.04937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Clinical Benchmark for Emergency Care (MC-BEC): A  Comprehensive Benchmark for Evaluating Foundation Models in Emergency  Medicine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+E">Emma Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kansal%2C+A">Aman Kansal</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Julie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+B+T">Boyang Tom Jin</a>, 
<a href="/search/cs?searchtype=author&query=Reisler%2C+J+R">Julia Rachel Reisler</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D+A">David A Kim</a>, 
<a href="/search/cs?searchtype=author&query=Rajpurkar%2C+P">Pranav Rajpurkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We propose the Multimodal Clinical Benchmark for Emergency Care (MC-BEC), a
comprehensive benchmark for evaluating foundation models in Emergency Medicine
using a dataset of 100K+ continuously monitored Emergency Department visits
from 2020-2022. MC-BEC focuses on clinically relevant prediction tasks at
timescales from minutes to days, including predicting patient decompensation,
disposition, and emergency department (ED) revisit, and includes a standardized
evaluation framework with train-test splits and evaluation metrics. The
multimodal dataset includes a wide range of detailed clinical data, including
triage information, prior diagnoses and medications, continuously measured
vital signs, electrocardiogram and photoplethysmograph waveforms, orders placed
and medications administered throughout the visit, free-text reports of imaging
studies, and information on ED diagnosis, disposition, and subsequent revisits.
We provide performance baselines for each prediction task to enable the
evaluation of multimodal, multitask models. We believe that MC-BEC will
encourage researchers to develop more effective, generalizable, and accessible
foundation models for multimodal clinical data.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04938" title="Abstract">arXiv:2311.04938</a> [<a href="/pdf/2311.04938" title="Download PDF">pdf</a>, <a href="/ps/2311.04938" title="Download PostScript">ps</a>, <a href="/format/2311.04938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved DDIM Sampling with Moment Matching Gaussian Mixtures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gabbur%2C+P">Prasad Gabbur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose using a Gaussian Mixture Model (GMM) as reverse transition
operator (kernel) within the Denoising Diffusion Implicit Models (DDIM)
framework, which is one of the most widely used approaches for accelerated
sampling from pre-trained Denoising Diffusion Probabilistic Models (DDPM).
Specifically we match the first and second order central moments of the DDPM
forward marginals by constraining the parameters of the GMM. We see that moment
matching is sufficient to obtain samples with equal or better quality than the
original DDIM with Gaussian kernels. We provide experimental results with
unconditional models trained on CelebAHQ and FFHQ and class-conditional models
trained on ImageNet datasets respectively. Our results suggest that using the
GMM kernel leads to significant improvements in the quality of the generated
samples when the number of sampling steps is small, as measured by FID and IS
metrics. For example on ImageNet 256x256, using 10 sampling steps, we achieve a
FID of 6.94 and IS of 207.85 with a GMM kernel compared to 10.15 and 196.73
respectively with a Gaussian kernel.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04939" title="Abstract">arXiv:2311.04939</a> [<a href="/pdf/2311.04939" title="Download PDF">pdf</a>, <a href="/format/2311.04939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LooGLE: Can Long-Context Language Models Understand Long Contexts?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiaqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mengmeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zilong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Muhan Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs), despite their impressive performance in various
language tasks, are typically limited to processing texts within context-window
size. This limitation has spurred significant research efforts to enhance LLMs'
long-context understanding with high-quality long-sequence benchmarks. However,
prior datasets in this regard suffer from shortcomings, such as short context
length compared to the context window of modern LLMs; outdated documents that
have data leakage problems; and an emphasis on short dependency tasks rather
than long dependency tasks. In this paper, we present LooGLE, a Long Context
Generic Language Evaluation benchmark for LLMs' long context understanding.
LooGLE features relatively new documents post-2022, with over 24,000 tokens per
document and 6,000 newly generated questions spanning diverse domains. Human
annotators meticulously crafted more than 1,100 high-quality question-answer
pairs to meet the long dependency requirements. These pairs underwent thorough
cross-validation, yielding the most precise assessment of LLMs' long dependency
capabilities. The evaluation of eight state-of-the-art LLMs on LooGLE revealed
key findings: (i) commercial models outperformed open-sourced models; (ii) LLMs
excelled in short dependency tasks like short question-answering and cloze
tasks but struggled with more intricate long dependency tasks; (iii) in-context
learning and chaining thoughts offered only marginal improvements; (iv)
retrieval-based techniques demonstrated substantial benefits for short
question-answering, while strategies for extending context window length had
limited impact on long context understanding. As such, LooGLE not only provides
a systematic and comprehensive evaluation schema on long-context LLMs, but also
sheds light on future development of enhanced models towards "true long-context
understanding".
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04940" title="Abstract">arXiv:2311.04940</a> [<a href="/pdf/2311.04940" title="Download PDF">pdf</a>, <a href="/ps/2311.04940" title="Download PostScript">ps</a>, <a href="/format/2311.04940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable Geoscience Artificial Intelligence (XGeoS-AI): Application  to Demystify Image Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jin-Jian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chao-Sheng Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lin Li</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Bin Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">As Earth science enters the era of big data, artificial intelligence (AI) not
only offers great potential for solving geoscience problems, but also plays a
critical role in accelerating the understanding of the complex, interactive,
and multiscale processes of Earth's behavior. As geoscience AI models are
progressively utilized for significant predictions in crucial situations,
geoscience researchers are increasingly demanding their interpretability and
versatility. This study proposes an interpretable geoscience artificial
intelligence (XGeoS-AI) framework to unravel the mystery of image recognition
in the Earth sciences, and its effectiveness and versatility is demonstrated by
taking computed tomography (CT) image recognition as an example. Inspired by
the mechanism of human vision, the proposed XGeoS-AI framework generates a
threshold value from a local region within the whole image to complete the
recognition. Different kinds of artificial intelligence (AI) methods, such as
Support Vector Regression (SVR), Multilayer Perceptron (MLP), Convolutional
Neural Network (CNN), can be adopted as the AI engines of the proposed XGeoS-AI
framework to efficiently complete geoscience image recognition tasks.
Experimental results demonstrate that the effectiveness, versatility, and
heuristics of the proposed framework have great potential in solving geoscience
image recognition problems. Interpretable AI should receive more and more
attention in the field of the Earth sciences, which is the key to promoting
more rational and wider applications of AI in the field of Earth sciences. In
addition, the proposed interpretable framework may be the forerunner of
technological innovation in the Earth sciences.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04943" title="Abstract">arXiv:2311.04943</a> [<a href="/pdf/2311.04943" title="Download PDF">pdf</a>, <a href="/format/2311.04943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MathNAS: If Blocks Have a Role in Mathematical Architecture Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qinsi%2C+W">Wang Qinsi</a>, 
<a href="/search/cs?searchtype=author&query=Jinhan%2C+K">Ke Jinhan</a>, 
<a href="/search/cs?searchtype=author&query=Zhi%2C+L">Liang Zhi</a>, 
<a href="/search/cs?searchtype=author&query=Sihai%2C+Z">Zhang Sihai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Neural Architecture Search (NAS) has emerged as a favoured method for
unearthing effective neural architectures. Recent development of large models
has intensified the demand for faster search speeds and more accurate search
results. However, designing large models by NAS is challenging due to the
dramatical increase of search space and the associated huge performance
evaluation cost. Consider a typical modular search space widely used in NAS, in
which a neural architecture consists of $m$ block nodes and a block node has
$n$ alternative blocks. Facing the space containing $n^m$ candidate networks,
existing NAS methods attempt to find the best one by searching and evaluating
candidate networks directly.Different from the general strategy that takes
architecture search as a whole problem, we propose a novel divide-and-conquer
strategy by making use of the modular nature of the search space.Here, we
introduce MathNAS, a general NAS framework based on mathematical programming.In
MathNAS, the performances of the $m*n$ possible building blocks in the search
space are calculated first, and then the performance of a network is directly
predicted based on the performances of its building blocks. Although estimating
block performances involves network training, just as what happens for network
performance evaluation in existing NAS methods, predicting network performance
is completely training-free and thus extremely fast. In contrast to the $n^m$
candidate networks to evaluate in existing NAS methods, which require training
and a formidable computational burden, there are only $m*n$ possible blocks to
handle in MathNAS. Therefore, our approach effectively reduces the complexity
of network performance evaluation.Our code is available at
https://github.com/wangqinsi1/MathNAS.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04944" title="Abstract">arXiv:2311.04944</a> [<a href="/pdf/2311.04944" title="Download PDF">pdf</a>, <a href="/format/2311.04944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Edge-assisted U-Shaped Split Federated Learning with Privacy-preserving  for Internet of Things
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hengliang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zihang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Detian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiqiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+S">Siqing You</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">In the realm of the Internet of Things (IoT), deploying deep learning models
to process data generated or collected by IoT devices is a critical challenge.
However, direct data transmission can cause network congestion and inefficient
execution, given that IoT devices typically lack computation and communication
capabilities. Centralized data processing in data centers is also no longer
feasible due to concerns over data privacy and security. To address these
challenges, we present an innovative Edge-assisted U-Shaped Split Federated
Learning (EUSFL) framework, which harnesses the high-performance capabilities
of edge servers to assist IoT devices in model training and optimization
process. In this framework, we leverage Federated Learning (FL) to enable data
holders to collaboratively train models without sharing their data, thereby
enhancing data privacy protection by transmitting only model parameters.
Additionally, inspired by Split Learning (SL), we split the neural network into
three parts using U-shaped splitting for local training on IoT devices. By
exploiting the greater computation capability of edge servers, our framework
effectively reduces overall training time and allows IoT devices with varying
capabilities to perform training tasks efficiently. Furthermore, we proposed a
novel noise mechanism called LabelDP to ensure that data features and labels
can securely resist reconstruction attacks, eliminating the risk of privacy
leakage. Our theoretical analysis and experimental results demonstrate that
EUSFL can be integrated with various aggregation algorithms, maintaining good
performance across different computing capabilities of IoT devices, and
significantly reducing training time and local computation overhead.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04945" title="Abstract">arXiv:2311.04945</a> [<a href="/pdf/2311.04945" title="Download PDF">pdf</a>, <a href="/format/2311.04945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Auto deep learning for bioacoustic signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tosato%2C+G">Giulio Tosato</a>, 
<a href="/search/cs?searchtype=author&query=Shehata%2C+A">Abdelrahman Shehata</a>, 
<a href="/search/cs?searchtype=author&query=Janssen%2C+J">Joshua Janssen</a>, 
<a href="/search/cs?searchtype=author&query=Kamp%2C+K">Kees Kamp</a>, 
<a href="/search/cs?searchtype=author&query=Jati%2C+P">Pramatya Jati</a>, 
<a href="/search/cs?searchtype=author&query=Stowell%2C+D">Dan Stowell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This study investigates the potential of automated deep learning to enhance
the accuracy and efficiency of multi-class classification of bird
vocalizations, compared against traditional manually-designed deep learning
models. Using the Western Mediterranean Wetland Birds dataset, we investigated
the use of AutoKeras, an automated machine learning framework, to automate
neural architecture search and hyperparameter tuning. Comparative analysis
validates our hypothesis that the AutoKeras-derived model consistently
outperforms traditional models like MobileNet, ResNet50 and VGG16. Our approach
and findings underscore the transformative potential of automated deep learning
for advancing bioacoustics research and models. In fact, the automated
techniques eliminate the need for manual feature engineering and model design
while improving performance. This study illuminates best practices in sampling,
evaluation and reporting to enhance reproducibility in this nascent field. All
the code used is available at https:
//github.com/giuliotosato/AutoKeras-bioacustic
<br />Keywords: AutoKeras; automated deep learning; audio classification; Wetlands
Bird dataset; comparative analysis; bioacoustics; validation dataset;
multi-class classification; spectrograms.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04948" title="Abstract">arXiv:2311.04948</a> [<a href="/pdf/2311.04948" title="Download PDF">pdf</a>, <a href="/format/2311.04948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explained anomaly detection in text reviews: Can subjective scenarios be  correctly evaluated?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Novoa-Paradela%2C+D">David Novoa-Paradela</a>, 
<a href="/search/cs?searchtype=author&query=Fontenla-Romero%2C+O">Oscar Fontenla-Romero</a>, 
<a href="/search/cs?searchtype=author&query=Guijarro-Berdi%C3%B1as%2C+B">Bertha Guijarro-Berdi&#xf1;as</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The article is under review in the journal Engineering Applications of Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper presents a pipeline to detect and explain anomalous reviews in
online platforms. The pipeline is made up of three modules and allows the
detection of reviews that do not generate value for users due to either
worthless or malicious composition. The classifications are accompanied by a
normality score and an explanation that justifies the decision made. The
pipeline's ability to solve the anomaly detection task was evaluated using
different datasets created from a large Amazon database. Additionally, a study
comparing three explainability techniques involving 241 participants was
conducted to assess the explainability module. The study aimed to measure the
impact of explanations on the respondents' ability to reproduce the
classification model and their perceived usefulness. This work can be useful to
automate tasks in review online platforms, such as those for electronic
commerce, and offers inspiration for addressing similar problems in the field
of anomaly detection in textual data. We also consider it interesting to have
carried out a human evaluation of the capacity of different explainability
techniques in a real and infrequent scenario such as the detection of anomalous
reviews, as well as to reflect on whether it is possible to explain tasks as
humanly subjective as this one.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04950" title="Abstract">arXiv:2311.04950</a> [<a href="/pdf/2311.04950" title="Download PDF">pdf</a>, <a href="/format/2311.04950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lightweight Diffusion Models with Distillation-Based Block Neural  Architecture Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Siao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+C">Chaoyu Guan</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yansong Tang</a>, 
<a href="/search/cs?searchtype=author&query=zhu%2C+W">Wenwu zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Diffusion models have recently shown remarkable generation ability, achieving
state-of-the-art performance in many tasks. However, the high computational
cost is still a troubling problem for diffusion models. To tackle this problem,
we propose to automatically remove the structural redundancy in diffusion
models with our proposed Diffusion Distillation-based Block-wise Neural
Architecture Search (DiffNAS). Specifically, given a larger pretrained teacher,
we leverage DiffNAS to search for the smallest architecture which achieves
on-par or even better performance than the teacher. Considering current
diffusion models are based on UNet which naturally has a block-wise structure,
we perform neural architecture search independently in each block, which
largely reduces the search space. Different from previous block-wise NAS
methods, DiffNAS contains a block-wise local search strategy and a retraining
strategy with a joint dynamic loss. Concretely, during the search process, we
block-wisely select the best subnet to avoid the unfairness brought by the
global search strategy used in previous works. When retraining the searched
architecture, we adopt a dynamic joint loss to maintain the consistency between
supernet training and subnet retraining, which also provides informative
objectives for each block and shortens the paths of gradient propagation. We
demonstrate this joint loss can effectively improve model performance. We also
prove the necessity of the dynamic adjustment of this loss. The experiments
show that our method can achieve significant computational reduction,
especially on latent diffusion models with about 50% MACs and Parameter
reduction.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04951" title="Abstract">arXiv:2311.04951</a> [<a href="/pdf/2311.04951" title="Download PDF">pdf</a>, <a href="/format/2311.04951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Speculative Sampling and KV-Cache Optimizations Together for  Generative AI using OpenVINO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barad%2C+H">Haim Barad</a>, 
<a href="/search/cs?searchtype=author&query=Aidova%2C+E">Ekaterina Aidova</a>, 
<a href="/search/cs?searchtype=author&query=Gorbachev%2C+Y">Yury Gorbachev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published on openvino.ai. Code available at <a href="https://github.com/openvinotoolkit/openvino_notebooks/tree/main/notebooks/266-speculative-sampling">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Performance (cs.PF)

</div>
<p class="mathjax">Inference optimizations are critical for improving user experience and
reducing infrastructure costs and power consumption. In this article, we
illustrate a form of dynamic execution known as speculative sampling to reduce
the overall latency of text generation and compare it with standard
autoregressive sampling. This can be used together with model-based
optimizations (e.g. quantization) to provide an optimized solution. Both
sampling methods make use of KV caching. A Jupyter notebook and some sample
executions are provided.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04954" title="Abstract">arXiv:2311.04954</a> [<a href="/pdf/2311.04954" title="Download PDF">pdf</a>, <a href="/format/2311.04954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt Sketching for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beurer-Kellner%2C+L">Luca Beurer-Kellner</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+M+N">Mark Niklas M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+M">Marc Fischer</a>, 
<a href="/search/cs?searchtype=author&query=Vechev%2C+M">Martin Vechev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Many recent prompting strategies for large language models (LLMs) query the
model multiple times sequentially -- first to produce intermediate results and
then the final answer. However, using these methods, both decoder and model are
unaware of potential follow-up prompts, leading to disconnected and undesirably
wordy intermediate responses. In this work, we address this issue by proposing
prompt sketching, a new prompting paradigm in which an LLM does not only
respond by completing a prompt, but by predicting values for multiple variables
in a template. This way, sketching grants users more control over the
generation process, e.g., by providing a reasoning framework via intermediate
instructions, leading to better overall results. The key idea enabling
sketching with existing, autoregressive models is to adapt the decoding
procedure to also score follow-up instructions during text generation, thus
optimizing overall template likelihood in inference. Our experiments show that
in a zero-shot setting, prompt sketching outperforms existing, sequential
prompting schemes such as direct asking or chain-of-thought on 7 out of 8 LLM
benchmarking tasks, including state tracking, arithmetic reasoning, and general
question answering. To facilitate future use, we release a number of generic,
yet effective sketches applicable to many tasks, and an open source library
called dclib, powering our sketch-aware decoders.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04978" title="Abstract">arXiv:2311.04978</a> [<a href="/pdf/2311.04978" title="Download PDF">pdf</a>, <a href="/format/2311.04978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the steerability of large language models toward data-driven personas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Mehrabi%2C+N">Ninareh Mehrabi</a>, 
<a href="/search/cs?searchtype=author&query=Peris%2C+C">Charith Peris</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+P">Palash Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K">Kai-Wei Chang</a>, 
<a href="/search/cs?searchtype=author&query=Galstyan%2C+A">Aram Galstyan</a>, 
<a href="/search/cs?searchtype=author&query=Zemel%2C+R">Richard Zemel</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+R">Rahul Gupta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The recent surge in Large Language Model (LLM) related applications has led
to a concurrent escalation in expectations for LLMs to accommodate a myriad of
personas and encompass a broad spectrum of perspectives. An important first
step towards addressing this demand is to align language models with specific
personas, be it groups of users or individuals. Towards this goal, we first
present a new conceptualization of a persona. Moving beyond the traditional
reliance on demographics like age, gender, or political party affiliation, we
introduce a data-driven persona definition methodology built on
collaborative-filtering. In this methodology, users are embedded into a
continuous vector space based on their opinions and clustered into cohorts that
manifest coherent views across specific inquiries. This methodology allows for
a more nuanced understanding of different latent social groups present in the
overall population (as opposed to simply using demographic groups) and enhances
the applicability of model steerability. Finally, we present an efficient
method to steer LLMs towards a particular persona. We learn a soft-prompting
model to map the continuous representation of users into sequences of virtual
tokens which, when prepended to the LLM input, enables the LLM to produce
responses aligned with a given user. Our results show that our steerability
algorithm is superior in performance compared to a collection of baselines.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04980" title="Abstract">arXiv:2311.04980</a> [<a href="/pdf/2311.04980" title="Download PDF">pdf</a>, <a href="/format/2311.04980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MaxEVA: Maximizing the Efficiency of Matrix Multiplication on Versal AI  Engine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taka%2C+E">Endri Taka</a>, 
<a href="/search/cs?searchtype=author&query=Arora%2C+A">Aman Arora</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kai-Chiang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Marculescu%2C+D">Diana Marculescu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as full paper at FPT 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">The increasing computational and memory requirements of Deep Learning (DL)
workloads has led to outstanding innovations in hardware architectures. An
archetype of such architectures is the novel Versal AI Engine (AIE) by
AMD/Xilinx. The AIE comprises multiple programmable processors optimized for
vector-based algorithms. An AIE array consisting of 400 processor cores,
operating at 1.25 GHz is able to deliver a peak throughput of 8 TFLOPs for
32-bit floating-point (fp32), and 128 TOPs for 8-bit integer (int8) precision.
In this work, we propose MaxEVA: a novel framework to efficiently map Matrix
Multiplication (MatMul) workloads on Versal AIE devices. Our framework
maximizes the performance and energy efficiency of MatMul applications by
efficiently exploiting features of the AIE architecture and resolving
performance bottlenecks from multiple angles. When demonstrating on the VC1902
device of the VCK190 board, MaxEVA accomplishes up to 5.44 TFLOPs and 77.01
TOPs throughput for fp32 and int8 precisions, respectively. In terms of energy
efficiency, MaxEVA attains up to 85.11 GFLOPs/W for fp32, and 1.73 TOPs/W for
int8. Our proposed method substantially outperforms the state-of-the-art
approach by exhibiting up to 2.19x throughput gain and 29.4% higher energy
efficiency. The MaxEVA framework provides notable insights to fill the
knowledge gap in effectively designing MatMul-based DL workloads on the new
Versal AIE devices.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04986" title="Abstract">arXiv:2311.04986</a> [<a href="/pdf/2311.04986" title="Download PDF">pdf</a>, <a href="/format/2311.04986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Inductive Biases in Video Modeling through Neural CDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chiu%2C+J">Johnathan Chiu</a>, 
<a href="/search/cs?searchtype=author&query=Duffield%2C+S">Samuel Duffield</a>, 
<a href="/search/cs?searchtype=author&query=Hunter-Gordon%2C+M">Max Hunter-Gordon</a>, 
<a href="/search/cs?searchtype=author&query=Donatella%2C+K">Kaelan Donatella</a>, 
<a href="/search/cs?searchtype=author&query=Aifer%2C+M">Max Aifer</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+A">Andi Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce a novel approach to video modeling that leverages controlled
differential equations (CDEs) to address key challenges in video tasks, notably
video interpolation and mask propagation. We apply CDEs at varying resolutions
leading to a continuous-time U-Net architecture. Unlike traditional methods,
our approach does not require explicit optical flow learning, and instead makes
use of the inherent continuous-time features of CDEs to produce a highly
expressive video model. We demonstrate competitive performance against
state-of-the-art models for video interpolation and mask propagation tasks.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04991" title="Abstract">arXiv:2311.04991</a> [<a href="/pdf/2311.04991" title="Download PDF">pdf</a>, <a href="/format/2311.04991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effective Restoration of Source Knowledge in Continual Test Time  Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niloy%2C+F+F">Fahim Faisal Niloy</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+S+M">Sk Miraj Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Raychaudhuri%2C+D+S">Dripta S. Raychaudhuri</a>, 
<a href="/search/cs?searchtype=author&query=Oymak%2C+S">Samet Oymak</a>, 
<a href="/search/cs?searchtype=author&query=Roy-Chowdhury%2C+A+K">Amit K. Roy-Chowdhury</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Traditional test-time adaptation (TTA) methods face significant challenges in
adapting to dynamic environments characterized by continuously changing
long-term target distributions. These challenges primarily stem from two
factors: catastrophic forgetting of previously learned valuable source
knowledge and gradual error accumulation caused by miscalibrated pseudo labels.
To address these issues, this paper introduces an unsupervised domain change
detection method that is capable of identifying domain shifts in dynamic
environments and subsequently resets the model parameters to the original
source pre-trained values. By restoring the knowledge from the source, it
effectively corrects the negative consequences arising from the gradual
deterioration of model parameters caused by ongoing shifts in the domain. Our
method involves progressive estimation of global batch-norm statistics specific
to each domain, while keeping track of changes in the statistics triggered by
domain shifts. Importantly, our method is agnostic to the specific adaptation
technique employed and thus, can be incorporated to existing TTA methods to
enhance their performance in dynamic environments. We perform extensive
experiments on benchmark datasets to demonstrate the superior performance of
our method compared to state-of-the-art adaptation methods.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04997" title="Abstract">arXiv:2311.04997</a> [<a href="/pdf/2311.04997" title="Download PDF">pdf</a>, <a href="/format/2311.04997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digital Twin-based 3D Map Management for Edge-assisted Device Pose  Tracking in Mobile AR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Conghao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jie Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mushu Li</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+N">Nan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xuemin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+W">Weihua Zhuang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to IEEE Internet of Things Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Edge-device collaboration has the potential to facilitate compute-intensive
device pose tracking for resource-constrained mobile augmented reality (MAR)
devices. In this paper, we devise a 3D map management scheme for edge-assisted
MAR, wherein an edge server constructs and updates a 3D map of the physical
environment by using the camera frames uploaded from an MAR device, to support
local device pose tracking. Our objective is to minimize the uncertainty of
device pose tracking by periodically selecting a proper set of uploaded camera
frames and updating the 3D map. To cope with the dynamics of the uplink data
rate and the user's pose, we formulate a Bayes-adaptive Markov decision process
problem and propose a digital twin (DT)-based approach to solve the problem.
First, a DT is designed as a data model to capture the time-varying uplink data
rate, thereby supporting 3D map management. Second, utilizing extensive
generated data provided by the DT, a model-based reinforcement learning
algorithm is developed to manage the 3D map while adapting to these dynamics.
Numerical results demonstrate that the designed DT outperforms Markov models in
accurately capturing the time-varying uplink data rate, and our devised
DT-based 3D map management scheme surpasses benchmark schemes in reducing
device pose tracking uncertainty.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04999" title="Abstract">arXiv:2311.04999</a> [<a href="/pdf/2311.04999" title="Download PDF">pdf</a>, <a href="/format/2311.04999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit Neural Representations for Breathing-compensated Volume  Reconstruction in Robotic Ultrasound Aorta Screening
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Velikova%2C+Y">Yordanka Velikova</a>, 
<a href="/search/cs?searchtype=author&query=Azampour%2C+M+F">Mohammad Farid Azampour</a>, 
<a href="/search/cs?searchtype=author&query=Simson%2C+W">Walter Simson</a>, 
<a href="/search/cs?searchtype=author&query=Esposito%2C+M">Marco Esposito</a>, 
<a href="/search/cs?searchtype=author&query=Navab%2C+N">Nassir Navab</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Ultrasound (US) imaging is widely used in diagnosing and staging abdominal
diseases due to its lack of non-ionizing radiation and prevalent availability.
However, significant inter-operator variability and inconsistent image
acquisition hinder the widespread adoption of extensive screening programs.
Robotic ultrasound systems have emerged as a promising solution, offering
standardized acquisition protocols and the possibility of automated
acquisition. Additionally, these systems enable access to 3D data via robotic
tracking, enhancing volumetric reconstruction for improved ultrasound
interpretation and precise disease diagnosis. However, the interpretability of
3D US reconstruction of abdominal images can be affected by the patient's
breathing motion. This study introduces a method to compensate for breathing
motion in 3D US compounding by leveraging implicit neural representations. Our
approach employs a robotic ultrasound system for automated screenings. To
demonstrate the method's effectiveness, we evaluate our proposed method for the
diagnosis and monitoring of abdominal aorta aneurysms as a representative use
case. Our experiments demonstrate that our proposed pipeline facilitates robust
automated robotic acquisition, mitigating artifacts from breathing motion, and
yields smoother 3D reconstructions for enhanced screening and medical
diagnosis.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05006" title="Abstract">arXiv:2311.05006</a> [<a href="/pdf/2311.05006" title="Download PDF">pdf</a>, <a href="/format/2311.05006" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Familiarity-Based Open-Set Recognition Under Adversarial Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Enevoldsen%2C+P">Philip Enevoldsen</a>, 
<a href="/search/cs?searchtype=author&query=Gundersen%2C+C">Christian Gundersen</a>, 
<a href="/search/cs?searchtype=author&query=Lang%2C+N">Nico Lang</a>, 
<a href="/search/cs?searchtype=author&query=Belongie%2C+S">Serge Belongie</a>, 
<a href="/search/cs?searchtype=author&query=Igel%2C+C">Christian Igel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in: The 2nd Workshop and Challenges for Out-of-Distribution Generalization in Computer Vision, ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Open-set recognition (OSR), the identification of novel categories, can be a
critical component when deploying classification models in real-world
applications. Recent work has shown that familiarity-based scoring rules such
as the Maximum Softmax Probability (MSP) or the Maximum Logit Score (MLS) are
strong baselines when the closed-set accuracy is high. However, one of the
potential weaknesses of familiarity-based OSR are adversarial attacks. Here, we
present gradient-based adversarial attacks on familiarity scores for both types
of attacks, False Familiarity and False Novelty attacks, and evaluate their
effectiveness in informed and uninformed settings on TinyImageNet.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05012" title="Abstract">arXiv:2311.05012</a> [<a href="/pdf/2311.05012" title="Download PDF">pdf</a>, <a href="/ps/2311.05012" title="Download PostScript">ps</a>, <a href="/format/2311.05012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frequency-Based Reduced Models from Purely Time-Domain Data via Data  Informativity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ackermann%2C+M+S">Michael S. Ackermann</a>, 
<a href="/search/math?searchtype=author&query=Gugercin%2C+S">Serkan Gugercin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Frequency-based methods have been successfully employed in creating high
fidelity data-driven reduced order models (DDROMs) for linear dynamical
systems. These methods require access to values (and sometimes derivatives) of
the frequency-response function (transfer function) in the complex plane. These
frequency domain values can at times be costly or difficult to obtain
(especially if the method of choice requires resampling); instead one may have
access to only time-domain input-output data. The data informativity approach
to moment matching provides a powerful new framework for recovering the
required frequency data from a single time-domain trajectory. In this work, we
analyze and extend upon this framework, resulting in vastly improved
conditioning of the associated linear systems, an error indicator, and removal
of an assumption that the system order is known. This analysis leads to a
robust algorithm for recovering frequency information from time-domain data,
suitable for large scale systems. We demonstrate the effectiveness of our
algorithm by forming frequency based DDROMs from time-domain data of several
dynamical systems.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05013" title="Abstract">arXiv:2311.05013</a> [<a href="/pdf/2311.05013" title="Download PDF">pdf</a>, <a href="/format/2311.05013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Learning Generalization for Nonlinear Systems Through  Dual-Scale Homogeneity Transformations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Haddad%2C+A+G">Abdel Gafoor Haddad</a>, 
<a href="/search/eess?searchtype=author&query=Boiko%2C+I">Igor Boiko</a>, 
<a href="/search/eess?searchtype=author&query=Zweiri%2C+Y">Yahya Zweiri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Reinforcement learning is an emerging approach to control dynamical systems
for which classical approaches are difficult to apply. However, trained agents
may not generalize against the variations of system parameters. This paper
presents the concept of dual-scale homogeneity, an important property in
understating the scaling behavior of nonlinear systems. Furthermore, it also
presents an effective yet simple approach to designing a parameter-dependent
control law that homogenizes a nonlinear system. The presented approach is
applied to two systems, demonstrating its ability to provide a consistent
performance irrespective of parameters variations. To demonstrate the
practicality of the proposed approach, the control policy is generated by a
deep deterministic policy gradient to control the load position of a quadrotor
with a slung load. The proposed synergy between the homogeneity transformations
and reinforcement learning yields superior performance compared to other recent
learning-based control techniques. It achieves a success rate of 96% in
bringing the load to its designated target with a 3D RMSE of 0.0253 m. The
video that shows the experimental results along with a summary of the paper is
available at this link.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05014" title="Abstract">arXiv:2311.05014</a> [<a href="/pdf/2311.05014" title="Download PDF">pdf</a>, <a href="/format/2311.05014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpreting Pretrained Language Models via Concept Bottlenecks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zhen Tan</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Lu Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Song Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bo%2C+Y">Yuan Bo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jundong Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huan Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Pretrained language models (PLMs) have made significant strides in various
natural language processing tasks. However, the lack of interpretability due to
their ``black-box'' nature poses challenges for responsible implementation.
Although previous studies have attempted to improve interpretability by using,
e.g., attention weights in self-attention layers, these weights often lack
clarity, readability, and intuitiveness. In this research, we propose a novel
approach to interpreting PLMs by employing high-level, meaningful concepts that
are easily understandable for humans. For example, we learn the concept of
``Food'' and investigate how it influences the prediction of a model's
sentiment towards a restaurant review. We introduce C$^3$M, which combines
human-annotated and machine-generated concepts to extract hidden neurons
designed to encapsulate semantically meaningful and task-specific concepts.
Through empirical evaluations on real-world datasets, we manifest that our
approach offers valuable insights to interpret PLM behavior, helps diagnose
model failures, and enhances model robustness amidst noisy concept labels.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05015" title="Abstract">arXiv:2311.05015</a> [<a href="/pdf/2311.05015" title="Download PDF">pdf</a>, <a href="/ps/2311.05015" title="Download PostScript">ps</a>, <a href="/format/2311.05015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beamforming Performances of Holographic Surfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Khormuji%2C+M+N">Majid Nasiri Khormuji</a>, 
<a href="/search/cs?searchtype=author&query=Popovic%2C+B+M">Branislav M. Popovic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 26 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Wireless Communications, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this paper, we investigate the beamforming performances of holographic
surfaces implemented as lossless antenna arrays with less than half-wavelength
spacing. We first develop a method to quantify the mutual coupling effect among
the antennas in an array. The developed coupling model is general and
applicable to arrays with arbitrary distribution of any type of antennas with
arbitrary structure, physical size and radiation power pattern. In particular,
it reduces to a neat analytical expression for arbitrarily deployed isotropic
antenna arrays. We then discuss the beamforming design for holographic
surfaces, and in particular provide analytical beamforming characterizations
for arrays with two arbitrarily spaced isotropic antennas. Numerical results
indicate that, by accounting for the mutual coupling effect between antennas,
the array densification by packing more antennas in a given surface aperture
can significantly enhance both the beamforming gain and spatial resolution of
the system. The beamforming gain enhancement and beamwidth reduction can be
several dBs higher than, and more than half of, those achieved by the
conventional half-wavelength spaced antenna arrays in the same surface
aperture. The gains of densification become saturated when the antenna spacing
is below a critical value, and the saturated gain reduces as the surface
aperture increases.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05017" title="Abstract">arXiv:2311.05017</a> [<a href="/pdf/2311.05017" title="Download PDF">pdf</a>, <a href="/format/2311.05017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Sensing and Semantic Communications with Multi-Task Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sagduyu%2C+Y+E">Yalin E. Sagduyu</a>, 
<a href="/search/cs?searchtype=author&query=Erpek%2C+T">Tugba Erpek</a>, 
<a href="/search/cs?searchtype=author&query=Yener%2C+A">Aylin Yener</a>, 
<a href="/search/cs?searchtype=author&query=Ulukus%2C+S">Sennur Ulukus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT); Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper explores the integration of deep learning techniques for joint
sensing and communications, with an extension to semantic communications. The
integrated system comprises a transmitter and receiver operating over a
wireless channel, subject to noise and fading effects. The transmitter employs
a deep neural network, namely an encoder, for joint operations of source
coding, channel coding, and modulation, while the receiver utilizes another
deep neural network, namely a decoder, for joint operations of demodulation,
channel decoding, and source decoding to reconstruct the data samples. The
transmitted signal serves a dual purpose, supporting communication with the
receiver and enabling sensing. When a target is present, the reflected signal
is received, and another deep neural network decoder is utilized for sensing.
This decoder is responsible for detecting the target's presence and determining
its range. All these deep neural networks, including one encoder and two
decoders, undergo joint training through multi-task learning, considering data
and channel characteristics. This paper extends to incorporate semantic
communications by introducing an additional deep neural network, another
decoder at the receiver, operating as a task classifier. This decoder evaluates
the fidelity of label classification for received signals, enhancing the
integration of semantics within the communication process. The study presents
results based on using the CIFAR-10 as the input data and accounting for
channel effects like Additive White Gaussian Noise (AWGN) and Rayleigh fading.
The results underscore the effectiveness of multi-task deep learning in
achieving high-fidelity joint sensing and semantic communications.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05018" title="Abstract">arXiv:2311.05018</a> [<a href="/pdf/2311.05018" title="Download PDF">pdf</a>, <a href="/format/2311.05018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Effective Paraphrasing for Information Disguise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+A">Anmol Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Shrey Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Bonagiri%2C+V">Vamshi Bonagiri</a>, 
<a href="/search/cs?searchtype=author&query=Gaur%2C+M">Manas Gaur</a>, 
<a href="/search/cs?searchtype=author&query=Reagle%2C+J">Joseph Reagle</a>, 
<a href="/search/cs?searchtype=author&query=Kumaraguru%2C+P">Ponnurangam Kumaraguru</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ECIR 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 45th European Conference on Information Retrieval, ECIR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Information Disguise (ID), a part of computational ethics in Natural Language
Processing (NLP), is concerned with best practices of textual paraphrasing to
prevent the non-consensual use of authors' posts on the Internet. Research on
ID becomes important when authors' written online communication pertains to
sensitive domains, e.g., mental health. Over time, researchers have utilized
AI-based automated word spinners (e.g., SpinRewriter, WordAI) for paraphrasing
content. However, these tools fail to satisfy the purpose of ID as their
paraphrased content still leads to the source when queried on search engines.
There is limited prior work on judging the effectiveness of paraphrasing
methods for ID on search engines or their proxies, neural retriever (NeurIR)
models. We propose a framework where, for a given sentence from an author's
post, we perform iterative perturbation on the sentence in the direction of
paraphrasing with an attempt to confuse the search mechanism of a NeurIR system
when the sentence is queried on it. Our experiments involve the subreddit
'r/AmItheAsshole' as the source of public content and Dense Passage Retriever
as a NeurIR system-based proxy for search engines. Our work introduces a novel
method of phrase-importance rankings using perplexity scores and involves
multi-level phrase substitutions via beam search. Our multi-phrase substitution
scheme succeeds in disguising sentences 82% of the time and hence takes an
essential step towards enabling researchers to disguise sensitive content
effectively before making it public. We also release the code of our approach.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05019" title="Abstract">arXiv:2311.05019</a> [<a href="/pdf/2311.05019" title="Download PDF">pdf</a>, <a href="/format/2311.05019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DEMASQ: Unmasking the ChatGPT Wordsmith
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumari%2C+K">Kavita Kumari</a>, 
<a href="/search/cs?searchtype=author&query=Pegoraro%2C+A">Alessandro Pegoraro</a>, 
<a href="/search/cs?searchtype=author&query=Fereidooni%2C+H">Hossein Fereidooni</a>, 
<a href="/search/cs?searchtype=author&query=Sadeghi%2C+A">Ahmad-Reza Sadeghi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the Network and Distributed System Security (NDSS) Symposium 2024. 15 pages, 3 figures, 6 tables, 3 algorithms, 6 equations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The potential misuse of ChatGPT and other Large Language Models (LLMs) has
raised concerns regarding the dissemination of false information, plagiarism,
academic dishonesty, and fraudulent activities. Consequently, distinguishing
between AI-generated and human-generated content has emerged as an intriguing
research topic. However, current text detection methods lack precision and are
often restricted to specific tasks or domains, making them inadequate for
identifying content generated by ChatGPT. In this paper, we propose an
effective ChatGPT detector named DEMASQ, which accurately identifies
ChatGPT-generated content. Our method addresses two critical factors: (i) the
distinct biases in text composition observed in human- and machine-generated
content and (ii) the alterations made by humans to evade previous detection
methods. DEMASQ is an energy-based detection model that incorporates novel
aspects, such as (i) optimization inspired by the Doppler effect to capture the
interdependence between input text embeddings and output labels, and (ii) the
use of explainable AI techniques to generate diverse perturbations. To evaluate
our detector, we create a benchmark dataset comprising a mixture of prompts
from both ChatGPT and humans, encompassing domains such as medical, open Q&amp;A,
finance, wiki, and Reddit. Our evaluation demonstrates that DEMASQ achieves
high accuracy in identifying content generated by ChatGPT.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05020" title="Abstract">arXiv:2311.05020</a> [<a href="/pdf/2311.05020" title="Download PDF">pdf</a>, <a href="/format/2311.05020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> First Tragedy, then Parse: History Repeats Itself in the New Era of  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saphra%2C+N">Naomi Saphra</a>, 
<a href="/search/cs?searchtype=author&query=Fleisig%2C+E">Eve Fleisig</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+K">Kyunghyun Cho</a>, 
<a href="/search/cs?searchtype=author&query=Lopez%2C+A">Adam Lopez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Many NLP researchers are experiencing an existential crisis triggered by the
astonishing success of ChatGPT and other systems based on large language models
(LLMs). After such a disruptive change to our understanding of the field, what
is left to do? Taking a historical lens, we look for guidance from the first
era of LLMs, which began in 2005 with large $n$-gram models for machine
translation. We identify durable lessons from the first era, and more
importantly, we identify evergreen problems where NLP researchers can continue
to make meaningful contributions in areas where LLMs are ascendant. Among these
lessons, we discuss the primacy of hardware advancement in shaping the
availability and importance of scale, as well as the urgent challenge of
quality evaluation, both automated and human. We argue that disparities in
scale are transient and that researchers can work to reduce them; that data,
rather than hardware, is still a bottleneck for many meaningful applications;
that meaningful evaluation informed by actual use is still an open problem; and
that there is still room for speculative approaches.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05021" title="Abstract">arXiv:2311.05021</a> [<a href="/pdf/2311.05021" title="Download PDF">pdf</a>, <a href="/format/2311.05021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging a realistic synthetic database to learn Shape-from-Shading  for estimating the colon depth in colonoscopy images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruano%2C+J">Josu&#xe9; Ruano</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez%2C+M">Mart&#xed;n G&#xf3;mez</a>, 
<a href="/search/cs?searchtype=author&query=Romero%2C+E">Eduardo Romero</a>, 
<a href="/search/cs?searchtype=author&query=Manzanera%2C+A">Antoine Manzanera</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Colonoscopy is the choice procedure to diagnose colon and rectum cancer, from
early detection of small precancerous lesions (polyps), to confirmation of
malign masses. However, the high variability of the organ appearance and the
complex shape of both the colon wall and structures of interest make this
exploration difficult. Learned visuospatial and perceptual abilities mitigate
technical limitations in clinical practice by proper estimation of the
intestinal depth. This work introduces a novel methodology to estimate colon
depth maps in single frames from monocular colonoscopy videos. The generated
depth map is inferred from the shading variation of the colon wall with respect
to the light source, as learned from a realistic synthetic database. Briefly, a
classic convolutional neural network architecture is trained from scratch to
estimate the depth map, improving sharp depth estimations in haustral folds and
polyps by a custom loss function that minimizes the estimation error in edges
and curvatures. The network was trained by a custom synthetic colonoscopy
database herein constructed and released, composed of 248,400 frames (47
videos), with depth annotations at the level of pixels. This collection
comprehends 5 subsets of videos with progressively higher levels of visual
complexity. Evaluation of the depth estimation with the synthetic database
reached a threshold accuracy of 95.65%, and a mean-RMSE of 0.451 cm, while a
qualitative assessment with a real database showed consistent depth
estimations, visually evaluated by the expert gastroenterologist coauthoring
this paper. Finally, the method achieved competitive performance with respect
to another state-of-the-art method using a public synthetic database and
comparable results in a set of images with other five state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05024" title="Abstract">arXiv:2311.05024</a> [<a href="/pdf/2311.05024" title="Download PDF">pdf</a>, <a href="/ps/2311.05024" title="Download PostScript">ps</a>, <a href="/format/2311.05024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Einstien-Multidimensional Extrapolation methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bentbib%2C+A+H">A. H. Bentbib</a>, 
<a href="/search/math?searchtype=author&query=Jbilou%2C+K">K. Jbilou</a>, 
<a href="/search/math?searchtype=author&query=Tahiri%2C+R">R. Tahiri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we present a new framework for the recent multidimensional
extrapolation methods: Tensor Global Minimal Polynomial (TG-MPE) and Tensor
Global Reduced Rank Extrapolation (TG-RRE) methods. We develop a new approach
to the one presented in \cite{17}. The proposed framework highlights, in
addition their polynomial feature, the connection of TG-MPE and TG-RRE with
nonlinear Krylov subspace methods. A unified algorithm is proposed for their
implemention. Theoretical results are given and some numerical experiments on
linear and nonlinear problems are considered to confirm the performance of the
proposed algorithms.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05028" title="Abstract">arXiv:2311.05028</a> [<a href="/pdf/2311.05028" title="Download PDF">pdf</a>, <a href="/ps/2311.05028" title="Download PostScript">ps</a>, <a href="/format/2311.05028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impact of Changes to Daylight Illumination level on Architectural  experience in Offices Based on VR and EEG
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Payedar-Ardakani%2C+P">Pegah Payedar-Ardakani</a>, 
<a href="/search/cs?searchtype=author&query=Gorji-Mahlabani%2C+Y">Yousef Gorji-Mahlabani</a>, 
<a href="/search/cs?searchtype=author&query=Ghanbaran%2C+A">Abdolhamid Ghanbaran</a>, 
<a href="/search/cs?searchtype=author&query=Ebrahimpour%2C+R">Reza Ebrahimpour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">This study investigates the influence of varying illumination levels on
architectural experiences by employing a comprehensive approach that combines
self-reported assessments and neurophysiological measurements. Thirty
participants were exposed to nine distinct illumination conditions in a
controlled virtual reality environment. Subjective assessments, collected
through questionnaires in which participants were asked to rate how pleasant,
interesting, exciting, calming, complex, bright and spacious they found the
space. Objective measurements of brain activity were collected by
electroencephalogram (EEG). Data analysis demonstrated that illumination levels
significantly influenced cognitive engagement and different architectural
experience indicators. This alignment between subjective assessment and EEG
data underscores the relationship between illuminance and architectural
experiences. The study bridges the gap between quantitative and qualitative
assessments, providing a deeper understanding of the intricate connection
between lighting conditions and human responses. These findings contribute to
the enhancement of environmental design based on neuroscientific insights,
emphasizing the critical role of well-considered daylighting design in
positively influencing occupants' cognitive and emotional states within built
environments.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05029" title="Abstract">arXiv:2311.05029</a> [<a href="/pdf/2311.05029" title="Download PDF">pdf</a>, <a href="/format/2311.05029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> S$^3$AD: Semi-supervised Small Apple Detection in Orchard Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Johanson%2C+R">Robert Johanson</a>, 
<a href="/search/cs?searchtype=author&query=Wilms%2C+C">Christian Wilms</a>, 
<a href="/search/cs?searchtype=author&query=Johannsen%2C+O">Ole Johannsen</a>, 
<a href="/search/cs?searchtype=author&query=Frintrop%2C+S">Simone Frintrop</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV 2024. The dataset MAD is available at <a href="http://www.inf.uni-hamburg.de/mad">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Crop detection is integral for precision agriculture applications such as
automated yield estimation or fruit picking. However, crop detection, e.g.,
apple detection in orchard environments remains challenging due to a lack of
large-scale datasets and the small relative size of the crops in the image. In
this work, we address these challenges by reformulating the apple detection
task in a semi-supervised manner. To this end, we provide the large,
high-resolution dataset MAD comprising 105 labeled images with 14,667 annotated
apple instances and 4,440 unlabeled images. Utilizing this dataset, we also
propose a novel Semi-Supervised Small Apple Detection system S$^3$AD based on
contextual attention and selective tiling to improve the challenging detection
of small apples, while limiting the computational overhead. We conduct an
extensive evaluation on MAD and the MSU dataset, showing that S$^3$AD
substantially outperforms strong fully-supervised baselines, including several
small object detection systems, by up to $14.9\%$. Additionally, we exploit the
detailed annotations of our dataset w.r.t. apple properties to analyze the
influence of relative size or level of occlusion on the results of various
systems, quantifying current challenges.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05034" title="Abstract">arXiv:2311.05034</a> [<a href="/pdf/2311.05034" title="Download PDF">pdf</a>, <a href="/format/2311.05034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Just-in-time Quantization with Processing-In-Memory for Efficient ML  Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ibrahim%2C+M+A">Mohamed Assem Ibrahim</a>, 
<a href="/search/cs?searchtype=author&query=Aga%2C+S">Shaizeen Aga</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Ada Li</a>, 
<a href="/search/cs?searchtype=author&query=Pati%2C+S">Suchita Pati</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M">Mahzabeen Islam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Data format innovations have been critical for machine learning (ML) scaling,
which in turn fuels ground-breaking ML capabilities. However, even in the
presence of low-precision formats, model weights are often stored in both
high-precision and low-precision during training. Furthermore, with emerging
directional data formats (e.g., MX9, MX6, etc.) multiple low-precision weight
copies can be required. To lower memory capacity needs of weights, we explore
just-in-time quantization (JIT-Q) where we only store high-precision weights in
memory and generate low-precision weights only when needed. To perform JIT-Q
efficiently, in this work, we evaluate emerging processing-in-memory (PIM)
technology to execute quantization. With PIM, we can offload quantization to
in-memory compute units enabling quantization to be performed without incurring
costly data movement while allowing quantization to be concurrent with
accelerator computation. Our proposed PIM-offloaded quantization keeps up with
GPU compute and delivers considerable capacity savings (up to 24\%) at marginal
throughput loss (up to 2.4\%). Said memory capacity savings can unlock several
benefits such as fitting larger model in the same system, reducing model
parallelism requirement, and improving overall ML training efficiency.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05037" title="Abstract">arXiv:2311.05037</a> [<a href="/pdf/2311.05037" title="Download PDF">pdf</a>, <a href="/format/2311.05037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Embedded Platform Patterns for Distributed and Secure Logging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Basic%2C+F">Fikret Basic</a>, 
<a href="/search/cs?searchtype=author&query=Steger%2C+C">Christian Steger</a>, 
<a href="/search/cs?searchtype=author&query=Kofler%2C+R">Robert Kofler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted copy for Publication at the 26th European Conference on Pattern Languages of Programs (EuroPLoP), ACM, 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE); Systems and Control (eess.SY)

</div>
<p class="mathjax">With the advent of modern embedded systems, logging as a process is becoming
more and more prevalent for diagnostic and analytic services. Traditionally,
storage and managing of the logged data are generally kept as a part of one
entity together with the main logic components. In systems that implement
network connections, this activity is usually handled over a remote device.
However, enabling remote connection is still considered a limiting factor for
many embedded devices due to the demanding production cost. A significant
challenge is presented to vendors who need to decide how the data will be
extracted and handled for an embedded platform during the design concept phase.
It is generally desirable that logging memory modules are able to be addressed
as separate units. These devices need to be appropriately secured and
verifiable on a different system since data compromise can lead to enormous
privacy and even financial losses. In this paper, we present two patterns.
First, a pattern that allows flexible logging operation design in terms of
module and interface responsibility separation. Second, a pattern for the
design of secure logging processes during the utilization of constrained
embedded devices. The introduced patterns fulfil the following conditions: (i)
flexibility, design is independent of the chip vendors making the logging
memory modules easily replaceable, (ii) self-sufficiency, every logging
controller is maintained as a separate entity in a decentralized topology,
(iii) security, through providing authenticity, confidentiality, and integrity
by means of using a dedicated security module.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05038" title="Abstract">arXiv:2311.05038</a> [<a href="/pdf/2311.05038" title="Download PDF">pdf</a>, <a href="/format/2311.05038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An approach to performance portability through generic programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hadjigeorgiou%2C+A">Andreas Hadjigeorgiou</a>, 
<a href="/search/cs?searchtype=author&query=Stylianou%2C+C">Christodoulos Stylianou</a>, 
<a href="/search/cs?searchtype=author&query=Weiland%2C+M">Michele Weiland</a>, 
<a href="/search/cs?searchtype=author&query=Verschuur%2C+D+J">Dirk Jacob Verschuur</a>, 
<a href="/search/cs?searchtype=author&query=Finkenrath%2C+J">Jacob Finkenrath</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">The expanding hardware diversity in high performance computing adds enormous
complexity to scientific software development. Developers who aim to write
maintainable software have two options: 1) To use a so-called data locality
abstraction that handles portability internally, thereby,
performance-productivity becomes a trade off. Such abstractions usually come in
the form of libraries, domain-specific languages, and run-time systems. 2) To
use generic programming where performance, productivity and portability are
subject to software design. In the direction of the second, this work describes
a design approach that allows the integration of low-level and verbose
programming tools into high-level generic algorithms based on template
meta-programming in C++. This enables the development of performance-portable
applications targeting host-device computer architectures, such as CPUs and
GPUs. With a suitable design in place, the extensibility of generic algorithms
to new hardware becomes a well defined procedure that can be developed in
isolation from other parts of the code. That allows scientific software to be
maintainable and efficient in a period of diversifying hardware in HPC. As
proof of concept, a finite-difference modelling algorithm for the acoustic wave
equation is developed and benchmarked using roofline model analysis on Intel
Xeon Gold 6248 CPU, Nvidia Tesla V100 GPU, and AMD MI100 GPU.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05040" title="Abstract">arXiv:2311.05040</a> [<a href="/pdf/2311.05040" title="Download PDF">pdf</a>, <a href="/ps/2311.05040" title="Download PostScript">ps</a>, <a href="/format/2311.05040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Network Flow Problems with Electric Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pulyassary%2C+H">Haripriya Pulyassary</a>, 
<a href="/search/cs?searchtype=author&query=Kollias%2C+K">Kostas Kollias</a>, 
<a href="/search/cs?searchtype=author&query=Schild%2C+A">Aaron Schild</a>, 
<a href="/search/cs?searchtype=author&query=Shmoys%2C+D">David Shmoys</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Manxi Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Electric vehicle (EV) adoption in long-distance logistics faces challenges
such as range anxiety and uneven distribution of charging stations. Two pivotal
questions emerge: How can EVs be efficiently routed in a charging network
considering range limits, charging speeds and prices? And, can the existing
charging infrastructure sustain the increasing demand for EVs in long-distance
logistics? This paper addresses these questions by introducing a novel
theoretical and computational framework to study the EV network flow problems.
We present an EV network flow model that incorporates range constraints and
nonlinear charging rates, and identify conditions under which polynomial-time
solutions can be obtained for optimal single EV routing, maximum flow, and
minimum-cost flow problems. Our findings provide insights for optimizing EV
routing in logistics, ensuring an efficient and sustainable future.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05041" title="Abstract">arXiv:2311.05041</a> [<a href="/pdf/2311.05041" title="Download PDF">pdf</a>, <a href="/format/2311.05041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Transfer Learning for Efficient Video-Specific Human Pose  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taketsugu%2C+H">Hiromu Taketsugu</a>, 
<a href="/search/cs?searchtype=author&query=Ukita%2C+N">Norimichi Ukita</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 12 figures, Accepted by WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Human Pose (HP) estimation is actively researched because of its wide range
of applications. However, even estimators pre-trained on large datasets may not
perform satisfactorily due to a domain gap between the training and test data.
To address this issue, we present our approach combining Active Learning (AL)
and Transfer Learning (TL) to adapt HP estimators to individual video domains
efficiently. For efficient learning, our approach quantifies (i) the estimation
uncertainty based on the temporal changes in the estimated heatmaps and (ii)
the unnaturalness in the estimated full-body HPs. These quantified criteria are
then effectively combined with the state-of-the-art representativeness
criterion to select uncertain and diverse samples for efficient HP estimator
learning. Furthermore, we reconsider the existing Active Transfer Learning
(ATL) method to introduce novel ideas related to the retraining methods and
Stopping Criteria (SC). Experimental results demonstrate that our method
enhances learning efficiency and outperforms comparative methods. Our code is
publicly available at: https://github.com/ImIntheMiddle/VATL4Pose-WACV2024
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05042" title="Abstract">arXiv:2311.05042</a> [<a href="/pdf/2311.05042" title="Download PDF">pdf</a>, <a href="/format/2311.05042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Annotation of Scientific Texts for ML-based Keyphrase  Extraction and Validation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amusat%2C+O+O">Oluwamayowa O. Amusat</a>, 
<a href="/search/cs?searchtype=author&query=Hegde%2C+H">Harshad Hegde</a>, 
<a href="/search/cs?searchtype=author&query=Mungall%2C+C+J">Christopher J. Mungall</a>, 
<a href="/search/cs?searchtype=author&query=Giannakou%2C+A">Anna Giannakou</a>, 
<a href="/search/cs?searchtype=author&query=Byers%2C+N+P">Neil P. Byers</a>, 
<a href="/search/cs?searchtype=author&query=Gunter%2C+D">Dan Gunter</a>, 
<a href="/search/cs?searchtype=author&query=Fagnan%2C+K">Kjiersten Fagnan</a>, 
<a href="/search/cs?searchtype=author&query=Ramakrishnan%2C+L">Lavanya Ramakrishnan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 6 figures, 10 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Genomics (q-bio.GN)

</div>
<p class="mathjax">Advanced omics technologies and facilities generate a wealth of valuable data
daily; however, the data often lacks the essential metadata required for
researchers to find and search them effectively. The lack of metadata poses a
significant challenge in the utilization of these datasets. Machine
learning-based metadata extraction techniques have emerged as a potentially
viable approach to automatically annotating scientific datasets with the
metadata necessary for enabling effective search. Text labeling, usually
performed manually, plays a crucial role in validating machine-extracted
metadata. However, manual labeling is time-consuming; thus, there is an need to
develop automated text labeling techniques in order to accelerate the process
of scientific innovation. This need is particularly urgent in fields such as
environmental genomics and microbiome science, which have historically received
less attention in terms of metadata curation and creation of gold-standard text
mining datasets.
<br />In this paper, we present two novel automated text labeling approaches for
the validation of ML-generated metadata for unlabeled texts, with specific
applications in environmental genomics. Our techniques show the potential of
two new ways to leverage existing information about the unlabeled texts and the
scientific domain. The first technique exploits relationships between different
types of data sources related to the same research study, such as publications
and proposals. The second technique takes advantage of domain-specific
controlled vocabularies or ontologies. In this paper, we detail applying these
approaches for ML-generated metadata validation. Our results show that the
proposed label assignment approaches can generate both generic and
highly-specific text labels for the unlabeled texts, with up to 44% of the
labels matching with those suggested by a ML keyword extraction algorithm.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05043" title="Abstract">arXiv:2311.05043</a> [<a href="/pdf/2311.05043" title="Download PDF">pdf</a>, <a href="/format/2311.05043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-shot Translation of Attention Patterns in VQA Models to Natural  Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salewski%2C+L">Leonard Salewski</a>, 
<a href="/search/cs?searchtype=author&query=Koepke%2C+A+S">A. Sophia Koepke</a>, 
<a href="/search/cs?searchtype=author&query=Lensch%2C+H+P+A">Hendrik P. A. Lensch</a>, 
<a href="/search/cs?searchtype=author&query=Akata%2C+Z">Zeynep Akata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in GCPR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Converting a model's internals to text can yield human-understandable
insights about the model. Inspired by the recent success of training-free
approaches for image captioning, we propose ZS-A2T, a zero-shot framework that
translates the transformer attention of a given model into natural language
without requiring any training. We consider this in the context of Visual
Question Answering (VQA). ZS-A2T builds on a pre-trained large language model
(LLM), which receives a task prompt, question, and predicted answer, as inputs.
The LLM is guided to select tokens which describe the regions in the input
image that the VQA model attended to. Crucially, we determine this similarity
by exploiting the text-image matching capabilities of the underlying VQA model.
Our framework does not require any training and allows the drop-in replacement
of different guiding sources (e.g. attribution instead of attention maps), or
language models. We evaluate this novel task on textual explanation datasets
for VQA, giving state-of-the-art performances for the zero-shot setting on
GQA-REX and VQA-X. Our code is available at:
https://github.com/ExplainableML/ZS-A2T.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05047" title="Abstract">arXiv:2311.05047</a> [<a href="/pdf/2311.05047" title="Download PDF">pdf</a>, <a href="/ps/2311.05047" title="Download PostScript">ps</a>, <a href="/format/2311.05047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepLearningBrasil@LT-EDI-2023: Exploring Deep Learning Techniques for  Detecting Depression in Social Media Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garcia%2C+E">Eduardo Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Gomes%2C+J">Juliana Gomes</a>, 
<a href="/search/cs?searchtype=author&query=J%C3%BAnior%2C+A+B">Adalberto Barbosa J&#xfa;nior</a>, 
<a href="/search/cs?searchtype=author&query=Borges%2C+C">Cardeque Borges</a>, 
<a href="/search/cs?searchtype=author&query=da+Silva%2C+N">N&#xe1;dia da Silva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this paper, we delineate the strategy employed by our team,
DeepLearningBrasil, which secured us the first place in the shared task
DepSign-LT-EDI@RANLP-2023, achieving a 47.0% Macro F1-Score and a notable 2.4%
advantage. The task was to classify social media texts into three distinct
levels of depression - "not depressed," "moderately depressed," and "severely
depressed." Leveraging the power of the RoBERTa and DeBERTa models, we further
pre-trained them on a collected Reddit dataset, specifically curated from
mental health-related Reddit's communities (Subreddits), leading to an enhanced
understanding of nuanced mental health discourse. To address lengthy textual
data, we used truncation techniques that retained the essence of the content by
focusing on its beginnings and endings. Our model was robust against unbalanced
data by incorporating sample weights into the loss. Cross-validation and
ensemble techniques were then employed to combine our k-fold trained models,
delivering an optimal solution. The accompanying code is made available for
transparency and further development.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05050" title="Abstract">arXiv:2311.05050</a> [<a href="/pdf/2311.05050" title="Download PDF">pdf</a>, <a href="/format/2311.05050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Generative Modeling of Sequential Data with Trainable Token  Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+W">Wanda Hou</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+L">Li Miao</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Y">Yi-Zhuang You</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">Generative models are a class of machine learning models that aim to learn
the underlying probability distribution of data. Unlike discriminative models,
generative models focus on capturing the data's inherent structure, allowing
them to generate new samples that resemble the original data. To fully exploit
the potential of modeling probability distributions using quantum physics, a
quantum-inspired generative model known as the Born machines have shown great
advancements in learning classical and quantum data over matrix product
state(MPS) framework. The Born machines support tractable log-likelihood,
autoregressive and mask sampling, and have shown outstanding performance in
various unsupervised learning tasks. However, much of the current research has
been centered on improving the expressive power of MPS, predominantly embedding
each token directly by a corresponding tensor index. In this study, we
generalize the embedding method into trainable quantum measurement operators
that can be simultaneously honed with MPS. Our study indicated that combined
with trainable embedding, Born machines can exhibit better performance and
learn deeper correlations from the dataset.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05051" title="Abstract">arXiv:2311.05051</a> [<a href="/pdf/2311.05051" title="Download PDF">pdf</a>, <a href="/format/2311.05051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning Brasil at ABSAPT 2022: Portuguese Transformer Ensemble  Approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gomes%2C+J+R+S">Juliana Resplande Santanna Gomes</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+E+A+S">Eduardo Augusto Santos Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Junior%2C+A+F+B">Adalberto Ferreira Barbosa Junior</a>, 
<a href="/search/cs?searchtype=author&query=Rodrigues%2C+R+C">Ruan Chaves Rodrigues</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+D+F+C">Diogo Fernandes Costa Silva</a>, 
<a href="/search/cs?searchtype=author&query=Maia%2C+D+F">Dyonnatan Ferreira Maia</a>, 
<a href="/search/cs?searchtype=author&query=da+Silva%2C+N+F+F">N&#xe1;dia F&#xe9;lix Felipe da Silva</a>, 
<a href="/search/cs?searchtype=author&query=Filho%2C+A+R+G">Arlindo Rodrigues Galv&#xe3;o Filho</a>, 
<a href="/search/cs?searchtype=author&query=da+Silva+Soares%2C+A">Anderson da Silva Soares</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 3 figures, In Proceedings of the Iberian Languages Evaluation Forum (IberLEF 2022), Online. CEUR. org
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Aspect-based Sentiment Analysis (ABSA) is a task whose objective is to
classify the individual sentiment polarity of all entities, called aspects, in
a sentence. The task is composed of two subtasks: Aspect Term Extraction (ATE),
identify all aspect terms in a sentence; and Sentiment Orientation Extraction
(SOE), given a sentence and its aspect terms, the task is to determine the
sentiment polarity of each aspect term (positive, negative or neutral). This
article presents we present our participation in Aspect-Based Sentiment
Analysis in Portuguese (ABSAPT) 2022 at IberLEF 2022. We submitted the best
performing systems, achieving new state-of-the-art results on both subtasks.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05052" title="Abstract">arXiv:2311.05052</a> [<a href="/pdf/2311.05052" title="Download PDF">pdf</a>, <a href="/ps/2311.05052" title="Download PostScript">ps</a>, <a href="/format/2311.05052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Matrix Completion via Memoryless Scalar Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eamaz%2C+A">Arian Eamaz</a>, 
<a href="/search/cs?searchtype=author&query=Yeganegi%2C+F">Farhang Yeganegi</a>, 
<a href="/search/cs?searchtype=author&query=Soltanalian%2C+M">Mojtaba Soltanalian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2310.03224">arXiv:2310.03224</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">We delve into the impact of memoryless scalar quantization on matrix
completion. We broaden our theoretical discussion to encompass the coarse
quantization scenario with a dithering scheme, where the only available
information for low-rank matrix recovery is few-bit low-resolution data. Our
primary motivation for this research is to evaluate the recovery performance of
nuclear norm minimization in handling quantized matrix problems without the use
of any regularization terms such as those stemming from maximum likelihood
estimation. We furnish theoretical guarantees for both scenarios: when access
to dithers is available during the reconstruction process, and when we have
access solely to the statistical properties of the dithers. Additionally, we
conduct a comprehensive analysis of the effects of sign flips and
prequantization noise on the recovery performance, particularly when the impact
of sign flips is quantified using the well-known Hamming distance in the upper
bound of recovery error.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05054" title="Abstract">arXiv:2311.05054</a> [<a href="/pdf/2311.05054" title="Download PDF">pdf</a>, <a href="/format/2311.05054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometry-Calibrated DRO: Combating Over-Pessimism with Free Energy  Implications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiashuo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiayun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+H">Hao Zou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+P">Peng Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Short version appears at 37th Conference on Neural Information Processing Systems (NeurIPS 2023), Workshop on Distribution Shifts (DistShift)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Machine learning algorithms minimizing average risk are susceptible to
distributional shifts. Distributionally Robust Optimization (DRO) addresses
this issue by optimizing the worst-case risk within an uncertainty set.
However, DRO suffers from over-pessimism, leading to low-confidence
predictions, poor parameter estimations as well as poor generalization. In this
work, we conduct a theoretical analysis of a probable root cause of
over-pessimism: excessive focus on noisy samples. To alleviate the impact of
noise, we incorporate data geometry into calibration terms in DRO, resulting in
our novel Geometry-Calibrated DRO (GCDRO) for regression. We establish the
connection between our risk objective and the Helmholtz free energy in
statistical physics, and this free-energy-based risk can extend to standard DRO
methods. Leveraging gradient flow in Wasserstein space, we develop an
approximate minimax optimization algorithm with a bounded error ratio and
elucidate how our approach mitigates noisy sample effects. Comprehensive
experiments confirm GCDRO's superiority over conventional DRO methods.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05061" title="Abstract">arXiv:2311.05061</a> [<a href="/pdf/2311.05061" title="Download PDF">pdf</a>, <a href="/format/2311.05061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Compression of Overparameterized Deep Models through  Low-Dimensional Learning Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kwon%2C+S+M">Soo Min Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zekai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Dogyoon Song</a>, 
<a href="/search/cs?searchtype=author&query=Balzano%2C+L">Laura Balzano</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Q">Qing Qu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Overparameterized models have proven to be powerful tools for solving various
machine learning tasks. However, overparameterization often leads to a
substantial increase in computational and memory costs, which in turn requires
extensive resources to train. In this work, we aim to reduce this complexity by
studying the learning dynamics of overparameterized deep networks. By
extensively studying its learning dynamics, we unveil that the weight matrices
of various architectures exhibit a low-dimensional structure. This finding
implies that we can compress the networks by reducing the training to a small
subspace. We take a step in developing a principled approach for compressing
deep networks by studying deep linear models. We demonstrate that the principal
components of deep linear models are fitted incrementally but within a small
subspace, and use these insights to compress deep linear networks by decreasing
the width of its intermediate layers. Remarkably, we observe that with a
particular choice of initialization, the compressed network converges faster
than the original network, consistently yielding smaller recovery errors
throughout all iterations of gradient descent. We substantiate this observation
by developing a theory focused on the deep matrix factorization problem, and by
conducting empirical evaluations on deep matrix sensing. Finally, we
demonstrate how our compressed model can enhance the utility of deep nonlinear
models. Overall, we observe that our compression technique accelerates the
training process by more than 2x, without compromising model quality.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05063" title="Abstract">arXiv:2311.05063</a> [<a href="/pdf/2311.05063" title="Download PDF">pdf</a>, <a href="/format/2311.05063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rust for Embedded Systems: Current State, Challenges and Open Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Ayushi Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+S">Shashank Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Torres-Arias%2C+S">Santiago Torres-Arias</a>, 
<a href="/search/cs?searchtype=author&query=Machiry%2C+A">Aravind Machiry</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Embedded software is used in safety-critical systems such as medical devices
and autonomous vehicles, where software defects, including security
vulnerabilities, have severe consequences. Most embedded codebases are
developed in unsafe languages, specifically C/C++, and are riddled with memory
safety vulnerabilities. To prevent such vulnerabilities, RUST, a performant
memory-safe systems language, provides an optimal choice for developing
embedded software. RUST interoperability enables developing RUST applications
on top of existing C codebases. Despite this, even the most resourceful
organizations continue to develop embedded software in C/C++. This paper
performs the first systematic study to holistically understand the current
state and challenges of using RUST for embedded systems. Our study is organized
across three research questions. We collected a dataset of 2,836 RUST embedded
software spanning various categories and 5 Static Application Security Testing
( SAST) tools. We performed a systematic analysis of our dataset and surveys
with 225 developers to investigate our research questions. We found that
existing RUST software support is inadequate, SAST tools cannot handle certain
features of RUST embedded software, resulting in failures, and the prevalence
of advanced types in existing RUST software makes it challenging to engineer
interoperable code. In addition, we found various challenges faced by
developers in using RUST for embedded systems development.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05067" title="Abstract">arXiv:2311.05067</a> [<a href="/pdf/2311.05067" title="Download PDF">pdf</a>, <a href="/format/2311.05067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Exploration with Unlabeled Prior Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qiyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jason Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+D">Dibya Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Amy Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+S">Sergey Levine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 16 figures, 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Learning to solve tasks from a sparse reward signal is a major challenge for
standard reinforcement learning (RL) algorithms. However, in the real world,
agents rarely need to solve sparse reward tasks entirely from scratch. More
often, we might possess prior experience to draw on that provides considerable
guidance about which actions and outcomes are possible in the world, which we
can use to explore more effectively for new tasks. In this work, we study how
prior data without reward labels may be used to guide and accelerate
exploration for an agent solving a new sparse reward task. We propose a simple
approach that learns a reward model from online experience, labels the
unlabeled prior data with optimistic rewards, and then uses it concurrently
alongside the online data for downstream policy and critic optimization. This
general formula leads to rapid exploration in several challenging sparse-reward
domains where tabula rasa exploration is insufficient, including the AntMaze
domain, Adroit hand manipulation domain, and a visual simulated robotic
manipulation domain. Our results highlight the ease of incorporating unlabeled
prior data into existing online RL algorithms, and the (perhaps surprising)
effectiveness of doing so.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05069" title="Abstract">arXiv:2311.05069</a> [<a href="/pdf/2311.05069" title="Download PDF">pdf</a>, <a href="/ps/2311.05069" title="Download PostScript">ps</a>, <a href="/format/2311.05069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robotics for poultry farming: challenges and opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ozenturk%2C+U">Ugur Ozenturk</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhengqi Chen</a> (3), 
<a href="/search/cs?searchtype=author&query=Jamone%2C+L">Lorenzo Jamone</a> (3), 
<a href="/search/cs?searchtype=author&query=Versace%2C+E">Elisabetta Versace</a> (1) ((1) School of Biological and Behavioural Sciences, Department of Biological and Experimental Psychology, Queen Mary University of London, UK, (2) Ataturk University, Faculty of Veterinary Medicine, Department of Animal Science, Turkiye, (3) ARQ (Advanced Robotics at Queen Mary), School of Engineering and Materials Science, Queen Mary University of London, UK)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 50 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Poultry farming plays a pivotal role in addressing human food demand. Robots
are emerging as promising tools in poultry farming, with the potential to
address sustainability issues while meeting the increasing production needs and
demand for animal welfare. This review aims to identify the current
advancements, limitations and future directions of development for robotics in
poultry farming by examining existing challenges, solutions and innovative
research, including robot-animal interactions. We cover the application of
robots in different areas, from environmental monitoring to disease control,
floor eggs collection and animal welfare. Robots not only demonstrate effective
implementation on farms but also hold potential for ethological research on
collective and social behaviour, which can in turn drive a better integration
in industrial farming, with improved productivity and enhanced animal welfare.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05071" title="Abstract">arXiv:2311.05071</a> [<a href="/pdf/2311.05071" title="Download PDF">pdf</a>, <a href="/format/2311.05071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Behavior of Audio-Visual Fusion Architectures in Identity  Verification Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Claborne%2C+D">Daniel Claborne</a>, 
<a href="/search/cs?searchtype=author&query=Slyman%2C+E">Eric Slyman</a>, 
<a href="/search/cs?searchtype=author&query=Pazdernik%2C+K">Karl Pazdernik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We train an identity verification architecture and evaluate modifications to
the part of the model that combines audio and visual representations, including
in scenarios where one input is missing in either of two examples to be
compared. We report results on the Voxceleb1-E test set that suggest averaging
the output embeddings improves error rate in the full-modality setting and when
a single modality is missing, and makes more complete use of the embedding
space than systems which use shared layers and discuss possible reasons for
this behavior.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05074" title="Abstract">arXiv:2311.05074</a> [<a href="/pdf/2311.05074" title="Download PDF">pdf</a>, <a href="/format/2311.05074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Framework to Assess (Dis)agreement Among Diverse Rater Groups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prabhakaran%2C+V">Vinodkumar Prabhakaran</a>, 
<a href="/search/cs?searchtype=author&query=Homan%2C+C">Christopher Homan</a>, 
<a href="/search/cs?searchtype=author&query=Aroyo%2C+L">Lora Aroyo</a>, 
<a href="/search/cs?searchtype=author&query=Parrish%2C+A">Alicia Parrish</a>, 
<a href="/search/cs?searchtype=author&query=Taylor%2C+A">Alex Taylor</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz%2C+M">Mark D&#xed;az</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Ding Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent advancements in conversational AI have created an urgent need for
safety guardrails that prevent users from being exposed to offensive and
dangerous content. Much of this work relies on human ratings and feedback, but
does not account for the fact that perceptions of offense and safety are
inherently subjective and that there may be systematic disagreements between
raters that align with their socio-demographic identities. Instead, current
machine learning approaches largely ignore rater subjectivity and use gold
standards that obscure disagreements (e.g., through majority voting). In order
to better understand the socio-cultural leanings of such tasks, we propose a
comprehensive disagreement analysis framework to measure systematic diversity
in perspectives among different rater subgroups. We then demonstrate its
utility by applying this framework to a dataset of human-chatbot conversations
rated by a demographically diverse pool of raters. Our analysis reveals
specific rater groups that have more diverse perspectives than the rest, and
informs demographic axes that are crucial to consider for safety annotations.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05075" title="Abstract">arXiv:2311.05075</a> [<a href="/pdf/2311.05075" title="Download PDF">pdf</a>, <a href="/ps/2311.05075" title="Download PostScript">ps</a>, <a href="/format/2311.05075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mental Health Diagnosis in the Digital Age: Harnessing Sentiment  Analysis on Social Media Platforms upon Ultra-Sparse Feature Content
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+H">Haijian Shao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Ming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+S">Shengjie Zhai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Amid growing global mental health concerns, particularly among vulnerable
groups, natural language processing offers a tremendous potential for early
detection and intervention of people's mental disorders via analyzing their
postings and discussions on social media platforms. However, ultra-sparse
training data, often due to vast vocabularies and low-frequency words, hinders
the analysis accuracy. Multi-labeling and Co-occurrences of symptoms may also
blur the boundaries in distinguishing similar/co-related disorders. To address
these issues, we propose a novel semantic feature preprocessing technique with
a three-folded structure: 1) mitigating the feature sparsity with a weak
classifier, 2) adaptive feature dimension with modulus loops, and 3)
deep-mining and extending features among the contexts. With enhanced semantic
features, we train a machine learning model to predict and classify mental
disorders. We utilize the Reddit Mental Health Dataset 2022 to examine
conditions such as Anxiety, Borderline Personality Disorder (BPD), and
Bipolar-Disorder (BD) and present solutions to the data sparsity challenge,
highlighted by 99.81% non-zero elements. After applying our preprocessing
technique, the feature sparsity decreases to 85.4%. Overall, our methods, when
compared to seven benchmark models, demonstrate significant performance
improvements: 8.0% in accuracy, 0.069 in precision, 0.093 in recall, 0.102 in
F1 score, and 0.059 in AUC. This research provides foundational insights for
mental health prediction and monitoring, providing innovative solutions to
navigate challenges associated with ultra-sparse data feature and intricate
multi-label classification in the domain of mental health analysis.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05076" title="Abstract">arXiv:2311.05076</a> [<a href="/pdf/2311.05076" title="Download PDF">pdf</a>, <a href="/format/2311.05076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating diversion and treatment policies for opioid use disorder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=White%2C+V+M">Veronica M. White</a>, 
<a href="/search/cs?searchtype=author&query=Albert%2C+L+A">Laura A. Albert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">The United States opioid crisis has led to over 840,000 fatalities since the
1990s. It has strained hospitals, treatment facilities, and law enforcement
agencies due to the enormous resources and procedures needed to respond to the
crisis. As a result, many individuals who use opioids never receive or finish
the treatment they need and instead have many interactions with hospitals or
the criminal justice system. This paper introduces a discrete event simulation
model that evaluates three opioid use disorder treatment policies: arrest
diversion, re-entry case management, and overdose diversion. Publicly available
data from 2011 to 2019 in Dane County, Wisconsin, was used to forecast
opioid-related outcomes through 2032. Through analyzing a variety of policy-mix
implementations, the study offers a versatile framework for evaluating policies
at various implementation levels. The results demonstrate that treatment
policies that create new pathways and programming by utilizing treatment
services and successfully divert at least 20\% of eligible individuals can lead
to more opioid-resilient communities. The benefits increase when more policies
are enacted and/or are offered to more individuals. We assume communities
invest in increasing treatment capacity to meet increased treatment demand. In
policy-mixes where societal savings from decreased opioid use, hospital
encounters, and opioid-related arrests outweigh the costs of opioid use
disorder treatment, the 2032 total savings range from \$7.04 to \$29.73
million. To reverse the opioid crisis within a community, treatment policies
may need to be combined with other strategies, such as harm reduction, supply
reduction, and use prevention.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05077" title="Abstract">arXiv:2311.05077</a> [<a href="/pdf/2311.05077" title="Download PDF">pdf</a>, <a href="/format/2311.05077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> POISE: Pose Guided Human Silhouette Extraction under Occlusions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dutta%2C+A">Arindam Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Lal%2C+R">Rohit Lal</a>, 
<a href="/search/cs?searchtype=author&query=Raychaudhuri%2C+D+S">Dripta S. Raychaudhuri</a>, 
<a href="/search/cs?searchtype=author&query=Ta%2C+C+K">Calvin Khang Ta</a>, 
<a href="/search/cs?searchtype=author&query=Roy-Chowdhury%2C+A+K">Amit K. Roy-Chowdhury</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Winter Conference on Applications of Computer Vision, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Human silhouette extraction is a fundamental task in computer vision with
applications in various downstream tasks. However, occlusions pose a
significant challenge, leading to incomplete and distorted silhouettes. To
address this challenge, we introduce POISE: Pose Guided Human Silhouette
Extraction under Occlusions, a novel self-supervised fusion framework that
enhances accuracy and robustness in human silhouette prediction. By combining
initial silhouette estimates from a segmentation model with human joint
predictions from a 2D pose estimation model, POISE leverages the complementary
strengths of both approaches, effectively integrating precise body shape
information and spatial information to tackle occlusions. Furthermore, the
self-supervised nature of \POISE eliminates the need for costly annotations,
making it scalable and practical. Extensive experimental results demonstrate
its superiority in improving silhouette extraction under occlusions, with
promising results in downstream tasks such as gait recognition. The code for
our method is available https://github.com/take2rohit/poise.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05079" title="Abstract">arXiv:2311.05079</a> [<a href="/pdf/2311.05079" title="Download PDF">pdf</a>, <a href="/format/2311.05079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Social Media Bot Detection using Dropout-GAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shukla%2C+A">Anant Shukla</a>, 
<a href="/search/cs?searchtype=author&query=Jurecek%2C+M">Martin Jurecek</a>, 
<a href="/search/cs?searchtype=author&query=Stamp%2C+M">Mark Stamp</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Bot activity on social media platforms is a pervasive problem, undermining
the credibility of online discourse and potentially leading to cybercrime. We
propose an approach to bot detection using Generative Adversarial Networks
(GAN). We discuss how we overcome the issue of mode collapse by utilizing
multiple discriminators to train against one generator, while decoupling the
discriminator to perform social media bot detection and utilizing the generator
for data augmentation. In terms of classification accuracy, our approach
outperforms the state-of-the-art techniques in this field. We also show how the
generator in the GAN can be used to evade such a classification technique.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05081" title="Abstract">arXiv:2311.05081</a> [<a href="/pdf/2311.05081" title="Download PDF">pdf</a>, <a href="/format/2311.05081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized test utilities for long-tail performance in extreme  multi-label classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schultheis%2C+E">Erik Schultheis</a>, 
<a href="/search/cs?searchtype=author&query=Wydmuch%2C+M">Marek Wydmuch</a>, 
<a href="/search/cs?searchtype=author&query=Kot%C5%82owski%2C+W">Wojciech Kot&#x142;owski</a>, 
<a href="/search/cs?searchtype=author&query=Babbar%2C+R">Rohit Babbar</a>, 
<a href="/search/cs?searchtype=author&query=Dembczy%C5%84ski%2C+K">Krzysztof Dembczy&#x144;ski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the authors' version of the work accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Extreme multi-label classification (XMLC) is the task of selecting a small
subset of relevant labels from a very large set of possible labels. As such, it
is characterized by long-tail labels, i.e., most labels have very few positive
instances. With standard performance measures such as precision@k, a classifier
can ignore tail labels and still report good performance. However, it is often
argued that correct predictions in the tail are more interesting or rewarding,
but the community has not yet settled on a metric capturing this intuitive
concept. The existing propensity-scored metrics fall short on this goal by
confounding the problems of long-tail and missing labels. In this paper, we
analyze generalized metrics budgeted "at k" as an alternative solution. To
tackle the challenging problem of optimizing these metrics, we formulate it in
the expected test utility (ETU) framework, which aims at optimizing the
expected performance on a fixed test set. We derive optimal prediction rules
and construct computationally efficient approximations with provable regret
guarantees and robustness against model misspecification. Our algorithm, based
on block coordinate ascent, scales effortlessly to XMLC problems and obtains
promising results in terms of long-tail performance.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05082" title="Abstract">arXiv:2311.05082</a> [<a href="/pdf/2311.05082" title="Download PDF">pdf</a>, <a href="/format/2311.05082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Adaptation Gains for Nonlinear Systems with Unmatched  Uncertainties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lopez%2C+B+T">Brett T. Lopez</a>, 
<a href="/search/eess?searchtype=author&query=Slotine%2C+J">Jean-Jacques Slotine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> V1
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">We present a new direct adaptive control approach for nonlinear systems with
unmatched and matched uncertainties. The method relies on adjusting the
adaptation gains of individual unmatched parameters whose adaptation transients
would otherwise destabilize the closed-loop system. The approach also
guarantees the restoration of the adaptation gains to their nominal values and
can readily incorporate direct adaptation laws for matched uncertainties. The
proposed framework is general as it only requires stabilizability for all
possible models.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05084" title="Abstract">arXiv:2311.05084</a> [<a href="/pdf/2311.05084" title="Download PDF">pdf</a>, <a href="/format/2311.05084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Signal Temporal Logic-Guided Apprenticeship Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Puranic%2C+A+G">Aniruddh G. Puranic</a>, 
<a href="/search/cs?searchtype=author&query=Deshmukh%2C+J+V">Jyotirmoy V. Deshmukh</a>, 
<a href="/search/cs?searchtype=author&query=Nikolaidis%2C+S">Stefanos Nikolaidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Apprenticeship learning crucially depends on effectively learning rewards,
and hence control policies from user demonstrations. Of particular difficulty
is the setting where the desired task consists of a number of sub-goals with
temporal dependencies. The quality of inferred rewards and hence policies are
typically limited by the quality of demonstrations, and poor inference of these
can lead to undesirable outcomes. In this letter, we show how temporal logic
specifications that describe high level task objectives, are encoded in a graph
to define a temporal-based metric that reasons about behaviors of demonstrators
and the learner agent to improve the quality of inferred rewards and policies.
Through experiments on a diverse set of robot manipulator simulations, we show
how our framework overcomes the drawbacks of prior literature by drastically
improving the number of demonstrations required to learn a control policy.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05085" title="Abstract">arXiv:2311.05085</a> [<a href="/pdf/2311.05085" title="Download PDF">pdf</a>, <a href="/format/2311.05085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizing Large Language Models as Rationalizers of  Knowledge-intensive Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mishra%2C+A">Aditi Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+S">Sajjadur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hannah Kim</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+K">Kushan Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Hruschka%2C+E">Estevam Hruschka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) are proficient at generating fluent text with
minimal task-specific supervision. Yet, their ability to provide well-grounded
rationalizations for knowledge-intensive tasks remains under-explored. Such
tasks, like commonsense multiple-choice questions, require rationales based on
world knowledge to support predictions and refute alternate options. We
consider the task of generating knowledge-guided rationalization in natural
language by using expert-written examples in a few-shot manner. Surprisingly,
crowd-workers preferred knowledge-grounded rationales over crowdsourced
rationalizations, citing their factuality, sufficiency, and comprehensive
refutations. Although LLMs-generated rationales were preferable, further
improvements in conciseness and novelty are required. In another study, we show
how rationalization of incorrect model predictions erodes humans' trust in
LLM-generated rationales. Motivated by these observations, we create a
two-stage pipeline to review task predictions and eliminate potential incorrect
decisions before rationalization, enabling trustworthy rationale generation.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05088" title="Abstract">arXiv:2311.05088</a> [<a href="/pdf/2311.05088" title="Download PDF">pdf</a>, <a href="/format/2311.05088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta-learning of semi-supervised learning from tasks with heterogeneous  attribute spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Iwata%2C+T">Tomoharu Iwata</a>, 
<a href="/search/cs?searchtype=author&query=Kumagai%2C+A">Atsutoshi Kumagai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">We propose a meta-learning method for semi-supervised learning that learns
from multiple tasks with heterogeneous attribute spaces. The existing
semi-supervised meta-learning methods assume that all tasks share the same
attribute space, which prevents us from learning with a wide variety of tasks.
With the proposed method, the expected test performance on tasks with a small
amount of labeled data is improved with unlabeled data as well as data in
various tasks, where the attribute spaces are different among tasks. The
proposed method embeds labeled and unlabeled data simultaneously in a
task-specific space using a neural network, and the unlabeled data's labels are
estimated by adapting classification or regression models in the embedding
space. For the neural network, we develop variable-feature self-attention
layers, which enable us to find embeddings of data with different attribute
spaces with a single neural network by considering interactions among examples,
attributes, and labels. Our experiments on classification and regression
datasets with heterogeneous attribute spaces demonstrate that our proposed
method outperforms the existing meta-learning and semi-supervised learning
methods.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05089" title="Abstract">arXiv:2311.05089</a> [<a href="/pdf/2311.05089" title="Download PDF">pdf</a>, <a href="/format/2311.05089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Legal-HNet: Mixing Legal Long-Context Tokens with Hartley Transform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Giofr%C3%A9%2C+D">Daniele Giofr&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Ghantasala%2C+S">Sneha Ghantasala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Since its introduction, the transformers architecture has seen great adoption
in NLP applications, but it also has limitations. Although the self-attention
mechanism allows for generating very rich representations of the input text,
its effectiveness may be limited in specialized domains such as legal, where,
for example, language models often have to process very long texts. In this
paper, we explore alternatives to replace the attention-based layers with
simpler token-mixing mechanisms: Hartley and Fourier transforms. Using these
non-parametric techniques, we train models with long input documents from
scratch in the legal domain setting. We also introduce a new hybrid Seq2Seq
architecture, a no-attention-based encoder connected with an attention-based
decoder, which performs quite well on existing summarization tasks with much
less compute and memory requirements. We believe that similar, if not better
performance, as in the case of long correlations of abstractive text
summarization tasks, can be achieved by adopting these simpler infrastructures.
This not only makes training models from scratch accessible to more people, but
also contributes to the reduction of the carbon footprint during training.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05090" title="Abstract">arXiv:2311.05090</a> [<a href="/pdf/2311.05090" title="Download PDF">pdf</a>, <a href="/format/2311.05090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Motion Masking for Secure, Usable, and Scalable Real-Time  Anonymization of Virtual Reality Motion Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nair%2C+V">Vivek Nair</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Wenbo Guo</a>, 
<a href="/search/cs?searchtype=author&query=O%27Brien%2C+J+F">James F. O&#x27;Brien</a>, 
<a href="/search/cs?searchtype=author&query=Rosenberg%2C+L">Louis Rosenberg</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Dawn Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Virtual reality (VR) and "metaverse" systems have recently seen a resurgence
in interest and investment as major technology companies continue to enter the
space. However, recent studies have demonstrated that the motion tracking
"telemetry" data used by nearly all VR applications is as uniquely identifiable
as a fingerprint scan, raising significant privacy concerns surrounding
metaverse technologies. Although previous attempts have been made to anonymize
VR motion data, we present in this paper a state-of-the-art VR identification
model that can convincingly bypass known defensive countermeasures. We then
propose a new "deep motion masking" approach that scalably facilitates the
real-time anonymization of VR telemetry data. Through a large-scale user study
(N=182), we demonstrate that our method is significantly more usable and
private than existing VR anonymity systems.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05092" title="Abstract">arXiv:2311.05092</a> [<a href="/pdf/2311.05092" title="Download PDF">pdf</a>, <a href="/format/2311.05092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GeoFormer: Predicting Human Mobility using Generative Pre-trained  Transformer (GPT)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Solatorio%2C+A+V">Aivin V. Solatorio</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in the HuMob-Challenge '23: 1st International Workshop on the Human Mobility Prediction Challenge. Repository is available at <a href="https://github.com/avsolatorio/GeoFormer">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Predicting human mobility holds significant practical value, with
applications ranging from enhancing disaster risk planning to simulating
epidemic spread. In this paper, we present the GeoFormer, a decoder-only
transformer model adapted from the GPT architecture to forecast human mobility.
Our proposed model is rigorously tested in the context of the HuMob Challenge
2023 -- a competition designed to evaluate the performance of prediction models
on standardized datasets to predict human mobility. The challenge leverages two
datasets encompassing urban-scale data of 25,000 and 100,000 individuals over a
longitudinal period of 75 days. GeoFormer stands out as a top performer in the
competition, securing a place in the top-3 ranking. Its success is underscored
by performing well on both performance metrics chosen for the competition --
the GEO-BLEU and the Dynamic Time Warping (DTW) measures. The performance of
the GeoFormer on the HuMob Challenge 2023 underscores its potential to make
substantial contributions to the field of human mobility prediction, with
far-reaching implications for disaster preparedness, epidemic control, and
beyond.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05094" title="Abstract">arXiv:2311.05094</a> [<a href="/pdf/2311.05094" title="Download PDF">pdf</a>, <a href="/format/2311.05094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Combinatorial Algorithms for Efficient Sortation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Van+Dyk%2C+M">Madison Van Dyk</a>, 
<a href="/search/cs?searchtype=author&query=Klause%2C+K">Kim Klause</a>, 
<a href="/search/cs?searchtype=author&query=Koenemann%2C+J">Jochen Koenemann</a>, 
<a href="/search/cs?searchtype=author&query=Megow%2C+N">Nicole Megow</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
<p class="mathjax">Modern parcel logistic networks are designed to ship demand between given
origin, destination pairs of nodes in an underlying directed network.
Efficiency dictates that volume needs to be consolidated at intermediate nodes
in typical hub-and-spoke fashion. In practice, such consolidation requires
parcel sortation. In this work, we propose a mathematical model for the
physical requirements, and limitations of parcel sortation. We then show that
it is NP-hard to determine whether a feasible sortation plan exists. We discuss
several settings, where (near-)feasibility of a given sortation instance can be
determined efficiently. The algorithms we propose are fast and build on
combinatorial witness set type lower bounds that are reminiscent and extend
those used in earlier work on degree-bounded spanning trees and arborescences.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05100" title="Abstract">arXiv:2311.05100</a> [<a href="/pdf/2311.05100" title="Download PDF">pdf</a>, <a href="/format/2311.05100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-similarity Prior Distillation for Unsupervised Remote Physiological  Measurement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weiyu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Ying Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yun Ge</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaolin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jie Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yingcong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Remote photoplethysmography (rPPG) is a noninvasive technique that aims to
capture subtle variations in facial pixels caused by changes in blood volume
resulting from cardiac activities. Most existing unsupervised methods for rPPG
tasks focus on the contrastive learning between samples while neglecting the
inherent self-similar prior in physiological signals. In this paper, we propose
a Self-Similarity Prior Distillation (SSPD) framework for unsupervised rPPG
estimation, which capitalizes on the intrinsic self-similarity of cardiac
activities. Specifically, we first introduce a physical-prior embedded
augmentation technique to mitigate the effect of various types of noise. Then,
we tailor a self-similarity-aware network to extract more reliable self-similar
physiological features. Finally, we develop a hierarchical self-distillation
paradigm to assist the network in disentangling self-similar physiological
patterns from facial videos. Comprehensive experiments demonstrate that the
unsupervised SSPD framework achieves comparable or even superior performance
compared to the state-of-the-art supervised methods. Meanwhile, SSPD maintains
the lowest inference time and computation cost among end-to-end models. The
source codes are available at https://github.com/LinXi1C/SSPD.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05101" title="Abstract">arXiv:2311.05101</a> [<a href="/pdf/2311.05101" title="Download PDF">pdf</a>, <a href="/format/2311.05101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrated Sensing and Communication for Network-Assisted Full-Duplex  Cell-Free Distributed Massive MIMO Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+F">Fan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jingxuan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiamin Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Feiyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dongming Wang</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+X">Xiaohu You</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we combine the network-assisted full-duplex (NAFD) technology
and distributed radar sensing to implement integrated sensing and communication
(ISAC). The ISAC system features both uplink and downlink remote radio units
(RRUs) equipped with communication and sensing capabilities. We evaluate the
communication and sensing performance of the system using the sum communication
rates and the Cramer-Rao lower bound (CRLB), respectively. We compare the
performance of the proposed scheme with other ISAC schemes, the result shows
that the proposed scheme can provide more stable sensing and better
communication performance. Furthermore, we propose two power allocation
algorithms to optimize the communication and sensing performance jointly. One
algorithm is based on the deep Q-network (DQN) and the other one is based on
the non-dominated sorting genetic algorithm II (NSGA-II). The proposed
algorithms provide more feasible solutions and achieve better system
performance than the equal power allocation algorithm.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05106" title="Abstract">arXiv:2311.05106</a> [<a href="/pdf/2311.05106" title="Download PDF">pdf</a>, <a href="/format/2311.05106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A differentiable brain simulator bridging brain simulation and  brain-inspired computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chaoming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianqiu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+S">Sichao He</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yifeng Gong</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+H">Hongyaoxing Gu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shangyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Si Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Brain simulation builds dynamical models to mimic the structure and functions
of the brain, while brain-inspired computing (BIC) develops intelligent systems
by learning from the structure and functions of the brain. The two fields are
intertwined and should share a common programming framework to facilitate each
other's development. However, none of the existing software in the fields can
achieve this goal, because traditional brain simulators lack differentiability
for training, while existing deep learning (DL) frameworks fail to capture the
biophysical realism and complexity of brain dynamics. In this paper, we
introduce BrainPy, a differentiable brain simulator developed using JAX and
XLA, with the aim of bridging the gap between brain simulation and BIC. BrainPy
expands upon the functionalities of JAX, a powerful AI framework, by
introducing complete capabilities for flexible, efficient, and scalable brain
simulation. It offers a range of sparse and event-driven operators for
efficient and scalable brain simulation, an abstraction for managing the
intricacies of synaptic computations, a modular and flexible interface for
constructing multi-scale brain models, and an object-oriented just-in-time
compilation approach to handle the memory-intensive nature of brain dynamics.
We showcase the efficiency and scalability of BrainPy on benchmark tasks,
highlight its differentiable simulation for biologically plausible spiking
models, and discuss its potential to support research at the intersection of
brain simulation and BIC.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05108" title="Abstract">arXiv:2311.05108</a> [<a href="/pdf/2311.05108" title="Download PDF">pdf</a>, <a href="/format/2311.05108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personalized Online Federated Learning with Multiple Kernels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghari%2C+P+M">Pouya M. Ghari</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yanning Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at NeurIPS 2022
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> in Advances in Neural Information Processing Systems, volume 35,
  pages 33316--33329, 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Multi-kernel learning (MKL) exhibits well-documented performance in online
non-linear function approximation. Federated learning enables a group of
learners (called clients) to train an MKL model on the data distributed among
clients to perform online non-linear function approximation. There are some
challenges in online federated MKL that need to be addressed: i) Communication
efficiency especially when a large number of kernels are considered ii)
Heterogeneous data distribution among clients. The present paper develops an
algorithmic framework to enable clients to communicate with the server to send
their updates with affordable communication cost while clients employ a large
dictionary of kernels. Utilizing random feature (RF) approximation, the present
paper proposes scalable online federated MKL algorithm. We prove that using the
proposed online federated MKL algorithm, each client enjoys sub-linear regret
with respect to the RF approximation of its best kernel in hindsight, which
indicates that the proposed algorithm can effectively deal with heterogeneity
of the data distributed among clients. Experimental results on real datasets
showcase the advantages of the proposed algorithm compared with other online
federated kernel learning ones.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05109" title="Abstract">arXiv:2311.05109</a> [<a href="/pdf/2311.05109" title="Download PDF">pdf</a>, <a href="/format/2311.05109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reducing the Side-Effects of Oscillations in Training of Quantized YOLO  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+K">Kartik Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Asthana%2C+A">Akshay Asthana</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Quantized networks use less computational and memory resources and are
suitable for deployment on edge devices. While quantization-aware training QAT
is the well-studied approach to quantize the networks at low precision, most
research focuses on over-parameterized networks for classification with limited
studies on popular and edge device friendly single-shot object detection and
semantic segmentation methods like YOLO. Moreover, majority of QAT methods rely
on Straight-through Estimator (STE) approximation which suffers from an
oscillation phenomenon resulting in sub-optimal network quantization. In this
paper, we show that it is difficult to achieve extremely low precision (4-bit
and lower) for efficient YOLO models even with SOTA QAT methods due to
oscillation issue and existing methods to overcome this problem are not
effective on these models. To mitigate the effect of oscillation, we first
propose Exponentially Moving Average (EMA) based update to the QAT model.
Further, we propose a simple QAT correction method, namely QC, that takes only
a single epoch of training after standard QAT procedure to correct the error
induced by oscillating weights and activations resulting in a more accurate
quantized model. With extensive evaluation on COCO dataset using various YOLO5
and YOLO7 variants, we show that our correction method improves quantized YOLO
networks consistently on both object detection and segmentation tasks at
low-precision (4-bit and 3-bit).
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05111" title="Abstract">arXiv:2311.05111</a> [<a href="/pdf/2311.05111" title="Download PDF">pdf</a>, <a href="/format/2311.05111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vector Approximate Survey Propagation for Model-Mismatched Estimation  (Or: How to Achieve Kabashima&#x27;s 1RSB Prediction)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haochuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Huimin Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">For approximate inference in high-dimensional generalized linear models
(GLMs), the performance of an estimator may significantly degrade when mismatch
exists between the postulated model and the ground truth. In mismatched GLMs
with rotation-invariant measurement matrices, Kabashima et al. proved vector
approximate message passing (VAMP) computes exactly the optimal estimator if
the replica symmetry (RS) ansatz is valid, but it becomes inappropriate if RS
breaking (RSB) appears. Although the one-step RSB (1RSB) saddle point equations
were given for the optimal estimator, the question remains: how to achieve the
1RSB prediction? This paper answers the question by proposing a new algorithm,
vector approximate survey propagation (VASP). VASP derives from a reformulation
of Kabashima's extremum conditions, which later links the theoretical equations
to survey propagation in vector form and finally the algorithm. VASP has a
complexity as low as VAMP, while embracing VAMP as a special case. The SE
derived for VASP can capture precisely the per-iteration behavior of the
simulated algorithm, and the SE's fixed point equations perfectly match
Kabashima's 1RSB prediction, which indicates VASP can achieve the optimal
performance even in a model-mismatched setting with 1RSB. Simulation results
confirm VASP outperforms many state-of-the-art algorithms.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05112" title="Abstract">arXiv:2311.05112</a> [<a href="/pdf/2311.05112" title="Download PDF">pdf</a>, <a href="/ps/2311.05112" title="Download PostScript">ps</a>, <a href="/format/2311.05112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Large Language Models in Medicine: Progress, Application,  and Challenge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hongjian Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+B">Boyang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+X">Xinyu Zou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiru Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S+S">Sam S. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Peilin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junling Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+Y">Yining Hua</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+C">Chengfeng Mao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fenglin Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. Version 1
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs), such as ChatGPT, have achieved substantial
attention due to their impressive human language understanding and generation
capabilities. Therefore, the application of LLMs in medicine to assist
physicians and patient care emerges as a promising research direction in both
artificial intelligence and clinical medicine. To this end, this survey
provides a comprehensive overview of the current progress, applications, and
challenges faced by LLMs in medicine. Specifically, we aim to address the
following questions: 1) What are LLMs and how can medical LLMs be built? 2)
What are the downstream performances of medical LLMs? 3) How can medical LLMs
be utilized in real-world clinical practice? 4) What challenges arise from the
use of medical LLMs? 5) How can we better construct and utilize medical LLMs?
As a result, this survey aims to provide insights into the opportunities and
challenges of LLMs in medicine and serve as a valuable resource for
constructing practical and effective medical LLMs. A regularly updated list of
practical guide resources of medical LLMs can be found at
https://github.com/AI-in-Health/MedLLMsPracticalGuide.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05113" title="Abstract">arXiv:2311.05113</a> [<a href="/pdf/2311.05113" title="Download PDF">pdf</a>, <a href="/format/2311.05113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conic10K: A Challenging Math Problem Understanding and Reasoning Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haoyi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+W">Wenyang Hui</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yezeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Weiqi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+K">Kewei Tu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yi Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Mathematical understanding and reasoning are crucial tasks for assessing the
capabilities of artificial intelligence (AI). However, existing benchmarks
either require just a few steps of reasoning, or only contain a small amount of
data in one specific topic, making it hard to analyse AI's behaviour with
reference to different problems within a specific topic in detail. In this
work, we propose Conic10K, a challenging math problem dataset on conic sections
in Chinese senior high school education. Our dataset contains various problems
with different reasoning depths, while only the knowledge from conic sections
is required. Since the dataset only involves a narrow range of knowledge, it is
easy to separately analyse the knowledge a model possesses and the reasoning
ability it has. For each problem, we provide a high-quality formal
representation, the reasoning steps, and the final solution. Experiments show
that existing large language models, including GPT-4, exhibit weak performance
on complex reasoning. We hope that our findings could inspire more advanced
techniques for precise natural language understanding and reasoning. Our
dataset and codes are available at https://github.com/whyNLP/Conic10K.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05114" title="Abstract">arXiv:2311.05114</a> [<a href="/pdf/2311.05114" title="Download PDF">pdf</a>, <a href="/format/2311.05114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt Your Mind: Refine Personalized Text Prompts within Your Mind
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+G">Guinan Su</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yanwu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jie Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Large language models (LLMs) have demonstrated remarkable potential in
natural language understanding and generation, making them valuable tools for
enhancing conversational interactions. However, LLMs encounter challenges such
as lacking multi-step reasoning capabilities, and heavy reliance on prompts. In
this regard, we introduce a prompt-refinement system named PromptMind, also
known as "Prompt Your Mind", to provide an automated solution for generating
contextually relevant prompts during conversations. PromptMind enhances the
overall interaction between humans and chatbots through an automatic prompt
suggestion and an automatic prompt refinement. To assess the effectiveness of
PromptMind, we designed three interaction tasks to evaluate emotional support,
advice acquisition, and task-oriented interactions during human-chatbot
interactions. The results demonstrated that PromptMind reduced mental demands
during interactions and fostered enhanced performance and social connections
between users and chatbots. In summary, our findings indicate that PromptMind
acts as a bridge, facilitating smoother information exchange and enhancing the
usability of chatbot interactions.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05117" title="Abstract">arXiv:2311.05117</a> [<a href="/pdf/2311.05117" title="Download PDF">pdf</a>, <a href="/format/2311.05117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Translation Quality Estimation Exploiting Synthetic Data  and Pre-trained Multilingual Encoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuroda%2C+Y">Yuto Kuroda</a>, 
<a href="/search/cs?searchtype=author&query=Fujita%2C+A">Atsushi Fujita</a>, 
<a href="/search/cs?searchtype=author&query=Kajiwara%2C+T">Tomoyuki Kajiwara</a>, 
<a href="/search/cs?searchtype=author&query=Ninomiya%2C+T">Takashi Ninomiya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Translation quality estimation (TQE) is the task of predicting translation
quality without reference translations. Due to the enormous cost of creating
training data for TQE, only a few translation directions can benefit from
supervised training. To address this issue, unsupervised TQE methods have been
studied. In this paper, we extensively investigate the usefulness of synthetic
TQE data and pre-trained multilingual encoders in unsupervised sentence-level
TQE, both of which have been proven effective in the supervised training
scenarios. Our experiment on WMT20 and WMT21 datasets revealed that this
approach can outperform other unsupervised TQE methods on high- and
low-resource translation directions in predicting post-editing effort and human
evaluation score, and some zero-resource translation directions in predicting
post-editing effort.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05120" title="Abstract">arXiv:2311.05120</a> [<a href="/pdf/2311.05120" title="Download PDF">pdf</a>, <a href="/ps/2311.05120" title="Download PostScript">ps</a>, <a href="/format/2311.05120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quranic Conversations: Developing a Semantic Search tool for the Quran  using Arabic NLP Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shohoud%2C+Y">Yasser Shohoud</a>, 
<a href="/search/cs?searchtype=author&query=Shoman%2C+M">Maged Shoman</a>, 
<a href="/search/cs?searchtype=author&query=Abdelazim%2C+S">Sarah Abdelazim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The Holy Book of Quran is believed to be the literal word of God (Allah) as
revealed to the Prophet Muhammad (PBUH) over a period of approximately 23
years. It is the book where God provides guidance on how to live a righteous
and just life, emphasizing principles like honesty, compassion, charity and
justice, as well as providing rules for personal conduct, family matters,
business ethics and much more. However, due to constraints related to the
language and the Quran organization, it is challenging for Muslims to get all
relevant ayahs (verses) pertaining to a matter or inquiry of interest. Hence,
we developed a Quran semantic search tool which finds the verses pertaining to
the user inquiry or prompt. To achieve this, we trained several models on a
large dataset of over 30 tafsirs, where typically each tafsir corresponds to
one verse in the Quran and, using cosine similarity, obtained the tafsir tensor
which is most similar to the prompt tensor of interest, which was then used to
index for the corresponding ayah in the Quran. Using the SNxLM model, we were
able to achieve a cosine similarity score as high as 0.97 which corresponds to
the abdu tafsir for a verse relating to financial matters.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05122" title="Abstract">arXiv:2311.05122</a> [<a href="/pdf/2311.05122" title="Download PDF">pdf</a>, <a href="/ps/2311.05122" title="Download PostScript">ps</a>, <a href="/format/2311.05122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ScribblePolyp: Scribble-Supervised Polyp Segmentation through Dual  Consistency Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zixun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yuncheng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jun Wei</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+H">Hannah Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhen Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by BIBM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Automatic polyp segmentation models play a pivotal role in the clinical
diagnosis of gastrointestinal diseases. In previous studies, most methods
relied on fully supervised approaches, necessitating pixel-level annotations
for model training. However, the creation of pixel-level annotations is both
expensive and time-consuming, impeding the development of model generalization.
In response to this challenge, we introduce ScribblePolyp, a novel
scribble-supervised polyp segmentation framework. Unlike fully-supervised
models, ScribblePolyp only requires the annotation of two lines (scribble
labels) for each image, significantly reducing the labeling cost. Despite the
coarse nature of scribble labels, which leave a substantial portion of pixels
unlabeled, we propose a two-branch consistency alignment approach to provide
supervision for these unlabeled pixels. The first branch employs transformation
consistency alignment to narrow the gap between predictions under different
transformations of the same input image. The second branch leverages affinity
propagation to refine predictions into a soft version, extending additional
supervision to unlabeled pixels. In summary, ScribblePolyp is an efficient
model that does not rely on teacher models or moving average pseudo labels
during training. Extensive experiments on the SUN-SEG dataset underscore the
effectiveness of ScribblePolyp, achieving a Dice score of 0.8155, with the
potential for a 1.8% improvement in the Dice score through a straightforward
self-training strategy.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05126" title="Abstract">arXiv:2311.05126</a> [<a href="/pdf/2311.05126" title="Download PDF">pdf</a>, <a href="/format/2311.05126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring and Analyzing the Effect of Avatar&#x27;s Realism on Anxiety of  English as Second Language (ESL) Speakers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sanchez%2C+J+R">Joshua Rafael Sanchez</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuntao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+X">Xin Yi</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yuanchun Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">The emergence of virtual avatars provides innovative opportunities for remote
conferencing, education, and more. Our study investigates how the realism of
avatars, used by native English speakers, impacts the anxiety levels of English
as a Second Language (ESL) speakers during interactions. ESL participants
engaged in conversations with native English speakers represented through
cartoonish avatars, realistic-like avatars, or actual video streams. We
measured both the ESL speakers' self-reported anxiety and their physiological
indicators of anxiety. Our findings show that interactions with native speakers
using cartoonish avatars or direct video lead to reduced anxiety levels among
ESL participants. However, interactions with avatars that closely resemble
humans heightened these anxieties. These insights are critically important for
the design and application of virtual avatars, especially in addressing
cross-cultural communication barriers and enhancing user experience.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05128" title="Abstract">arXiv:2311.05128</a> [<a href="/pdf/2311.05128" title="Download PDF">pdf</a>, <a href="/format/2311.05128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring and Analyzing Wildland Fire Data Via Machine Learning  Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dulal%2C+D">Dipak Dulal</a>, 
<a href="/search/cs?searchtype=author&query=Charney%2C+J+J">Joseph J. Charney</a>, 
<a href="/search/cs?searchtype=author&query=Gallagher%2C+M">Michael Gallagher</a>, 
<a href="/search/cs?searchtype=author&query=Navasca%2C+C">Carmeliza Navasca</a>, 
<a href="/search/cs?searchtype=author&query=Skowronski%2C+N">Nicholas Skowronski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This research project investigated the correlation between a 10 Hz time
series of thermocouple temperatures and turbulent kinetic energy (TKE) computed
from wind speeds collected from a small experimental prescribed burn at the
Silas Little Experimental Forest in New Jersey, USA. The primary objective of
this project was to explore the potential for using thermocouple temperatures
as predictors for estimating the TKE produced by a wildland fire. Machine
learning models, including Deep Neural Networks, Random Forest Regressor,
Gradient Boosting, and Gaussian Process Regressor, are employed to assess the
potential for thermocouple temperature perturbations to predict TKE values.
Data visualization and correlation analyses reveal patterns and relationships
between thermocouple temperatures and TKE, providing insight into the
underlying dynamics. The project achieves high accuracy in predicting TKE by
employing various machine learning models despite a weak correlation between
the predictors and the target variable. The results demonstrate significant
success, particularly from regression models, in accurately estimating the TKE.
The research findings contribute to fire behavior and smoke modeling science,
emphasizing the importance of incorporating machine learning approaches and
identifying complex relationships between fine-scale fire behavior and
turbulence. Accurate TKE estimation using thermocouple temperatures allows for
the refinement of models that can inform decision-making in fire management
strategies, facilitate effective risk mitigation, and optimize fire management
efforts. This project highlights the valuable role of machine learning
techniques in analyzing wildland fire data, showcasing their potential to
advance fire research and management practices.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05137" title="Abstract">arXiv:2311.05137</a> [<a href="/pdf/2311.05137" title="Download PDF">pdf</a>, <a href="/format/2311.05137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable Fluid Physics Parameter Identification Via Stirring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wenqiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+D">Dongzhe Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yutong Li</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jieji Ren</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cewu Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Fluid interactions permeate daily human activities, with properties like
density and viscosity playing pivotal roles in household tasks. While density
estimation is straightforward through Archimedes' principle, viscosity poses a
more intricate challenge, especially given the varied behaviors of Newtonian
and non-Newtonian fluids. These fluids, which differ in their stress-strain
relationships, are delineated by specific constitutive models such as the
Carreau, Cross, and Herschel-Bulkley models, each possessing unique viscosity
parameters. This study introduces a novel differentiable fitting framework,
DiffStir, tailored to identify key physics parameters via the common daily
operation of stirring. By employing a robotic arm for stirring and harnessing a
differentiable Material Point Method (diffMPM)-based simulator, the framework
can determine fluid parameters by matching observations from both the simulator
and the real world. Recognizing the distinct preferences of the aforementioned
constitutive models for specific fluids, an online strategy was adopted to
adaptively select the most fitting model based on real-world data.
Additionally, we propose a refining neural network to bridge the sim-to-real
gap and mitigate sensor noise-induced inaccuracies. Comprehensive experiments
were conducted to validate the efficacy of DiffStir, showcasing its precision
in parameter estimation when benchmarked against reported literature values.
More experiments and videos can be found in the supplementary materials and on
the website: https://sites.google.com/view/diffstir.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05139" title="Abstract">arXiv:2311.05139</a> [<a href="/pdf/2311.05139" title="Download PDF">pdf</a>, <a href="/format/2311.05139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On neural and dimensional collapse in supervised and unsupervised  contrastive learning with hard negative sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+R">Ruijie Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Thuan Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Aeron%2C+S">Shuchin Aeron</a>, 
<a href="/search/cs?searchtype=author&query=Ishwar%2C+P">Prakash Ishwar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">For a widely-studied data model and general loss and sample-hardening
functions we prove that the Supervised Contrastive Learning (SCL), Hard-SCL
(HSCL), and Unsupervised Contrastive Learning (UCL) risks are minimized by
representations that exhibit Neural Collapse (NC), i.e., the class means form
an Equianglular Tight Frame (ETF) and data from the same class are mapped to
the same representation. We also prove that for any representation mapping, the
HSCL and Hard-UCL (HUCL) risks are lower bounded by the corresponding SCL and
UCL risks. Although the optimality of ETF is known for SCL, albeit only for
InfoNCE loss, its optimality for HSCL and UCL under general loss and hardening
functions is novel. Moreover, our proofs are much simpler, compact, and
transparent. We empirically demonstrate, for the first time, that ADAM
optimization of HSCL and HUCL risks with random initialization and suitable
hardness levels can indeed converge to the NC geometry if we incorporate
unit-ball or unit-sphere feature normalization. Without incorporating hard
negatives or feature normalization, however, the representations learned via
ADAM suffer from dimensional collapse (DC) and fail to attain the NC geometry.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05141" title="Abstract">arXiv:2311.05141</a> [<a href="/pdf/2311.05141" title="Download PDF">pdf</a>, <a href="/format/2311.05141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable Cloth Parameter Identification and State Estimation in  Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+D">Dongzhe Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+S">Siqiong Yao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wenqiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cewu Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In the realm of robotic cloth manipulation, accurately estimating the cloth
state during or post-execution is imperative. However, the inherent
complexities in a cloth's dynamic behavior and its near-infinite degrees of
freedom (DoF) pose significant challenges. Traditional methods have been
restricted to using keypoints or boundaries as cues for cloth state, which do
not holistically capture the cloth's structure, especially during intricate
tasks like folding. Additionally, the critical influence of cloth physics has
often been overlooked in past research. Addressing these concerns, we introduce
DiffCP, a novel differentiable pipeline that leverages the Anisotropic
Elasto-Plastic (A-EP) constitutive model, tailored for differentiable
computation and robotic tasks. DiffCP adopts a ``real-to-sim-to-real''
methodology. By observing real-world cloth states through an RGB-D camera and
projecting this data into a differentiable simulator, the system identifies
physics parameters by minimizing the geometric variance between observed and
target states. Extensive experiments demonstrate DiffCP's ability and stability
to determine physics parameters under varying manipulations, grasping points,
and speeds. Additionally, its applications extend to cloth material
identification, manipulation trajectory generation, and more notably, enhancing
cloth pose estimation accuracy. More experiments and videos can be found in the
supplementary materials and on the website:
https://sites.google.com/view/diffcp.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05143" title="Abstract">arXiv:2311.05143</a> [<a href="/pdf/2311.05143" title="Download PDF">pdf</a>, <a href="/format/2311.05143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCAAT: Improving Neural Network Interpretability via Saliency  Constrained Adaptive Adversarial Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Rui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+W">Wenkang Qin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+P">Peixiang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Haowang">Haowang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Lin Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep Neural Networks (DNNs) are expected to provide explanation for users to
understand their black-box predictions. Saliency map is a common form of
explanation illustrating the heatmap of feature attributions, but it suffers
from noise in distinguishing important features. In this paper, we propose a
model-agnostic learning method called Saliency Constrained Adaptive Adversarial
Training (SCAAT) to improve the quality of such DNN interpretability. By
constructing adversarial samples under the guidance of saliency map, SCAAT
effectively eliminates most noise and makes saliency maps sparser and more
faithful without any modification to the model architecture. We apply SCAAT to
multiple DNNs and evaluate the quality of the generated saliency maps on
various natural and pathological image datasets. Evaluations on different
domains and metrics show that SCAAT significantly improves the interpretability
of DNNs by providing more faithful saliency maps without sacrificing their
predictive power.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05144" title="Abstract">arXiv:2311.05144</a> [<a href="/pdf/2311.05144" title="Download PDF">pdf</a>, <a href="/format/2311.05144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Counter-Empirical Attacking based on Adversarial Reinforcement Learning  for Time-Relevant Scoring System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiangguo Sun</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hong Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hang Dong</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+B">Bo Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+S">Si Qin</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Q">Qingwei Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to TKDE on 08-Jun-2022, receive the 1st round decision (major revision) on 20-Apr-2023, submitted to TKDE 2nd time on 30-May-2023, receive the 2nd round decision (major revision) on 30-Sep-2023, submitted to TKDE 3rd time on 15-Oct-2023, now under review for the 3rd round of reviewing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Scoring systems are commonly seen for platforms in the era of big data. From
credit scoring systems in financial services to membership scores in E-commerce
shopping platforms, platform managers use such systems to guide users towards
the encouraged activity pattern, and manage resources more effectively and more
efficiently thereby. To establish such scoring systems, several "empirical
criteria" are firstly determined, followed by dedicated top-down design for
each factor of the score, which usually requires enormous effort to adjust and
tune the scoring function in the new application scenario. What's worse, many
fresh projects usually have no ground-truth or any experience to evaluate a
reasonable scoring system, making the designing even harder. To reduce the
effort of manual adjustment of the scoring function in every new scoring
system, we innovatively study the scoring system from the preset empirical
criteria without any ground truth, and propose a novel framework to improve the
system from scratch. In this paper, we propose a "counter-empirical attacking"
mechanism that can generate "attacking" behavior traces and try to break the
empirical rules of the scoring system. Then an adversarial "enhancer" is
applied to evaluate the scoring system and find the improvement strategy. By
training the adversarial learning problem, a proper scoring function can be
learned to be robust to the attacking activity traces that are trying to
violate the empirical criteria. Extensive experiments have been conducted on
two scoring systems including a shared computing resource platform and a
financial credit system. The experimental results have validated the
effectiveness of our proposed framework.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05145" title="Abstract">arXiv:2311.05145</a> [<a href="/pdf/2311.05145" title="Download PDF">pdf</a>, <a href="/format/2311.05145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing power grid resilience to cyber-physical attacks using  distributed retail electricity markets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Nair%2C+V+J">Vineet Jagadeesan Nair</a>, 
<a href="/search/eess?searchtype=author&query=Srivastava%2C+P">Priyank Srivastava</a>, 
<a href="/search/eess?searchtype=author&query=Annaswamy%2C+A">Anuradha Annaswamy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We propose using a hierarchical retail market structure to alert and dispatch
resources to mitigate cyber-physical attacks on a distribution grid. We
simulate attacks where a number of generation nodes in a distribution grid are
attacked. We show that the market is able to successfully meet the shortfall
between demand and supply by utilizing the flexibility of remaining resources
while minimizing any extra power that needs to be imported from the main
transmission grid. This includes utilizing upward flexibility or reserves of
remaining online generators and some curtailment or shifting of flexible loads,
which results in higher costs. Using price signals and market-based
coordination, the grid operator can achieve its objectives without direct
control over distributed energy resources and is able to accurately compensate
prosumers for the grid support they provide.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05146" title="Abstract">arXiv:2311.05146</a> [<a href="/pdf/2311.05146" title="Download PDF">pdf</a>, <a href="/format/2311.05146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OW-SLR: Overlapping Windows on Semi-Local Region for Image  Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhardwaj%2C+R">Rishav Bhardwaj</a>, 
<a href="/search/cs?searchtype=author&query=Balaji%2C+J+J">Janarthanam Jothi Balaji</a>, 
<a href="/search/cs?searchtype=author&query=Lakshminarayanan%2C+V">Vasudevan Lakshminarayanan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">There has been considerable progress in implicit neural representation to
upscale an image to any arbitrary resolution. However, existing methods are
based on defining a function to predict the Red, Green and Blue (RGB) value
from just four specific loci. Relying on just four loci is insufficient as it
leads to losing fine details from the neighboring region(s). We show that by
taking into account the semi-local region leads to an improvement in
performance. In this paper, we propose applying a new technique called
Overlapping Windows on Semi-Local Region (OW-SLR) to an image to obtain any
arbitrary resolution by taking the coordinates of the semi-local region around
a point in the latent space. This extracted detail is used to predict the RGB
value of a point. We illustrate the technique by applying the algorithm to the
Optical Coherence Tomography-Angiography (OCT-A) images and show that it can
upscale them to random resolution. This technique outperforms the existing
state-of-the-art methods when applied to the OCT500 dataset. OW-SLR provides
better results for classifying healthy and diseased retinal images such as
diabetic retinopathy and normals from the given set of OCT-A images. The
project page is available at https://rishavbb.github.io/ow-slr/index.html
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05147" title="Abstract">arXiv:2311.05147</a> [<a href="/pdf/2311.05147" title="Download PDF">pdf</a>, <a href="/ps/2311.05147" title="Download PostScript">ps</a>, <a href="/format/2311.05147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Association Learning of Self-Attention and Convolution in Image  Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+K">Kui Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xuemei Jia</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wenxin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenbin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Junjun Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in Chinese language, Journal of Image and Graphics. arXiv admin note: substantial text overlap with <a href="/abs/2207.10455">arXiv:2207.10455</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">CNNs and Self attention have achieved great success in multimedia
applications for dynamic association learning of self-attention and convolution
in image restoration. However, CNNs have at least two shortcomings: 1) limited
receptive field; 2) static weight of sliding window at inference, unable to
cope with the content diversity.In view of the advantages and disadvantages of
CNNs and Self attention, this paper proposes an association learning method to
utilize the advantages and suppress their shortcomings, so as to achieve
high-quality and efficient inpainting. We regard rain distribution reflects the
degradation location and degree, in addition to the rain distribution
prediction. Thus, we propose to refine background textures with the predicted
degradation prior in an association learning manner. As a result, we accomplish
image deraining by associating rain streak removal and background recovery,
where an image deraining network and a background recovery network are designed
for two subtasks. The key part of association learning is a novel multi-input
attention module. It generates the degradation prior and produces the
degradation mask according to the predicted rainy distribution. Benefited from
the global correlation calculation of SA, MAM can extract the informative
complementary components from the rainy input with the degradation mask, and
then help accurate texture restoration. Meanwhile, SA tends to aggregate
feature maps with self-attention importance, but convolution diversifies them
to focus on the local textures. A hybrid fusion network involves one residual
Transformer branch and one encoder-decoder branch. The former takes a few
learnable tokens as input and stacks multi-head attention and feed-forward
networks to encode global features of the image. The latter, conversely,
leverages the multi-scale encoder-decoder to represent contexture knowledge.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05150" title="Abstract">arXiv:2311.05150</a> [<a href="/pdf/2311.05150" title="Download PDF">pdf</a>, <a href="/format/2311.05150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fuel-Optimal Powered Descent Guidance for Hazardous Terrain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Basar%2C+S+Z">Sheikh Zeeshan Basar</a>, 
<a href="/search/eess?searchtype=author&query=Ghosh%2C+S">Satadal Ghosh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprints of the 22nd IFAC World Congress, Yokohama, Japan, July 9-14, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Future interplanetary missions will carry more and more sensitive equipment
critical for setting up bases for crewed missions. The ability to manoeuvre
around hazardous terrain thus becomes a critical mission aspect. However, large
diverts and manoeuvres consume a significant amount of fuel, leading to less
fuel remaining for emergencies or return missions. Thus, requiring more fuel to
be carried onboard. This work presents fuel-optimal guidance to avoid hazardous
terrain and safely land at the desired location. We approximate the hazardous
terrain as step-shaped polygons and define barriers around the terrain. Using
an augmented cost functional, fuel-optimal guidance command, which avoids the
terrain, is derived. The results are validated using computer simulations and
tested against many initial conditions to prove their effectiveness.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05152" title="Abstract">arXiv:2311.05152</a> [<a href="/pdf/2311.05152" title="Download PDF">pdf</a>, <a href="/format/2311.05152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-modal Prompts: Adapting Large Pre-trained Models for Audio-Visual  Downstream Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+H">Haoyi Duan</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Mingze Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+L">Li Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jieming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhou Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM)

</div>
<p class="mathjax">In recent years, the deployment of large-scale pre-trained models in
audio-visual downstream tasks has yielded remarkable outcomes. However, these
models, primarily trained on single-modality unconstrained datasets, still
encounter challenges in feature extraction for multi-modal tasks, leading to
suboptimal performance. This limitation arises due to the introduction of
irrelevant modality-specific information during encoding, which adversely
affects the performance of downstream tasks. To address this challenge, this
paper proposes a novel Dual-Guided Spatial-Channel-Temporal (DG-SCT) attention
mechanism. This mechanism leverages audio and visual modalities as soft prompts
to dynamically adjust the parameters of pre-trained models based on the current
multi-modal input features. Specifically, the DG-SCT module incorporates
trainable cross-modal interaction layers into pre-trained audio-visual
encoders, allowing adaptive extraction of crucial information from the current
modality across spatial, channel, and temporal dimensions, while preserving the
frozen parameters of large-scale pre-trained models. Experimental evaluations
demonstrate that our proposed model achieves state-of-the-art results across
multiple downstream tasks, including AVE, AVVP, AVS, and AVQA. Furthermore, our
model exhibits promising performance in challenging few-shot and zero-shot
scenarios. The source code and pre-trained models are available at
https://github.com/haoyi-duan/DG-SCT.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05155" title="Abstract">arXiv:2311.05155</a> [<a href="/pdf/2311.05155" title="Download PDF">pdf</a>, <a href="/format/2311.05155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly-supervised Deep Cognate Detection Framework for Low-Resourced  Languages Using Morphological Knowledge of Closely-Related Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goswami%2C+K">Koustava Goswami</a>, 
<a href="/search/cs?searchtype=author&query=Rani%2C+P">Priya Rani</a>, 
<a href="/search/cs?searchtype=author&query=Fransen%2C+T">Theodorus Fransen</a>, 
<a href="/search/cs?searchtype=author&query=McCrae%2C+J+P">John P. McCrae</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP 2023 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Exploiting cognates for transfer learning in under-resourced languages is an
exciting opportunity for language understanding tasks, including unsupervised
machine translation, named entity recognition and information retrieval.
Previous approaches mainly focused on supervised cognate detection tasks based
on orthographic, phonetic or state-of-the-art contextual language models, which
under-perform for most under-resourced languages. This paper proposes a novel
language-agnostic weakly-supervised deep cognate detection framework for
under-resourced languages using morphological knowledge from closely related
languages. We train an encoder to gain morphological knowledge of a language
and transfer the knowledge to perform unsupervised and weakly-supervised
cognate detection tasks with and without the pivot language for the
closely-related languages. While unsupervised, it overcomes the need for
hand-crafted annotation of cognates. We performed experiments on different
published cognate detection datasets across language families and observed not
only significant improvement over the state-of-the-art but also our method
outperformed the state-of-the-art supervised and unsupervised methods. Our
model can be extended to a wide range of languages from any language family as
it overcomes the requirement of the annotation of the cognate pairs for
training. The code and dataset building scripts can be found at
https://github.com/koustavagoswami/Weakly_supervised-Cognate_Detection
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05160" title="Abstract">arXiv:2311.05160</a> [<a href="/pdf/2311.05160" title="Download PDF">pdf</a>, <a href="/format/2311.05160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RAPID: Training-free Retrieval-based Log Anomaly Detection with PLM  considering Token-level information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=No%2C+G">Gunho No</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yukyung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+H">Hyeongwon Kang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+P">Pilsung Kang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As the IT industry advances, system log data becomes increasingly crucial.
Many computer systems rely on log texts for management due to restricted access
to source code. The need for log anomaly detection is growing, especially in
real-world applications, but identifying anomalies in rapidly accumulating logs
remains a challenging task. Traditional deep learning-based anomaly detection
models require dataset-specific training, leading to corresponding delays.
Notably, most methods only focus on sequence-level log information, which makes
the detection of subtle anomalies harder, and often involve inference processes
that are difficult to utilize in real-time. We introduce RAPID, a model that
capitalizes on the inherent features of log data to enable anomaly detection
without training delays, ensuring real-time capability. RAPID treats logs as
natural language, extracting representations using pre-trained language models.
Given that logs can be categorized based on system context, we implement a
retrieval-based technique to contrast test logs with the most similar normal
logs. This strategy not only obviates the need for log-specific training but
also adeptly incorporates token-level information, ensuring refined and robust
detection, particularly for unseen logs. We also propose the core set
technique, which can reduce the computational cost needed for comparison.
Experimental results show that even without training on log data, RAPID
demonstrates competitive performance compared to prior models and achieves the
best performance on certain datasets. Through various research questions, we
verified its capability for real-time detection without delay.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05161" title="Abstract">arXiv:2311.05161</a> [<a href="/pdf/2311.05161" title="Download PDF">pdf</a>, <a href="/format/2311.05161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Computation Efficiency in Large Language Models through Weight  and Activation Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jangwhan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minsoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Baek%2C+S">Seungcheol Baek</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+S+J">Seok Joong Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Sung%2C+W">Wonyong Sung</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jungwook Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 Main Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) are proficient in natural language processing
tasks, but their deployment is often restricted by extensive parameter sizes
and computational demands. This paper focuses on post-training quantization
(PTQ) in LLMs, specifically 4-bit weight and 8-bit activation (W4A8)
quantization, to enhance computational efficiency -- a topic less explored
compared to weight-only quantization. We present two innovative techniques:
activation-quantization-aware scaling (AQAS) and sequence-length-aware
calibration (SLAC) to enhance PTQ by considering the combined effects on
weights and activations and aligning calibration sequence lengths to target
tasks. Moreover, we introduce dINT, a hybrid data format combining integer and
denormal representations, to address the underflow issue in W4A8 quantization,
where small values are rounded to zero. Through rigorous evaluations of LLMs,
including OPT and LLaMA, we demonstrate that our techniques significantly boost
task accuracies to levels comparable with full-precision models. By developing
arithmetic units compatible with dINT, we further confirm that our methods
yield a 2$\times$ hardware efficiency improvement compared to 8-bit integer MAC
unit.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05162" title="Abstract">arXiv:2311.05162</a> [<a href="/pdf/2311.05162" title="Download PDF">pdf</a>, <a href="/ps/2311.05162" title="Download PostScript">ps</a>, <a href="/format/2311.05162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Global error estimates of high-order fully decoupled schemes for the  Cahn-Hilliard-Navier-Stokes model of Two-Phase Incompressible Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+X">Xiaoli Li</a>, 
<a href="/search/math?searchtype=author&query=Zheng%2C+N">Nan Zheng</a>, 
<a href="/search/math?searchtype=author&query=Shen%2C+J">Jie Shen</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+Z">Zhengguang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2009.09353">arXiv:2009.09353</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper we construct new fully decoupled and high-order
implicit-explicit (IMEX) schemes for the two-phase incompressible flows based
on the new generalized scalar auxiliary variable approach with optimal energy
approximation (EOP-GSAV) for Cahn-Hilliard equation and consistent splitting
method for Navier-Stokes equation. These schemes are linear, fully decoupled,
unconditionally energy stable, only require solving a sequence of elliptic
equations with constant coefficients at each time step, and provide a new
technique to preserve the consistency between original energy and modified
energy. We derive that numerical solutions of these schemes are uniformly
bounded without any restriction on time step size. Furthermore, we carry out a
rigorous error analysis for the first-order scheme and establish optimal global
error estimates for the phase function, velocity and pressure in two and
three-dimensional cases. Numerical examples are presented to validate the
proposed schemes.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05168" title="Abstract">arXiv:2311.05168</a> [<a href="/pdf/2311.05168" title="Download PDF">pdf</a>, <a href="/format/2311.05168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FireMatch: A Semi-Supervised Video Fire Detection Network Based on  Consistency and Distribution Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Q">Qinghua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zuoyong Li</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+K">Kun Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Haoyi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaoguang Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep learning techniques have greatly enhanced the performance of fire
detection in videos. However, video-based fire detection models heavily rely on
labeled data, and the process of data labeling is particularly costly and
time-consuming, especially when dealing with videos. Considering the limited
quantity of labeled video data, we propose a semi-supervised fire detection
model called FireMatch, which is based on consistency regularization and
adversarial distribution alignment. Specifically, we first combine consistency
regularization with pseudo-label. For unlabeled data, we design video data
augmentation to obtain corresponding weakly augmented and strongly augmented
samples. The proposed model predicts weakly augmented samples and retains
pseudo-label above a threshold, while training on strongly augmented samples to
predict these pseudo-labels for learning more robust feature representations.
Secondly, we generate video cross-set augmented samples by adversarial
distribution alignment to expand the training data and alleviate the decline in
classification performance caused by insufficient labeled data. Finally, we
introduce a fairness loss to help the model produce diverse predictions for
input samples, thereby addressing the issue of high confidence with the
non-fire class in fire classification scenarios. The FireMatch achieved an
accuracy of 76.92% and 91.81% on two real-world fire datasets, respectively.
The experimental results demonstrate that the proposed method outperforms the
current state-of-the-art semi-supervised classification methods.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05169" title="Abstract">arXiv:2311.05169</a> [<a href="/pdf/2311.05169" title="Download PDF">pdf</a>, <a href="/format/2311.05169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models and Prompt Engineering for Biomedical Query  Focused Multi-Document Summarisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moll%C3%A1%2C+D">Diego Moll&#xe1;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 7 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper reports on the use of prompt engineering and GPT-3.5 for
biomedical query-focused multi-document summarisation. Using GPT-3.5 and
appropriate prompts, our system achieves top ROUGE-F1 results in the task of
obtaining short-paragraph-sized answers to biomedical questions in the 2023
BioASQ Challenge (BioASQ 11b). This paper confirms what has been observed in
other domains: 1) Prompts that incorporated few-shot samples generally improved
on their counterpart zero-shot variants; 2) The largest improvement was
achieved by retrieval augmented generation. The fact that these prompts allow
our top runs to rank within the top two runs of BioASQ 11b demonstrate the
power of using adequate prompts for Large Language Models in general, and
GPT-3.5 in particular, for query-focused summarisation.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05170" title="Abstract">arXiv:2311.05170</a> [<a href="/pdf/2311.05170" title="Download PDF">pdf</a>, <a href="/format/2311.05170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Local Parallel Finite Element Method for Super-Hydrophobic Proppants  in a Hydraulic Fracturing System Based on a 2D/3D Transient Triple-Porosity  Navier-Stokes Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cao%2C+L">Luling Cao</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+J">Jian Li</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+Z">Zhangxin Chen</a>, 
<a href="/search/math?searchtype=author&query=Du%2C+G">Guangzhi Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">A hydraulic fracturing system with super-hydrophobic proppants is
characterized by a transient triple-porosity Navier-Stokes model. For this
complex multiphysics system, particularly in the context of three-dimensional
space, a local parallel and non-iterative finite element method based on
two-grid discretizations is proposed. The underlying idea behind utilizing the
local parallel approach is to combine a decoupled method, a two-grid method and
a domain decomposition method. The strategy allows us to initially capture
low-frequency data across the decoupled domain using a coarse grid. Then it
tackles high-frequency components by solving residual equations within
overlapping subdomains by employing finer grids and local parallel procedures
at each time step. By utilizing this approach, a significant improvement in
computational efficiency can be achieved. Furthermore, the convergence results
of the approximate solutions from the algorithm are obtained. Finally, we
perform 2D/3D numerical experiments to demonstrate the effectiveness and
efficiency of the algorithm as well as to illustrate its advantages in
application.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05171" title="Abstract">arXiv:2311.05171</a> [<a href="/pdf/2311.05171" title="Download PDF">pdf</a>, <a href="/format/2311.05171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Residual Connection in Training Large-Scale Spiking Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yudong Li</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Y">Yunlin Lei</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xu Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Spiking Neural Network (SNN) is known as the most famous brain-inspired
model, but the non-differentiable spiking mechanism makes it hard to train
large-scale SNNs. To facilitate the training of large-scale SNNs, many training
methods are borrowed from Artificial Neural Networks (ANNs), among which deep
residual learning is the most commonly used. But the unique features of SNNs
make prior intuition built upon ANNs not available for SNNs. Although there are
a few studies that have made some pioneer attempts on the topology of Spiking
ResNet, the advantages of different connections remain unclear. To tackle this
issue, we analyze the merits and limitations of various residual connections
and empirically demonstrate our ideas with extensive experiments. Then, based
on our observations, we abstract the best-performing connections into densely
additive (DA) connection, extend such a concept to other topologies, and
propose four architectures for training large-scale SNNs, termed DANet, which
brings up to 13.24% accuracy gain on ImageNet. Besides, in order to present a
detailed methodology for designing the topology of large-scale SNNs, we further
conduct in-depth discussions on their applicable scenarios in terms of their
performance on various scales of datasets and demonstrate their advantages over
prior architectures. At a low training expense, our best-performing
ResNet-50/101/152 obtain 73.71%/76.13%/77.22% top-1 accuracy on ImageNet with 4
time steps. We believe that this work shall give more insights for future works
to design the topology of their networks and promote the development of
large-scale SNNs. The code will be publicly available.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05177" title="Abstract">arXiv:2311.05177</a> [<a href="/pdf/2311.05177" title="Download PDF">pdf</a>, <a href="/format/2311.05177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Model Checking of Temporal Interaction Dynamics in the  Supreme Court
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Susmoy Das</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Arpit Sharma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 1 figure, 11 tables, accepted at the 11th International Symposium DATAMOD 2023: FROM DATA TO MODELS AND BACK
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">The Supreme Court plays an extremely critical role in ensuring adherence to
the rule of law and in strengthening the democracy. Due to this reason,
modeling and analysis of small group interactions in the courtroom setting is
an important task as it can help in understanding court decision-making. We
apply probabilistic model checking for the modeling and analysis of temporal
interaction dynamics in the context of the Supreme Court of the United States.
We have used the transcripts of the oral arguments of cases from the Supreme
Court for constructing a discrete-time Markov reward model (DTMRM). Next, we
formulate interesting queries over interaction by using probabilistic
computation tree logic (PCTL) and PCTL with rewards and verify them using a
probabilistic symbolic model checker (PRISM). Our experimental results show
that probabilistic model checking is very effective in identifying trends,
hidden patterns, and how justices behave during the trials. These results not
only provide valuable feedback to the justices but may also be used by the
advocates and law students for finding better ways to present their arguments
in the court.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05178" title="Abstract">arXiv:2311.05178</a> [<a href="/pdf/2311.05178" title="Download PDF">pdf</a>, <a href="/format/2311.05178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forceps with direct torque control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhuoqi Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference on New Technologies for Computer and Robot Assisted Surgery 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This study presents a conceptual design of laparoscopic forceps whose
grasping torque can be directly controlled by the user. By integrating an
adjustable constant torque mechanism, the handle opening angle is converted to
the grasping torque irrespective of the jaw opening angle. This feature
overcomes the limitation regarding of the lack of direct haptic feedback in
laparoscopic minimally invasive surgery, preventing damage of delicate tissue
during forceps grasping.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05185" title="Abstract">arXiv:2311.05185</a> [<a href="/pdf/2311.05185" title="Download PDF">pdf</a>, <a href="/format/2311.05185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixture of Weak &amp; Strong Experts on Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+H">Hanqing Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+H">Hanjia Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+D">Diyi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yinglong Xia</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jiebo Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Realistic graphs contain both rich self-features of nodes and informative
structures of neighborhoods, jointly handled by a GNN in the typical setup. We
propose to decouple the two modalities by mixture of weak and strong experts
(Mowst), where the weak expert is a light-weight Multi-layer Perceptron (MLP),
and the strong expert is an off-the-shelf Graph Neural Network (GNN). To adapt
the experts' collaboration to different target nodes, we propose a "confidence"
mechanism based on the dispersion of the weak expert's prediction logits. The
strong expert is conditionally activated when either the node's classification
relies on neighborhood information, or the weak expert has low model quality.
We reveal interesting training dynamics by analyzing the influence of the
confidence function on loss: our training algorithm encourages the
specialization of each expert by effectively generating soft splitting of the
graph. In addition, our "confidence" design imposes a desirable bias toward the
strong expert to benefit from GNN's better generalization capability. Mowst is
easy to optimize and achieves strong expressive power, with a computation cost
comparable to a single GNN. Empirically, Mowst shows significant accuracy
improvement on 6 standard node classification benchmarks (including both
homophilous and heterophilous graphs).
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05190" title="Abstract">arXiv:2311.05190</a> [<a href="/pdf/2311.05190" title="Download PDF">pdf</a>, <a href="/format/2311.05190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Audio-visual Saliency for Omnidirectional Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuxin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xilei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+H">Huiyu Duan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jie Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaiwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yucheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Li Chen</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+X">Xiongkuo Min</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+G">Guangtao Zhai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Visual saliency prediction for omnidirectional videos (ODVs) has shown great
significance and necessity for omnidirectional videos to help ODV coding, ODV
transmission, ODV rendering, etc.. However, most studies only consider visual
information for ODV saliency prediction while audio is rarely considered
despite its significant influence on the viewing behavior of ODV. This is
mainly due to the lack of large-scale audio-visual ODV datasets and
corresponding analysis. Thus, in this paper, we first establish the largest
audio-visual saliency dataset for omnidirectional videos (AVS-ODV), which
comprises the omnidirectional videos, audios, and corresponding captured
eye-tracking data for three video sound modalities including mute, mono, and
ambisonics. Then we analyze the visual attention behavior of the observers
under various omnidirectional audio modalities and visual scenes based on the
AVS-ODV dataset. Furthermore, we compare the performance of several
state-of-the-art saliency prediction models on the AVS-ODV dataset and
construct a new benchmark. Our AVS-ODV datasets and the benchmark will be
released to facilitate future research.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05192" title="Abstract">arXiv:2311.05192</a> [<a href="/pdf/2311.05192" title="Download PDF">pdf</a>, <a href="/format/2311.05192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TransReg: Cross-transformer as auto-registration module for multi-view  mammogram mass detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H+C">Hoang C. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Phan%2C+C">Chi Phan</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+H+H">Hieu H. Pham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Screening mammography is the most widely used method for early breast cancer
detection, significantly reducing mortality rates. The integration of
information from multi-view mammograms enhances radiologists' confidence and
diminishes false-positive rates since they can examine on dual-view of the same
breast to cross-reference the existence and location of the lesion. Inspired by
this, we present TransReg, a Computer-Aided Detection (CAD) system designed to
exploit the relationship between craniocaudal (CC), and mediolateral oblique
(MLO) views. The system includes cross-transformer to model the relationship
between the region of interest (RoIs) extracted by siamese Faster RCNN network
for mass detection problems. Our work is the first time cross-transformer has
been integrated into an object detection framework to model the relation
between ipsilateral views. Our experimental evaluation on DDSM and VinDr-Mammo
datasets shows that our TransReg, equipped with SwinT as a feature extractor
achieves state-of-the-art performance. Specifically, at the false positive rate
per image at 0.5, TransReg using SwinT gets a recall at 83.3% for DDSM dataset
and 79.7% for VinDr-Mammo dataset. Furthermore, we conduct a comprehensive
analysis to demonstrate that cross-transformer can function as an
auto-registration module, aligning the masses in dual-view and utilizing this
information to inform final predictions. It is a replication diagnostic
workflow of expert radiologists
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05195" title="Abstract">arXiv:2311.05195</a> [<a href="/pdf/2311.05195" title="Download PDF">pdf</a>, <a href="/format/2311.05195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PRODIGy: a PROfile-based DIalogue Generation dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Occhipinti%2C+D">Daniela Occhipinti</a>, 
<a href="/search/cs?searchtype=author&query=Tekiroglu%2C+S+S">Serra Sinem Tekiroglu</a>, 
<a href="/search/cs?searchtype=author&query=Guerini%2C+M">Marco Guerini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Providing dialogue agents with a profile representation can improve their
consistency and coherence, leading to better conversations. However, current
profile-based dialogue datasets for training such agents contain either
explicit profile representations that are simple and dialogue-specific, or
implicit representations that are difficult to collect. In this work, we
propose a unified framework in which we bring together both standard and more
sophisticated profile representations by creating a new resource where each
dialogue is aligned with all possible speaker representations such as
communication style, biographies, and personality. This framework allows to
test several baselines built using generative language models with several
profile configurations. The automatic evaluation shows that profile-based
models have better generalisation capabilities than models trained on dialogues
only, both in-domain and cross-domain settings. These results are consistent
for fine-tuned models and instruction-based LLMs. Additionally, human
evaluation demonstrates a clear preference for generations consistent with both
profile and context. Finally, to account for possible privacy concerns, all
experiments are done under two configurations: inter-character and
intra-character. In the former, the LM stores the information about the
character in its internal representation, while in the latter, the LM does not
retain any personal information but uses it only at inference time.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05197" title="Abstract">arXiv:2311.05197</a> [<a href="/pdf/2311.05197" title="Download PDF">pdf</a>, <a href="/ps/2311.05197" title="Download PostScript">ps</a>, <a href="/format/2311.05197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning in Computed Tomography Pulmonary Angiography Imaging: A  Dual-Pronged Approach for Pulmonary Embolism Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bushra%2C+F">Fabiha Bushra</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+M+E+H">Muhammad E. H. Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Sarmun%2C+R">Rusab Sarmun</a>, 
<a href="/search/cs?searchtype=author&query=Kabir%2C+S">Saidul Kabir</a>, 
<a href="/search/cs?searchtype=author&query=Said%2C+M">Menatalla Said</a>, 
<a href="/search/cs?searchtype=author&query=Zoghoul%2C+S+B">Sohaib Bassam Zoghoul</a>, 
<a href="/search/cs?searchtype=author&query=Mushtak%2C+A">Adam Mushtak</a>, 
<a href="/search/cs?searchtype=author&query=Al-Hashimi%2C+I">Israa Al-Hashimi</a>, 
<a href="/search/cs?searchtype=author&query=Alqahtani%2C+A">Abdulrahman Alqahtani</a>, 
<a href="/search/cs?searchtype=author&query=Hasan%2C+A">Anwarul Hasan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Expert Systems With Applications (Print ISSN: 0957-4174)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Pulmonary Embolism (PE) is a critical medical condition characterized by
obstructions in the pulmonary arteries. Despite being a major health concern,
it often goes underdiagnosed leading to detrimental clinical outcomes. The
increasing reliance on Computed Tomography Pulmonary Angiography for diagnosis
presents challenges and a pressing need for enhanced diagnostic solutions. The
primary objective of this study is to leverage deep learning techniques to
enhance the Computer Assisted Diagnosis of PE. This study presents a
comprehensive dual-pronged approach combining classification and detection for
PE diagnosis. We introduce an Attention-Guided Convolutional Neural Network
(AG-CNN) for classification, addressing both global and local lesion region.
For detection, state-of-the-art models are employed to pinpoint potential PE
regions. Different ensembling techniques further improve detection accuracy by
combining predictions from different models. Finally, a heuristic strategy
integrates classifier outputs with detection results, ensuring robust and
accurate PE identification. Our attention-guided classification approach,
tested on the Ferdowsi University of Mashhad's Pulmonary Embolism (FUMPE)
dataset, outperformed the baseline model DenseNet-121 by achieving an 8.1%
increase in the Area Under the Receiver Operating Characteristic. By employing
ensemble techniques with detection models, the mean average precision (mAP) was
considerably enhanced by a 4.7% increase. The classifier-guided framework
further refined the mAP and F1 scores over the ensemble models. Our research
offers a comprehensive approach to PE diagnostics using deep learning,
addressing the prevalent issues of underdiagnosis and misdiagnosis. We aim to
improve PE patient care by integrating AI solutions into clinical workflows,
highlighting the potential of human-AI collaboration in medical diagnostics.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05198" title="Abstract">arXiv:2311.05198</a> [<a href="/pdf/2311.05198" title="Download PDF">pdf</a>, <a href="/format/2311.05198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive-Labeling for Enhancing Remote Sensing Cloud Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gala%2C+J">Jay Gala</a>, 
<a href="/search/cs?searchtype=author&query=Nag%2C+S">Sauradip Nag</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Huichou Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruirui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiatian Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the TCCML Workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Cloud analysis is a critical component of weather and climate science,
impacting various sectors like disaster management. However, achieving
fine-grained cloud analysis, such as cloud segmentation, in remote sensing
remains challenging due to the inherent difficulties in obtaining accurate
labels, leading to significant labeling errors in training data. Existing
methods often assume the availability of reliable segmentation annotations,
limiting their overall performance. To address this inherent limitation, we
introduce an innovative model-agnostic Cloud Adaptive-Labeling (CAL) approach,
which operates iteratively to enhance the quality of training data annotations
and consequently improve the performance of the learned model. Our methodology
commences by training a cloud segmentation model using the original
annotations. Subsequently, it introduces a trainable pixel intensity threshold
for adaptively labeling the cloud training images on the fly. The newly
generated labels are then employed to fine-tune the model. Extensive
experiments conducted on multiple standard cloud segmentation benchmarks
demonstrate the effectiveness of our approach in significantly boosting the
performance of existing segmentation models. Our CAL method establishes new
state-of-the-art results when compared to a wide array of existing
alternatives.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05199" title="Abstract">arXiv:2311.05199</a> [<a href="/pdf/2311.05199" title="Download PDF">pdf</a>, <a href="/format/2311.05199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BrainNetDiff: Generative AI Empowers Brain Network Generation via  Multimodal Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zong%2C+Y">Yongcheng Zong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuqiang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Brain network analysis has emerged as pivotal method for gaining a deeper
understanding of brain functions and disease mechanisms. Despite the existence
of various network construction approaches, shortcomings persist in the
learning of correlations between structural and functional brain imaging data.
In light of this, we introduce a novel method called BrainNetDiff, which
combines a multi-head Transformer encoder to extract relevant features from
fMRI time series and integrates a conditional latent diffusion model for brain
network generation. Leveraging a conditional prompt and a fusion attention
mechanism, this method significantly improves the accuracy and stability of
brain network generation. To the best of our knowledge, this represents the
first framework that employs diffusion for the fusion of the multimodal brain
imaging and brain network generation from images to graphs. We validate
applicability of this framework in the construction of brain network across
healthy and neurologically impaired cohorts using the authentic dataset.
Experimental results vividly demonstrate the significant effectiveness of the
proposed method across the downstream disease classification tasks. These
findings convincingly emphasize the prospective value in the field of brain
network research, particularly its key significance in neuroimaging analysis
and disease diagnosis. This research provides a valuable reference for the
processing of multimodal brain imaging data and introduces a novel, efficient
solution to the field of neuroimaging.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05201" title="Abstract">arXiv:2311.05201</a> [<a href="/pdf/2311.05201" title="Download PDF">pdf</a>, <a href="/format/2311.05201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Green Resilience of Cyber-Physical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rimawi%2C+D">Diaeddin Rimawi</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2022 IEEE International Symposium on Software Reliability
  Engineering Workshops (ISSREW) Doctoral Symposium (ISSRE-DS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Cyber-Physical System (CPS) represents systems that join both hardware and
software components to perform real-time services. Maintaining the system's
reliability is critical to the continuous delivery of these services. However,
the CPS running environment is full of uncertainties and can easily lead to
performance degradation. As a result, the need for a recovery technique is
highly needed to achieve resilience in the system, with keeping in mind that
this technique should be as green as possible. This early doctorate proposal,
suggests a game theory solution to achieve resilience and green in CPS. Game
theory has been known for its fast performance in decision-making, helping the
system to choose what maximizes its payoffs. The proposed game model is
described over a real-life collaborative artificial intelligence system (CAIS),
that involves robots with humans to achieve a common goal. It shows how the
expected results of the system will achieve the resilience of CAIS with
minimized CO2 footprint.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05203" title="Abstract">arXiv:2311.05203</a> [<a href="/pdf/2311.05203" title="Download PDF">pdf</a>, <a href="/format/2311.05203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Whisper in Focus: Enhancing Stuttered Speech Classification with Encoder  Layer Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ameer%2C+H">Huma Ameer</a>, 
<a href="/search/cs?searchtype=author&query=Latif%2C+S">Seemab Latif</a>, 
<a href="/search/cs?searchtype=author&query=Latif%2C+R">Rabia Latif</a>, 
<a href="/search/cs?searchtype=author&query=Mukhtar%2C+S">Sana Mukhtar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures, 6 tables, journal paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In recent years, advancements in the field of speech processing have led to
cutting-edge deep learning algorithms with immense potential for real-world
applications. The automated identification of stuttered speech is one of such
applications that the researchers are addressing by employing deep learning
techniques. Recently, researchers have utilized Wav2vec2.0, a speech
recognition model to classify disfluency types in stuttered speech. Although
Wav2vec2.0 has shown commendable results, its ability to generalize across all
disfluency types is limited. In addition, since its base model uses 12 encoder
layers, it is considered a resource-intensive model. Our study unravels the
capabilities of Whisper for the classification of disfluency types in stuttered
speech. We have made notable contributions in three pivotal areas: enhancing
the quality of SEP28-k benchmark dataset, exploration of Whisper for
classification, and introducing an efficient encoder layer freezing strategy.
The optimized Whisper model has achieved the average F1-score of 0.81, which
proffers its abilities. This study also unwinds the significance of deeper
encoder layers in the identification of disfluency types, as the results
demonstrate their greater contribution compared to initial layers. This
research represents substantial contributions, shifting the emphasis towards an
efficient solution, thereby thriving towards prospective innovation.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05210" title="Abstract">arXiv:2311.05210</a> [<a href="/pdf/2311.05210" title="Download PDF">pdf</a>, <a href="/ps/2311.05210" title="Download PostScript">ps</a>, <a href="/format/2311.05210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From &quot;What&quot; to &quot;When&quot; -- a Spiking Neural Network Predicting Rare Events  and Time to their Occurrence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kiselev%2C+M">Mikhail Kiselev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2309.08476">arXiv:2309.08476</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">In the reinforcement learning (RL) tasks, the ability to predict receiving
reward in the near or more distant future means the ability to evaluate the
current state as more or less close to the target state (labelled by the reward
signal). In the present work, we utilize a spiking neural network (SNN) to
predict time to the next target event (reward - in case of RL). In the context
of SNNs, events are represented as spikes emitted by network neurons or input
nodes. It is assumed that target events are indicated by spikes emitted by a
special network input node. Using description of the current state encoded in
the form of spikes from the other input nodes, the network should predict
approximate time of the next target event. This research paper presents a novel
approach to learning the corresponding predictive model by an SNN consisting of
leaky integrate-and-fire (LIF) neurons. The proposed method leverages specially
designed local synaptic plasticity rules and a novel columnar-layered SNN
architecture. Similar to our previous works, this study places a strong
emphasis on the hardware-friendliness of the proposed models, ensuring their
efficient implementation on modern and future neuroprocessors. The approach
proposed was tested on a simple reward prediction task in the context of one of
the RL benchmark ATARI games, ping-pong. It was demonstrated that the SNN
described in this paper gives superior prediction accuracy in comparison with
precise machine learning techniques, such as decision tree algorithms and
convolutional neural networks.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05213" title="Abstract">arXiv:2311.05213</a> [<a href="/pdf/2311.05213" title="Download PDF">pdf</a>, <a href="/format/2311.05213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tracking and Following a Suspended Moving Object using Camera-Based  Vision System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ambrosino%2C+M">Michele Ambrosino</a>, 
<a href="/search/cs?searchtype=author&query=Mahmalji%2C+M">Manar Mahmalji</a>, 
<a href="/search/cs?searchtype=author&query=Rossell%C3%B3%2C+N+B">Nicol&#xe1;s Bono Rossell&#xf3;</a>, 
<a href="/search/cs?searchtype=author&query=Garone%2C+E">Emanuele Garone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">When robots are able to see and respond to their surroundings, a whole new
world of possibilities opens up. To bring these possibilities to life, the
robotics industry is increasingly adopting camera-based vision systems,
especially when a robotic system needs to interact with a dynamic environment
or moving target. However, this kind of vision system is known to have low data
transmission rates, packet loss during communication and noisy measurements as
major disadvantages. These problems can perturb the control performance and the
quality of the robot-environment interaction. To improve the quality of visual
information, in this paper, we propose to model the dynamics of the motion of a
target object and use this model to implement an Extended Kalman Filter based
on Intermittent Observations of the vision system. The effectiveness of the
proposed approach was tested through experiments with a robotic arm, a camera
device in an eye-to-hand configuration, and an oscillating suspended block as a
target to follow.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05215" title="Abstract">arXiv:2311.05215</a> [<a href="/pdf/2311.05215" title="Download PDF">pdf</a>, <a href="/format/2311.05215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the security of randomly transformed quadratic programs for  privacy-preserving cloud-based control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Binfet%2C+P">Philipp Binfet</a>, 
<a href="/search/eess?searchtype=author&query=Schl%C3%BCter%2C+N">Nils Schl&#xfc;ter</a>, 
<a href="/search/eess?searchtype=author&query=Darup%2C+M+S">Moritz Schulze Darup</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation at the 62nd IEEE Conference on Decision and Control 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Control related data, such as system states and inputs or controller
specifications, is often sensitive. Meanwhile, the increasing connectivity of
cloud-based or networked control results in vast amounts of such data, which
poses a privacy threat, especially when evaluation on external platforms is
considered. In this context, a cipher based on a random affine transformation
gained attention, which is supposed to enable privacy-preserving evaluations of
quadratic programs (QPs) with little computational overhead compared to other
methods.
<br />This paper deals with the security of such randomly transformed QPs in the
context of model predictive control (MPC). In particular, we show how to
construct attacks against this cipher and thereby underpin concerns regarding
its security in a practical setting. To this end, we exploit invariants under
the transformations and common specifications of MPC-related QPs. Our numerical
examples then illustrate that these two ingredients suffice to extract
information from ciphertexts.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05221" title="Abstract">arXiv:2311.05221</a> [<a href="/pdf/2311.05221" title="Download PDF">pdf</a>, <a href="/format/2311.05221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Let&#x27;s Get the FACS Straight -- Reconstructing Obstructed Facial Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C3%BCchner%2C+T">Tim B&#xfc;chner</a>, 
<a href="/search/cs?searchtype=author&query=Sickert%2C+S">Sven Sickert</a>, 
<a href="/search/cs?searchtype=author&query=Volk%2C+G+F">Gerd Fabian Volk</a>, 
<a href="/search/cs?searchtype=author&query=Anders%2C+C">Christoph Anders</a>, 
<a href="/search/cs?searchtype=author&query=Guntinas-Lichius%2C+O">Orlando Guntinas-Lichius</a>, 
<a href="/search/cs?searchtype=author&query=Denzler%2C+J">Joachim Denzler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> VISAPP 2023 paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The human face is one of the most crucial parts in interhuman communication.
Even when parts of the face are hidden or obstructed the underlying facial
movements can be understood. Machine learning approaches often fail in that
regard due to the complexity of the facial structures. To alleviate this
problem a common approach is to fine-tune a model for such a specific
application. However, this is computational intensive and might have to be
repeated for each desired analysis task. In this paper, we propose to
reconstruct obstructed facial parts to avoid the task of repeated fine-tuning.
As a result, existing facial analysis methods can be used without further
changes with respect to the data. In our approach, the restoration of facial
features is interpreted as a style transfer task between different recording
setups. By using the CycleGAN architecture the requirement of matched pairs,
which is often hard to fullfill, can be eliminated. To proof the viability of
our approach, we compare our reconstructions with real unobstructed recordings.
We created a novel data set in which 36 test subjects were recorded both with
and without 62 surface electromyography sensors attached to their faces. In our
evaluation, we feature typical facial analysis tasks, like the computation of
Facial Action Units and the detection of emotions. To further assess the
quality of the restoration, we also compare perceptional distances. We can
show, that scores similar to the videos without obstructing sensors can be
achieved.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05227" title="Abstract">arXiv:2311.05227</a> [<a href="/pdf/2311.05227" title="Download PDF">pdf</a>, <a href="/ps/2311.05227" title="Download PostScript">ps</a>, <a href="/format/2311.05227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kantian Deontology Meets AI Alignment: Towards Morally Robust Fairness  Metrics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mougan%2C+C">Carlos Mougan</a>, 
<a href="/search/cs?searchtype=author&query=Brand%2C+J">Joshua Brand</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Deontological ethics, specifically understood through Immanuel Kant, provides
a moral framework that emphasizes the importance of duties and principles,
rather than the consequences of action. Understanding that despite the
prominence of deontology, it is currently an overlooked approach in fairness
metrics, this paper explores the compatibility of a Kantian deontological
framework in fairness metrics, part of the AI alignment field. We revisit
Kant's critique of utilitarianism, which is the primary approach in AI fairness
metrics and argue that fairness principles should align with the Kantian
deontological framework. By integrating Kantian ethics into AI alignment, we
not only bring in a widely-accepted prominent moral theory but also strive for
a more morally grounded AI landscape that better balances outcomes and
procedures in pursuit of fairness and justice.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05230" title="Abstract">arXiv:2311.05230</a> [<a href="/pdf/2311.05230" title="Download PDF">pdf</a>, <a href="/format/2311.05230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConRad: Image Constrained Radiance Fields for 3D Generation from a  Single Image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Purushwalkam%2C+S">Senthil Purushwalkam</a>, 
<a href="/search/cs?searchtype=author&query=Naik%2C+N">Nikhil Naik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Advances in Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present a novel method for reconstructing 3D objects from a single RGB
image. Our method leverages the latest image generation models to infer the
hidden 3D structure while remaining faithful to the input image. While existing
methods obtain impressive results in generating 3D models from text prompts,
they do not provide an easy approach for conditioning on input RGB data.
Na\"ive extensions of these methods often lead to improper alignment in
appearance between the input image and the 3D reconstructions. We address these
challenges by introducing Image Constrained Radiance Fields (ConRad), a novel
variant of neural radiance fields. ConRad is an efficient 3D representation
that explicitly captures the appearance of an input image in one viewpoint. We
propose a training algorithm that leverages the single RGB image in conjunction
with pretrained Diffusion Models to optimize the parameters of a ConRad
representation. Extensive experiments show that ConRad representations can
simplify preservation of image details while producing a realistic 3D
reconstruction. Compared to existing state-of-the-art baselines, we show that
our 3D reconstructions remain more faithful to the input and produce more
consistent 3D models while demonstrating significantly improved quantitative
performance on a ShapeNet object benchmark.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05232" title="Abstract">arXiv:2311.05232</a> [<a href="/pdf/2311.05232" title="Download PDF">pdf</a>, <a href="/format/2311.05232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Hallucination in Large Language Models: Principles,  Taxonomy, Challenges, and Open Questions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Lei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Weijiang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Weitao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+W">Weihong Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhangyin Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haotian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qianglong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Weihua Peng</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xiaocheng Feng</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+B">Bing Qin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Ting Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress; 49 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The emergence of large language models (LLMs) has marked a significant
breakthrough in natural language processing (NLP), leading to remarkable
advancements in text understanding and generation. Nevertheless, alongside
these strides, LLMs exhibit a critical tendency to produce hallucinations,
resulting in content that is inconsistent with real-world facts or user inputs.
This phenomenon poses substantial challenges to their practical deployment and
raises concerns over the reliability of LLMs in real-world scenarios, which
attracts increasing attention to detect and mitigate these hallucinations. In
this survey, we aim to provide a thorough and in-depth overview of recent
advances in the field of LLM hallucinations. We begin with an innovative
taxonomy of LLM hallucinations, then delve into the factors contributing to
hallucinations. Subsequently, we present a comprehensive overview of
hallucination detection methods and benchmarks. Additionally, representative
approaches designed to mitigate hallucinations are introduced accordingly.
Finally, we analyze the challenges that highlight the current limitations and
formulate open questions, aiming to delineate pathways for future research on
hallucinations in LLMs.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05237" title="Abstract">arXiv:2311.05237</a> [<a href="/pdf/2311.05237" title="Download PDF">pdf</a>, <a href="/format/2311.05237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Widely Applicable Strong Baseline for Sports Ball Detection and Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tarashima%2C+S">Shuhei Tarashima</a>, 
<a href="/search/cs?searchtype=author&query=Haq%2C+M+A">Muhammad Abdul Haq</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yushan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tagawa%2C+N">Norio Tagawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> BMVC2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this work, we present a novel Sports Ball Detection and Tracking (SBDT)
method that can be applied to various sports categories. Our approach is
composed of (1) high-resolution feature extraction, (2) position-aware model
training, and (3) inference considering temporal consistency, all of which are
put together as a new SBDT baseline. Besides, to validate the
wide-applicability of our approach, we compare our baseline with 6
state-of-the-art SBDT methods on 5 datasets from different sports categories.
We achieve this by newly introducing two SBDT datasets, providing new ball
annotations for two datasets, and re-implementing all the methods to ease
extensive comparison. Experimental results demonstrate that our approach is
substantially superior to existing methods on all the sports categories covered
by the datasets. We believe our proposed method can play as a Widely Applicable
Strong Baseline (WASB) of SBDT, and our datasets and codebase will promote
future SBDT research. Datasets and codes will be made publicly available.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05241" title="Abstract">arXiv:2311.05241</a> [<a href="/pdf/2311.05241" title="Download PDF">pdf</a>, <a href="/format/2311.05241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Meta-Learning Meets Online and Continual Learning: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Son%2C+J">Jaehyeon Son</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Soochan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+G">Gunhee Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Over the past decade, deep neural networks have demonstrated significant
success using the training scheme that involves mini-batch stochastic gradient
descent on extensive datasets. Expanding upon this accomplishment, there has
been a surge in research exploring the application of neural networks in other
learning scenarios. One notable framework that has garnered significant
attention is meta-learning. Often described as "learning to learn,"
meta-learning is a data-driven approach to optimize the learning algorithm.
Other branches of interest are continual learning and online learning, both of
which involve incrementally updating a model with streaming data. While these
frameworks were initially developed independently, recent works have started
investigating their combinations, proposing novel problem settings and learning
algorithms. However, due to the elevated complexity and lack of unified
terminology, discerning differences between the learning frameworks can be
challenging even for experienced researchers. To facilitate a clear
understanding, this paper provides a comprehensive survey that organizes
various problem settings using consistent terminology and formal descriptions.
By offering an overview of these learning paradigms, our work aims to foster
further advancements in this promising area of research.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05243" title="Abstract">arXiv:2311.05243</a> [<a href="/pdf/2311.05243" title="Download PDF">pdf</a>, <a href="/format/2311.05243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A higher-order transformation approach to the formalization and analysis  of BPMN using graph transformation systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kr%C3%A4uter%2C+T">Tim Kr&#xe4;uter</a>, 
<a href="/search/cs?searchtype=author&query=Rutle%2C+A">Adrian Rutle</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6nig%2C+H">Harald K&#xf6;nig</a>, 
<a href="/search/cs?searchtype=author&query=Lamo%2C+Y">Yngve Lamo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The Business Process Modeling Notation (BPMN) is a widely used standard
notation for defining intra- and inter-organizational workflows. However, the
informal description of the BPMN execution semantics leads to different
interpretations of BPMN elements and difficulties in checking behavioral
properties. In this article, we propose a formalization of the execution
semantics of BPMN that, compared to existing approaches, covers more BPMN
elements while also facilitating property checking. Our approach is based on a
higher-order transformation from BPMN models to graph transformation systems.
To show the capabilities of our approach, we implemented it as an open-source
web-based tool. A demonstration of our tool is available at
https://youtu.be/MxXbNUl6IjE.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05245" title="Abstract">arXiv:2311.05245</a> [<a href="/pdf/2311.05245" title="Download PDF">pdf</a>, <a href="/ps/2311.05245" title="Download PostScript">ps</a>, <a href="/format/2311.05245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty Wrapper in the medical domain: Establishing transparent  uncertainty quantification for opaque machine learning models in practice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=J%C3%B6ckel%2C+L">Lisa J&#xf6;ckel</a>, 
<a href="/search/cs?searchtype=author&query=Kl%C3%A4s%2C+M">Michael Kl&#xe4;s</a>, 
<a href="/search/cs?searchtype=author&query=Popp%2C+G">Georg Popp</a>, 
<a href="/search/cs?searchtype=author&query=Hilger%2C+N">Nadja Hilger</a>, 
<a href="/search/cs?searchtype=author&query=Fricke%2C+S">Stephan Fricke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">When systems use data-based models that are based on machine learning (ML),
errors in their results cannot be ruled out. This is particularly critical if
it remains unclear to the user how these models arrived at their decisions and
if errors can have safety-relevant consequences, as is often the case in the
medical field. In such cases, the use of dependable methods to quantify the
uncertainty remaining in a result allows the user to make an informed decision
about further usage and draw possible conclusions based on a given result. This
paper demonstrates the applicability and practical utility of the Uncertainty
Wrapper using flow cytometry as an application from the medical field that can
benefit from the use of ML models in conjunction with dependable and
transparent uncertainty quantification.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05246" title="Abstract">arXiv:2311.05246</a> [<a href="/pdf/2311.05246" title="Download PDF">pdf</a>, <a href="/ps/2311.05246" title="Download PostScript">ps</a>, <a href="/format/2311.05246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reduction-based Creative Telescoping for P-recursive Sequences via  Integral Bases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shaoshi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+L">Lixin Du</a>, 
<a href="/search/cs?searchtype=author&query=Kauers%2C+M">Manuel Kauers</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rong-Hua Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>

</div>
<p class="mathjax">We propose a way to split a given bivariate P-recursive sequence into a
summable part and a non-summable part in such a way that the non-summable part
is minimal in some sense. This decomposition gives rise to a new
reduction-based creative telescoping algorithm based on the concept of integral
bases.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05247" title="Abstract">arXiv:2311.05247</a> [<a href="/pdf/2311.05247" title="Download PDF">pdf</a>, <a href="/ps/2311.05247" title="Download PostScript">ps</a>, <a href="/format/2311.05247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficacy Analysis of Power Swing Blocking and Out-of-Step Tripping  Functions in Grid-Following VSC Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xiong%2C+Y">Yongxin Xiong</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+H">Heng Wu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xiongfei Wang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yifei Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Power flow oscillations can occur in power systems after major disturbances
such as system faults, which may result in significant power swings and even
lead to system collapse. This paper provides a detailed analysis of the
efficacy of the legacy power swing blocking and out-of-step tripping functions
in grid-following voltage-source converter (GFL-VSC) systems. First, the power
swing dynamics of GFL-VSC are characterized, considering the outer power
control loops and phase-locked loop (PLL). It is found that the loss of
synchronism (LOS) of the GFL-VSC system is caused by the divergence of the
output angle of the PLL, which is fundamentally different from that of
synchronous generator (SG)-based systems, whose LOS originates from the
divergence of power angle differences between power sources. Therefore, the
legacy setting principles for power swing blocking and out-of-step tripping
function designed for SG-based systems can not be directly applied to GFL-VSC
systems, and may even malfunction. Time-domain simulations are performed in the
PSCAD/EMTDC platform to validate the correctness of the theoretical analysis.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05250" title="Abstract">arXiv:2311.05250</a> [<a href="/pdf/2311.05250" title="Download PDF">pdf</a>, <a href="/format/2311.05250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Complexity of Checking Non-Emptiness in Symbolic Tree Automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raya%2C+R">Rodrigo Raya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2307.00151">arXiv:2307.00151</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">We study the satisfiability problem of symbolic tree automata and decompose
it into the satisfiability problem of the existential first-order theory of the
input characters and the existential monadic second-order theory of the indices
of the accepted words. We use our decomposition to obtain tight computational
complexity bounds on the decision problem for this automata class and an
extension that considers linear arithmetic constraints on the underlying
effective Boolean algebra
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05252" title="Abstract">arXiv:2311.05252</a> [<a href="/pdf/2311.05252" title="Download PDF">pdf</a>, <a href="/format/2311.05252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can we run our Ethereum nodes at home?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cortes-Goicoechea%2C+M">Mikel Cortes-Goicoechea</a>, 
<a href="/search/cs?searchtype=author&query=Mohandas-Daryanani%2C+T">Tarun Mohandas-Daryanani</a>, 
<a href="/search/cs?searchtype=author&query=Mu%C3%B1oz-Tapia%2C+J+L">Jose L. Mu&#xf1;oz-Tapia</a>, 
<a href="/search/cs?searchtype=author&query=Bautista-Gomez%2C+L">Leonardo Bautista-Gomez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Scalability is a common issue among the most used permissionless blockchains,
and several approaches have been proposed to solve this issue. Tackling
scalability while preserving the security and decentralization of the network
is a significant challenge. To deliver effective scaling solutions, Ethereum
achieved a major protocol improvement, including a change in the consensus
mechanism towards Proof of Stake. This improvement aimed a vast reduction of
the hardware requirements to run a node, leading to significant sustainability
benefits with a lower network energy consumption. This work analyzes the
resource usage behavior of different clients running as Ethereum consensus
nodes, comparing their performance under different configurations and analyzing
their differences. Our results show higher requirements than claimed initially
and how different clients react to network perturbations. Furthermore, we
discuss the differences between the consensus clients, including their strong
points and limitations.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05256" title="Abstract">arXiv:2311.05256</a> [<a href="/pdf/2311.05256" title="Download PDF">pdf</a>, <a href="/format/2311.05256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Task-Specific Graph Network Simulators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dahlinger%2C+P">Philipp Dahlinger</a>, 
<a href="/search/cs?searchtype=author&query=Freymuth%2C+N">Niklas Freymuth</a>, 
<a href="/search/cs?searchtype=author&query=Volpp%2C+M">Michael Volpp</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+T">Tai Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Neumann%2C+G">Gerhard Neumann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Simulating dynamic physical interactions is a critical challenge across
multiple scientific domains, with applications ranging from robotics to
material science. For mesh-based simulations, Graph Network Simulators (GNSs)
pose an efficient alternative to traditional physics-based simulators. Their
inherent differentiability and speed make them particularly well-suited for
inverse design problems. Yet, adapting to new tasks from limited available data
is an important aspect for real-world applications that current methods
struggle with. We frame mesh-based simulation as a meta-learning problem and
use a recent Bayesian meta-learning method to improve GNSs adaptability to new
scenarios by leveraging context data and handling uncertainties. Our approach,
latent task-specific graph network simulator, uses non-amortized task posterior
approximations to sample latent descriptions of unknown system properties.
Additionally, we leverage movement primitives for efficient full trajectory
prediction, effectively addressing the issue of accumulating errors encountered
by previous auto-regressive methods. We validate the effectiveness of our
approach through various experiments, performing on par with or better than
established baseline methods. Movement primitives further allow us to
accommodate various types of context data, as demonstrated through the
utilization of point clouds during inference. By combining GNSs with
meta-learning, we bring them closer to real-world applicability, particularly
in scenarios with smaller datasets.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05259" title="Abstract">arXiv:2311.05259</a> [<a href="/pdf/2311.05259" title="Download PDF">pdf</a>, <a href="/ps/2311.05259" title="Download PostScript">ps</a>, <a href="/format/2311.05259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design and Control of a VTOL Aerial Vehicle Tilting its Rotors Only with  Rotor Thrusts and a Passive Joint
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ito%2C+T">Takumi Ito</a>, 
<a href="/search/eess?searchtype=author&query=Funada%2C+R">Riku Funada</a>, 
<a href="/search/eess?searchtype=author&query=Sampei%2C+M">Mitsuji Sampei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">This paper presents a novel VTOL UAV that owns a link connecting four rotors
and a fuselage by a passive joint, allowing the control of the rotor's tilting
angle by adjusting the rotors' thrust. This unique structure contributes to
eliminating additional actuators, such as servo motors, to control the tilting
angles of rotors, resulting in the UAV's weight lighter and simpler structure.
We first derive the dynamical model of the newly designed UAV and analyze its
controllability. Then, we design the controller that leverages the tiltable
link with four rotors to accelerate the UAV while suppressing a deviation of
the UAV's angle of attack from the desired value to restrain the change of the
aerodynamic force. Finally, the validity of the proposed control strategy is
evaluated in simulation study.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05261" title="Abstract">arXiv:2311.05261</a> [<a href="/pdf/2311.05261" title="Download PDF">pdf</a>, <a href="/ps/2311.05261" title="Download PostScript">ps</a>, <a href="/format/2311.05261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RAGLog: Log Anomaly Detection using Retrieval Augmented Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jonathan Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+S+L">Swee Liang Wong</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yidi Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2203.10960">arXiv:2203.10960</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The ability to detect log anomalies from system logs is a vital activity
needed to ensure cyber resiliency of systems. It is applied for fault
identification or facilitate cyber investigation and digital forensics.
However, as logs belonging to different systems and components differ
significantly, the challenge to perform such analysis is humanly challenging
from the volume, variety and velocity of logs. This is further complicated by
the lack or unavailability of anomalous log entries to develop trained machine
learning or artificial intelligence models for such purposes. In this research
work, we explore the use of a Retrieval Augmented Large Language Model that
leverages a vector database to detect anomalies from logs. We used a Question
and Answer configuration pipeline. To the best of our knowledge, our experiment
which we called RAGLog is a novel one and the experimental results show much
promise.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05263" title="Abstract">arXiv:2311.05263</a> [<a href="/pdf/2311.05263" title="Download PDF">pdf</a>, <a href="/format/2311.05263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-Based Minimum Bayes Risk Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jinnai%2C+Y">Yuu Jinnai</a>, 
<a href="/search/cs?searchtype=author&query=Morimura%2C+T">Tetsuro Morimura</a>, 
<a href="/search/cs?searchtype=author&query=Honda%2C+U">Ukyo Honda</a>, 
<a href="/search/cs?searchtype=author&query=Ariu%2C+K">Kaito Ariu</a>, 
<a href="/search/cs?searchtype=author&query=Abe%2C+K">Kenshi Abe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Minimum Bayes Risk (MBR) decoding has been shown to be a powerful alternative
to beam search decoding in a variety of text generation tasks. MBR decoding
selects a hypothesis from a pool of hypotheses that has the least expected risk
under a probability model according to a given utility function. Since it is
impractical to compute the expected risk exactly over all possible hypotheses,
two approximations are commonly used in MBR. First, it integrates over a
sampled set of hypotheses rather than over all possible hypotheses. Second, it
estimates the probability of each hypothesis using a Monte Carlo estimator.
While the first approximation is necessary to make it computationally feasible,
the second is not essential since we typically have access to the model
probability at inference time. We propose Model-Based MBR (MBMBR), a variant of
MBR that uses the model probability itself as the estimate of the probability
distribution instead of the Monte Carlo estimate. We show analytically and
empirically that the model-based estimate is more promising than the Monte
Carlo estimate in text generation tasks. Our experiments show that MBMBR
outperforms MBR in several text generation tasks, both with encoder-decoder
models and with large language models.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05265" title="Abstract">arXiv:2311.05265</a> [<a href="/pdf/2311.05265" title="Download PDF">pdf</a>, <a href="/format/2311.05265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Don&#x27;t Waste a Single Annotation: Improving Single-Label Classifiers  Through Soft Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Ben Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yue Li</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+Y">Yida Mu</a>, 
<a href="/search/cs?searchtype=author&query=Scarton%2C+C">Carolina Scarton</a>, 
<a href="/search/cs?searchtype=author&query=Bontcheva%2C+K">Kalina Bontcheva</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xingyi Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023 (Findings)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we address the limitations of the common data annotation and
training methods for objective single-label classification tasks. Typically,
when annotating such tasks annotators are only asked to provide a single label
for each sample and annotator disagreement is discarded when a final hard label
is decided through majority voting. We challenge this traditional approach,
acknowledging that determining the appropriate label can be difficult due to
the ambiguity and lack of context in the data samples. Rather than discarding
the information from such ambiguous annotations, our soft label method makes
use of them for training. Our findings indicate that additional annotator
information, such as confidence, secondary label and disagreement, can be used
to effectively generate soft labels. Training classifiers with these soft
labels then leads to improved performance and calibration on the hard label
test set.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05266" title="Abstract">arXiv:2311.05266</a> [<a href="/pdf/2311.05266" title="Download PDF">pdf</a>, <a href="/ps/2311.05266" title="Download PostScript">ps</a>, <a href="/format/2311.05266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RIS in Indoor Environments: Benchmarking Against Ambient Propagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sadeghian%2C+M">Masoud Sadeghian</a>, 
<a href="/search/cs?searchtype=author&query=Pizzo%2C+A">Andrea Pizzo</a>, 
<a href="/search/cs?searchtype=author&query=Lozano%2C+A">Angel Lozano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the 2023 Asilomar Conference on Signals, Systems, and Computers, Pacific Grove, CA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">The improvements in received signal power brought about by a reflective
intelligent surface (RIS) might be overstated if background propagation
mechanisms such as reflections, scattering, and diffraction are ignored. This
paper addresses this issue for non-line-of-sight indoor settings, contrasting
the energy conveyed by an RIS with the energy already reaching the receiver
through environmental reflections. And, to prevent artifacts, such naturally
occurring reflections are not modeled via approximate methods, but rather
through a rigorous physics-based formulation. It is found that the environment
contributes a level of energy commensurate with that of an ideal RIS of
considerable size; to have substantial impact, an actual RIS would have to
generously exceed this size.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05267" title="Abstract">arXiv:2311.05267</a> [<a href="/pdf/2311.05267" title="Download PDF">pdf</a>, <a href="/format/2311.05267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis and Characterization of Performance Variability for OpenMP  Runtime
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+M">Minyu Cui</a>, 
<a href="/search/cs?searchtype=author&query=Papadopoulou%2C+N">Nikela Papadopoulou</a>, 
<a href="/search/cs?searchtype=author&query=Peric%C3%A0s%2C+M">Miquel Peric&#xe0;s</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at ROSS 2023 (International Workshop on Runtime and Operating Systems for Supercomputers), held in conjunction with SC23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">In the high performance computing (HPC) domain, performance variability is a
major scalability issue for parallel computing applications with heavy
synchronization and communication. In this paper, we present an experimental
performance analysis of OpenMP benchmarks regarding the variation of execution
time, and determine the potential factors causing performance variability. Our
work offers some understanding of performance distributions and directions for
future work on how to mitigate variability for OpenMP-based applications. Two
representative OpenMP benchmarks from the EPCC OpenMP micro-benchmark suite and
BabelStream are run across two x86 multicore platforms featuring up to 256
threads. From the obtained results, we characterize and explain the execution
time variability as a function of thread-pinning, simultaneous multithreading
(SMT) and core frequency variation.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05268" title="Abstract">arXiv:2311.05268</a> [<a href="/pdf/2311.05268" title="Download PDF">pdf</a>, <a href="/ps/2311.05268" title="Download PostScript">ps</a>, <a href="/format/2311.05268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modelling prospective memory and resilient situated communications via  Wizard of Oz
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanzhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Broz%2C+F">Frank Broz</a>, 
<a href="/search/cs?searchtype=author&query=Neerincx%2C+M">Mark Neerincx</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages. Part of WTF 23 workshop proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This abstract presents a scenario for human-robot action in a home setting
involving an older adult and a robot. The scenario is designed to explore the
envisioned modelling of memory for communication with a socially assistive
robots (SAR). The scenario will enable the gathering of data on failures of
speech technology and human-robot communication involving shared memory that
may occur during daily activities such as a music-listening activity.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05270" title="Abstract">arXiv:2311.05270</a> [<a href="/pdf/2311.05270" title="Download PDF">pdf</a>, <a href="/format/2311.05270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of Data Processing and Machine Learning Techniques in  P300-based Authentication using Brain-Computer Interfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bernal%2C+E+L">Eduardo L&#xf3;pez Bernal</a>, 
<a href="/search/cs?searchtype=author&query=Bernal%2C+S+L">Sergio L&#xf3;pez Bernal</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+G+M">Gregorio Mart&#xed;nez P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Celdr%C3%A1n%2C+A+H">Alberto Huertas Celdr&#xe1;n</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Brain-Computer Interfaces (BCIs) are used in various application scenarios
allowing direct communication between the brain and computers. Specifically,
electroencephalography (EEG) is one of the most common techniques for obtaining
evoked potentials resulting from external stimuli, as the P300 potential is
elicited from known images. The combination of Machine Learning (ML) and P300
potentials is promising for authenticating subjects since the brain waves
generated by each person when facing a particular stimulus are unique. However,
existing authentication solutions do not extensively explore P300 potentials
and fail when analyzing the most suitable processing and ML-based
classification techniques. Thus, this work proposes i) a framework for
authenticating BCI users using the P300 potential; ii) the validation of the
framework on ten subjects creating an experimental scenario employing a
non-invasive EEG-based BCI; and iii) the evaluation of the framework
performance defining two experiments (binary and multiclass ML classification)
and three testing configurations incrementally analyzing the performance of
different processing techniques and the differences between classifying with
epochs or statistical values. This framework achieved a performance close to
100\% f1-score in both experiments for the best classifier, highlighting its
effectiveness in accurately authenticating users and demonstrating the
feasibility of performing EEG-based authentication using P300 potentials.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05276" title="Abstract">arXiv:2311.05276</a> [<a href="/pdf/2311.05276" title="Download PDF">pdf</a>, <a href="/format/2311.05276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAMVG: A Multi-stage Image Vectorization Model with the Segment-Anything  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Haokun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chong%2C+J+I">Juang Ian Chong</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+T">Teng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+R">Ran Yi</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+Y">Yu-Kun Lai</a>, 
<a href="/search/cs?searchtype=author&query=Rosin%2C+P+L">Paul L. Rosin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vector graphics are widely used in graphical designs and have received more
and more attention. However, unlike raster images which can be easily obtained,
acquiring high-quality vector graphics, typically through automatically
converting from raster images remains a significant challenge, especially for
more complex images such as photos or artworks. In this paper, we propose
SAMVG, a multi-stage model to vectorize raster images into SVG (Scalable Vector
Graphics). Firstly, SAMVG uses general image segmentation provided by the
Segment-Anything Model and uses a novel filtering method to identify the best
dense segmentation map for the entire image. Secondly, SAMVG then identifies
missing components and adds more detailed components to the SVG. Through a
series of extensive experiments, we demonstrate that SAMVG can produce high
quality SVGs in any domain while requiring less computation time and complexity
compared to previous state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05281" title="Abstract">arXiv:2311.05281</a> [<a href="/pdf/2311.05281" title="Download PDF">pdf</a>, <a href="/format/2311.05281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding Software Vulnerabilities in Open-Source C Projects via Bounded  Model Checking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Sousa%2C+J+O">Janislley Oliveira de Sousa</a>, 
<a href="/search/cs?searchtype=author&query=de+Farias%2C+B+C">Bruno Carvalho de Farias</a>, 
<a href="/search/cs?searchtype=author&query=da+Silva%2C+T+A">Thales Araujo da Silva</a>, 
<a href="/search/cs?searchtype=author&query=de+Lima+Filho%2C+E+B">Eddie Batista de Lima Filho</a>, 
<a href="/search/cs?searchtype=author&query=Cordeiro%2C+L+C">Lucas C. Cordeiro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, submitted to STTT journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Computer-based systems have solved several domain problems, including
industrial, military, education, and wearable. Nevertheless, such arrangements
need high-quality software to guarantee security and safety as both are
mandatory for modern software products. We advocate that bounded model-checking
techniques can efficiently detect vulnerabilities in general software systems.
However, such an approach struggles to scale up and verify extensive code
bases. Consequently, we have developed and evaluated a methodology to verify
large software systems using a state-of-the-art bounded model checker. In
particular, we pre-process input source-code files and guide the respective
model checker to explore them systematically. Moreover, the proposed scheme
includes a function-wise prioritization strategy, which readily provides
results for code entities according to a scale of importance. Experimental
results using a real implementation of the proposed methodology show that it
can efficiently verify large software systems. Besides, it presented low peak
memory allocation when executed. We have evaluated our approach by verifying
twelve popular open-source C projects, where we have found real software
vulnerabilities that their developers confirmed.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05284" title="Abstract">arXiv:2311.05284</a> [<a href="/pdf/2311.05284" title="Download PDF">pdf</a>, <a href="/format/2311.05284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Challenges and Opportunities in the Co-design of Convolutions and RISC-V  Vector Processors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S+R">Sonia Rani Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Papadopoulou%2C+N">Nikela Papadopoulou</a>, 
<a href="/search/cs?searchtype=author&query=Peric%C3%A0s%2C+M">Miquel Peric&#xe0;s</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at the Second International workshop on RISC-V for HPC, co-located with SC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">The RISC-V "V" extension introduces vector processing to the RISC-V
architecture. Unlike most SIMD extensions, it supports long vectors which can
result in significant improvement of multiple applications. In this paper, we
present our ongoing research to implement and optimize a vectorized Winograd
algorithm used in convolutional layers on RISC-V Vector(RISC-VV) processors.
Our study identifies effective techniques for optimizing the kernels of
Winograd on RISC-VV using intrinsic instructions, and showcases how certain
instructions offer better performance. Our co-design findings suggest that the
Winograd algorithm benefits from vector lengths up to 2048 bits and cache sizes
up to 64MB.
<br />We use our experience with Winograd to highlight potential enhancements for
the standard that would simplify code generation and aid low-level programming.
Finally, we share our experience from experimenting with forks of gem5 for
RISC-VV and stress the importance of a mature software ecosystem, to facilitate
design space exploration and architectural optimization.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05286" title="Abstract">arXiv:2311.05286</a> [<a href="/pdf/2311.05286" title="Download PDF">pdf</a>, <a href="/format/2311.05286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Inference from Text: Unveiling Interactions between Variables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuxiang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yulan He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a long paper to the Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Adjusting for latent covariates is crucial for estimating causal effects from
observational textual data. Most existing methods only account for confounding
covariates that affect both treatment and outcome, potentially leading to
biased causal effects. This bias arises from insufficient consideration of
non-confounding covariates, which are relevant only to either the treatment or
the outcome. In this work, we aim to mitigate the bias by unveiling
interactions between different variables to disentangle the non-confounding
covariates when estimating causal effects from text. The disentangling process
ensures covariates only contribute to their respective objectives, enabling
independence between variables. Additionally, we impose a constraint to balance
representations from the treatment group and control group to alleviate
selection bias. We conduct experiments on two different treatment factors under
various scenarios, and the proposed model significantly outperforms recent
strong baselines. Furthermore, our thorough analysis on earnings call
transcripts demonstrates that our model can effectively disentangle the
variables, and further investigations into real-world scenarios provide
guidance for investors to make informed decisions.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05289" title="Abstract">arXiv:2311.05289</a> [<a href="/pdf/2311.05289" title="Download PDF">pdf</a>, <a href="/format/2311.05289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VoxNeRF: Bridging Voxel Representation and Neural Radiance Fields for  Enhanced Indoor View Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gasperini%2C+S">Stefano Gasperini</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shun-Cheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Navab%2C+N">Nassir Navab</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Creating high-quality view synthesis is essential for immersive applications
but continues to be problematic, particularly in indoor environments and for
real-time deployment. Current techniques frequently require extensive
computational time for both training and rendering, and often produce
less-than-ideal 3D representations due to inadequate geometric structuring. To
overcome this, we introduce VoxNeRF, a novel approach that leverages volumetric
representations to enhance the quality and efficiency of indoor view synthesis.
Firstly, VoxNeRF constructs a structured scene geometry and converts it into a
voxel-based representation. We employ multi-resolution hash grids to adaptively
capture spatial features, effectively managing occlusions and the intricate
geometry of indoor scenes. Secondly, we propose a unique voxel-guided efficient
sampling technique. This innovation selectively focuses computational resources
on the most relevant portions of ray segments, substantially reducing
optimization time. We validate our approach against three public indoor
datasets and demonstrate that VoxNeRF outperforms state-of-the-art methods.
Remarkably, it achieves these gains while reducing both training and rendering
times, surpassing even Instant-NGP in speed and bringing the technology closer
to real-time.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05296" title="Abstract">arXiv:2311.05296</a> [<a href="/pdf/2311.05296" title="Download PDF">pdf</a>, <a href="/format/2311.05296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeeLM: Dependency-enhanced Large Language Model for Sentence Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xianming Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jing Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in Progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent studies have proposed using large language models (LLMs) for sentence
embeddings. However, most existing LLMs are built with an autoregressive
architecture that primarily captures forward dependencies while neglecting
backward dependencies. Previous work has highlighted the importance of backward
dependencies in improving sentence embeddings. To address this issue, in this
paper, we first present quantitative evidence demonstrating the limited
learning of backward dependencies in LLMs. Then, we propose a novel approach
called Dependency-Enhanced Large Language Model (DeeLM) to improve sentence
embeddings. Specifically, we found a turning point in LLMs, where surpassing
specific LLM layers leads to a significant performance drop in the semantic
textual similarity (STS) task. STS is a crucial task for evaluating sentence
embeddings. We then extract the layers after the turning point to make them
bidirectional, allowing for the learning of backward dependencies. Extensive
experiments demonstrate that DeeLM outperforms baselines and achieves
state-of-the-art performance across various STS tasks.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05297" title="Abstract">arXiv:2311.05297</a> [<a href="/pdf/2311.05297" title="Download PDF">pdf</a>, <a href="/format/2311.05297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do personality tests generalize to Large Language Models?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dorner%2C+F+E">Florian E. Dorner</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%BChr%2C+T">Tom S&#xfc;hr</a>, 
<a href="/search/cs?searchtype=author&query=Samadi%2C+S">Samira Samadi</a>, 
<a href="/search/cs?searchtype=author&query=Kelava%2C+A">Augustin Kelava</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Socially Responsible Language Modelling Research (SoLaR) 2023 Workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">With large language models (LLMs) appearing to behave increasingly human-like
in text-based interactions, it has become popular to attempt to evaluate
various properties of these models using tests originally designed for humans.
While re-using existing tests is a resource-efficient way to evaluate LLMs,
careful adjustments are usually required to ensure that test results are even
valid across human sub-populations. Thus, it is not clear to what extent
different tests' validity generalizes to LLMs. In this work, we provide
evidence that LLMs' responses to personality tests systematically deviate from
typical human responses, implying that these results cannot be interpreted in
the same way as human test results. Concretely, reverse-coded items (e.g. "I am
introverted" vs "I am extraverted") are often both answered affirmatively by
LLMs. In addition, variation across different prompts designed to "steer" LLMs
to simulate particular personality types does not follow the clear separation
into five independent personality factors from human samples. In light of these
results, we believe it is important to pay more attention to tests' validity
for LLMs before drawing strong conclusions about potentially ill-defined
concepts like LLMs' "personality".
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05298" title="Abstract">arXiv:2311.05298</a> [<a href="/pdf/2311.05298" title="Download PDF">pdf</a>, <a href="/format/2311.05298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Vision-and-Language Reasoning via Spatial Relations Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Cheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Rui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Ye Guo</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+P">Peixiang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiru Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+W">Wenkui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhongyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hong Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Visual commonsense reasoning (VCR) is a challenging multi-modal task, which
requires high-level cognition and commonsense reasoning ability about the real
world. In recent years, large-scale pre-training approaches have been developed
and promoted the state-of-the-art performance of VCR. However, the existing
approaches almost employ the BERT-like objectives to learn multi-modal
representations. These objectives motivated from the text-domain are
insufficient for the excavation on the complex scenario of visual modality.
Most importantly, the spatial distribution of the visual objects is basically
neglected. To address the above issue, we propose to construct the spatial
relation graph based on the given visual scenario. Further, we design two
pre-training tasks named object position regression (OPR) and spatial relation
classification (SRC) to learn to reconstruct the spatial relation graph
respectively. Quantitative analysis suggests that the proposed method can guide
the representations to maintain more spatial context and facilitate the
attention on the essential visual regions for reasoning. We achieve the
state-of-the-art results on VCR and two other vision-and-language reasoning
tasks VQA, and NLVR.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05303" title="Abstract">arXiv:2311.05303</a> [<a href="/pdf/2311.05303" title="Download PDF">pdf</a>, <a href="/format/2311.05303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reliable and Efficient Data Collection in UAV-based IoT Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joshi%2C+P">Poorvi Joshi</a> (1), 
<a href="/search/cs?searchtype=author&query=Kalita%2C+A">Alakesh Kalita</a> (2), 
<a href="/search/cs?searchtype=author&query=Gurusamy%2C+M">Mohan Gurusamy</a> (1) ((1) National University of Singapore, (2) Singapore University of Technology and Design)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 7 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">Internet of Things (IoT) involves sensors for monitoring and wireless
networks for efficient communication. However, resource-constrained IoT devices
and limitations in existing wireless technologies hinder its full potential.
Integrating Unmanned Aerial Vehicles (UAVs) into IoT networks can address some
challenges by expanding its' coverage, providing security, and bringing
computing closer to IoT devices. Nevertheless, effective data collection in
UAV-assisted IoT networks is hampered by factors, including dynamic UAV
behavior, environmental variables, connectivity instability, and security
considerations. In this survey, we first explore UAV-based IoT networks,
focusing on communication and networking aspects. Next, we cover various
UAV-based data collection methods their advantages and disadvantages, followed
by a discussion on performance metrics for data collection. As this article
primarily emphasizes reliable and efficient data collection in UAV-assisted IoT
networks, we briefly discuss existing research on data accuracy and
consistency, network connectivity, and data security and privacy to provide
insights into reliable data collection. Additionally, we discuss efficient data
collection strategies in UAV-based IoT networks, covering trajectory and path
planning, collision avoidance, sensor network clustering, data aggregation, UAV
swarm formations, and artificial intelligence for optimization. We also present
two use cases of UAVs as a service for enhancing data collection reliability
and efficiency. Finally, we discuss future challenges in data collection for
UAV-assisted IoT networks.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05304" title="Abstract">arXiv:2311.05304</a> [<a href="/pdf/2311.05304" title="Download PDF">pdf</a>, <a href="/format/2311.05304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Valuation and Detections in Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenqian Li</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+S">Shuran Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fengrui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+Y">Yan Pang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Federated Learning (FL) enables collaborative model training without sharing
raw data, demanding abundant, high-quality data for optimal model performance.
Fair and efficient data evaluation is a fundamental issue for incentivizing
clients to provide more high-quality data. Meanwhile, it is likely that only a
subset of clients and datasets are relevant for a learning task while the rest
of them may have a negative impact on the model training. This paper introduces
a novel privacy-preserving method for evaluating client contributions and
selecting relevant data samples without a pre-specified training algorithm. Our
proposed approach, FedBary, utilizes Wasserstein distance within the federated
context, offering a new pioneering solution for data valuation, which provides
transparent data evaluation and efficient computation of Wasserstein barycenter
to mitigate reliance on validation data. We conduct extensive empirical
experiments and theoretical analysis, showing the promising research of this
valuation metric.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05310" title="Abstract">arXiv:2311.05310</a> [<a href="/pdf/2311.05310" title="Download PDF">pdf</a>, <a href="/format/2311.05310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPADES: A Realistic Spacecraft Pose Estimation Dataset using Event  Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rathinam%2C+A">Arunkumar Rathinam</a>, 
<a href="/search/cs?searchtype=author&query=Qadadri%2C+H">Haytam Qadadri</a>, 
<a href="/search/cs?searchtype=author&query=Aouada%2C+D">Djamila Aouada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages and 8 Figures. This work has been submitted to the IEEE (ICRA 2024) for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent years, there has been a growing demand for improved autonomy for
in-orbit operations such as rendezvous, docking, and proximity maneuvers,
leading to increased interest in employing Deep Learning-based Spacecraft Pose
Estimation techniques. However, due to limited access to real target datasets,
algorithms are often trained using synthetic data and applied in the real
domain, resulting in a performance drop due to the domain gap. State-of-the-art
approaches employ Domain Adaptation techniques to mitigate this issue. In the
search for viable solutions, event sensing has been explored in the past and
shown to reduce the domain gap between simulations and real-world scenarios.
Event sensors have made significant advancements in hardware and software in
recent years. Moreover, the characteristics of the event sensor offer several
advantages in space applications compared to RGB sensors. To facilitate further
training and evaluation of DL-based models, we introduce a novel dataset,
SPADES, comprising real event data acquired in a controlled laboratory
environment and simulated event data using the same camera intrinsics.
Furthermore, we propose an effective data filtering method to improve the
quality of training data, thus enhancing model performance. Additionally, we
introduce an image-based event representation that outperforms existing
representations. A multifaceted baseline evaluation was conducted using
different event representations, event filtering strategies, and algorithmic
frameworks, and the results are summarized. The dataset will be made available
at <a href="http://cvi2.uni.lu/spades.">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05316" title="Abstract">arXiv:2311.05316</a> [<a href="/pdf/2311.05316" title="Download PDF">pdf</a>, <a href="/format/2311.05316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ABIGX: A Unified Framework for eXplainable Fault Detection and  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhuo%2C+Y">Yue Zhuo</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+J">Jinchuan Qian</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhihuan Song</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Z">Zhiqiang Ge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">For explainable fault detection and classification (FDC), this paper proposes
a unified framework, ABIGX (Adversarial fault reconstruction-Based Integrated
Gradient eXplanation). ABIGX is derived from the essentials of previous
successful fault diagnosis methods, contribution plots (CP) and
reconstruction-based contribution (RBC). It is the first explanation framework
that provides variable contributions for the general FDC models. The core part
of ABIGX is the adversarial fault reconstruction (AFR) method, which rethinks
the FR from the perspective of adversarial attack and generalizes to fault
classification models with a new fault index. For fault classification, we put
forward a new problem of fault class smearing, which intrinsically hinders the
correct explanation. We prove that ABIGX effectively mitigates this problem and
outperforms the existing gradient-based explanation methods. For fault
detection, we theoretically bridge ABIGX with conventional fault diagnosis
methods by proving that CP and RBC are the linear specifications of ABIGX. The
experiments evaluate the explanations of FDC by quantitative metrics and
intuitive illustrations, the results of which show the general superiority of
ABIGX to other advanced explanation methods.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05317" title="Abstract">arXiv:2311.05317</a> [<a href="/pdf/2311.05317" title="Download PDF">pdf</a>, <a href="/format/2311.05317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RepQ: Generalizing Quantization-Aware Training for Re-Parametrized  Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prutianova%2C+A">Anastasiia Prutianova</a>, 
<a href="/search/cs?searchtype=author&query=Zaytsev%2C+A">Alexey Zaytsev</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Chung-Kuei Lee</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+F">Fengyu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Koryakovskiy%2C+I">Ivan Koryakovskiy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> BMVC 2023 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Existing neural networks are memory-consuming and computationally intensive,
making deploying them challenging in resource-constrained environments.
However, there are various methods to improve their efficiency. Two such
methods are quantization, a well-known approach for network compression, and
re-parametrization, an emerging technique designed to improve model
performance. Although both techniques have been studied individually, there has
been limited research on their simultaneous application. To address this gap,
we propose a novel approach called RepQ, which applies quantization to
re-parametrized networks. Our method is based on the insight that the test
stage weights of an arbitrary re-parametrized layer can be presented as a
differentiable function of trainable parameters. We enable quantization-aware
training by applying quantization on top of this function. RepQ generalizes
well to various re-parametrized models and outperforms the baseline method LSQ
quantization scheme in all experiments.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05319" title="Abstract">arXiv:2311.05319</a> [<a href="/pdf/2311.05319" title="Download PDF">pdf</a>, <a href="/format/2311.05319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TLCFuse: Temporal Multi-Modality Fusion Towards Occlusion-Aware Semantic  Segmentation-Aided Motion Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salazar-Gomez%2C+G">Gustavo Salazar-Gomez</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenqian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Diaz-Zapata%2C+M">Manuel Diaz-Zapata</a>, 
<a href="/search/cs?searchtype=author&query=Sierra-Gonzalez%2C+D">David Sierra-Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Laugier%2C+C">Christian Laugier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In autonomous driving, addressing occlusion scenarios is crucial yet
challenging. Robust surrounding perception is essential for handling occlusions
and aiding motion planning. State-of-the-art models fuse Lidar and Camera data
to produce impressive perception results, but detecting occluded objects
remains challenging. In this paper, we emphasize the crucial role of temporal
cues by integrating them alongside these modalities to address this challenge.
We propose a novel approach for bird's eye view semantic grid segmentation,
that leverages sequential sensor data to achieve robustness against occlusions.
Our model extracts information from the sensor readings using attention
operations and aggregates this information into a lower-dimensional latent
representation, enabling thus the processing of multi-step inputs at each
prediction step. Moreover, we show how it can also be directly applied to
forecast the development of traffic scenes and be seamlessly integrated into a
motion planner for trajectory planning. On the semantic segmentation tasks, we
evaluate our model on the nuScenes dataset and show that it outperforms other
baselines, with particularly large differences when evaluating on occluded and
partially-occluded vehicles. Additionally, on motion planning task we are among
the early teams to train and evaluate on nuPlan, a cutting-edge large-scale
dataset for motion planning.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05321" title="Abstract">arXiv:2311.05321</a> [<a href="/pdf/2311.05321" title="Download PDF">pdf</a>, <a href="/format/2311.05321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finite Element Analysis of the Oseen eigenvalue problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lepe%2C+F">Felipe Lepe</a>, 
<a href="/search/math?searchtype=author&query=Rivera%2C+G">Gonzalo Rivera</a>, 
<a href="/search/math?searchtype=author&query=Vellojin%2C+J">Jesus Vellojin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We propose and analyze a finite element method for the Oseen eigenvalue
problem. This problem is an extension of the Stokes eigenvalue problem, where
the presence of the convective term leads to a non-symmetric problem and hence,
to complex eigenvalues and eigenfunctions. With the aid of the compact
operators theory, we prove that for inf-sup stable finite elements the
convergence holds and hence, error estimates for the eigenvalues and
eigenfunctions are derived. We also propose an a posteriori error estimator
which results to be reliable and efficient. We report a series of numerical
tests in two and three dimension in order to assess the performance of the
method and the proposed estimator.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05322" title="Abstract">arXiv:2311.05322</a> [<a href="/pdf/2311.05322" title="Download PDF">pdf</a>, <a href="/format/2311.05322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical Modeling for Shoulder Injury Detection Using Microwave Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Borzooei%2C+S">Sahar Borzooei</a>, 
<a href="/search/math?searchtype=author&query=Tournier%2C+P">Pierre-Henri Tournier</a>, 
<a href="/search/math?searchtype=author&query=Dolean%2C+V">Victorita Dolean</a>, 
<a href="/search/math?searchtype=author&query=Pichot%2C+C">Christian Pichot</a>, 
<a href="/search/math?searchtype=author&query=Joachimowicz%2C+N">Nadine Joachimowicz</a>, 
<a href="/search/math?searchtype=author&query=Roussel%2C+H">Helene Roussel</a>, 
<a href="/search/math?searchtype=author&query=Migliaccio%2C+C">Claire Migliaccio</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">A portable imaging system for the on-site detection of shoulder injury is
necessary to identify its extent and avoid its development to severe condition.
Here, firstly a microwave tomography system is introduced using
state-of-the-art numerical modeling and parallel computing for imaging
different tissues in the shoulder. The results show that the proposed method is
capable of accurately detecting and localizing rotator cuff tears of different
size. In the next step, an efficient design in terms of computing time and
complexity is proposed to detect the variations in the injured model with
respect to the healthy model. The method is based on finite element
discretization and uses parallel preconditioners from the domain decomposition
method to accelerate computations. It is implemented using the open source
FreeFEM software.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05323" title="Abstract">arXiv:2311.05323</a> [<a href="/pdf/2311.05323" title="Download PDF">pdf</a>, <a href="/format/2311.05323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial Attention-based Distribution Integration Network for Human Pose  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Sihan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jing Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+X">Xiaoxuan Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaoyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qijin Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In recent years, human pose estimation has made significant progress through
the implementation of deep learning techniques. However, these techniques still
face limitations when confronted with challenging scenarios, including
occlusion, diverse appearances, variations in illumination, and overlap. To
cope with such drawbacks, we present the Spatial Attention-based Distribution
Integration Network (SADI-NET) to improve the accuracy of localization in such
situations. Our network consists of three efficient models: the receptive
fortified module (RFM), spatial fusion module (SFM), and distribution learning
module (DLM). Building upon the classic HourglassNet architecture, we replace
the basic block with our proposed RFM. The RFM incorporates a dilated residual
block and attention mechanism to expand receptive fields while enhancing
sensitivity to spatial information. In addition, the SFM incorporates
multi-scale characteristics by employing both global and local attention
mechanisms. Furthermore, the DLM, inspired by residual log-likelihood
estimation (RLE), reconfigures a predicted heatmap using a trainable
distribution weight. For the purpose of determining the efficacy of our model,
we conducted extensive experiments on the MPII and LSP benchmarks.
Particularly, our model obtained a remarkable $92.10\%$ percent accuracy on the
MPII test dataset, demonstrating significant improvements over existing models
and establishing state-of-the-art performance.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05332" title="Abstract">arXiv:2311.05332</a> [<a href="/pdf/2311.05332" title="Download PDF">pdf</a>, <a href="/format/2311.05332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Road with GPT-4V(ision): Early Explorations of Visual-Language  Model on Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+L">Licheng Wen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xuemeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+D">Daocheng Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaofeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+P">Pinlong Cai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+T">Tao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yingxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Linran Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+D">Dengke Shang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shaoyan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yeqi Bai</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xinyu Cai</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+M">Min Dou</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shuanglu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Botian Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Robotics (cs.RO)

</div>
<p class="mathjax">The pursuit of autonomous driving technology hinges on the sophisticated
integration of perception, decision-making, and control systems. Traditional
approaches, both data-driven and rule-based, have been hindered by their
inability to grasp the nuance of complex driving environments and the
intentions of other road users. This has been a significant bottleneck,
particularly in the development of common sense reasoning and nuanced scene
understanding necessary for safe and reliable autonomous driving. The advent of
Visual Language Models (VLM) represents a novel frontier in realizing fully
autonomous vehicle driving. This report provides an exhaustive evaluation of
the latest state-of-the-art VLM, \modelnamefull, and its application in
autonomous driving scenarios. We explore the model's abilities to understand
and reason about driving scenes, make decisions, and ultimately act in the
capacity of a driver. Our comprehensive tests span from basic scene recognition
to complex causal reasoning and real-time decision-making under varying
conditions. Our findings reveal that \modelname demonstrates superior
performance in scene understanding and causal reasoning compared to existing
autonomous systems. It showcases the potential to handle out-of-distribution
scenarios, recognize intentions, and make informed decisions in real driving
contexts. However, challenges remain, particularly in direction discernment,
traffic light recognition, vision grounding, and spatial reasoning tasks. These
limitations underscore the need for further research and development. Project
is now available on GitHub for interested parties to access and utilize:
\url{https://github.com/PJLab-ADG/GPT4V-AD-Exploration}
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05334" title="Abstract">arXiv:2311.05334</a> [<a href="/pdf/2311.05334" title="Download PDF">pdf</a>, <a href="/format/2311.05334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-time Addressee Estimation: Deployment of a Deep-Learning Model on  the iCub Robot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mazzola%2C+C">Carlo Mazzola</a>, 
<a href="/search/cs?searchtype=author&query=Rea%2C+F">Francesco Rea</a>, 
<a href="/search/cs?searchtype=author&query=Sciutti%2C+A">Alessandra Sciutti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 3 figures, paper presented at IRIM-3D 2023 Conference, Funded by the Horizon-Widera-2021 European Twinning project TERAIS: G.A. n. 101079338
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Addressee Estimation is the ability to understand to whom a person is
talking, a skill essential for social robots to interact smoothly with humans.
In this sense, it is one of the problems that must be tackled to develop
effective conversational agents in multi-party and unstructured scenarios. As
humans, one of the channels that mainly lead us to such estimation is the
non-verbal behavior of speakers: first of all, their gaze and body pose.
Inspired by human perceptual skills, in the present work, a deep-learning model
for Addressee Estimation relying on these two non-verbal features is designed,
trained, and deployed on an iCub robot. The study presents the procedure of
such implementation and the performance of the model deployed in real-time
human-robot interaction compared to previous tests on the dataset used for the
training.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05336" title="Abstract">arXiv:2311.05336</a> [<a href="/pdf/2311.05336" title="Download PDF">pdf</a>, <a href="/format/2311.05336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SynFacePAD 2023: Competition on Face Presentation Attack Detection Based  on Privacy-aware Synthetic Training Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+M">Meiling Fang</a>, 
<a href="/search/cs?searchtype=author&query=Huber%2C+M">Marco Huber</a>, 
<a href="/search/cs?searchtype=author&query=Fierrez%2C+J">Julian Fierrez</a>, 
<a href="/search/cs?searchtype=author&query=Ramachandra%2C+R">Raghavendra Ramachandra</a>, 
<a href="/search/cs?searchtype=author&query=Damer%2C+N">Naser Damer</a>, 
<a href="/search/cs?searchtype=author&query=Alkhaddour%2C+A">Alhasan Alkhaddour</a>, 
<a href="/search/cs?searchtype=author&query=Kasantcev%2C+M">Maksim Kasantcev</a>, 
<a href="/search/cs?searchtype=author&query=Pryadchenko%2C+V">Vasiliy Pryadchenko</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Ziyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huangfu%2C+H">Huijie Huangfu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yingyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yuchen Pan</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Junjun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xianming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xianyun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Caiyong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xingyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+Z">Zhaohua Chang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+G">Guangzhe Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Tapia%2C+J">Juan Tapia</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez-Soler%2C+L">Lazaro Gonzalez-Soler</a>, 
<a href="/search/cs?searchtype=author&query=Aravena%2C+C">Carlos Aravena</a>, 
<a href="/search/cs?searchtype=author&query=Schulz%2C+D">Daniel Schulz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IJCB2 023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents a summary of the Competition on Face Presentation Attack
Detection Based on Privacy-aware Synthetic Training Data (SynFacePAD 2023) held
at the 2023 International Joint Conference on Biometrics (IJCB 2023). The
competition attracted a total of 8 participating teams with valid submissions
from academia and industry. The competition aimed to motivate and attract
solutions that target detecting face presentation attacks while considering
synthetic-based training data motivated by privacy, legal and ethical concerns
associated with personal data. To achieve that, the training data used by the
participants was limited to synthetic data provided by the organizers. The
submitted solutions presented innovations and novel approaches that led to
outperforming the considered baseline in the investigated benchmarks.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05337" title="Abstract">arXiv:2311.05337</a> [<a href="/pdf/2311.05337" title="Download PDF">pdf</a>, <a href="/format/2311.05337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Atom: Neural Traffic Compression with Spatio-Temporal Graph Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Almasan%2C+P">Paul Almasan</a>, 
<a href="/search/cs?searchtype=author&query=Rusek%2C+K">Krzysztof Rusek</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+S">Shihan Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xiang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xiangle Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Cabellos-Aparicio%2C+A">Albert Cabellos-Aparicio</a>, 
<a href="/search/cs?searchtype=author&query=Barlet-Ros%2C+P">Pere Barlet-Ros</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures, 2nd International Workshop on Graph Neural Networking (GNNet '23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Storing network traffic data is key to efficient network management; however,
it is becoming more challenging and costly due to the ever-increasing data
transmission rates, traffic volumes, and connected devices. In this paper, we
explore the use of neural architectures for network traffic compression.
Specifically, we consider a network scenario with multiple measurement points
in a network topology. Such measurements can be interpreted as multiple time
series that exhibit spatial and temporal correlations induced by network
topology, routing, or user behavior. We present \textit{Atom}, a neural traffic
compression method that leverages spatial and temporal correlations present in
network traffic. \textit{Atom} implements a customized spatio-temporal graph
neural network design that effectively exploits both types of correlations
simultaneously. The experimental results show that \textit{Atom} can outperform
GZIP's compression ratios by 50\%-65\% on three real-world networks.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05344" title="Abstract">arXiv:2311.05344</a> [<a href="/pdf/2311.05344" title="Download PDF">pdf</a>, <a href="/format/2311.05344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visually Guided Model Predictive Robot Control via 6D Object Pose  Localization and Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fourmy%2C+M">Mederic Fourmy</a>, 
<a href="/search/cs?searchtype=author&query=Priban%2C+V">Vojtech Priban</a>, 
<a href="/search/cs?searchtype=author&query=Behrens%2C+J+K">Jan Kristof Behrens</a>, 
<a href="/search/cs?searchtype=author&query=Mansard%2C+N">Nicolas Mansard</a>, 
<a href="/search/cs?searchtype=author&query=Sivic%2C+J">Josef Sivic</a>, 
<a href="/search/cs?searchtype=author&query=Petrik%2C+V">Vladimir Petrik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The objective of this work is to enable manipulation tasks with respect to
the 6D pose of a dynamically moving object using a camera mounted on a robot.
Examples include maintaining a constant relative 6D pose of the robot arm with
respect to the object, grasping the dynamically moving object, or
co-manipulating the object together with a human. Fast and accurate 6D pose
estimation is crucial to achieve smooth and stable robot control in such
situations. The contributions of this work are three fold. First, we propose a
new visual perception module that asynchronously combines accurate
learning-based 6D object pose localizer and a high-rate model-based 6D pose
tracker. The outcome is a low-latency accurate and temporally consistent 6D
object pose estimation from the input video stream at up to 120 Hz. Second, we
develop a visually guided robot arm controller that combines the new visual
perception module with a torque-based model predictive control algorithm.
Asynchronous combination of the visual and robot proprioception signals at
their corresponding frequencies results in stable and robust 6D object pose
guided robot arm control. Third, we experimentally validate the proposed
approach on a challenging 6D pose estimation benchmark and demonstrate 6D
object pose-guided control with dynamically moving objects on a real 7 DoF
Franka Emika Panda robot.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05346" title="Abstract">arXiv:2311.05346</a> [<a href="/pdf/2311.05346" title="Download PDF">pdf</a>, <a href="/format/2311.05346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerated Shapley Value Approximation for Data Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Watson%2C+L">Lauren Watson</a>, 
<a href="/search/cs?searchtype=author&query=Kujawa%2C+Z">Zeno Kujawa</a>, 
<a href="/search/cs?searchtype=author&query=Andreeva%2C+R">Rayna Andreeva</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hao-Tsung Yang</a>, 
<a href="/search/cs?searchtype=author&query=Elahi%2C+T">Tariq Elahi</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+R">Rik Sarkar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Data valuation has found various applications in machine learning, such as
data filtering, efficient learning and incentives for data sharing. The most
popular current approach to data valuation is the Shapley value. While popular
for its various applications, Shapley value is computationally expensive even
to approximate, as it requires repeated iterations of training models on
different subsets of data. In this paper we show that the Shapley value of data
points can be approximated more efficiently by leveraging the structural
properties of machine learning problems. We derive convergence guarantees on
the accuracy of the approximate Shapley value for different learning settings
including Stochastic Gradient Descent with convex and non-convex loss
functions. Our analysis suggests that in fact models trained on small subsets
are more important in the context of data valuation. Based on this idea, we
describe $\delta$-Shapley -- a strategy of only using small subsets for the
approximation. Experiments show that this approach preserves approximate value
and rank of data, while achieving speedup of up to 9.9x. In pre-trained
networks the approach is found to bring more efficiency in terms of accurate
evaluation using small subsets.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05348" title="Abstract">arXiv:2311.05348</a> [<a href="/pdf/2311.05348" title="Download PDF">pdf</a>, <a href="/format/2311.05348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> u-LLaVA: Unifying Multi-Modal Tasks via Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jinjin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Liwu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuzhe Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yanchun Xie</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yi-Jie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yaqian Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advances such as LLaVA and Mini-GPT4 have successfully integrated
visual information into LLMs, yielding inspiring outcomes and giving rise to a
new generation of multi-modal LLMs, or MLLMs. Nevertheless, these methods
struggle with hallucinations and the mutual interference between tasks. To
tackle these problems, we propose an efficient and accurate approach to adapt
to downstream tasks by utilizing LLM as a bridge to connect multiple expert
models, namely u-LLaVA. Firstly, we incorporate the modality alignment module
and multi-task modules into LLM. Then, we reorganize or rebuild multi-type
public datasets to enable efficient modality alignment and instruction
following. Finally, task-specific information is extracted from the trained LLM
and provided to different modules for solving downstream tasks. The overall
framework is simple, effective, and achieves state-of-the-art performance
across multiple benchmarks. We also release our model, the generated data, and
the code base publicly available.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05350" title="Abstract">arXiv:2311.05350</a> [<a href="/pdf/2311.05350" title="Download PDF">pdf</a>, <a href="/format/2311.05350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> There&#x27;s no Data Like Better Data: Using QE Metrics for MT Data Filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peter%2C+J">Jan-Thorsten Peter</a>, 
<a href="/search/cs?searchtype=author&query=Vilar%2C+D">David Vilar</a>, 
<a href="/search/cs?searchtype=author&query=Deutsch%2C+D">Daniel Deutsch</a>, 
<a href="/search/cs?searchtype=author&query=Finkelstein%2C+M">Mara Finkelstein</a>, 
<a href="/search/cs?searchtype=author&query=Juraska%2C+J">Juraj Juraska</a>, 
<a href="/search/cs?searchtype=author&query=Freitag%2C+M">Markus Freitag</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to be published at WMT23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Quality Estimation (QE), the evaluation of machine translation output without
the need of explicit references, has seen big improvements in the last years
with the use of neural metrics. In this paper we analyze the viability of using
QE metrics for filtering out bad quality sentence pairs in the training data of
neural machine translation systems~(NMT). While most corpus filtering methods
are focused on detecting noisy examples in collections of texts, usually huge
amounts of web crawled data, QE models are trained to discriminate more
fine-grained quality differences. We show that by selecting the highest quality
sentence pairs in the training data, we can improve translation quality while
reducing the training size by half. We also provide a detailed analysis of the
filtering results, which highlights the differences between both approaches.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05360" title="Abstract">arXiv:2311.05360</a> [<a href="/pdf/2311.05360" title="Download PDF">pdf</a>, <a href="/ps/2311.05360" title="Download PostScript">ps</a>, <a href="/format/2311.05360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Basis functions nonlinear data-enabled predictive control: Consistent  and computationally efficient formulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lazar%2C+M">Mircea Lazar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper considers the extension of data-enabled predictive control (DeePC)
to nonlinear systems via general basis functions. Firstly, we formulate a basis
functions DeePC behavioral predictor and we identify necessary and sufficient
conditions for equivalence with a corresponding basis functions multi-step
identified predictor. The derived conditions yield a dynamic regularization
cost function that enables a well-posed (i.e., consistent) basis functions
formulation of nonlinear DeePC. To optimize computational efficiency of basis
functions DeePC we further develop two alternative formulations that use a
simpler, sparse regularization cost function and ridge regression,
respectively. Consistency implications for Koopman DeePC as well as several
methods for constructing the basis functions representation are also indicated.
The effectiveness of the developed consistent basis functions DeePC
formulations is illustrated on a benchmark nonlinear pendulum state-space
model, for both noise free and noisy data.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05362" title="Abstract">arXiv:2311.05362</a> [<a href="/pdf/2311.05362" title="Download PDF">pdf</a>, <a href="/format/2311.05362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling and Control of Intrinsically Elasticity Coupled Soft-Rigid  Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patterson%2C+Z+J">Zach J. Patterson</a>, 
<a href="/search/cs?searchtype=author&query=Della+Santina%2C+C">Cosimo Della Santina</a>, 
<a href="/search/cs?searchtype=author&query=Rus%2C+D">Daniela Rus</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">While much work has been done recently in the realm of model-based control of
soft robots and soft-rigid hybrids, most works examine robots that have an
inherently serial structure. While these systems have been prevalent in the
literature, there is an increasing trend toward designing soft-rigid hybrids
with intrinsically coupled elasticity between various degrees of freedom. In
this work, we seek to address the issues of modeling and controlling such
structures, particularly when underactuated. We introduce several simple models
for elastic coupling, typical of those seen in these systems. We then propose a
controller that compensates for the elasticity, and we prove its stability with
Lyapunov methods without relying on the elastic dominance assumption. This
controller is applicable to the general class of underactuated soft robots.
After evaluating the controller in simulated cases, we then develop a simple
hardware platform to evaluate both the models and the controller. Finally,
using the hardware, we demonstrate a novel use case for underactuated,
elastically coupled systems in "sensorless" force control.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05363" title="Abstract">arXiv:2311.05363</a> [<a href="/pdf/2311.05363" title="Download PDF">pdf</a>, <a href="/format/2311.05363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond the training set: an intuitive method for detecting distribution  shift in model-based optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Damani%2C+F">Farhan Damani</a>, 
<a href="/search/cs?searchtype=author&query=Brookes%2C+D+H">David H Brookes</a>, 
<a href="/search/cs?searchtype=author&query=Sternlieb%2C+T">Theodore Sternlieb</a>, 
<a href="/search/cs?searchtype=author&query=Webster%2C+C">Cameron Webster</a>, 
<a href="/search/cs?searchtype=author&query=Malina%2C+S">Stephen Malina</a>, 
<a href="/search/cs?searchtype=author&query=Jajoo%2C+R">Rishi Jajoo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+K">Kathy Lin</a>, 
<a href="/search/cs?searchtype=author&query=Sinai%2C+S">Sam Sinai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Model-based optimization (MBO) is increasingly applied to design problems in
science and engineering. A common scenario involves using a fixed training set
to train models, with the goal of designing new samples that outperform those
present in the training data. A major challenge in this setting is distribution
shift, where the distributions of training and design samples are different.
While some shift is expected, as the goal is to create better designs, this
change can negatively affect model accuracy and subsequently, design quality.
Despite the widespread nature of this problem, addressing it demands deep
domain knowledge and artful application. To tackle this issue, we propose a
straightforward method for design practitioners that detects distribution
shifts. This method trains a binary classifier using knowledge of the unlabeled
design distribution to separate the training data from the design data. The
classifier's logit scores are then used as a proxy measure of distribution
shift. We validate our method in a real-world application by running offline
MBO and evaluate the effect of distribution shift on design quality. We find
that the intensity of the shift in the design distribution varies based on the
number of steps taken by the optimization algorithm, and our simple approach
can identify these shifts. This enables users to constrain their search to
regions where the model's predictions are reliable, thereby increasing the
quality of designs.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05367" title="Abstract">arXiv:2311.05367</a> [<a href="/pdf/2311.05367" title="Download PDF">pdf</a>, <a href="/format/2311.05367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reducing Disorder: An Information-Theory Formulation of MEV
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hughes%2C+C">Ciaran Hughes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Maximal Extractable Value (MEV) has garnered significant attention in the
cryptocurrency community. Such attention is a consequence of the revenue that
can be generated from MEV, as well as the risks MEV poses to the fundamental
value proposition of the underlying blockchain technology. In this work, we
provide an information-theoretic formulation of MEV. With this formulation, we
make common statements about MEV mathematically rigorous. For example, we show
that i) all non-trivial blockchains and decentralised applications must
generate MEV; ii) how MEV can be reduced at the expense of user expressibility;
and iii) how MEV can be good or bad from an information theoretic standpoint.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05368" title="Abstract">arXiv:2311.05368</a> [<a href="/pdf/2311.05368" title="Download PDF">pdf</a>, <a href="/format/2311.05368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probable Approximate Coordination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Livshits%2C+A">Ariel Livshits</a>, 
<a href="/search/cs?searchtype=author&query=Moses%2C+Y">Yoram Moses</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper is 20 pages long and contains 3 figures. It is to be published in the 2023 Conference on Principles of Distributed Systems (OPODIS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">We study the problem of how to coordinate the actions of independent agents
in a distributed system where message arrival times are unbounded, but are
determined by an exponential probability distribution. Asynchronous protocols
executed in such a model are guaranteed to succeed with probability 1. We
demonstrate a case in which the best asynchronous protocol can be improved on
significantly. Specifically, we focus on the task of performing actions by
different agents in a linear temporal order -- a problem known in the
literature as Ordered Response. In asynchronous systems, ensuring such an
ordering requires the construction of a message chain that passes through each
acting agent, in order. Solving Ordered Response in this way in our model will
terminate in time that grows linearly in the number of participating agents
$n$, in expectation. We show that relaxing the specification slightly allows
for a significant saving in time. Namely, if Ordered Response should be
guaranteed with high probability (arbitrarily close to 1), it is possible to
significantly shorten the expected execution time of the protocol. We present
two protocols that adhere to the relaxed specification. One of our protocols
executes exponentially faster than a message chain, when the number of
participating agents $n$ is large, while the other is roughly quadratically
faster. For small values of $n$, it is also possible to achieve similar results
by using a hybrid protocol.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05371" title="Abstract">arXiv:2311.05371</a> [<a href="/pdf/2311.05371" title="Download PDF">pdf</a>, <a href="/format/2311.05371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training Robust Deep Physiological Measurement Models with Synthetic  Video-based Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ou%2C+Y">Yuxuan Ou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuzhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuntang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+S">Shwetak Patel</a>, 
<a href="/search/cs?searchtype=author&query=McDuf%2C+D">Daniel McDuf</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent advances in supervised deep learning techniques have demonstrated the
possibility to remotely measure human physiological vital signs (e.g.,
photoplethysmograph, heart rate) just from facial videos. However, the
performance of these methods heavily relies on the availability and diversity
of real labeled data. Yet, collecting large-scale real-world data with
high-quality labels is typically challenging and resource intensive, which also
raises privacy concerns when storing personal bio-metric data. Synthetic
video-based datasets (e.g., SCAMPS~\cite{mcduff2022scamps}) with
photo-realistic synthesized avatars are introduced to alleviate the issues
while providing high-quality synthetic data. However, there exists a
significant gap between synthetic and real-world data, which hinders the
generalization of neural models trained on these synthetic datasets. In this
paper, we proposed several measures to add real-world noise to synthetic
physiological signals and corresponding facial videos. We experimented with
individual and combined augmentation methods and evaluated our framework on
three public real-world datasets. Our results show that we were able to reduce
the average MAE from 6.9 to 2.0.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05372" title="Abstract">arXiv:2311.05372</a> [<a href="/pdf/2311.05372" title="Download PDF">pdf</a>, <a href="/format/2311.05372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Angle and Delay Cram&#xe9;r-Rao Bound Optimization for Integrated  Sensing and Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+L">Ling Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been submitted to IEEE TVT
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we study a multi-input multi-output (MIMO) beamforming design
in an integrated sensing and communication (ISAC) system, in which an ISAC base
station (BS) is used to communicate with multiple downlink users and
simultaneously the communication signals are reused for sensing multiple
targets. Our interested sensing parameters are the angle and delay information
of the targets, which can be used to locate these targets. Under this
consideration, we first derive the Cram\'{e}r-Rao bound (CRB) for angle and
delay estimation. Then, we optimize the transmit beamforming at the BS to
minimize the CRB, subject to communication rate and power constraints. In
particular, we obtain the optimal solution in closed-form in the case of
single-target and single-user, and in the case of multi-target and multi-user
scenario, the sparsity of the optimal solution is proven, leading to a
reduction in computational complexity during optimization. The numerical
results demonstrate that the optimized beamforming yields excellent positioning
performance and effectively reduces the requirement for a large number of
antennas at the BS.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05373" title="Abstract">arXiv:2311.05373</a> [<a href="/pdf/2311.05373" title="Download PDF">pdf</a>, <a href="/ps/2311.05373" title="Download PostScript">ps</a>, <a href="/format/2311.05373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What is prompt literacy? An exploratory study of language learners&#x27;  development of new literacy skill using generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hwang%2C+Y">Yohan Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+H">Jang Ho Lee</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+D">Dongkwang Shin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">In the current study,we propose that, in the era of generative AI, there is
now a new form of literacy called "prompt literacy," which refers to the
ability to generate precise prompts as input for AI systems, interpret the
outputs, and iteratively refine prompts to achieve desired results. To explore
the emergence and development of this literacy skill, the current study
examined 30 EFL students' engagement in an AI-powered image creation project,
through which they created artworks representing the socio-cultural meanings of
English words by iteratively drafting and refining prompts in generative AI
tools. By examining AI-generated images and the participants' drafting and
revision of their prompts, this study demonstrated the emergence of learners'
prompt literacy skills. The survey data further showed the participants'
perceived improvement in their vocabulary learning strategies as a result of
engaging in the target AI-powered project. In addition, the participants'
post-project reflection revealed three benefits of developing prompt literacy:
enjoyment from manifesting imagined outcomes; recognition of its importance for
communication, problem-solving and career development; and the enhanced
understanding of the collaborative nature of human-AI interaction. These
findings suggest that prompt literacy is an increasingly crucial literacy for
the AI era.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05374" title="Abstract">arXiv:2311.05374</a> [<a href="/pdf/2311.05374" title="Download PDF">pdf</a>, <a href="/format/2311.05374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TencentLLMEval: A Hierarchical Evaluation of Real-World Capabilities for  Human-Aligned LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Shuyi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+W">Wenlin Yao</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yong Dai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shaobo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Donlin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Lifeng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xinhua Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+P">Pengzhi Wei</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yujie Lin</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhichao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhengyou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+J">Jing Nie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuhong Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) have shown impressive capabilities across
various natural language tasks. However, evaluating their alignment with human
preferences remains a challenge. To this end, we propose a comprehensive human
evaluation framework to assess LLMs' proficiency in following instructions on
diverse real-world tasks. We construct a hierarchical task tree encompassing 7
major areas covering over 200 categories and over 800 tasks, which covers
diverse capabilities such as question answering, reasoning, multiturn dialogue,
and text generation, to evaluate LLMs in a comprehensive and in-depth manner.
We also design detailed evaluation standards and processes to facilitate
consistent, unbiased judgments from human evaluators. A test set of over 3,000
instances is released, spanning different difficulty levels and knowledge
domains. Our work provides a standardized methodology to evaluate human
alignment in LLMs for both English and Chinese. We also analyze the feasibility
of automating parts of evaluation with a strong LLM (GPT-4). Our framework
supports a thorough assessment of LLMs as they are integrated into real-world
applications. We have made publicly available the task tree, TencentLLMEval
dataset, and evaluation methodology which have been demonstrated as effective
in assessing the performance of Tencent Hunyuan LLMs. By doing so, we aim to
facilitate the benchmarking of advances in the development of safe and
human-aligned LLMs.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05379" title="Abstract">arXiv:2311.05379</a> [<a href="/pdf/2311.05379" title="Download PDF">pdf</a>, <a href="/format/2311.05379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memorisation Cartography: Mapping out the Memorisation-Generalisation  Continuum in Neural Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dankers%2C+V">Verna Dankers</a>, 
<a href="/search/cs?searchtype=author&query=Titov%2C+I">Ivan Titov</a>, 
<a href="/search/cs?searchtype=author&query=Hupkes%2C+D">Dieuwke Hupkes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in EMNLP 2023; 21 pages total (9 in the main paper, 3 pages with limitations, acknowledgments and references, 9 pages with appendices)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">When training a neural network, it will quickly memorise some source-target
mappings from your dataset but never learn some others. Yet, memorisation is
not easily expressed as a binary feature that is good or bad: individual
datapoints lie on a memorisation-generalisation continuum. What determines a
datapoint's position on that spectrum, and how does that spectrum influence
neural models' performance? We address these two questions for neural machine
translation (NMT) models. We use the counterfactual memorisation metric to (1)
build a resource that places 5M NMT datapoints on a memorisation-generalisation
map, (2) illustrate how the datapoints' surface-level characteristics and a
models' per-datum training signals are predictive of memorisation in NMT, (3)
and describe the influence that subsets of that map have on NMT systems'
performance.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05383" title="Abstract">arXiv:2311.05383</a> [<a href="/pdf/2311.05383" title="Download PDF">pdf</a>, <a href="/ps/2311.05383" title="Download PostScript">ps</a>, <a href="/format/2311.05383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Hand Recognition in Uncontrolled and Uncooperative  Environments using Multiple Spatial Transformers and Loss Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Matkowski%2C+W+M">Wojciech Michal Matkowski</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaojie Li</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+A+W+K">Adams Wai Kin Kong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The prevalence of smartphone and consumer camera has led to more evidence in
the form of digital images, which are mostly taken in uncontrolled and
uncooperative environments. In these images, criminals likely hide or cover
their faces while their hands are observable in some cases, creating a
challenging use case for forensic investigation. Many existing hand-based
recognition methods perform well for hand images collected in controlled
environments with user cooperation. However, their performance deteriorates
significantly in uncontrolled and uncooperative environments. A recent work has
exposed the potential of hand recognition in these environments. However, only
the palmar regions were considered, and the recognition performance is still
far from satisfactory. To improve the recognition accuracy, an algorithm
integrating a multi-spatial transformer network (MSTN) and multiple loss
functions is proposed to fully utilize information in full hand images. MSTN is
firstly employed to localize the palms and fingers and estimate the alignment
parameters. Then, the aligned images are further fed into pretrained
convolutional neural networks, where features are extracted. Finally, a
training scheme with multiple loss functions is used to train the network
end-to-end. To demonstrate the effectiveness of the proposed algorithm, the
trained model is evaluated on NTU-PI-v1 database and six benchmark databases
from different domains. Experimental results show that the proposed algorithm
performs significantly better than the existing methods in these uncontrolled
and uncooperative environments and has good generalization capabilities to
samples from different domains.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05395" title="Abstract">arXiv:2311.05395</a> [<a href="/pdf/2311.05395" title="Download PDF">pdf</a>, <a href="/format/2311.05395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An SBP-SAT Continuous Galerkin Finite Element Formulation for Smooth and  Discontinuous Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Malan%2C+A+G">Arnaud G. Malan</a>, 
<a href="/search/math?searchtype=author&query=Nordstrom%2C+J">Jan Nordstrom</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The high-order accurate continuous Galerkin finite element method offers
attractive computational efficiency for computational fluid dynamics. A
challenge is however spurious oscillations which result for convection
dominated flows over discontinuities. To derive a continuous Galerkin scheme
for both smooth and discontinuous fields we start by first writing the scheme
in Summation-by-Parts (SBP) form for a single element mesh. Boundary conditions
are applied weakly via Simultaneous-Approximation-Terms (SAT) and Gauss-Labotto
quadrature employed in the interest of computational efficiency. We then show
that the stable single element baseline scheme in SBP-SAT form extends
trivially to a provably stable multi-element formulation. Next, we develop
provably stable element based Galerkin-weighted artificial dissipation
operators to deal with spurious oscillations over shocks while retaining high
order accuracy elsewhere. The resulting scheme achieves super-convergence with
accuracy of Order(p+2) when using p^th order Lagrange polynomials for smooth
fields. The developed dissipation operators furnish WENO like behaviour over
discontinuities while retaining high order accuracy elsewhere for both linear
and non-linear wave propagation problems.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05398" title="Abstract">arXiv:2311.05398</a> [<a href="/pdf/2311.05398" title="Download PDF">pdf</a>, <a href="/format/2311.05398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Sample Complexity Of ERMs In Stochastic Convex Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carmon%2C+D">Daniel Carmon</a>, 
<a href="/search/cs?searchtype=author&query=Livni%2C+R">Roi Livni</a>, 
<a href="/search/cs?searchtype=author&query=Yehudayoff%2C+A">Amir Yehudayoff</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Stochastic convex optimization is one of the most well-studied models for
learning in modern machine learning. Nevertheless, a central fundamental
question in this setup remained unresolved: "How many data points must be
observed so that any empirical risk minimizer (ERM) shows good performance on
the true population?" This question was proposed by Feldman (2016), who proved
that $\Omega(\frac{d}{\epsilon}+\frac{1}{\epsilon^2})$ data points are
necessary (where $d$ is the dimension and $\epsilon&gt;0$ is the accuracy
parameter). Proving an $\omega(\frac{d}{\epsilon}+\frac{1}{\epsilon^2})$ lower
bound was left as an open problem. In this work we show that in fact
$\tilde{O}(\frac{d}{\epsilon}+\frac{1}{\epsilon^2})$ data points are also
sufficient. This settles the question and yields a new separation between ERMs
and uniform convergence. This sample complexity holds for the classical setup
of learning bounded convex Lipschitz functions over the Euclidean unit ball. We
further generalize the result and show that a similar upper bound holds for all
symmetric convex bodies. The general bound is composed of two terms: (i) a term
of the form $\tilde{O}(\frac{d}{\epsilon})$ with an inverse-linear dependence
on the accuracy parameter, and (ii) a term that depends on the statistical
complexity of the class of $\textit{linear}$ functions (captured by the
Rademacher complexity). The proof builds a mechanism for controlling the
behavior of stochastic convex optimization problems.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05400" title="Abstract">arXiv:2311.05400</a> [<a href="/pdf/2311.05400" title="Download PDF">pdf</a>, <a href="/format/2311.05400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SIRE: scale-invariant, rotation-equivariant estimation of artery  orientations using graph neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alblas%2C+D">Dieuwertje Alblas</a>, 
<a href="/search/cs?searchtype=author&query=Suk%2C+J">Julian Suk</a>, 
<a href="/search/cs?searchtype=author&query=Brune%2C+C">Christoph Brune</a>, 
<a href="/search/cs?searchtype=author&query=Yeung%2C+K+K">Kak Khee Yeung</a>, 
<a href="/search/cs?searchtype=author&query=Wolterink%2C+J+M">Jelmer M. Wolterink</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Medical Image Analysis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Blood vessel orientation as visualized in 3D medical images is an important
descriptor of its geometry that can be used for centerline extraction and
subsequent segmentation and visualization. Arteries appear at many scales and
levels of tortuosity, and determining their exact orientation is challenging.
Recent works have used 3D convolutional neural networks (CNNs) for this
purpose, but CNNs are sensitive to varying vessel sizes and orientations. We
present SIRE: a scale-invariant, rotation-equivariant estimator for local
vessel orientation. SIRE is modular and can generalise due to symmetry
preservation.
<br />SIRE consists of a gauge equivariant mesh CNN (GEM-CNN) operating on multiple
nested spherical meshes with different sizes in parallel. The features on each
mesh are a projection of image intensities within the corresponding sphere.
These features are intrinsic to the sphere and, in combination with the
GEM-CNN, lead to SO(3)-equivariance. Approximate scale invariance is achieved
by weight sharing and use of a symmetric maximum function to combine
multi-scale predictions. Hence, SIRE can be trained with arbitrarily oriented
vessels with varying radii to generalise to vessels with a wide range of
calibres and tortuosity.
<br />We demonstrate the efficacy of SIRE using three datasets containing vessels
of varying scales: the vascular model repository (VMR), the ASOCA coronary
artery set, and a set of abdominal aortic aneurysms (AAAs). We embed SIRE in a
centerline tracker which accurately tracks AAAs, regardless of the data SIRE is
trained with. Moreover, SIRE can be used to track coronary arteries, even when
trained only with AAAs.
<br />In conclusion, by incorporating SO(3) and scale symmetries, SIRE can
determine the orientations of vessels outside of the training domain, forming a
robust and data-efficient solution to geometric analysis of blood vessels in 3D
medical images.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05401" title="Abstract">arXiv:2311.05401</a> [<a href="/pdf/2311.05401" title="Download PDF">pdf</a>, <a href="/ps/2311.05401" title="Download PostScript">ps</a>, <a href="/format/2311.05401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCRITA 2023: Trust, Acceptance and Social Cues in Human-Robot  Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rossi%2C+A">Alessandra Rossi</a>, 
<a href="/search/cs?searchtype=author&query=Holthaus%2C+P">Patrick Holthaus</a>, 
<a href="/search/cs?searchtype=author&query=Lakatos%2C+G">Gabriella Lakatos</a>, 
<a href="/search/cs?searchtype=author&query=Moros%2C+S">S&#xed;lvia Moros</a>, 
<a href="/search/cs?searchtype=author&query=Riches%2C+L">Lewis Riches</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SCRITA 2023 workshop proceedings including 9 articles
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This workshop focused on identifying the challenges and dynamics between
people and robots to foster short interactions and long-lasting relationships
in different fields, from educational, service, collaborative, companion,
care-home and medical robotics. For that, this workshop facilitated a
discussion about people's trust towards robots "in the field", inviting
workshop participants to contribute their past experiences and lessons learnt.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05402" title="Abstract">arXiv:2311.05402</a> [<a href="/pdf/2311.05402" title="Download PDF">pdf</a>, <a href="/ps/2311.05402" title="Download PostScript">ps</a>, <a href="/format/2311.05402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Risk-aware Scheduling and Dispatch of Flexibility Events in Buildings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Scharnhorst%2C+P">Paul Scharnhorst</a>, 
<a href="/search/eess?searchtype=author&query=Schubnel%2C+B">Baptiste Schubnel</a>, 
<a href="/search/eess?searchtype=author&query=Carrillo%2C+R+E">Rafael E. Carrillo</a>, 
<a href="/search/eess?searchtype=author&query=Alet%2C+P">Pierre-Jean Alet</a>, 
<a href="/search/eess?searchtype=author&query=Jones%2C+C+N">Colin N. Jones</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Transactions on Smart Grid
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Residential and commercial buildings, equipped with systems such as heat
pumps, hot water tanks, or stationary energy storage, have a large potential to
offer their consumption flexibility as grid services. In this work, we leverage
this flexibility to react to consumption requests related to maximizing
self-consumption and reducing peak loads. We present a general characterization
of consumption flexibility in the form of flexibility envelopes and discuss a
data-driven battery model formulation for modeling individual buildings. These
models are used to predict the available consumption flexibility while
incorporating a description of uncertainty and being risk-aware with a
pre-defined risk level. A Mixed-integer Linear Program (MILP) is formulated to
schedule the activation of the buildings in order to best respond to an
external consumption request. An aggregated consumption request is dispatched
to the active individual buildings by an algorithm, based on the previously
determined schedule. The effectiveness of the approach is demonstrated by
coordinating up to 500 simulated buildings using the Energym Python library and
observing about 1.5 times peak power reduction in comparison with a baseline
approach while maintaining comfort more robustly. We demonstrate the
scalability of the approach, with solving times being approximately linear in
the number of considered assets in the scheduling problem.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05404" title="Abstract">arXiv:2311.05404</a> [<a href="/pdf/2311.05404" title="Download PDF">pdf</a>, <a href="/ps/2311.05404" title="Download PostScript">ps</a>, <a href="/format/2311.05404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Privacy of Health Data Lifecycle: A Taxonomy, Review, and  Future Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bose%2C+S">Sunanda Bose</a>, 
<a href="/search/cs?searchtype=author&query=Marijan%2C+D">Dusica Marijan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">With the increasing breaches and security threats that endanger health data,
ensuring patients' privacy is essential. To that end, the research community
has proposed various privacy-preserving approaches based on cryptography,
hashing, or ledger technologies for alleviating health data vulnerability. To
establish a comprehensive understanding of health data privacy risks, and the
benefits and limitations of existing privacy-preserving approaches, we perform
a detailed review of existing work and distill 10 distinct privacy concerns
occurring in a health data lifecycle. Furthermore, we classify existing
approaches based on their applicability to particular privacy concerns
occurring at a particular lifecycle stage. Finally, we propose a taxonomy of
techniques used for privacy preservation in healthcare and triangulate those
techniques with the lifecycle stages and concerns. Our review indicates heavy
usage of cryptographical techniques in this domain. However, we have also found
that healthcare systems have special requirements that require novel
cryptographic techniques and security schemes to address special needs.
Therefore, we identify several future research directions to mitigate the
security challenges for privacy preservation in health data management.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05410" title="Abstract">arXiv:2311.05410</a> [<a href="/pdf/2311.05410" title="Download PDF">pdf</a>, <a href="/format/2311.05410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear Gaussian Bounding Box Representation and Ring-Shaped Rotated  Convolution for Oriented Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yunkai Ma</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Junfeng Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhaoyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+F">Fengshui Jing</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+M">Min Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Due to the frequent variability of object orientation, accurate prediction of
orientation information remains a challenge in oriented object detection. To
better extract orientation-related information, current methods primarily focus
on the design of reasonable representations of oriented bounding box (OBB) and
rotation-sensitive feature extraction. However, existing OBB representations
often suffer from boundary discontinuity and representation ambiguity problems.
Methods of designing continuous and unambiguous regression losses do not
essentially solve such problems. Gaussian bounding box (GBB) avoids these OBB
representation problems, but directly regressing GBB is susceptible to
numerical instability. In this paper, we propose linear GBB (LGBB), a novel OBB
representation. By linearly transforming the elements of GBB, LGBB does not
have the boundary discontinuity and representation ambiguity problems, and have
high numerical stability. On the other hand, current rotation-sensitive feature
extraction methods based on convolutions can only extract features under a
local receptive field, which is slow in aggregating rotation-sensitive
features. To address this issue, we propose ring-shaped rotated convolution
(RRC). By adaptively rotating feature maps to arbitrary orientations, RRC
extracts rotation-sensitive features under a ring-shaped receptive field,
rapidly aggregating rotation-sensitive features and contextual information. RRC
can be applied to various models in a plug-and-play manner. Experimental
results demonstrate that the proposed LGBB and RRC are effective and achieve
state-of-the-art (SOTA) performance. By integrating LGBB and RRC into various
models, the detection accuracy is effectively improved on DOTA and HRSC2016
datasets.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05417" title="Abstract">arXiv:2311.05417</a> [<a href="/pdf/2311.05417" title="Download PDF">pdf</a>, <a href="/format/2311.05417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting the Position Uncertainty at the Time of Closest Approach with  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guimar%C3%A3es%2C+M">Marta Guimar&#xe3;es</a>, 
<a href="/search/cs?searchtype=author&query=Soares%2C+C">Cl&#xe1;udia Soares</a>, 
<a href="/search/cs?searchtype=author&query=Manfletti%2C+C">Chiara Manfletti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">The risk of collision between resident space objects has significantly
increased in recent years. As a result, spacecraft collision avoidance
procedures have become an essential part of satellite operations. To ensure
safe and effective space activities, satellite owners and operators rely on
constantly updated estimates of encounters. These estimates include the
uncertainty associated with the position of each object at the expected TCA.
These estimates are crucial in planning risk mitigation measures, such as
collision avoidance manoeuvres. As the TCA approaches, the accuracy of these
estimates improves, as both objects' orbit determination and propagation
procedures are made for increasingly shorter time intervals. However, this
improvement comes at the cost of taking place close to the critical decision
moment. This means that safe avoidance manoeuvres might not be possible or
could incur significant costs. Therefore, knowing the evolution of this
variable in advance can be crucial for operators. This work proposes a machine
learning model based on diffusion models to forecast the position uncertainty
of objects involved in a close encounter, particularly for the secondary object
(usually debris), which tends to be more unpredictable. We compare the
performance of our model with other state-of-the-art solutions and a na\"ive
baseline approach, showing that the proposed solution has the potential to
significantly improve the safety and effectiveness of spacecraft operations.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05418" title="Abstract">arXiv:2311.05418</a> [<a href="/pdf/2311.05418" title="Download PDF">pdf</a>, <a href="/ps/2311.05418" title="Download PostScript">ps</a>, <a href="/format/2311.05418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalization in medical AI: a perspective on developing scalable  models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Behar%2C+J+A">Joachim A. Behar</a>, 
<a href="/search/cs?searchtype=author&query=Levy%2C+J">Jeremy Levy</a>, 
<a href="/search/cs?searchtype=author&query=Celi%2C+L+A">Leo Anthony Celi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Over the past few years, research has witnessed the advancement of deep
learning models trained on large datasets, some even encompassing millions of
examples. While these impressive performance on their hidden test sets, they
often underperform when assessed on external datasets. Recognizing the critical
role of generalization in medical AI development, many prestigious journals now
require reporting results both on the local hidden test set as well as on
external datasets before considering a study for publication. Effectively, the
field of medical AI has transitioned from the traditional usage of a single
dataset that is split into train and test to a more comprehensive framework
using multiple datasets, some of which are used for model development (source
domain) and others for testing (target domains). However, this new experimental
setting does not necessarily resolve the challenge of generalization. This is
because of the variability encountered in intended use and specificities across
hospital cultures making the idea of universally generalizable systems a myth.
On the other hand, the systematic, and a fortiori recurrent re-calibration, of
models at the individual hospital level, although ideal, may be overoptimistic
given the legal, regulatory and technical challenges that are involved.
Re-calibration using transfer learning may not even be possible in some
instances where reference labels of target domains are not available. In this
perspective we establish a hierarchical three-level scale system reflecting the
generalization level of a medical AI algorithm. This scale better reflects the
diversity of real-world medical scenarios per which target domain data for
re-calibration of models may or not be available and if it is, may or not have
reference labels systematically available.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05419" title="Abstract">arXiv:2311.05419</a> [<a href="/pdf/2311.05419" title="Download PDF">pdf</a>, <a href="/format/2311.05419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mirror: A Universal Framework for Various Information Extraction Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+T">Tong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Junfei Ren</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zijian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Mengsong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guoliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+X">Xiaoye Qu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenliang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhefeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huai%2C+B">Baoxing Huai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP23 main conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Sharing knowledge between information extraction tasks has always been a
challenge due to the diverse data formats and task variations. Meanwhile, this
divergence leads to information waste and increases difficulties in building
complex applications in real scenarios. Recent studies often formulate IE tasks
as a triplet extraction problem. However, such a paradigm does not support
multi-span and n-ary extraction, leading to weak versatility. To this end, we
reorganize IE problems into unified multi-slot tuples and propose a universal
framework for various IE tasks, namely Mirror. Specifically, we recast existing
IE tasks as a multi-span cyclic graph extraction problem and devise a
non-autoregressive graph decoding algorithm to extract all spans in a single
step. It is worth noting that this graph structure is incredibly versatile, and
it supports not only complex IE tasks, but also machine reading comprehension
and classification tasks. We manually construct a corpus containing 57 datasets
for model pretraining, and conduct experiments on 30 datasets across 8
downstream tasks. The experimental results demonstrate that our model has
decent compatibility and outperforms or reaches competitive performance with
SOTA systems under few-shot and zero-shot settings. The code, model weights,
and pretraining corpus are available at https://github.com/Spico197/Mirror .
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05420" title="Abstract">arXiv:2311.05420</a> [<a href="/pdf/2311.05420" title="Download PDF">pdf</a>, <a href="/format/2311.05420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Counterfactually Fair Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zuo%2C+Z">Zhiqun Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Khalili%2C+M+M">Mohammad Mahdi Khalili</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xueru Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">The use of machine learning models in high-stake applications (e.g.,
healthcare, lending, college admission) has raised growing concerns due to
potential biases against protected social groups. Various fairness notions and
methods have been proposed to mitigate such biases. In this work, we focus on
Counterfactual Fairness (CF), a fairness notion that is dependent on an
underlying causal graph and first proposed by Kusner \textit{et
al.}~\cite{kusner2017counterfactual}; it requires that the outcome an
individual perceives is the same in the real world as it would be in a
"counterfactual" world, in which the individual belongs to another social
group. Learning fair models satisfying CF can be challenging. It was shown in
\cite{kusner2017counterfactual} that a sufficient condition for satisfying CF
is to \textbf{not} use features that are descendants of sensitive attributes in
the causal graph. This implies a simple method that learns CF models only using
non-descendants of sensitive attributes while eliminating all descendants.
Although several subsequent works proposed methods that use all features for
training CF models, there is no theoretical guarantee that they can satisfy CF.
In contrast, this work proposes a new algorithm that trains models using all
the available features. We theoretically and empirically show that models
trained with this method can satisfy CF\footnote{The code repository for this
work can be found in
\url{https://github.com/osu-srml/CF_Representation_Learning}}.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05421" title="Abstract">arXiv:2311.05421</a> [<a href="/pdf/2311.05421" title="Download PDF">pdf</a>, <a href="/format/2311.05421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Based Causal Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mamaghan%2C+A+M+K">Amir Mohammad Karimi Mamaghan</a>, 
<a href="/search/cs?searchtype=author&query=Dittadi%2C+A">Andrea Dittadi</a>, 
<a href="/search/cs?searchtype=author&query=Bauer%2C+S">Stefan Bauer</a>, 
<a href="/search/cs?searchtype=author&query=Johansson%2C+K+H">Karl Henrik Johansson</a>, 
<a href="/search/cs?searchtype=author&query=Quinzan%2C+F">Francesco Quinzan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
<p class="mathjax">Causal reasoning can be considered a cornerstone of intelligent systems.
Having access to an underlying causal graph comes with the promise of
cause-effect estimation and the identification of efficient and safe
interventions. However, learning causal representations remains a major
challenge, due to the complexity of many real-world systems. Previous works on
causal representation learning have mostly focused on Variational Auto-Encoders
(VAE). These methods only provide representations from a point estimate, and
they are unsuitable to handle high dimensions. To overcome these problems, we
proposed a new Diffusion-based Causal Representation Learning (DCRL) algorithm.
This algorithm uses diffusion-based representations for causal discovery. DCRL
offers access to infinite dimensional latent codes, which encode different
levels of information in the latent code. In a first proof of principle, we
investigate the use of DCRL for causal representation learning. We further
demonstrate experimentally that this approach performs comparably well in
identifying the causal structure and causal variables.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05424" title="Abstract">arXiv:2311.05424</a> [<a href="/pdf/2311.05424" title="Download PDF">pdf</a>, <a href="/format/2311.05424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ESPORT: Electronic Sports Professionals Observations and Reflections on  Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bia%C5%82ecki%2C+A">Andrzej Bia&#x142;ecki</a>, 
<a href="/search/cs?searchtype=author&query=Xenopoulos%2C+P">Peter Xenopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Dobrowolski%2C+P">Pawe&#x142; Dobrowolski</a>, 
<a href="/search/cs?searchtype=author&query=Bia%C5%82ecki%2C+R">Robert Bia&#x142;ecki</a>, 
<a href="/search/cs?searchtype=author&query=Gajewski%2C+J">Jan Gajewski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Esports and high performance human-computer interaction are on the forefront
of applying new hardware and software technologies in practice. Despite that,
there is a paucity of research on how semi-professional and professional
championship level players approach aspects of their preparation.
<br />To address that, we have performed, transcribed, and analyzed interviews with
top-tournament players, coaches, and managers across multiple game titles. The
interviews range from competitive events occuring between 2015-2020. Initial
processing included transcription and manual verification. The pre-processed
interview data were then organized and structured into relevant categories,
touching on psychological, physical, and nutritional aspects of esports
preparation. Further, where applicable, interview responses where rated and
quantified via consensus judgement by a panel of experts.
<br />The results indicate that physical training was most often mentioned as a
relevant or consistent activity, while nutrition was indicated as relatively
unimportant. Qualitative analysis also indicated that consistency and
resiliency were noted as the most key factors recommended for upcoming esports
competitors. It is also clear that many players put emphasis on balancing their
gameplay time and with activities. Lastly, we identified important areas of
inquiry towards a deeper understanding of the mental and physical demands of
professional esports players.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05425" title="Abstract">arXiv:2311.05425</a> [<a href="/pdf/2311.05425" title="Download PDF">pdf</a>, <a href="/format/2311.05425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Mining Sample Pair Semantics for Image-text Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chena%2C+Y">Yongfeng Chena</a>, 
<a href="/search/cs?searchtype=author&query=Liua%2C+J">Jin Liua</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhijing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chena%2C+R">Ruihan Chena</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+J">Junpeng Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, commonsense learning has been a hot topic in image-text matching.
Although it can describe more graphic correlations, commonsense learning still
has some shortcomings: 1) The existing methods are based on triplet semantic
similarity measurement loss, which cannot effectively match the intractable
negative in image-text sample pairs. 2) The weak generalization ability of the
model leads to the poor effect of image and text matching on large-scale
datasets. According to these shortcomings. This paper proposes a novel
image-text matching model, called Active Mining Sample Pair Semantics
image-text matching model (AMSPS). Compared with the single semantic learning
mode of the commonsense learning model with triplet loss function, AMSPS is an
active learning idea. Firstly, the proposed Adaptive Hierarchical Reinforcement
Loss (AHRL) has diversified learning modes. Its active learning mode enables
the model to more focus on the intractable negative samples to enhance the
discriminating ability. In addition, AMSPS can also adaptively mine more hidden
relevant semantic representations from uncommented items, which greatly
improves the performance and generalization ability of the model. Experimental
results on Flickr30K and MSCOCO universal datasets show that our proposed
method is superior to advanced comparison methods.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05426" title="Abstract">arXiv:2311.05426</a> [<a href="/pdf/2311.05426" title="Download PDF">pdf</a>, <a href="/format/2311.05426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistical Learning of Conjunction Data Messages Through a Bayesian  Non-Homogeneous Poisson Process
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guimar%C3%A3es%2C+M">Marta Guimar&#xe3;es</a>, 
<a href="/search/cs?searchtype=author&query=Soares%2C+C">Cl&#xe1;udia Soares</a>, 
<a href="/search/cs?searchtype=author&query=Manfletti%2C+C">Chiara Manfletti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Current approaches for collision avoidance and space traffic management face
many challenges, mainly due to the continuous increase in the number of objects
in orbit and the lack of scalable and automated solutions. To avoid
catastrophic incidents, satellite owners/operators must be aware of their
assets' collision risk to decide whether a collision avoidance manoeuvre needs
to be performed. This process is typically executed through the use of warnings
issued in the form of CDMs which contain information about the event, such as
the expected TCA and the probability of collision. Our previous work presented
a statistical learning model that allowed us to answer two important questions:
(1) Will any new conjunctions be issued in the next specified time interval?
(2) When and with what uncertainty will the next CDM arrive? However, the model
was based on an empirical Bayes homogeneous Poisson process, which assumes that
the arrival rates of CDMs are constant over time. In fact, the rate at which
the CDMs are issued depends on the behaviour of the objects as well as on the
screening process performed by third parties. Thus, in this work, we extend the
previous study and propose a Bayesian non-homogeneous Poisson process
implemented with high precision using a Probabilistic Programming Language to
fully describe the underlying phenomena. We compare the proposed solution with
a baseline model to demonstrate the added value of our approach. The results
show that this problem can be successfully modelled by our Bayesian
non-homogeneous Poisson Process with greater accuracy, contributing to the
development of automated collision avoidance systems and helping operators
react timely but sparingly with satellite manoeuvres.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05430" title="Abstract">arXiv:2311.05430</a> [<a href="/pdf/2311.05430" title="Download PDF">pdf</a>, <a href="/format/2311.05430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taxonomy for Resident Space Objects in LEO: A Deep Learning Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guimar%C3%A3es%2C+M">Marta Guimar&#xe3;es</a>, 
<a href="/search/cs?searchtype=author&query=Soares%2C+C">Cl&#xe1;udia Soares</a>, 
<a href="/search/cs?searchtype=author&query=Manfletti%2C+C">Chiara Manfletti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The increasing number of RSOs has raised concerns about the risk of
collisions and catastrophic incidents for all direct and indirect users of
space. To mitigate this issue, it is essential to have a good understanding of
the various RSOs in orbit and their behaviour. A well-established taxonomy
defining several classes of RSOs is a critical step in achieving this
understanding. This taxonomy helps assign objects to specific categories based
on their main characteristics, leading to better tracking services.
Furthermore, a well-established taxonomy can facilitate research and analysis
processes by providing a common language and framework for better understanding
the factors that influence RSO behaviour in space. These factors, in turn, help
design more efficient and effective strategies for space traffic management.
Our work proposes a new taxonomy for RSOs focusing on the low Earth orbit
regime to enhance space traffic management. In addition, we present a deep
learning-based model that uses an autoencoder architecture to reduce the
features representing the characteristics of the RSOs. The autoencoder
generates a lower-dimensional space representation that is then explored using
techniques such as Uniform Manifold Approximation and Projection to identify
fundamental clusters of RSOs based on their unique characteristics. This
approach captures the complex and non-linear relationships between the features
and the RSOs' classes identified. Our proposed taxonomy and model offer a
significant contribution to the ongoing efforts to mitigate the overall risks
posed by the increasing number of RSOs in orbit.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05432" title="Abstract">arXiv:2311.05432</a> [<a href="/pdf/2311.05432" title="Download PDF">pdf</a>, <a href="/format/2311.05432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual Pipeline Style Transfer with Input Distribution Differentiation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">ShiQi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">JunJie Kang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">YuJian Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">The color and texture dual pipeline architecture (CTDP) suppresses texture
representation and artifacts through masked total variation loss (Mtv), and
further experiments have shown that smooth input can almost completely
eliminate texture representation. We have demonstrated through experiments that
smooth input is not the key reason for removing texture representations, but
rather the distribution differentiation of the training dataset. Based on this,
we propose an input distribution differentiation training strategy (IDD), which
forces the generation of textures to be completely dependent on the noise
distribution, while the smooth distribution will not produce textures at all.
Overall, our proposed distribution differentiation training strategy allows for
two pre-defined input distributions to be responsible for two generation tasks,
with noise distribution responsible for texture generation and smooth
distribution responsible for color smooth transfer. Finally, we choose a smooth
distribution as the input for the forward inference stage to completely
eliminate texture representations and artifacts in color transfer tasks.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05434" title="Abstract">arXiv:2311.05434</a> [<a href="/pdf/2311.05434" title="Download PDF">pdf</a>, <a href="/ps/2311.05434" title="Download PostScript">ps</a>, <a href="/format/2311.05434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Core determinants of quality criteria for mhealth for hypertension:  evidence from machine learning instruments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Paula%2C+D">Danielly de Paula</a>, 
<a href="/search/cs?searchtype=author&query=Sasso%2C+A">Ariane Sasso</a>, 
<a href="/search/cs?searchtype=author&query=Coester%2C+J">Justus Coester</a>, 
<a href="/search/cs?searchtype=author&query=Boettinger%2C+E">Erwin Boettinger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 6 Figures, 1 Table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Uncontrolled hypertension is a global problem that needs to be addressed.
Despite the many mHealth solutions in the market, the nonadherence relative to
intended use jeopardizes treatment success. Although investigating user
experience is one of the most important mechanisms for understanding mHealth
discontinuance, surprisingly, the core determinants of overall user experience
(i.e., positive and negative) about mHealth apps for hypertension are unknown.
To address the mentioned gap in knowledge, this study adopts the computational
grounded theory methodological framework and employs advanced deep learning
algorithms to predict core quality criteria that affect overall user experience
of hypertension apps published in the Apple App Store. This study contributes
to theory and practice of designing evidence-based interventions for
hypertension in the form of propositions and provide valuable managerial
implications and recommendations for manufacturers.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05435" title="Abstract">arXiv:2311.05435</a> [<a href="/pdf/2311.05435" title="Download PDF">pdf</a>, <a href="/ps/2311.05435" title="Download PostScript">ps</a>, <a href="/format/2311.05435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parkinson&#x27;s Disease Detection through Vocal Biomarkers and Advanced  Machine Learning Algorithms: A Comprehensive Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sayed%2C+M+A">Md Abu Sayed</a>, 
<a href="/search/cs?searchtype=author&query=Ahamed%2C+S">Sabbir Ahamed</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+D+M">Duc M Cao</a>, 
<a href="/search/cs?searchtype=author&query=Pavel%2C+M+E+U+I">Md Eyasin Ul Islam Pavel</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+M">Malay Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Mia%2C+M+T">Md Tuhin Mia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Parkinson's disease (PD) is a prevalent neurodegenerative disorder known for
its impact on motor neurons, causing symptoms like tremors, stiffness, and gait
difficulties. This study explores the potential of vocal feature alterations in
PD patients as a means of early disease prediction. This research aims to
predict the onset of Parkinson's disease. Utilizing a variety of advanced
machine-learning algorithms, including XGBoost, LightGBM, Bagging, AdaBoost,
and Support Vector Machine, among others, the study evaluates the predictive
performance of these models using metrics such as accuracy, area under the
curve (AUC), sensitivity, and specificity. The findings of this comprehensive
analysis highlight LightGBM as the most effective model, achieving an
impressive accuracy rate of 96%, alongside a matching AUC of 96%. LightGBM
exhibited a remarkable sensitivity of 100% and specificity of 94.43%,
surpassing other machine learning algorithms in accuracy and AUC scores. Given
the complexities of Parkinson's disease and its challenges in early diagnosis,
this study underscores the significance of leveraging vocal biomarkers coupled
with advanced machine-learning techniques for precise and timely PD detection.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05437" title="Abstract">arXiv:2311.05437</a> [<a href="/pdf/2311.05437" title="Download PDF">pdf</a>, <a href="/format/2311.05437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLaVA-Plus: Learning to Use Tools for Creating Multimodal Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shilong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haotian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Feng Li</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+T">Tianhe Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+X">Xueyan Zou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianwei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hang Su</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jianfeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chunyuan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 25M file size. Project Page: <a href="https://llava-vl.github.io/llava-plus/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">LLaVA-Plus is a general-purpose multimodal assistant that expands the
capabilities of large multimodal models. It maintains a skill repository of
pre-trained vision and vision-language models and can activate relevant tools
based on users' inputs to fulfill real-world tasks. LLaVA-Plus is trained on
multimodal instruction-following data to acquire the ability to use tools,
covering visual understanding, generation, external knowledge retrieval, and
compositions. Empirical results show that LLaVA-Plus outperforms LLaVA in
existing capabilities and exhibits new ones. It is distinct in that the image
query is directly grounded and actively engaged throughout the entire human-AI
interaction sessions, significantly improving tool use performance and enabling
new scenarios.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05440" title="Abstract">arXiv:2311.05440</a> [<a href="/pdf/2311.05440" title="Download PDF">pdf</a>, <a href="/format/2311.05440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Practical Approach to Novel Class Discovery in Tabular Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Troisemaine%2C+C">Colin Troisemaine</a>, 
<a href="/search/cs?searchtype=author&query=Reiffers-Masson%2C+A">Alexandre Reiffers-Masson</a>, 
<a href="/search/cs?searchtype=author&query=Gosselin%2C+S">St&#xe9;phane Gosselin</a>, 
<a href="/search/cs?searchtype=author&query=Lemaire%2C+V">Vincent Lemaire</a>, 
<a href="/search/cs?searchtype=author&query=Vaton%2C+S">Sandrine Vaton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, including 3 pages of annexes
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The problem of Novel Class Discovery (NCD) consists in extracting knowledge
from a labeled set of known classes to accurately partition an unlabeled set of
novel classes. While NCD has recently received a lot of attention from the
community, it is often solved on computer vision problems and under unrealistic
conditions. In particular, the number of novel classes is usually assumed to be
known in advance, and their labels are sometimes used to tune hyperparameters.
Methods that rely on these assumptions are not applicable in real-world
scenarios. In this work, we focus on solving NCD in tabular data when no prior
knowledge of the novel classes is available. To this end, we propose to tune
the hyperparameters of NCD methods by adapting the $k$-fold cross-validation
process and hiding some of the known classes in each fold. Since we have found
that methods with too many hyperparameters are likely to overfit these hidden
classes, we define a simple deep NCD model. This method is composed of only the
essential elements necessary for the NCD problem and performs impressively well
under realistic conditions. Furthermore, we find that the latent space of this
method can be used to reliably estimate the number of novel classes.
Additionally, we adapt two unsupervised clustering algorithms ($k$-means and
Spectral Clustering) to leverage the knowledge of the known classes. Extensive
experiments are conducted on 7 tabular datasets and demonstrate the
effectiveness of the proposed method and hyperparameter tuning process, and
show that the NCD problem can be solved without relying on knowledge from the
novel classes.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05445" title="Abstract">arXiv:2311.05445</a> [<a href="/pdf/2311.05445" title="Download PDF">pdf</a>, <a href="/format/2311.05445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Airfoil generation and feature extraction using the conditional  VAE-WGAN-gp
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yonekura%2C+K">Kazuo Yonekura</a>, 
<a href="/search/cs?searchtype=author&query=Tomori%2C+Y">Yuki Tomori</a>, 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+K">Katsuyuki Suzuki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">A machine learning method was applied to solve an inverse airfoil design
problem. A conditional VAE-WGAN-gp model, which couples the conditional
variational autoencoder (VAE) and Wasserstein generative adversarial network
with gradient penalty (WGAN-gp), is proposed for an airfoil generation method,
and then it is compared with the WGAN-gp and VAE models. The VAEGAN model
couples the VAE and GAN models, which enables feature extraction in the GAN
models. In airfoil generation tasks, to generate airfoil shapes that satisfy
lift coefficient requirements, it is known that VAE outperforms WGAN-gp with
respect to the accuracy of the reproduction of the lift coefficient, whereas
GAN outperforms VAE with respect to the smoothness and variations of generated
shapes. In this study, VAE-WGAN-gp demonstrated a good performance in all three
aspects. Latent distribution was also studied to compare the feature extraction
ability of the proposed method.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05449" title="Abstract">arXiv:2311.05449</a> [<a href="/pdf/2311.05449" title="Download PDF">pdf</a>, <a href="/ps/2311.05449" title="Download PostScript">ps</a>, <a href="/format/2311.05449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding emotions in the context of IT-based self-monitoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Paula%2C+D">Danielly de Paula</a>, 
<a href="/search/cs?searchtype=author&query=Borchert%2C+F">Florian Borchert</a>, 
<a href="/search/cs?searchtype=author&query=Sasso%2C+A">Ariane Sasso</a>, 
<a href="/search/cs?searchtype=author&query=Uebernickel%2C+F">Falk Uebernickel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages, 5 Figures, 5 Tables, 2 Appendixes
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">This study explores the intersection of information technology-based
self-monitoring (ITSM) and emotional responses in chronic care. It critiques
the lack of theoretical depth in current ITSM research and proposes a dynamic
emotion process theory to understand ITSM's impact on users' emotions.
Utilizing computational grounded theory and machine learning analysis of
hypertension app reviews, the research seeks to extend emotion theory by
examining ITSM stimuli and their influence on emotional episodes, moving beyond
discrete emotion models towards a continuous, nuanced understanding of
emotional responses.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05450" title="Abstract">arXiv:2311.05450</a> [<a href="/pdf/2311.05450" title="Download PDF">pdf</a>, <a href="/format/2311.05450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cognitively Inspired Components for Social Conversational Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Clay%2C+A">Alex Clay</a>, 
<a href="/search/cs?searchtype=author&query=Alonso%2C+E">Eduardo Alonso</a>, 
<a href="/search/cs?searchtype=author&query=Mondrag%C3%B3n%2C+E">Esther Mondrag&#xf3;n</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 figures, This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Current conversational agents (CA) have seen improvement in conversational
quality in recent years due to the influence of large language models (LLMs)
like GPT3. However, two key categories of problem remain. Firstly there are the
unique technical problems resulting from the approach taken in creating the CA,
such as scope with retrieval agents and the often nonsensical answers of former
generative agents. Secondly, humans perceive CAs as social actors, and as a
result expect the CA to adhere to social convention. Failure on the part of the
CA in this respect can lead to a poor interaction and even the perception of
threat by the user. As such, this paper presents a survey highlighting a
potential solution to both categories of problem through the introduction of
cognitively inspired additions to the CA. Through computational facsimiles of
semantic and episodic memory, emotion, working memory, and the ability to
learn, it is possible to address both the technical and social problems
encountered by CAs.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05451" title="Abstract">arXiv:2311.05451</a> [<a href="/pdf/2311.05451" title="Download PDF">pdf</a>, <a href="/format/2311.05451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> All Should Be Equal in the Eyes of Language Models: Counterfactually  Aware Fair Text Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+P">Pragyan Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Java%2C+A">Abhinav Java</a>, 
<a href="/search/cs?searchtype=author&query=Jandial%2C+S">Surgan Jandial</a>, 
<a href="/search/cs?searchtype=author&query=Shahid%2C+S">Simra Shahid</a>, 
<a href="/search/cs?searchtype=author&query=Furniturewala%2C+S">Shaz Furniturewala</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamurthy%2C+B">Balaji Krishnamurthy</a>, 
<a href="/search/cs?searchtype=author&query=Bhatia%2C+S">Sumit Bhatia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first four authors contributed equally to the work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Fairness in Language Models (LMs) remains a longstanding challenge, given the
inherent biases in training data that can be perpetuated by models and affect
the downstream tasks. Recent methods employ expensive retraining or attempt
debiasing during inference by constraining model outputs to contrast from a
reference set of biased templates or exemplars. Regardless, they dont address
the primary goal of fairness to maintain equitability across different
demographic groups. In this work, we posit that inferencing LMs to generate
unbiased output for one demographic under a context ensues from being aware of
outputs for other demographics under the same context. To this end, we propose
Counterfactually Aware Fair InferencE (CAFIE), a framework that dynamically
compares the model understanding of diverse demographics to generate more
equitable sentences. We conduct an extensive empirical evaluation using base
LMs of varying sizes and across three diverse datasets and found that CAFIE
outperforms strong baselines. CAFIE produces fairer text and strikes the best
balance between fairness and language modeling capability
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05457" title="Abstract">arXiv:2311.05457</a> [<a href="/pdf/2311.05457" title="Download PDF">pdf</a>, <a href="/format/2311.05457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Mobile Sensing Strategies Generation for Human Behaviour  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+N">Nan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhuolei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuntao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Salim%2C+F+D">Flora D. Salim</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yuanchun Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Mobile sensing plays a crucial role in generating digital traces to
understand human daily lives. However, studying behaviours like mood or sleep
quality in smartphone users requires carefully designed mobile sensing
strategies such as sensor selection and feature construction. This process is
time-consuming, burdensome, and requires expertise in multiple domains.
Furthermore, the resulting sensing framework lacks generalizability, making it
difficult to apply to different scenarios. To address these challenges, we
propose an automated mobile sensing strategy for human behaviour understanding.
First, we establish a knowledge base and consolidate rules for effective
feature construction, data collection, and model selection. Then, we introduce
the multi-granular human behaviour representation and design procedures for
leveraging large language models to generate strategies. Our approach is
validated through blind comparative studies and usability evaluation.
Ultimately, our approach holds the potential to revolutionise the field of
mobile sensing and its applications.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05461" title="Abstract">arXiv:2311.05461</a> [<a href="/pdf/2311.05461" title="Download PDF">pdf</a>, <a href="/format/2311.05461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Control3D: Towards Controllable Text-to-3D Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yingwei Pan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yehao Li</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+T">Ting Yao</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+T">Tao Mei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM Multimedia 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Recent remarkable advances in large-scale text-to-image diffusion models have
inspired a significant breakthrough in text-to-3D generation, pursuing 3D
content creation solely from a given text prompt. However, existing text-to-3D
techniques lack a crucial ability in the creative process: interactively
control and shape the synthetic 3D contents according to users' desired
specifications (e.g., sketch). To alleviate this issue, we present the first
attempt for text-to-3D generation conditioning on the additional hand-drawn
sketch, namely Control3D, which enhances controllability for users. In
particular, a 2D conditioned diffusion model (ControlNet) is remoulded to guide
the learning of 3D scene parameterized as NeRF, encouraging each view of 3D
scene aligned with the given text prompt and hand-drawn sketch. Moreover, we
exploit a pre-trained differentiable photo-to-sketch model to directly estimate
the sketch of the rendered image over synthetic 3D scene. Such estimated sketch
along with each sampled view is further enforced to be geometrically consistent
with the given sketch, pursuing better controllable text-to-3D generation.
Through extensive experiments, we demonstrate that our proposal can generate
accurate and faithful 3D scenes that align closely with the input text prompts
and sketches.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05462" title="Abstract">arXiv:2311.05462</a> [<a href="/pdf/2311.05462" title="Download PDF">pdf</a>, <a href="/format/2311.05462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatGPT and other Large Language Models for Cybersecurity of Smart Grid  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zaboli%2C+A">Aydin Zaboli</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+S+L">Seong Lok Choi</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+T">Tai-Jin Song</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+J">Junho Hong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, Submitted to 2024 IEEE Power &amp; Energy Society General Meeting (PESGM), Seattle, WA USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Cybersecurity breaches targeting electrical substations constitute a
significant threat to the integrity of the power grid, necessitating
comprehensive defense and mitigation strategies. Any anomaly in information and
communication technology (ICT) should be detected for secure communications
between devices in digital substations. This paper proposes large language
models (LLM), e.g., ChatGPT, for the cybersecurity of IEC 61850-based digital
substation communications. Multicast messages such as generic object oriented
substation event (GOOSE) and sampled value (SV) are used for case studies. The
proposed LLM-based cybersecurity framework includes for the first time data
pre-processing of communication systems and human-in-the-loop (HITL) training
(considering the cybersecurity guidelines recommended by humans). The results
show a comparative analysis of detected anomaly data carried out based on the
performance evaluation metrics for different LLMs. A hardware-in-the-loop (HIL)
testbed is used to generate and extract a dataset of IEC 61850 communications.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05463" title="Abstract">arXiv:2311.05463</a> [<a href="/pdf/2311.05463" title="Download PDF">pdf</a>, <a href="/format/2311.05463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ControlStyle: Text-Driven Stylized Image Generation Using Diffusion  Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingwen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yingwei Pan</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+T">Ting Yao</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+T">Tao Mei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM Multimedia 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Recently, the multimedia community has witnessed the rise of diffusion models
trained on large-scale multi-modal data for visual content creation,
particularly in the field of text-to-image generation. In this paper, we
propose a new task for ``stylizing'' text-to-image models, namely text-driven
stylized image generation, that further enhances editability in content
creation. Given input text prompt and style image, this task aims to produce
stylized images which are both semantically relevant to input text prompt and
meanwhile aligned with the style image in style. To achieve this, we present a
new diffusion model (ControlStyle) via upgrading a pre-trained text-to-image
model with a trainable modulation network enabling more conditions of text
prompts and style images. Moreover, diffusion style and content regularizations
are simultaneously introduced to facilitate the learning of this modulation
network with these diffusion priors, pursuing high-quality stylized
text-to-image generation. Extensive experiments demonstrate the effectiveness
of our ControlStyle in producing more visually pleasing and artistic results,
surpassing a simple combination of text-to-image model and conventional style
transfer techniques.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05464" title="Abstract">arXiv:2311.05464</a> [<a href="/pdf/2311.05464" title="Download PDF">pdf</a>, <a href="/format/2311.05464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3DStyle-Diffusion: Pursuing Fine-grained Text-driven 3D Stylization with  2D Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Haibo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yingwei Pan</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+T">Ting Yao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhineng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+T">Tao Mei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM Multimedia 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">3D content creation via text-driven stylization has played a fundamental
challenge to multimedia and graphics community. Recent advances of cross-modal
foundation models (e.g., CLIP) have made this problem feasible. Those
approaches commonly leverage CLIP to align the holistic semantics of stylized
mesh with the given text prompt. Nevertheless, it is not trivial to enable more
controllable stylization of fine-grained details in 3D meshes solely based on
such semantic-level cross-modal supervision. In this work, we propose a new
3DStyle-Diffusion model that triggers fine-grained stylization of 3D meshes
with additional controllable appearance and geometric guidance from 2D
Diffusion models. Technically, 3DStyle-Diffusion first parameterizes the
texture of 3D mesh into reflectance properties and scene lighting using
implicit MLP networks. Meanwhile, an accurate depth map of each sampled view is
achieved conditioned on 3D mesh. Then, 3DStyle-Diffusion leverages a
pre-trained controllable 2D Diffusion model to guide the learning of rendered
images, encouraging the synthesized image of each view semantically aligned
with text prompt and geometrically consistent with depth map. This way
elegantly integrates both image rendering via implicit MLP networks and
diffusion process of image synthesis in an end-to-end fashion, enabling a
high-quality fine-grained stylization of 3D meshes. We also build a new dataset
derived from Objaverse and the evaluation protocol for this task. Through both
qualitative and quantitative experiments, we validate the capability of our
3DStyle-Diffusion. Source code and data are available at
\url{https://github.com/yanghb22-fdu/3DStyle-Diffusion-Official}.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05470" title="Abstract">arXiv:2311.05470</a> [<a href="/pdf/2311.05470" title="Download PDF">pdf</a>, <a href="/format/2311.05470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing ship hull forms using generative adversarial networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yonekura%2C+K">Kazuo Yonekura</a>, 
<a href="/search/cs?searchtype=author&query=Omori%2C+K">Kotaro Omori</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xinran Qi</a>, 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+K">Katsuyuki Suzuki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">We proposed a GAN-based method to generate a ship hull form. Unlike
mathematical hull forms that require geometrical parameters to generate ship
hull forms, the proposed method requires desirable ship performance parameters,
i.e., the drag coefficient and tonnage. The requirements of ship owners are
generally focused on the ship performance and not the geometry itself. Hence,
the proposed model is useful for obtaining the ship hull form based on an
owner's requirements. The GAN model was trained using a ship hull form dataset
generated using the generalized Wigley hull form. The proposed method was
evaluated through numerical experiments and successfully generated ship data
with small errors.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05472" title="Abstract">arXiv:2311.05472</a> [<a href="/pdf/2311.05472" title="Download PDF">pdf</a>, <a href="/format/2311.05472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text Representation Distillation via Information Bottleneck Principle
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanzhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+D">Dingkun Long</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zehan Li</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+P">Pengjun Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023. The code and pre-trained models are available at [this https URL](<a href="https://github.com/Alibaba-NLP/IBKD">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Pre-trained language models (PLMs) have recently shown great success in text
representation field. However, the high computational cost and high-dimensional
representation of PLMs pose significant challenges for practical applications.
To make models more accessible, an effective method is to distill large models
into smaller representation models. In order to relieve the issue of
performance degradation after distillation, we propose a novel Knowledge
Distillation method called IBKD. This approach is motivated by the Information
Bottleneck principle and aims to maximize the mutual information between the
final representation of the teacher and student model, while simultaneously
reducing the mutual information between the student model's representation and
the input data. This enables the student model to preserve important learned
information while avoiding unnecessary information, thus reducing the risk of
over-fitting. Empirical studies on two main downstream applications of text
representation (Semantic Textual Similarity and Dense Retrieval tasks)
demonstrate the effectiveness of our proposed approach.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05473" title="Abstract">arXiv:2311.05473</a> [<a href="/pdf/2311.05473" title="Download PDF">pdf</a>, <a href="/format/2311.05473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do Ensembling and Meta-Learning Improve Outlier Detection in Randomized  Controlled Trials?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nelson%2C+W">Walter Nelson</a>, 
<a href="/search/cs?searchtype=author&query=Ranisau%2C+J">Jonathan Ranisau</a>, 
<a href="/search/cs?searchtype=author&query=Petch%2C+J">Jeremy Petch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2023, December 10th, 2023, New Orleans, United States, 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Modern multi-centre randomized controlled trials (MCRCTs) collect massive
amounts of tabular data, and are monitored intensively for irregularities by
humans. We began by empirically evaluating 6 modern machine learning-based
outlier detection algorithms on the task of identifying irregular data in 838
datasets from 7 real-world MCRCTs with a total of 77,001 patients from over 44
countries. Our results reinforce key findings from prior work in the outlier
detection literature on data from other domains. Existing algorithms often
succeed at identifying irregularities without any supervision, with at least
one algorithm exhibiting positive performance 70.6% of the time. However,
performance across datasets varies substantially with no single algorithm
performing consistently well, motivating new techniques for unsupervised model
selection or other means of aggregating potentially discordant predictions from
multiple candidate models. We propose the Meta-learned Probabilistic Ensemble
(MePE), a simple algorithm for aggregating the predictions of multiple
unsupervised models, and show that it performs favourably compared to recent
meta-learning approaches for outlier detection model selection. While
meta-learning shows promise, small ensembles outperform all forms of
meta-learning on average, a negative result that may guide the application of
current outlier detection approaches in healthcare and other real-world
domains.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05474" title="Abstract">arXiv:2311.05474</a> [<a href="/pdf/2311.05474" title="Download PDF">pdf</a>, <a href="/ps/2311.05474" title="Download PostScript">ps</a>, <a href="/format/2311.05474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Complexity of the Virtual Network Embedding in Specific Tree  Topologies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pankratov%2C+S">Sergey Pankratov</a>, 
<a href="/search/cs?searchtype=author&query=Aksenov%2C+V">Vitaly Aksenov</a>, 
<a href="/search/cs?searchtype=author&query=Schmid%2C+S">Stefan Schmid</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Virtual networks are an innovative abstraction that extends cloud computing
concepts to the network: by supporting bandwidth reservations between compute
nodes (e.g., virtual machines), virtual networks can provide a predictable
performance to distributed and communication-intensive cloud applications.
However, in order to make the most efficient use of the shared resources, the
Virtual Network Embedding (VNE) problem has to be solved: a virtual network
should be mapped onto the given physical network so that resource reservations
are minimized. The problem has been studied intensively already and is known to
be NP-hard in general. In this paper, we revisit this problem and consider it
on specific topologies, as they often arise in practice. To be more precise, we
study the weighted version of the VNE problem: we consider a virtual weighted
network of a specific topology which we want to embed onto a weighted network
with capacities and specific topology. As for topologies, we consider most
fundamental and commonly used ones: line, star, $2$-tiered star, oversubscribed
$2$-tiered star, and tree, in addition to also considering arbitrary
topologies. We show that typically the VNE problem is NP-hard even in more
specialized cases, however, sometimes there exists a polynomial algorithm: for
example, an embedding of the oversubscribed $2$-tiered star onto the tree is
polynomial while an embedding of an arbitrary $2$-tiered star is not.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05478" title="Abstract">arXiv:2311.05478</a> [<a href="/pdf/2311.05478" title="Download PDF">pdf</a>, <a href="/format/2311.05478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Retraining-free GAN Fingerprinting via Personalized Normalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fei%2C+J">Jianwei Fei</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Z">Zhihua Xia</a>, 
<a href="/search/cs?searchtype=author&query=Tondi%2C+B">Benedetta Tondi</a>, 
<a href="/search/cs?searchtype=author&query=Barni%2C+M">Mauro Barni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">In recent years, there has been significant growth in the commercial
applications of generative models, licensed and distributed by model developers
to users, who in turn use them to offer services. In this scenario, there is a
need to track and identify the responsible user in the presence of a violation
of the license agreement or any kind of malicious usage. Although there are
methods enabling Generative Adversarial Networks (GANs) to include invisible
watermarks in the images they produce, generating a model with a different
watermark, referred to as a fingerprint, for each user is time- and
resource-consuming due to the need to retrain the model to include the desired
fingerprint. In this paper, we propose a retraining-free GAN fingerprinting
method that allows model developers to easily generate model copies with the
same functionality but different fingerprints. The generator is modified by
inserting additional Personalized Normalization (PN) layers whose parameters
(scaling and bias) are generated by two dedicated shallow networks (ParamGen
Nets) taking the fingerprint as input. A watermark decoder is trained
simultaneously to extract the fingerprint from the generated images. The
proposed method can embed different fingerprints inside the GAN by just
changing the input of the ParamGen Nets and performing a feedforward pass,
without finetuning or retraining. The performance of the proposed method in
terms of robustness against both model-level and image-level attacks is also
superior to the state-of-the-art.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05481" title="Abstract">arXiv:2311.05481</a> [<a href="/pdf/2311.05481" title="Download PDF">pdf</a>, <a href="/format/2311.05481" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> meta4: semantically-aligned generation of metaphoric gestures using  self-supervised text and speech representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fares%2C+M">Mireille Fares</a>, 
<a href="/search/cs?searchtype=author&query=Pelachaud%2C+C">Catherine Pelachaud</a>, 
<a href="/search/cs?searchtype=author&query=Obin%2C+N">Nicolas Obin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Image Schemas are repetitive cognitive patterns that influence the way we
conceptualize and reason about various concepts present in speech. These
patterns are deeply embedded within our cognitive processes and are reflected
in our bodily expressions including gestures. Particularly, metaphoric gestures
possess essential characteristics and semantic meanings that align with Image
Schemas, to visually represent abstract concepts. The shape and form of
gestures can convey abstract concepts, such as extending the forearm and hand
or tracing a line with hand movements to visually represent the image schema of
PATH. Previous behavior generation models have primarily focused on utilizing
speech (acoustic features and text) to drive the generation model of virtual
agents. They have not considered key semantic information as those carried by
Image Schemas to effectively generate metaphoric gestures. To address this
limitation, we introduce META4, a deep learning approach that generates
metaphoric gestures from both speech and Image Schemas. Our approach has two
primary goals: computing Image Schemas from input text to capture the
underlying semantic and metaphorical meaning, and generating metaphoric
gestures driven by speech and the computed image schemas. Our approach is the
first method for generating speech driven metaphoric gestures while leveraging
the potential of Image Schemas. We demonstrate the effectiveness of our
approach and highlight the importance of both speech and image schemas in
modeling metaphoric gestures.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05487" title="Abstract">arXiv:2311.05487</a> [<a href="/pdf/2311.05487" title="Download PDF">pdf</a>, <a href="/format/2311.05487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> News and Misinformation Consumption in Europe: A Longitudinal  Cross-Country Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baqir%2C+A">Anees Baqir</a>, 
<a href="/search/cs?searchtype=author&query=Galeazzi%2C+A">Alessandro Galeazzi</a>, 
<a href="/search/cs?searchtype=author&query=Zollo%2C+F">Fabiana Zollo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">The Internet and social media have transformed news availability and
accessibility, reshaping information consumption and production. However, they
can also facilitate the rapid spread of misinformation, posing significant
societal challenges. To combat misinformation effectively, it is crucial to
understand the online information environment and news consumption patterns.
Most existing research has primarily focused on single topics or individual
countries, lacking cross-country comparisons. This study investigated
information consumption in four European countries, analyzing three years of
Twitter activity from news outlet accounts in France, Germany, Italy, and the
UK and focusing on the role of misinformation sources. Our work offers a
perspective on how topics of European significance are interpreted across
various countries. Results indicate that reliable sources dominate the
information landscape, although unreliable content is still present across all
countries and topics. While most users engage with reliable sources, a small
percentage consume questionable content. Interestingly, few users have a mixed
information diet, bridging the gap between questionable and reliable news in
the similarity network. Cross-country comparisons revealed differences in
audience overlap of news sources, offering valuable guidance for policymakers
and scholars in developing effective and tailored solutions to combat
misinformation.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05490" title="Abstract">arXiv:2311.05490</a> [<a href="/pdf/2311.05490" title="Download PDF">pdf</a>, <a href="/ps/2311.05490" title="Download PostScript">ps</a>, <a href="/format/2311.05490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> General Policies, Subgoal Structure, and Planning Width
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bonet%2C+B">Blai Bonet</a>, 
<a href="/search/cs?searchtype=author&query=Geffner%2C+H">Hector Geffner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">It has been observed that many classical planning domains with atomic goals
can be solved by means of a simple polynomial exploration procedure, called IW,
that runs in time exponential in the problem width, which in these cases is
bounded and small. Yet, while the notion of width has become part of
state-of-the-art planning algorithms such as BFWS, there is no good explanation
for why so many benchmark domains have bounded width when atomic goals are
considered. In this work, we address this question by relating bounded width
with the existence of general optimal policies that in each planning instance
are represented by tuples of atoms of bounded size. We also define the notions
of (explicit) serializations and serialized width that have a broader scope as
many domains have a bounded serialized width but no bounded width. Such
problems are solved non-optimally in polynomial time by a suitable variant of
the Serialized IW algorithm. Finally, the language of general policies and the
semantics of serializations are combined to yield a simple, meaningful, and
expressive language for specifying serializations in compact form in the form
of sketches, which can be used for encoding domain control knowledge by hand or
for learning it from small examples. Sketches express general problem
decompositions in terms of subgoals, and sketches of bounded width express
problem decompositions that can be solved in polynomial time.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05494" title="Abstract">arXiv:2311.05494</a> [<a href="/pdf/2311.05494" title="Download PDF">pdf</a>, <a href="/format/2311.05494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Object-centric Cross-modal Feature Distillation for Event-based Object  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Liniger%2C+A">Alexander Liniger</a>, 
<a href="/search/cs?searchtype=author&query=Millhaeusler%2C+M">Mario Millhaeusler</a>, 
<a href="/search/cs?searchtype=author&query=Tsiminaki%2C+V">Vagia Tsiminaki</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanyou Li</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+D">Dengxin Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Event cameras are gaining popularity due to their unique properties, such as
their low latency and high dynamic range. One task where these benefits can be
crucial is real-time object detection. However, RGB detectors still outperform
event-based detectors due to the sparsity of the event data and missing visual
details. In this paper, we develop a novel knowledge distillation approach to
shrink the performance gap between these two modalities. To this end, we
propose a cross-modality object detection distillation method that by design
can focus on regions where the knowledge distillation works best. We achieve
this by using an object-centric slot attention mechanism that can iteratively
decouple features maps into object-centric features and corresponding
pixel-features used for distillation. We evaluate our novel distillation
approach on a synthetic and a real event dataset with aligned grayscale images
as a teacher modality. We show that object-centric distillation allows to
significantly improve the performance of the event-based student object
detector, nearly halving the performance gap with respect to the teacher.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05498" title="Abstract">arXiv:2311.05498</a> [<a href="/pdf/2311.05498" title="Download PDF">pdf</a>, <a href="/format/2311.05498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trust your BMS: Designing a Lightweight Authentication Architecture for  Industrial Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Basic%2C+F">Fikret Basic</a>, 
<a href="/search/cs?searchtype=author&query=Steger%2C+C">Christian Steger</a>, 
<a href="/search/cs?searchtype=author&query=Seifert%2C+C">Christian Seifert</a>, 
<a href="/search/cs?searchtype=author&query=Kofler%2C+R">Robert Kofler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted copy for Publication at the 23rd International Conference on Industrial Technology (ICIT), IEEE, 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI); Software Engineering (cs.SE); Systems and Control (eess.SY)

</div>
<p class="mathjax">With the advent of clean energy awareness and systems that rely on extensive
battery usage, the community has seen an increased interest in the development
of more complex and secure Battery Management Systems (BMS). In particular, the
inclusion of BMS in modern complex systems like electric vehicles and power
grids has presented a new set of security-related challenges. A concern is
shown when BMS are intended to extend their communication with external system
networks, as their interaction can leave many backdoors open that potential
attackers could exploit. Hence, it is highly desirable to find a general design
that can be used for BMS and its system inclusion. In this work, a security
architecture solution is proposed intended for the communication between BMS
and other system devices. The aim of the proposed architecture is to be easily
applicable in different industrial settings and systems, while at the same time
keeping the design lightweight in nature.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05499" title="Abstract">arXiv:2311.05499</a> [<a href="/pdf/2311.05499" title="Download PDF">pdf</a>, <a href="/format/2311.05499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measuring the Prevalence of WiFi Bottlenecks in Home Access Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+R">Ranya Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Richardson%2C+M">Marc Richardson</a>, 
<a href="/search/cs?searchtype=author&query=Martins%2C+G">Guilherme Martins</a>, 
<a href="/search/cs?searchtype=author&query=Feamster%2C+N">Nick Feamster</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Performance (cs.PF)

</div>
<p class="mathjax">As broadband Internet speeds continue to increase, the home wireless ("WiFi")
network may more frequently become a performance bottleneck. Past research, now
nearly a decade old, initially documented this phenomenon through indirect
inference techniques, noting the prevalence of WiFi bottlenecks but never
directly measuring them. In the intervening years, access network (and WiFi)
speeds have increased, warranting a re-appraisal of this important question,
particularly with renewed private and federal investment in access network
infrastructure. This paper studies this question, developing a new system and
measurement technique to perform direct measurements of WiFi and access network
performance, ultimately collecting and analyzing a first-of-its-kind dataset of
more than 13,000 joint measurements of WiFi and access network throughputs, in
a real-world deployment spanning more than 50 homes, for nearly two years.
Using this dataset, we re-examine the question of whether, when, and to what
extent a user's home wireless network may be a performance bottleneck,
particularly relative to their access connection. We do so by directly and
continuously measuring the user's Internet performance along two separate
components of the Internet path -- from a wireless client inside the home
network to the wired point of access (e.g., the cable modem), and from the
wired point of access to the user's ISP. Confirming and revising results from
more than a decade ago, we find that a user's home wireless network is often
the throughput bottleneck. In particular, for users with access links that
exceed 800~Mbps, the user's home wireless network was the performance
bottleneck 100% of the time.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05511" title="Abstract">arXiv:2311.05511</a> [<a href="/pdf/2311.05511" title="Download PDF">pdf</a>, <a href="/format/2311.05511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anytime-Constrained Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McMahan%2C+J">Jeremy McMahan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaojin Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We introduce and study constrained Markov Decision Processes (cMDPs) with
anytime constraints. An anytime constraint requires the agent to never violate
its budget at any point in time, almost surely. Although Markovian policies are
no longer sufficient, we show that there exist optimal deterministic policies
augmented with cumulative costs. In fact, we present a fixed-parameter
tractable reduction from anytime-constrained cMDPs to unconstrained MDPs. Our
reduction yields planning and learning algorithms that are time and
sample-efficient for tabular cMDPs so long as the precision of the costs is
logarithmic in the size of the cMDP. However, we also show that computing
non-trivial approximately optimal policies is NP-hard in general. To circumvent
this bottleneck, we design provable approximation algorithms that efficiently
compute or learn an approximately feasible policy with optimal value so long as
the maximum supported cost is bounded by a polynomial in the cMDP or by the
absolute budget. Given our hardness results, our approximation guarantees are
the best possible in terms of tractability under worst-case analysis.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05512" title="Abstract">arXiv:2311.05512</a> [<a href="/pdf/2311.05512" title="Download PDF">pdf</a>, <a href="/format/2311.05512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Operational modal analysis of under-determined system based on Bayesian  CP decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tomita%2C+S">Sunao Tomita</a>, 
<a href="/search/eess?searchtype=author&query=Jimbo%2C+T">Tomohiko Jimbo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Modal parameters such as natural frequencies, modal shapes, and the damping
ratio are useful to understand structural dynamics of mechanical systems. Modal
parameters need to be estimated under operational conditions for use in
structural health monitoring. Therefore, operational modal analysis (OMA)
without input signals has been proposed to easily extract modal parameters
under operational conditions. Recently, OMA for under-determined systems with
more active modes than measurement outputs has been investigated to reduce the
number of sensors. This study proposes the OMA framework for under-determined
systems based on Bayesian CP (CANDECOMP/PARAFAC) decomposition of second-order
statistical data. The proposed method enables us to extract the modal
parameters from under-determined systems without tuning the number of active
modes, because the rank of the tensor data corresponding to the number of
active modes is automatically determined via Bayesian inference. The
effectiveness of this method is demonstrated using artificial vibration data of
a mass-spring system under operational and under-determined conditions.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05513" title="Abstract">arXiv:2311.05513</a> [<a href="/pdf/2311.05513" title="Download PDF">pdf</a>, <a href="/ps/2311.05513" title="Download PostScript">ps</a>, <a href="/format/2311.05513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Learning Management System to Affective Tutoring system: a  preliminary study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Edouard%2C+N">Nadaud Edouard</a>, 
<a href="/search/cs?searchtype=author&query=Thibault%2C+G">Geoffroy Thibault</a>, 
<a href="/search/cs?searchtype=author&query=Tesnim%2C+K">Khelifi Tesnim</a>, 
<a href="/search/cs?searchtype=author&query=Antoun%2C+Y">Yaacoub Antoun</a>, 
<a href="/search/cs?searchtype=author&query=Siba%2C+H">Haidar Siba</a>, 
<a href="/search/cs?searchtype=author&query=Nourh%C3%88ne%2C+B+R">Ben Rabah Nourh&#xc8;ne</a>, 
<a href="/search/cs?searchtype=author&query=Pierre%2C+A+J">Aubin Jean Pierre</a>, 
<a href="/search/cs?searchtype=author&query=Lionel%2C+P">Prevost Lionel</a>, 
<a href="/search/cs?searchtype=author&query=Benedicte%2C+L+G">Le Grand Benedicte</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this study, we investigate the combination of indicators, including
performance, behavioral engagement, and emotional engagement, to identify
students experiencing difficulties. We analyzed data from two primary sources:
digital traces extracted from th e Learning Management System (LMS) and images
captured by students' webcams. The digital traces provided insights into
students' interactions with the educational content, while the images were
utilized to analyze their emotional expressions during learnin g activities. By
utilizing real data collected from students at a French engineering school,
recorded during the 2022 2023 academic year, we observed a correlation between
positive emotional states and improved academic outcomes. These preliminary
findings support the notion that emotions play a crucial role in
differentiating between high achieving and low achieving students.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05514" title="Abstract">arXiv:2311.05514</a> [<a href="/pdf/2311.05514" title="Download PDF">pdf</a>, <a href="/format/2311.05514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Survey of Threshold Digital Signatures: NIST Standards,  Post-Quantum Cryptography, Exotic Techniques, and Real-World Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sedghighadikolaei%2C+K">Kiarash Sedghighadikolaei</a>, 
<a href="/search/cs?searchtype=author&query=Yavuz%2C+A+A">Attila Altay Yavuz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Threshold digital signatures enable a distributed execution of signature
functionalities and will play a crucial role in the security of emerging
decentralized next-generation networked systems and applications. In this
paper, we provide a comprehensive and systematic survey of threshold and
distributed signatures with advanced features. Our survey encompasses threshold
signatures in conventional and post-quantum cryptography (PQC) settings and
captures custom-design and standard signatures (e.g., conventional NIST and
NIST-PQC). We examine both generic (via secure multi-party computation) and
custom thresholding techniques for a myriad of signature families while
investigating exotic signatures, real-life applications, and potential future
research direction.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05521" title="Abstract">arXiv:2311.05521</a> [<a href="/pdf/2311.05521" title="Download PDF">pdf</a>, <a href="/format/2311.05521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BakedAvatar: Baking Neural Fields for Real-Time Head Avatar Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+H">Hao-Bin Duan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Miao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jin-Chuan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xu-Chuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yan-Pei Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM Transactions on Graphics (SIGGRAPH Asia 2023)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM Trans. Graph. 42, 6, Article 225 (December 2023), 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Synthesizing photorealistic 4D human head avatars from videos is essential
for VR/AR, telepresence, and video game applications. Although existing Neural
Radiance Fields (NeRF)-based methods achieve high-fidelity results, the
computational expense limits their use in real-time applications. To overcome
this limitation, we introduce BakedAvatar, a novel representation for real-time
neural head avatar synthesis, deployable in a standard polygon rasterization
pipeline. Our approach extracts deformable multi-layer meshes from learned
isosurfaces of the head and computes expression-, pose-, and view-dependent
appearances that can be baked into static textures for efficient rasterization.
We thus propose a three-stage pipeline for neural head avatar synthesis, which
includes learning continuous deformation, manifold, and radiance fields,
extracting layered meshes and textures, and fine-tuning texture details with
differential rasterization. Experimental results demonstrate that our
representation generates synthesis results of comparable quality to other
state-of-the-art methods while significantly reducing the inference time
required. We further showcase various head avatar synthesis results from
monocular videos, including view synthesis, face reenactment, expression
editing, and pose editing, all at interactive frame rates.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05524" title="Abstract">arXiv:2311.05524</a> [<a href="/pdf/2311.05524" title="Download PDF">pdf</a>, <a href="/format/2311.05524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SeaTurtleID2022: A long-span dataset for reliable sea turtle  re-identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adam%2C+L">Luk&#xe1;&#x161; Adam</a>, 
<a href="/search/cs?searchtype=author&query=%C4%8Cerm%C3%A1k%2C+V">Vojt&#x11b;ch &#x10c;erm&#xe1;k</a>, 
<a href="/search/cs?searchtype=author&query=Papafitsoros%2C+K">Kostas Papafitsoros</a>, 
<a href="/search/cs?searchtype=author&query=Picek%2C+L">Luk&#xe1;&#x161; Picek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2211.10307">arXiv:2211.10307</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper introduces the first public large-scale, long-span dataset with
sea turtle photographs captured in the wild -- SeaTurtleID2022
(https://www.kaggle.com/datasets/wildlifedatasets/seaturtleid2022). The dataset
contains 8729 photographs of 438 unique individuals collected within 13 years,
making it the longest-spanned dataset for animal re-identification. All
photographs include various annotations, e.g., identity, encounter timestamp,
and body parts segmentation masks. Instead of standard "random" splits, the
dataset allows for two realistic and ecologically motivated splits: (i) a
time-aware closed-set with training, validation, and test data from different
days/years, and (ii) a time-aware open-set with new unknown individuals in test
and validation sets. We show that time-aware splits are essential for
benchmarking re-identification methods, as random splits lead to performance
overestimation. Furthermore, a baseline instance segmentation and
re-identification performance over various body parts is provided. Finally, an
end-to-end system for sea turtle re-identification is proposed and evaluated.
The proposed system based on Hybrid Task Cascade for head instance segmentation
and ArcFace-trained feature-extractor achieved an accuracy of 86.8%.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05538" title="Abstract">arXiv:2311.05538</a> [<a href="/pdf/2311.05538" title="Download PDF">pdf</a>, <a href="/format/2311.05538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Embedding Space Interpolation Beyond Mini-Batch, Beyond Pairs and Beyond  Examples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Venkataramanan%2C+S">Shashanka Venkataramanan</a>, 
<a href="/search/cs?searchtype=author&query=Kijak%2C+E">Ewa Kijak</a>, 
<a href="/search/cs?searchtype=author&query=Amsaleg%2C+L">Laurent Amsaleg</a>, 
<a href="/search/cs?searchtype=author&query=Avrithis%2C+Y">Yannis Avrithis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023. arXiv admin note: substantial text overlap with <a href="/abs/2206.14868">arXiv:2206.14868</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Mixup refers to interpolation-based data augmentation, originally motivated
as a way to go beyond empirical risk minimization (ERM). Its extensions mostly
focus on the definition of interpolation and the space (input or feature) where
it takes place, while the augmentation process itself is less studied. In most
methods, the number of generated examples is limited to the mini-batch size and
the number of examples being interpolated is limited to two (pairs), in the
input space.
<br />We make progress in this direction by introducing MultiMix, which generates
an arbitrarily large number of interpolated examples beyond the mini-batch size
and interpolates the entire mini-batch in the embedding space. Effectively, we
sample on the entire convex hull of the mini-batch rather than along linear
segments between pairs of examples.
<br />On sequence data, we further extend to Dense MultiMix. We densely interpolate
features and target labels at each spatial location and also apply the loss
densely. To mitigate the lack of dense labels, we inherit labels from examples
and weight interpolation factors by attention as a measure of confidence.
<br />Overall, we increase the number of loss terms per mini-batch by orders of
magnitude at little additional cost. This is only possible because of
interpolating in the embedding space. We empirically show that our solutions
yield significant improvement over state-of-the-art mixup methods on four
different benchmarks, despite interpolation being only linear. By analyzing the
embedding space, we show that the classes are more tightly clustered and
uniformly spread over the embedding space, thereby explaining the improved
behavior.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05539" title="Abstract">arXiv:2311.05539</a> [<a href="/pdf/2311.05539" title="Download PDF">pdf</a>, <a href="/format/2311.05539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Deep Learning Method for Simultaneous Denoising and Missing Wedge  Reconstruction in Cryogenic Electron Tomography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wiedemann%2C+S">Simon Wiedemann</a>, 
<a href="/search/cs?searchtype=author&query=Heckel%2C+R">Reinhard Heckel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Cryogenic electron tomography (cryo-ET) is a technique for imaging biological
samples such as viruses, cells, and proteins in 3D. A microscope collects a
series of 2D projections of the sample, and the goal is to reconstruct the 3D
density of the sample called the tomogram. This is difficult as the 2D
projections have a missing wedge of information and are noisy. Tomograms
reconstructed with conventional methods, such as filtered back-projection,
suffer from the noise, and from artifacts and anisotropic resolution due to the
missing wedge of information. To improve the visual quality and resolution of
such tomograms, we propose a deep-learning approach for simultaneous denoising
and missing wedge reconstruction called DeepDeWedge. DeepDeWedge is based on
fitting a neural network to the 2D projections with a self-supervised loss
inspired by noise2noise-like methods. The algorithm requires no training or
ground truth data. Experiments on synthetic and real cryo-ET data show that
DeepDeWedge achieves competitive performance for deep learning-based denoising
and missing wedge reconstruction of cryo-ET tomograms.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05540" title="Abstract">arXiv:2311.05540</a> [<a href="/pdf/2311.05540" title="Download PDF">pdf</a>, <a href="/format/2311.05540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Usability and Adoption of Graphical Data-Driven Development Tools
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weber%2C+T">Thomas Weber</a>, 
<a href="/search/cs?searchtype=author&query=Mayer%2C+S">Sven Mayer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Software development of modern, data-driven applications still relies on
tools that use interaction paradigms that have remained mostly unchanged for
decades. While rich forms of interactions exist as an alternative to textual
command input, they find little adoption in professional software creation. In
this work, we compare graphical programming using direct manipulation to the
traditional, textual way of creating data-driven applications to determine the
benefits and drawbacks of each. In a between-subjects user study (N=18), we
compared developing a machine learning architecture with a graphical editor to
traditional code-based development. While qualitative and quantitative measures
show general benefits of graphical direct manipulation, the user's subjective
perception does not always match this. Participants were aware of the possible
benefits of such tools but were still biased in their perception. Our findings
highlight that alternative software creation tools cannot just rely on good
usability but must emphasize the demands of their specific target group, e.g.
user control and flexibility, if they want long-term benefits and adoption.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05545" title="Abstract">arXiv:2311.05545</a> [<a href="/pdf/2311.05545" title="Download PDF">pdf</a>, <a href="/format/2311.05545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extending Regev&#x27;s factoring algorithm to compute discrete logarithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eker%C3%A5%2C+M">Martin Eker&#xe5;</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%A4rtner%2C+J">Joel G&#xe4;rtner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">Regev recently introduced a quantum factoring algorithm that may be perceived
as a $d$-dimensional variation of Shor's factoring algorithm. In this work, we
extend Regev's factoring algorithm to an algorithm for computing discrete
logarithms in a natural way. Furthermore, we discuss natural extensions of
Regev's factoring algorithm to order finding, and to factoring completely via
order finding.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05548" title="Abstract">arXiv:2311.05548</a> [<a href="/pdf/2311.05548" title="Download PDF">pdf</a>, <a href="/format/2311.05548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> L-WaveBlock: A Novel Feature Extractor Leveraging Wavelets for  Generative Adversarial Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shah%2C+M">Mirat Shah</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+V">Vansh Jain</a>, 
<a href="/search/cs?searchtype=author&query=Chokshi%2C+A">Anmol Chokshi</a>, 
<a href="/search/cs?searchtype=author&query=Parasnis%2C+G">Guruprasad Parasnis</a>, 
<a href="/search/cs?searchtype=author&query=Bide%2C+P">Pramod Bide</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 figures, 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Generative Adversarial Networks (GANs) have risen to prominence in the field
of deep learning, facilitating the generation of realistic data from random
noise. The effectiveness of GANs often depends on the quality of feature
extraction, a critical aspect of their architecture. This paper introduces
L-WaveBlock, a novel and robust feature extractor that leverages the
capabilities of the Discrete Wavelet Transform (DWT) with deep learning
methodologies. L-WaveBlock is catered to quicken the convergence of GAN
generators while simultaneously enhancing their performance. The paper
demonstrates the remarkable utility of L-WaveBlock across three datasets, a
road satellite imagery dataset, the CelebA dataset and the GoPro dataset,
showcasing its ability to ease feature extraction and make it more efficient.
By utilizing DWT, L-WaveBlock efficiently captures the intricate details of
both structural and textural details, and further partitions feature maps into
orthogonal subbands across multiple scales while preserving essential
information at the same time. Not only does it lead to faster convergence, but
also gives competent results on every dataset by employing the L-WaveBlock. The
proposed method achieves an Inception Score of 3.6959 and a Structural
Similarity Index of 0.4261 on the maps dataset, a Peak Signal-to-Noise Ratio of
29.05 and a Structural Similarity Index of 0.874 on the CelebA dataset. The
proposed method performs competently to the state-of-the-art for the image
denoising dataset, albeit not better, but still leads to faster convergence
than conventional methods. With this, L-WaveBlock emerges as a robust and
efficient tool for enhancing GAN-based image generation, demonstrating superior
convergence speed and competitive performance across multiple datasets for
image resolution, image generation and image denoising.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05550" title="Abstract">arXiv:2311.05550</a> [<a href="/pdf/2311.05550" title="Download PDF">pdf</a>, <a href="/format/2311.05550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards End-to-End Spoken Grammatical Error Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bann%C3%B2%2C+S">Stefano Bann&#xf2;</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+R">Rao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+M">Mengjie Qian</a>, 
<a href="/search/cs?searchtype=author&query=Knill%2C+K+M">Kate M. Knill</a>, 
<a href="/search/cs?searchtype=author&query=Gales%2C+M+J+F">Mark J.F. Gales</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Grammatical feedback is crucial for L2 learners, teachers, and testers.
Spoken grammatical error correction (GEC) aims to supply feedback to L2
learners on their use of grammar when speaking. This process usually relies on
a cascaded pipeline comprising an ASR system, disfluency removal, and GEC, with
the associated concern of propagating errors between these individual modules.
In this paper, we introduce an alternative "end-to-end" approach to spoken GEC,
exploiting a speech recognition foundation model, Whisper. This foundation
model can be used to replace the whole framework or part of it, e.g., ASR and
disfluency removal. These end-to-end approaches are compared to more standard
cascaded approaches on the data obtained from a free-speaking spoken language
assessment test, Linguaskill. Results demonstrate that end-to-end spoken GEC is
possible within this architecture, but the lack of available data limits
current performance compared to a system using large quantities of text-based
GEC data. Conversely, end-to-end disfluency detection and removal, which is
easier for the attention-based Whisper to learn, does outperform cascaded
approaches. Additionally, the paper discusses the challenges of providing
feedback to candidates when using end-to-end systems for spoken GEC.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05552" title="Abstract">arXiv:2311.05552</a> [<a href="/pdf/2311.05552" title="Download PDF">pdf</a>, <a href="/format/2311.05552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Iron(ic) Melting Pot: Reviewing Human Evaluation in Humour, Irony  and Sarcasm Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Loakman%2C+T">Tyler Loakman</a>, 
<a href="/search/cs?searchtype=author&query=Maladry%2C+A">Aaron Maladry</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chenghua Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Human evaluation is often considered to be the gold standard method of
evaluating a Natural Language Generation system. However, whilst its importance
is accepted by the community at large, the quality of its execution is often
brought into question. In this position paper, we argue that the generation of
more esoteric forms of language - humour, irony and sarcasm - constitutes a
subdomain where the characteristics of selected evaluator panels are of utmost
importance, and every effort should be made to report demographic
characteristics wherever possible, in the interest of transparency and
replicability. We support these claims with an overview of each language form
and an analysis of examples in terms of how their interpretation is affected by
different participant variables. We additionally perform a critical survey of
recent works in NLG to assess how well evaluation procedures are reported in
this subdomain, and note a severe lack of open reporting of evaluator
demographic information, and a significant reliance on crowdsourcing platforms
for recruitment.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05553" title="Abstract">arXiv:2311.05553</a> [<a href="/pdf/2311.05553" title="Download PDF">pdf</a>, <a href="/format/2311.05553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Removing RLHF Protections in GPT-4 via Fine-Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Q">Qiusi Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+R">Richard Fang</a>, 
<a href="/search/cs?searchtype=author&query=Bindu%2C+R">Rohan Bindu</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Akul Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Hashimoto%2C+T">Tatsunori Hashimoto</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+D">Daniel Kang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As large language models (LLMs) have increased in their capabilities, so does
their potential for dual use. To reduce harmful outputs, produces and vendors
of LLMs have used reinforcement learning with human feedback (RLHF). In tandem,
LLM vendors have been increasingly enabling fine-tuning of their most powerful
models. However, concurrent work has shown that fine-tuning can remove RLHF
protections. We may expect that the most powerful models currently available
(GPT-4) are less susceptible to fine-tuning attacks.
<br />In this work, we show the contrary: fine-tuning allows attackers to remove
RLHF protections with as few as 340 examples and a 95% success rate. These
training examples can be automatically generated with weaker models. We further
show that removing RLHF protections does not decrease usefulness on
non-censored outputs, providing evidence that our fine-tuning strategy does not
decrease usefulness despite using weaker models to generate training data. Our
results show the need for further research on protections on LLMs.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05556" title="Abstract">arXiv:2311.05556</a> [<a href="/pdf/2311.05556" title="Download PDF">pdf</a>, <a href="/format/2311.05556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LCM-LoRA: A Universal Stable-Diffusion Acceleration Module
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Simian Luo</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Yiqin Tan</a>, 
<a href="/search/cs?searchtype=author&query=Patil%2C+S">Suraj Patil</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+D">Daniel Gu</a>, 
<a href="/search/cs?searchtype=author&query=von+Platen%2C+P">Patrick von Platen</a>, 
<a href="/search/cs?searchtype=author&query=Passos%2C+A">Apolin&#xe1;rio Passos</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Longbo Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jian Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hang Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Latent Consistency Models (LCMs) have achieved impressive performance in
accelerating text-to-image generative tasks, producing high-quality images with
minimal inference steps. LCMs are distilled from pre-trained latent diffusion
models (LDMs), requiring only ~32 A100 GPU training hours. This report further
extends LCMs' potential in two aspects: First, by applying LoRA distillation to
Stable-Diffusion models including SD-V1.5, SSD-1B, and SDXL, we have expanded
LCM's scope to larger models with significantly less memory consumption,
achieving superior image generation quality. Second, we identify the LoRA
parameters obtained through LCM distillation as a universal Stable-Diffusion
acceleration module, named LCM-LoRA. LCM-LoRA can be directly plugged into
various Stable-Diffusion fine-tuned models or LoRAs without training, thus
representing a universally applicable accelerator for diverse image generation
tasks. Compared with previous numerical PF-ODE solvers such as DDIM,
DPM-Solver, LCM-LoRA can be viewed as a plug-in neural PF-ODE solver that
possesses strong generalization abilities. Project page:
https://github.com/luosiallen/latent-consistency-model.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05557" title="Abstract">arXiv:2311.05557</a> [<a href="/pdf/2311.05557" title="Download PDF">pdf</a>, <a href="/format/2311.05557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Neural-Network Statistics for Low-Power DNN Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bamberg%2C+L">Lennart Bamberg</a>, 
<a href="/search/cs?searchtype=author&query=Najafi%2C+A">Ardalan Najafi</a>, 
<a href="/search/cs?searchtype=author&query=Garcia-Ortiz%2C+A">Alberto Garcia-Ortiz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Specialized compute blocks have been developed for efficient DNN execution.
However, due to the vast amount of data and parameter movements, the
interconnects and on-chip memories form another bottleneck, impairing power and
performance. This work addresses this bottleneck by contributing a low-power
technique for edge-AI inference engines that combines overhead-free coding with
a statistical analysis of the data and parameters of neural networks. Our
approach reduces the interconnect and memory power consumption by up to 80% for
state-of-the-art benchmarks while providing additional power savings for the
compute blocks by up to 39%. These power improvements are achieved with no loss
of accuracy and negligible hardware cost.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05562" title="Abstract">arXiv:2311.05562</a> [<a href="/pdf/2311.05562" title="Download PDF">pdf</a>, <a href="/format/2311.05562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Human Legibility in Collaborative Robot Tasks through  Augmented Reality and Workspace Preparation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tung%2C+Y">Yi-Shiuan Tung</a>, 
<a href="/search/cs?searchtype=author&query=Luebbers%2C+M+B">Matthew B. Luebbers</a>, 
<a href="/search/cs?searchtype=author&query=Roncone%2C+A">Alessandro Roncone</a>, 
<a href="/search/cs?searchtype=author&query=Hayes%2C+B">Bradley Hayes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6th International Workshop on Virtual, Augmented, and Mixed-Reality for Human-Robot Interactions (VAM-HRI)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Understanding the intentions of human teammates is critical for safe and
effective human-robot interaction. The canonical approach for human-aware robot
motion planning is to first predict the human's goal or path, and then
construct a robot plan that avoids collision with the human. This method can
generate unsafe interactions if the human model and subsequent predictions are
inaccurate. In this work, we present an algorithmic approach for both arranging
the configuration of objects in a shared human-robot workspace, and projecting
``virtual obstacles'' in augmented reality, optimizing for legibility in a
given task. These changes to the workspace result in more legible human
behavior, improving robot predictions of human goals, thereby improving task
fluency and safety. To evaluate our approach, we propose two user studies
involving a collaborative tabletop task with a manipulator robot, and a
warehouse navigation task with a mobile robot.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05565" title="Abstract">arXiv:2311.05565</a> [<a href="/pdf/2311.05565" title="Download PDF">pdf</a>, <a href="/format/2311.05565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Performance Transformers for Table Structure Recognition Need Early  Convolutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">ShengYun Peng</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seongmin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaojing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Balasubramaniyan%2C+R">Rajarajeswari Balasubramaniyan</a>, 
<a href="/search/cs?searchtype=author&query=Chau%2C+D+H">Duen Horng Chau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Table Representation Learning Workshop at NeurIPS 2023 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Table structure recognition (TSR) aims to convert tabular images into a
machine-readable format, where a visual encoder extracts image features and a
textual decoder generates table-representing tokens. Existing approaches use
classic convolutional neural network (CNN) backbones for the visual encoder and
transformers for the textual decoder. However, this hybrid CNN-Transformer
architecture introduces a complex visual encoder that accounts for nearly half
of the total model parameters, markedly reduces both training and inference
speed, and hinders the potential for self-supervised learning in TSR. In this
work, we design a lightweight visual encoder for TSR without sacrificing
expressive power. We discover that a convolutional stem can match classic CNN
backbone performance, with a much simpler model. The convolutional stem strikes
an optimal balance between two crucial factors for high-performance TSR: a
higher receptive field (RF) ratio and a longer sequence length. This allows it
to "see" an appropriate portion of the table and "store" the complex table
structure within sufficient context length for the subsequent transformer. We
conducted reproducible ablation studies and open-sourced our code at
https://github.com/poloclub/tsr-convstem to enhance transparency, inspire
innovations, and facilitate fair comparisons in our domain as tables are a
promising modality for representation learning.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05567" title="Abstract">arXiv:2311.05567</a> [<a href="/pdf/2311.05567" title="Download PDF">pdf</a>, <a href="/format/2311.05567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Emotion Expression Recognition in Older Adults Interacting  with a Virtual Coach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Palmero%2C+C">Cristina Palmero</a>, 
<a href="/search/cs?searchtype=author&query=deVelasco%2C+M">Mikel deVelasco</a>, 
<a href="/search/cs?searchtype=author&query=Hmani%2C+M+A">Mohamed Amine Hmani</a>, 
<a href="/search/cs?searchtype=author&query=Mtibaa%2C+A">Aymen Mtibaa</a>, 
<a href="/search/cs?searchtype=author&query=Letaifa%2C+L+B">Leila Ben Letaifa</a>, 
<a href="/search/cs?searchtype=author&query=Buch-Cardona%2C+P">Pau Buch-Cardona</a>, 
<a href="/search/cs?searchtype=author&query=Justo%2C+R">Raquel Justo</a>, 
<a href="/search/cs?searchtype=author&query=Amorese%2C+T">Terry Amorese</a>, 
<a href="/search/cs?searchtype=author&query=Gonz%C3%A1lez-Fraile%2C+E">Eduardo Gonz&#xe1;lez-Fraile</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez-Ruanova%2C+B">Bego&#xf1;a Fern&#xe1;ndez-Ruanova</a>, 
<a href="/search/cs?searchtype=author&query=Tenorio-Laranga%2C+J">Jofre Tenorio-Laranga</a>, 
<a href="/search/cs?searchtype=author&query=Johansen%2C+A+T">Anna Torp Johansen</a>, 
<a href="/search/cs?searchtype=author&query=da+Silva%2C+M+R">Micaela Rodrigues da Silva</a>, 
<a href="/search/cs?searchtype=author&query=Martinussen%2C+L+J">Liva Jenny Martinussen</a>, 
<a href="/search/cs?searchtype=author&query=Korsnes%2C+M+S">Maria Stylianou Korsnes</a>, 
<a href="/search/cs?searchtype=author&query=Cordasco%2C+G">Gennaro Cordasco</a>, 
<a href="/search/cs?searchtype=author&query=Esposito%2C+A">Anna Esposito</a>, 
<a href="/search/cs?searchtype=author&query=El-Yacoubi%2C+M+A">Mounim A. El-Yacoubi</a>, 
<a href="/search/cs?searchtype=author&query=Petrovska-Delacr%C3%A9taz%2C+D">Dijana Petrovska-Delacr&#xe9;taz</a>, 
<a href="/search/cs?searchtype=author&query=Torres%2C+M+I">M. In&#xe9;s Torres</a>, 
<a href="/search/cs?searchtype=author&query=Escalera%2C+S">Sergio Escalera</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">The EMPATHIC project aimed to design an emotionally expressive virtual coach
capable of engaging healthy seniors to improve well-being and promote
independent aging. One of the core aspects of the system is its human sensing
capabilities, allowing for the perception of emotional states to provide a
personalized experience. This paper outlines the development of the emotion
expression recognition module of the virtual coach, encompassing data
collection, annotation design, and a first methodological approach, all
tailored to the project requirements. With the latter, we investigate the role
of various modalities, individually and combined, for discrete emotion
expression recognition in this context: speech from audio, and facial
expressions, gaze, and head dynamics from video. The collected corpus includes
users from Spain, France, and Norway, and was annotated separately for the
audio and video channels with distinct emotional labels, allowing for a
performance comparison across cultures and label types. Results confirm the
informative power of the modalities studied for the emotional categories
considered, with multimodal methods generally outperforming others (around 68%
accuracy with audio labels and 72-74% with video labels). The findings are
expected to contribute to the limited literature on emotion recognition applied
to older adults in conversational human-machine interaction.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05579" title="Abstract">arXiv:2311.05579</a> [<a href="/pdf/2311.05579" title="Download PDF">pdf</a>, <a href="/format/2311.05579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SigScatNet: A Siamese + Scattering based Deep Learning Approach for  Signature Forgery Detection and Similarity Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chokshi%2C+A">Anmol Chokshi</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+V">Vansh Jain</a>, 
<a href="/search/cs?searchtype=author&query=Bhope%2C+R">Rajas Bhope</a>, 
<a href="/search/cs?searchtype=author&query=Dhage%2C+S">Sudhir Dhage</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">The surge in counterfeit signatures has inflicted widespread inconveniences
and formidable challenges for both individuals and organizations. This
groundbreaking research paper introduces SigScatNet, an innovative solution to
combat this issue by harnessing the potential of a Siamese deep learning
network, bolstered by Scattering wavelets, to detect signature forgery and
assess signature similarity. The Siamese Network empowers us to ascertain the
authenticity of signatures through a comprehensive similarity index, enabling
precise validation and comparison. Remarkably, the integration of Scattering
wavelets endows our model with exceptional efficiency, rendering it light
enough to operate seamlessly on cost-effective hardware systems. To validate
the efficacy of our approach, extensive experimentation was conducted on two
open-sourced datasets: the ICDAR SigComp Dutch dataset and the CEDAR dataset.
The experimental results demonstrate the practicality and resounding success of
our proposed SigScatNet, yielding an unparalleled Equal Error Rate of 3.689%
with the ICDAR SigComp Dutch dataset and an astonishing 0.0578% with the CEDAR
dataset. Through the implementation of SigScatNet, our research spearheads a
new state-of-the-art in signature analysis in terms of EER scores and
computational efficiency, offering an advanced and accessible solution for
detecting forgery and quantifying signature similarities. By employing
cutting-edge Siamese deep learning and Scattering wavelets, we provide a robust
framework that paves the way for secure and efficient signature verification
systems.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05580" title="Abstract">arXiv:2311.05580</a> [<a href="/pdf/2311.05580" title="Download PDF">pdf</a>, <a href="/format/2311.05580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inference for Probabilistic Dependency Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Richardson%2C+O+E">Oliver E. Richardson</a>, 
<a href="/search/cs?searchtype=author&query=Halpern%2C+J+Y">Joseph Y. Halpern</a>, 
<a href="/search/cs?searchtype=author&query=De+Sa%2C+C">Christopher De Sa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> extended version of the paper with corrected reduction proof
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> PMLR 216:1741-1751, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Artificial Intelligence (cs.AI); Computational Complexity (cs.CC); Probability (math.PR)

</div>
<p class="mathjax">Probabilistic dependency graphs (PDGs) are a flexible class of probabilistic
graphical models, subsuming Bayesian Networks and Factor Graphs. They can also
capture inconsistent beliefs, and provide a way of measuring the degree of this
inconsistency. We present the first tractable inference algorithm for PDGs with
discrete variables, making the asymptotic complexity of PDG inference similar
that of the graphical models they generalize. The key components are: (1) the
observation that, in many cases, the distribution a PDG specifies can be
formulated as a convex optimization problem (with exponential cone
constraints), (2) a construction that allows us to express these problems
compactly for PDGs of boundeed treewidth, (3) contributions to the theory of
PDGs that justify the construction, and (4) an appeal to interior point methods
that can solve such problems in polynomial time. We verify the correctness and
complexity of our approach, and provide an implementation of it. We then
evaluate our implementation, and demonstrate that it outperforms baseline
approaches. Our code is available at
<a href="http://github.com/orichardson/pdg-infer-uai.">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05582" title="Abstract">arXiv:2311.05582</a> [<a href="/pdf/2311.05582" title="Download PDF">pdf</a>, <a href="/format/2311.05582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint SDN Synchronization and Controller Placement in Wireless Networks  using Deep Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mudvari%2C+A">Akrit Mudvari</a>, 
<a href="/search/cs?searchtype=author&query=Tassiulas%2C+L">Leandros Tassiulas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE NOMS'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Software Defined Networking has afforded numerous benefits to the network
users but there are certain persisting issues with this technology, two of
which are scalability and privacy. The natural solution to overcoming these
limitations is a distributed SDN controller architecture where multiple
controllers are deployed over the network, with each controller orchestrating a
certain segment of the network. However, since the centralized control is the
key attribute of SDN that allows it to be so beneficial, a centralized logical
view of the network will have to be maintained by each of these controllers;
this can be done through synchronization of the distributed controllers, where
each controller communicates with the others to ensure that they remain
informed about the entire network. There is however a network cost associated
with constantly having to update each others about different aspects of the
network, which will become a greater issue in dynamic wireless networks. To
minimize this network cost, there is a need to consider not only when to get
the update information from the neighboring controllers, but also where to
dynamically place the controllers such that the network costs may be minimized.
The placement should take into consideration both communication for
synchronization among the distributed controllers and communication of the
controllers with the network devices that they manage. In this work, we show
that our multi-objective deep reinforcement learning-based method performs the
best at achieving different application goals by developing policy for
controller synchronization as well as placement, outperforming different other
possible approaches, under a wide variety of network conditions.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05584" title="Abstract">arXiv:2311.05584</a> [<a href="/pdf/2311.05584" title="Download PDF">pdf</a>, <a href="/format/2311.05584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot Goal-Directed Dialogue via RL on Imagined Conversations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+J">Joey Hong</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+S">Sergey Levine</a>, 
<a href="/search/cs?searchtype=author&query=Dragan%2C+A">Anca Dragan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Large language models (LLMs) have emerged as powerful and general solutions
to many natural language tasks. However, many of the most important
applications of language generation are interactive, where an agent has to talk
to a person to reach a desired outcome. For example, a teacher might try to
understand their student's current comprehension level to tailor their
instruction accordingly, and a travel agent might ask questions of their
customer to understand their preferences in order to recommend activities they
might enjoy. LLMs trained with supervised fine-tuning or "single-step" RL, as
with standard RLHF, might struggle which tasks that require such goal-directed
behavior, since they are not trained to optimize for overall conversational
outcomes after multiple turns of interaction. In this work, we explore a new
method for adapting LLMs with RL for such goal-directed dialogue. Our key
insight is that, though LLMs might not effectively solve goal-directed dialogue
tasks out of the box, they can provide useful data for solving such tasks by
simulating suboptimal but human-like behaviors. Given a textual description of
a goal-directed dialogue task, we leverage LLMs to sample diverse synthetic
rollouts of hypothetical in-domain human-human interactions. Our algorithm then
utilizes this dataset with offline reinforcement learning to train an
interactive conversational agent that can optimize goal-directed objectives
over multiple turns. In effect, the LLM produces examples of possible
interactions, and RL then processes these examples to learn to perform more
optimal interactions. Empirically, we show that our proposed approach achieves
state-of-the-art performance in various goal-directed dialogue tasks that
include teaching and preference elicitation.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05587" title="Abstract">arXiv:2311.05587</a> [<a href="/pdf/2311.05587" title="Download PDF">pdf</a>, <a href="/ps/2311.05587" title="Download PostScript">ps</a>, <a href="/format/2311.05587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Methods for Media Mix Modelling with shape and funnel effects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marin%2C+J">Javier Marin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In recent years, significant progress in generative AI has highlighted the
important role of physics-inspired models that utilize advanced mathematical
concepts based on fundamental physics principles to enhance artificial
intelligence capabilities. Among these models, those based on diffusion
equations have greatly improved image quality. This study aims to explore the
potential uses of Maxwell-Boltzmann equation, which forms the basis of the
kinetic theory of gases, and the Michaelis-Menten model in Marketing Mix
Modelling (MMM) applications. We propose incorporating these equations into
Hierarchical Bayesian models to analyse consumer behaviour in the context of
advertising. These equation sets excel in accurately describing the random
dynamics in complex systems like social interactions and consumer-advertising
interactions.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05589" title="Abstract">arXiv:2311.05589</a> [<a href="/pdf/2311.05589" title="Download PDF">pdf</a>, <a href="/format/2311.05589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Coefficient Makes SVRG Effective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yida Yin</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhiqiu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Darrell%2C+T">Trevor Darrell</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhuang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">Stochastic Variance Reduced Gradient (SVRG), introduced by Johnson &amp; Zhang
(2013), is a theoretically compelling optimization method. However, as Defazio
&amp; Bottou (2019) highlights, its effectiveness in deep learning is yet to be
proven. In this work, we demonstrate the potential of SVRG in optimizing
real-world neural networks. Our analysis finds that, for deeper networks, the
strength of the variance reduction term in SVRG should be smaller and decrease
as training progresses. Inspired by this, we introduce a multiplicative
coefficient $\alpha$ to control the strength and adjust it through a linear
decay schedule. We name our method $\alpha$-SVRG. Our results show
$\alpha$-SVRG better optimizes neural networks, consistently reducing training
loss compared to both baseline and the standard SVRG across various
architectures and image classification datasets. We hope our findings encourage
further exploration into variance reduction techniques in deep learning. Code
is available at https://github.com/davidyyd/alpha-SVRG.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05590" title="Abstract">arXiv:2311.05590</a> [<a href="/pdf/2311.05590" title="Download PDF">pdf</a>, <a href="/format/2311.05590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conversational AI Threads for Visualizing Multidimensional Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+M">Matt-Heun Hong</a>, 
<a href="/search/cs?searchtype=author&query=Crisan%2C+A">Anamaria Crisan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generative Large Language Models (LLMs) show potential in data analysis, yet
their full capabilities remain uncharted. Our work explores the capabilities of
LLMs for creating and refining visualizations via conversational interfaces. We
used an LLM to conduct a re-analysis of a prior Wizard-of-Oz study examining
the use of chatbots for conducting visual analysis. We surfaced the strengths
and weaknesses of LLM-driven analytic chatbots, finding that they fell short in
supporting progressive visualization refinements. From these findings, we
developed AI Threads, a multi-threaded analytic chatbot that enables analysts
to proactively manage conversational context and improve the efficacy of its
outputs. We evaluate its usability through a crowdsourced study (n=40) and
in-depth interviews with expert analysts (n=10). We further demonstrate the
capabilities of AI Threads on a dataset outside the LLM's training corpus. Our
findings show the potential of LLMs while also surfacing challenges and
fruitful avenues for future research.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05591" title="Abstract">arXiv:2311.05591</a> [<a href="/pdf/2311.05591" title="Download PDF">pdf</a>, <a href="/ps/2311.05591" title="Download PostScript">ps</a>, <a href="/format/2311.05591" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accuracy of a Vision-Language Model on Challenging Medical Cases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Buckley%2C+T">Thomas Buckley</a>, 
<a href="/search/cs?searchtype=author&query=Diao%2C+J+A">James A. Diao</a>, 
<a href="/search/cs?searchtype=author&query=Rodman%2C+A">Adam Rodman</a>, 
<a href="/search/cs?searchtype=author&query=Manrai%2C+A+K">Arjun K. Manrai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Background: General-purpose large language models that utilize both text and
images have not been evaluated on a diverse array of challenging medical cases.
<br />Methods: Using 934 cases from the NEJM Image Challenge published between 2005
and 2023, we evaluated the accuracy of the recently released Generative
Pre-trained Transformer 4 with Vision model (GPT-4V) compared to human
respondents overall and stratified by question difficulty, image type, and skin
tone. We further conducted a physician evaluation of GPT-4V on 69 NEJM
clinicopathological conferences (CPCs). Analyses were conducted for models
utilizing text alone, images alone, and both text and images.
<br />Results: GPT-4V achieved an overall accuracy of 61% (95% CI, 58 to 64%)
compared to 49% (95% CI, 49 to 50%) for humans. GPT-4V outperformed humans at
all levels of difficulty and disagreement, skin tones, and image types; the
exception was radiographic images, where performance was equivalent between
GPT-4V and human respondents. Longer, more informative captions were associated
with improved performance for GPT-4V but similar performance for human
respondents. GPT-4V included the correct diagnosis in its differential for 80%
(95% CI, 68 to 88%) of CPCs when using text alone, compared to 58% (95% CI, 45
to 70%) of CPCs when using both images and text.
<br />Conclusions: GPT-4V outperformed human respondents on challenging medical
cases and was able to synthesize information from both images and text, but
performance deteriorated when images were added to highly informative text.
Overall, our results suggest that multimodal AI models may be useful in medical
diagnostic reasoning but that their accuracy may depend heavily on context.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05596" title="Abstract">arXiv:2311.05596</a> [<a href="/pdf/2311.05596" title="Download PDF">pdf</a>, <a href="/format/2311.05596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM Augmented Hierarchical Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prakash%2C+B">Bharat Prakash</a>, 
<a href="/search/cs?searchtype=author&query=Oates%2C+T">Tim Oates</a>, 
<a href="/search/cs?searchtype=author&query=Mohsenin%2C+T">Tinoosh Mohsenin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Solving long-horizon, temporally-extended tasks using Reinforcement Learning
(RL) is challenging, compounded by the common practice of learning without
prior knowledge (or tabula rasa learning). Humans can generate and execute
plans with temporally-extended actions and quickly learn to perform new tasks
because we almost never solve problems from scratch. We want autonomous agents
to have this same ability. Recently, LLMs have been shown to encode a
tremendous amount of knowledge about the world and to perform impressive
in-context learning and reasoning. However, using LLMs to solve real world
problems is hard because they are not grounded in the current task. In this
paper we exploit the planning capabilities of LLMs while using RL to provide
learning from the environment, resulting in a hierarchical agent that uses LLMs
to solve long-horizon tasks. Instead of completely relying on LLMs, they guide
a high-level policy, making learning significantly more sample efficient. This
approach is evaluated in simulation environments such as MiniGrid, SkillHack,
and Crafter, and on a real robot arm in block manipulation tasks. We show that
agents trained using our approach outperform other baselines methods and, once
trained, don't need access to LLMs during deployment.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05598" title="Abstract">arXiv:2311.05598</a> [<a href="/pdf/2311.05598" title="Download PDF">pdf</a>, <a href="/format/2311.05598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sorting Out Quantum Monte Carlo
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Richter-Powell%2C+J">Jack Richter-Powell</a>, 
<a href="/search/cs?searchtype=author&query=Thiede%2C+L">Luca Thiede</a>, 
<a href="/search/cs?searchtype=author&query=Asparu-Guzik%2C+A">Al&#xe1;n Asparu-Guzik</a>, 
<a href="/search/cs?searchtype=author&query=Duvenaud%2C+D">David Duvenaud</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Chemical Physics (physics.chem-ph); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Molecular modeling at the quantum level requires choosing a parameterization
of the wavefunction that both respects the required particle symmetries, and is
scalable to systems of many particles. For the simulation of fermions, valid
parameterizations must be antisymmetric with respect to the exchange of
particles. Typically, antisymmetry is enforced by leveraging the anti-symmetry
of determinants with respect to the exchange of matrix rows, but this involves
computing a full determinant each time the wavefunction is evaluated. Instead,
we introduce a new antisymmetrization layer derived from sorting, the
$\textit{sortlet}$, which scales as $O(N \log N)$ with regards to the number of
particles -- in contrast to $O(N^3)$ for the determinant. We show numerically
that applying this anti-symmeterization layer on top of an attention based
neural-network backbone yields a flexible wavefunction parameterization capable
of reaching chemical accuracy when approximating the ground state of first-row
atoms and small molecules.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05599" title="Abstract">arXiv:2311.05599</a> [<a href="/pdf/2311.05599" title="Download PDF">pdf</a>, <a href="/format/2311.05599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SynH2R: Synthesizing Hand-Object Motions for Learning Human-to-Robot  Handovers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Christen%2C+S">Sammy Christen</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+L">Lan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chao%2C+Y">Yu-Wei Chao</a>, 
<a href="/search/cs?searchtype=author&query=Hilliges%2C+O">Otmar Hilliges</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jie Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Vision-based human-to-robot handover is an important and challenging task in
human-robot interaction. Recent work has attempted to train robot policies by
interacting with dynamic virtual humans in simulated environments, where the
policies can later be transferred to the real world. However, a major
bottleneck is the reliance on human motion capture data, which is expensive to
acquire and difficult to scale to arbitrary objects and human grasping motions.
In this paper, we introduce a framework that can generate plausible human
grasping motions suitable for training the robot. To achieve this, we propose a
hand-object synthesis method that is designed to generate handover-friendly
motions similar to humans. This allows us to generate synthetic training and
testing data with 100x more objects than previous work. In our experiments, we
show that our method trained purely with synthetic data is competitive with
state-of-the-art methods that rely on real human motion data both in simulation
and on a real system. In addition, we can perform evaluations on a larger scale
compared to prior work. With our newly introduced test set, we show that our
model can better scale to a large variety of unseen objects and human motions
compared to the baselines. Project page:
https://eth-ait.github.io/synthetic-handovers/
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05600" title="Abstract">arXiv:2311.05600</a> [<a href="/pdf/2311.05600" title="Download PDF">pdf</a>, <a href="/format/2311.05600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FogROS2-Sky: Optimizing Latency and Cost for Multi-Cloud Robot  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kaiyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hari%2C+K">Kush Hari</a>, 
<a href="/search/cs?searchtype=author&query=Khare%2C+R">Rohil Khare</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+C">Charlotte Le</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+T">Trinity Chung</a>, 
<a href="/search/cs?searchtype=author&query=Drake%2C+J">Jaimyn Drake</a>, 
<a href="/search/cs?searchtype=author&query=Dharmarajan%2C+K">Karthik Dharmarajan</a>, 
<a href="/search/cs?searchtype=author&query=Adebola%2C+S">Simeon Adebola</a>, 
<a href="/search/cs?searchtype=author&query=Ichnowski%2C+J">Jeffrey Ichnowski</a>, 
<a href="/search/cs?searchtype=author&query=Kubiatowicz%2C+J">John Kubiatowicz</a>, 
<a href="/search/cs?searchtype=author&query=Goldberg%2C+K">Ken Goldberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper studies the cost-performance tradeoffs in cloud robotics with
heterogeneous cloud service providers, which have complex pricing models and
varying application requirements. We present FogROS2-Sky, a cost-efficient open
source robotics platform that offloads unmodified ROS2 applications to multiple
cloud providers and enables fine-grained cost analysis for ROS2 applications'
communication with multiple cloud providers. As each provider offers different
options for CPU, GPU, memory, and latency, it can be very difficult for users
to decide which to choose. FogROS2-Sky includes an optimization algorithm,
which either finds the best available hardware specification that fulfills the
user's latency and cost constraints or reports that such a specification does
not exist. We use FogROS2-Sky to perform time-cost analysis on three robotics
applications: visual SLAM, grasp planning, and motion planning. We are able to
sample different hardware setups at nearly half the cost while still create
cost and latency functions suitable for the optimizer. We also evaluate the
optimizer's efficacy for these applications with the Pareto frontier and show
that the optimizer selects efficient hardware configurations to balance cost
and latency. Videos and code are available on the website
https://sites.google.com/view/fogros2-sky
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05601" title="Abstract">arXiv:2311.05601</a> [<a href="/pdf/2311.05601" title="Download PDF">pdf</a>, <a href="/format/2311.05601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FAMuS: Frames Across Multiple Sources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vashishtha%2C+S">Siddharth Vashishtha</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+A">Alexander Martin</a>, 
<a href="/search/cs?searchtype=author&query=Gantt%2C+W">William Gantt</a>, 
<a href="/search/cs?searchtype=author&query=Van+Durme%2C+B">Benjamin Van Durme</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+A+S">Aaron Steven White</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Understanding event descriptions is a central aspect of language processing,
but current approaches focus overwhelmingly on single sentences or documents.
Aggregating information about an event \emph{across documents} can offer a much
richer understanding. To this end, we present FAMuS, a new corpus of Wikipedia
passages that \emph{report} on some event, paired with underlying,
genre-diverse (non-Wikipedia) \emph{source} articles for the same event. Events
and (cross-sentence) arguments in both report and source are annotated against
FrameNet, providing broad coverage of different event types. We present results
on two key event understanding tasks enabled by FAMuS: \emph{source validation}
-- determining whether a document is a valid source for a target report event
-- and \emph{cross-document argument extraction} -- full-document argument
extraction for a target event from both its report and the correct source
article. We release both FAMuS and our models to support further research.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05602" title="Abstract">arXiv:2311.05602</a> [<a href="/pdf/2311.05602" title="Download PDF">pdf</a>, <a href="/format/2311.05602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconstructing Objects in-the-wild for Realistic Sensor Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Ze Yang</a>, 
<a href="/search/cs?searchtype=author&query=Manivasagam%2C+S">Sivabalan Manivasagam</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingkang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+R">Rui Hu</a>, 
<a href="/search/cs?searchtype=author&query=Urtasun%2C+R">Raquel Urtasun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICRA 2023. Project page: <a href="https://waabi.ai/neusim/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Reconstructing objects from real world data and rendering them at novel views
is critical to bringing realism, diversity and scale to simulation for robotics
training and testing. In this work, we present NeuSim, a novel approach that
estimates accurate geometry and realistic appearance from sparse in-the-wild
data captured at distance and at limited viewpoints. Towards this goal, we
represent the object surface as a neural signed distance function and leverage
both LiDAR and camera sensor data to reconstruct smooth and accurate geometry
and normals. We model the object appearance with a robust physics-inspired
reflectance representation effective for in-the-wild data. Our experiments show
that NeuSim has strong view synthesis performance on challenging scenarios with
sparse training views. Furthermore, we showcase composing NeuSim assets into a
virtual world and generating realistic multi-sensor data for evaluating
self-driving perception models.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05604" title="Abstract">arXiv:2311.05604</a> [<a href="/pdf/2311.05604" title="Download PDF">pdf</a>, <a href="/format/2311.05604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D-QAE: Fully Quantum Auto-Encoding of 3D Point Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rathi%2C+L">Lakshika Rathi</a>, 
<a href="/search/cs?searchtype=author&query=Tretschk%2C+E">Edith Tretschk</a>, 
<a href="/search/cs?searchtype=author&query=Theobalt%2C+C">Christian Theobalt</a>, 
<a href="/search/cs?searchtype=author&query=Dabral%2C+R">Rishabh Dabral</a>, 
<a href="/search/cs?searchtype=author&query=Golyanik%2C+V">Vladislav Golyanik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 11 figures, 5 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> British Machine Vision Conference (BMVC) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing methods for learning 3D representations are deep neural networks
trained and tested on classical hardware. Quantum machine learning
architectures, despite their theoretically predicted advantages in terms of
speed and the representational capacity, have so far not been considered for
this problem nor for tasks involving 3D data in general. This paper thus
introduces the first quantum auto-encoder for 3D point clouds. Our 3D-QAE
approach is fully quantum, i.e. all its data processing components are designed
for quantum hardware. It is trained on collections of 3D point clouds to
produce their compressed representations. Along with finding a suitable
architecture, the core challenges in designing such a fully quantum model
include 3D data normalisation and parameter optimisation, and we propose
solutions for both these tasks. Experiments on simulated gate-based quantum
hardware demonstrate that our method outperforms simple classical baselines,
paving the way for a new research direction in 3D computer vision. The source
code is available at https://4dqv.mpi-inf.mpg.de/QAE3D/.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05606" title="Abstract">arXiv:2311.05606</a> [<a href="/pdf/2311.05606" title="Download PDF">pdf</a>, <a href="/format/2311.05606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion-Generative Multi-Fidelity Learning for Physical Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shibo Li</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+S">Shikai Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhe%2C+S">Shandian Zhe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Multi-fidelity surrogate learning is important for physical simulation
related applications in that it avoids running numerical solvers from scratch,
which is known to be costly, and it uses multi-fidelity examples for training
and greatly reduces the cost of data collection. Despite the variety of
existing methods, they all build a model to map the input parameters outright
to the solution output. Inspired by the recent breakthrough in generative
models, we take an alternative view and consider the solution output as
generated from random noises. We develop a diffusion-generative multi-fidelity
(DGMF) learning method based on stochastic differential equations (SDE), where
the generation is a continuous denoising process. We propose a conditional
score model to control the solution generation by the input parameters and the
fidelity. By conditioning on additional inputs (temporal or spacial variables),
our model can efficiently learn and predict multi-dimensional solution arrays.
Our method naturally unifies discrete and continuous fidelity modeling. The
advantage of our method in several typical applications shows a promising new
direction for multi-fidelity learning.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05607" title="Abstract">arXiv:2311.05607</a> [<a href="/pdf/2311.05607" title="Download PDF">pdf</a>, <a href="/format/2311.05607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-Time Neural Rasterization for Large Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J+Y">Jeffrey Yunfan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Ze Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingkang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Manivasagam%2C+S">Sivabalan Manivasagam</a>, 
<a href="/search/cs?searchtype=author&query=Urtasun%2C+R">Raquel Urtasun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in ICCV 2023. webpage: <a href="https://waabi.ai/NeuRas/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">We propose a new method for realistic real-time novel-view synthesis (NVS) of
large scenes. Existing neural rendering methods generate realistic results, but
primarily work for small scale scenes (&lt;50 square meters) and have difficulty
at large scale (&gt;10000 square meters). Traditional graphics-based rasterization
rendering is fast for large scenes but lacks realism and requires expensive
manually created assets. Our approach combines the best of both worlds by
taking a moderate-quality scaffold mesh as input and learning a neural texture
field and shader to model view-dependant effects to enhance realism, while
still using the standard graphics pipeline for real-time rendering. Our method
outperforms existing neural rendering methods, providing at least 30x faster
rendering with comparable or better realism for large self-driving and drone
scenes. Our work is the first to enable real-time rendering of large real-world
scenes.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05608" title="Abstract">arXiv:2311.05608</a> [<a href="/pdf/2311.05608" title="Download PDF">pdf</a>, <a href="/format/2311.05608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FigStep: Jailbreaking Large Vision-language Models via Typographic  Visual Prompts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yichen Gong</a>, 
<a href="/search/cs?searchtype=author&query=Ran%2C+D">Delong Ran</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Conglei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cong%2C+T">Tianshuo Cong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Anyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+S">Sisi Duan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoyun Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Large vision-language models (VLMs) like GPT-4V represent an unprecedented
revolution in the field of artificial intelligence (AI). Compared to
single-modal large language models (LLMs), VLMs possess more versatile
capabilities by incorporating additional modalities (e.g., images). Meanwhile,
there's a rising enthusiasm in the AI community to develop open-source VLMs,
such as LLaVA and MiniGPT4, which, however, have not undergone rigorous safety
assessment. In this paper, to demonstrate that more modalities lead to
unforeseen AI safety issues, we propose FigStep, a novel jailbreaking framework
against VLMs. FigStep feeds harmful instructions into VLMs through the image
channel and then uses benign text prompts to induce VLMs to output contents
that violate common AI safety policies. Our experimental results show that
FigStep can achieve an average attack success rate of 94.8% across 2 families
of popular open-source VLMs, LLaVA and MiniGPT4 (a total of 5 VLMs). Moreover,
we demonstrate that the methodology of FigStep can even jailbreak GPT-4V, which
already leverages several system-level mechanisms to filter harmful queries.
Above all, our experimental results reveal that VLMs are vulnerable to
jailbreaking attacks, which highlights the necessity of novel safety alignments
between visual and textual modalities.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05609" title="Abstract">arXiv:2311.05609</a> [<a href="/pdf/2311.05609" title="Download PDF">pdf</a>, <a href="/format/2311.05609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Do I Hear? Generating Sounds for Visuals with ChatGPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+D+C">David Chuan-En Lin</a>, 
<a href="/search/cs?searchtype=author&query=Martelaro%2C+N">Nikolas Martelaro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Demo: <a href="http://soundify.cc">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This short paper introduces a workflow for generating realistic soundscapes
for visual media. In contrast to prior work, which primarily focus on matching
sounds for on-screen visuals, our approach extends to suggesting sounds that
may not be immediately visible but are essential to crafting a convincing and
immersive auditory environment. Our key insight is leveraging the reasoning
capabilities of language models, such as ChatGPT. In this paper, we describe
our workflow, which includes creating a scene context, brainstorming sounds,
and generating the sounds.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05610" title="Abstract">arXiv:2311.05610</a> [<a href="/pdf/2311.05610" title="Download PDF">pdf</a>, <a href="/format/2311.05610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Parallelization Layouts for Large-Scale Distributed Model  Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hagemann%2C+J">Johannes Hagemann</a>, 
<a href="/search/cs?searchtype=author&query=Weinbach%2C+S">Samuel Weinbach</a>, 
<a href="/search/cs?searchtype=author&query=Dobler%2C+K">Konstantin Dobler</a>, 
<a href="/search/cs?searchtype=author&query=Schall%2C+M">Maximilian Schall</a>, 
<a href="/search/cs?searchtype=author&query=de+Melo%2C+G">Gerard de Melo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Efficiently training large language models requires parallelizing across
hundreds of hardware accelerators and invoking various compute and memory
optimizations. When combined, many of these strategies have complex
interactions regarding the final training efficiency. Prior work tackling this
problem did not have access to the latest set of optimizations, such as
FlashAttention or sequence parallelism. In this work, we conduct a
comprehensive ablation study of possible training configurations for large
language models. We distill this large study into several key recommendations
for the most efficient training. For instance, we find that using a micro-batch
size of 1 usually enables the most efficient training layouts. Larger
micro-batch sizes necessitate activation checkpointing or higher degrees of
model parallelism and also lead to larger pipeline bubbles. Our most efficient
configurations enable us to achieve state-of-the-art training efficiency
results over a range of model sizes, most notably a Model FLOPs utilization of
70.5% when training a 13B model.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05613" title="Abstract">arXiv:2311.05613</a> [<a href="/pdf/2311.05613" title="Download PDF">pdf</a>, <a href="/format/2311.05613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Window Attention is Bugged: How not to Interpolate Position Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bolya%2C+D">Daniel Bolya</a>, 
<a href="/search/cs?searchtype=author&query=Ryali%2C+C">Chaitanya Ryali</a>, 
<a href="/search/cs?searchtype=author&query=Hoffman%2C+J">Judy Hoffman</a>, 
<a href="/search/cs?searchtype=author&query=Feichtenhofer%2C+C">Christoph Feichtenhofer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. Code release will be coming in the future
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Window attention, position embeddings, and high resolution finetuning are
core concepts in the modern transformer era of computer vision. However, we
find that naively combining these near ubiquitous components can have a
detrimental effect on performance. The issue is simple: interpolating position
embeddings while using window attention is wrong. We study two state-of-the-art
methods that have these three components, namely Hiera and ViTDet, and find
that both do indeed suffer from this bug. To fix it, we introduce a simple
absolute window position embedding strategy, which solves the bug outright in
Hiera and allows us to increase both speed and performance of the model in
ViTDet. We finally combine the two to obtain HieraDet, which achieves 61.7 box
mAP on COCO, making it state-of-the-art for models that only use ImageNet-1k
pretraining. This all stems from what is essentially a 3 line bug fix, which we
name "absolute win".
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Fri, 10 Nov 23</h3>
<dl>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04942" title="Abstract">arXiv:2311.04942</a> (cross-list from eess.IV) [<a href="/pdf/2311.04942" title="Download PDF">pdf</a>, <a href="/format/2311.04942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CSAM: A 2.5D Cross-Slice Attention Module for Anisotropic Volumetric  Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hung%2C+A+L+Y">Alex Ling Yu Hung</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+H">Haoxin Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+K">Kai Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Du%2C+X">Xiaoxi Du</a>, 
<a href="/search/eess?searchtype=author&query=Pang%2C+K">Kaifeng Pang</a>, 
<a href="/search/eess?searchtype=author&query=Miao%2C+Q">Qi Miao</a>, 
<a href="/search/eess?searchtype=author&query=Raman%2C+S+S">Steven S. Raman</a>, 
<a href="/search/eess?searchtype=author&query=Terzopoulos%2C+D">Demetri Terzopoulos</a>, 
<a href="/search/eess?searchtype=author&query=Sung%2C+K">Kyunghyun Sung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">A large portion of volumetric medical data, especially magnetic resonance
imaging (MRI) data, is anisotropic, as the through-plane resolution is
typically much lower than the in-plane resolution. Both 3D and purely 2D deep
learning-based segmentation methods are deficient in dealing with such
volumetric data since the performance of 3D methods suffers when confronting
anisotropic data, and 2D methods disregard crucial volumetric information.
Insufficient work has been done on 2.5D methods, in which 2D convolution is
mainly used in concert with volumetric information. These models focus on
learning the relationship across slices, but typically have many parameters to
train. We offer a Cross-Slice Attention Module (CSAM) with minimal trainable
parameters, which captures information across all the slices in the volume by
applying semantic, positional, and slice attention on deep feature maps at
different scales. Our extensive experiments using different network
architectures and tasks demonstrate the usefulness and generalizability of
CSAM. Associated code is available at https://github.com/aL3x-O-o-Hung/CSAM.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04946" title="Abstract">arXiv:2311.04946</a> (cross-list from q-fin.PM) [<a href="/pdf/2311.04946" title="Download PDF">pdf</a>, <a href="/ps/2311.04946" title="Download PostScript">ps</a>, <a href="/format/2311.04946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Inference on Investment Constraints and Non-stationarity in  Dynamic Portfolio Optimization through Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Nakayama%2C+Y">Yasuhiro Nakayama</a>, 
<a href="/search/q-fin?searchtype=author&query=Sawaki%2C+T">Tomochika Sawaki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, 11 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Portfolio Management (q-fin.PM)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this study, we have developed a dynamic asset allocation investment
strategy using reinforcement learning techniques. To begin with, we have
addressed the crucial issue of incorporating non-stationarity of financial time
series data into reinforcement learning algorithms, which is a significant
implementation in the application of reinforcement learning in investment
strategies. Our findings highlight the significance of introducing certain
variables such as regime change in the environment setting to enhance the
prediction accuracy. Furthermore, the application of reinforcement learning in
investment strategies provides a remarkable advantage of setting the
optimization problem flexibly. This enables the integration of practical
constraints faced by investors into the algorithm, resulting in efficient
optimization. Our study has categorized the investment strategy formulation
conditions into three main categories, including performance measurement
indicators, portfolio management rules, and other constraints. We have
evaluated the impact of incorporating these conditions into the environment and
rewards in a reinforcement learning framework and examined how they influence
investment behavior.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04965" title="Abstract">arXiv:2311.04965</a> (cross-list from quant-ph) [<a href="/pdf/2311.04965" title="Download PDF">pdf</a>, <a href="/format/2311.04965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expressibility-induced Concentration of Quantum Neural Tangent Kernels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Yu%2C+L">Li-Wei Yu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+W">Weikang Li</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ye%2C+Q">Qi Ye</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lu%2C+Z">Zhide Lu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Han%2C+Z">Zizhao Han</a>, 
<a href="/search/quant-ph?searchtype=author&query=Deng%2C+D">Dong-Ling Deng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages,6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Quantum tangent kernel methods provide an efficient approach to analyzing the
performance of quantum machine learning models in the infinite-width limit,
which is of crucial importance in designing appropriate circuit architectures
for certain learning tasks. Recently, they have been adapted to describe the
convergence rate of training errors in quantum neural networks in an analytical
manner. Here, we study the connections between the trainability and
expressibility of quantum tangent kernel models. In particular, for global loss
functions, we rigorously prove that high expressibility of both the global and
local quantum encodings can lead to exponential concentration of quantum
tangent kernel values to zero. Whereas for local loss functions, such issue of
exponential concentration persists owing to the high expressibility, but can be
partially mitigated. We further carry out extensive numerical simulations to
support our analytical theories. Our discoveries unveil a pivotal
characteristic of quantum neural tangent kernels, offering valuable insights
for the design of wide quantum variational circuit models in practical
applications.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04996" title="Abstract">arXiv:2311.04996</a> (cross-list from eess.AS) [<a href="/pdf/2311.04996" title="Download PDF">pdf</a>, <a href="/format/2311.04996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPU-Accelerated WFST Beam Search Decoder for CTC-based Speech  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Galvez%2C+D">Daniel Galvez</a>, 
<a href="/search/eess?searchtype=author&query=Kaldewey%2C+T">Tim Kaldewey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">While Connectionist Temporal Classification (CTC) models deliver
state-of-the-art accuracy in automated speech recognition (ASR) pipelines,
their performance has been limited by CPU-based beam search decoding. We
introduce a GPU-accelerated Weighted Finite State Transducer (WFST) beam search
decoder compatible with current CTC models. It increases pipeline throughput
and decreases latency, supports streaming inference, and also supports advanced
features like utterance-specific word boosting via on-the-fly composition. We
provide pre-built DLPack-based python bindings for ease of use with
Python-based machine learning frameworks at
https://github.com/nvidia-riva/riva-asrlib-decoder. We evaluated our decoder
for offline and online scenarios, demonstrating that it is the fastest beam
search decoder for CTC models. In the offline scenario it achieves up to 7
times more throughput than the current state-of-the-art CPU decoder and in the
online streaming scenario, it achieves nearly 8 times lower latency, with same
or better word error rate.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05003" title="Abstract">arXiv:2311.05003</a> (cross-list from eess.SP) [<a href="/pdf/2311.05003" title="Download PDF">pdf</a>, <a href="/ps/2311.05003" title="Download PostScript">ps</a>, <a href="/format/2311.05003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harmonic Retrieval Using Weighted Lifted-Structure Low-Rank Matrix  Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bokaei%2C+M">Mohammad Bokaei</a>, 
<a href="/search/eess?searchtype=author&query=Razavikia%2C+S">Saeed Razavikia</a>, 
<a href="/search/eess?searchtype=author&query=Rini%2C+S">Stefano Rini</a>, 
<a href="/search/eess?searchtype=author&query=Amini%2C+A">Arash Amini</a>, 
<a href="/search/eess?searchtype=author&query=Behrouzi%2C+H">Hamid Behrouzi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">In this paper, we investigate the problem of recovering the frequency
components of a mixture of $K$ complex sinusoids from a random subset of $N$
equally-spaced time-domain samples. Because of the random subset, the samples
are effectively non-uniform. Besides, the frequency values of each of the $K$
complex sinusoids are assumed to vary continuously within a given range.
<br />For this problem, we propose a two-step strategy: (i) we first lift the
incomplete set of uniform samples (unavailable samples are treated as missing
data) into a structured matrix with missing entries, which is potentially
low-rank; then (ii) we complete the matrix using a weighted nuclear
minimization problem. We call the method a \emph{ weighted lifted-structured
(WLi) low-rank matrix recovery}. Our approach can be applied to a range of
matrix structures such as Hankel and double-Hankel, among others, and provides
improvement over the unweighted existing schemes such as EMaC and DEMaC. We
provide theoretical guarantees for the proposed method, as well as numerical
simulations in both noiseless and noisy settings. Both the theoretical and the
numerical results confirm the superiority of the proposed approach.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05009" title="Abstract">arXiv:2311.05009</a> (cross-list from physics.comp-ph) [<a href="/pdf/2311.05009" title="Download PDF">pdf</a>, <a href="/format/2311.05009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consensus-based construction of high-dimensional free energy surface
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Lyu%2C+L">Liyao Lyu</a>, 
<a href="/search/physics?searchtype=author&query=Lei%2C+H">Huan Lei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Numerical Analysis (math.NA); Machine Learning (stat.ML)

</div>
<p class="mathjax">One essential problem in quantifying the collective behaviors of molecular
systems lies in the accurate construction of free energy surfaces (FESs). The
main challenges arise from the prevalence of energy barriers and the high
dimensionality. Existing approaches are often based on sophisticated enhanced
sampling methods to establish efficient exploration of the full-phase space. On
the other hand, the collection of optimal sample points for the numerical
approximation of FESs remains largely under-explored, where the discretization
error could become dominant for systems with a large number of collective
variables (CVs). We propose a consensus sampling-based approach by
reformulating the construction as a minimax problem which simultaneously
optimizes the function representation and the training set. In particular, the
maximization step establishes a stochastic interacting particle system to
achieve the adaptive sampling of the max-residue regime by modulating the
exploitation of the Laplace approximation of the current loss function and the
exploration of the uncharted phase space; the minimization step updates the FES
approximation with the new training set. By iteratively solving the minimax
problem, the present method essentially achieves an adversarial learning of the
FESs with unified tasks for both phase space exploration and posterior
error-enhanced sampling. We demonstrate the method by constructing the FESs of
molecular systems with a number of CVs up to 30.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05025" title="Abstract">arXiv:2311.05025</a> (cross-list from stat.CO) [<a href="/pdf/2311.05025" title="Download PDF">pdf</a>, <a href="/format/2311.05025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unbiased Kinetic Langevin Monte Carlo with Inexact Gradients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Chada%2C+N+K">Neil K. Chada</a>, 
<a href="/search/stat?searchtype=author&query=Leimkuhler%2C+B">Benedict Leimkuhler</a>, 
<a href="/search/stat?searchtype=author&query=Paulin%2C+D">Daniel Paulin</a>, 
<a href="/search/stat?searchtype=author&query=Whalley%2C+P+A">Peter A. Whalley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 92 Pages, 11 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation (stat.CO)</span>; Numerical Analysis (math.NA); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
<p class="mathjax">We present an unbiased method for Bayesian posterior means based on kinetic
Langevin dynamics that combines advanced splitting methods with enhanced
gradient approximations. Our approach avoids Metropolis correction by coupling
Markov chains at different discretization levels in a multilevel Monte Carlo
approach. Theoretical analysis demonstrates that our proposed estimator is
unbiased, attains finite variance, and satisfies a central limit theorem. It
can achieve accuracy $\epsilon&gt;0$ for estimating expectations of Lipschitz
functions in $d$ dimensions with $\mathcal{O}(d^{1/4}\epsilon^{-2})$ expected
gradient evaluations, without assuming warm start. We exhibit similar bounds
using both approximate and stochastic gradients, and our method's computational
cost is shown to scale logarithmically with the size of the dataset. The
proposed method is tested using a multinomial regression problem on the MNIST
dataset and a Poisson regression model for soccer scores. Experiments indicate
that the number of gradient evaluations per effective sample is independent of
dimension, even when using inexact gradients. For product distributions, we
give dimension-independent variance bounds. Our results demonstrate that the
unbiased algorithm we present can be much more efficient than the
``gold-standard" randomized Hamiltonian Monte Carlo.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05032" title="Abstract">arXiv:2311.05032</a> (cross-list from eess.IV) [<a href="/pdf/2311.05032" title="Download PDF">pdf</a>, <a href="/format/2311.05032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transfer learning from a sparsely annotated dataset of 3D medical images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Humpire-Mamani%2C+G+E">Gabriel Efrain Humpire-Mamani</a>, 
<a href="/search/eess?searchtype=author&query=Jacobs%2C+C">Colin Jacobs</a>, 
<a href="/search/eess?searchtype=author&query=Prokop%2C+M">Mathias Prokop</a>, 
<a href="/search/eess?searchtype=author&query=van+Ginneken%2C+B">Bram van Ginneken</a>, 
<a href="/search/eess?searchtype=author&query=Lessmann%2C+N">Nikolas Lessmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Transfer learning leverages pre-trained model features from a large dataset
to save time and resources when training new models for various tasks,
potentially enhancing performance. Due to the lack of large datasets in the
medical imaging domain, transfer learning from one medical imaging model to
other medical imaging models has not been widely explored. This study explores
the use of transfer learning to improve the performance of deep convolutional
neural networks for organ segmentation in medical imaging. A base segmentation
model (3D U-Net) was trained on a large and sparsely annotated dataset; its
weights were used for transfer learning on four new down-stream segmentation
tasks for which a fully annotated dataset was available. We analyzed the
training set size's influence to simulate scarce data. The results showed that
transfer learning from the base model was beneficial when small datasets were
available, providing significant performance improvements; where fine-tuning
the base model is more beneficial than updating all the network weights with
vanilla transfer learning. Transfer learning with fine-tuning increased the
performance by up to 0.129 (+28\%) Dice score than experiments trained from
scratch, and on average 23 experiments increased the performance by 0.029 Dice
score in the new segmentation tasks. The study also showed that cross-modality
transfer learning using CT scans was beneficial. The findings of this study
demonstrate the potential of transfer learning to improve the efficiency of
annotation and increase the accessibility of accurate organ segmentation in
medical imaging, ultimately leading to improved patient care. We made the
network definition and weights publicly available to benefit other users and
researchers.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05046" title="Abstract">arXiv:2311.05046</a> (cross-list from stat.ML) [<a href="/pdf/2311.05046" title="Download PDF">pdf</a>, <a href="/format/2311.05046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Consistency of Maximum Likelihood Estimation of Probabilistic  Principal Component Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Datta%2C+A">Arghya Datta</a>, 
<a href="/search/stat?searchtype=author&query=Chakrabarty%2C+S">Sayak Chakrabarty</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 1 figure, to appear in NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Probabilistic principal component analysis (PPCA) is currently one of the
most used statistical tools to reduce the ambient dimension of the data. From
multidimensional scaling to the imputation of missing data, PPCA has a broad
spectrum of applications ranging from science and engineering to quantitative
finance.
<br />Despite this wide applicability in various fields, hardly any theoretical
guarantees exist to justify the soundness of the maximal likelihood (ML)
solution for this model. In fact, it is well known that the maximum likelihood
estimation (MLE) can only recover the true model parameters up to a rotation.
The main obstruction is posed by the inherent identifiability nature of the
PPCA model resulting from the rotational symmetry of the parameterization. To
resolve this ambiguity, we propose a novel approach using quotient topological
spaces and in particular, we show that the maximum likelihood solution is
consistent in an appropriate quotient Euclidean space. Furthermore, our
consistency results encompass a more general class of estimators beyond the
MLE. Strong consistency of the ML estimate and consequently strong covariance
estimation of the PPCA model have also been established under a compactness
assumption.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05115" title="Abstract">arXiv:2311.05115</a> (cross-list from math.OC) [<a href="/pdf/2311.05115" title="Download PDF">pdf</a>, <a href="/ps/2311.05115" title="Download PostScript">ps</a>, <a href="/format/2311.05115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Convex Optimization for Guidance and Control of Vehicular  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+Z">Zhenbo Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Guidance and control (G&amp;C) technologies play a central role in the
development and operation of vehicular systems. The emergence of computational
guidance and control (CG&amp;C) and highly efficient numerical algorithms has
opened up the great potential for solving complex constrained G&amp;C problems
onboard, enabling higher level of autonomous vehicle operations. In particular,
convex-optimization-based G&amp;C has matured significantly over the years and many
advances continue to be made, allowing the generation of optimal G&amp;C solutions
in real-time for many vehicular systems in aerospace, automotive, and other
domains. In this paper, we review recent major advances in convex optimization
and convexification techniques for G&amp;C of vehicular systems, focusing primarily
on three important application fields: 1) Space vehicles for powered descent
guidance, small body landing, rendezvous and proximity operations, orbital
transfer, spacecraft reorientation, space robotics and manipulation, spacecraft
formation flying, and station keeping; 2) Air vehicles including
hypersonic/entry vehicles, missiles and projectiles, launch/ascent vehicles,
and low-speed air vehicles; and 3) Motion control and powertrain control of
ground vehicles. Throughout the paper, we draw figures that illustrate the
basic mission concepts and scenarios and present tables that summarize
similarities and distinctions among the key problems, ideas, and approaches.
Where available, we provide comparative analyses and reveal correlations
between different applications. Finally, we identify open challenges and
issues, discuss potential opportunities, and make suggestions for future
research directions.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05116" title="Abstract">arXiv:2311.05116</a> (cross-list from math.AG) [<a href="/pdf/2311.05116" title="Download PDF">pdf</a>, <a href="/format/2311.05116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Covering Number of Real Algebraic Varieties: Improved Bound and  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+Y">Yifan Zhang</a>, 
<a href="/search/math?searchtype=author&query=Kileel%2C+J">Joe Kileel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Geometry (math.AG)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
<p class="mathjax">We prove an upper bound on the covering number of real algebraic varieties,
images of polynomial maps and semialgebraic sets. The bound remarkably improves
the best known bound by Yomdin-Comte, and its proof is much more
straightforward. As a consequence, our result gives a bound on volume of the
tubular neighborhood of a real variety, improving the results by Lotz and
Basu-Lerario. We apply our theory to three main application domains. Firstly,
we derive a near-optimal bound on the covering number of low rank CP tensors.
Secondly, we prove a bound on the sketching dimension for (general) polynomial
optimization problems. Lastly, we deduce generalization error bounds for deep
neural networks with rational or ReLU activations, improving or matching the
best known results in the literature.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05135" title="Abstract">arXiv:2311.05135</a> (cross-list from math.OC) [<a href="/pdf/2311.05135" title="Download PDF">pdf</a>, <a href="/format/2311.05135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Computational Efficiency for Powered Descent Guidance via  Transformer-based Tight Constraint Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Briden%2C+J">Julia Briden</a>, 
<a href="/search/math?searchtype=author&query=Gurga%2C+T">Trey Gurga</a>, 
<a href="/search/math?searchtype=author&query=Johnson%2C+B">Breanna Johnson</a>, 
<a href="/search/math?searchtype=author&query=Cauligi%2C+A">Abhishek Cauligi</a>, 
<a href="/search/math?searchtype=author&query=Linares%2C+R">Richard Linares</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AIAA SciTech 2024 on 25-Aug-2023. Full manuscript submitted to AIAA SciTech 2024 on 25-May-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Robotics (cs.RO); Systems and Control (eess.SY)

</div>
<p class="mathjax">In this work, we present Transformer-based Powered Descent Guidance (T-PDG),
a scalable algorithm for reducing the computational complexity of the direct
optimization formulation of the spacecraft powered descent guidance problem.
T-PDG uses data from prior runs of trajectory optimization algorithms to train
a transformer neural network, which accurately predicts the relationship
between problem parameters and the globally optimal solution for the powered
descent guidance problem. The solution is encoded as the set of tight
constraints corresponding to the constrained minimum-cost trajectory and the
optimal final time of landing. By leveraging the attention mechanism of
transformer neural networks, large sequences of time series data can be
accurately predicted when given only the spacecraft state and landing site
parameters. When applied to the real problem of Mars powered descent guidance,
T-PDG reduces the time for computing the 3 degree of freedom fuel-optimal
trajectory, when compared to lossless convexification, from an order of 1-8
seconds to less than 500 milliseconds. A safe and optimal solution is
guaranteed by including a feasibility check in T-PDG before returning the final
trajectory.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05167" title="Abstract">arXiv:2311.05167</a> (cross-list from physics.chem-ph) [<a href="/pdf/2311.05167" title="Download PDF">pdf</a>, <a href="/format/2311.05167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perfecting Liquid-State Theories with Machine Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Wu%2C+J">Jianzhong Wu</a>, 
<a href="/search/physics?searchtype=author&query=Gu%2C+M">Mengyang Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Soft Condensed Matter (cond-mat.soft); Machine Learning (cs.LG); Computational Physics (physics.comp-ph); Applications (stat.AP)

</div>
<p class="mathjax">Recent years have seen a significant increase in the use of machine
intelligence for predicting electronic structure, molecular force fields, and
the physicochemical properties of various condensed systems. However,
substantial challenges remain in developing a comprehensive framework capable
of handling a wide range of atomic compositions and thermodynamic conditions.
This perspective discusses potential future developments in liquid-state
theories leveraging on recent advancements of functional machine learning. By
harnessing the strengths of theoretical analysis and machine learning
techniques including surrogate models, dimension reduction and uncertainty
quantification, we envision that liquid-state theories will gain significant
improvements in accuracy, scalability and computational efficiency, enabling
their broader applications across diverse materials and chemical systems.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05179" title="Abstract">arXiv:2311.05179</a> (cross-list from eess.AS) [<a href="/pdf/2311.05179" title="Download PDF">pdf</a>, <a href="/format/2311.05179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Whispered Speech Recognition Performance using  Pseudo-whispered based Data Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lin%2C+Z">Zhaofeng Lin</a>, 
<a href="/search/eess?searchtype=author&query=Patel%2C+T">Tanvina Patel</a>, 
<a href="/search/eess?searchtype=author&query=Scharenborg%2C+O">Odette Scharenborg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ASRU 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Whispering is a distinct form of speech known for its soft, breathy, and
hushed characteristics, often used for private communication. The acoustic
characteristics of whispered speech differ substantially from normally phonated
speech and the scarcity of adequate training data leads to low automatic speech
recognition (ASR) performance. To address the data scarcity issue, we use a
signal processing-based technique that transforms the spectral characteristics
of normal speech to those of pseudo-whispered speech. We augment an End-to-End
ASR with pseudo-whispered speech and achieve an 18.2% relative reduction in
word error rate for whispered speech compared to the baseline. Results for the
individual speaker groups in the wTIMIT database show the best results for US
English. Further investigation showed that the lack of glottal information in
whispered speech has the largest impact on whispered speech ASR performance.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05181" title="Abstract">arXiv:2311.05181</a> (cross-list from math.DS) [<a href="/pdf/2311.05181" title="Download PDF">pdf</a>, <a href="/format/2311.05181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-efficient flocking in multi-agent systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dykhovychnyi%2C+O">Oleksandr Dykhovychnyi</a>, 
<a href="/search/math?searchtype=author&query=Panchenko%2C+A">Alexander Panchenko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Modeling collective motion in multi-agent systems has gained much attention
in recent years. In particular, of interest are the conditions under which
flocking dynamics emerges. We present a generalization of the multi-agent model
of Olfati--Saber with non-linear navigational feedback forces. As opposed to
the original model, our model is, in general, not dissipative. This makes
obtaining sufficient conditions for flocking challenging due to the absence of
an obvious choice of a Lyapunov function. By means of an alternative argument,
we show that our model possesses a global attractor when the navigational
feedback forces are bounded perturbations of the linear ones. We further
demonstrate that, under mild conditions, the dynamics of the group converges to
a complete velocity agreement at an exponential rate. We show that the
attractor of a dissipative system can contain non-equilibrium solutions. We
construct explicit examples of such solutions and obtain conditions under which
they cannot exist. In addition, we present a case study of the energy
efficiency of our model. We show how non-linear navigational feedback forces,
which possess flexibility that linear forces lack, can be used to reduce
on-board energy consumption.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05191" title="Abstract">arXiv:2311.05191</a> (cross-list from math.AP) [<a href="/pdf/2311.05191" title="Download PDF">pdf</a>, <a href="/format/2311.05191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Determining Sources in the Bioluminescence Tomography Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ding%2C+M">Ming-Hui Ding</a>, 
<a href="/search/math?searchtype=author&query=Gong%2C+R">Rongfang Gong</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+H">Hongyu Liu</a>, 
<a href="/search/math?searchtype=author&query=Lo%2C+C+W+K">Catharine W.K. Lo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">In this paper, we revisit the bioluminescence tomography (BLT) problem, where
one seeks to reconstruct bioluminescence signals (an internal light source)
from external measurements of the Cauchy data. As one kind of optical imaging,
the BLT has many merits such as high signal-to-noise ratio, non-destructivity
and cost-effectiveness etc., and has potential applications such as cancer
diagnosis, drug discovery and development as well as gene therapies and so on.
In the literature, BLT is extensively studied based on diffusion approximation
(DA) equation, where the distribution of peak sources is to be reconstructed
and no solution uniqueness is guaranteed without adequate a priori information.
Motivated by the solution uniqueness issue, several theoretical results are
explored. The major contributions in this work that are new to the literature
are two-fold: first, we show the theoretical uniqueness of the BLT problem
where the light sources are in the shape of $C^2$ domains or polyhedral- or
corona-shaped; second, we support our results with plenty of problem-orientated
numerical experiments.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05239" title="Abstract">arXiv:2311.05239</a> (cross-list from quant-ph) [<a href="/pdf/2311.05239" title="Download PDF">pdf</a>, <a href="/format/2311.05239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Quantum-Native Communication Systems: New Developments, Trends,  and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Zhou%2C+X">Xiaolin Zhou</a>, 
<a href="/search/quant-ph?searchtype=author&query=Shen%2C+A">Anqi Shen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hu%2C+S">Shuyan Hu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ni%2C+W">Wei Ni</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hossain%2C+E">Ekram Hossain</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hanzo%2C+L">Lajos Hanzo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 52 pages, 29 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">The potential synergy between quantum communications and future wireless
communication systems is explored. By proposing a quantum-native or
quantum-by-design philosophy, the survey examines technologies such as
quantum-domain (QD) multi-input multi-output (MIMO), QD non-orthogonal multiple
access (NOMA), quantum secure direct communication (QSDC), QD resource
allocation, QD routing, and QD artificial intelligence (AI). The recent
research advances in these areas are summarized. Given the behavior of photonic
and particle-like Terahertz (THz) systems, a comprehensive system-oriented
perspective is adopted to assess the feasibility of using quantum
communications in future systems. This survey also reviews quantum optimization
algorithms and quantum neural networks to explore the potential integration of
quantum communication and quantum computing in future systems. Additionally,
the current status of quantum sensing, quantum radar, and quantum timing is
briefly reviewed in support of future applications. The associated research
gaps and future directions are identified, including extending the entanglement
coherence time, developing THz quantum communications devices, addressing
challenges in channel estimation and tracking, and establishing the theoretical
bounds and performance trade-offs of quantum communication, computing, and
sensing. This survey offers a unique perspective on the potential for quantum
communications to revolutionize future systems and pave the way for even more
advanced technologies.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05262" title="Abstract">arXiv:2311.05262</a> (cross-list from math.CO) [<a href="/pdf/2311.05262" title="Download PDF">pdf</a>, <a href="/ps/2311.05262" title="Download PostScript">ps</a>, <a href="/format/2311.05262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $K_2$-Hamiltonian Graphs: II
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Goedgebeur%2C+J">Jan Goedgebeur</a>, 
<a href="/search/math?searchtype=author&query=Renders%2C+J">Jarne Renders</a>, 
<a href="/search/math?searchtype=author&query=Wiener%2C+G">G&#xe1;bor Wiener</a>, 
<a href="/search/math?searchtype=author&query=Zamfirescu%2C+C+T">Carol T. Zamfirescu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, to appear in Journal of Graph Theory
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">In this paper we use theoretical and computational tools to continue our
investigation of $K_2$-hamiltonian graphs, i.e. graphs in which the removal of
any pair of adjacent vertices yields a hamiltonian graph, and their interplay
with $K_1$-hamiltonian graphs, i.e. graphs in which every vertex-deleted
subgraph is hamiltonian. Perhaps surprisingly, there exist graphs that are both
$K_1$- and $K_2$-hamiltonian, yet non-hamiltonian, e.g. the Petersen graph.
Gr\"unbaum conjectured that every planar $K_1$-hamiltonian graph must itself be
hamiltonian; Thomassen disproved this conjecture. Here we show that even planar
graphs that are both $K_1$- and $K_2$-hamiltonian need not be hamiltonian, and
that the number of such graphs grows at least exponentially. Motivated by
results of Aldred, McKay, and Wormald, we determine for every integer $n$ that
is not 14 or 17 whether there exists a $K_2$-hypohamiltonian, i.e.
non-hamiltonian and $K_2$-hamiltonian, graph of order~$n$, and characterise all
orders for which such cubic graphs and such snarks exist. We also describe the
smallest cubic planar graph which is $K_2$-hypohamiltonian, as well as the
smallest planar $K_2$-hypohamiltonian graph of girth $5$. We conclude with open
problems and by correcting two inaccuracies from the first article [Zamfirescu,
SIAM J. Disc. Math. 35 (2021) 1706-1728].
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05269" title="Abstract">arXiv:2311.05269</a> (cross-list from eess.IV) [<a href="/pdf/2311.05269" title="Download PDF">pdf</a>, <a href="/format/2311.05269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single-shot Tomography of Discrete Dynamic Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kadu%2C+A">Ajinkya Kadu</a>, 
<a href="/search/eess?searchtype=author&query=Lucka%2C+F">Felix Lucka</a>, 
<a href="/search/eess?searchtype=author&query=Batenburg%2C+K+J">Kees Joost Batenburg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 9 figures; currently submitted to IEEE Transactions on Computational Imaging
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computational Engineering, Finance, and Science (cs.CE); Computer Vision and Pattern Recognition (cs.CV); Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper presents a novel method for the reconstruction of high-resolution
temporal images in dynamic tomographic imaging, particularly for discrete
objects with smooth boundaries that vary over time. Addressing the challenge of
limited measurements per time point, we propose a technique that
synergistically incorporates spatial and temporal information of the dynamic
objects. This is achieved through the application of the level-set method for
image segmentation and the representation of motion via a sinusoidal basis. The
result is a computationally efficient and easily optimizable variational
framework that enables the reconstruction of high-quality 2D or 3D image
sequences with a single projection per frame. Compared to current methods, our
proposed approach demonstrates superior performance on both synthetic and
pseudo-dynamic real X-ray tomography datasets. The implications of this
research extend to improved visualization and analysis of dynamic processes in
tomographic imaging, finding potential applications in diverse scientific and
industrial domains.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05306" title="Abstract">arXiv:2311.05306</a> (cross-list from math.OC) [<a href="/pdf/2311.05306" title="Download PDF">pdf</a>, <a href="/format/2311.05306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Exponential Stabilization of a Heat and Piezoelectric Beam  Interaction with Static or Hybrid Feedback Controllers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ozer%2C+A+O">Ahmet Ozkan Ozer</a>, 
<a href="/search/math?searchtype=author&query=Khalilullah%2C+I">Ibrahim Khalilullah</a>, 
<a href="/search/math?searchtype=author&query=Rasaq%2C+U">Uthman Rasaq</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 1 figure. arXiv admin note: text overlap with <a href="/abs/2309.13986">arXiv:2309.13986</a>, <a href="/abs/2309.07492">arXiv:2309.07492</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Analysis of PDEs (math.AP); Numerical Analysis (math.NA)

</div>
<p class="mathjax">A system of partial differential equations (PDE) of a heat-transferring
copper rod and a magnetizable piezoelectric beam, describing the longitudinal
vibrations and the total charge accumulation at the electrodes of the beam, is
considered in the transmission line setting. For magnetizable piezoelectric
beams, traveling electromagnetic and mechanical waves are able to interact
strongly despite a huge difference in velocities. It is known that the heat and
beam interactions in the open-loop setting does not yield exponentially
stability with the thermal effects only. Therefore, two types of boundary-type
state feedback controllers are proposed. (i) Both feedback controllers are
chosen static. (ii) The electrical controller of the piezoelectric beam is
chosen dynamic to accelerate the system dynamics. The PDE system for each case
is shown to have exponentially stable solutions by cleverly-constructed
Lyapunov functions with various multipliers. The proposed proof technique is in
line with proving the exponential stability of Finite-Difference-based robust
model reductions as the discretization parameter tends to zero.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05309" title="Abstract">arXiv:2311.05309</a> (cross-list from cond-mat.soft) [<a href="/pdf/2311.05309" title="Download PDF">pdf</a>, <a href="/format/2311.05309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Liquid phase fast electron tomography unravels the true 3D structure of  colloidal assemblies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Esteban%2C+D+A">Daniel Arenas Esteban</a>, 
<a href="/search/cond-mat?searchtype=author&query=Wang%2C+D">Da Wang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Kadu%2C+A">Ajinkya Kadu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Olluyn%2C+N">Noa Olluyn</a>, 
<a href="/search/cond-mat?searchtype=author&query=Iglesias%2C+A+S">Ana S&#xe1;nchez Iglesias</a>, 
<a href="/search/cond-mat?searchtype=author&query=Perez%2C+A+G">Alejandro Gomez Perez</a>, 
<a href="/search/cond-mat?searchtype=author&query=Casablanca%2C+J+G">Jesus Gonzalez Casablanca</a>, 
<a href="/search/cond-mat?searchtype=author&query=Nicolopoulos%2C+S">Stavros Nicolopoulos</a>, 
<a href="/search/cond-mat?searchtype=author&query=Liz-Marz%C3%A1n%2C+L+M">Luis M. Liz-Marz&#xe1;n</a>, 
<a href="/search/cond-mat?searchtype=author&query=Bals%2C+S">Sara Bals</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 12 figures, 2 tables, in process of submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Soft Condensed Matter (cond-mat.soft)</span>; Materials Science (cond-mat.mtrl-sci); Computational Engineering, Finance, and Science (cs.CE); Chemical Physics (physics.chem-ph)

</div>
<p class="mathjax">Electron tomography has become a commonly used tool to investigate the
three-dimensional (3D) structure of nanomaterials, including colloidal
nanoparticle assemblies. However, the nature of the electron microscopy
technique typically requires such characterization to be carried out under high
vacuum. Therefore, pre-treatment sample preparation is needed for assemblies
prepared by (wet) colloid chemistry methods, including solvent evaporation and
deposition on a solid substrate (TEM grid). As a result, changes are
consistently imposed on the actual nanoparticle organization, which is largely
responsible for the nanomaterial properties. Therefore, we propose herein the
application of (fast) electron tomography of nanoparticle assemblies while in
their original colloidal environment. To address the challenges related to
electron tomography in liquid, we devised a method that combines fast data
acquisition in a commercial liquid in situ TEM cell with a dedicated
reconstruction workflow. We present the application of this method to two
different systems, which exemplify the effects of drying and vacuum, depending
on the nature of the protecting ligands. 3D reconstructions of assemblies
comprising polystyrene-capped Au nanoparticles encapsulated in polymeric shells
revealed less compact and more distorted configurations for experiments
performed in a liquid medium compared to their dried counterparts. On the other
hand, quantitative analysis of the interparticle distance of self-assembled Au
nanorods in water agrees with the previously reported dimensions of the ligand
layers surrounding the nanorods, whereas the nanorods are in much closer
contact in similar dried assemblies. This study, therefore, emphasizes the
importance of developing high-resolution characterization tools that preserve
the native environment of colloidal nanostructures.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05311" title="Abstract">arXiv:2311.05311</a> (cross-list from math.OC) [<a href="/pdf/2311.05311" title="Download PDF">pdf</a>, <a href="/ps/2311.05311" title="Download PostScript">ps</a>, <a href="/format/2311.05311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Newton-GSOR method for solving large-scale unconstrained optimization  problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ray%2C+S+S">Santoshi Subhalaxmi Ray</a>, 
<a href="/search/math?searchtype=author&query=Saha%2C+M">Manideepa Saha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Unconstrained convex optimization problems have enormous applications in
various field of science and engineering. Different iterative methods are
available in literature to solve such problem, and Newton method is among the
oldest and simplest one. Due to slow convergence rate of Newton's methods, many
research have been carried out to modify the Newton's method for faster
convergence rate. In 2019, Ghazali et al. modified Newton's method and proposed
Netwon-SOR method, which is a combination of Newton method with SOR iterative
method to solve a linear system. In this paper, we propose a modification of
Newton-SOR method by modifying SOR method to generalized SOR method. Numerical
experiments are carried out to check the efficiently of the proposed method.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05330" title="Abstract">arXiv:2311.05330</a> (cross-list from stat.AP) [<a href="/pdf/2311.05330" title="Download PDF">pdf</a>, <a href="/format/2311.05330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applying a new category association estimator to sentiment analysis on  the Web
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Xavier%2C+H+S">Henrique S. Xavier</a>, 
<a href="/search/stat?searchtype=author&query=Cortiz%2C+D">Diogo Cortiz</a>, 
<a href="/search/stat?searchtype=author&query=Silvestrin%2C+M">Mateus Silvestrin</a>, 
<a href="/search/stat?searchtype=author&query=Freitas%2C+A+L">Ana Lu&#xed;sa Freitas</a>, 
<a href="/search/stat?searchtype=author&query=Morello%2C+L+Y+N">Let&#xed;cia Yumi Nakao Morello</a>, 
<a href="/search/stat?searchtype=author&query=Pantale%C3%A3o%2C+F+N">Fernanda Naomi Pantale&#xe3;o</a>, 
<a href="/search/stat?searchtype=author&query=R%C3%AAgo%2C+G+G+d">Gabriel Gaudencio do R&#xea;go</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures. Submitted to the Web Conference 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applications (stat.AP)</span>; Computers and Society (cs.CY); Methodology (stat.ME)

</div>
<p class="mathjax">This paper introduces a novel Bayesian method for measuring the degree of
association between categorical variables. The method is grounded in the formal
definition of variable independence and was implemented using MCMC techniques.
Unlike existing methods, this approach does not assume prior knowledge of the
total number of occurrences for any category, making it particularly
well-suited for applications like sentiment analysis. We applied the method to
a dataset comprising 4,613 tweets written in Portuguese, each annotated for 30
possibly overlapping emotional categories. Through this analysis, we identified
pairs of emotions that exhibit associations and mutually exclusive pairs.
Furthermore, the method identifies hierarchical relations between categories, a
feature observed in our data, and was used to cluster emotions into basic level
groups.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05341" title="Abstract">arXiv:2311.05341</a> (cross-list from astro-ph.IM) [<a href="/pdf/2311.05341" title="Download PDF">pdf</a>, <a href="/format/2311.05341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Dedispersion using Many-Core Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Novotn%C3%BD%2C+J">Jan Novotn&#xfd;</a>, 
<a href="/search/astro-ph?searchtype=author&query=Ad%C3%A1mek%2C+K">Karel Ad&#xe1;mek</a>, 
<a href="/search/astro-ph?searchtype=author&query=Clark%2C+M+A">M.A. Clark</a>, 
<a href="/search/astro-ph?searchtype=author&query=Giles%2C+M">Mike Giles</a>, 
<a href="/search/astro-ph?searchtype=author&query=Armour%2C+W">Wesley Armour</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The Astrophysical Journal Supplement Series, Volume 269, Number 1,
  2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Astrophysical radio signals are excellent probes of extreme physical
processes that emit them. However, to reach Earth, electromagnetic radiation
passes through the ionised interstellar medium (ISM), introducing a
frequency-dependent time delay (dispersion) to the emitted signal. Removing
dispersion enables searches for transient signals like Fast Radio Bursts (FRB)
or repeating signals from isolated pulsars or those in orbit around other
compact objects. The sheer volume and high resolution of data that next
generation radio telescopes will produce require High-Performance Computing
(HPC) solutions and algorithms to be used in time-domain data processing
pipelines to extract scientifically valuable results in real-time. This paper
presents a state-of-the-art implementation of brute force incoherent
dedispersion on NVIDIA GPUs, and on Intel and AMD CPUs. We show that our
implementation is 4x faster (8-bit 8192 channels input) than other available
solutions and demonstrate, using 11 existing telescopes, that our
implementation is at least 20 faster than real-time. This work is part of the
AstroAccelerate package.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05407" title="Abstract">arXiv:2311.05407</a> (cross-list from physics.comp-ph) [<a href="/pdf/2311.05407" title="Download PDF">pdf</a>, <a href="/ps/2311.05407" title="Download PostScript">ps</a>, <a href="/format/2311.05407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Distillation for Neural Network Potentials toward Foundational  Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Jung%2C+G+S">Gang Seob Jung</a>, 
<a href="/search/physics?searchtype=author&query=Lee%2C+S">Sangkeun Lee</a>, 
<a href="/search/physics?searchtype=author&query=Choi%2C+J+Y">Jong Youl Choi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Machine Learning (cs.LG); Chemical Physics (physics.chem-ph)

</div>
<p class="mathjax">Machine learning (ML) techniques and atomistic modeling have rapidly
transformed materials design and discovery. Specifically, generative models can
swiftly propose promising materials for targeted applications. However, the
predicted properties of materials through the generative models often do not
match with calculated properties through ab initio calculations. This
discrepancy can arise because the generated coordinates are not fully relaxed,
whereas the many properties are derived from relaxed structures. Neural
network-based potentials (NNPs) can expedite the process by providing relaxed
structures from the initially generated ones. Nevertheless, acquiring data to
train NNPs for this purpose can be extremely challenging as it needs to
encompass previously unknown structures. This study utilized extended ensemble
molecular dynamics (MD) to secure a broad range of liquid- and solid-phase
configurations in one of the metallic systems, nickel. Then, we could
significantly reduce them through active learning without losing much accuracy.
We found that the NNP trained from the distilled data could predict different
energy-minimized closed-pack crystal structures even though those structures
were not explicitly part of the initial data. Furthermore, the data can be
translated to other metallic systems (aluminum and niobium), without repeating
the sampling and distillation processes. Our approach to data acquisition and
distillation has demonstrated the potential to expedite NNP development and
enhance materials design and discovery by integrating generative models.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05428" title="Abstract">arXiv:2311.05428</a> (cross-list from math.CO) [<a href="/pdf/2311.05428" title="Download PDF">pdf</a>, <a href="/ps/2311.05428" title="Download PostScript">ps</a>, <a href="/format/2311.05428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The classification of orthogonal arrays OA(2048,14,2,7) and some  completely regular codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Krotov%2C+D+S">Denis S. Krotov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We describe the classification of orthogonal arrays OA$(2048,14,2,7)$, or,
equivalently, completely regular $\{14;2\}$-codes in the $14$-cube ($30848$
equivalence classes). In particular, we find that there is exactly one
almost-OA$(2048,14,2,7+1)$, up to equivalence. As derived objects,
OA$(1024,13,2,6)$ ($202917$ classes) and completely regular $\{12,2;2,12\}$-
and $\{14, 12, 2; 2, 12, 14\}$-codes in the $13$- and $14$-cubes, respectively,
are also classified.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05436" title="Abstract">arXiv:2311.05436</a> (cross-list from stat.ML) [<a href="/pdf/2311.05436" title="Download PDF">pdf</a>, <a href="/format/2311.05436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fair Wasserstein Coresets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Xiong%2C+Z">Zikai Xiong</a>, 
<a href="/search/stat?searchtype=author&query=Dalmasso%2C+N">Niccol&#xf2; Dalmasso</a>, 
<a href="/search/stat?searchtype=author&query=Potluru%2C+V+K">Vamsi K. Potluru</a>, 
<a href="/search/stat?searchtype=author&query=Balch%2C+T">Tucker Balch</a>, 
<a href="/search/stat?searchtype=author&query=Veloso%2C+M">Manuela Veloso</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 6 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent technological advancements have given rise to the ability of
collecting vast amounts of data, that often exceed the capacity of commonly
used machine learning algorithms. Approaches such as coresets and synthetic
data distillation have emerged as frameworks to generate a smaller, yet
representative, set of samples for downstream training. As machine learning is
increasingly applied to decision-making processes, it becomes imperative for
modelers to consider and address biases in the data concerning subgroups
defined by factors like race, gender, or other sensitive attributes. Current
approaches focus on creating fair synthetic representative samples by
optimizing local properties relative to the original samples. These methods,
however, are not guaranteed to positively affect the performance or fairness of
downstream learning processes. In this work, we present Fair Wasserstein
Coresets (FWC), a novel coreset approach which generates fair synthetic
representative samples along with sample-level weights to be used in downstream
learning tasks. FWC aims to minimize the Wasserstein distance between the
original datasets and the weighted synthetic samples while enforcing (an
empirical version of) demographic parity, a prominent criterion for algorithmic
fairness, via a linear constraint. We show that FWC can be thought of as a
constrained version of Lloyd's algorithm for k-medians or k-means clustering.
Our experiments, conducted on both synthetic and real datasets, demonstrate the
scalability of our approach and highlight the competitive performance of FWC
compared to existing fair clustering approaches, even when attempting to
enhance the fairness of the latter through fair pre-processing techniques.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05446" title="Abstract">arXiv:2311.05446</a> (cross-list from math.MG) [<a href="/pdf/2311.05446" title="Download PDF">pdf</a>, <a href="/ps/2311.05446" title="Download PostScript">ps</a>, <a href="/format/2311.05446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Brunn--Minkowski and functional inequalities via convexity of  entropy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Aishwarya%2C+G">Gautam Aishwarya</a>, 
<a href="/search/math?searchtype=author&query=Rotem%2C+L">Liran Rotem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, comments welcome!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Metric Geometry (math.MG)</span>; Information Theory (cs.IT); Probability (math.PR)

</div>
<p class="mathjax">We study the connection between the concavity properties of a measure $\nu$
and the convexity properties of the associated relative entropy $D(\cdot \Vert
\nu)$ on Wasserstein space. As a corollary we prove a new dimensional
Brunn-Minkowski inequality for centered star-shaped bodies, when the measure
$\nu$ is log-concave with a p-homogeneous potential (such as the Gaussian
measure). Our method allows us to go beyond the usual convexity assumption on
the sets that appears essential for the standard differential-geometric
technique in this area.
<br />We then take a finer look at the convexity properties of the Gaussian
relative entropy, which yields new functional inequalities. First we obtain
curvature and dimensional reinforcements to Otto--Villani's ``HWI'' inequality
in the Gauss space, when restricted to even strongly log-concave measures. As
corollaries, we obtain improved versions of Gross' logarithmic Sobolev
inequality and Talgrand's transportation cost inequality in this setting.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05452" title="Abstract">arXiv:2311.05452</a> (cross-list from eess.IV) [<a href="/pdf/2311.05452" title="Download PDF">pdf</a>, <a href="/format/2311.05452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer-based Model for Oral Epithelial Dysplasia Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shephard%2C+A+J">Adam J Shephard</a>, 
<a href="/search/eess?searchtype=author&query=Mahmood%2C+H">Hanya Mahmood</a>, 
<a href="/search/eess?searchtype=author&query=Raza%2C+S+E+A">Shan E Ahmed Raza</a>, 
<a href="/search/eess?searchtype=author&query=Araujo%2C+A+L+D">Anna Luiza Damaceno Araujo</a>, 
<a href="/search/eess?searchtype=author&query=Santos-Silva%2C+A+R">Alan Roger Santos-Silva</a>, 
<a href="/search/eess?searchtype=author&query=Lopes%2C+M+A">Marcio Ajudarte Lopes</a>, 
<a href="/search/eess?searchtype=author&query=Vargas%2C+P+A">Pablo Agustin Vargas</a>, 
<a href="/search/eess?searchtype=author&query=McCombe%2C+K">Kris McCombe</a>, 
<a href="/search/eess?searchtype=author&query=Craig%2C+S">Stephanie Craig</a>, 
<a href="/search/eess?searchtype=author&query=James%2C+J">Jacqueline James</a>, 
<a href="/search/eess?searchtype=author&query=Brooks%2C+J">Jill Brooks</a>, 
<a href="/search/eess?searchtype=author&query=Nankivell%2C+P">Paul Nankivell</a>, 
<a href="/search/eess?searchtype=author&query=Mehanna%2C+H">Hisham Mehanna</a>, 
<a href="/search/eess?searchtype=author&query=Khurram%2C+S+A">Syed Ali Khurram</a>, 
<a href="/search/eess?searchtype=author&query=Rajpoot%2C+N+M">Nasir M Rajpoot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Oral epithelial dysplasia (OED) is a premalignant histopathological diagnosis
given to lesions of the oral cavity. OED grading is subject to large
inter/intra-rater variability, resulting in the under/over-treatment of
patients. We developed a new Transformer-based pipeline to improve detection
and segmentation of OED in haematoxylin and eosin (H&amp;E) stained whole slide
images (WSIs). Our model was trained on OED cases (n = 260) and controls (n =
105) collected using three different scanners, and validated on test data from
three external centres in the United Kingdom and Brazil (n = 78). Our internal
experiments yield a mean F1-score of 0.81 for OED segmentation, which reduced
slightly to 0.71 on external testing, showing good generalisability, and
gaining state-of-the-art results. This is the first externally validated study
to use Transformers for segmentation in precancerous histology images. Our
publicly available model shows great promise to be the first step of a
fully-integrated pipeline, allowing earlier and more efficient OED diagnosis,
ultimately benefiting patient outcomes.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05477" title="Abstract">arXiv:2311.05477</a> (cross-list from eess.IV) [<a href="/pdf/2311.05477" title="Download PDF">pdf</a>, <a href="/format/2311.05477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using ResNet to Utilize 4-class T2-FLAIR Slice Classification Based on  the Cholinergic Pathways Hyperintensities Scale for Pathological Aging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tsai%2C+W+K">Wei-Chun Kevin Tsai</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yi-Chien Liu</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+M">Ming-Chun Yu</a>, 
<a href="/search/eess?searchtype=author&query=Chou%2C+C">Chia-Ju Chou</a>, 
<a href="/search/eess?searchtype=author&query=Yan%2C+S">Sui-Hing Yan</a>, 
<a href="/search/eess?searchtype=author&query=Fan%2C+Y">Yang-Teng Fan</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+Y">Yan-Hsiang Huang</a>, 
<a href="/search/eess?searchtype=author&query=Chiu%2C+Y">Yen-Ling Chiu</a>, 
<a href="/search/eess?searchtype=author&query=Chuang%2C+Y">Yi-Fang Chuang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+R">Ran-Zan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Shih%2C+Y">Yao-Chia Shih</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">The Cholinergic Pathways Hyperintensities Scale (CHIPS) is a visual rating
scale used to assess the extent of cholinergic white matter hyperintensities in
T2-FLAIR images, serving as an indicator of dementia severity. However, the
manual selection of four specific slices for rating throughout the entire brain
is a time-consuming process. Our goal was to develop a deep learning-based
model capable of automatically identifying the four slices relevant to CHIPS.
To achieve this, we trained a 4-class slice classification model (BSCA) using
the ADNI T2-FLAIR dataset (N=150) with the assistance of ResNet. Subsequently,
we tested the model's performance on a local dataset (N=30). The results
demonstrated the efficacy of our model, with an accuracy of 99.82% and an
F1-score of 99.83%. This achievement highlights the potential impact of BSCA as
an automatic screening tool, streamlining the selection of four specific
T2-FLAIR slices that encompass white matter landmarks along the cholinergic
pathways. Clinicians can leverage this tool to assess the risk of clinical
dementia development efficiently.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05479" title="Abstract">arXiv:2311.05479</a> (cross-list from eess.IV) [<a href="/pdf/2311.05479" title="Download PDF">pdf</a>, <a href="/format/2311.05479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retinal OCT Synthesis with Denoising Diffusion Probabilistic Models for  Layer Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wu%2C+Y">Yuli Wu</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+W">Weidong He</a>, 
<a href="/search/eess?searchtype=author&query=Eschweiler%2C+D">Dennis Eschweiler</a>, 
<a href="/search/eess?searchtype=author&query=Dou%2C+N">Ningxin Dou</a>, 
<a href="/search/eess?searchtype=author&query=Fan%2C+Z">Zixin Fan</a>, 
<a href="/search/eess?searchtype=author&query=Mi%2C+S">Shengli Mi</a>, 
<a href="/search/eess?searchtype=author&query=Walter%2C+P">Peter Walter</a>, 
<a href="/search/eess?searchtype=author&query=Stegmaier%2C+J">Johannes Stegmaier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">Modern biomedical image analysis using deep learning often encounters the
challenge of limited annotated data. To overcome this issue, deep generative
models can be employed to synthesize realistic biomedical images. In this
regard, we propose an image synthesis method that utilizes denoising diffusion
probabilistic models (DDPMs) to automatically generate retinal optical
coherence tomography (OCT) images. By providing rough layer sketches, the
trained DDPMs can generate realistic circumpapillary OCT images. We further
find that more accurate pseudo labels can be obtained through knowledge
adaptation, which greatly benefits the segmentation task. Through this, we
observe a consistent improvement in layer segmentation accuracy, which is
validated using various neural networks. Furthermore, we have discovered that a
layer segmentation model trained solely with synthesized images can achieve
comparable results to a model trained exclusively with real images. These
findings demonstrate the promising potential of DDPMs in reducing the need for
manual annotations of retinal OCT images.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05486" title="Abstract">arXiv:2311.05486</a> (cross-list from quant-ph) [<a href="/pdf/2311.05486" title="Download PDF">pdf</a>, <a href="/format/2311.05486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disease Gene Prioritization With Quantum Walks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Saarinen%2C+H">Harto Saarinen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Goldsmith%2C+M">Mark Goldsmith</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+R">Rui-Sheng Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Loscalzo%2C+J">Joseph Loscalzo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Maniscalco%2C+S">Sabrina Maniscalco</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG); Molecular Networks (q-bio.MN)

</div>
<p class="mathjax">Disease gene prioritization assigns scores to genes or proteins according to
their likely relevance for a given disease based on a provided set of seed
genes. Here, we describe a new algorithm for disease gene prioritization based
on continuous-time quantum walks using the adjacency matrix of a
protein-protein interaction (PPI) network. Our algorithm can be seen as a
quantum version of a previous method known as the diffusion kernel, but,
importantly, has higher performance in predicting disease genes, and also
permits the encoding of seed node self-loops into the underlying Hamiltonian,
which offers yet another boost in performance. We demonstrate the success of
our proposed method by comparing it to several well-known gene prioritization
methods on three disease sets, across seven different PPI networks. In order to
compare these methods, we use cross-validation and examine the mean reciprocal
ranks and recall values. We further validate our method by performing an
enrichment analysis of the predicted genes for coronary artery disease. We also
investigate the impact of adding self-loops to the seeds, and argue that they
allow the quantum walker to remain more local to low-degree seed nodes.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05501" title="Abstract">arXiv:2311.05501</a> (cross-list from stat.ML) [<a href="/pdf/2311.05501" title="Download PDF">pdf</a>, <a href="/format/2311.05501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dirichlet Active Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Miller%2C+K">Kevin Miller</a>, 
<a href="/search/stat?searchtype=author&query=Murray%2C+R">Ryan Murray</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 66 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This work introduces Dirichlet Active Learning (DiAL), a Bayesian-inspired
approach to the design of active learning algorithms. Our framework models
feature-conditional class probabilities as a Dirichlet random field and lends
observational strength between similar features in order to calibrate the
random field. This random field can then be utilized in learning tasks: in
particular, we can use current estimates of mean and variance to conduct
classification and active learning in the context where labeled data is scarce.
We demonstrate the applicability of this model to low-label rate graph learning
by constructing ``propagation operators'' based upon the graph Laplacian, and
offer computational studies demonstrating the method's competitiveness with the
state of the art. Finally, we provide rigorous guarantees regarding the ability
of this approach to ensure both exploration and exploitation, expressed
respectively in terms of cluster exploration and increased attention to
decision boundaries.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05529" title="Abstract">arXiv:2311.05529</a> (cross-list from quant-ph) [<a href="/pdf/2311.05529" title="Download PDF">pdf</a>, <a href="/format/2311.05529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information-theoretic generalization bounds for learning from quantum  data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Caro%2C+M">Matthias Caro</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gur%2C+T">Tom Gur</a>, 
<a href="/search/quant-ph?searchtype=author&query=Rouz%C3%A9%2C+C">Cambyse Rouz&#xe9;</a>, 
<a href="/search/quant-ph?searchtype=author&query=Fran%C3%A7a%2C+D+S">Daniel Stilck Fran&#xe7;a</a>, 
<a href="/search/quant-ph?searchtype=author&query=Subramanian%2C+S">Sathyawageeswar Subramanian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48+14 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
<p class="mathjax">Learning tasks play an increasingly prominent role in quantum information and
computation. They range from fundamental problems such as state discrimination
and metrology over the framework of quantum probably approximately correct
(PAC) learning, to the recently proposed shadow variants of state tomography.
However, the many directions of quantum learning theory have so far evolved
separately. We propose a general mathematical formalism for describing quantum
learning by training on classical-quantum data and then testing how well the
learned hypothesis generalizes to new data. In this framework, we prove bounds
on the expected generalization error of a quantum learner in terms of classical
and quantum information-theoretic quantities measuring how strongly the
learner's hypothesis depends on the specific data seen during training.
<br />To achieve this, we use tools from quantum optimal transport and quantum
concentration inequalities to establish non-commutative versions of decoupling
lemmas that underlie recent information-theoretic generalization bounds for
classical machine learning.
<br />Our framework encompasses and gives intuitively accessible generalization
bounds for a variety of quantum learning scenarios such as quantum state
discrimination, PAC learning quantum states, quantum parameter estimation, and
quantumly PAC learning classical functions. Thereby, our work lays a foundation
for a unifying quantum information-theoretic perspective on quantum learning.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05533" title="Abstract">arXiv:2311.05533</a> (cross-list from math.CO) [<a href="/pdf/2311.05533" title="Download PDF">pdf</a>, <a href="/ps/2311.05533" title="Download PostScript">ps</a>, <a href="/format/2311.05533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building Hamiltonian Cycles in the Semi-Random Graph Process in Less  Than $2n$ Rounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Frieze%2C+A">Alan Frieze</a>, 
<a href="/search/math?searchtype=author&query=Gao%2C+P">Pu Gao</a>, 
<a href="/search/math?searchtype=author&query=MacRury%2C+C">Calum MacRury</a>, 
<a href="/search/math?searchtype=author&query=Pra%C5%82at%2C+P">Pawe&#x142; Pra&#x142;at</a>, 
<a href="/search/math?searchtype=author&query=Sorkin%2C+G">Gregory Sorkin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages. arXiv admin note: substantial text overlap with <a href="/abs/2205.02350">arXiv:2205.02350</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">The semi-random graph process is an adaptive random graph process in which an
online algorithm is initially presented an empty graph on $n$ vertices. In each
round, a vertex $u$ is presented to the algorithm independently and uniformly
at random. The algorithm then adaptively selects a vertex $v$, and adds the
edge $uv$ to the graph. For a given graph property, the objective of the
algorithm is to force the graph to satisfy this property asymptotically almost
surely in as few rounds as possible.
<br />We focus on the property of Hamiltonicity. We present an adaptive strategy
which creates a Hamiltonian cycle in $\alpha n$ rounds, where $\alpha &lt;
1.81696$ is derived from the solution to a system of differential equations. We
also show that achieving Hamiltonicity requires at least $\beta n$ rounds,
where $\beta &gt; 1.26575$.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05546" title="Abstract">arXiv:2311.05546</a> (cross-list from quant-ph) [<a href="/pdf/2311.05546" title="Download PDF">pdf</a>, <a href="/format/2311.05546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Agent Quantum Reinforcement Learning using Evolutionary  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=K%C3%B6lle%2C+M">Michael K&#xf6;lle</a>, 
<a href="/search/quant-ph?searchtype=author&query=Topp%2C+F">Felix Topp</a>, 
<a href="/search/quant-ph?searchtype=author&query=Phan%2C+T">Thomy Phan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Altmann%2C+P">Philipp Altmann</a>, 
<a href="/search/quant-ph?searchtype=author&query=N%C3%BC%C3%9Flein%2C+J">Jonas N&#xfc;&#xdf;lein</a>, 
<a href="/search/quant-ph?searchtype=author&query=Linnhoff-Popien%2C+C">Claudia Linnhoff-Popien</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Multi-Agent Reinforcement Learning is becoming increasingly more important in
times of autonomous driving and other smart industrial applications.
Simultaneously a promising new approach to Reinforcement Learning arises using
the inherent properties of quantum mechanics, reducing the trainable parameters
of a model significantly. However, gradient-based Multi-Agent Quantum
Reinforcement Learning methods often have to struggle with barren plateaus,
holding them back from matching the performance of classical approaches. We
build upon a existing approach for gradient free Quantum Reinforcement Learning
and propose tree approaches with Variational Quantum Circuits for Multi-Agent
Reinforcement Learning using evolutionary optimization. We evaluate our
approach in the Coin Game environment and compare them to classical approaches.
We showed that our Variational Quantum Circuit approaches perform significantly
better compared to a neural network with a similar amount of trainable
parameters. Compared to the larger neural network, our approaches archive
similar results using $97.88\%$ less parameters.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05559" title="Abstract">arXiv:2311.05559</a> (cross-list from quant-ph) [<a href="/pdf/2311.05559" title="Download PDF">pdf</a>, <a href="/format/2311.05559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disentangling Quantum and Classical Contributions in Hybrid Quantum  Machine Learning Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=K%C3%B6lle%2C+M">Michael K&#xf6;lle</a>, 
<a href="/search/quant-ph?searchtype=author&query=Maurer%2C+J">Jonas Maurer</a>, 
<a href="/search/quant-ph?searchtype=author&query=Altmann%2C+P">Philipp Altmann</a>, 
<a href="/search/quant-ph?searchtype=author&query=S%C3%BCnkel%2C+L">Leo S&#xfc;nkel</a>, 
<a href="/search/quant-ph?searchtype=author&query=Stein%2C+J">Jonas Stein</a>, 
<a href="/search/quant-ph?searchtype=author&query=Linnhoff-Popien%2C+C">Claudia Linnhoff-Popien</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Quantum computing offers the potential for superior computational
capabilities, particularly for data-intensive tasks. However, the current state
of quantum hardware puts heavy restrictions on input size. To address this,
hybrid transfer learning solutions have been developed, merging pre-trained
classical models, capable of handling extensive inputs, with variational
quantum circuits. Yet, it remains unclear how much each component - classical
and quantum - contributes to the model's results. We propose a novel hybrid
architecture: instead of utilizing a pre-trained network for compression, we
employ an autoencoder to derive a compressed version of the input data. This
compressed data is then channeled through the encoder part of the autoencoder
to the quantum component. We assess our model's classification capabilities
against two state-of-the-art hybrid transfer learning architectures, two purely
classical architectures and one quantum architecture. Their accuracy is
compared across four datasets: Banknote Authentication, Breast Cancer
Wisconsin, MNIST digits, and AudioMNIST. Our research suggests that classical
components significantly influence classification in hybrid transfer learning,
a contribution often mistakenly ascribed to the quantum element. The
performance of our model aligns with that of a variational quantum circuit
using amplitude embedding, positioning it as a feasible alternative.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05566" title="Abstract">arXiv:2311.05566</a> (cross-list from math.CO) [<a href="/pdf/2311.05566" title="Download PDF">pdf</a>, <a href="/ps/2311.05566" title="Download PostScript">ps</a>, <a href="/format/2311.05566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On degree-$3$ and $(n-4)$-correlation-immune perfect colorings of  $n$-cubes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Krotov%2C+D+S">Denis S. Krotov</a>, 
<a href="/search/math?searchtype=author&query=Valyuzhenich%2C+A+A">Alexandr A. Valyuzhenich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">A perfect $k$-coloring of the Boolean hypercube $Q_n$ is a function from the
set of binary words of length $n$ onto a $k$-set of colors such that for any
colors $i$ and $j$ every word of color $i$ has exactly $S(i,j)$ neighbors (at
Hamming distance $1$) of color $j$, where the coefficient $S(i,j)$ depend only
on $i$ and $j$ but not on the particular choice of the words. The $k$-by-$k$
table of all coefficients $S(i,j)$ is called the quotient matrix. We
characterize perfect colorings of $Q_n$ of degree at most $3$, that is, with
quotient matrix whose all eigenvalues are not less than $n-6$, or,
equivalently, such that every color corresponds to a Boolean function
represented by a polynomial of degree at most $3$ over $R$. Additionally, we
characterize $(n-4)$-correlation-immune perfect colorings of $Q_n$, whose all
colors correspond to $(n-4)$-correlation-immune Boolean functions, or,
equivalently, all non-main (different from $n$) eigenvalues of the quotient
matrix are not greater than $6-n$.
<br />Keywords: perfect coloring, equitable partition, resilient function,
correlation-immune function.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05573" title="Abstract">arXiv:2311.05573</a> (cross-list from stat.ML) [<a href="/pdf/2311.05573" title="Download PDF">pdf</a>, <a href="/format/2311.05573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Outlier-Robust Wasserstein DRO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Nietert%2C+S">Sloan Nietert</a>, 
<a href="/search/stat?searchtype=author&query=Goldfeld%2C+Z">Ziv Goldfeld</a>, 
<a href="/search/stat?searchtype=author&query=Shafiee%2C+S">Soroosh Shafiee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appearing at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">Distributionally robust optimization (DRO) is an effective approach for
data-driven decision-making in the presence of uncertainty. Geometric
uncertainty due to sampling or localized perturbations of data points is
captured by Wasserstein DRO (WDRO), which seeks to learn a model that performs
uniformly well over a Wasserstein ball centered around the observed data
distribution. However, WDRO fails to account for non-geometric perturbations
such as adversarial outliers, which can greatly distort the Wasserstein
distance measurement and impede the learned model. We address this gap by
proposing a novel outlier-robust WDRO framework for decision-making under both
geometric (Wasserstein) perturbations and non-geometric (total variation (TV))
contamination that allows an $\varepsilon$-fraction of data to be arbitrarily
corrupted. We design an uncertainty set using a certain robust Wasserstein ball
that accounts for both perturbation types and derive minimax optimal excess
risk bounds for this procedure that explicitly capture the Wasserstein and TV
risks. We prove a strong duality result that enables tractable convex
reformulations and efficient computation of our outlier-robust WDRO problem.
When the loss function depends only on low-dimensional features of the data, we
eliminate certain dimension dependencies from the risk bounds that are
unavoidable in the general setting. Finally, we present experiments validating
our theory on standard regression and classification tasks.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05574" title="Abstract">arXiv:2311.05574</a> (cross-list from math.CO) [<a href="/pdf/2311.05574" title="Download PDF">pdf</a>, <a href="/ps/2311.05574" title="Download PostScript">ps</a>, <a href="/format/2311.05574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A near-optimal zero-free disk for the Ising model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Patel%2C+V">Viresh Patel</a>, 
<a href="/search/math?searchtype=author&query=Regts%2C+G">Guus Regts</a>, 
<a href="/search/math?searchtype=author&query=Stam%2C+A">Ayla Stam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS); Mathematical Physics (math-ph)

</div>
<p class="mathjax">The partition function of the Ising model of a graph $G=(V,E)$ is defined as
$Z_{\text{Ising}}(G;b)=\sum_{\sigma:V\to \{0,1\}} b^{m(\sigma)}$, where
$m(\sigma)$ denotes the number of edges $e=\{u,v\}$ such that
$\sigma(u)=\sigma(v)$. We show that for any positive integer $\Delta$ and any
graph $G$ of maximum degree at most $\Delta$, $Z_{\text{Ising}}(G;b)\neq 0$ for
all $b\in \mathbb{C}$ satisfying $|\frac{b-1}{b+1}| \leq
\frac{1-o_\Delta(1)}{\Delta-1}$ (where $o_\Delta(1) \to 0$ as $\Delta\to
\infty$). This is optimal in the sense that $\tfrac{1-o_\Delta(1)}{\Delta-1}$
cannot be replaced by $\tfrac{c}{\Delta-1}$ for any constant $c &gt; 1$ unless
P=NP.
<br />To prove our result we use a standard reformulation of the partition function
of the Ising model as the generating function of even sets. We establish a
zero-free disk for this generating function inspired by techniques from
statistical physics on partition functions of a polymer models. Our approach is
quite general and we discuss extensions of it to a certain types of polymer
models.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Fri, 10 Nov 23</h3>
<dl>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1611.07658" title="Abstract">arXiv:1611.07658</a> (replaced) [<a href="/pdf/1611.07658" title="Download PDF">pdf</a>, <a href="/format/1611.07658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Network Formation Model Based on Subgraphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Chandrasekhar%2C+A+G">Arun G. Chandrasekhar</a>, 
<a href="/search/physics?searchtype=author&query=Jackson%2C+M+O">Matthew O. Jackson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1807.08949" title="Abstract">arXiv:1807.08949</a> (replaced) [<a href="/pdf/1807.08949" title="Download PDF">pdf</a>, <a href="/ps/1807.08949" title="Download PostScript">ps</a>, <a href="/format/1807.08949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Note on Clustering Aggregation for Binary Clusterings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiehua Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hermelin%2C+D">Danny Hermelin</a>, 
<a href="/search/cs?searchtype=author&query=Sorge%2C+M">Manuel Sorge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1902.07497" title="Abstract">arXiv:1902.07497</a> (replaced) [<a href="/pdf/1902.07497" title="Download PDF">pdf</a>, <a href="/format/1902.07497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysing Factorizations of Action-Value Networks for Cooperative  Multi-Agent Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Castellini%2C+J">Jacopo Castellini</a>, 
<a href="/search/cs?searchtype=author&query=Oliehoek%2C+F+A">Frans A. Oliehoek</a>, 
<a href="/search/cs?searchtype=author&query=Savani%2C+R">Rahul Savani</a>, 
<a href="/search/cs?searchtype=author&query=Whiteson%2C+S">Shimon Whiteson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work as been accepted as an Extended Abstract in Proc. of the 18th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2019), N. Agmon, M. E. Taylor, E. Elkind, M. Veloso (eds.), May 2019, Montreal, Canada
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Auton Agent Multi-Agent Syst 35, 25 (2021)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1912.06708" title="Abstract">arXiv:1912.06708</a> (replaced) [<a href="/pdf/1912.06708" title="Download PDF">pdf</a>, <a href="/format/1912.06708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A posteriori Trading-inspired Model-free Time Series Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Plessen%2C+M+G">Mogens Graf Plessen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, double column, 13 figures, 2 tables Accepted at IEEE International Conference on Big Data 2023 (ICBD2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2001.08510" title="Abstract">arXiv:2001.08510</a> (replaced) [<a href="/pdf/2001.08510" title="Download PDF">pdf</a>, <a href="/format/2001.08510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bibliography of distributed approximation beyond bounded degree
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feuilloley%2C+L">Laurent Feuilloley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> An annotated bibliography. Fourth version (October 2023). Approx 5 new papers since 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2002.00540" title="Abstract">arXiv:2002.00540</a> (replaced) [<a href="/pdf/2002.00540" title="Download PDF">pdf</a>, <a href="/format/2002.00540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Query Predicates with Disjunctions for Column-Oriented  Engines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+A">Albert Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ileri%2C+A+M">Atalay Mert Ileri</a>, 
<a href="/search/cs?searchtype=author&query=Madden%2C+S">Sam Madden</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2010.13380" title="Abstract">arXiv:2010.13380</a> (replaced) [<a href="/pdf/2010.13380" title="Download PDF">pdf</a>, <a href="/format/2010.13380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The training accuracy of two-layer neural networks: its estimation and  understanding using random datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+S">Shuyue Guan</a>, 
<a href="/search/cs?searchtype=author&query=Loew%2C+M">Murray Loew</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures. Accepted by IEEE AIPR 2023 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2012.04132" title="Abstract">arXiv:2012.04132</a> (replaced) [<a href="/pdf/2012.04132" title="Download PDF">pdf</a>, <a href="/format/2012.04132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Number Sense as an Emergent Property of the Manipulating Brain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Kondapaneni%2C+N">Neehar Kondapaneni</a>, 
<a href="/search/q-bio?searchtype=author&query=Perona%2C+P">Pietro Perona</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 5 figures, 15 supplemental figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2012.11258" title="Abstract">arXiv:2012.11258</a> (replaced) [<a href="/pdf/2012.11258" title="Download PDF">pdf</a>, <a href="/format/2012.11258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Difference Rewards Policy Gradients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Castellini%2C+J">Jacopo Castellini</a>, 
<a href="/search/cs?searchtype=author&query=Devlin%2C+S">Sam Devlin</a>, 
<a href="/search/cs?searchtype=author&query=Oliehoek%2C+F+A">Frans A. Oliehoek</a>, 
<a href="/search/cs?searchtype=author&query=Savani%2C+R">Rahul Savani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work as been accepted as an Extended Abstract in Proc. of the 20th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2021), U. Endriss, A. Now\'e, F. Dignum, A. Lomuscio (eds.), May 3-7 2021, Online
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Neural Comput &amp; Applic (2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.07505" title="Abstract">arXiv:2104.07505</a> (replaced) [<a href="/pdf/2104.07505" title="Download PDF">pdf</a>, <a href="/format/2104.07505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying Gender Bias Towards Politicians in Cross-Lingual Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sta%C5%84czak%2C+K">Karolina Sta&#x144;czak</a>, 
<a href="/search/cs?searchtype=author&query=Choudhury%2C+S+R">Sagnik Ray Choudhury</a>, 
<a href="/search/cs?searchtype=author&query=Pimentel%2C+T">Tiago Pimentel</a>, 
<a href="/search/cs?searchtype=author&query=Cotterell%2C+R">Ryan Cotterell</a>, 
<a href="/search/cs?searchtype=author&query=Augenstein%2C+I">Isabelle Augenstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.00906" title="Abstract">arXiv:2106.00906</a> (replaced) [<a href="/pdf/2106.00906" title="Download PDF">pdf</a>, <a href="/format/2106.00906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Operator Splitting for Learning to Predict Equilibria in Convex Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McKenzie%2C+D">Daniel McKenzie</a>, 
<a href="/search/cs?searchtype=author&query=Heaton%2C+H">Howard Heaton</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qiuwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Fung%2C+S+W">Samy Wu Fung</a>, 
<a href="/search/cs?searchtype=author&query=Osher%2C+S">Stanley Osher</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+W">Wotao Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.11886" title="Abstract">arXiv:2107.11886</a> (replaced) [<a href="/pdf/2107.11886" title="Download PDF">pdf</a>, <a href="/ps/2107.11886" title="Download PostScript">ps</a>, <a href="/format/2107.11886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Logspace Reducibility From Secret Leakage Planted Clique
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mardia%2C+J">Jay Mardia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Data Structures and Algorithms (cs.DS); Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.01736" title="Abstract">arXiv:2110.01736</a> (replaced) [<a href="/pdf/2110.01736" title="Download PDF">pdf</a>, <a href="/format/2110.01736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdjointBackMapV2: Precise Reconstruction of Arbitrary CNN Unit&#x27;s  Activation via Adjoint Operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+Q">Qing Wan</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+S+W">Siu Wun Cheung</a>, 
<a href="/search/cs?searchtype=author&query=Choe%2C+Y">Yoonsuck Choe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a preprint prior to peer-review. For the revised/finalized version, please see <a href="https://doi.org/10.1016/j.neunet.2023.11.009">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.06659" title="Abstract">arXiv:2201.06659</a> (replaced) [<a href="/pdf/2201.06659" title="Download PDF">pdf</a>, <a href="/format/2201.06659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Blockage Pre-Avoidance using Reconfigurable Intelligent Surfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Makki%2C+B">Behrooz Makki</a>, 
<a href="/search/cs?searchtype=author&query=%C3%85str%C3%B6m%2C+M">Magnus &#xc5;str&#xf6;m</a>, 
<a href="/search/cs?searchtype=author&query=Alouini%2C+M">Mohamed-Slim Alouini</a>, 
<a href="/search/cs?searchtype=author&query=Svensson%2C+T">Tommy Svensson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Communications Magazine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.00825" title="Abstract">arXiv:2203.00825</a> (replaced) [<a href="/pdf/2203.00825" title="Download PDF">pdf</a>, <a href="/format/2203.00825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Effective Resource Procurement in MEC: a Resource Re-selling  Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Siew%2C+M">Marie Siew</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+S">Shikhar Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+K">Kun Guo</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+D">Desmond Cai</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+W">Wanli Wen</a>, 
<a href="/search/cs?searchtype=author&query=Joe-Wong%2C+C">Carlee Joe-Wong</a>, 
<a href="/search/cs?searchtype=author&query=Quek%2C+T+Q+S">Tony Q.S. Quek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE Transactions on Services Computing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.16463" title="Abstract">arXiv:2203.16463</a> (replaced) [<a href="/pdf/2203.16463" title="Download PDF">pdf</a>, <a href="/ps/2203.16463" title="Download PostScript">ps</a>, <a href="/format/2203.16463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perfectly Accurate Membership Inference by a Dishonest Central Server in  Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pichler%2C+G">Georg Pichler</a>, 
<a href="/search/cs?searchtype=author&query=Romanelli%2C+M">Marco Romanelli</a>, 
<a href="/search/cs?searchtype=author&query=Vega%2C+L+R">Leonardo Rey Vega</a>, 
<a href="/search/cs?searchtype=author&query=Piantanida%2C+P">Pablo Piantanida</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted for publication in IEEE Transactions on Dependable and Secure Computing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.07028" title="Abstract">arXiv:2204.07028</a> (replaced) [<a href="/pdf/2204.07028" title="Download PDF">pdf</a>, <a href="/format/2204.07028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Distributed Knowledge Congruence in Proxy-data-free  Federated Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhiyuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Sheng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Min Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Q">Quyang Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junbo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zeju Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qingxiang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM Transactions on Intelligent Systems and Technology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.07501" title="Abstract">arXiv:2204.07501</a> (replaced) [<a href="/pdf/2204.07501" title="Download PDF">pdf</a>, <a href="/format/2204.07501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating few shot and Contrastive learning Methods for Code Clone  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khajezade%2C+M">Mohamad Khajezade</a>, 
<a href="/search/cs?searchtype=author&query=Fard%2C+F+H">Fatemeh Hendijani Fard</a>, 
<a href="/search/cs?searchtype=author&query=Shehata%2C+M+S">Mohamed S. Shehata</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.09885" title="Abstract">arXiv:2204.09885</a> (replaced) [<a href="/pdf/2204.09885" title="Download PDF">pdf</a>, <a href="/format/2204.09885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Attention-Based Model for Predicting Contextual Informativeness and  Curriculum Learning Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nam%2C+S">Sungjin Nam</a>, 
<a href="/search/cs?searchtype=author&query=Jurgens%2C+D">David Jurgens</a>, 
<a href="/search/cs?searchtype=author&query=Frishkoff%2C+G">Gwen Frishkoff</a>, 
<a href="/search/cs?searchtype=author&query=Collins-Thompson%2C+K">Kevyn Collins-Thompson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.11753" title="Abstract">arXiv:2204.11753</a> (replaced) [<a href="/pdf/2204.11753" title="Download PDF">pdf</a>, <a href="/format/2204.11753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Number Partitioning with Splitting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bismuth%2C+S">Samuel Bismuth</a>, 
<a href="/search/cs?searchtype=author&query=Makarov%2C+V">Vladislav Makarov</a>, 
<a href="/search/cs?searchtype=author&query=Segal-Halevi%2C+E">Erel Segal-Halevi</a>, 
<a href="/search/cs?searchtype=author&query=Shapira%2C+D">Dana Shapira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.05211" title="Abstract">arXiv:2205.05211</a> (replaced) [<a href="/pdf/2205.05211" title="Download PDF">pdf</a>, <a href="/format/2205.05211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parallel Private Retrieval of Merkle Proofs via Tree Colorings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Q">Quang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Gagiano%2C+R">Rinaldo Gagiano</a>, 
<a href="/search/cs?searchtype=author&query=Huynh%2C+D">Duy Huynh</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+X">Xun Yi</a>, 
<a href="/search/cs?searchtype=author&query=Dau%2C+S+H">Son Hoang Dau</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+P+L">Phuc Lu Le</a>, 
<a href="/search/cs?searchtype=author&query=Luu%2C+Q">Quang-Hung Luu</a>, 
<a href="/search/cs?searchtype=author&query=Viterbo%2C+E">Emanuele Viterbo</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yu-Chih Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jingge Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Jalalzai%2C+M+M">Mohammad M. Jalalzai</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Chen Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Cryptography and Security (cs.CR); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.08913" title="Abstract">arXiv:2205.08913</a> (replaced) [<a href="/pdf/2205.08913" title="Download PDF">pdf</a>, <a href="/ps/2205.08913" title="Download PostScript">ps</a>, <a href="/format/2205.08913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Price Interpretability of Prediction Markets: A Convergence Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Yu%2C+D">Dian Yu</a>, 
<a href="/search/q-fin?searchtype=author&query=Gao%2C+J">Jianjun Gao</a>, 
<a href="/search/q-fin?searchtype=author&query=Wu%2C+W">Weiping Wu</a>, 
<a href="/search/q-fin?searchtype=author&query=Wang%2C+Z">Zizhuo Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Trading and Market Microstructure (q-fin.TR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.09048" title="Abstract">arXiv:2205.09048</a> (replaced) [<a href="/pdf/2205.09048" title="Download PDF">pdf</a>, <a href="/format/2205.09048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Global Contrast Masked Autoencoders Are Powerful Pathological  Representation Learners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Quan%2C+H">Hao Quan</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xingyu Li</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+W">Weixing Chen</a>, 
<a href="/search/eess?searchtype=author&query=Bai%2C+Q">Qun Bai</a>, 
<a href="/search/eess?searchtype=author&query=Zou%2C+M">Mingchen Zou</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+R">Ruijie Yang</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+T">Tingting Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Qi%2C+R">Ruiqun Qi</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+X">Xinghua Gao</a>, 
<a href="/search/eess?searchtype=author&query=Cui%2C+X">Xiaoyu Cui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.04798" title="Abstract">arXiv:2206.04798</a> (replaced) [<a href="/pdf/2206.04798" title="Download PDF">pdf</a>, <a href="/format/2206.04798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A*Net: A Scalable Path-based Reasoning Approach for Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhaocheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xinyu Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Galkin%2C+M">Mikhail Galkin</a>, 
<a href="/search/cs?searchtype=author&query=Xhonneux%2C+S">Sophie Xhonneux</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Ming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gazeau%2C+M">Maxime Gazeau</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jian Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.09595" title="Abstract">arXiv:2206.09595</a> (replaced) [<a href="/pdf/2206.09595" title="Download PDF">pdf</a>, <a href="/format/2206.09595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconstruction and segmentation from sparse sequential X-ray  measurements of wood logs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Springer%2C+S">Sebastian Springer</a>, 
<a href="/search/eess?searchtype=author&query=Glielmo%2C+A">Aldo Glielmo</a>, 
<a href="/search/eess?searchtype=author&query=Senchukova%2C+A">Angelina Senchukova</a>, 
<a href="/search/eess?searchtype=author&query=Kauppi%2C+T">Tomi Kauppi</a>, 
<a href="/search/eess?searchtype=author&query=Suuronen%2C+J">Jarkko Suuronen</a>, 
<a href="/search/eess?searchtype=author&query=Roininen%2C+L">Lassi Roininen</a>, 
<a href="/search/eess?searchtype=author&query=Haario%2C+H">Heikki Haario</a>, 
<a href="/search/eess?searchtype=author&query=Hauptmann%2C+A">Andreas Hauptmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Computational Engineering, Finance, and Science (cs.CE); Optimization and Control (math.OC); Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.11832" title="Abstract">arXiv:2206.11832</a> (replaced) [<a href="/pdf/2206.11832" title="Download PDF">pdf</a>, <a href="/format/2206.11832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the parameterized complexity of computing tree-partitions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bodlaender%2C+H+L">Hans L. Bodlaender</a>, 
<a href="/search/cs?searchtype=author&query=Groenland%2C+C">Carla Groenland</a>, 
<a href="/search/cs?searchtype=author&query=Jacob%2C+H">Hugo Jacob</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.13862" title="Abstract">arXiv:2207.13862</a> (replaced) [<a href="/pdf/2207.13862" title="Download PDF">pdf</a>, <a href="/format/2207.13862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HDSDP: Software for Semidefinite Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+W">Wenzhi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+D">Dongdong Ge</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yinyu Ye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Software (cs.MS)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.11642" title="Abstract">arXiv:2208.11642</a> (replaced) [<a href="/pdf/2208.11642" title="Download PDF">pdf</a>, <a href="/ps/2208.11642" title="Download PostScript">ps</a>, <a href="/format/2208.11642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the existence of strong proof complexity generators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krajicek%2C+J">Jan Krajicek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preliminary version August 2022, revised July 2023 and November 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Logic in Computer Science (cs.LO); Logic (math.LO)

</div>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.00445" title="Abstract">arXiv:2209.00445</a> (replaced) [<a href="/pdf/2209.00445" title="Download PDF">pdf</a>, <a href="/format/2209.00445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpreting Embedding Spaces by Conceptualization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Simhi%2C+A">Adi Simhi</a>, 
<a href="/search/cs?searchtype=author&query=Markovitch%2C+S">Shaul Markovitch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.05954" title="Abstract">arXiv:2209.05954</a> (replaced) [<a href="/pdf/2209.05954" title="Download PDF">pdf</a>, <a href="/format/2209.05954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatically Score Tissue Images Like a Pathologist by Transfer  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+I">Iris Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.07932" title="Abstract">arXiv:2209.07932</a> (replaced) [<a href="/pdf/2209.07932" title="Download PDF">pdf</a>, <a href="/format/2209.07932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Top-Tuning: a study on transfer learning for an efficient alternative to  fine tuning for image classification with fast kernel methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alfano%2C+P+D">Paolo Didier Alfano</a>, 
<a href="/search/cs?searchtype=author&query=Pastore%2C+V+P">Vito Paolo Pastore</a>, 
<a href="/search/cs?searchtype=author&query=Rosasco%2C+L">Lorenzo Rosasco</a>, 
<a href="/search/cs?searchtype=author&query=Odone%2C+F">Francesca Odone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.12493" title="Abstract">arXiv:2209.12493</a> (replaced) [<a href="/pdf/2209.12493" title="Download PDF">pdf</a>, <a href="/format/2209.12493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Predictive Monitoring of Dynamical Systems for Signal Temporal  Logic Specifications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yu%2C+X">Xinyi Yu</a>, 
<a href="/search/eess?searchtype=author&query=Dong%2C+W">Weijie Dong</a>, 
<a href="/search/eess?searchtype=author&query=Yin%2C+X">Xiang Yin</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+S">Shaoyuan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted to Automatica. arXiv admin note: substantial text overlap with <a href="/abs/2203.16267">arXiv:2203.16267</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.09134" title="Abstract">arXiv:2210.09134</a> (replaced) [<a href="/pdf/2210.09134" title="Download PDF">pdf</a>, <a href="/ps/2210.09134" title="Download PostScript">ps</a>, <a href="/format/2210.09134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Principled Pruning of Bayesian Neural Networks through Variational Free  Energy Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beckers%2C+J">Jim Beckers</a>, 
<a href="/search/cs?searchtype=author&query=van+Erp%2C+B">Bart van Erp</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Ziyue Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Kondrashov%2C+K">Kirill Kondrashov</a>, 
<a href="/search/cs?searchtype=author&query=de+Vries%2C+B">Bert de Vries</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.10962" title="Abstract">arXiv:2210.10962</a> (replaced) [<a href="/pdf/2210.10962" title="Download PDF">pdf</a>, <a href="/format/2210.10962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimization on Manifolds via Graph Gaussian Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Kim%2C+H">Hwanwoo Kim</a>, 
<a href="/search/stat?searchtype=author&query=Sanz-Alonso%2C+D">Daniel Sanz-Alonso</a>, 
<a href="/search/stat?searchtype=author&query=Yang%2C+R">Ruiyi Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.15642" title="Abstract">arXiv:2210.15642</a> (replaced) [<a href="/pdf/2210.15642" title="Download PDF">pdf</a>, <a href="/ps/2210.15642" title="Download PostScript">ps</a>, <a href="/format/2210.15642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Existential Definability over the Subword Ordering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baumann%2C+P">Pascal Baumann</a>, 
<a href="/search/cs?searchtype=author&query=Ganardi%2C+M">Moses Ganardi</a>, 
<a href="/search/cs?searchtype=author&query=Thinniyam%2C+R+S">Ramanathan S. Thinniyam</a>, 
<a href="/search/cs?searchtype=author&query=Zetzsche%2C+G">Georg Zetzsche</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.12845" title="Abstract">arXiv:2211.12845</a> (replaced) [<a href="/pdf/2211.12845" title="Download PDF">pdf</a>, <a href="/format/2211.12845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Super-resolution Reconstruction of Single Image for Latent features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/eess?searchtype=author&query=Yan%2C+J">Jing-Ke Yan</a>, 
<a href="/search/eess?searchtype=author&query=Cai%2C+J">Jing-Ye Cai</a>, 
<a href="/search/eess?searchtype=author&query=Deng%2C+J">Jian-Hua Deng</a>, 
<a href="/search/eess?searchtype=author&query=Qin%2C+Q">Qin Qin</a>, 
<a href="/search/eess?searchtype=author&query=Cheng%2C+Y">Yao Cheng</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computational Visual Media,2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.03080" title="Abstract">arXiv:2212.03080</a> (replaced) [<a href="/pdf/2212.03080" title="Download PDF">pdf</a>, <a href="/format/2212.03080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Straggler-Resilient Differentially-Private Decentralized Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yakimenka%2C+Y">Yauhen Yakimenka</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+C">Chung-Wei Weng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hsuan-Yin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Rosnes%2C+E">Eirik Rosnes</a>, 
<a href="/search/cs?searchtype=author&query=Kliewer%2C+J">J&#xf6;rg Kliewer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was presented in part at the IEEE Information Theory Workshop (ITW), Mumbai, India, November 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.09015" title="Abstract">arXiv:2212.09015</a> (replaced) [<a href="/pdf/2212.09015" title="Download PDF">pdf</a>, <a href="/format/2212.09015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GAN-based Tabular Data Generator for Constructing Synopsis in  Approximate Query Processing: Challenges and Solutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fallahian%2C+M">Mohammadali Fallahian</a>, 
<a href="/search/cs?searchtype=author&query=Dorodchi%2C+M">Mohsen Dorodchi</a>, 
<a href="/search/cs?searchtype=author&query=Kreth%2C+K">Kyle Kreth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.02982" title="Abstract">arXiv:2301.02982</a> (replaced) [<a href="/pdf/2301.02982" title="Download PDF">pdf</a>, <a href="/format/2301.02982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Why Batch Normalization Damage Federated Learning on Non-IID Data?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanmeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Q">Qingjiang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+T">Tsung-Hui Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.03081" title="Abstract">arXiv:2301.03081</a> (replaced) [<a href="/pdf/2301.03081" title="Download PDF">pdf</a>, <a href="/ps/2301.03081" title="Download PostScript">ps</a>, <a href="/format/2301.03081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Diagnosis of Carotid Atherosclerosis Using a Portable Freehand  3D Ultrasound Imaging System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+J">Jiawen Li</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+Y">Yunqian Huang</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+S">Sheng Song</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+H">Hongbo Chen</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+J">Junni Shi</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+D">Duo Xu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+H">Haibin Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+M">Man Chen</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+R">Rui Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.08067" title="Abstract">arXiv:2301.08067</a> (replaced) [<a href="/pdf/2301.08067" title="Download PDF">pdf</a>, <a href="/ps/2301.08067" title="Download PostScript">ps</a>, <a href="/format/2301.08067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpreting CNN Predictions using Conditional Generative Adversarial  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guna%2C+R+T+A">R T Akash Guna</a>, 
<a href="/search/cs?searchtype=author&query=Benitez%2C+R">Raul Benitez</a>, 
<a href="/search/cs?searchtype=author&query=Sikha%2C+O+K">O K Sikha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.09633" title="Abstract">arXiv:2301.09633</a> (replaced) [<a href="/pdf/2301.09633" title="Download PDF">pdf</a>, <a href="/format/2301.09633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prediction-Powered Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Angelopoulos%2C+A+N">Anastasios N. Angelopoulos</a>, 
<a href="/search/stat?searchtype=author&query=Bates%2C+S">Stephen Bates</a>, 
<a href="/search/stat?searchtype=author&query=Fannjiang%2C+C">Clara Fannjiang</a>, 
<a href="/search/stat?searchtype=author&query=Jordan%2C+M+I">Michael I. Jordan</a>, 
<a href="/search/stat?searchtype=author&query=Zrnic%2C+T">Tijana Zrnic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is available at <a href="https://github.com/aangelopoulos/ppi_py">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.09734" title="Abstract">arXiv:2301.09734</a> (replaced) [<a href="/pdf/2301.09734" title="Download PDF">pdf</a>, <a href="/format/2301.09734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topological Learning in Multi-Class Data Sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Griffin%2C+C">Christopher Griffin</a>, 
<a href="/search/cs?searchtype=author&query=Karn%2C+T">Trevor Karn</a>, 
<a href="/search/cs?searchtype=author&query=Apple%2C+B">Benjamin Apple</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 18 figures. This is a complete revision of v1
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Analysis, Statistics and Probability (physics.data-an)

</div>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10171" title="Abstract">arXiv:2301.10171</a> (replaced) [<a href="/pdf/2301.10171" title="Download PDF">pdf</a>, <a href="/format/2301.10171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral Cross-Domain Neural Network with Soft-adaptive Threshold  Spectral Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Che Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Sibo Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+W">Weiping Ding</a>, 
<a href="/search/cs?searchtype=author&query=Arcucci%2C+R">Rossella Arcucci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12534" title="Abstract">arXiv:2301.12534</a> (replaced) [<a href="/pdf/2301.12534" title="Download PDF">pdf</a>, <a href="/format/2301.12534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vicarious Offense and Noise Audit of Offensive Speech Classifiers:  Unifying Human and Machine Disagreement on What is Offensive
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weerasooriya%2C+T+C">Tharindu Cyril Weerasooriya</a>, 
<a href="/search/cs?searchtype=author&query=Dutta%2C+S">Sujan Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Ranasinghe%2C+T">Tharindu Ranasinghe</a>, 
<a href="/search/cs?searchtype=author&query=Zampieri%2C+M">Marcos Zampieri</a>, 
<a href="/search/cs?searchtype=author&query=Homan%2C+C+M">Christopher M. Homan</a>, 
<a href="/search/cs?searchtype=author&query=KhudaBukhsh%2C+A+R">Ashiqur R. KhudaBukhsh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to appear at EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.00856" title="Abstract">arXiv:2302.00856</a> (replaced) [<a href="/pdf/2302.00856" title="Download PDF">pdf</a>, <a href="/ps/2302.00856" title="Download PostScript">ps</a>, <a href="/format/2302.00856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> idT5: Indonesian Version of Multilingual T5 Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fuadi%2C+M">Mukhlish Fuadi</a>, 
<a href="/search/cs?searchtype=author&query=Wibawa%2C+A+D">Adhi Dharma Wibawa</a>, 
<a href="/search/cs?searchtype=author&query=Sumpeno%2C+S">Surya Sumpeno</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01056" title="Abstract">arXiv:2302.01056</a> (replaced) [<a href="/pdf/2302.01056" title="Download PDF">pdf</a>, <a href="/format/2302.01056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Pretrained Features: Noisy Image Modeling Provides Adversarial  Defense
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=You%2C+Z">Zunzhi You</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Daochang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bohyung Han</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chang Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01713" title="Abstract">arXiv:2302.01713</a> (replaced) [<a href="/pdf/2302.01713" title="Download PDF">pdf</a>, <a href="/format/2302.01713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Avoiding the Data Mess: Industry Insights from Data Mesh  Implementations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bode%2C+J">Jan Bode</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%BChl%2C+N">Niklas K&#xfc;hl</a>, 
<a href="/search/cs?searchtype=author&query=Kreuzberger%2C+D">Dominik Kreuzberger</a>, 
<a href="/search/cs?searchtype=author&query=Hirschl%2C+S">Sebastian Hirschl</a>, 
<a href="/search/cs?searchtype=author&query=Holtmann%2C+C">Carsten Holtmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.04023" title="Abstract">arXiv:2302.04023</a> (replaced) [<a href="/pdf/2302.04023" title="Download PDF">pdf</a>, <a href="/format/2302.04023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on  Reasoning, Hallucination, and Interactivity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bang%2C+Y">Yejin Bang</a>, 
<a href="/search/cs?searchtype=author&query=Cahyawijaya%2C+S">Samuel Cahyawijaya</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+N">Nayeon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+W">Wenliang Dai</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+D">Dan Su</a>, 
<a href="/search/cs?searchtype=author&query=Wilie%2C+B">Bryan Wilie</a>, 
<a href="/search/cs?searchtype=author&query=Lovenia%2C+H">Holy Lovenia</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Z">Ziwei Ji</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tiezheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+W">Willy Chung</a>, 
<a href="/search/cs?searchtype=author&query=Do%2C+Q+V">Quyet V. Do</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Fung%2C+P">Pascale Fung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages, AACL 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.08688" title="Abstract">arXiv:2302.08688</a> (replaced) [<a href="/pdf/2302.08688" title="Download PDF">pdf</a>, <a href="/format/2302.08688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Classification of SARS-CoV-2 Spike Sequences Using Federated  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chourasia%2C+P">Prakash Chourasia</a>, 
<a href="/search/cs?searchtype=author&query=Murad%2C+T">Taslim Murad</a>, 
<a href="/search/cs?searchtype=author&query=Tayebi%2C+Z">Zahra Tayebi</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+S">Sarwan Ali</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+I+U">Imdad Ullah Khan</a>, 
<a href="/search/cs?searchtype=author&query=Patterson%2C+M">Murray Patterson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures, Accepted at 10th International Conference on Information Management and Big Data (SIMBig 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.08934" title="Abstract">arXiv:2302.08934</a> (replaced) [<a href="/pdf/2302.08934" title="Download PDF">pdf</a>, <a href="/format/2302.08934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active RIS Aided ISAC Systems: Beamforming Design and Performance  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhiyuan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+H">Hong Ren</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+C">Cunhua Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Gui Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Boshi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+M">Mianxiong Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiangzhou Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages,11 figures, accepted by IEEE TCOM
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09239" title="Abstract">arXiv:2302.09239</a> (replaced) [<a href="/pdf/2302.09239" title="Download PDF">pdf</a>, <a href="/ps/2302.09239" title="Download PostScript">ps</a>, <a href="/format/2302.09239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster Wavelet Tree Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ceregini%2C+M">Matteo Ceregini</a>, 
<a href="/search/cs?searchtype=author&query=Kurpicz%2C+F">Florian Kurpicz</a>, 
<a href="/search/cs?searchtype=author&query=Venturini%2C+R">Rossano Venturini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.10093" title="Abstract">arXiv:2302.10093</a> (replaced) [<a href="/pdf/2302.10093" title="Download PDF">pdf</a>, <a href="/format/2302.10093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Progressive Ensemble Distillation: Building Ensembles for Efficient  Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dennis%2C+D+K">Don Kurian Dennis</a>, 
<a href="/search/cs?searchtype=author&query=Shetty%2C+A">Abhishek Shetty</a>, 
<a href="/search/cs?searchtype=author&query=Sevekari%2C+A">Anish Sevekari</a>, 
<a href="/search/cs?searchtype=author&query=Koishida%2C+K">Kazuhito Koishida</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+V">Virginia Smith</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.10158" title="Abstract">arXiv:2302.10158</a> (replaced) [<a href="/pdf/2302.10158" title="Download PDF">pdf</a>, <a href="/ps/2302.10158" title="Download PostScript">ps</a>, <a href="/format/2302.10158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse PCA Beyond Covariance Thresholding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Novikov%2C+G">Gleb Novikov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> COLT 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.12761" title="Abstract">arXiv:2302.12761</a> (replaced) [<a href="/pdf/2302.12761" title="Download PDF">pdf</a>, <a href="/ps/2302.12761" title="Download PostScript">ps</a>, <a href="/format/2302.12761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Randomized low-rank approximation of parameter-dependent matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kressner%2C+D">Daniel Kressner</a>, 
<a href="/search/math?searchtype=author&query=Lam%2C+H+Y">Hei Yin Lam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00618" title="Abstract">arXiv:2303.00618</a> (replaced) [<a href="/pdf/2303.00618" title="Download PDF">pdf</a>, <a href="/format/2303.00618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robustness of quantum algorithms against coherent control errors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Berberich%2C+J">Julian Berberich</a>, 
<a href="/search/quant-ph?searchtype=author&query=Fink%2C+D">Daniel Fink</a>, 
<a href="/search/quant-ph?searchtype=author&query=Holm%2C+C">Christian Holm</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00986" title="Abstract">arXiv:2303.00986</a> (replaced) [<a href="/pdf/2303.00986" title="Download PDF">pdf</a>, <a href="/format/2303.00986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pay Less But Get More: A Dual-Attention-based Channel Estimation Network  for Massive MIMO Systems with Low-Density Pilots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhou%2C+B">Binggui Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+X">Xi Yang</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+S">Shaodan Ma</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+F">Feifei Gao</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+G">Guanghua Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 9 figures, 6 tables. Accepted by IEEE Transactions on Wireless Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01353" title="Abstract">arXiv:2303.01353</a> (replaced) [<a href="/pdf/2303.01353" title="Download PDF">pdf</a>, <a href="/format/2303.01353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Penalising the biases in norm regularisation enforces sparsity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Boursier%2C+E">Etienne Boursier</a>, 
<a href="/search/stat?searchtype=author&query=Flammarion%2C+N">Nicolas Flammarion</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02738" title="Abstract">arXiv:2303.02738</a> (replaced) [<a href="/pdf/2303.02738" title="Download PDF">pdf</a>, <a href="/format/2303.02738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncoupled and Convergent Learning in Two-Player Zero-Sum Markov Games  with Bandit Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Haipeng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+C">Chen-Yu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Weiqiang Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05089" title="Abstract">arXiv:2303.05089</a> (replaced) [<a href="/pdf/2303.05089" title="Download PDF">pdf</a>, <a href="/format/2303.05089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adiabatic elimination for composite open quantum systems: reduced model  formulation and numerical simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=R%C3%A9gent%2C+F+L">Fran&#xe7;ois-Marie Le R&#xe9;gent</a>, 
<a href="/search/quant-ph?searchtype=author&query=Rouchon%2C+P">Pierre Rouchon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted, minor release from the previous one
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Dynamical Systems (math.DS); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05828" title="Abstract">arXiv:2303.05828</a> (replaced) [<a href="/pdf/2303.05828" title="Download PDF">pdf</a>, <a href="/format/2303.05828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapting Contrastive Language-Image Pretrained (CLIP) Models for  Out-of-Distribution Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adaloglou%2C+N">Nikolas Adaloglou</a>, 
<a href="/search/cs?searchtype=author&query=Michels%2C+F">Felix Michels</a>, 
<a href="/search/cs?searchtype=author&query=Kaiser%2C+T">Tim Kaiser</a>, 
<a href="/search/cs?searchtype=author&query=Kollmann%2C+M">Markus Kollmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> version_02
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08222" title="Abstract">arXiv:2303.08222</a> (replaced) [<a href="/pdf/2303.08222" title="Download PDF">pdf</a>, <a href="/format/2303.08222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disconnected from Reality: Do the core concepts of the metaverse exclude  disabled individuals?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Quinlan%2C+M">Mark Quinlan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> TIAM23 Workshop at ACM CHI 23, Hamburg, Germany
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08507" title="Abstract">arXiv:2303.08507</a> (replaced) [<a href="/pdf/2303.08507" title="Download PDF">pdf</a>, <a href="/format/2303.08507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonatomic Non-Cooperative Neighbourhood Balancing Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Auger%2C+D">David Auger</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+J">Johanne Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Lobstein%2C+A">Antoine Lobstein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 6 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08789" title="Abstract">arXiv:2303.08789</a> (replaced) [<a href="/pdf/2303.08789" title="Download PDF">pdf</a>, <a href="/format/2303.08789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PLEX: Making the Most of the Available Data for Robotic Manipulation  Pretraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thomas%2C+G">Garrett Thomas</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+C">Ching-An Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Loynd%2C+R">Ricky Loynd</a>, 
<a href="/search/cs?searchtype=author&query=Frujeri%2C+F+V">Felipe Vieira Frujeri</a>, 
<a href="/search/cs?searchtype=author&query=Vineet%2C+V">Vibhav Vineet</a>, 
<a href="/search/cs?searchtype=author&query=Jalobeanu%2C+M">Mihai Jalobeanu</a>, 
<a href="/search/cs?searchtype=author&query=Kolobov%2C+A">Andrey Kolobov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00549" title="Abstract">arXiv:2304.00549</a> (replaced) [<a href="/pdf/2304.00549" title="Download PDF">pdf</a>, <a href="/format/2304.00549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variational Denoising for Variational Quantum Eigensolver
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Tran%2C+Q+H">Quoc Hoan Tran</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kikuchi%2C+S">Shinji Kikuchi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Oshima%2C+H">Hirotaka Oshima</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> main text: 6 pages, 5 figures Supplementary Material: 16 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03183" title="Abstract">arXiv:2304.03183</a> (replaced) [<a href="/pdf/2304.03183" title="Download PDF">pdf</a>, <a href="/format/2304.03183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> History-deterministic Timed Automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bose%2C+S">Sougata Bose</a>, 
<a href="/search/cs?searchtype=author&query=Henzinger%2C+T+A">Thomas A. Henzinger</a>, 
<a href="/search/cs?searchtype=author&query=Lehtinen%2C+K">Karoliina Lehtinen</a>, 
<a href="/search/cs?searchtype=author&query=Schewe%2C+S">Sven Schewe</a>, 
<a href="/search/cs?searchtype=author&query=Totzke%2C+P">Patrick Totzke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03251" title="Abstract">arXiv:2304.03251</a> (replaced) [<a href="/pdf/2304.03251" title="Download PDF">pdf</a>, <a href="/format/2304.03251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SALUDA: Surface-based Automotive Lidar Unsupervised Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Michele%2C+B">Bjoern Michele</a>, 
<a href="/search/cs?searchtype=author&query=Boulch%2C+A">Alexandre Boulch</a>, 
<a href="/search/cs?searchtype=author&query=Puy%2C+G">Gilles Puy</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+T">Tuan-Hung Vu</a>, 
<a href="/search/cs?searchtype=author&query=Marlet%2C+R">Renaud Marlet</a>, 
<a href="/search/cs?searchtype=author&query=Courty%2C+N">Nicolas Courty</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to 3DV 2024. Project repository: github.com/valeoai/SALUDA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04234" title="Abstract">arXiv:2304.04234</a> (replaced) [<a href="/pdf/2304.04234" title="Download PDF">pdf</a>, <a href="/format/2304.04234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variational operator learning: A unified paradigm marrying training  neural operators and solving partial differential equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tengfei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dachuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+P">Peng Hao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bo Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This version mainly improves the quality of the bitmaps in the results compared to the previous version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07687" title="Abstract">arXiv:2304.07687</a> (replaced) [<a href="/pdf/2304.07687" title="Download PDF">pdf</a>, <a href="/format/2304.07687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MLRegTest: A Benchmark for the Machine Learning of Regular Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+der+Poel%2C+S">Sam van der Poel</a>, 
<a href="/search/cs?searchtype=author&query=Lambert%2C+D">Dakotah Lambert</a>, 
<a href="/search/cs?searchtype=author&query=Kostyszyn%2C+K">Kalina Kostyszyn</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+T">Tiantian Gao</a>, 
<a href="/search/cs?searchtype=author&query=Verma%2C+R">Rahul Verma</a>, 
<a href="/search/cs?searchtype=author&query=Andersen%2C+D">Derek Andersen</a>, 
<a href="/search/cs?searchtype=author&query=Chau%2C+J">Joanne Chau</a>, 
<a href="/search/cs?searchtype=author&query=Peterson%2C+E">Emily Peterson</a>, 
<a href="/search/cs?searchtype=author&query=Clair%2C+C+S">Cody St. Clair</a>, 
<a href="/search/cs?searchtype=author&query=Fodor%2C+P">Paul Fodor</a>, 
<a href="/search/cs?searchtype=author&query=Shibata%2C+C">Chihiro Shibata</a>, 
<a href="/search/cs?searchtype=author&query=Heinz%2C+J">Jeffrey Heinz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, MLRegTest benchmark available at <a href="https://doi.org/10.5061/dryad.dncjsxm4h">this https URL</a> , associated code at <a href="https://github.com/heinz-jeffrey/subregular-learning">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07880" title="Abstract">arXiv:2304.07880</a> (replaced) [<a href="/pdf/2304.07880" title="Download PDF">pdf</a>, <a href="/format/2304.07880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sabi&#xe1;: Portuguese Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pires%2C+R">Ramon Pires</a>, 
<a href="/search/cs?searchtype=author&query=Abonizio%2C+H">Hugo Abonizio</a>, 
<a href="/search/cs?searchtype=author&query=Almeida%2C+T+S">Thales Sales Almeida</a>, 
<a href="/search/cs?searchtype=author&query=Nogueira%2C+R">Rodrigo Nogueira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10957" title="Abstract">arXiv:2304.10957</a> (replaced) [<a href="/pdf/2304.10957" title="Download PDF">pdf</a>, <a href="/format/2304.10957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Port-Hamiltonian formulation and structure-preserving discretization of  hyperelastic strings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kinon%2C+P+L">Philipp L. Kinon</a>, 
<a href="/search/math?searchtype=author&query=Thoma%2C+T">Tobias Thoma</a>, 
<a href="/search/math?searchtype=author&query=Betsch%2C+P">Peter Betsch</a>, 
<a href="/search/math?searchtype=author&query=Kotyczka%2C+P">Paul Kotyczka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures. Submitted as a proceeding to the ECCOMAS Thematic Conference on Multibody Dynamics 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Computational Engineering, Finance, and Science (cs.CE); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13000" title="Abstract">arXiv:2304.13000</a> (replaced) [<a href="/pdf/2304.13000" title="Download PDF">pdf</a>, <a href="/format/2304.13000" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segment anything, from space?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Simiao Ren</a>, 
<a href="/search/cs?searchtype=author&query=Luzi%2C+F">Francesco Luzi</a>, 
<a href="/search/cs?searchtype=author&query=Lahrichi%2C+S">Saad Lahrichi</a>, 
<a href="/search/cs?searchtype=author&query=Kassaw%2C+K">Kaleb Kassaw</a>, 
<a href="/search/cs?searchtype=author&query=Collins%2C+L+M">Leslie M. Collins</a>, 
<a href="/search/cs?searchtype=author&query=Bradbury%2C+K">Kyle Bradbury</a>, 
<a href="/search/cs?searchtype=author&query=Malof%2C+J+M">Jordan M. Malof</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work accepted at WACV 2024, this is only a pre-print, please go to WACV website for the official version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.01588" title="Abstract">arXiv:2305.01588</a> (replaced) [<a href="/pdf/2305.01588" title="Download PDF">pdf</a>, <a href="/format/2305.01588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Gradient Clipping: Stochastic bias and tight convergence  guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koloskova%2C+A">Anastasia Koloskova</a>, 
<a href="/search/cs?searchtype=author&query=Hendrikx%2C+H">Hadrien Hendrikx</a>, 
<a href="/search/cs?searchtype=author&query=Stich%2C+S+U">Sebastian U. Stich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07567" title="Abstract">arXiv:2305.07567</a> (replaced) [<a href="/pdf/2305.07567" title="Download PDF">pdf</a>, <a href="/format/2305.07567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Critical Theorem for q-Polymatroids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Alfarano%2C+G+N">Gianira N. Alfarano</a>, 
<a href="/search/math?searchtype=author&query=Byrne%2C+E">Eimear Byrne</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08422" title="Abstract">arXiv:2305.08422</a> (replaced) [<a href="/pdf/2305.08422" title="Download PDF">pdf</a>, <a href="/ps/2305.08422" title="Download PostScript">ps</a>, <a href="/format/2305.08422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The generalized Pythagorean theorem on the compactifications of certain  dually flat spaces via toric geometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Fujita%2C+H">Hajime Fujita</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 4 figures : Minor revisions on the format, title changed according to referee's suggestion, typos corrected, explanation added, to appear in Information Geometry
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symplectic Geometry (math.SG)</span>; Information Theory (cs.IT); Differential Geometry (math.DG)

</div>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10564" title="Abstract">arXiv:2305.10564</a> (replaced) [<a href="/pdf/2305.10564" title="Download PDF">pdf</a>, <a href="/format/2305.10564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Counterfactually Comparing Abstaining Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Choe%2C+Y+J">Yo Joong Choe</a>, 
<a href="/search/stat?searchtype=author&query=Gangrade%2C+A">Aditya Gangrade</a>, 
<a href="/search/stat?searchtype=author&query=Ramdas%2C+A">Aaditya Ramdas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023. Preliminary work presented at the ICML 2023 Workshop on Counterfactuals in Minds and Machines. Code available at <a href="https://github.com/yjchoe/ComparingAbstainingClassifiers">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10577" title="Abstract">arXiv:2305.10577</a> (replaced) [<a href="/pdf/2305.10577" title="Download PDF">pdf</a>, <a href="/format/2305.10577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting the Complexity of and Algorithms for the Graph Traversal Edit  Distance and Its Variants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Y">Yutong Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yihang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Kingsford%2C+C">Carl Kingsford</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Genomics (q-bio.GN)

</div>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12396" title="Abstract">arXiv:2305.12396</a> (replaced) [<a href="/pdf/2305.12396" title="Download PDF">pdf</a>, <a href="/format/2305.12396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Feature and Differentiable $ k $-NN Graph Learning using Dirichlet  Energy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+F">Feiping Nie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuelong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12894" title="Abstract">arXiv:2305.12894</a> (replaced) [<a href="/pdf/2305.12894" title="Download PDF">pdf</a>, <a href="/ps/2305.12894" title="Download PostScript">ps</a>, <a href="/format/2305.12894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Human Feedback to Scale Educational Datasets: Combining  Crowdworkers and Comparative Judgement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Henkel%2C+O">Owen Henkel</a>, 
<a href="/search/cs?searchtype=author&query=Hills%2C+L">Libby Hills</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13903" title="Abstract">arXiv:2305.13903</a> (replaced) [<a href="/pdf/2305.13903" title="Download PDF">pdf</a>, <a href="/format/2305.13903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Let&#x27;s Think Frame by Frame with VIP: A Video Infilling and Prediction  Dataset for Evaluating Video Chain-of-Thought
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Himakunthala%2C+V">Vaishnavi Himakunthala</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+A">Andy Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Rose%2C+D">Daniel Rose</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ryan He</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+A">Alex Mei</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yujie Lu</a>, 
<a href="/search/cs?searchtype=author&query=Sonar%2C+C">Chinmay Sonar</a>, 
<a href="/search/cs?searchtype=author&query=Saxon%2C+M">Michael Saxon</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W+Y">William Yang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14734" title="Abstract">arXiv:2305.14734</a> (replaced) [<a href="/pdf/2305.14734" title="Download PDF">pdf</a>, <a href="/format/2305.14734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancements in Arabic Grammatical Error Detection and Correction: An  Empirical Investigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alhafni%2C+B">Bashar Alhafni</a>, 
<a href="/search/cs?searchtype=author&query=Inoue%2C+G">Go Inoue</a>, 
<a href="/search/cs?searchtype=author&query=Khairallah%2C+C">Christian Khairallah</a>, 
<a href="/search/cs?searchtype=author&query=Habash%2C+N">Nizar Habash</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14979" title="Abstract">arXiv:2305.14979</a> (replaced) [<a href="/pdf/2305.14979" title="Download PDF">pdf</a>, <a href="/format/2305.14979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessment of the Reliablity of a Model&#x27;s Decision by Generalizing  Attribution to the Wavelet Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kasmi%2C+G">Gabriel Kasmi</a>, 
<a href="/search/cs?searchtype=author&query=Dubus%2C+L">Laurent Dubus</a>, 
<a href="/search/cs?searchtype=author&query=Drenan%2C+Y+S">Yves-Marie Saint Drenan</a>, 
<a href="/search/cs?searchtype=author&query=Blanc%2C+P">Philippe Blanc</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 10 figures, 3 tables. Camera-ready version accepted at the XAI in action workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15001" title="Abstract">arXiv:2305.15001</a> (replaced) [<a href="/pdf/2305.15001" title="Download PDF">pdf</a>, <a href="/format/2305.15001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Training of Complex-Valued Autoencoders for Object Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stani%C4%87%2C+A">Aleksandar Stani&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Gopalakrishnan%2C+A">Anand Gopalakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Irie%2C+K">Kazuki Irie</a>, 
<a href="/search/cs?searchtype=author&query=Schmidhuber%2C+J">J&#xfc;rgen Schmidhuber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16841" title="Abstract">arXiv:2305.16841</a> (replaced) [<a href="/pdf/2305.16841" title="Download PDF">pdf</a>, <a href="/format/2305.16841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable Random Partition Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sutter%2C+T+M">Thomas M. Sutter</a>, 
<a href="/search/cs?searchtype=author&query=Ryser%2C+A">Alain Ryser</a>, 
<a href="/search/cs?searchtype=author&query=Liebeskind%2C+J">Joram Liebeskind</a>, 
<a href="/search/cs?searchtype=author&query=Vogt%2C+J+E">Julia E. Vogt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Neurips 2023. Code release will follow
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01187" title="Abstract">arXiv:2306.01187</a> (replaced) [<a href="/pdf/2306.01187" title="Download PDF">pdf</a>, <a href="/format/2306.01187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training neural operators to preserve invariant measures of chaotic  attractors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+R">Ruoxi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+P+Y">Peter Y. Lu</a>, 
<a href="/search/cs?searchtype=author&query=Orlova%2C+E">Elena Orlova</a>, 
<a href="/search/cs?searchtype=author&query=Willett%2C+R">Rebecca Willett</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01194" title="Abstract">arXiv:2306.01194</a> (replaced) [<a href="/pdf/2306.01194" title="Download PDF">pdf</a>, <a href="/format/2306.01194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimating WebRTC Video QoE Metrics Without Using Application Headers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+T">Taveesh Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Mangla%2C+T">Tarun Mangla</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Arpit Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Junchen Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Feamster%2C+N">Nick Feamster</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01289" title="Abstract">arXiv:2306.01289</a> (replaced) [<a href="/pdf/2306.01289" title="Download PDF">pdf</a>, <a href="/format/2306.01289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> nnMobileNe: Rethinking CNN for Retinopathy Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhu%2C+W">Wenhui Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Qiu%2C+P">Peijie Qiu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/eess?searchtype=author&query=Lepore%2C+N">Natasha Lepore</a>, 
<a href="/search/eess?searchtype=author&query=Dumitrascu%2C+O+M">Oana M. Dumitrascu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yalin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code:<a href="https://github.com/Retinal-Research/NNMOBILE-NET">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01665" title="Abstract">arXiv:2306.01665</a> (replaced) [<a href="/pdf/2306.01665" title="Download PDF">pdf</a>, <a href="/format/2306.01665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SourceP: Detecting Ponzi Schemes on Ethereum with Source Code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+P">Pengcheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+L">Liang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+K">Keting Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02913" title="Abstract">arXiv:2306.02913</a> (replaced) [<a href="/pdf/2306.02913" title="Download PDF">pdf</a>, <a href="/format/2306.02913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralized SGD and Average-direction SAM are Asymptotically  Equivalent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+T">Tongtian Zhu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+F">Fengxiang He</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kaixuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Mingli Song</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40th International Conference on Machine Learning (ICML 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Distributed, Parallel, and Cluster Computing (cs.DC); Systems and Control (eess.SY); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04027" title="Abstract">arXiv:2306.04027</a> (replaced) [<a href="/pdf/2306.04027" title="Download PDF">pdf</a>, <a href="/format/2306.04027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intervention Generalization: A View from Factor Graph Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bravo-Hermsdorff%2C+G">Gecia Bravo-Hermsdorff</a>, 
<a href="/search/stat?searchtype=author&query=Watson%2C+D+S">David S. Watson</a>, 
<a href="/search/stat?searchtype=author&query=Yu%2C+J">Jialin Yu</a>, 
<a href="/search/stat?searchtype=author&query=Zeitler%2C+J">Jakob Zeitler</a>, 
<a href="/search/stat?searchtype=author&query=Silva%2C+R">Ricardo Silva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Camera ready version (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05527" title="Abstract">arXiv:2306.05527</a> (replaced) [<a href="/pdf/2306.05527" title="Download PDF">pdf</a>, <a href="/format/2306.05527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Teaching AI to Teach: Leveraging Limited Human Salience Data Into  Unlimited Saliency-Based Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Crum%2C+C+R">Colton R. Crum</a>, 
<a href="/search/cs?searchtype=author&query=Boyd%2C+A">Aidan Boyd</a>, 
<a href="/search/cs?searchtype=author&query=Bowyer%2C+K">Kevin Bowyer</a>, 
<a href="/search/cs?searchtype=author&query=Czajka%2C+A">Adam Czajka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05693" title="Abstract">arXiv:2306.05693</a> (replaced) [<a href="/pdf/2306.05693" title="Download PDF">pdf</a>, <a href="/ps/2306.05693" title="Download PostScript">ps</a>, <a href="/format/2306.05693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Active and Passive Beamforming for RIS-Assisted Full-Duplex  Systems under Imperfect CSI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Li-Hsiang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Ku%2C+C">Chia-Jou Ku</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+K">Kai-Ten Feng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07005" title="Abstract">arXiv:2306.07005</a> (replaced) [<a href="/pdf/2306.07005" title="Download PDF">pdf</a>, <a href="/format/2306.07005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-Generated Image Detection using a Cross-Attention Enhanced  Dual-Stream Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xi%2C+Z">Ziyi Xi</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wenmin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+K">Kangkang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+W">Weiqi Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+P">Peijia Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 41 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07915" title="Abstract">arXiv:2306.07915</a> (replaced) [<a href="/pdf/2306.07915" title="Download PDF">pdf</a>, <a href="/format/2306.07915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Captioners Are Scalable Vision Learners Too
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tschannen%2C+M">Michael Tschannen</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+M">Manoj Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Steiner%2C+A">Andreas Steiner</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xiaohua Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Houlsby%2C+N">Neil Houlsby</a>, 
<a href="/search/cs?searchtype=author&query=Beyer%2C+L">Lucas Beyer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023. v2 adds SugarCrepe results and more ablations, v3 has minor fixes
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08013" title="Abstract">arXiv:2306.08013</a> (replaced) [<a href="/pdf/2306.08013" title="Download PDF">pdf</a>, <a href="/format/2306.08013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TopP&amp;R: Robust Support Estimation Approach for Evaluating Fidelity and  Diversity in Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+P+J">Pum Jun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+Y">Yoojin Jang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jisu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+J">Jaejun Yoo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09955" title="Abstract">arXiv:2306.09955</a> (replaced) [<a href="/pdf/2306.09955" title="Download PDF">pdf</a>, <a href="/format/2306.09955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training shallow ReLU networks on noisy data using hinge loss: when do  we overfit and is it benign?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=George%2C+E">Erin George</a>, 
<a href="/search/cs?searchtype=author&query=Murray%2C+M">Michael Murray</a>, 
<a href="/search/cs?searchtype=author&query=Swartworth%2C+W">William Swartworth</a>, 
<a href="/search/cs?searchtype=author&query=Needell%2C+D">Deanna Needell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages, 2 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11167" title="Abstract">arXiv:2306.11167</a> (replaced) [<a href="/pdf/2306.11167" title="Download PDF">pdf</a>, <a href="/format/2306.11167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models are Fixated by Red Herrings: Exploring Creative  Problem Solving and Einstellung Effect using the Only Connect Wall Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naeini%2C+S">Saeid Naeini</a>, 
<a href="/search/cs?searchtype=author&query=Saqur%2C+R">Raeid Saqur</a>, 
<a href="/search/cs?searchtype=author&query=Saeidi%2C+M">Mozhgan Saeidi</a>, 
<a href="/search/cs?searchtype=author&query=Giorgi%2C+J">John Giorgi</a>, 
<a href="/search/cs?searchtype=author&query=Taati%2C+B">Babak Taati</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v4,v3: Mincor cosmetic adjustments, typo-fixes etc. from V2. Fixed Fig. 2 caption overlapping with text in S2.2. V2: with added OCW-Randomized and OCW-WordNet results in Section 4.3 (added). 22 pages with Appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12929" title="Abstract">arXiv:2306.12929</a> (replaced) [<a href="/pdf/2306.12929" title="Download PDF">pdf</a>, <a href="/format/2306.12929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantizable Transformers: Removing Outliers by Helping Attention Heads  Do Nothing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bondarenko%2C+Y">Yelysei Bondarenko</a>, 
<a href="/search/cs?searchtype=author&query=Nagel%2C+M">Markus Nagel</a>, 
<a href="/search/cs?searchtype=author&query=Blankevoort%2C+T">Tijmen Blankevoort</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15051" title="Abstract">arXiv:2306.15051</a> (replaced) [<a href="/pdf/2306.15051" title="Download PDF">pdf</a>, <a href="/format/2306.15051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sustainable RF Wireless Energy Transfer for Massive IoT: enablers and  challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rosabal%2C+O+M">Osmel Mart&#xed;nez Rosabal</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez%2C+O+L+A">Onel L. Alcaraz L&#xf3;pez</a>, 
<a href="/search/cs?searchtype=author&query=Alves%2C+H">Hirley Alves</a>, 
<a href="/search/cs?searchtype=author&query=Latva-aho%2C+M">Matti Latva-aho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 7 figures, 2 tables, submitted to IEEE Access Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16473" title="Abstract">arXiv:2306.16473</a> (replaced) [<a href="/pdf/2306.16473" title="Download PDF">pdf</a>, <a href="/ps/2306.16473" title="Download PostScript">ps</a>, <a href="/format/2306.16473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coordinating Multiple Resources to Manage Postdisaster Operation of  Interdependent Electric Power and Natural Gas Distribution Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+K">Kaigui Xie</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Hongbin Wang</a>, 
<a href="/search/eess?searchtype=author&query=Hou%2C+X">Xingzhe Hou</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+T">Tao Chen</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+H">Hongzhou Chen</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+Y">Yufei He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16900" title="Abstract">arXiv:2306.16900</a> (replaced) [<a href="/pdf/2306.16900" title="Download PDF">pdf</a>, <a href="/format/2306.16900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Surveying (Dis)Parities and Concerns of Compute Hungry NLP Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Ji-Ung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Puerto%2C+H">Haritz Puerto</a>, 
<a href="/search/cs?searchtype=author&query=van+Aken%2C+B">Betty van Aken</a>, 
<a href="/search/cs?searchtype=author&query=Arase%2C+Y">Yuki Arase</a>, 
<a href="/search/cs?searchtype=author&query=Forde%2C+J+Z">Jessica Zosa Forde</a>, 
<a href="/search/cs?searchtype=author&query=Derczynski%2C+L">Leon Derczynski</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%BCckl%C3%A9%2C+A">Andreas R&#xfc;ckl&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Gurevych%2C+I">Iryna Gurevych</a>, 
<a href="/search/cs?searchtype=author&query=Schwartz%2C+R">Roy Schwartz</a>, 
<a href="/search/cs?searchtype=author&query=Strubell%2C+E">Emma Strubell</a>, 
<a href="/search/cs?searchtype=author&query=Dodge%2C+J">Jesse Dodge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17750" title="Abstract">arXiv:2306.17750</a> (replaced) [<a href="/pdf/2306.17750" title="Download PDF">pdf</a>, <a href="/format/2306.17750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TD Convergence: An Optimization Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Asadi%2C+K">Kavosh Asadi</a>, 
<a href="/search/cs?searchtype=author&query=Sabach%2C+S">Shoham Sabach</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gottesman%2C+O">Omer Gottesman</a>, 
<a href="/search/cs?searchtype=author&query=Fakoor%2C+R">Rasool Fakoor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00562" title="Abstract">arXiv:2307.00562</a> (replaced) [<a href="/pdf/2307.00562" title="Download PDF">pdf</a>, <a href="/format/2307.00562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A MIL Approach for Anomaly Detection in Surveillance Videos from  Multiple Camera Views
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pereira%2C+S+S+L">Silas Santiago Lopes Pereira</a>, 
<a href="/search/cs?searchtype=author&query=Maia%2C+J+E+B">Jos&#xe9; Everardo Bessa Maia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 Pages, 4 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02064" title="Abstract">arXiv:2307.02064</a> (replaced) [<a href="/pdf/2307.02064" title="Download PDF">pdf</a>, <a href="/format/2307.02064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Facing Off World Model Backbones: RNNs, Transformers, and S4
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+F">Fei Deng</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Junyeong Park</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+S">Sungjin Ahn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023. Added instantiation with S5. Project page: <a href="https://fdeng18.github.io/s4wm">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02697" title="Abstract">arXiv:2307.02697</a> (replaced) [<a href="/pdf/2307.02697" title="Download PDF">pdf</a>, <a href="/format/2307.02697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strahler Number of Natural Language Sentences in Comparison with Random  Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tanaka-Ishii%2C+K">Kumiko Tanaka-Ishii</a>, 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+A">Akira Tanaka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 12 figures, 11 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Statistical Mechanics, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Data Analysis, Statistics and Probability (physics.data-an)

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03744" title="Abstract">arXiv:2307.03744</a> (replaced) [<a href="/pdf/2307.03744" title="Download PDF">pdf</a>, <a href="/format/2307.03744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing Traditional and LLM-based Search for Consumer Choice: A  Randomized Experiment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Spatharioti%2C+S+E">Sofia Eleni Spatharioti</a>, 
<a href="/search/cs?searchtype=author&query=Rothschild%2C+D+M">David M. Rothschild</a>, 
<a href="/search/cs?searchtype=author&query=Goldstein%2C+D+G">Daniel G. Goldstein</a>, 
<a href="/search/cs?searchtype=author&query=Hofman%2C+J+M">Jake M. Hofman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04052" title="Abstract">arXiv:2307.04052</a> (replaced) [<a href="/pdf/2307.04052" title="Download PDF">pdf</a>, <a href="/format/2307.04052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Group Auxiliary Datasets for Molecule
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Huang%2C+T">Tinglin Huang</a>, 
<a href="/search/q-bio?searchtype=author&query=Hu%2C+Z">Ziniu Hu</a>, 
<a href="/search/q-bio?searchtype=author&query=Ying%2C+R">Rex Ying</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023, Camera Ready Version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04461" title="Abstract">arXiv:2307.04461</a> (replaced) [<a href="/pdf/2307.04461" title="Download PDF">pdf</a>, <a href="/format/2307.04461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-modal Graph Learning over UMLS Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Burger%2C+M">Manuel Burger</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%A4tsch%2C+G">Gunnar R&#xe4;tsch</a>, 
<a href="/search/cs?searchtype=author&query=Kuznetsova%2C+R">Rita Kuznetsova</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Machine Learning for Health (ML4H) 2023 in Proceedings of Machine Learning Research 225
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05439" title="Abstract">arXiv:2307.05439</a> (replaced) [<a href="/pdf/2307.05439" title="Download PDF">pdf</a>, <a href="/format/2307.05439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Metropolis Sampling for Constrained Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fishman%2C+N">Nic Fishman</a>, 
<a href="/search/cs?searchtype=author&query=Klarner%2C+L">Leo Klarner</a>, 
<a href="/search/cs?searchtype=author&query=Mathieu%2C+E">Emile Mathieu</a>, 
<a href="/search/cs?searchtype=author&query=Hutchinson%2C+M">Michael Hutchinson</a>, 
<a href="/search/cs?searchtype=author&query=de+Bortoli%2C+V">Valentin de Bortoli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06250" title="Abstract">arXiv:2307.06250</a> (replaced) [<a href="/pdf/2307.06250" title="Download PDF">pdf</a>, <a href="/format/2307.06250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifiability Guarantees for Causal Disentanglement from Soft  Interventions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhang%2C+J">Jiaqi Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Squires%2C+C">Chandler Squires</a>, 
<a href="/search/stat?searchtype=author&query=Greenewald%2C+K">Kristjan Greenewald</a>, 
<a href="/search/stat?searchtype=author&query=Srivastava%2C+A">Akash Srivastava</a>, 
<a href="/search/stat?searchtype=author&query=Shanmugam%2C+K">Karthikeyan Shanmugam</a>, 
<a href="/search/stat?searchtype=author&query=Uhler%2C+C">Caroline Uhler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06285" title="Abstract">arXiv:2307.06285</a> (replaced) [<a href="/pdf/2307.06285" title="Download PDF">pdf</a>, <a href="/ps/2307.06285" title="Download PostScript">ps</a>, <a href="/format/2307.06285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Smoothed Analysis of the Koml&#xf3;s Conjecture: Rademacher Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Aigner-Horev%2C+E">Elad Aigner-Horev</a>, 
<a href="/search/math?searchtype=author&query=Hefetz%2C+D">Dan Hefetz</a>, 
<a href="/search/math?searchtype=author&query=Trushkin%2C+M">Michael Trushkin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> For version 3, some oversights have been corrected and more importantly the dependency between n and d has been significantly improved to reach optimum
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Information Theory (cs.IT); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06933" title="Abstract">arXiv:2307.06933</a> (replaced) [<a href="/pdf/2307.06933" title="Download PDF">pdf</a>, <a href="/format/2307.06933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FDAPT: Federated Domain-adaptive Pre-training for Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Lekang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Svoboda%2C+F">Filip Svoboda</a>, 
<a href="/search/cs?searchtype=author&query=Lane%2C+N+D">Nicholas D. Lane</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at International Workshop on Federated Learning in the Age of Foundation Models in Conjunction with NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07086" title="Abstract">arXiv:2307.07086</a> (replaced) [<a href="/pdf/2307.07086" title="Download PDF">pdf</a>, <a href="/format/2307.07086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Value-Gradient Iteration with Quadratic Approximate Value Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yang%2C+A">Alan Yang</a>, 
<a href="/search/math?searchtype=author&query=Boyd%2C+S">Stephen Boyd</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07980" title="Abstract">arXiv:2307.07980</a> (replaced) [<a href="/pdf/2307.07980" title="Download PDF">pdf</a>, <a href="/format/2307.07980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Byzantine-Robust Distributed Online Learning: Taming Adversarial  Participants in An Adversarial Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xingrong Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhaoxian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+Q">Qing Ling</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zhi Tian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12943" title="Abstract">arXiv:2307.12943</a> (replaced) [<a href="/pdf/2307.12943" title="Download PDF">pdf</a>, <a href="/format/2307.12943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian Cooling and Dikin Walks: The Interior-Point Method for  Logconcave Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kook%2C+Y">Yunbum Kook</a>, 
<a href="/search/cs?searchtype=author&query=Vempala%2C+S+S">Santosh S. Vempala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16695" title="Abstract">arXiv:2307.16695</a> (replaced) [<a href="/pdf/2307.16695" title="Download PDF">pdf</a>, <a href="/format/2307.16695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A theory of data variability in Neural Network Bayesian inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Lindner%2C+J">Javed Lindner</a>, 
<a href="/search/cond-mat?searchtype=author&query=Dahmen%2C+D">David Dahmen</a>, 
<a href="/search/cond-mat?searchtype=author&query=Kr%C3%A4mer%2C+M">Michael Kr&#xe4;mer</a>, 
<a href="/search/cond-mat?searchtype=author&query=Helias%2C+M">Moritz Helias</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 56 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Disordered Systems and Neural Networks (cond-mat.dis-nn)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03811" title="Abstract">arXiv:2308.03811</a> (replaced) [<a href="/pdf/2308.03811" title="Download PDF">pdf</a>, <a href="/format/2308.03811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Convex Bilevel Optimization with Time-Varying Objective Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lin%2C+S">Sen Lin</a>, 
<a href="/search/math?searchtype=author&query=Sow%2C+D">Daouda Sow</a>, 
<a href="/search/math?searchtype=author&query=Ji%2C+K">Kaiyi Ji</a>, 
<a href="/search/math?searchtype=author&query=Liang%2C+Y">Yingbin Liang</a>, 
<a href="/search/math?searchtype=author&query=Shroff%2C+N">Ness Shroff</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05061" title="Abstract">arXiv:2308.05061</a> (replaced) [<a href="/pdf/2308.05061" title="Download PDF">pdf</a>, <a href="/format/2308.05061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-Tune Language Models as Multi-Modal Differential Equation Solvers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Liu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Siting Liu</a>, 
<a href="/search/cs?searchtype=author&query=Osher%2C+S+J">Stanley J. Osher</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06294" title="Abstract">arXiv:2308.06294</a> (replaced) [<a href="/pdf/2308.06294" title="Download PDF">pdf</a>, <a href="/ps/2308.06294" title="Download PostScript">ps</a>, <a href="/format/2308.06294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Phenotype Recognition in Clinical Notes Using Large Language  Models: PhenoBCBERT and PhenoGPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Yang%2C+J">Jingye Yang</a>, 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+C">Cong Liu</a>, 
<a href="/search/q-bio?searchtype=author&query=Deng%2C+W">Wendy Deng</a>, 
<a href="/search/q-bio?searchtype=author&query=Wu%2C+D">Da Wu</a>, 
<a href="/search/q-bio?searchtype=author&query=Weng%2C+C">Chunhua Weng</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhou%2C+Y">Yunyun Zhou</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+K">Kai Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07663" title="Abstract">arXiv:2308.07663</a> (replaced) [<a href="/pdf/2308.07663" title="Download PDF">pdf</a>, <a href="/ps/2308.07663" title="Download PostScript">ps</a>, <a href="/format/2308.07663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coherent set identification via direct low rank maximum likelihood  estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Polzin%2C+R">Robert Polzin</a>, 
<a href="/search/cs?searchtype=author&query=Klebanov%2C+I">Ilja Klebanov</a>, 
<a href="/search/cs?searchtype=author&query=N%C3%BCsken%2C+N">Nikolas N&#xfc;sken</a>, 
<a href="/search/cs?searchtype=author&query=Koltai%2C+P">P&#xe9;ter Koltai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10130" title="Abstract">arXiv:2308.10130</a> (replaced) [<a href="/pdf/2308.10130" title="Download PDF">pdf</a>, <a href="/format/2308.10130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Approximation of Operator-Valued Riccati Equations in Hilbert  Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cheung%2C+J">James Cheung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Revision 2
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11100" title="Abstract">arXiv:2308.11100</a> (replaced) [<a href="/pdf/2308.11100" title="Download PDF">pdf</a>, <a href="/format/2308.11100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Early Exits for Fast Inference in Automatic Modulation  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohammed%2C+E">Elsayed Mohammed</a>, 
<a href="/search/cs?searchtype=author&query=Mashaal%2C+O">Omar Mashaal</a>, 
<a href="/search/cs?searchtype=author&query=Abou-Zeid%2C+H">Hatem Abou-Zeid</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in GLOBECOM2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11123" title="Abstract">arXiv:2308.11123</a> (replaced) [<a href="/pdf/2308.11123" title="Download PDF">pdf</a>, <a href="/format/2308.11123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hey That&#x27;s Mine Imperceptible Watermarks are Preserved in Diffusion  Generated Outputs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ditria%2C+L">Luke Ditria</a>, 
<a href="/search/cs?searchtype=author&query=Drummond%2C+T">Tom Drummond</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14991" title="Abstract">arXiv:2308.14991</a> (replaced) [<a href="/pdf/2308.14991" title="Download PDF">pdf</a>, <a href="/format/2308.14991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incorporating Neuro-Inspired Adaptability for Continual Learning in  Artificial Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingxing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qian Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingtian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hang Su</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yi Zhong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00608" title="Abstract">arXiv:2309.00608</a> (replaced) [<a href="/pdf/2309.00608" title="Download PDF">pdf</a>, <a href="/format/2309.00608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Copiloting the Copilots: Fusing Large Language Models with Completion  Engines for Automated Program Repair
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yuxiang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+C+S">Chunqiu Steven Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lingming Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted at ESEC/FSE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG); Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01784" title="Abstract">arXiv:2309.01784</a> (replaced) [<a href="/pdf/2309.01784" title="Download PDF">pdf</a>, <a href="/format/2309.01784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ATMS: Algorithmic Trading-Guided Market Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+S">Song Wei</a>, 
<a href="/search/cs?searchtype=author&query=Coletta%2C+A">Andrea Coletta</a>, 
<a href="/search/cs?searchtype=author&query=Vyetrenko%2C+S">Svitlana Vyetrenko</a>, 
<a href="/search/cs?searchtype=author&query=Balch%2C+T">Tucker Balch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Trading and Market Microstructure (q-fin.TR); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04069" title="Abstract">arXiv:2309.04069</a> (replaced) [<a href="/pdf/2309.04069" title="Download PDF">pdf</a>, <a href="/format/2309.04069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inferring physical laws by artificial intelligence based causal models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+J">Jorawar Singh</a>, 
<a href="/search/cs?searchtype=author&query=Bharti%2C+K">Kishor Bharti</a>, 
<a href="/search/cs?searchtype=author&query=Arvind">Arvind</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Latex 12 pages, 16 figures (Minor changes, references added)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Data Analysis, Statistics and Probability (physics.data-an); Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05528" title="Abstract">arXiv:2309.05528</a> (replaced) [<a href="/pdf/2309.05528" title="Download PDF">pdf</a>, <a href="/format/2309.05528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the detection of Out-Of-Distribution samples in Multiple Instance  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bescond%2C+L+L">Lo&#xef;c Le Bescond</a>, 
<a href="/search/cs?searchtype=author&query=Vakalopoulou%2C+M">Maria Vakalopoulou</a>, 
<a href="/search/cs?searchtype=author&query=Christodoulidis%2C+S">Stergios Christodoulidis</a>, 
<a href="/search/cs?searchtype=author&query=Andr%C3%A9%2C+F">Fabrice Andr&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Talbot%2C+H">Hugues Talbot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07096" title="Abstract">arXiv:2309.07096</a> (replaced) [<a href="/pdf/2309.07096" title="Download PDF">pdf</a>, <a href="/ps/2309.07096" title="Download PostScript">ps</a>, <a href="/format/2309.07096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The legibility of the imaged human brain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Ruffle%2C+J+K">James K Ruffle</a>, 
<a href="/search/q-bio?searchtype=author&query=Gray%2C+R+J">Robert J Gray</a>, 
<a href="/search/q-bio?searchtype=author&query=Mohinta%2C+S">Samia Mohinta</a>, 
<a href="/search/q-bio?searchtype=author&query=Pombo%2C+G">Guilherme Pombo</a>, 
<a href="/search/q-bio?searchtype=author&query=Kaul%2C+C">Chaitanya Kaul</a>, 
<a href="/search/q-bio?searchtype=author&query=Hyare%2C+H">Harpreet Hyare</a>, 
<a href="/search/q-bio?searchtype=author&query=Rees%2C+G">Geraint Rees</a>, 
<a href="/search/q-bio?searchtype=author&query=Nachev%2C+P">Parashkev Nachev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 6 figures, 1 table, 2 supplementary figures, 1 supplementary table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12214" title="Abstract">arXiv:2309.12214</a> (replaced) [<a href="/pdf/2309.12214" title="Download PDF">pdf</a>, <a href="/format/2309.12214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can We Reliably Improve the Robustness to Image Acquisition of Remote  Sensing of PV Systems?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kasmi%2C+G">Gabriel Kasmi</a>, 
<a href="/search/cs?searchtype=author&query=Dubus%2C+L">Laurent Dubus</a>, 
<a href="/search/cs?searchtype=author&query=Saint-Drenan%2C+Y">Yves-Marie Saint-Drenan</a>, 
<a href="/search/cs?searchtype=author&query=Blanc%2C+P">Philippe Blanc</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 11 figures, 4 tables. Camera ready version accepted for the Tackling Climate Change with Machine Learning workshop at NeurIPS 2023. Note: Appendix B.1. overlaps with <a href="/abs/2305.14979">arXiv:2305.14979</a> (Assessment of the Reliablity of a Model's Decision by Generalizing Attribution to the Wavelet Domain)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13016" title="Abstract">arXiv:2309.13016</a> (replaced) [<a href="/pdf/2309.13016" title="Download PDF">pdf</a>, <a href="/format/2309.13016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Deep Gradient Leakage via Inversion Influence Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haobo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+J">Junyuan Hong</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yuyang Deng</a>, 
<a href="/search/cs?searchtype=author&query=Mahdavi%2C+M">Mehrdad Mahdavi</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiayu Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 18 figures, accepted to NeurIPS2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13271" title="Abstract">arXiv:2309.13271</a> (replaced) [<a href="/pdf/2309.13271" title="Download PDF">pdf</a>, <a href="/format/2309.13271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure Inter-domain Routing and Forwarding via Verifiable Forwarding  Commitments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoliang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhuotao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qi Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yangfei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+S">Sitong Ling</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+J">Jiangou Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Ke Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jianping Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13335" title="Abstract">arXiv:2309.13335</a> (replaced) [<a href="/pdf/2309.13335" title="Download PDF">pdf</a>, <a href="/format/2309.13335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-enhanced Vector Index
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hailin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yujing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+R">Ruiheng Chang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Ting Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+Z">Ziming Miao</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yingyan Hou</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+X">Xupeng Miao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haonan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+B">Bochen Pang</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Y">Yuefeng Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+W">Weiwei Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Mao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+B">Bin Cui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16393" title="Abstract">arXiv:2309.16393</a> (replaced) [<a href="/pdf/2309.16393" title="Download PDF">pdf</a>, <a href="/format/2309.16393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HIC-YOLOv5: Improved YOLOv5 For Small Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Shiyi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yini Fang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages,10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01905" title="Abstract">arXiv:2310.01905</a> (replaced) [<a href="/pdf/2310.01905" title="Download PDF">pdf</a>, <a href="/ps/2310.01905" title="Download PostScript">ps</a>, <a href="/format/2310.01905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain-Driven Design in Software Development: A Systematic Literature  Review on Implementation, Challenges, and Effectiveness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C3%96zkan%2C+O">Ozan &#xd6;zkan</a>, 
<a href="/search/cs?searchtype=author&query=Babur%2C+%C3%96">&#xd6;nder Babur</a>, 
<a href="/search/cs?searchtype=author&query=van+den+Brand%2C+M">Mark van den Brand</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review: Submitted to ACM Computing Surveys on 14 August 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04118" title="Abstract">arXiv:2310.04118</a> (replaced) [<a href="/pdf/2310.04118" title="Download PDF">pdf</a>, <a href="/format/2310.04118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enumeration and updates for conjunctive linear algebra queries through  expressibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mu%C3%B1oz%2C+T">Thomas Mu&#xf1;oz</a>, 
<a href="/search/cs?searchtype=author&query=Riveros%2C+C">Cristian Riveros</a>, 
<a href="/search/cs?searchtype=author&query=Vansummeren%2C+S">Stijn Vansummeren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 80 pages total: 16 main body, 3 of references and 61 of appendix which contains detailed proofs
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Databases (cs.DB); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06328" title="Abstract">arXiv:2310.06328</a> (replaced) [<a href="/pdf/2310.06328" title="Download PDF">pdf</a>, <a href="/format/2310.06328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Antenna Response Consistency Driven Self-supervised Learning for  WIFI-based Human Activity Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Ke Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiangtao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hongyuan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+D">Dingchang Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06643" title="Abstract">arXiv:2310.06643</a> (replaced) [<a href="/pdf/2310.06643" title="Download PDF">pdf</a>, <a href="/format/2310.06643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit Variational Inference for High-Dimensional Posteriors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Uppal%2C+A">Anshuk Uppal</a>, 
<a href="/search/cs?searchtype=author&query=Stensbo-Smidt%2C+K">Kristoffer Stensbo-Smidt</a>, 
<a href="/search/cs?searchtype=author&query=Boomsma%2C+W">Wouter Boomsma</a>, 
<a href="/search/cs?searchtype=author&query=Frellsen%2C+J">Jes Frellsen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages and appendix, 9 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07602" title="Abstract">arXiv:2310.07602</a> (replaced) [<a href="/pdf/2310.07602" title="Download PDF">pdf</a>, <a href="/format/2310.07602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual Radar: A Multi-modal Dataset with Dual 4D Radar for Autonomous  Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Li Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Cheng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Ziying Song</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guangqi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yichen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaofei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jun Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qingshan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenlin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+S+S">Shuzhi Sam Ge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07867" title="Abstract">arXiv:2310.07867</a> (replaced) [<a href="/pdf/2310.07867" title="Download PDF">pdf</a>, <a href="/format/2310.07867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cheap Talking Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Condorelli%2C+D">Daniele Condorelli</a>, 
<a href="/search/econ?searchtype=author&query=Furlan%2C+M">Massimiliano Furlan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09949" title="Abstract">arXiv:2310.09949</a> (replaced) [<a href="/pdf/2310.09949" title="Download PDF">pdf</a>, <a href="/format/2310.09949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chameleon: a heterogeneous and disaggregated accelerator system for  retrieval-augmented language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wenqi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zeller%2C+M">Marco Zeller</a>, 
<a href="/search/cs?searchtype=author&query=Waleffe%2C+R">Roger Waleffe</a>, 
<a href="/search/cs?searchtype=author&query=Hoefler%2C+T">Torsten Hoefler</a>, 
<a href="/search/cs?searchtype=author&query=Alonso%2C+G">Gustavo Alonso</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09982" title="Abstract">arXiv:2310.09982</a> (replaced) [<a href="/pdf/2310.09982" title="Download PDF">pdf</a>, <a href="/format/2310.09982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AP$n$P: A Less-constrained P$n$P Solver for Pose Estimation with Unknown  Anisotropic Scaling or Focal Lengths
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jiaxin Wei</a>, 
<a href="/search/cs?searchtype=author&query=Leutenegger%2C+S">Stefan Leutenegger</a>, 
<a href="/search/cs?searchtype=author&query=Kneip%2C+L">Laurent Kneip</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10378" title="Abstract">arXiv:2310.10378</a> (replaced) [<a href="/pdf/2310.10378" title="Download PDF">pdf</a>, <a href="/format/2310.10378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Lingual Consistency of Factual Knowledge in Multilingual Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+J">Jirui Qi</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez%2C+R">Raquel Fern&#xe1;ndez</a>, 
<a href="/search/cs?searchtype=author&query=Bisazza%2C+A">Arianna Bisazza</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP2023 main conference. All code and data are released at <a href="https://github.com/Betswish/Cross-Lingual-Consistency">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12421" title="Abstract">arXiv:2310.12421</a> (replaced) [<a href="/pdf/2310.12421" title="Download PDF">pdf</a>, <a href="/ps/2310.12421" title="Download PostScript">ps</a>, <a href="/format/2310.12421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting and Mitigating Algorithmic Bias in Binary Classification using  Causal Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hui%2C+W">Wendy Hui</a>, 
<a href="/search/cs?searchtype=author&query=Lau%2C+W+K">Wai Kwong Lau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 2 figures, 6 tables, R-script in appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12802" title="Abstract">arXiv:2310.12802</a> (replaced) [<a href="/pdf/2310.12802" title="Download PDF">pdf</a>, <a href="/format/2310.12802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An effective theory of collective deep learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Arola-Fern%C3%A1ndez%2C+L">Llu&#xed;s Arola-Fern&#xe1;ndez</a>, 
<a href="/search/physics?searchtype=author&query=Lacasa%2C+L">Lucas Lacasa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Adaptation and Self-Organizing Systems (nlin.AO)

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13121" title="Abstract">arXiv:2310.13121</a> (replaced) [<a href="/pdf/2310.13121" title="Download PDF">pdf</a>, <a href="/format/2310.13121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Addition in Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Quirke%2C+P">Philip Quirke</a>, 
<a href="/search/cs?searchtype=author&query=Barez%2C+F">Fazl Barez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 8 figures, submitted to ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13236" title="Abstract">arXiv:2310.13236</a> (replaced) [<a href="/pdf/2310.13236" title="Download PDF">pdf</a>, <a href="/format/2310.13236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Efficient Federated Learning Framework for Training Semantic  Communication System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+L+X">Loc X. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+H+Q">Huy Q. Le</a>, 
<a href="/search/cs?searchtype=author&query=Tun%2C+Y+L">Ye Lin Tun</a>, 
<a href="/search/cs?searchtype=author&query=Aung%2C+P+S">Pyae Sone Aung</a>, 
<a href="/search/cs?searchtype=author&query=Tun%2C+Y+K">Yan Kyaw Tun</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhu Han</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+C+S">Choong Seon Hong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13620" title="Abstract">arXiv:2310.13620</a> (replaced) [<a href="/pdf/2310.13620" title="Download PDF">pdf</a>, <a href="/format/2310.13620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging Information-Theoretic and Geometric Compression in Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+E">Emily Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Kervadec%2C+C">Corentin Kervadec</a>, 
<a href="/search/cs?searchtype=author&query=Baroni%2C+M">Marco Baroni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 Camera-Ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14360" title="Abstract">arXiv:2310.14360</a> (replaced) [<a href="/pdf/2310.14360" title="Download PDF">pdf</a>, <a href="/ps/2310.14360" title="Download PostScript">ps</a>, <a href="/format/2310.14360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is ChatGPT a game changer for geocoding -- a benchmark for geocoding  address parsing techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhengcong Yin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Diya Li</a>, 
<a href="/search/cs?searchtype=author&query=Goldberg%2C+D+W">Daniel W. Goldberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15008" title="Abstract">arXiv:2310.15008</a> (replaced) [<a href="/pdf/2310.15008" title="Download PDF">pdf</a>, <a href="/format/2310.15008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wonder3D: Single Image to 3D using Cross-Domain Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Long%2C+X">Xiaoxiao Long</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuan-Chen Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Cheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Z">Zhiyang Dou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingjie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yuexin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Song-Hai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Habermann%2C+M">Marc Habermann</a>, 
<a href="/search/cs?searchtype=author&query=Theobalt%2C+C">Christian Theobalt</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenping Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://www.xxlong.site/Wonder3D/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15588" title="Abstract">arXiv:2310.15588</a> (replaced) [<a href="/pdf/2310.15588" title="Download PDF">pdf</a>, <a href="/format/2310.15588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Closed Loop Molecular Communication Testbed: Setup, Interference  Analysis, and Experimental Results
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brand%2C+L">Lukas Brand</a>, 
<a href="/search/cs?searchtype=author&query=Scherer%2C+M">Maike Scherer</a>, 
<a href="/search/cs?searchtype=author&query=Dieck%2C+T+t">Teena tom Dieck</a>, 
<a href="/search/cs?searchtype=author&query=Lotter%2C+S">Sebastian Lotter</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%A4fer%2C+M">Maximilian Sch&#xe4;fer</a>, 
<a href="/search/cs?searchtype=author&query=Burkovski%2C+A">Andreas Burkovski</a>, 
<a href="/search/cs?searchtype=author&query=Sticht%2C+H">Heinrich Sticht</a>, 
<a href="/search/cs?searchtype=author&query=Castiglione%2C+K">Kathrin Castiglione</a>, 
<a href="/search/cs?searchtype=author&query=Schober%2C+R">Robert Schober</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures, 1 table. This work has been submitted for possible publication to the IEEE International Conference on Communications (ICC) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15720" title="Abstract">arXiv:2310.15720</a> (replaced) [<a href="/pdf/2310.15720" title="Download PDF">pdf</a>, <a href="/format/2310.15720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ensemble of Task-Specific Language Models for Brain Encoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arun%2C+A">Arvindh Arun</a>, 
<a href="/search/cs?searchtype=author&query=John%2C+J">Jerrin John</a>, 
<a href="/search/cs?searchtype=author&query=Kumaran%2C+S">Sanjai Kumaran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15767" title="Abstract">arXiv:2310.15767</a> (replaced) [<a href="/pdf/2310.15767" title="Download PDF">pdf</a>, <a href="/ps/2310.15767" title="Download PostScript">ps</a>, <a href="/format/2310.15767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unpaired MRI Super Resolution with Self-Supervised Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Q">Quanwei Liu</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+J">Jianan Liu</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+X">Xiling Liu</a>, 
<a href="/search/eess?searchtype=author&query=Dong%2C+Y">Yanni Dong</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+T">Tao Huang</a>, 
<a href="/search/eess?searchtype=author&query=Lv%2C+Z">Zhihan Lv</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16772" title="Abstract">arXiv:2310.16772</a> (replaced) [<a href="/pdf/2310.16772" title="Download PDF">pdf</a>, <a href="/format/2310.16772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI Agent as Urban Planner: Steering Stakeholder Dynamics in Urban  Planning via Consensus-based Multi-Agent Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+K">Kejiang Qian</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+L">Lingjun Mao</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xin Liang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yimin Ding</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xinran Wei</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Ziyi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiajie Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17220" title="Abstract">arXiv:2310.17220</a> (replaced) [<a href="/pdf/2310.17220" title="Download PDF">pdf</a>, <a href="/ps/2310.17220" title="Download PostScript">ps</a>, <a href="/format/2310.17220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Validating Digital Traces with Survey Data: The Use Case of Religiosity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=K%C4%B1na%2C+M+F">M.Fuat K&#x131;na</a>, 
<a href="/search/cs?searchtype=author&query=Y%C3%B6r%C3%BCk%2C+E">Erdem Y&#xf6;r&#xfc;k</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%BCrriyeto%C4%9Flu%2C+A">Ali H&#xfc;rriyeto&#x11f;lu</a>, 
<a href="/search/cs?searchtype=author&query=Yard%C4%B1%2C+M+C">Melih Can Yard&#x131;</a>, 
<a href="/search/cs?searchtype=author&query=Ats%C4%B1zelti%2C+%C5%9E">&#x15e;&#xfc;kr&#xfc; Ats&#x131;zelti</a>, 
<a href="/search/cs?searchtype=author&query=Duru%C5%9Fan%2C+F">F&#x131;rat Duru&#x15f;an</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCrerk%2C+O">O&#x11f;uz G&#xfc;rerk</a>, 
<a href="/search/cs?searchtype=author&query=Etg%C3%BC%2C+T">Tolga Etg&#xfc;</a>, 
<a href="/search/cs?searchtype=author&query=Ni%C5%9Fanc%C4%B1%2C+Z">Z&#xfc;beyir Ni&#x15f;anc&#x131;</a>, 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+O">Osman Mutlu</a>, 
<a href="/search/cs?searchtype=author&query=Turbic%2C+G+B">Gizem Bacaks&#x131;zlar Turbic</a>, 
<a href="/search/cs?searchtype=author&query=Akbulut%2C+Y">Yusuf Akbulut</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17980" title="Abstract">arXiv:2310.17980</a> (replaced) [<a href="/pdf/2310.17980" title="Download PDF">pdf</a>, <a href="/format/2310.17980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sketching and Streaming for Dictionary Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Becker%2C+R">Ruben Becker</a>, 
<a href="/search/cs?searchtype=author&query=Canton%2C+M">Matteo Canton</a>, 
<a href="/search/cs?searchtype=author&query=Cenzato%2C+D">Davide Cenzato</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sung-Hwan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kodric%2C+B">Bojana Kodric</a>, 
<a href="/search/cs?searchtype=author&query=Prezza%2C+N">Nicola Prezza</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18590" title="Abstract">arXiv:2310.18590</a> (replaced) [<a href="/pdf/2310.18590" title="Download PDF">pdf</a>, <a href="/format/2310.18590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Early Readouts to Mediate Featural Bias in Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tiwari%2C+R">Rishabh Tiwari</a>, 
<a href="/search/cs?searchtype=author&query=Sivasubramanian%2C+D">Durga Sivasubramanian</a>, 
<a href="/search/cs?searchtype=author&query=Mekala%2C+A">Anmol Mekala</a>, 
<a href="/search/cs?searchtype=author&query=Ramakrishnan%2C+G">Ganesh Ramakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Shenoy%2C+P">Pradeep Shenoy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19218" title="Abstract">arXiv:2310.19218</a> (replaced) [<a href="/pdf/2310.19218" title="Download PDF">pdf</a>, <a href="/format/2310.19218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Federated Unlearning: A Taxonomy, Challenges and Future  Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiaxi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yang Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19630" title="Abstract">arXiv:2310.19630</a> (replaced) [<a href="/pdf/2310.19630" title="Download PDF">pdf</a>, <a href="/ps/2310.19630" title="Download PostScript">ps</a>, <a href="/format/2310.19630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convolutional Neural Networks for Automatic Detection of Intact  Adenovirus from TEM Imaging with Debris, Broken and Artefacts Particles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rukundo%2C+O">Olivier Rukundo</a>, 
<a href="/search/cs?searchtype=author&query=Behanova%2C+A">Andrea Behanova</a>, 
<a href="/search/cs?searchtype=author&query=De+Feo%2C+R">Riccardo De Feo</a>, 
<a href="/search/cs?searchtype=author&query=Ronkko%2C+S">Seppo Ronkko</a>, 
<a href="/search/cs?searchtype=author&query=Oja%2C+J">Joni Oja</a>, 
<a href="/search/cs?searchtype=author&query=Tohka%2C+J">Jussi Tohka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20190" title="Abstract">arXiv:2310.20190</a> (replaced) [<a href="/pdf/2310.20190" title="Download PDF">pdf</a>, <a href="/format/2310.20190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visible to Thermal image Translation for improving visual task in low  light conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+M+A">Md Azim Khan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00136" title="Abstract">arXiv:2311.00136</a> (replaced) [<a href="/pdf/2311.00136" title="Download PDF">pdf</a>, <a href="/format/2311.00136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neuroformer: Multimodal and Multitask Generative Pretraining for Brain  Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Antoniades%2C+A">Antonis Antoniades</a>, 
<a href="/search/q-bio?searchtype=author&query=Yu%2C+Y">Yiyi Yu</a>, 
<a href="/search/q-bio?searchtype=author&query=Canzano%2C+J">Joseph Canzano</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+W">William Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Smith%2C+S+L">Spencer LaVere Smith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages for main paper. 22 pages in total. 13 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00153" title="Abstract">arXiv:2311.00153</a> (replaced) [<a href="/pdf/2311.00153" title="Download PDF">pdf</a>, <a href="/format/2311.00153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards A Natural Language Interface for Flexible Multi-Agent Task  Assignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brawer%2C+J">Jake Brawer</a>, 
<a href="/search/cs?searchtype=author&query=Bishop%2C+K">Kayleigh Bishop</a>, 
<a href="/search/cs?searchtype=author&query=Hayes%2C+B">Bradley Hayes</a>, 
<a href="/search/cs?searchtype=author&query=Roncone%2C+A">Alessandro Roncone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00447" title="Abstract">arXiv:2311.00447</a> (replaced) [<a href="/pdf/2311.00447" title="Download PDF">pdf</a>, <a href="/format/2311.00447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Opportunities of Green Computing: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">You Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xiujing Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Maolin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+G">Gangwei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Huakang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yupeng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhe Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kehang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sui%2C+Y">Yongduo Sui</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+F">Fengwei Jia</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zuoli Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tiannuo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weibo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yunong Mao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yi Li</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+D">De Bao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yu Li</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+H">Hongrui Liao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Ting Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingwen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jinchi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiangyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=WEI%2C+Y">Ying WEI</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+H">Hong Qian</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kin%2C+W">Wai Kin</a> (Victor)
<a href="/search/cs?searchtype=author&query=Chan">Chan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yusen Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shiyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Jining Yan</a>, 
<a href="/search/cs?searchtype=author&query=Mou%2C+C">Chao Mou</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Shuai Han</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+W">Wuxia Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guannan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xiaodong Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 113 pages, 18 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00887" title="Abstract">arXiv:2311.00887</a> (replaced) [<a href="/pdf/2311.00887" title="Download PDF">pdf</a>, <a href="/format/2311.00887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Centralized Management of a Wifi Mesh for Autonomous Farms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tahir%2C+A">Ammar Tahir</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yueshen Li</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+J">Jianli Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Changxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+D">Daniel Moon</a>, 
<a href="/search/cs?searchtype=author&query=Mihigo%2C+A">Aganze Mihigo</a>, 
<a href="/search/cs?searchtype=author&query=Tariq%2C+M+T">Muhammad Taimoor Tariq</a>, 
<a href="/search/cs?searchtype=author&query=Vasisht%2C+D">Deepak Vasisht</a>, 
<a href="/search/cs?searchtype=author&query=Mittal%2C+R">Radhika Mittal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01771" title="Abstract">arXiv:2311.01771</a> (replaced) [<a href="/pdf/2311.01771" title="Download PDF">pdf</a>, <a href="/format/2311.01771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Generalized Low-Rank Tensor Contextual Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+Q">Qianxin Yi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yiyang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Shaojie Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01800" title="Abstract">arXiv:2311.01800</a> (replaced) [<a href="/pdf/2311.01800" title="Download PDF">pdf</a>, <a href="/format/2311.01800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Method development for lowering supply temperatures in existing  buildings using minimal building information and demand measurement data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Stock%2C+J">Jan Stock</a>, 
<a href="/search/eess?searchtype=author&query=Althaus%2C+P">Philipp Althaus</a>, 
<a href="/search/eess?searchtype=author&query=Johnen%2C+S">Sascha Johnen</a>, 
<a href="/search/eess?searchtype=author&query=Xhonneux%2C+A">Andr&#xe9; Xhonneux</a>, 
<a href="/search/eess?searchtype=author&query=M%C3%BCller%2C+D">Dirk M&#xfc;ller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 1 table, 10 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 18th International IBPSA Conference and
  Exhibition Building Simulation 2023 (BuildingSimulation 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02096" title="Abstract">arXiv:2311.02096</a> (replaced) [<a href="/pdf/2311.02096" title="Download PDF">pdf</a>, <a href="/format/2311.02096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variational Autoencoders for Noise Reduction in Industrial LLRF Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Edelen%2C+J+P">J. P. Edelen</a>, 
<a href="/search/physics?searchtype=author&query=Henderson%2C+M+J">M. J. Henderson</a>, 
<a href="/search/physics?searchtype=author&query=Einstein-Curtis%2C+J">J. Einstein-Curtis</a>, 
<a href="/search/physics?searchtype=author&query=Hall%2C+C+C">C. C. Hall</a>, 
<a href="/search/physics?searchtype=author&query=Cruz%2C+J+A+D">J. A. Diaz Cruz</a>, 
<a href="/search/physics?searchtype=author&query=Edelen%2C+A+L">A. L. Edelen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Talk presented at LLRF Workshop 2023 (LLRF2023, arXiv: <a href="/abs/2310.03199">2310.03199</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Accelerator Physics (physics.acc-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02271" title="Abstract">arXiv:2311.02271</a> (replaced) [<a href="/pdf/2311.02271" title="Download PDF">pdf</a>, <a href="/format/2311.02271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FaMeSumm: Investigating and Improving Faithfulness of Medical  Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Nan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yusen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Wu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+P">Prasenjit Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Main Conference of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02408" title="Abstract">arXiv:2311.02408</a> (replaced) [<a href="/pdf/2311.02408" title="Download PDF">pdf</a>, <a href="/format/2311.02408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Citance-Contextualized Summarization of Scientific Papers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Syed%2C+S">Shahbaz Syed</a>, 
<a href="/search/cs?searchtype=author&query=Hakimi%2C+A+D">Ahmad Dawar Hakimi</a>, 
<a href="/search/cs?searchtype=author&query=Al-Khatib%2C+K">Khalid Al-Khatib</a>, 
<a href="/search/cs?searchtype=author&query=Potthast%2C+M">Martin Potthast</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP 2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02510" title="Abstract">arXiv:2311.02510</a> (replaced) [<a href="/pdf/2311.02510" title="Download PDF">pdf</a>, <a href="/format/2311.02510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anthropomorphic Grasping with Neural Object Shape Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hidalgo-Carvajal%2C+D">Diego Hidalgo-Carvajal</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hanzhi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Bettelani%2C+G+C">Gemma C. Bettelani</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+J">Jaesug Jung</a>, 
<a href="/search/cs?searchtype=author&query=Zavaglia%2C+M">Melissa Zavaglia</a>, 
<a href="/search/cs?searchtype=author&query=Busse%2C+L">Laura Busse</a>, 
<a href="/search/cs?searchtype=author&query=Naceri%2C+A">Abdeldjallil Naceri</a>, 
<a href="/search/cs?searchtype=author&query=Leutenegger%2C+S">Stefan Leutenegger</a>, 
<a href="/search/cs?searchtype=author&query=Haddadin%2C+S">Sami Haddadin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to RA-L 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02576" title="Abstract">arXiv:2311.02576</a> (replaced) [<a href="/pdf/2311.02576" title="Download PDF">pdf</a>, <a href="/format/2311.02576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Feasible Dynamic Grasping: Leveraging Gaussian Process Distance  Field, SE(3) Equivariance and Riemannian Mixture Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+H+J">Ho Jin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Figueroa%2C+N">Nadia Figueroa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02831" title="Abstract">arXiv:2311.02831</a> (replaced) [<a href="/pdf/2311.02831" title="Download PDF">pdf</a>, <a href="/format/2311.02831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SemanticTopoLoop: Semantic Loop Closure With 3D Topological Graph Based  on Quadric-Level Object Map
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhenzhong Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03312" title="Abstract">arXiv:2311.03312</a> (replaced) [<a href="/pdf/2311.03312" title="Download PDF">pdf</a>, <a href="/format/2311.03312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Single 2D Pose with Context is Worth Hundreds for 3D Human Pose  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qitao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Ce Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mengyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03346" title="Abstract">arXiv:2311.03346</a> (replaced) [<a href="/pdf/2311.03346" title="Download PDF">pdf</a>, <a href="/ps/2311.03346" title="Download PostScript">ps</a>, <a href="/format/2311.03346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decomposing Probability Marginals Beyond Affine Requirements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Matuschke%2C+J">Jannik Matuschke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03405" title="Abstract">arXiv:2311.03405</a> (replaced) [<a href="/pdf/2311.03405" title="Download PDF">pdf</a>, <a href="/format/2311.03405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication Efficient and Privacy-Preserving Federated Learning Based  on Evolution Strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lan%2C+G">Guangchen Lan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Course Project of CS59200: Distributed Optimization for Machine Learning. Lecturer: Prof. B. Bullins
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03421" title="Abstract">arXiv:2311.03421</a> (replaced) [<a href="/e-print/2311.03421" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hopfield-Enhanced Deep Neural Networks for Artifact-Resilient Brain  State Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Marin-Llobet%2C+A">Arnau Marin-Llobet</a>, 
<a href="/search/q-bio?searchtype=author&query=Manasanch%2C+A">Arnau Manasanch</a>, 
<a href="/search/q-bio?searchtype=author&query=Sanchez-Vives%2C+M+V">Maria V. Sanchez-Vives</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The resolution is low in one of the figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03663" title="Abstract">arXiv:2311.03663</a> (replaced) [<a href="/pdf/2311.03663" title="Download PDF">pdf</a>, <a href="/format/2311.03663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Principles from Clinical Research for NLP Model Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elangovan%2C+A">Aparna Elangovan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiayuan He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Verspoor%2C+K">Karin Verspoor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03755" title="Abstract">arXiv:2311.03755</a> (replaced) [<a href="/pdf/2311.03755" title="Download PDF">pdf</a>, <a href="/format/2311.03755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multilingual Mathematical Autoformalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+A+Q">Albert Q. Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenda Li</a>, 
<a href="/search/cs?searchtype=author&query=Jamnik%2C+M">Mateja Jamnik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03764" title="Abstract">arXiv:2311.03764</a> (replaced) [<a href="/pdf/2311.03764" title="Download PDF">pdf</a>, <a href="/format/2311.03764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neuro-GPT: Developing A Foundation Model for EEG
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+W">Wenhui Cui</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+W">Woojae Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Th%C3%B6lke%2C+P">Philipp Th&#xf6;lke</a>, 
<a href="/search/cs?searchtype=author&query=Medani%2C+T">Takfarinas Medani</a>, 
<a href="/search/cs?searchtype=author&query=Jerbi%2C+K">Karim Jerbi</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+A+A">Anand A. Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Leahy%2C+R+M">Richard M. Leahy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03828" title="Abstract">arXiv:2311.03828</a> (replaced) [<a href="/pdf/2311.03828" title="Download PDF">pdf</a>, <a href="/format/2311.03828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-view Information Integration and Propagation for Occluded Person  Re-identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+N">Neng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Shuanglin Yan</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jinhui Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liyan Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03839" title="Abstract">arXiv:2311.03839</a> (replaced) [<a href="/pdf/2311.03839" title="Download PDF">pdf</a>, <a href="/format/2311.03839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aspects of human memory and Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Janik%2C+R+A">Romuald A. Janik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13+3 pages; v2: abstract expanded and future research directions added
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04252" title="Abstract">arXiv:2311.04252</a> (replaced) [<a href="/pdf/2311.04252" title="Download PDF">pdf</a>, <a href="/ps/2311.04252" title="Download PostScript">ps</a>, <a href="/format/2311.04252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CNN-Based Structural Damage Detection using Time-Series Sensor Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pathak%2C+I">Ishan Pathak</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+I">Ishan Jha</a>, 
<a href="/search/cs?searchtype=author&query=Sadana%2C+A">Aditya Sadana</a>, 
<a href="/search/cs?searchtype=author&query=Bhowmik%2C+B">Basuraj Bhowmik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04458" title="Abstract">arXiv:2311.04458</a> (replaced) [<a href="/pdf/2311.04458" title="Download PDF">pdf</a>, <a href="/format/2311.04458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retargeting video with an end-to-end framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+T">Thi-Ngoc-Hanh Le</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">HuiGuang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yi-Ru Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+T">Tong-Yee Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted for publication on IEEE Transactions on Visualization and Computer Graphics, October 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04464" title="Abstract">arXiv:2311.04464</a> (replaced) [<a href="/pdf/2311.04464" title="Download PDF">pdf</a>, <a href="/format/2311.04464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Few-shot CLIP with Semantic-Aware Fine-Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuefeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+X">Xiaofeng Mao</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xiu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhigang Li</a>, 
<a href="/search/cs?searchtype=author&query=lu%2C+W">Wang lu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jindong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+X">Xiangyang Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04502" title="Abstract">arXiv:2311.04502</a> (replaced) [<a href="/pdf/2311.04502" title="Download PDF">pdf</a>, <a href="/format/2311.04502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TADA: Making Node-link Diagrams Accessible to Blind and Low-Vision  People
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yichun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Nacenta%2C+M+A">Miguel A. Nacenta</a>, 
<a href="/search/cs?searchtype=author&query=Sukhai%2C+M+A">Mahadeo A. Sukhai</a>, 
<a href="/search/cs?searchtype=author&query=Somanath%2C+S">Sowmya Somanath</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04532" title="Abstract">arXiv:2311.04532</a> (replaced) [<a href="/pdf/2311.04532" title="Download PDF">pdf</a>, <a href="/format/2311.04532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Diverse Large Language Models for Automatic and General Bug  Reproduction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+S">Sungmin Kang</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+J">Juyeon Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Askarbekkyzy%2C+N">Nargiz Askarbekkyzy</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+S">Shin Yoo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work is an extension of our prior work, available at <a href="/abs/2209.11515">arXiv:2209.11515</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04591" title="Abstract">arXiv:2311.04591</a> (replaced) [<a href="/pdf/2311.04591" title="Download PDF">pdf</a>, <a href="/format/2311.04591" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Human Pose Estimation for Autonomous Driving with 3D Event  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xiaoting Yin</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Hao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiaan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ze Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yaozu Ye</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+H">Huajian Ni</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kailun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kaiwei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of <a href="/abs/2206.04511">arXiv:2206.04511</a>. The code and dataset are available at <a href="https://github.com/MasterHow/EventPointPose">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM); Robotics (cs.RO); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04592" title="Abstract">arXiv:2311.04592</a> (replaced) [<a href="/pdf/2311.04592" title="Download PDF">pdf</a>, <a href="/format/2311.04592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Characterizing the Evolution of Embedding Space of Neural Networks  using Algebraic Topology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suresh%2C+S">Suryaka Suresh</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+B">Bishshoy Das</a>, 
<a href="/search/cs?searchtype=author&query=Abrol%2C+V">Vinayak Abrol</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+S+D">Sumantra Dutta Roy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04648" title="Abstract">arXiv:2311.04648</a> (replaced) [<a href="/pdf/2311.04648" title="Download PDF">pdf</a>, <a href="/format/2311.04648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chrono DEM-Engine: A Discrete Element Method dual-GPU simulator with  customizable contact forces and element shape
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruochun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tagliafierro%2C+B">Bonaventura Tagliafierro</a>, 
<a href="/search/cs?searchtype=author&query=Heuvel%2C+C+V">Colin Vanden Heuvel</a>, 
<a href="/search/cs?searchtype=author&query=Sabarwal%2C+S">Shlok Sabarwal</a>, 
<a href="/search/cs?searchtype=author&query=Bakke%2C+L">Luning Bakke</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Y">Yulong Yue</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xin Wei</a>, 
<a href="/search/cs?searchtype=author&query=Serban%2C+R">Radu Serban</a>, 
<a href="/search/cs?searchtype=author&query=Negrut%2C+D">Dan Negrut</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 30 figures, 9 tables. This preprint is submitted to Computer Physics Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Software Engineering (cs.SE); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04661" title="Abstract">arXiv:2311.04661</a> (replaced) [<a href="/pdf/2311.04661" title="Download PDF">pdf</a>, <a href="/format/2311.04661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Massive Editing for Large Language Models via Meta Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Chenmien Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Ge Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04692" title="Abstract">arXiv:2311.04692</a> (replaced) [<a href="/pdf/2311.04692" title="Download PDF">pdf</a>, <a href="/format/2311.04692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Analysis of Just-in-Time Compilation in Modern Databases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+M">Miao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhengyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+K">Kongzhang Hao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liuyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chunling Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yi Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A peer-reviewed version of this paper has been published at the Australasian Database Conference (ADC) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04723" title="Abstract">arXiv:2311.04723</a> (replaced) [<a href="/pdf/2311.04723" title="Download PDF">pdf</a>, <a href="/format/2311.04723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication Complexity of Common Randomness Generation with Isotropic  States
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Dong%2C+Y">Yangjing Dong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yao%2C+P">Penghui Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 2 figures. Update funding information
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04797" title="Abstract">arXiv:2311.04797</a> (replaced) [<a href="/pdf/2311.04797" title="Download PDF">pdf</a>, <a href="/format/2311.04797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CloverLeaf on Intel Multi-Core CPUs: A Case Study in Write-Allocate  Evasion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Laukemann%2C+J">Jan Laukemann</a>, 
<a href="/search/cs?searchtype=author&query=Gruber%2C+T">Thomas Gruber</a>, 
<a href="/search/cs?searchtype=author&query=Hager%2C+G">Georg Hager</a>, 
<a href="/search/cs?searchtype=author&query=Oryspayev%2C+D">Dossay Oryspayev</a>, 
<a href="/search/cs?searchtype=author&query=Wellein%2C+G">Gerhard Wellein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages including artifact appendix; 10 figures, 1 table; added missing e-mail address
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04798" title="Abstract">arXiv:2311.04798</a> (replaced) [<a href="/pdf/2311.04798" title="Download PDF">pdf</a>, <a href="/format/2311.04798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tools for Refactoring to Microservices: A Preliminary Usability Report
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fritzsch%2C+J">Jonas Fritzsch</a>, 
<a href="/search/cs?searchtype=author&query=Correia%2C+F">Filipe Correia</a>, 
<a href="/search/cs?searchtype=author&query=Bogner%2C+J">Justus Bogner</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+S">Stefan Wagner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the 5th International Conference on Microservices (2023); <a href="https://www.conf-micro.services/2023/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04828" title="Abstract">arXiv:2311.04828</a> (replaced) [<a href="/pdf/2311.04828" title="Download PDF">pdf</a>, <a href="/format/2311.04828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SODAWideNet -- Salient Object Detection with an Attention augmented Wide  Encoder Decoder network without ImageNet pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dulam%2C+R+V+S">Rohit Venkata Sai Dulam</a>, 
<a href="/search/cs?searchtype=author&query=Kambhamettu%2C+C">Chandra Kambhamettu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ISVC'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04879" title="Abstract">arXiv:2311.04879</a> (replaced) [<a href="/pdf/2311.04879" title="Download PDF">pdf</a>, <a href="/format/2311.04879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LongQLoRA: Efficient and Effective Method to Extend Context Length of  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianxin Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item277">Cross-lists</a></li>
<li><a href="#item317">Replacements</a></li>
</ul>
<small>[ total of 512 entries:  <b>1-512</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2311">2311</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
