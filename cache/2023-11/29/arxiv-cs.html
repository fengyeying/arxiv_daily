<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Mon 27 Nov 23  to  Tue 28 Nov 23, announced Wed, 29 Nov 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item412">Cross-lists</a></li>
<li><a href="#item473">Replacements</a></li>
</ul>
<small>[ total of 711 entries:  <b>1-711</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Wed, 29 Nov 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16104" title="Abstract">arXiv:2311.16104</a> [<a href="/pdf/2311.16104" title="Download PDF">pdf</a>, <a href="/format/2311.16104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Analytics with Differential Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Digalakis%2C+V">Vassilis Digalakis Jr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Diploma Thesis, School of Electrical and Computer Engineering, Technical University of Crete, Chania, Greece, 2018
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Databases (cs.DB)

</div>
<p class="mathjax">Differential privacy is the state-of-the-art definition for privacy,
guaranteeing that any analysis performed on a sensitive dataset leaks no
information about the individuals whose data are contained therein. In this
thesis, we develop differentially private algorithms to analyze distributed and
streaming data. In the distributed model, we consider the particular problem of
learning -- in a distributed fashion -- a global model of the data, that can
subsequently be used for arbitrary analyses. We build upon PrivBayes, a
differentially private method that approximates the high-dimensional
distribution of a centralized dataset as a product of low-order distributions,
utilizing a Bayesian Network model. We examine three novel approaches to
learning a global Bayesian Network from distributed data, while offering the
differential privacy guarantee to all local datasets. Our work includes a
detailed theoretical analysis of the distributed, differentially private
entropy estimator which we use in one of our algorithms, as well as a detailed
experimental evaluation, using both synthetic and real-world data. In the
streaming model, we focus on the problem of estimating the density of a stream
of users, which expresses the fraction of all users that actually appear in the
stream. We offer one of the strongest privacy guarantees for the streaming
model, user-level pan-privacy, which ensures that the privacy of any user is
protected, even against an adversary that observes the internal state of the
algorithm. We provide a detailed analysis of an existing, sampling-based
algorithm for the problem and propose two novel modifications that
significantly improve it, both theoretically and experimentally, by optimally
using all the allocated "privacy budget."
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16105" title="Abstract">arXiv:2311.16105</a> [<a href="/pdf/2311.16105" title="Download PDF">pdf</a>, <a href="/ps/2311.16105" title="Download PostScript">ps</a>, <a href="/format/2311.16105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Privacy-preserving Central Bank Ledger for Central Bank Digital  Currency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chan%2C+W+M+T">Wang Mong Tikvah Chan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Retail central bank digital currency (rCBDC) is seen as a key upgrade of the
monetary system in the 21st century. However, privacy concerns are the main
impediment to rCBDC's development and roll-out. On the one hand, the rights of
people to keep their transactions private should be protected, including
against central bank surveillance. On the other hand, the central bank needs to
ensure that no over-issuance of money or other frauds occur, demanding a
certain form of knowledge of rCBDC transactions to safeguard against malicious
users. This work focuses on rCBDC architectures based on the unspent
transaction output (UTXO) data model and tackles the research problem of
preserving a sufficient degree of privacy for UTXO transaction records while
allowing the central bank to verify their correctness. User privacy is not
adequately addressed in the UTXO-based rCBDC architectures. Using evolving
public keys as pseudonyms to hide the real identities of users only solves the
privacy issue partially. Some information could still be leaked out. This work
investigates techniques to address the shortcomings of the pseudonym approach.
First, a Pedersen commitment scheme is applied to hide the transaction values
of a UTXO transaction while allowing the central bank to verify that no
over-issuance of rCBDC has occurred in the transaction.This work uses a Schnorr
signature to prove no over-issuance of money, which reduces overheads and
enables a non-interactive proof. Then, Coinjoin is applied to aggregate UTXO
transactions from different users into one larger UTXO transaction to obfuscate
the payer-payee relationship while preserving the correctness of the amount of
money flow. This work applies k-anonymity to analyse the privacy guarantee of
Coinjoin. By modelling the transaction traffic by a Poisson process, the
trade-off between anonymity and transaction confirmation time of Coinjoin is
analysed.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16106" title="Abstract">arXiv:2311.16106</a> [<a href="/pdf/2311.16106" title="Download PDF">pdf</a>, <a href="/ps/2311.16106" title="Download PostScript">ps</a>, <a href="/format/2311.16106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonparametric Spatio-Temporal Joint Probabilistic Data Association  Coupled Filter and Interfering Extended Target Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akbari%2C+B">Behzad Akbari</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Haibin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Ya-Jun Pan</a>, 
<a href="/search/cs?searchtype=author&query=Tharmarasa%2C+R">R.Tharmarasa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures, Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Extended target tracking estimates the centroid and shape of the target in
space and time. In various situations where extended target tracking is
applicable, the presence of multiple targets can lead to interference,
particularly when they maneuver behind one another in a sensor like a camera.
Nonetheless, when dealing with multiple extended targets, there's a tendency
for them to share similar shapes within a group, which can enhance their
detectability. For instance, the coordinated movement of a cluster of aerial
vehicles might cause radar misdetections during their convergence or
divergence. Similarly, in the context of a self-driving car, lane markings
might split or converge, resulting in inaccurate lane tracking detections. A
well-known joint probabilistic data association coupled (JPDAC) filter can
address this problem in only a single-point target tracking. A variation of
JPDACF was developed by introducing a nonparametric Spatio-Temporal Joint
Probabilistic Data Association Coupled Filter (ST-JPDACF) to address the
problem for extended targets. Using different kernel functions, we manage the
dependency of measurements in space (inside a frame) and time (between frames).
Kernel functions are able to be learned using a limited number of training
data. This extension can be used for tracking the shape and dynamics of
nonparametric dependent extended targets in clutter when targets share
measurements. The proposed algorithm was compared with other well-known
supervised methods in the interfering case and achieved promising results.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16107" title="Abstract">arXiv:2311.16107</a> [<a href="/pdf/2311.16107" title="Download PDF">pdf</a>, <a href="/ps/2311.16107" title="Download PostScript">ps</a>, <a href="/format/2311.16107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Innovative Design of Substitution Box Using Trigonometric  Transformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ishaq%2C+K">Kashif Ishaq</a>, 
<a href="/search/cs?searchtype=author&query=Qarni%2C+A+A">Awais Ahmed Qarni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">As the number of hacking events and cyber threats keeps going up, it is
getting harder and harder to communicate securely and keep personal information
safe on the Internet. Cryptography is a very important way to deal with these
problems because it can secure data by changing it from one form to another. In
this study, we show a new, lightweight algorithm that is based on trigonometric
ideas and offers a lot of security by making it less likely that cryptanalysis
will work. The performance of our suggested algorithm is better than that of
older methods like the Hill cipher, Blowfish, and DES. Even though traditional
methods offer good security, they may have more work to do, which slows them
down. The suggested algorithm tries to close this gap by offering a solution
based on trigonometric ideas that are both fast and safe. The main goal of this
study is to come up with a small but strong encryption algorithm that cannot be
broken by cryptanalysis and keeps Internet communication safe. We want to speed
up the coding process without making it less secure by using trigonometric
principles. The suggested algorithm uses trigonometric functions and operations
to create non-linearity and confusion, making it resistant to both differential
and linear cryptanalysis. We show that the suggested algorithm is more secure
and faster than traditional methods like the Hill cipher, Blowfish, and DES by
doing a lot of research and testing. Combining trigonometric ideas with a
simple design makes it workable for real world uses and offers a promising way
to protect data on the Internet.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16108" title="Abstract">arXiv:2311.16108</a> [<a href="/pdf/2311.16108" title="Download PDF">pdf</a>, <a href="/format/2311.16108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Picogrid: An experimental platform for prosumer microgrids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marathe%2C+M">Maitreyee Marathe</a>, 
<a href="/search/cs?searchtype=author&query=Venkataramanan%2C+G">Giri Venkataramanan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE Energy Conversion Conference and Expo 2023, Nashville, USA (8 pages, 12 figures)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The Microgrid paradigm is gaining momentum as one of the key pieces of
technology for expanding clean energy access and improving energy resilience.
Most of the interest in this pertains to distinct entities that either generate
electricity or act as loads, i.e., distinct producers and consumers. Remote
community microgrids and emerging transactive energy service models with
interconnected prosumers do not clearly fit into this paradigm. Notwithstanding
various publications that present concepts and simulations, there has been a
dearth of experimental platforms to study them, due to practical challenges.
This paper presents the `Picogrid' - an experimental platform particularly
designed for dc prosumer microgrids. It is a low-power, low-cost hardware
platform that enables interconnecting multiple prosumer entities in a bench-top
setup. Each prosumer sends data to a cloud dashboard and can receive set points
for optimal operation from a remote computer system, lending itself to use in a
virtual lab setup. The platform enables implementation of custom power profiles
based on real-world generation and demand datasets. Features of the platform
are demonstrated using simulation and experimental results.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16109" title="Abstract">arXiv:2311.16109</a> [<a href="/pdf/2311.16109" title="Download PDF">pdf</a>, <a href="/format/2311.16109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transfer Learning between Motor Imagery Datasets using Deep Learning --  Validation of Framework and Comparison of Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guetschel%2C+P">Pierre Guetschel</a>, 
<a href="/search/cs?searchtype=author&query=Tangermann%2C+M">Michael Tangermann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Keywords: EEG, BCI, Motor Imagery, Deep Learning, Transfer Learning, Cross-Dataset. 3 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">We present a simple deep learning-based framework commonly used in computer
vision and demonstrate its effectiveness for cross-dataset transfer learning in
mental imagery decoding tasks that are common in the field of Brain-Computer
Interfaces (BCI). We investigate, on a large selection of 12 motor-imagery
datasets, which ones are well suited for transfer, both as donors and as
receivers. Challenges. Deep learning models typically require long training
times and are data-hungry, which impedes their use for BCI systems that have to
minimize the recording time for (training) examples and are subject to
constraints induced by experiments involving human subjects. A solution to both
issues is transfer learning, but it comes with its own challenge, i.e.,
substantial data distribution shifts between datasets, subjects and even
between subsequent sessions of the same subject. Approach. For every pair of
pre-training (donor) and test (receiver) dataset, we first train a model on the
donor before training merely an additional new linear classification layer
based on a few receiver trials. Performance of this transfer approach is then
tested on other trials of the receiver dataset. Significance. First, we lower
the threshold to use transfer learning between motor imagery datasets: the
overall framework is extremely simple and nevertheless obtains decent
classification scores. Second, we demonstrate that deep learning models are a
good option for motor imagery cross-dataset transfer both for the reasons
outlined in the first point and because the framework presented is viable in
online scenarios. Finally, analysing which datasets are best suited for
transfer learning can be used as a reference for future researchers to
determine which to use for pre-training or benchmarking.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16110" title="Abstract">arXiv:2311.16110</a> [<a href="/pdf/2311.16110" title="Download PDF">pdf</a>, <a href="/format/2311.16110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Community Battery Energy Storage Systems for Enhancing Distribution  System Operation: A Multi-objective Optimization Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+M">Markus Wagner</a>, 
<a href="/search/cs?searchtype=author&query=Liebman%2C+A">Ariel Liebman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE International Conference on Energy Technologies for Future Grids, 2023 (IEEE ETFG 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Neural and Evolutionary Computing (cs.NE); Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
<p class="mathjax">The growing penetration of distributed energy resources (DERs) in
distribution networks (DNs) raises new operational challenges, particularly in
terms of reliability and voltage regulation. In response to these challenges,
we introduce an innovative DN operation framework with multi-objective
optimization, leveraging community battery energy storage systems (C-BESS). The
proposed framework targets two key operational objectives: first, to minimize
voltage deviation, which is a concern for a distribution network service
provider (DNSP), and second, to maximize the utilization of DERs on the demand
side. Recognizing the conflicting nature of these objectives, we utilize C-BESS
to enhance the system's adaptability to dynamically adjust DN operations. The
multi-objective optimization problem is solved using the non-dominated sorting
genetic algorithm-II (NSGA-II). Case studies using real-world data are
conducted to validate the effectiveness of the proposed framework. The results
show significant improvements in voltage regulation and DER utilization,
demonstrating the potential of C-BESS in enabling more reliable DN operation.
Our findings contribute to the ongoing discourse on the role of C-BESS in DN
operation enhancement and DER integration.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16112" title="Abstract">arXiv:2311.16112</a> [<a href="/pdf/2311.16112" title="Download PDF">pdf</a>, <a href="/format/2311.16112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Co-learning synaptic delays, weights and adaptation in spiking neural  networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deckers%2C+L">Lucas Deckers</a>, 
<a href="/search/cs?searchtype=author&query=Van+Damme%2C+L">Laurens Van Damme</a>, 
<a href="/search/cs?searchtype=author&query=Tsang%2C+I+J">Ing Jyh Tsang</a>, 
<a href="/search/cs?searchtype=author&query=Van+Leekwijck%2C+W">Werner Van Leekwijck</a>, 
<a href="/search/cs?searchtype=author&query=Latr%C3%A9%2C+S">Steven Latr&#xe9;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Spiking neural networks (SNN) distinguish themselves from artificial neural
networks (ANN) because of their inherent temporal processing and spike-based
computations, enabling a power-efficient implementation in neuromorphic
hardware. In this paper, we demonstrate that data processing with spiking
neurons can be enhanced by co-learning the connection weights with two other
biologically inspired neuronal features: 1) a set of parameters describing
neuronal adaptation processes and 2) synaptic propagation delays. The former
allows the spiking neuron to learn how to specifically react to incoming spikes
based on its past. The trained adaptation parameters result in neuronal
heterogeneity, which is found in the brain and also leads to a greater variety
in available spike patterns. The latter enables to learn to explicitly
correlate patterns that are temporally distanced. Synaptic delays reflect the
time an action potential requires to travel from one neuron to another. We show
that each of the co-learned features separately leads to an improvement over
the baseline SNN and that the combination of both leads to state-of-the-art SNN
results on all speech recognition datasets investigated with a simple 2-hidden
layer feed-forward network. Our SNN outperforms the ANN on the neuromorpic
datasets (Spiking Heidelberg Digits and Spiking Speech Commands), even with
fewer trainable parameters. On the 35-class Google Speech Commands dataset, our
SNN also outperforms a GRU of similar size. Our work presents brain-inspired
improvements to SNN that enable them to excel over an equivalent ANN of similar
size on tasks with rich temporal dynamics.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16113" title="Abstract">arXiv:2311.16113</a> [<a href="/pdf/2311.16113" title="Download PDF">pdf</a>, <a href="/format/2311.16113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BAGEL: Backdoor Attacks against Federated Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kongyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jiannong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jiaxing Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shaowei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yun Peng</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Weilong Peng</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+K">Kechao Cai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Federated Contrastive Learning (FCL) is an emerging privacy-preserving
paradigm in distributed learning for unlabeled data. In FCL, distributed
parties collaboratively learn a global encoder with unlabeled data, and the
global encoder could be widely used as a feature extractor to build models for
many downstream tasks. However, FCL is also vulnerable to many security threats
(e.g., backdoor attacks) due to its distributed nature, which are seldom
investigated in existing solutions. In this paper, we study the backdoor attack
against FCL as a pioneer research, to illustrate how backdoor attacks on
distributed local clients act on downstream tasks. Specifically, in our system,
malicious clients can successfully inject a backdoor into the global encoder by
uploading poisoned local updates, thus downstream models built with this global
encoder will also inherit the backdoor. We also investigate how to inject
backdoors into multiple downstream models, in terms of two different backdoor
attacks, namely the \textit{centralized attack} and the \textit{decentralized
attack}. Experiment results show that both the centralized and the
decentralized attacks can inject backdoors into downstream models effectively
with high attack success rates. Finally, we evaluate two defense methods
against our proposed backdoor attacks in FCL, which indicates that the
decentralized backdoor attack is more stealthy and harder to defend.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16114" title="Abstract">arXiv:2311.16114</a> [<a href="/pdf/2311.16114" title="Download PDF">pdf</a>, <a href="/format/2311.16114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Noise-Robust Joint Representation for Multimodal Emotion  Recognition under Realistic Incomplete Data Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+Q">Qi Fan</a> (1), 
<a href="/search/cs?searchtype=author&query=Zuo%2C+H">Haolin Zuo</a> (1), 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Rui Liu</a> (1), 
<a href="/search/cs?searchtype=author&query=Lian%2C+Z">Zheng Lian</a> (2), 
<a href="/search/cs?searchtype=author&query=Gao%2C+G">Guanglai Gao</a> (1) ((1) Inner Mongolia University, Hohhot, China, (2) Institute of Automation, Chinese Academy of Sciences, Beijing, China)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Multimodal emotion recognition (MER) in practical scenarios presents a
significant challenge due to the presence of incomplete data, such as missing
or noisy data. Traditional methods often discard missing data or replace it
with a zero vector, neglecting the availability issue of noisy data.
Consequently, these approaches are not fully applicable to realistic scenarios,
where both missing and noisy data are prevalent. To address this problem, we
propose a novel noise-robust MER model, named NMER, which effectively learns
robust multimodal joint representations from incomplete data containing noise.
Our approach incorporates two key components. First, we introduce a noise
scheduler that adjusts the type and level of noise in the training data,
emulating the characteristics of incomplete data in realistic scenarios.
Second, we employ a Variational AutoEncoder (VAE)-based NMER model to generate
robust multimodal joint representations from the noisy data, leveraging the
modality invariant feature. The experimental results on the benchmark dataset
IEMOCAP indicate the proposed NMER outperforms state-of-the-art MER systems.
The ablation results also confirm the effectiveness of the VAE structure. We
release our code at \href{https://github.com/WooyoohL/Noise-robust_MER.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16115" title="Abstract">arXiv:2311.16115</a> [<a href="/pdf/2311.16115" title="Download PDF">pdf</a>, <a href="/ps/2311.16115" title="Download PostScript">ps</a>, <a href="/format/2311.16115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI and Democracy&#x27;s Digital Identity Crisis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+S">Shrey Jain</a>, 
<a href="/search/cs?searchtype=author&query=Spelliscy%2C+C">Connor Spelliscy</a>, 
<a href="/search/cs?searchtype=author&query=Vance-Law%2C+S">Samuel Vance-Law</a>, 
<a href="/search/cs?searchtype=author&query=Moore%2C+S">Scott Moore</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">AI-enabled tools have become sophisticated enough to allow a small number of
individuals to run disinformation campaigns of an unprecedented scale.
Privacy-preserving identity attestations can drastically reduce instances of
impersonation and make disinformation easy to identify and potentially hinder.
By understanding how identity attestations are positioned across the spectrum
of decentralization, we can gain a better understanding of the costs and
benefits of various attestations. In this paper, we discuss attestation types,
including governmental, biometric, federated, and web of trust-based, and
include examples such as e-Estonia, China's social credit system, Worldcoin,
OAuth, X (formerly Twitter), Gitcoin Passport, and EAS. We believe that the
most resilient systems create an identity that evolves and is connected to a
network of similarly evolving identities that verify one another. In this type
of system, each entity contributes its respective credibility to the
attestation process, creating a larger, more comprehensive set of attestations.
We believe these systems could be the best approach to authenticating identity
and protecting against some of the threats to democracy that AI can pose in the
hands of malicious actors. However, governments will likely attempt to mitigate
these risks by implementing centralized identity authentication systems; these
centralized systems could themselves pose risks to the democratic processes
they are built to defend. We therefore recommend that policymakers support the
development of standards-setting organizations for identity, provide legal
clarity for builders of decentralized tooling, and fund research critical to
effective identity authentication systems.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16116" title="Abstract">arXiv:2311.16116</a> [<a href="/pdf/2311.16116" title="Download PDF">pdf</a>, <a href="/ps/2311.16116" title="Download PostScript">ps</a>, <a href="/format/2311.16116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resource Scheduling for UAVs-aided D2D Networks: A Multi-objective  Optimization Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+H">Hongyang Pan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yanheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+G">Geng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pengfei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yuen%2C+C">Chau Yuen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Unmanned aerial vehicles (UAVs)-aided device-todevice (D2D) networks have
attracted great interests with the development of 5G/6G communications, while
there are several challenges about resource scheduling in UAVs-aided D2D
networks. In this work, we formulate a UAVs-aided D2D network resource
scheduling optimization problem (NetResSOP) to comprehensively consider the
number of deployed UAVs, UAV positions, UAV transmission powers, UAV flight
velocities, communication channels, and UAV-device pair assignment so as to
maximize the D2D network capacity, minimize the number of deployed UAVs, and
minimize the average energy consumption over all UAVs simultaneously. The
formulated NetResSOP is a mixed-integer programming problem (MIPP) and an
NP-hard problem, which means that it is difficult to be solved in polynomial
time. Moreover, there are trade-offs between the optimization objectives, and
hence it is also difficult to find an optimal solution that can simultaneously
make all objectives be optimal. Thus, we propose a non-dominated sorting
genetic algorithm-III with a Flexible solution dimension mechanism, a Discrete
part generation mechanism, and a UAV number adjustment mechanism (NSGA-III-FDU)
for solving the problem comprehensively. Simulation results demonstrate the
effectiveness and the stability of the proposed NSGA-III-FDU under different
scales and settings of the D2D networks.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16117" title="Abstract">arXiv:2311.16117</a> [<a href="/pdf/2311.16117" title="Download PDF">pdf</a>, <a href="/format/2311.16117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicated Diffusion: Predicate Logic-Based Attention Guidance for  Text-to-Image Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sueyoshi%2C+K">Kota Sueyoshi</a>, 
<a href="/search/cs?searchtype=author&query=Matsubara%2C+T">Takashi Matsubara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 14 figures, ~400 images, ~30MB
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diffusion models have achieved remarkable results in generating high-quality,
diverse, and creative images. However, when it comes to text-based image
generation, they often fail to capture the intended meaning presented in the
text. For instance, a specified object may not be generated, an unnecessary
object may be generated, and an adjective may alter objects it was not intended
to modify. Moreover, we found that relationships indicating possession between
objects are often overlooked. While users' intentions in text are diverse,
existing methods tend to specialize in only some aspects of these. In this
paper, we propose Predicated Diffusion, a unified framework to express users'
intentions. We consider that the root of the above issues lies in the text
encoder, which often focuses only on individual words and neglects the logical
relationships between them. The proposed method does not solely rely on the
text encoder, but instead, represents the intended meaning in the text as
propositions using predicate logic and treats the pixels in the attention maps
as the fuzzy predicates. This enables us to obtain a differentiable loss
function that makes the image fulfill the proposition by minimizing it. When
compared to several existing methods, we demonstrated that Predicated Diffusion
can generate images that are more faithful to various text prompts, as verified
by human evaluators and pretrained image-text models.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16118" title="Abstract">arXiv:2311.16118</a> [<a href="/pdf/2311.16118" title="Download PDF">pdf</a>, <a href="/ps/2311.16118" title="Download PostScript">ps</a>, <a href="/format/2311.16118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imperceptible CMOS camera dazzle for adversarial attacks on deep neural  networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stein%2C+Z">Zvi Stein</a>, 
<a href="/search/cs?searchtype=author&query=Stern%2C+A">Adrian Stern</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Despite the outstanding performance of deep neural networks, they are
vulnerable to adversarial attacks. While there are many invisible attacks in
the digital domain, most physical world adversarial attacks are visible. Here
we present an invisible optical adversarial attack that uses a light source to
dazzle a CMOS camera with a rolling shutter. We present the photopic conditions
required to keep the attacking light source completely invisible while
sufficiently jamming the captured image so that a deep neural network applied
to it is deceived.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16119" title="Abstract">arXiv:2311.16119</a> [<a href="/pdf/2311.16119" title="Download PDF">pdf</a>, <a href="/format/2311.16119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ignore This Title and HackAPrompt: Exposing Systemic Vulnerabilities of  LLMs through a Global Scale Prompt Hacking Competition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schulhoff%2C+S">Sander Schulhoff</a>, 
<a href="/search/cs?searchtype=author&query=Pinto%2C+J">Jeremy Pinto</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A">Anaum Khan</a>, 
<a href="/search/cs?searchtype=author&query=Bouchard%2C+L">Louis-Fran&#xe7;ois Bouchard</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+C">Chenglei Si</a>, 
<a href="/search/cs?searchtype=author&query=Anati%2C+S">Svetlina Anati</a>, 
<a href="/search/cs?searchtype=author&query=Tagliabue%2C+V">Valen Tagliabue</a>, 
<a href="/search/cs?searchtype=author&query=Kost%2C+A+L">Anson Liu Kost</a>, 
<a href="/search/cs?searchtype=author&query=Carnahan%2C+C">Christopher Carnahan</a>, 
<a href="/search/cs?searchtype=author&query=Boyd-Graber%2C+J">Jordan Boyd-Graber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 8 figures Codebase: <a href="https://github.com/PromptLabs/hackaprompt">this https URL</a> Dataset: <a href="https://huggingface.co/datasets/hackaprompt/hackaprompt-dataset/blob/main/README.md">this https URL</a> Playground: <a href="https://huggingface.co/spaces/hackaprompt/playground">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Large Language Models (LLMs) are increasingly being deployed in interactive
contexts that involve direct user engagement, such as chatbots and writing
assistants. These deployments are increasingly plagued by prompt injection and
jailbreaking (collectively, prompt hacking), in which models are manipulated to
ignore their original instructions and instead follow potentially malicious
ones. Although widely acknowledged as a significant security threat, there is a
dearth of large-scale resources and quantitative studies on prompt hacking. To
address this lacuna, we launch a global prompt hacking competition, which
allows for free-form human input attacks. We elicit 600K+ adversarial prompts
against three state-of-the-art LLMs. We describe the dataset, which empirically
verifies that current LLMs can indeed be manipulated via prompt hacking. We
also present a comprehensive taxonomical ontology of the types of adversarial
prompts.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16120" title="Abstract">arXiv:2311.16120</a> [<a href="/pdf/2311.16120" title="Download PDF">pdf</a>, <a href="/format/2311.16120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sanity checks for patch visualisation in prototype-based image  classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu-Darme%2C+R">Romain Xu-Darme</a> (LSL, LIG), 
<a href="/search/cs?searchtype=author&query=Qu%C3%A9not%2C+G">Georges Qu&#xe9;not</a> (LIG), 
<a href="/search/cs?searchtype=author&query=Chihani%2C+Z">Zakaria Chihani</a> (LSL), 
<a href="/search/cs?searchtype=author&query=Rousset%2C+M">Marie-Christine Rousset</a> (LIG)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2302.08508">arXiv:2302.08508</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition Workshops (CVPRW), Jun 2023, Vancouvers, Canada
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this work, we perform an analysis of the visualisation methods implemented
in ProtoPNet and ProtoTree, two self-explaining visual classifiers based on
prototypes. We show that such methods do not correctly identify the regions of
interest inside of the images, and therefore do not reflect the model
behaviour, which can create a false sense of bias in the model. We also
demonstrate quantitatively that this issue can be mitigated by using other
saliency methods that provide more faithful image patches.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16121" title="Abstract">arXiv:2311.16121</a> [<a href="/pdf/2311.16121" title="Download PDF">pdf</a>, <a href="/format/2311.16121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-Time Neural Materials using Block-Compressed Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weinreich%2C+C">Cl&#xe9;ment Weinreich</a>, 
<a href="/search/cs?searchtype=author&query=de+Oliveira%2C+L">Louis de Oliveira</a>, 
<a href="/search/cs?searchtype=author&query=Houdard%2C+A">Antoine Houdard</a>, 
<a href="/search/cs?searchtype=author&query=Nader%2C+G">Georges Nader</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Neural materials typically consist of a collection of neural features along
with a decoder network. The main challenge in integrating such models in
real-time rendering pipelines lies in the large size required to store their
features in GPU memory and the complexity of evaluating the network
efficiently. We present a neural material model whose features and decoder are
specifically designed to be used in real-time rendering pipelines. Our
framework leverages hardware-based block compression (BC) texture formats to
store the learned features and trains the model to output the material
information continuously in space and scale. To achieve this, we organize the
features in a block-based manner and emulate BC6 decompression during training,
making it possible to export them as regular BC6 textures. This structure
allows us to use high resolution features while maintaining a low memory
footprint. Consequently, this enhances our model's overall capability, enabling
the use of a lightweight and simple decoder architecture that can be evaluated
directly in a shader. Furthermore, since the learned features can be decoded
continuously, it allows for random uv sampling and smooth transition between
scales without needing any subsequent filtering. As a result, our neural
material has a small memory footprint, can be decoded extremely fast adding a
minimal computational overhead to the rendering pipeline.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16122" title="Abstract">arXiv:2311.16122</a> [<a href="/pdf/2311.16122" title="Download PDF">pdf</a>, <a href="/format/2311.16122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Generative Augmentations for Few-Shot Counting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doubinsky%2C+P">Perla Doubinsky</a> (CEDRIC - VERTIGO, CNAM), 
<a href="/search/cs?searchtype=author&query=Audebert%2C+N">Nicolas Audebert</a> (CEDRIC - VERTIGO, CNAM), 
<a href="/search/cs?searchtype=author&query=Crucianu%2C+M">Michel Crucianu</a> (CEDRIC - VERTIGO), 
<a href="/search/cs?searchtype=author&query=Borgne%2C+H+L">Herv&#xe9; Le Borgne</a> (CEA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">With the availability of powerful text-to-image diffusion models, recent
works have explored the use of synthetic data to improve image classification
performances. These works show that it can effectively augment or even replace
real data. In this work, we investigate how synthetic data can benefit few-shot
class-agnostic counting. This requires to generate images that correspond to a
given input number of objects. However, text-to-image models struggle to grasp
the notion of count. We propose to rely on a double conditioning of Stable
Diffusion with both a prompt and a density map in order to augment a training
dataset for few-shot counting. Due to the small dataset size, the fine-tuned
model tends to generate images close to the training images. We propose to
enhance the diversity of synthesized images by exchanging captions between
images thus creating unseen configurations of object types and spatial layout.
Our experiments show that our diversified generation strategy significantly
improves the counting accuracy of two recent and performing few-shot counting
models on FSC147 and CARPK.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16123" title="Abstract">arXiv:2311.16123</a> [<a href="/pdf/2311.16123" title="Download PDF">pdf</a>, <a href="/format/2311.16123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Multiple Neighborhood Neural Cellular Automata (MNNCA) for  Enhanced Texture Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Petersen%2C+M">Magnus Petersen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Cellular Automata and Lattice Gases (nlin.CG)

</div>
<p class="mathjax">Cellular Automata (CA) have long been foundational in simulating dynamical
systems computationally. With recent innovations, this model class has been
brought into the realm of deep learning by parameterizing the CA's update rule
using an artificial neural network, termed Neural Cellular Automata (NCA). This
allows NCAs to be trained via gradient descent, enabling them to evolve into
specific shapes, generate textures, and mimic behaviors such as swarming.
However, a limitation of traditional NCAs is their inability to exhibit
sufficiently complex behaviors, restricting their potential in creative and
modeling tasks. Our research explores enhancing the NCA framework by
incorporating multiple neighborhoods and introducing structured noise for seed
states. This approach is inspired by techniques that have historically
amplified the expressiveness of classical continuous CA. All code and example
videos are publicly available on https://github.com/MagnusPetersen/MNNCA.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16124" title="Abstract">arXiv:2311.16124</a> [<a href="/pdf/2311.16124" title="Download PDF">pdf</a>, <a href="/format/2311.16124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffAttack: Evasion Attacks Against Diffusion-Based Adversarial  Purification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+M">Mintong Kang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Dawn Song</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Diffusion-based purification defenses leverage diffusion models to remove
crafted perturbations of adversarial examples and achieve state-of-the-art
robustness. Recent studies show that even advanced attacks cannot break such
defenses effectively, since the purification process induces an extremely deep
computational graph which poses the potential problem of gradient obfuscation,
high memory cost, and unbounded randomness. In this paper, we propose a unified
framework DiffAttack to perform effective and efficient attacks against
diffusion-based purification defenses, including both DDPM and score-based
approaches. In particular, we propose a deviated-reconstruction loss at
intermediate diffusion steps to induce inaccurate density gradient estimation
to tackle the problem of vanishing/exploding gradients. We also provide a
segment-wise forwarding-backwarding algorithm, which leads to memory-efficient
gradient backpropagation. We validate the attack effectiveness of DiffAttack
compared with existing adaptive attacks on CIFAR-10 and ImageNet. We show that
DiffAttack decreases the robust accuracy of models compared with SOTA attacks
by over 20% on CIFAR-10 under $\ell_\infty$ attack $(\epsilon=8/255)$, and over
10% on ImageNet under $\ell_\infty$ attack $(\epsilon=4/255)$. We conduct a
series of ablations studies, and we find 1) DiffAttack with the
deviated-reconstruction loss added over uniformly sampled time steps is more
effective than that added over only initial/final steps, and 2) diffusion-based
purification with a moderate diffusion length is more robust under DiffAttack.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16125" title="Abstract">arXiv:2311.16125</a> [<a href="/pdf/2311.16125" title="Download PDF">pdf</a>, <a href="/format/2311.16125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision-Based Incoming Traffic Estimator Using Deep Neural Network on  General Purpose Embedded Hardware
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zoysa%2C+K+G">K. G. Zoysa</a>, 
<a href="/search/cs?searchtype=author&query=Munasinghe%2C+S+R">S. R. Munasinghe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 11 figures, journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Traffic management is a serious problem in many cities around the world. Even
the suburban areas are now experiencing regular traffic congestion.
Inappropriate traffic control wastes fuel, time, and the productivity of
nations. Though traffic signals are used to improve traffic flow, they often
cause problems due to inappropriate or obsolete timing that does not tally with
the actual traffic intensity at the intersection. Traffic intensity
determination based on statistical methods only gives the average intensity
expected at any given time. However, to control traffic accurately, it is
required to know the real-time traffic intensity. In this research, image
processing and machine learning have been used to estimate actual traffic
intensity in real time. General-purpose electronic hardware has been used for
in-situ image processing based on the edge-detection method. A deep neural
network (DNN) was trained to infer traffic intensity in each image in real
time. The trained DNN estimated traffic intensity accurately in 90% of the
real-time images during road tests. The electronic system was implemented on a
Raspberry Pi single-board computer; hence, it is cost-effective for large-scale
deployment.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16127" title="Abstract">arXiv:2311.16127</a> [<a href="/pdf/2311.16127" title="Download PDF">pdf</a>, <a href="/format/2311.16127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SeamlessNeRF: Stitching Part NeRFs with Gradient Propagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+B">Bingchen Gong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuehao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiaoguang Han</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Q">Qi Dou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in SIGGRAPH Asia 2023. Project website is accessible at <a href="https://sites.google.com/view/seamlessnerf">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Neural Radiance Fields (NeRFs) have emerged as promising digital mediums of
3D objects and scenes, sparking a surge in research to extend the editing
capabilities in this domain. The task of seamless editing and merging of
multiple NeRFs, resembling the ``Poisson blending'' in 2D image editing,
remains a critical operation that is under-explored by existing work. To fill
this gap, we propose SeamlessNeRF, a novel approach for seamless appearance
blending of multiple NeRFs. In specific, we aim to optimize the appearance of a
target radiance field in order to harmonize its merge with a source field. We
propose a well-tailored optimization procedure for blending, which is
constrained by 1) pinning the radiance color in the intersecting boundary area
between the source and target fields and 2) maintaining the original gradient
of the target. Extensive experiments validate that our approach can effectively
propagate the source appearance from the boundary area to the entire target
field through the gradients. To the best of our knowledge, SeamlessNeRF is the
first work that introduces gradient-guided appearance editing to radiance
fields, offering solutions for seamless stitching of 3D objects represented in
NeRFs.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16128" title="Abstract">arXiv:2311.16128</a> [<a href="/pdf/2311.16128" title="Download PDF">pdf</a>, <a href="/format/2311.16128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Inspired Discrete-Phase Optimization for 3D Beamforming with  PIN-Diode Extra-Large Antenna Arrays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minsung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Stockley%2C+A">Annalise Stockley</a>, 
<a href="/search/cs?searchtype=author&query=Briggs%2C+K">Keith Briggs</a>, 
<a href="/search/cs?searchtype=author&query=Jamieson%2C+K">Kyle Jamieson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Large antenna arrays can steer narrow beams towards a target area, and thus
improve the communications capacity of wireless channels and the fidelity of
radio sensing. Hardware that is capable of continuously-variable phase shifts
is expensive, presenting scaling challenges. PIN diodes that apply only
discrete phase shifts are promising and cost-effective; however, unlike
continuous phase shifters, finding the best phase configuration across elements
is an NP-hard optimization problem. Thus, the complexity of optimization
becomes a new bottleneck for large-antenna arrays. To address this challenge,
this paper suggests a procedure for converting the optimization objective
function from a ratio of quadratic functions to a sequence of more easily
solvable quadratic unconstrained binary optimization (QUBO) sub-problems. This
conversion is an exact equivalence, and the resulting QUBO forms are standard
input formats for various physics-inspired optimization methods. We demonstrate
that a simulated annealing approach is very effective for solving these
sub-problems, and we give performance metrics for several large array types
optimized by this technique. Through numerical experiments, we report 3D
beamforming performance for extra-large arrays with up to 10,000 elements.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16129" title="Abstract">arXiv:2311.16129</a> [<a href="/pdf/2311.16129" title="Download PDF">pdf</a>, <a href="/ps/2311.16129" title="Download PostScript">ps</a>, <a href="/format/2311.16129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dataset for Investigating Anomalies in Compute Clusters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McSpadden%2C+D">Diana McSpadden</a>, 
<a href="/search/cs?searchtype=author&query=Alanazi%2C+Y">Yasir Alanazi</a>, 
<a href="/search/cs?searchtype=author&query=Hess%2C+B">Bryan Hess</a>, 
<a href="/search/cs?searchtype=author&query=Hild%2C+L">Laura Hild</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+M">Mark Jones</a>, 
<a href="/search/cs?searchtype=author&query=Lub%2C+Y">Yiyang Lub</a>, 
<a href="/search/cs?searchtype=author&query=Mohammed%2C+A">Ahmed Mohammed</a>, 
<a href="/search/cs?searchtype=author&query=Moore%2C+W">Wesley Moore</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jie Ren</a>, 
<a href="/search/cs?searchtype=author&query=Schram%2C+M">Malachi Schram</a>, 
<a href="/search/cs?searchtype=author&query=Smirni%2C+E">Evgenia Smirni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work utilizing the dataset was presented in a Research track poster at the Super Computing 2023 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">The dataset was collected for 332 compute nodes throughout May 19 - 23, 2023.
May 19 - 22 characterizes normal compute cluster behavior, while May 23
includes an anomalous event. The dataset includes eight CPU, 11 disk, 47
memory, and 22 Slurm metrics. It represents five distinct hardware
configurations and contains over one million records, totaling more than 180GB
of raw data.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16131" title="Abstract">arXiv:2311.16131</a> [<a href="/pdf/2311.16131" title="Download PDF">pdf</a>, <a href="/ps/2311.16131" title="Download PostScript">ps</a>, <a href="/format/2311.16131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure Arcade: A Gamified Defense Against Cyber Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Loesch%2C+S">Sean Loesch</a>, 
<a href="/search/cs?searchtype=author&query=Hrastich%2C+R">Ryan Hrastich</a>, 
<a href="/search/cs?searchtype=author&query=Herbert%2C+J">Jordan Herbert</a>, 
<a href="/search/cs?searchtype=author&query=Drangstveit%2C+B">Ben Drangstveit</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+J">Jacob Weber</a>, 
<a href="/search/cs?searchtype=author&query=Vanamala%2C+M">Mounika Vanamala</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">In modernity, we continually receive increasingly intricate technologies that
allow us to increase our lives convenience and efficiency. Our technology,
particularly technology available over the internet, is advancing at
unprecedented speed. However, this speed of advancement allows those behind
malicious attacks to have an increasingly easier time taking advantage of those
who know little about computer security. Unfortunately, education in the
computer security field is generally limited only to tertiary education. This
research addresses this problem through a gamified web-based application that
drives users to reach learning goals to help them become more vigilant internet
users: 1. Learn and memorize general computer security terminology, 2. Become
familiar with basic cryptography concepts, 3. Learn to recognize potential
phishing scams via email quickly, and 4. Learn common attacks on servers and
how to deal with them.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16133" title="Abstract">arXiv:2311.16133</a> [<a href="/pdf/2311.16133" title="Download PDF">pdf</a>, <a href="/format/2311.16133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effective Quantization for Diffusion Models on CPUs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+H">Hanwen Chang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Haihao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yiyang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+X">Xinyu Ye</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhenzhong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+W">Wenhua Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+K">Kaokao Lv</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weiwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yintong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Heng Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Diffusion models have gained popularity for generating images from textual
descriptions. Nonetheless, the substantial need for computational resources
continues to present a noteworthy challenge, contributing to time-consuming
processes. Quantization, a technique employed to compress deep learning models
for enhanced efficiency, presents challenges when applied to diffusion models.
These models are notably more sensitive to quantization compared to other model
types, potentially resulting in a degradation of image quality. In this paper,
we introduce a novel approach to quantize the diffusion models by leveraging
both quantization-aware training and distillation. Our results show the
quantized models can maintain the high image quality while demonstrating the
inference efficiency on CPUs.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16136" title="Abstract">arXiv:2311.16136</a> [<a href="/pdf/2311.16136" title="Download PDF">pdf</a>, <a href="/format/2311.16136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ERASER: Machine Unlearning in MLaaS via an Inference Serving-Aware  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yuke Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+J">Jian Lou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+F">Feng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhan Qin</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+K">Kui Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Over the past few years, Machine Learning-as-a-Service (MLaaS) has received a
surging demand for supporting Machine Learning-driven services to offer
revolutionized user experience across diverse application areas. MLaaS provides
inference service with low inference latency to application users based on an
ML model trained using a dataset collected from numerous individual data
owners. Recently, for the sake of data owners' privacy and to comply with the
"right to be forgotten (RTBF)" as enacted by data protection legislation, many
machine unlearning methods have been proposed to remove data owners' data from
trained models upon their unlearning requests. However, despite their promising
efficiency, almost all existing machine unlearning methods handle unlearning
requests in a manner that is independent of inference requests, which
unfortunately introduces new security and privacy vulnerabilities for machine
unlearning in MLaaS. In this paper, we propose the ERASER framework for machinE
unleaRning in MLaAS via an inferencE seRving-aware approach. ERASER proposes a
novel certified inference consistency mechanism that reduces inference latency
by selectively postponing unlearning execution incurred by unlearning requests
from data owners, while strictly adhering to the RTBF principle. ERASER offers
three groups of design choices to allow for tailor-made variants that best suit
the specific environments and preferences of different MLaaS systems. Extensive
empirical evaluations across various settings confirm ERASER's effectiveness,
e.g., it can effectively save up to 99% of inference latency and 31% of
computation overhead over the inference-oblivion baseline.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16137" title="Abstract">arXiv:2311.16137</a> [<a href="/pdf/2311.16137" title="Download PDF">pdf</a>, <a href="/format/2311.16137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Graph-to-Text Approach to Knowledge-Grounded Response Generation in  Human-Robot Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Walker%2C+N+T">Nicholas Thomas Walker</a>, 
<a href="/search/cs?searchtype=author&query=Ultes%2C+S">Stefan Ultes</a>, 
<a href="/search/cs?searchtype=author&query=Lison%2C+P">Pierre Lison</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Dialogue &amp; Discourse 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Knowledge graphs are often used to represent structured information in a
flexible and efficient manner, but their use in situated dialogue remains
under-explored. This paper presents a novel conversational model for
human--robot interaction that rests upon a graph-based representation of the
dialogue state. The knowledge graph representing the dialogue state is
continuously updated with new observations from the robot sensors, including
linguistic, situated and multimodal inputs, and is further enriched by other
modules, in particular for spatial understanding. The neural conversational
model employed to respond to user utterances relies on a simple but effective
graph-to-text mechanism that traverses the dialogue state graph and converts
the traversals into a natural language form. This conversion of the state graph
into text is performed using a set of parameterized functions, and the values
for those parameters are optimized based on a small set of Wizard-of-Oz
interactions. After this conversion, the text representation of the dialogue
state graph is included as part of the prompt of a large language model used to
decode the agent response. The proposed approach is empirically evaluated
through a user study with a humanoid robot that acts as conversation partner to
evaluate the impact of the graph-to-text mechanism on the response generation.
After moving a robot along a tour of an indoor environment, participants
interacted with the robot using spoken dialogue and evaluated how well the
robot was able to answer questions about what the robot observed during the
tour. User scores show a statistically significant improvement in the perceived
factuality of the robot responses when the graph-to-text approach is employed,
compared to a baseline using inputs structured as semantic triples.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16138" title="Abstract">arXiv:2311.16138</a> [<a href="/pdf/2311.16138" title="Download PDF">pdf</a>, <a href="/format/2311.16138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> After-Stroke Arm Paresis Detection using Kinematic Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+K">Kenneth Lai</a>, 
<a href="/search/cs?searchtype=author&query=Almekhlafi%2C+M">Mohammed Almekhlafi</a>, 
<a href="/search/cs?searchtype=author&query=Yanushkevich%2C+S">Svetlana Yanushkevich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to IEEE Symposium Series on Computational Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper presents an approach for detecting unilateral arm
paralysis/weakness using kinematic data. Our method employs temporal
convolution networks and recurrent neural networks, guided by knowledge
distillation, where we use inertial measurement units attached to the body to
capture kinematic information such as acceleration, rotation, and flexion of
body joints during an action. This information is then analyzed to recognize
body actions and patterns. Our proposed network achieves a high paretic
detection accuracy of 97.99\%, with an action classification accuracy of
77.69\%, through knowledge sharing. Furthermore, by incorporating causal
reasoning, we can gain additional insights into the patient's condition, such
as their Fugl-Meyer assessment score or impairment level based on the machine
learning result. Overall, our approach demonstrates the potential of using
kinematic data and machine learning for detecting arm paralysis/weakness. The
results suggest that our method could be a useful tool for clinicians and
healthcare professionals working with patients with this condition.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16139" title="Abstract">arXiv:2311.16139</a> [<a href="/pdf/2311.16139" title="Download PDF">pdf</a>, <a href="/format/2311.16139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GNNBleed: Inference Attacks to Unveil Private Edges in Graphs with  Realistic Access to GNN Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zeyu Song</a>, 
<a href="/search/cs?searchtype=author&query=Kabir%2C+E">Ehsanul Kabir</a>, 
<a href="/search/cs?searchtype=author&query=Mehnaz%2C+S">Shagufta Mehnaz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to USENIX Security '24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Graph Neural Networks (GNNs) have increasingly become an indispensable tool
in learning from graph-structured data, catering to various applications
including social network analysis, recommendation systems, etc. At the heart of
these networks are the edges which are crucial in guiding GNN models'
predictions. In many scenarios, these edges represent sensitive information,
such as personal associations or financial dealings -- thus requiring privacy
assurance. However, their contributions to GNN model predictions may in turn be
exploited by the adversary to compromise their privacy. Motivated by these
conflicting requirements, this paper investigates edge privacy in contexts
where adversaries possess black-box GNN model access, restricted further by
access controls, preventing direct insights into arbitrary node outputs. In
this context, we introduce a series of privacy attacks grounded on the
message-passing mechanism of GNNs. These strategies allow adversaries to deduce
connections between two nodes not by directly analyzing the model's output for
these pairs but by analyzing the output for nodes linked to them. Our
evaluation with seven real-life datasets and four GNN architectures underlines
a significant vulnerability: even in systems fortified with access control
mechanisms, an adaptive adversary can decipher private connections between
nodes, thereby revealing potentially sensitive relationships and compromising
the confidentiality of the graph.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16140" title="Abstract">arXiv:2311.16140</a> [<a href="/pdf/2311.16140" title="Download PDF">pdf</a>, <a href="/ps/2311.16140" title="Download PostScript">ps</a>, <a href="/format/2311.16140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapting Segment Anything Model (SAM) through Prompt-based Learning for  Enhanced Protein Identification in Cryo-EM Micrographs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+F">Fei He</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhiyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+M">Mingyue Gao</a>, 
<a href="/search/cs?searchtype=author&query=Poudel%2C+B">Biplab Poudel</a>, 
<a href="/search/cs?searchtype=author&query=Dhas%2C+N+S+E+S">Newgin Sam Ebin Sam Dhas</a>, 
<a href="/search/cs?searchtype=author&query=Gyawali%2C+R">Rajan Gyawali</a>, 
<a href="/search/cs?searchtype=author&query=Dhakal%2C+A">Ashwin Dhakal</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jianlin Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dong Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Cryo-electron microscopy (cryo-EM) remains pivotal in structural biology, yet
the task of protein particle picking, integral for 3D protein structure
construction, is laden with manual inefficiencies. While recent AI tools such
as Topaz and crYOLO are advancing the field, they do not fully address the
challenges of cryo-EM images, including low contrast, complex shapes, and
heterogeneous conformations. This study explored prompt-based learning to adapt
the state-of-the-art image segmentation foundation model Segment Anything Model
(SAM) for cryo-EM. This focus was driven by the desire to optimize model
performance with a small number of labeled data without altering pre-trained
parameters, aiming for a balance between adaptability and foundational
knowledge retention. Through trials with three prompt-based learning
strategies, namely head prompt, prefix prompt, and encoder prompt, we observed
enhanced performance and reduced computational requirements compared to the
fine-tuning approach. This work not only highlights the potential of prompting
SAM in protein identification from cryo-EM micrographs but also suggests its
broader promise in biomedical image segmentation and object detection.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16141" title="Abstract">arXiv:2311.16141</a> [<a href="/pdf/2311.16141" title="Download PDF">pdf</a>, <a href="/format/2311.16141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Brain-Inspired Efficient Pruning: Exploiting Criticality in Spiking  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Boxiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+H">Haihang You</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Spiking Neural Networks (SNNs) have been an attractive option for deployment
on devices with limited computing resources and lower power consumption because
of the event-driven computing characteristic. As such devices have limited
computing and storage resources, pruning for SNNs has been widely focused
recently. However, the binary and non-differentiable property of spike signals
make pruning deep SNNs challenging, so existing methods require high time
overhead to make pruning decisions. In this paper, inspired by critical brain
hypothesis in neuroscience, we design a regeneration mechanism based on
criticality to efficiently obtain the critical pruned networks. Firstly, we
propose a low-cost metric for the criticality of pruning structures. Then we
re-rank the pruned structures after pruning and regenerate those with higher
criticality. We evaluate our method using VGG-16 and ResNet-19 for both
unstructured pruning and structured pruning. Our method achieves higher
performance compared to current state-of-the-art (SOTA) method with the same
time overhead. We also achieve comparable performances (even better on VGG-16)
compared to the SOTA method with 11.3x and 15.5x acceleration. Moreover, we
investigate underlying mechanism of our method and find that it efficiently
selects potential structures, learns the consistent feature representations and
reduces the overfitting during the recovery phase.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16142" title="Abstract">arXiv:2311.16142</a> [<a href="/pdf/2311.16142" title="Download PDF">pdf</a>, <a href="/format/2311.16142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating Lane-Free Traffic with a Dynamic Driving Simulator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sekeran%2C+M">Maya Sekeran</a>, 
<a href="/search/cs?searchtype=author&query=Syed%2C+A+A">Arslan Ali Syed</a>, 
<a href="/search/cs?searchtype=author&query=Lindner%2C+J">Johannes Lindner</a>, 
<a href="/search/cs?searchtype=author&query=Margreiter%2C+M">Martin Margreiter</a>, 
<a href="/search/cs?searchtype=author&query=Bogenberger%2C+K">Klaus Bogenberger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was presented at IEEE ITSC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Lane-free traffic (LFT) is a new traffic system that relies on connected and
automated vehicles (CAV) to increase road capacity and utilization by removing
traditional lane markings using coordinated maneuvering of CAVs in LFT
strategies. LFT is based on two main principles: upstream nudging and vehicles
moving without adhering to any lane markings. By leveraging CAV capabilities to
communicate and exchange information, LFT represents a promising future traffic
system. While current research uses LFT simulations in two-dimensional space,
driving simulators are necessary to investigate human behavior and perceived
safety in LFT. This paper proposes a conceptual framework for LFT driving
simulations and describes the assumptions, requirements, and recent
technological developments that make it possible to investigate the human
perspective and acceptance of LFT. Additionally, we propose a scenario matrix
that can act as a test guide to building driving simulation scenarios for the
LFT.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16143" title="Abstract">arXiv:2311.16143</a> [<a href="/pdf/2311.16143" title="Download PDF">pdf</a>, <a href="/format/2311.16143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ransomware Detection and Classification using Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kunku%2C+K">Kavitha Kunku</a>, 
<a href="/search/cs?searchtype=author&query=Zaman%2C+A">ANK Zaman</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+K">Kaushik Roy</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Symposium on Computational Intelligence in Cyber Security
  (IEEE CICS) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Vicious assaults, malware, and various ransomware pose a cybersecurity
threat, causing considerable damage to computer structures, servers, and mobile
and web apps across various industries and businesses. These safety concerns
are important and must be addressed immediately. Ransomware detection and
classification are critical for guaranteeing rapid reaction and prevention.
This study uses the XGBoost classifier and Random Forest (RF) algorithms to
detect and classify ransomware attacks. This approach involves analyzing the
behaviour of ransomware and extracting relevant features that can help
distinguish between different ransomware families. The models are evaluated on
a dataset of ransomware attacks and demonstrate their effectiveness in
accurately detecting and classifying ransomware. The results show that the
XGBoost classifier, Random Forest Classifiers, can effectively detect and
classify different ransomware attacks with high accuracy, thereby providing a
valuable tool for enhancing cybersecurity.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16145" title="Abstract">arXiv:2311.16145</a> [<a href="/pdf/2311.16145" title="Download PDF">pdf</a>, <a href="/format/2311.16145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual-Stream Attention Transformers for Sewer Defect Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Newaz%2C+A+A+R">Abdullah Al Redwan Newaz</a>, 
<a href="/search/cs?searchtype=author&query=Abdeldguerfi%2C+M">Mahdi Abdeldguerfi</a>, 
<a href="/search/cs?searchtype=author&query=Niles%2C+K+N">Kendall N. Niles</a>, 
<a href="/search/cs?searchtype=author&query=Tom%2C+J">Joe Tom</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose a dual-stream multi-scale vision transformer (DS-MSHViT)
architecture that processes RGB and optical flow inputs for efficient sewer
defect classification. Unlike existing methods that combine the predictions of
two separate networks trained on each modality, we jointly train a single
network with two branches for RGB and motion. Our key idea is to use
self-attention regularization to harness the complementary strengths of the RGB
and motion streams. The motion stream alone struggles to generate accurate
attention maps, as motion images lack the rich visual features present in RGB
images. To facilitate this, we introduce an attention consistency loss between
the dual streams. By leveraging motion cues through a self-attention
regularizer, we align and enhance RGB attention maps, enabling the network to
concentrate on pertinent input regions. We evaluate our data on a public
dataset as well as cross-validate our model performance in a novel dataset. Our
method outperforms existing models that utilize either convolutional neural
networks (CNNs) or multi-scale hybrid vision transformers (MSHViTs) without
employing attention regularization between the two streams.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16146" title="Abstract">arXiv:2311.16146</a> [<a href="/pdf/2311.16146" title="Download PDF">pdf</a>, <a href="/ps/2311.16146" title="Download PostScript">ps</a>, <a href="/format/2311.16146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emulators in JINSP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Miaomiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhe%2C+L">Lv Zhe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">JINSP(Jiutian Intelligence Network Simulation Platform) describes a series of
basic emulators and their combinations, such as the simulation of the protocol
stack for dynamic users in a real environment, which is composed of user
behavior simulation, base station simulation, and terminal simulation. It is
applied in specific business scenarios, such as multi-target antenna
optimization, compression feedback, and so on. This paper provides detailed
descriptions of each emulator and its combination based on this foundation,
including the implementation process of the emulator, integration with the
platform, experimental results, and other aspects.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16147" title="Abstract">arXiv:2311.16147</a> [<a href="/pdf/2311.16147" title="Download PDF">pdf</a>, <a href="/ps/2311.16147" title="Download PostScript">ps</a>, <a href="/format/2311.16147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Load balancing in cloud data centers with optimized virtual machines  placement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=naji%2C+H+R">Hamid Reza naji</a>, 
<a href="/search/cs?searchtype=author&query=Esmaeili%2C+R">Reza Esmaeili</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">So far, various solutions have been proposed for symmetric distribution of
load cloud computing environments. In this article, a new solution to the
optimal allocation of virtual machines in the cloud data centers is presented
to provide a good load balancing among servers. The proposed method offers a
solution uses learning automata as a reinforcement learning model to improve
the performance of the optimization algorithm for optimal placement of virtual
machines. Also, it helps the search algorithm to converge more quickly to the
global optimum. The simulation results show the proposed method has been able
to perform good level of load balancing in cloud data centers.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16148" title="Abstract">arXiv:2311.16148</a> [<a href="/pdf/2311.16148" title="Download PDF">pdf</a>, <a href="/format/2311.16148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Univariate Radial Basis Function Layers: Brain-inspired Deep Neural  Layers for Low-Dimensional Inputs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patil%2C+B">Basavasagar Patil</a>, 
<a href="/search/cs?searchtype=author&query=Alameda-Pineda%2C+X">Xavier Alameda-Pineda</a>, 
<a href="/search/cs?searchtype=author&query=Reinke%2C+C">Chris Reinke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep Neural Networks (DNNs) became the standard tool for function
approximation with most of the introduced architectures being developed for
high-dimensional input data. However, many real-world problems have
low-dimensional inputs for which standard Multi-Layer Perceptrons (MLPs) are
the default choice. An investigation into specialized architectures is missing.
We propose a novel DNN layer called Univariate Radial Basis Function (U-RBF)
layer as an alternative. Similar to sensory neurons in the brain, the U-RBF
layer processes each individual input dimension with a population of neurons
whose activations depend on different preferred input values. We verify its
effectiveness compared to MLPs in low-dimensional function regressions and
reinforcement learning tasks. The results show that the U-RBF is especially
advantageous when the target function becomes complex and difficult to
approximate.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16151" title="Abstract">arXiv:2311.16151</a> [<a href="/pdf/2311.16151" title="Download PDF">pdf</a>, <a href="/format/2311.16151" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimating Post-Synaptic Effects for Online Training of Feed-Forward  SNNs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Summe%2C+T">Thomas Summe</a>, 
<a href="/search/cs?searchtype=author&query=Schaefer%2C+C+J">Clemens JS Schaefer</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+S">Siddharth Joshi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Facilitating online learning in spiking neural networks (SNNs) is a key step
in developing event-based models that can adapt to changing environments and
learn from continuous data streams in real-time. Although forward-mode
differentiation enables online learning, its computational requirements
restrict scalability. This is typically addressed through approximations that
limit learning in deep models. In this study, we propose Online Training with
Postsynaptic Estimates (OTPE) for training feed-forward SNNs, which
approximates Real-Time Recurrent Learning (RTRL) by incorporating temporal
dynamics not captured by current approximations, such as Online Training
Through Time (OTTT) and Online Spatio-Temporal Learning (OSTL). We show
improved scaling for multi-layer networks using a novel approximation of
temporal effects on the subsequent layer's activity. This approximation incurs
minimal overhead in the time and space complexity compared to similar
algorithms, and the calculation of temporal effects remains local to each
layer. We characterize the learning performance of our proposed algorithms on
multiple SNN model configurations for rate-based and time-based encoding. OTPE
exhibits the highest directional alignment to exact gradients, calculated with
backpropagation through time (BPTT), in deep networks and, on time-based
encoding, outperforms other approximate methods. We also observe sizeable gains
in average performance over similar algorithms in offline training of Spiking
Heidelberg Digits with equivalent hyper-parameters (OTTT/OSTL - 70.5%; OTPE -
75.2%; BPTT - 78.1%).
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16152" title="Abstract">arXiv:2311.16152</a> [<a href="/pdf/2311.16152" title="Download PDF">pdf</a>, <a href="/format/2311.16152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human-Centered Programming: The Design of a Robotic Process Automation  Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gago%2C+P">Piotr Gago</a>, 
<a href="/search/cs?searchtype=author&query=Voitenkova%2C+A">Anna Voitenkova</a>, 
<a href="/search/cs?searchtype=author&query=Jab%C5%82onski%2C+D">Daniel Jab&#x142;onski</a>, 
<a href="/search/cs?searchtype=author&query=Debelyi%2C+I">Ihor Debelyi</a>, 
<a href="/search/cs?searchtype=author&query=Skorupska%2C+K">Kinga Skorupska</a>, 
<a href="/search/cs?searchtype=author&query=Grzeszczuk%2C+M">Maciej Grzeszczuk</a>, 
<a href="/search/cs?searchtype=author&query=Kope%C4%87%2C+W">Wies&#x142;aw Kope&#x107;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">RPA (Robotic Process Automation) helps automate repetitive tasks performed by
users, often across different software solutions. Regardless of the RPA tool
chosen, the key problem in automation is analyzing the steps of these tasks.
This is usually done by an analyst with the possible participation of the
person responsible for the given activity. However, currently there exists no
one-size-fits-all description language, which would allow to record, process,
and easily automate steps of specific tasks. Every RPA solution uses a
different notation, which is not easily human-readable, editable, and which
cannot be applied to a different automation platform. Therefore, in this paper,
we propose a new eXtensible Robotic Language (XRL) that can be understood by
both programmers and non-programmers to automate repetitive business processes.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16153" title="Abstract">arXiv:2311.16153</a> [<a href="/pdf/2311.16153" title="Download PDF">pdf</a>, <a href="/format/2311.16153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying and Mitigating Vulnerabilities in LLM-Integrated  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+F">Fengqing Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhangchen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+L">Luyao Niu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Boxin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jinyuan Jia</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Poovendran%2C+R">Radha Poovendran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) are increasingly deployed as the service backend
for LLM-integrated applications such as code completion and AI-powered search.
LLM-integrated applications serve as middleware to refine users' queries with
domain-specific knowledge to better inform LLMs and enhance the responses.
Despite numerous opportunities and benefits, LLM-integrated applications also
introduce new attack surfaces. Understanding, minimizing, and eliminating these
emerging attack surfaces is a new area of research. In this work, we consider a
setup where the user and LLM interact via an LLM-integrated application in the
middle. We focus on the communication rounds that begin with user's queries and
end with LLM-integrated application returning responses to the queries, powered
by LLMs at the service backend. For this query-response protocol, we identify
potential vulnerabilities that can originate from the malicious application
developer or from an outsider threat initiator that is able to control the
database access, manipulate and poison data that are high-risk for the user.
Successful exploits of the identified vulnerabilities result in the users
receiving responses tailored to the intent of a threat initiator. We assess
such threats against LLM-integrated applications empowered by OpenAI GPT-3.5
and GPT-4. Our empirical results show that the threats can effectively bypass
the restrictions and moderation policies of OpenAI, resulting in users
receiving responses that contain bias, toxic content, privacy risk, and
disinformation. To mitigate those threats, we identify and define four key
properties, namely integrity, source identification, attack detectability, and
utility preservation, that need to be satisfied by a safe LLM-integrated
application. Based on these properties, we develop a lightweight,
threat-agnostic defense that mitigates both insider and outsider threats.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16154" title="Abstract">arXiv:2311.16154</a> [<a href="/pdf/2311.16154" title="Download PDF">pdf</a>, <a href="/ps/2311.16154" title="Download PostScript">ps</a>, <a href="/format/2311.16154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stepping out of Flatland: Discovering Behavior Patterns as Topological  Structures in Cyber Hypergraphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jenne%2C+H">Helen Jenne</a>, 
<a href="/search/cs?searchtype=author&query=Aksoy%2C+S+G">Sinan G. Aksoy</a>, 
<a href="/search/cs?searchtype=author&query=Best%2C+D">Daniel Best</a>, 
<a href="/search/cs?searchtype=author&query=Bittner%2C+A">Alyson Bittner</a>, 
<a href="/search/cs?searchtype=author&query=Henselman-Petrusek%2C+G">Gregory Henselman-Petrusek</a>, 
<a href="/search/cs?searchtype=author&query=Joslyn%2C+C">Cliff Joslyn</a>, 
<a href="/search/cs?searchtype=author&query=Kay%2C+B">Bill Kay</a>, 
<a href="/search/cs?searchtype=author&query=Myers%2C+A">Audun Myers</a>, 
<a href="/search/cs?searchtype=author&query=Seppala%2C+G">Garret Seppala</a>, 
<a href="/search/cs?searchtype=author&query=Warley%2C+J">Jackson Warley</a>, 
<a href="/search/cs?searchtype=author&query=Young%2C+S+J">Stephen J. Young</a>, 
<a href="/search/cs?searchtype=author&query=Purvine%2C+E">Emilie Purvine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 11 figures. This paper is written for a general audience
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Data breaches and ransomware attacks occur so often that they have become
part of our daily news cycle. This is due to a myriad of factors, including the
increasing number of internet-of-things devices, shift to remote work during
the pandemic, and advancement in adversarial techniques, which all contribute
to the increase in both the complexity of data captured and the challenge of
protecting our networks. At the same time, cyber research has made strides,
leveraging advances in machine learning and natural language processing to
focus on identifying sophisticated attacks that are known to evade conventional
measures. While successful, the shortcomings of these methods, particularly the
lack of interpretability, are inherent and difficult to overcome. Consequently,
there is an ever-increasing need to develop new tools for analyzing cyber data
to enable more effective attack detection. In this paper, we present a novel
framework based in the theory of hypergraphs and topology to understand data
from cyber networks through topological signatures, which are both flexible and
can be traced back to the log data. While our approach's mathematical grounding
requires some technical development, this pays off in interpretability, which
we will demonstrate with concrete examples in a large-scale cyber network
dataset. These examples are an introduction to the broader possibilities that
lie ahead; our goal is to demonstrate the value of applying methods from the
burgeoning fields of hypernetwork science and applied topology to understand
relationships among behaviors in cyber data.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16157" title="Abstract">arXiv:2311.16157</a> [<a href="/pdf/2311.16157" title="Download PDF">pdf</a>, <a href="/format/2311.16157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GeoTop: Advancing Image Classification with Geometric-Topological  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abaach%2C+M">Mariem Abaach</a>, 
<a href="/search/cs?searchtype=author&query=Morilla%2C+I">Ian Morilla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV); Geometric Topology (math.GT)

</div>
<p class="mathjax">In this study, we explore the application of Topological Data Analysis (TDA)
and Lipschitz-Killing Curvatures (LKCs) as powerful tools for feature
extraction and classification in the context of biomedical multiomics problems.
TDA allows us to capture topological features and patterns within complex
datasets, while LKCs provide essential geometric insights. We investigate the
potential of combining both methods to improve classification accuracy. Using a
dataset of biomedical images, we demonstrate that TDA and LKCs can effectively
extract topological and geometrical features, respectively. The combination of
these features results in enhanced classification performance compared to using
each method individually. This approach offers promising results and has the
potential to advance our understanding of complex biological processes in
various biomedical applications. Our findings highlight the value of
integrating topological and geometrical information in biomedical data
analysis. As we continue to delve into the intricacies of multiomics problems,
the fusion of these insights holds great promise for unraveling the underlying
biological complexities.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16158" title="Abstract">arXiv:2311.16158</a> [<a href="/pdf/2311.16158" title="Download PDF">pdf</a>, <a href="/format/2311.16158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CarbNN: A Novel Active Transfer Learning Neural Network To Build De Novo  Metal Organic Frameworks (MOFs) for Carbon Capture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Redkar%2C+N">Neel Redkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 12 figures, presented at AAAI-23 orally &amp; as a poster
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Over the past decade, climate change has become an increasing problem with
one of the major contributing factors being carbon dioxide (CO2) emissions;
almost 51% of total US carbon emissions are from factories. Current materials
used in CO2 capture are lacking either in efficiency, sustainability, or cost.
<br />Electrocatalysis of CO2 is a new approach where CO2 can be reduced and the
components used industrially as fuel, saving transportation costs, creating
financial incentives. Metal Organic Frameworks (MOFs) are crystals made of
organo-metals that adsorb, filter, and electrocatalyze CO2. The current
available MOFs for capture &amp; electrocatalysis are expensive to manufacture and
inefficient at capture. The goal therefore is to computationally design a MOF
that can adsorb CO2 and catalyze carbon monoxide &amp; oxygen with low cost.
<br />A novel active transfer learning neural network was developed, utilizing
transfer learning due to limited available data on 15 MOFs. Using the Cambridge
Structural Database with 10,000 MOFs, the model used incremental mutations to
fit a trained fitness hyper-heuristic function. Eventually, a Selenium MOF
(C18MgO25Se11Sn20Zn5) was converged on. Through analysis of predictions &amp;
literature, the converged MOF was shown to be more effective &amp; more
synthetically accessible than existing MOFs, showing the model had an
understanding of effective electrocatalytic structures in the material space.
This novel network can be implemented for other gas separations and catalysis
applications that have limited training accessible datasets.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16161" title="Abstract">arXiv:2311.16161</a> [<a href="/pdf/2311.16161" title="Download PDF">pdf</a>, <a href="/format/2311.16161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision Encoder-Decoder Models for AI Coaching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nayak%2C+J+S">Jyothi S Nayak</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A+K+M+A">Afifah Khan Mohammed Ajmal Khan</a>, 
<a href="/search/cs?searchtype=author&query=Manjeshwar%2C+C">Chirag Manjeshwar</a>, 
<a href="/search/cs?searchtype=author&query=Banday%2C+I+A">Imadh Ajaz Banday</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This research paper introduces an innovative AI coaching approach by
integrating vision-encoder-decoder models. The feasibility of this method is
demonstrated using a Vision Transformer as the encoder and GPT-2 as the
decoder, achieving a seamless integration of visual input and textual
interaction. Departing from conventional practices of employing distinct models
for image recognition and text-based coaching, our integrated architecture
directly processes input images, enabling natural question-and-answer dialogues
with the AI coach. This unique strategy simplifies model architecture while
enhancing the overall user experience in human-AI interactions. We showcase
sample results to demonstrate the capability of the model. The results
underscore the methodology's potential as a promising paradigm for creating
efficient AI coach models in various domains involving visual inputs.
Importantly, this potential holds true regardless of the particular visual
encoder or text decoder chosen. Additionally, we conducted experiments with
different sizes of GPT-2 to assess the impact on AI coach performance,
providing valuable insights into the scalability and versatility of our
proposed methodology.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16162" title="Abstract">arXiv:2311.16162</a> [<a href="/pdf/2311.16162" title="Download PDF">pdf</a>, <a href="/format/2311.16162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Artificial Intelligence Technology for Mapping Research to  Sustainable Development Goals: A Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hui Yin</a>, 
<a href="/search/cs?searchtype=author&query=Aryani%2C+A">Amir Aryani</a>, 
<a href="/search/cs?searchtype=author&query=Lambert%2C+G">Gavin Lambert</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+M">Marcus White</a>, 
<a href="/search/cs?searchtype=author&query=Salvador-Carulla%2C+L">Luis Salvador-Carulla</a>, 
<a href="/search/cs?searchtype=author&query=Sadiq%2C+S">Shazia Sadiq</a>, 
<a href="/search/cs?searchtype=author&query=Sojli%2C+E">Elvira Sojli</a>, 
<a href="/search/cs?searchtype=author&query=Boddy%2C+J">Jennifer Boddy</a>, 
<a href="/search/cs?searchtype=author&query=Murray%2C+G">Greg Murray</a>, 
<a href="/search/cs?searchtype=author&query=Tham%2C+W+W">Wing Wah Tham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">The number of publications related to the Sustainable Development Goals
(SDGs) continues to grow. These publications cover a diverse spectrum of
research, from humanities and social sciences to engineering and health. Given
the imperative of funding bodies to monitor outcomes and impacts, linking
publications to relevant SDGs is critical but remains time-consuming and
difficult given the breadth and complexity of the SDGs. A publication may
relate to several goals (interconnection feature of goals), and therefore
require multidisciplinary knowledge to tag accurately. Machine learning
approaches are promising and have proven particularly valuable for tasks such
as manual data labeling and text classification. In this study, we employed
over 82,000 publications from an Australian university as a case study. We
utilized a similarity measure to map these publications onto Sustainable
Development Goals (SDGs). Additionally, we leveraged the OpenAI GPT model to
conduct the same task, facilitating a comparative analysis between the two
approaches. Experimental results show that about 82.89% of the results obtained
by the similarity measure overlap (at least one tag) with the outputs of the
GPT model. The adopted model (similarity measure) can complement GPT model for
SDG classification. Furthermore, deep learning methods, which include the
similarity measure used here, are more accessible and trusted for dealing with
sensitive data without the use of commercial AI services or the deployment of
expensive computing resources to operate large language models. Our study
demonstrates how a crafted combination of the two methods can achieve reliable
results for mapping research to the SDGs.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16167" title="Abstract">arXiv:2311.16167</a> [<a href="/pdf/2311.16167" title="Download PDF">pdf</a>, <a href="/format/2311.16167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MMPDE-Net and Moving Sampling Physics-informed Neural Networks Based On  Moving Mesh Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yang%2C+Y">Yu Yang</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+Q">Qihong Yang</a>, 
<a href="/search/math?searchtype=author&query=Deng%2C+Y">Yangtao Deng</a>, 
<a href="/search/math?searchtype=author&query=He%2C+Q">Qiaolin He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this work, we propose an end-to-end adaptive sampling neural network
(MMPDE-Net) based on the moving mesh PDE method, which can adaptively generate
new coordinates of sampling points by solving the moving mesh PDE. This model
focuses on improving the efficiency of individual sampling points. Moreover, we
have developed an iterative algorithm based on MMPDE-Net, which makes the
sampling points more precise and controllable. Since MMPDE-Net is a framework
independent of the deep learning solver, we combine it with PINN to propose
MS-PINN and demonstrate its effectiveness by performing error analysis under
the assumptions given in this paper. Meanwhile, we demonstrate the performance
improvement of MS-PINN compared to PINN through numerical experiments on four
typical examples to verify the effectiveness of our method.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16168" title="Abstract">arXiv:2311.16168</a> [<a href="/pdf/2311.16168" title="Download PDF">pdf</a>, <a href="/format/2311.16168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inexpensive High Fidelity Melt Pool Models in Additive Manufacturing  Using Generative Deep Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ogoke%2C+F">Francis Ogoke</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Quanliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ajenifujah%2C+O">Olabode Ajenifujah</a>, 
<a href="/search/cs?searchtype=author&query=Myers%2C+A">Alexander Myers</a>, 
<a href="/search/cs?searchtype=author&query=Quirarte%2C+G">Guadalupe Quirarte</a>, 
<a href="/search/cs?searchtype=author&query=Beuth%2C+J">Jack Beuth</a>, 
<a href="/search/cs?searchtype=author&query=Malen%2C+J">Jonathan Malen</a>, 
<a href="/search/cs?searchtype=author&query=Farimani%2C+A+B">Amir Barati Farimani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Materials Science (cond-mat.mtrl-sci)

</div>
<p class="mathjax">Defects in laser powder bed fusion (L-PBF) parts often result from the
meso-scale dynamics of the molten alloy near the laser, known as the melt pool.
For instance, the melt pool can directly contribute to the formation of
undesirable porosity, residual stress, and surface roughness in the final part.
Experimental in-situ monitoring of the three-dimensional melt pool physical
fields is challenging, due to the short length and time scales involved in the
process. Multi-physics simulation methods can describe the three-dimensional
dynamics of the melt pool, but are computationally expensive at the mesh
refinement required for accurate predictions of complex effects, such as the
formation of keyhole porosity. Therefore, in this work, we develop a generative
deep learning model based on the probabilistic diffusion framework to map
low-fidelity, coarse-grained simulation information to the high-fidelity
counterpart. By doing so, we bypass the computational expense of conducting
multiple high-fidelity simulations for analysis by instead upscaling
lightweight coarse mesh simulations. Specifically, we implement a 2-D diffusion
model to spatially upscale cross-sections of the coarsely simulated melt pool
to their high-fidelity equivalent. We demonstrate the preservation of key
metrics of the melting process between the ground truth simulation data and the
diffusion model output, such as the temperature field, the melt pool dimensions
and the variability of the keyhole vapor cavity. Specifically, we predict the
melt pool depth within 3 $\mu m$ based on low-fidelity input data 4$\times$
coarser than the high-fidelity simulations, reducing analysis time by two
orders of magnitude.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16169" title="Abstract">arXiv:2311.16169</a> [<a href="/pdf/2311.16169" title="Download PDF">pdf</a>, <a href="/format/2311.16169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Effectiveness of Large Language Models in Detecting  Security Vulnerabilities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khare%2C+A">Avishree Khare</a>, 
<a href="/search/cs?searchtype=author&query=Dutta%2C+S">Saikat Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Solko-Breslin%2C+A">Alaia Solko-Breslin</a>, 
<a href="/search/cs?searchtype=author&query=Alur%2C+R">Rajeev Alur</a>, 
<a href="/search/cs?searchtype=author&query=Naik%2C+M">Mayur Naik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Programming Languages (cs.PL); Software Engineering (cs.SE)

</div>
<p class="mathjax">Security vulnerabilities in modern software are prevalent and harmful. While
automated vulnerability detection tools have made promising progress, their
scalability and applicability remain challenging. Recently, Large Language
Models (LLMs), such as GPT-4 and CodeLlama, have demonstrated remarkable
performance on code-related tasks. However, it is unknown whether such LLMs can
do complex reasoning over code. In this work, we explore whether pre-trained
LLMs can detect security vulnerabilities and address the limitations of
existing tools. We evaluate the effectiveness of pre-trained LLMs on a set of
five diverse security benchmarks spanning two languages, Java and C/C++, and
including code samples from synthetic and real-world projects. We evaluate the
effectiveness of LLMs in terms of their performance, explainability, and
robustness.
<br />By designing a series of effective prompting strategies, we obtain the best
results on the synthetic datasets with GPT-4: F1 scores of 0.79 on OWASP, 0.86
on Juliet Java, and 0.89 on Juliet C/C++. Expectedly, the performance of LLMs
drops on the more challenging real-world datasets: CVEFixes Java and CVEFixes
C/C++, with GPT-4 reporting F1 scores of 0.48 and 0.62, respectively. We show
that LLMs can often perform better than existing static analysis and deep
learning-based vulnerability detection tools, especially for certain classes of
vulnerabilities. Moreover, LLMs also often provide reliable explanations,
identifying the vulnerable data flows in code. We find that fine-tuning smaller
LLMs can outperform the larger LLMs on synthetic datasets but provide limited
gains on real-world datasets. When subjected to adversarial attacks on code,
LLMs show mild degradation, with average accuracy reduction of up to 12.67%.
Finally, we share our insights and recommendations for future work on
leveraging LLMs for vulnerability detection.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16171" title="Abstract">arXiv:2311.16171</a> [<a href="/pdf/2311.16171" title="Download PDF">pdf</a>, <a href="/format/2311.16171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Agent Learning of Efficient Fulfilment and Routing Strategies in  E-Commerce
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shelke%2C+O">Omkar Shelke</a>, 
<a href="/search/cs?searchtype=author&query=Pathakota%2C+P">Pranavi Pathakota</a>, 
<a href="/search/cs?searchtype=author&query=Chauhan%2C+A">Anandsingh Chauhan</a>, 
<a href="/search/cs?searchtype=author&query=Khadilkar%2C+H">Harshad Khadilkar</a>, 
<a href="/search/cs?searchtype=author&query=Meisheri%2C+H">Hardik Meisheri</a>, 
<a href="/search/cs?searchtype=author&query=Ravindran%2C+B">Balaraman Ravindran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">This paper presents an integrated algorithmic framework for minimising
product delivery costs in e-commerce (known as the cost-to-serve or C2S). One
of the major challenges in e-commerce is the large volume of spatio-temporally
diverse orders from multiple customers, each of which has to be fulfilled from
one of several warehouses using a fleet of vehicles. This results in two levels
of decision-making: (i) selection of a fulfillment node for each order
(including the option of deferral to a future time), and then (ii) routing of
vehicles (each of which can carry multiple orders originating from the same
warehouse). We propose an approach that combines graph neural networks and
reinforcement learning to train the node selection and vehicle routing agents.
We include real-world constraints such as warehouse inventory capacity, vehicle
characteristics such as travel times, service times, carrying capacity, and
customer constraints including time windows for delivery. The complexity of
this problem arises from the fact that outcomes (rewards) are driven both by
the fulfillment node mapping as well as the routing algorithms, and are
spatio-temporally distributed. Our experiments show that this algorithmic
pipeline outperforms pure heuristic policies.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16172" title="Abstract">arXiv:2311.16172</a> [<a href="/pdf/2311.16172" title="Download PDF">pdf</a>, <a href="/format/2311.16172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evolutionary Machine Learning and Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Togelius%2C+J">Julian Togelius</a>, 
<a href="/search/cs?searchtype=author&query=Khalifa%2C+A">Ahmed Khalifa</a>, 
<a href="/search/cs?searchtype=author&query=Earle%2C+S">Sam Earle</a>, 
<a href="/search/cs?searchtype=author&query=Green%2C+M+C">Michael Cerny Green</a>, 
<a href="/search/cs?searchtype=author&query=Soros%2C+L">Lisa Soros</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 5 figures, part of Evolutionary Machine Learning Book (<a href="https://link.springer.com/book/10.1007/978-981-99-3814-8">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Evolutionary machine learning (EML) has been applied to games in multiple
ways, and for multiple different purposes. Importantly, AI research in games is
not only about playing games; it is also about generating game content,
modeling players, and many other applications. Many of these applications pose
interesting problems for EML. We will structure this chapter on EML for games
based on whether evolution is used to augment machine learning (ML) or ML is
used to augment evolution. For completeness, we also briefly discuss the usage
of ML and evolution separately in games.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16173" title="Abstract">arXiv:2311.16173</a> [<a href="/pdf/2311.16173" title="Download PDF">pdf</a>, <a href="/format/2311.16173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conditions for Length Generalization in Learning Reasoning Skills
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Changnan Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bing Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Reasoning is a fundamental capability of AI agents. Recently, large language
models (LLMs) have shown remarkable abilities to perform reasoning tasks.
However, numerous evaluations of the reasoning capabilities of LLMs have also
showed some limitations. An outstanding limitation is length generalization,
meaning that when trained on reasoning problems of smaller lengths or sizes,
the resulting models struggle with problems of larger sizes or lengths. This
potentially indicates some theoretical limitations of generalization in
learning reasoning skills. These evaluations and their observations motivated
us to perform a theoretical study of the length generalization problem. This
work focused on reasoning tasks that can be formulated as Markov dynamic
processes (MDPs) and/or directed acyclic graphs (DAGs). It identifies and
proves conditions that decide whether the length generalization problem can be
solved or not for a reasoning task in a particular representation. Experiments
are also conducted to verify the theoretical results.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16174" title="Abstract">arXiv:2311.16174</a> [<a href="/pdf/2311.16174" title="Download PDF">pdf</a>, <a href="/format/2311.16174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compact Modeling and Rapid Simulation of Silicon Photonic Micro-Disk and  Ring Modulators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Saxena%2C+V">Vishal Saxena</a>, 
<a href="/search/eess?searchtype=author&query=Shawon%2C+M+J">Md Jubayer Shawon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optics (physics.optics)

</div>
<p class="mathjax">Microdisk or microring modulators (MDMs or MRMs) realize compact
electro-optic modulation in active silicon photonics (SiP) foundry platforms. A
key advantage of these resonant modulators is that they readily implement dense
wavelength division multiplexing (DWDM) in optical interconnects by tuning and
locking the MDMs/MRMs to the DWDM wavelength grid. Compact modeling of static
and transient dynamics of these modulators is important for co-simulation with
CMOS drivers and wavelength stabilization circuits. This work presents the
first compact model for microdisk modulators with a novel approach that uses
experimental measurements and allows rapid and accurate simulation. This
approach employs coupled real-valued differential equations with analytic
signals in Verilog-A, leading to a 7X speed up in transient simulation time
over the current art while enhancing accuracy. Since the model is generalized,
it can also model microring resonators in addition to MDMs. The model also
includes thermo-optic tuning for MDM/MRM with an embedded microheater, which is
essential for simulations involving resonant wavelength stabilization.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16176" title="Abstract">arXiv:2311.16176</a> [<a href="/pdf/2311.16176" title="Download PDF">pdf</a>, <a href="/format/2311.16176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shortcut Bias Mitigation via Ensemble Diversity Using Diffusion  Probabilistic Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scimeca%2C+L">Luca Scimeca</a>, 
<a href="/search/cs?searchtype=author&query=Rubinstein%2C+A">Alexander Rubinstein</a>, 
<a href="/search/cs?searchtype=author&query=Teney%2C+D">Damien Teney</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+S+J">Seong Joon Oh</a>, 
<a href="/search/cs?searchtype=author&query=Nicolicioiu%2C+A+M">Armand Mihai Nicolicioiu</a>, 
<a href="/search/cs?searchtype=author&query=Bengio%2C+Y">Yoshua Bengio</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2310.02230">arXiv:2310.02230</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Spurious correlations in the data, where multiple cues are predictive of the
target labels, often lead to a phenomenon known as simplicity bias, where a
model relies on erroneous, easy-to-learn cues while ignoring reliable ones. In
this work, we propose an ensemble diversification framework exploiting
Diffusion Probabilistic Models (DPMs) for shortcut bias mitigation. We show
that at particular training intervals, DPMs can generate images with novel
feature combinations, even when trained on images displaying correlated input
features. We leverage this crucial property to generate synthetic
counterfactuals to increase model diversity via ensemble disagreement. We show
that DPM-guided diversification is sufficient to remove dependence on primary
shortcut cues, without a need for additional supervised signals. We further
empirically quantify its efficacy on several diversification objectives, and
finally show improved generalization and diversification performance on par
with prior work that relies on auxiliary data collection.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16179" title="Abstract">arXiv:2311.16179</a> [<a href="/pdf/2311.16179" title="Download PDF">pdf</a>, <a href="/format/2311.16179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Next-gen traffic surveillance: AI-assisted mobile traffic violation  detection system
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dede%2C+D">Dila Dede</a>, 
<a href="/search/cs?searchtype=author&query=Sars%C4%B1l%2C+M+A">Mehmet Ali Sars&#x131;l</a>, 
<a href="/search/cs?searchtype=author&query=Shaker%2C+A">Ata Shaker</a>, 
<a href="/search/cs?searchtype=author&query=Alt%C4%B1nta%C5%9F%2C+O">Olgu Alt&#x131;nta&#x15f;</a>, 
<a href="/search/cs?searchtype=author&query=Ergen%2C+O">Onur Ergen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Road traffic accidents pose a significant global public health concern,
leading to injuries, fatalities, and vehicle damage. Approximately 1,3 million
people lose their lives daily due to traffic accidents [World Health
Organization, 2022]. Addressing this issue requires accurate traffic law
violation detection systems to ensure adherence to regulations. The integration
of Artificial Intelligence algorithms, leveraging machine learning and computer
vision, has facilitated the development of precise traffic rule enforcement.
This paper illustrates how computer vision and machine learning enable the
creation of robust algorithms for detecting various traffic violations. Our
model, capable of identifying six common traffic infractions, detects red light
violations, illegal use of breakdown lanes, violations of vehicle following
distance, breaches of marked crosswalk laws, illegal parking, and parking on
marked crosswalks. Utilizing online traffic footage and a self-mounted on-dash
camera, we apply the YOLOv5 algorithm's detection module to identify traffic
agents such as cars, pedestrians, and traffic signs, and the strongSORT
algorithm for continuous interframe tracking. Six discrete algorithms analyze
agents' behavior and trajectory to detect violations. Subsequently, an
Identification Module extracts vehicle ID information, such as the license
plate, to generate violation notices sent to relevant authorities.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16180" title="Abstract">arXiv:2311.16180</a> [<a href="/pdf/2311.16180" title="Download PDF">pdf</a>, <a href="/ps/2311.16180" title="Download PostScript">ps</a>, <a href="/format/2311.16180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aiming to Minimize Alcohol-Impaired Road Fatalities: Utilizing  Fairness-Aware and Domain Knowledge-Infused Artificial Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Venkateswaran%2C+T">Tejas Venkateswaran</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+S+R">Sheikh Rabiul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Hasan%2C+M+G+M+M">Md Golam Moula Mehedi Hasan</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+M">Mohiuddin Ahmed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Big Data 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">Approximately 30% of all traffic fatalities in the United States are
attributed to alcohol-impaired driving. This means that, despite stringent laws
against this offense in every state, the frequency of drunk driving accidents
is alarming, resulting in approximately one person being killed every 45
minutes. The process of charging individuals with Driving Under the Influence
(DUI) is intricate and can sometimes be subjective, involving multiple stages
such as observing the vehicle in motion, interacting with the driver, and
conducting Standardized Field Sobriety Tests (SFSTs). Biases have been observed
through racial profiling, leading to some groups and geographical areas facing
fewer DUI tests, resulting in many actual DUI incidents going undetected,
ultimately leading to a higher number of fatalities. To tackle this issue, our
research introduces an Artificial Intelligence-based predictor that is both
fairness-aware and incorporates domain knowledge to analyze DUI-related
fatalities in different geographic locations. Through this model, we gain
intriguing insights into the interplay between various demographic groups,
including age, race, and income. By utilizing the provided information to
allocate policing resources in a more equitable and efficient manner, there is
potential to reduce DUI-related fatalities and have a significant impact on
road safety.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16185" title="Abstract">arXiv:2311.16185</a> [<a href="/pdf/2311.16185" title="Download PDF">pdf</a>, <a href="/format/2311.16185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Sentiment Analysis Results through Outlier Detection  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuetian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+M">Mei Si</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">When dealing with text data containing subjective labels like speaker
emotions, inaccuracies or discrepancies among labelers are not uncommon. Such
discrepancies can significantly affect the performance of machine learning
algorithms. This study investigates the potential of identifying and addressing
outliers in text data with subjective labels, aiming to enhance classification
outcomes. We utilized the Deep SVDD algorithm, a one-class classification
method, to detect outliers in nine text-based emotion and sentiment analysis
datasets. By employing both a small-sized language model (DistilBERT base model
with 66 million parameters) and non-deep learning machine learning algorithms
(decision tree, KNN, Logistic Regression, and LDA) as the classifier, our
findings suggest that the removal of outliers can lead to enhanced results in
most cases. Additionally, as outliers in such datasets are not necessarily
unlearnable, we experienced utilizing a large language model -- DeBERTa v3
large with 131 million parameters, which can capture very complex patterns in
data. We continued to observe performance enhancements across multiple
datasets.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16187" title="Abstract">arXiv:2311.16187</a> [<a href="/pdf/2311.16187" title="Download PDF">pdf</a>, <a href="/format/2311.16187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modelling wildland fire burn severity in California using a spatial  Super Learner approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Simafranca%2C+N">Nicholas Simafranca</a>, 
<a href="/search/cs?searchtype=author&query=Willoughby%2C+B">Bryant Willoughby</a>, 
<a href="/search/cs?searchtype=author&query=O%27Neil%2C+E">Erin O&#x27;Neil</a>, 
<a href="/search/cs?searchtype=author&query=Farr%2C+S">Sophie Farr</a>, 
<a href="/search/cs?searchtype=author&query=Reich%2C+B+J">Brian J Reich</a>, 
<a href="/search/cs?searchtype=author&query=Giertych%2C+N">Naomi Giertych</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+M">Margaret Johnson</a>, 
<a href="/search/cs?searchtype=author&query=Pascolini-Campbell%2C+M">Madeleine Pascolini-Campbell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP)

</div>
<p class="mathjax">Given the increasing prevalence of wildland fires in the Western US, there is
a critical need to develop tools to understand and accurately predict burn
severity. We develop a machine learning model to predict post-fire burn
severity using pre-fire remotely sensed data. Hydrological, ecological, and
topographical variables collected from four regions of California - the sites
of the Kincade fire (2019), the CZU Lightning Complex fire (2020), the Windy
fire (2021), and the KNP Fire (2021) - are used as predictors of the difference
normalized burn ratio. We hypothesize that a Super Learner (SL) algorithm that
accounts for spatial autocorrelation using Vecchia's Gaussian approximation
will accurately model burn severity. In all combinations of test and training
sets explored, the results of our model showed the SL algorithm outperformed
standard Linear Regression methods. After fitting and verifying the performance
of the SL model, we use interpretable machine learning tools to determine the
main drivers of severe burn damage, including greenness, elevation and fire
weather variables. These findings provide actionable insights that enable
communities to strategize interventions, such as early fire detection systems,
pre-fire season vegetation clearing activities, and resource allocation during
emergency responses. When implemented, this model has the potential to minimize
the loss of human life, property, resources, and ecosystems in California.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16191" title="Abstract">arXiv:2311.16191</a> [<a href="/pdf/2311.16191" title="Download PDF">pdf</a>, <a href="/format/2311.16191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MACE: A Multi-pattern Accommodated and Efficient Anomaly Detection  Method in the Frequency Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Feiyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=zhang%2C+Y">Yingying zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhen Qin</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lunting Fan</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+R">Renhe Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yuxuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Q">Qingsong Wen</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+S">Shuiguang Deng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Anomaly detection significantly enhances the robustness of cloud systems.
While neural network-based methods have recently demonstrated strong
advantages, they encounter practical challenges in cloud environments: the
contradiction between the impracticality of maintaining a unique model for each
service and the limited ability of dealing with diverse normal patterns by a
unified model, as well as issues with handling heavy traffic in real time and
short-term anomaly detection sensitivity. Thus, we propose MACE, a
Multi-pattern Accommodated and efficient Anomaly detection method in the
frequency domain for time series anomaly detection. There are three novel
characteristics of it: (i) a pattern extraction mechanism excelling at handling
diverse normal patterns, which enables the model to identify anomalies by
examining the correlation between the data sample and its service normal
pattern, instead of solely focusing on the data sample itself; (ii) a dualistic
convolution mechanism that amplifies short-term anomalies in the time domain
and hinders the reconstruction of anomalies in the frequency domain, which
enlarges the reconstruction error disparity between anomaly and normality and
facilitates anomaly detection; (iii) leveraging the sparsity and parallelism of
frequency domain to enhance model efficiency. We theoretically and
experimentally prove that using a strategically selected subset of Fourier
bases can not only reduce computational overhead but is also profit to
distinguish anomalies, compared to using the complete spectrum. Moreover,
extensive experiments demonstrate MACE's effectiveness in handling diverse
normal patterns with a unified model and it achieves state-of-the-art
performance with high efficiency. \end{abstract}
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16192" title="Abstract">arXiv:2311.16192</a> [<a href="/pdf/2311.16192" title="Download PDF">pdf</a>, <a href="/format/2311.16192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Utilizing Multiple Inputs Autoregressive Models for Bearing Remaining  Useful Life Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junliang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qinghua Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+G">Guanhua Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+G">Guoxi Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Accurate prediction of the Remaining Useful Life (RUL) of rolling bearings is
crucial in industrial production, yet existing models often struggle with
limited generalization capabilities due to their inability to fully process all
vibration signal patterns. We introduce a novel multi-input autoregressive
model to address this challenge in RUL prediction for bearings. Our approach
uniquely integrates vibration signals with previously predicted Health
Indicator (HI) values, employing feature fusion to output current window HI
values. Through autoregressive iterations, the model attains a global receptive
field, effectively overcoming the limitations in generalization. Furthermore,
we innovatively incorporate a segmentation method and multiple training
iterations to mitigate error accumulation in autoregressive models. Empirical
evaluation on the PMH2012 dataset demonstrates that our model, compared to
other backbone networks using similar autoregressive approaches, achieves
significantly lower Root Mean Square Error (RMSE) and Score. Notably, it
outperforms traditional autoregressive models that use label values as inputs
and non-autoregressive networks, showing superior generalization abilities with
a marked lead in RMSE and Score metrics.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16193" title="Abstract">arXiv:2311.16193</a> [<a href="/pdf/2311.16193" title="Download PDF">pdf</a>, <a href="/format/2311.16193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Students&#x27; interest in knowledge acquisition in Artificial Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Petrescu%2C+M">Manuela-Andreea Petrescu</a>, 
<a href="/search/cs?searchtype=author&query=Pop%2C+E">Emilia-Loredana Pop</a>, 
<a href="/search/cs?searchtype=author&query=Mihoc%2C+T">Tudor-Dan Mihoc</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 27th International Conference on Knowledge-Based and Intelligent
  Information &amp; Engineering Systems (KES 2023), Procedia Computer Science 225C,
  ISSN 1877-0509, 1027-1035, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Software Engineering (cs.SE)

</div>
<p class="mathjax">Some students' expectations and points of view related to the Artificial
Intelligence course are explored and analyzed in this study. We anonymous
collected answers from 58 undergraduate students out of 200 enrolled in the
Computer Science specialization. The answers were analysed and interpreted
using thematic analysis to find out their interests and attractive and
unattractive aspects related to the Artificial Intelligence study topic. We
concluded that students are interested in Artificial Intelligence due to its
trendiness, applicability, their passion and interest in the subject, the
potential for future growth, and high salaries. However, the students'
expectations were mainly related to achieving medium knowledge in the
Artificial Intelligence field, and men seem to be more interested in acquiring
high-level skills than women. The most common part that wasn't enjoyed by the
students was the mathematical aspect used in Artificial Intelligence. Some of
them (a small group) were also aware of the Artificial Intelligence potential
which could be used in an unethical manner for negative purposes. Our study
also provides a short comparison to the Databases course, in which students
were not that passionate or interested in achieving medium knowledge, their
interest was related to DB usage and basic information.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16194" title="Abstract">arXiv:2311.16194</a> [<a href="/pdf/2311.16194" title="Download PDF">pdf</a>, <a href="/format/2311.16194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BadCLIP: Trigger-Aware Prompt Learning for Backdoor Attacks on CLIP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jiawang Bai</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+K">Kuofeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+S">Shaobo Min</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Shu-Tao Xia</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhifeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Contrastive Vision-Language Pre-training, known as CLIP, has shown promising
effectiveness in addressing downstream image recognition tasks. However, recent
works revealed that the CLIP model can be implanted with a downstream-oriented
backdoor. On downstream tasks, one victim model performs well on clean samples
but predicts a specific target class whenever a specific trigger is present.
For injecting a backdoor, existing attacks depend on a large amount of
additional data to maliciously fine-tune the entire pre-trained CLIP model,
which makes them inapplicable to data-limited scenarios. In this work,
motivated by the recent success of learnable prompts, we address this problem
by injecting a backdoor into the CLIP model in the prompt learning stage. Our
method named BadCLIP is built on a novel and effective mechanism in backdoor
attacks on CLIP, i.e., influencing both the image and text encoders with the
trigger. It consists of a learnable trigger applied to images and a
trigger-aware context generator, such that the trigger can change text features
via trigger-aware prompts, resulting in a powerful and generalizable attack.
Extensive experiments conducted on 11 datasets verify that the clean accuracy
of BadCLIP is similar to those of advanced prompt learning methods and the
attack success rate is higher than 99% in most cases. BadCLIP is also
generalizable to unseen classes, and shows a strong generalization capability
under cross-dataset and cross-domain settings.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16195" title="Abstract">arXiv:2311.16195</a> [<a href="/pdf/2311.16195" title="Download PDF">pdf</a>, <a href="/format/2311.16195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Foundational Framework and Methodology for Personalized Early and  Timely Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schubert%2C+T">Tim Schubert</a>, 
<a href="/search/cs?searchtype=author&query=Peck%2C+R+W">Richard W Peck</a>, 
<a href="/search/cs?searchtype=author&query=Gimson%2C+A">Alexander Gimson</a>, 
<a href="/search/cs?searchtype=author&query=Davtyan%2C+C">Camelia Davtyan</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Schaar%2C+M">Mihaela van der Schaar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Early diagnosis of diseases holds the potential for deep transformation in
healthcare by enabling better treatment options, improving long-term survival
and quality of life, and reducing overall cost. With the advent of medical big
data, advances in diagnostic tests as well as in machine learning and
statistics, early or timely diagnosis seems within reach. Early diagnosis
research often neglects the potential for optimizing individual diagnostic
paths. To enable personalized early diagnosis, a foundational framework is
needed that delineates the diagnosis process and systematically identifies the
time-dependent value of various diagnostic tests for an individual patient
given their unique characteristics. Here, we propose the first foundational
framework for early and timely diagnosis. It builds on decision-theoretic
approaches to outline the diagnosis process and integrates machine learning and
statistical methodology for estimating the optimal personalized diagnostic
path. To describe the proposed framework as well as possibly other frameworks,
we provide essential definitions.
<br />The development of a foundational framework is necessary for several reasons:
1) formalism provides clarity for the development of decision support tools; 2)
observed information can be complemented with estimates of the future patient
trajectory; 3) the net benefit of counterfactual diagnostic paths and
associated uncertainties can be modeled for individuals 4) 'early' and 'timely'
diagnosis can be clearly defined; 5) a mechanism emerges for assessing the
value of technologies in terms of their impact on personalized early diagnosis,
resulting health outcomes and incurred costs.
<br />Finally, we hope that this foundational framework will unlock the
long-awaited potential of timely diagnosis and intervention, leading to
improved outcomes for patients and higher cost-effectiveness for healthcare
systems.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16196" title="Abstract">arXiv:2311.16196</a> [<a href="/pdf/2311.16196" title="Download PDF">pdf</a>, <a href="/format/2311.16196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variational Exploration Module VEM: A Cloud-Native Optimization and  Validation Tool for Geospatial Modeling and AI Workflows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuehnert%2C+J">Julian Kuehnert</a> (1), 
<a href="/search/cs?searchtype=author&query=Tadesse%2C+H">Hiwot Tadesse</a> (1), 
<a href="/search/cs?searchtype=author&query=Dearden%2C+C">Chris Dearden</a> (2), 
<a href="/search/cs?searchtype=author&query=Lickorish%2C+R">Rosie Lickorish</a> (3), 
<a href="/search/cs?searchtype=author&query=Fraccaro%2C+P">Paolo Fraccaro</a> (3), 
<a href="/search/cs?searchtype=author&query=Jones%2C+A">Anne Jones</a> (3), 
<a href="/search/cs?searchtype=author&query=Edwards%2C+B">Blair Edwards</a> (3), 
<a href="/search/cs?searchtype=author&query=Remy%2C+S+L">Sekou L. Remy</a> (1), 
<a href="/search/cs?searchtype=author&query=Melling%2C+P">Peter Melling</a> (4), 
<a href="/search/cs?searchtype=author&query=Culmer%2C+T">Tim Culmer</a> (4) ((1) IBM Research, Nairobi, Kenya, (2) STFC Hartree Centre, Warrington, UK, (3) IBM Research, Daresbury, UK, (4) Riskaware Ltd., Bristol, UK)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IAAI 2024: Deployed Innovative Tools for Enabling AI Applications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Geospatial observations combined with computational models have become key to
understanding the physical systems of our environment and enable the design of
best practices to reduce societal harm. Cloud-based deployments help to scale
up these modeling and AI workflows. Yet, for practitioners to make robust
conclusions, model tuning and testing is crucial, a resource intensive process
which involves the variation of model input variables. We have developed the
Variational Exploration Module which facilitates the optimization and
validation of modeling workflows deployed in the cloud by orchestrating
workflow executions and using Bayesian and machine learning-based methods to
analyze model behavior. User configurations allow the combination of diverse
sampling strategies in multi-agent environments. The flexibility and robustness
of the model-agnostic module is demonstrated using real-world applications.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16198" title="Abstract">arXiv:2311.16198</a> [<a href="/pdf/2311.16198" title="Download PDF">pdf</a>, <a href="/ps/2311.16198" title="Download PostScript">ps</a>, <a href="/format/2311.16198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ultra-short-term multi-step wind speed prediction for wind farms based  on adaptive noise reduction technology and temporal convolutional network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haojian Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">As an important clean and renewable kind of energy, wind power plays an
important role in coping with energy crisis and environmental pollution.
However, the volatility and intermittency of wind speed restrict the
development of wind power. To improve the utilization of wind power, this study
proposes a new wind speed prediction model based on data noise reduction
technology, temporal convolutional network (TCN), and gated recurrent unit
(GRU). Firstly, an adaptive data noise reduction algorithm P-SSA is proposed
based on singular spectrum analysis (SSA) and Pearson correlation coefficient.
The original wind speed is decomposed into multiple subsequences by SSA and
then reconstructed. When the Pearson correlation coefficient between the
reconstructed sequence and the original sequence is greater than 0.99, other
noise subsequences are deleted to complete the data denoising. Then, the
receptive field of the samples is expanded through the causal convolution and
dilated convolution of TCN, and the characteristics of wind speed change are
extracted. Then, the time feature information of the sequence is extracted by
GRU, and then the wind speed is predicted to form the wind speed sequence
prediction model of P-SSA-TCN-GRU. The proposed model was validated on three
wind farms in Shandong Province. The experimental results show that the
prediction performance of the proposed model is better than that of the
traditional model and other models based on TCN, and the wind speed prediction
of wind farms with high precision and strong stability is realized. The wind
speed predictions of this model have the potential to become the data that
support the operation and management of wind farms. The code is available at
link.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16199" title="Abstract">arXiv:2311.16199</a> [<a href="/pdf/2311.16199" title="Download PDF">pdf</a>, <a href="/format/2311.16199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symphony: Symmetry-Equivariant Point-Centered Spherical Harmonics for  Molecule Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Daigavane%2C+A">Ameya Daigavane</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Song Kim</a>, 
<a href="/search/cs?searchtype=author&query=Geiger%2C+M">Mario Geiger</a>, 
<a href="/search/cs?searchtype=author&query=Smidt%2C+T">Tess Smidt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Biomolecules (q-bio.BM)

</div>
<p class="mathjax">We present Symphony, an $E(3)$-equivariant autoregressive generative model
for 3D molecular geometries that iteratively builds a molecule from molecular
fragments. Existing autoregressive models such as G-SchNet and G-SphereNet for
molecules utilize rotationally invariant features to respect the 3D symmetries
of molecules. In contrast, Symphony uses message-passing with higher-degree
$E(3)$-equivariant features. This allows a novel representation of probability
distributions via spherical harmonic signals to efficiently model the 3D
geometry of molecules. We show that Symphony is able to accurately generate
small molecules from the QM9 dataset, outperforming existing autoregressive
models and approaching the performance of diffusion models.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16201" title="Abstract">arXiv:2311.16201</a> [<a href="/pdf/2311.16201" title="Download PDF">pdf</a>, <a href="/format/2311.16201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-trained Language Models Do Not Help Auto-regressive Text-to-Image  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuhui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=McKinzie%2C+B">Brandon McKinzie</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+Z">Zhe Gan</a>, 
<a href="/search/cs?searchtype=author&query=Shankar%2C+V">Vaishaal Shankar</a>, 
<a href="/search/cs?searchtype=author&query=Toshev%2C+A">Alexander Toshev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advances in image tokenizers, such as VQ-VAE, have enabled
text-to-image generation using auto-regressive methods, similar to language
modeling. However, these methods have yet to leverage pre-trained language
models, despite their adaptability to various downstream tasks. In this work,
we explore this gap by adapting a pre-trained language model for
auto-regressive text-to-image generation, and find that pre-trained language
models offer limited help. We provide a two-fold explanation by analyzing
tokens from each modality. First, we demonstrate that image tokens possess
significantly different semantics compared to text tokens, rendering
pre-trained language models no more effective in modeling them than randomly
initialized ones. Second, the text tokens in the image-text datasets are too
simple compared to normal language model pre-training data, which causes the
catastrophic degradation of language models' capability.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16203" title="Abstract">arXiv:2311.16203</a> [<a href="/pdf/2311.16203" title="Download PDF">pdf</a>, <a href="/format/2311.16203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatTraffc: Text-to-Traffic Generation via Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chengyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Q">Qitan Shao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+Y">Yisheng Lv</a>, 
<a href="/search/cs?searchtype=author&query=Piao%2C+X">Xinglin Piao</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+B">Baocai Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Traffic prediction is one of the most significant foundations in Intelligent
Transportation Systems (ITS). Traditional traffic prediction methods rely only
on historical traffic data to predict traffic trends and face two main
challenges. 1) insensitivity to unusual events. 2) poor performance in
long-term prediction. In this work, we explore how generative models combined
with text describing the traffic system can be applied for traffic generation
and name the task Text-to-Traffic Generation (TTG). The key challenge of the
TTG task is how to associate text with the spatial structure of the road
network and traffic data for generating traffic situations. To this end, we
propose ChatTraffic, the first diffusion model for text-to-traffic generation.
To guarantee the consistency between synthetic and real data, we augment a
diffusion model with the Graph Convolutional Network (GCN) to extract spatial
correlations of traffic data. In addition, we construct a large dataset
containing text-traffic pairs for the TTG task. We benchmarked our model
qualitatively and quantitatively on the released dataset. The experimental
results indicate that ChatTraffic can generate realistic traffic situations
from the text. Our code and dataset are available at
https://github.com/ChyaZhang/ChatTraffic.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16206" title="Abstract">arXiv:2311.16206</a> [<a href="/pdf/2311.16206" title="Download PDF">pdf</a>, <a href="/format/2311.16206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Instruction Tuning for Large Multimodal Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jinghan He</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Haiyun Guo</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+M">Ming Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinqiao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Instruction tuning is now a widely adopted approach to aligning large
multimodal models (LMMs) to follow human intent. It unifies the data format of
vision-language tasks, enabling multi-task joint training. However,
vision-language tasks are constantly being created in practice. Instead of
always re-training LMMs when new tasks arrive, continual learning offers
flexibility for models to continually and efficiently exploit the evolving
data. This work aims to explore the following two questions: 1) Do LMMs still
suffer from catastrophic forgetting in continual instruction tuning? 2) Are the
existing three classes of continual learning methods still applicable to the
continual instruction tuning of LMMs? An extensive study is conducted to
address the above questions. First, we establish the first benchmark in this
setting and reveal that catastrophic forgetting is still observed when
continually instruction-tuning LMMs. However, the multi-task joint instruction
tuning can facilitate the model's continual learning ability and mitigate
forgetting. Second, we integrate and adapt classic continual learning methods
to our context, demonstrating the efficacy of data replay and model expansion
strategies across diverse scenarios. In contrast, regularization-based methods
only perform well on models that have been jointly instruction-tuned on
multiple tasks. Third, we delve into the correlation and forgetting dynamics
between vision-language task pairs and propose task-similarity-informed
regularization and model expansion methods for continual instruction tuning of
LMMs. Experimental results show that our approach consistently boosts the
model's performance.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16241" title="Abstract">arXiv:2311.16241</a> [<a href="/pdf/2311.16241" title="Download PDF">pdf</a>, <a href="/format/2311.16241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SemiVL: Semi-Supervised Semantic Segmentation with Vision-Language  Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoyer%2C+L">Lukas Hoyer</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+D+J">David Joseph Tan</a>, 
<a href="/search/cs?searchtype=author&query=Naeem%2C+M+F">Muhammad Ferjad Naeem</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>, 
<a href="/search/cs?searchtype=author&query=Tombari%2C+F">Federico Tombari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In semi-supervised semantic segmentation, a model is trained with a limited
number of labeled images along with a large corpus of unlabeled images to
reduce the high annotation effort. While previous methods are able to learn
good segmentation boundaries, they are prone to confuse classes with similar
visual appearance due to the limited supervision. On the other hand,
vision-language models (VLMs) are able to learn diverse semantic knowledge from
image-caption datasets but produce noisy segmentation due to the image-level
training. In SemiVL, we propose to integrate rich priors from VLM pre-training
into semi-supervised semantic segmentation to learn better semantic decision
boundaries. To adapt the VLM from global to local reasoning, we introduce a
spatial fine-tuning strategy for label-efficient learning. Further, we design a
language-guided decoder to jointly reason over vision and language. Finally, we
propose to handle inherent ambiguities in class labels by providing the model
with language guidance in the form of class definitions. We evaluate SemiVL on
4 semantic segmentation datasets, where it significantly outperforms previous
semi-supervised methods. For instance, SemiVL improves the state-of-the-art by
+13.5 mIoU on COCO with 232 annotated images and by +6.1 mIoU on Pascal VOC
with 92 labels. Project page: https://github.com/google-research/semivl
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16254" title="Abstract">arXiv:2311.16254</a> [<a href="/pdf/2311.16254" title="Download PDF">pdf</a>, <a href="/format/2311.16254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Removing NSFW Concepts from Vision-and-Language Models for Text-to-Image  Retrieval and Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Poppi%2C+S">Samuele Poppi</a>, 
<a href="/search/cs?searchtype=author&query=Poppi%2C+T">Tobia Poppi</a>, 
<a href="/search/cs?searchtype=author&query=Cocchi%2C+F">Federico Cocchi</a>, 
<a href="/search/cs?searchtype=author&query=Cornia%2C+M">Marcella Cornia</a>, 
<a href="/search/cs?searchtype=author&query=Baraldi%2C+L">Lorenzo Baraldi</a>, 
<a href="/search/cs?searchtype=author&query=Cucchiara%2C+R">Rita Cucchiara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multimedia (cs.MM)

</div>
<p class="mathjax">Vision-and-Language models such as CLIP have demonstrated remarkable
effectiveness across a wide range of tasks. However, these models are typically
trained on web-scale data, which can introduce inappropriate content and lead
to the development of unsafe and biased behavior. This, in turn, hampers their
applicability in sensitive and trustworthy contexts and could raise significant
concern in their adoption. To overcome these limitations, we introduce a
methodology to make Vision-and-Language models safer by removing their
sensitivity to not-safe-for-work concepts. We show how this can be done by
distilling from a large language model which converts between safe and unsafe
sentences and which is fine-tuned starting from just 100 manually-curated
pairs. We conduct extensive experiments on the resulting embedding space for
both retrieval and text-to-image generation, where we show that our model can
also be properly employed with pre-trained image generators. Our source code
and trained models are available at: https://github.com/aimagelab/safe-clip.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16256" title="Abstract">arXiv:2311.16256</a> [<a href="/pdf/2311.16256" title="Download PDF">pdf</a>, <a href="/format/2311.16256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the stability of $&#x3b8;$-methods for DDEs and PDDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Rodr%C3%ADguez-Fern%C3%A1ndez%2C+A">Alejandro Rodr&#xed;guez-Fern&#xe1;ndez</a>, 
<a href="/search/math?searchtype=author&query=Mart%C3%ADn-Vaquero%2C+J">Jes&#xfa;s Mart&#xed;n-Vaquero</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 21st IMACS World Congress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, the stability of $\theta$-methods for delay differential
equations is studied based on the test equation $y'(t)=-A y(t) + B y(t-\tau)$,
where $\tau$ is a constant delay and $A$ is a positive definite matrix. It is
mainly considered the case where the matrices $A$ and $B$ are not simultaneosly
diagonalizable and the concept of field of values is used to prove a sufficient
condition for unconditional stability of these methods and another condition
which also guarantees their stability, but according to the step size. The
results obtained are also simplified for the case where the matrices $A$ and
$B$ are simultaneously diagonalizable and compared with other similar works for
the general case. Several numerical examples in which the theory discussed here
is applied to parabolic problems given by partial delay differential equations
with a diffusion term and a delayed term are presented, too.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16258" title="Abstract">arXiv:2311.16258</a> [<a href="/pdf/2311.16258" title="Download PDF">pdf</a>, <a href="/format/2311.16258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Exploration of Left-Corner Transformations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Opedal%2C+A">Andreas Opedal</a>, 
<a href="/search/cs?searchtype=author&query=Tsipidi%2C+E">Eleftheria Tsipidi</a>, 
<a href="/search/cs?searchtype=author&query=Pimentel%2C+T">Tiago Pimentel</a>, 
<a href="/search/cs?searchtype=author&query=Cotterell%2C+R">Ryan Cotterell</a>, 
<a href="/search/cs?searchtype=author&query=Vieira%2C+T">Tim Vieira</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Main conference long paper at EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Data Structures and Algorithms (cs.DS); Formal Languages and Automata Theory (cs.FL)

</div>
<p class="mathjax">The left-corner transformation (Rosenkrantz and Lewis, 1970) is used to
remove left recursion from context-free grammars, which is an important step
towards making the grammar parsable top-down with simple techniques. This paper
generalizes prior left-corner transformations to support semiring-weighted
production rules and to provide finer-grained control over which left corners
may be moved. Our generalized left-corner transformation (GLCT) arose from
unifying the left-corner transformation and speculation transformation (Eisner
and Blatz, 2007), originally for logic programming. Our new transformation and
speculation define equivalent weighted languages. Yet, their derivation trees
are structurally different in an important way: GLCT replaces left recursion
with right recursion, and speculation does not. We also provide several
technical results regarding the formal relationships between the outputs of
GLCT, speculation, and the original grammar. Lastly, we empirically investigate
the efficiency of GLCT for left-recursion elimination from grammars of nine
languages.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16261" title="Abstract">arXiv:2311.16261</a> [<a href="/pdf/2311.16261" title="Download PDF">pdf</a>, <a href="/format/2311.16261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RelVAE: Generative Pretraining for few-shot Visual Relationship  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karapiperis%2C+S">Sotiris Karapiperis</a>, 
<a href="/search/cs?searchtype=author&query=Diomataris%2C+M">Markos Diomataris</a>, 
<a href="/search/cs?searchtype=author&query=Pitsikalis%2C+V">Vassilis Pitsikalis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Visual relations are complex, multimodal concepts that play an important role
in the way humans perceive the world. As a result of their complexity,
high-quality, diverse and large scale datasets for visual relations are still
absent. In an attempt to overcome this data barrier, we choose to focus on the
problem of few-shot Visual Relationship Detection (VRD), a setting that has
been so far neglected by the community. In this work we present the first
pretraining method for few-shot predicate classification that does not require
any annotated relations. We achieve this by introducing a generative model that
is able to capture the variation of semantic, visual and spatial information of
relations inside a latent space and later exploiting its representations in
order to achieve efficient few-shot classification. We construct few-shot
training splits and show quantitative experiments on VG200 and VRD datasets
where our model outperforms the baselines. Lastly we attempt to interpret the
decisions of the model by conducting various qualitative experiments.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16263" title="Abstract">arXiv:2311.16263</a> [<a href="/pdf/2311.16263" title="Download PDF">pdf</a>, <a href="/format/2311.16263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MinIndy: Uma Ferramenta de In&#xed;cio R&#xe1;pido do Hyperledger Indy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Veloso%2C+A">Alan Veloso</a>, 
<a href="/search/cs?searchtype=author&query=Sousa%2C+J">Jeffson Sousa</a>, 
<a href="/search/cs?searchtype=author&query=Evaristo%2C+B">Bruno Evaristo</a>, 
<a href="/search/cs?searchtype=author&query=Abel%C3%A9m%2C+A">Ant&#xf4;nio Abel&#xe9;m</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> XIII Workshop de Gest\~ao de Identidades Digitais (WGID), in Portuguese language
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The Hyperledger Indy blockchain platform, aimed at identity management
networks, has gained importance, but instantiating a complete network is
complex and requires experience. Therefore, the present work describes MinIndy,
a tool designed to simplify the installation and configuration of Hyperledger
Indy networks. This simplification will allow people with a lower level of
expertise to create their Indy networks. Which makes it a viable alternative
for organizations looking to adopt Hyperledger Indy Blockchain networks with
less effort.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16267" title="Abstract">arXiv:2311.16267</a> [<a href="/pdf/2311.16267" title="Download PDF">pdf</a>, <a href="/format/2311.16267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applications of Large Language Models in Data Processing: Innovative  Approaches to Segmenting and Renewing Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yu-Chen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Akhilesh Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wen-Liang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+N">Norman Chang</a>, 
<a href="/search/cs?searchtype=author&query=Zakir%2C+M">Muhammad Zakir</a>, 
<a href="/search/cs?searchtype=author&query=Apte%2C+R">Rucha Apte</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+J+R">Jyh-Shing Roger Jang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Our paper investigates effective methods for code generation in
"specific-domain" applications, including the use of Large Language Models
(LLMs) for data segmentation and renewal, as well as stimulating deeper
thinking in LLMs through prompt adjustments. Using a real company product as an
example, we provide user manuals, API documentation, and other data. The ideas
discussed in this paper help segment and then convert this data into semantic
vectors to better reflect their true positioning. Subsequently, user
requirements are transformed into vectors to retrieve the most relevant
content, achieving about 70% accuracy in simple to medium-complexity tasks
through various prompt techniques. This paper is the first to enhance
specific-domain code generation effectiveness from this perspective.
Additionally, we experiment with generating more scripts from a limited number
using llama2-based fine-tuning to test its effectiveness in professional domain
code generation. This is a challenging and promising field, and once achieved,
it will not only lead to breakthroughs in LLM development across multiple
industries but also enable LLMs to understand and learn any new knowledge
effectively.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16272" title="Abstract">arXiv:2311.16272</a> [<a href="/pdf/2311.16272" title="Download PDF">pdf</a>, <a href="/format/2311.16272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Observer Design Using Reinforcement Learning and Quadratic  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Asri%2C+S">Soroush Asri</a>, 
<a href="/search/eess?searchtype=author&query=Rodrigues%2C+L">Luis Rodrigues</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper introduces an innovative approach based on policy iteration (PI),
a reinforcement learning (RL) algorithm, to obtain an optimal observer with a
quadratic cost function. This observer is designed for systems with a given
linearized model and a stabilizing Luenberger observer gain. We utilize
two-layer quadratic neural networks (QNN) for policy evaluation and derive a
linear correction term using the input and output data. This correction term
effectively rectifies inaccuracies introduced by the linearized model employed
within the observer design. A unique feature of the proposed methodology is
that the QNN is trained through convex optimization. The main advantage is that
the QNN's input-output mapping has an analytical expression as a quadratic
form, which can then be used to obtain a linear correction term policy. This is
in stark contrast to the available techniques in the literature that must train
a second neural network to obtain policy improvement. It is proven that the
obtained linear correction term is optimal for linear systems, as both the
value function and the QNN's input-output mapping are quadratic. The proposed
method is applied to a simple pendulum, demonstrating an enhanced correction
term policy compared to relying solely on the linearized model. This shows its
promise for addressing nonlinear systems.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16276" title="Abstract">arXiv:2311.16276</a> [<a href="/pdf/2311.16276" title="Download PDF">pdf</a>, <a href="/ps/2311.16276" title="Download PostScript">ps</a>, <a href="/format/2311.16276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Darknet Traffic Analysis A Systematic Literature Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saleem%2C+J">Javeriah Saleem</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+R">Rafiqul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+Z">Zahidul Islam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 Pages, 13 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The primary objective of an anonymity tool is to protect the anonymity of its
users through the implementation of strong encryption and obfuscation
techniques. As a result, it becomes very difficult to monitor and identify
users activities on these networks. Moreover, such systems have strong
defensive mechanisms to protect users against potential risks, including the
extraction of traffic characteristics and website fingerprinting. However, the
strong anonymity feature also functions as a refuge for those involved in
illicit activities who aim to avoid being traced on the network. As a result, a
substantial body of research has been undertaken to examine and classify
encrypted traffic using machine learning techniques. This paper presents a
comprehensive examination of the existing approaches utilized for the
categorization of anonymous traffic as well as encrypted network traffic inside
the darknet. Also, this paper presents a comprehensive analysis of methods of
darknet traffic using machine learning techniques to monitor and identify the
traffic attacks inside the darknet.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16277" title="Abstract">arXiv:2311.16277</a> [<a href="/pdf/2311.16277" title="Download PDF">pdf</a>, <a href="/format/2311.16277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Graph Neural Network-Based QUBO-Formulated Hamiltonian-Inspired Loss  Function for Combinatorial Optimization using Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rizvee%2C+R+A">Redwan Ahmed Rizvee</a>, 
<a href="/search/cs?searchtype=author&query=Hasan%2C+R">Raheeb Hasan</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+M+M">Md. Mosaddek Khan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Quadratic Unconstrained Binary Optimization (QUBO) is a generic technique to
model various NP-hard Combinatorial Optimization problems (CO) in the form of
binary variables. Ising Hamiltonian is used to model the energy function of a
system. QUBO to Ising Hamiltonian is regarded as a technique to solve various
canonical optimization problems through quantum optimization algorithms.
Recently, PI-GNN, a generic framework, has been proposed to address CO problems
over graphs based on Graph Neural Network (GNN) architecture. They introduced a
generic QUBO-formulated Hamiltonian-inspired loss function that was directly
optimized using GNN. PI-GNN is highly scalable but there lies a noticeable
decrease in the number of satisfied constraints when compared to
problem-specific algorithms and becomes more pronounced with increased graph
densities. Here, We identify a behavioral pattern related to it and devise
strategies to improve its performance. Another group of literature uses
Reinforcement learning (RL) to solve the aforementioned NP-hard problems using
problem-specific reward functions. In this work, we also focus on creating a
bridge between the RL-based solutions and the QUBO-formulated Hamiltonian. We
formulate and empirically evaluate the compatibility of the QUBO-formulated
Hamiltonian as the generic reward function in the RL-based paradigm in the form
of rewards. Furthermore, we also introduce a novel Monty Carlo Tree
Search-based strategy with GNN where we apply a guided search through manual
perturbation of node labels during training. We empirically evaluated our
methods and observed up to 44% improvement in the number of constraint
violations compared to the PI-GNN.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16278" title="Abstract">arXiv:2311.16278</a> [<a href="/pdf/2311.16278" title="Download PDF">pdf</a>, <a href="/format/2311.16278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VehicleGAN: Pair-flexible Pose Guided Image Synthesis for Vehicle  Re-identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Baolu Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Ping Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+L">Lan Fu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinlong Li</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+J">Jianwu Fang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhigang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hongkai Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vehicle Re-identification (Re-ID) has been broadly studied in the last
decade; however, the different camera view angle leading to confused
discrimination in the feature subspace for the vehicles of various poses, is
still challenging for the Vehicle Re-ID models in the real world. To promote
the Vehicle Re-ID models, this paper proposes to synthesize a large number of
vehicle images in the target pose, whose idea is to project the vehicles of
diverse poses into the unified target pose so as to enhance feature
discrimination. Considering that the paired data of the same vehicles in
different traffic surveillance cameras might be not available in the real
world, we propose the first Pair-flexible Pose Guided Image Synthesis method
for Vehicle Re-ID, named as VehicleGAN in this paper, which works for both
supervised and unsupervised settings without the knowledge of geometric 3D
models. Because of the feature distribution difference between real and
synthetic data, simply training a traditional metric learning based Re-ID model
with data-level fusion (i.e., data augmentation) is not satisfactory, therefore
we propose a new Joint Metric Learning (JML) via effective feature-level fusion
from both real and synthetic data. Intensive experimental results on the public
VeRi-776 and VehicleID datasets prove the accuracy and effectiveness of our
proposed VehicleGAN and JML.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16282" title="Abstract">arXiv:2311.16282</a> [<a href="/pdf/2311.16282" title="Download PDF">pdf</a>, <a href="/ps/2311.16282" title="Download PostScript">ps</a>, <a href="/format/2311.16282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Control of the Power Flows of a Stochastic Power System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zhen Wang</a>, 
<a href="/search/eess?searchtype=author&query=Xi%2C+K">Kaihua Xi</a>, 
<a href="/search/eess?searchtype=author&query=Cheng%2C+A">Aijie Cheng</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+H+X">Hai Xiang Lin</a>, 
<a href="/search/eess?searchtype=author&query=van+Schuppen%2C+J+H">Jan H. van Schuppen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A supplement with 20 pages, 5 figures, 43 tables has been added to the original manuscript
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">How to determine the power supply of a power system to guarantee that the
state remains during a short horizon in a critical subset of the state set? The
critical subset is related to the power flows of all power lines of a power
system and to transient stability. The control objective is to minimize a cost
function. That function is defined as the maximal power flow over all power
lines, including a multiple of its standard deviation, as a function of the
power supply vector. That the controlled system has an improved performance is
shown by numerical results of three academic examples including an eight-node
academic network, a twelve-node ring network, and a Manhattan-grid network.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16292" title="Abstract">arXiv:2311.16292</a> [<a href="/pdf/2311.16292" title="Download PDF">pdf</a>, <a href="/format/2311.16292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Student Mastery or AI Deception? Analyzing ChatGPT&#x27;s Assessment  Proficiency and Evaluating Detection Strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kevin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Akins%2C+S">Seth Akins</a>, 
<a href="/search/cs?searchtype=author&query=Mohammed%2C+A">Abdallah Mohammed</a>, 
<a href="/search/cs?searchtype=author&query=Lawrence%2C+R">Ramon Lawrence</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, Published in 2023 International Conference on Computational Science and Computational Intelligence Research Track on Education, IEEE CPS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Generative AI systems such as ChatGPT have a disruptive effect on learning
and assessment. Computer science requires practice to develop skills in problem
solving and programming that are traditionally developed using assignments.
Generative AI has the capability of completing these assignments for students
with high accuracy, which dramatically increases the potential for academic
integrity issues and students not achieving desired learning outcomes. This
work investigates the performance of ChatGPT by evaluating it across three
courses (CS1,CS2,databases). ChatGPT completes almost all introductory
assessments perfectly. Existing detection methods, such as MOSS and JPlag
(based on similarity metrics) and GPTzero (AI detection), have mixed success in
identifying AI solutions. Evaluating instructors and teaching assistants using
heuristics to distinguish between student and AI code shows that their
detection is not sufficiently accurate. These observations emphasize the need
for adapting assessments and improved detection methods.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16293" title="Abstract">arXiv:2311.16293</a> [<a href="/pdf/2311.16293" title="Download PDF">pdf</a>, <a href="/format/2311.16293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FHEmem: A Processing In-Memory Accelerator for Fully Homomorphic  Encryption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Minxuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Nam%2C+Y">Yujin Nam</a>, 
<a href="/search/cs?searchtype=author&query=Gangwar%2C+P">Pranav Gangwar</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weihong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Dutta%2C+A">Arpan Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Subramanyam%2C+K">Kartikeyan Subramanyam</a>, 
<a href="/search/cs?searchtype=author&query=Wilkerson%2C+C">Chris Wilkerson</a>, 
<a href="/search/cs?searchtype=author&query=Cammarota%2C+R">Rosario Cammarota</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Saransh Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Rosing%2C+T">Tajana Rosing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Fully Homomorphic Encryption (FHE) is a technique that allows arbitrary
computations to be performed on encrypted data without the need for decryption,
making it ideal for securing many emerging applications. However, FHE
computation is significantly slower than computation on plain data due to the
increase in data size after encryption. Processing In-Memory (PIM) is a
promising technology that can accelerate data-intensive workloads with
extensive parallelism. However, FHE is challenging for PIM acceleration due to
the long-bitwidth multiplications and complex data movements involved. We
propose a PIM-based FHE accelerator, FHEmem, which exploits a novel processing
in-memory architecture to achieve high-throughput and efficient acceleration
for FHE. We propose an optimized end-to-end processing flow, from low-level
hardware processing to high-level application mapping, that fully exploits the
high throughput of FHEmem hardware. Our evaluation shows FHEmem achieves
significant speedup and efficiency improvement over state-of-the-art FHE
accelerators.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16294" title="Abstract">arXiv:2311.16294</a> [<a href="/pdf/2311.16294" title="Download PDF">pdf</a>, <a href="/format/2311.16294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aligning Non-Causal Factors for Transformer-Based Source-Free Domain  Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sanyal%2C+S">Sunandini Sanyal</a>, 
<a href="/search/cs?searchtype=author&query=Asokan%2C+A+R">Ashish Ramayee Asokan</a>, 
<a href="/search/cs?searchtype=author&query=Bhambri%2C+S">Suvaansh Bhambri</a>, 
<a href="/search/cs?searchtype=author&query=YM%2C+P">Pradyumna YM</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+A">Akshay Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Kundu%2C+J+N">Jogendra Nath Kundu</a>, 
<a href="/search/cs?searchtype=author&query=Babu%2C+R+V">R Venkatesh Babu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024. Project Page: <a href="https://val.cds.iisc.ac.in/C-SFTrans/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Conventional domain adaptation algorithms aim to achieve better
generalization by aligning only the task-discriminative causal factors between
a source and target domain. However, we find that retaining the spurious
correlation between causal and non-causal factors plays a vital role in
bridging the domain gap and improving target adaptation. Therefore, we propose
to build a framework that disentangles and supports causal factor alignment by
aligning the non-causal factors first. We also investigate and find that the
strong shape bias of vision transformers, coupled with its multi-head
attention, make it a suitable architecture for realizing our proposed
disentanglement. Hence, we propose to build a Causality-enforcing Source-Free
Transformer framework (C-SFTrans) to achieve disentanglement via a novel
two-stage alignment approach: a) non-causal factor alignment: non-causal
factors are aligned using a style classification task which leads to an overall
global alignment, b) task-discriminative causal factor alignment: causal
factors are aligned via target adaptation. We are the first to investigate the
role of vision transformers (ViTs) in a privacy-preserving source-free setting.
Our approach achieves state-of-the-art results in several DA benchmarks.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16298" title="Abstract">arXiv:2311.16298</a> [<a href="/pdf/2311.16298" title="Download PDF">pdf</a>, <a href="/format/2311.16298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Influence Scores at Scale for Efficient Language Data Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anand%2C+N">Nikhil Anand</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+J">Joshua Tan</a>, 
<a href="/search/cs?searchtype=author&query=Minakova%2C+M">Maria Minakova</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP '23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Modern ML systems ingest data aggregated from diverse sources, such as
synthetic, human-annotated, and live customer traffic. Understanding
\textit{which} examples are important to the performance of a learning
algorithm is crucial for efficient model training. Recently, a growing body of
literature has given rise to various "influence scores," which use training
artifacts such as model confidence or checkpointed gradients to identify
important subsets of data. However, these methods have primarily been developed
in computer vision settings, and it remains unclear how well they generalize to
language-based tasks using pretrained models.
<br />In this paper, we explore the applicability of influence scores in language
classification tasks. We evaluate a diverse subset of these scores on the SNLI
dataset by quantifying accuracy changes in response to pruning training data
through random and influence-score-based sampling. We then stress-test one of
the scores -- "variance of gradients" (VoG) from Agarwal et al. (2022) -- in an
NLU model stack that was exposed to dynamic user speech patterns in a voice
assistant type of setting. Our experiments demonstrate that in many cases,
encoder-based language models can be finetuned on roughly 50% of the original
data without degradation in performance metrics. Along the way, we summarize
lessons learned from applying out-of-the-box implementations of influence
scores, quantify the effects of noisy and class-imbalanced data, and offer
recommendations on score-based sampling for better accuracy and training
efficiency.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16300" title="Abstract">arXiv:2311.16300</a> [<a href="/pdf/2311.16300" title="Download PDF">pdf</a>, <a href="/ps/2311.16300" title="Download PostScript">ps</a>, <a href="/format/2311.16300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Energysheds: A Technical Definition and Cooperative Planning  Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hamilton%2C+D">Dakota Hamilton</a>, 
<a href="/search/eess?searchtype=author&query=Chevalier%2C+S">Samuel Chevalier</a>, 
<a href="/search/eess?searchtype=author&query=Pandey%2C+A">Amritanshu Pandey</a>, 
<a href="/search/eess?searchtype=author&query=Almassalkhi%2C+M">Mads Almassalkhi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">There is growing interest in understanding how interactions between national
and global policy objectives and local community decision-making will impact
the clean energy transition. The concept of energysheds has gained traction in
the areas of public policy and social science as a way to study these
relationships. However, technical definitions for energysheds are still in
their infancy. In this work, we propose a mathematical definition for
energysheds. Analytical insights into the factors that impact a community's
ability to achieve their energyshed policy objectives are developed, and
various tradeoffs associated with interconnected energysheds within power
systems are studied. We also introduce a framework for energyshed planning to
help ensure equitable and cooperative decision making as communities invest in
local energy assets. This framework is applied in an example transmission
network, and numerical results are presented.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16302" title="Abstract">arXiv:2311.16302</a> [<a href="/pdf/2311.16302" title="Download PDF">pdf</a>, <a href="/format/2311.16302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comprehensive Benchmarking of Entropy and Margin Based Scoring Metrics  for Data Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sabbineni%2C+A">Anusha Sabbineni</a>, 
<a href="/search/cs?searchtype=author&query=Anand%2C+N">Nikhil Anand</a>, 
<a href="/search/cs?searchtype=author&query=Minakova%2C+M">Maria Minakova</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Efficient Natural Language and Speech Processing (ENLSP-III) workshop at NeurIPS '23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">While data selection methods have been studied extensively in active
learning, data pruning, and data augmentation settings, there is little
evidence for the efficacy of these methods in industry scale settings,
particularly in low-resource languages. Our work presents ways of assessing
prospective training examples in those settings for their "usefulness" or
"difficulty". We also demonstrate how these measures can be used in selecting
important examples for training supervised machine learning models. We
primarily experiment with entropy and Error L2-Norm (EL2N) scores. We use these
metrics to curate high quality datasets from a large pool of \textit{Weak
Signal Labeled} data, which assigns no-defect high confidence hypotheses during
inference as ground truth labels. We then conduct training data augmentation
experiments using these de-identified datasets and demonstrate that score-based
selection can result in a 2% decrease in semantic error rate and 4%-7% decrease
in domain classification error rate when compared to the baseline technique of
random selection.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16303" title="Abstract">arXiv:2311.16303</a> [<a href="/pdf/2311.16303" title="Download PDF">pdf</a>, <a href="/ps/2311.16303" title="Download PostScript">ps</a>, <a href="/format/2311.16303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Root causes, ongoing difficulties, proactive prevention techniques, and  emerging trends of enterprise data breaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patil%2C+R">Rina Patil</a>, 
<a href="/search/cs?searchtype=author&query=Pise%2C+G">Gayatri Pise</a>, 
<a href="/search/cs?searchtype=author&query=Bhosale%2C+Y">Yatin Bhosale</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">A data breach in the modern digital era is the unintentional or intentional
disclosure of private data to uninvited parties. Businesses now consider data
to be a crucial asset, and any breach of this data can have dire repercussions,
including harming a company's brand and resulting in losses. Enterprises now
place a high premium on detecting and preventing data loss due to the growing
amount of data and the increasing frequency of data breaches. Even with a great
deal of research, protecting sensitive data is still a difficult task. This
review attempts to highlight interesting prospects and offer insightful
information to those who are interested in learning about the risks that
businesses face from data leaks, current occurrences, state-of-the-art methods
for detection and prevention, new difficulties, and possible solutions.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16304" title="Abstract">arXiv:2311.16304</a> [<a href="/pdf/2311.16304" title="Download PDF">pdf</a>, <a href="/format/2311.16304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Self-calibration of Focal Lengths from the Fundamental Matrix
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kocur%2C+V">Viktor Kocur</a>, 
<a href="/search/cs?searchtype=author&query=Kyselica%2C+D">Daniel Kyselica</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%BAkelov%C3%A1%2C+Z">Zuzana K&#xfa;kelov&#xe1;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The problem of self-calibration of two cameras from a given fundamental
matrix is one of the basic problems in geometric computer vision. Under the
assumption of known principal points and square pixels, the well-known Bougnoux
formula offers a means to compute the two unknown focal lengths. However, in
many practical situations, the formula yields inaccurate results due to
commonly occurring singularities. Moreover, the estimates are sensitive to
noise in the computed fundamental matrix and to the assumed positions of the
principal points. In this paper, we therefore propose an efficient and robust
iterative method to estimate the focal lengths along with the principal points
of the cameras given a fundamental matrix and priors for the estimated camera
parameters. In addition, we study a computationally efficient check of models
generated within RANSAC that improves the accuracy of the estimated models
while reducing the total computational time. Extensive experiments on real and
synthetic data show that our iterative method brings significant improvements
in terms of the accuracy of the estimated focal lengths over the Bougnoux
formula and other state-of-the-art methods, even when relying on inaccurate
priors.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16311" title="Abstract">arXiv:2311.16311</a> [<a href="/pdf/2311.16311" title="Download PDF">pdf</a>, <a href="/format/2311.16311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizing Video Question Answering with Sparsified Inputs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shiyuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Piramuthu%2C+R">Robinson Piramuthu</a>, 
<a href="/search/cs?searchtype=author&query=Ordonez%2C+V">Vicente Ordonez</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+S">Shih-Fu Chang</a>, 
<a href="/search/cs?searchtype=author&query=Sigurdsson%2C+G+A">Gunnar A. Sigurdsson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In Video Question Answering, videos are often processed as a full-length
sequence of frames to ensure minimal loss of information. Recent works have
demonstrated evidence that sparse video inputs are sufficient to maintain high
performance. However, they usually discuss the case of single frame selection.
In our work, we extend the setting to multiple number of inputs and other
modalities. We characterize the task with different input sparsity and provide
a tool for doing that. Specifically, we use a Gumbel-based learnable selection
module to adaptively select the best inputs for the final task. In this way, we
experiment over public VideoQA benchmarks and provide analysis on how
sparsified inputs affect the performance. From our experiments, we have
observed only 5.2%-5.8% loss of performance with only 10% of video lengths,
which corresponds to 2-4 frames selected from each video. Meanwhile, we also
observed the complimentary behaviour between visual and textual inputs, even
under highly sparsified settings, suggesting the potential of improving data
efficiency for video-and-language tasks.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16312" title="Abstract">arXiv:2311.16312</a> [<a href="/pdf/2311.16312" title="Download PDF">pdf</a>, <a href="/ps/2311.16312" title="Download PostScript">ps</a>, <a href="/format/2311.16312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain-Specific Deep Learning Feature Extractor for Diabetic Foot Ulcer  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Basiri%2C+R">Reza Basiri</a>, 
<a href="/search/cs?searchtype=author&query=Popovic%2C+M+R">Milos R. Popovic</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S+S">Shehroz S. Khan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures, 3 tables, 2022 IEEE International Conference on Data Mining Workshops
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2022 IEEE International Conference on Data Mining Workshops. pp.
  1-5
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Diabetic Foot Ulcer (DFU) is a condition requiring constant monitoring and
evaluations for treatment. DFU patient population is on the rise and will soon
outpace the available health resources. Autonomous monitoring and evaluation of
DFU wounds is a much-needed area in health care. In this paper, we evaluate and
identify the most accurate feature extractor that is the core basis for
developing a deep-learning wound detection network. For the evaluation, we used
mAP and F1-score on the publicly available DFU2020 dataset. A combination of
UNet and EfficientNetb3 feature extractor resulted in the best evaluation among
the 14 networks compared. UNet and Efficientnetb3 can be used as the classifier
in the development of a comprehensive DFU domain-specific autonomous wound
detection pipeline.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16314" title="Abstract">arXiv:2311.16314</a> [<a href="/pdf/2311.16314" title="Download PDF">pdf</a>, <a href="/format/2311.16314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Designing Spatial Robots that are Architecturally Motivated
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+B+V+D">Binh Vinh Duc Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Moere%2C+A+V">Andrew Vande Moere</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">While robots are increasingly integrated into the built environment, little
is known how their qualities can meaningfully influence our spaces to
facilitate enjoyable and agreeable interaction, rather than robotic settings
that are driven by functional goals. Motivated by the premise that future
robots should be aware of architectural sensitivities, we developed a set of
exploratory studies that combine methods from both architectural and
interaction design. While we empirically discovered that dynamically moving
spatial elements, which we coin as spatial robots, can indeed create unique
life-sized affordances that encourage or resist human activities, we also
encountered many unforeseen design challenges originated from how ordinary
users and experts perceived spatial robots. This discussion thus could inform
similar design studies in the areas of human-building architecture (HBI) or
responsive and interactive architecture.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16328" title="Abstract">arXiv:2311.16328</a> [<a href="/pdf/2311.16328" title="Download PDF">pdf</a>, <a href="/format/2311.16328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Target-Free Compound Activity Prediction via Few-Shot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eckmann%2C+P">Peter Eckmann</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+J">Jake Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Gilson%2C+M+K">Michael K. Gilson</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+R">Rose Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Predicting the activities of compounds against protein-based or phenotypic
assays using only a few known compounds and their activities is a common task
in target-free drug discovery. Existing few-shot learning approaches are
limited to predicting binary labels (active/inactive). However, in real-world
drug discovery, degrees of compound activity are highly relevant. We study
Few-Shot Compound Activity Prediction (FS-CAP) and design a novel neural
architecture to meta-learn continuous compound activities across large
bioactivity datasets. Our model aggregates encodings generated from the known
compounds and their activities to capture assay information. We also introduce
a separate encoder for the unknown compound. We show that FS-CAP surpasses
traditional similarity-based techniques as well as other state of the art
few-shot learning methods on a variety of target-free drug discovery settings
and datasets.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16334" title="Abstract">arXiv:2311.16334</a> [<a href="/pdf/2311.16334" title="Download PDF">pdf</a>, <a href="/format/2311.16334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Basket Recommendation via Noise-tolerated Graph Contrastive  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xinrui He</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+T">Tianxin Wei</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jingrui He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CIKM 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Proceedings of the 32nd ACM International Conference on
  Information and Knowledge Management (CIKM '23). Association for Computing
  Machinery, New York, NY, USA, 709-719 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">The growth of e-commerce has seen a surge in popularity of platforms like
Amazon, eBay, and Taobao. This has given rise to a unique shopping behavior
involving baskets - sets of items purchased together. As a less studied
interaction mode in the community, the question of how should shopping basket
complement personalized recommendation systems remains under-explored. While
previous attempts focused on jointly modeling user purchases and baskets, the
distinct semantic nature of these elements can introduce noise when directly
integrated. This noise negatively impacts the model's performance, further
exacerbated by significant noise within both user and basket behaviors.
<br />In order to cope with the above difficulties, we propose a novel Basket
recommendation framework via Noise-tolerated Contrastive Learning, named BNCL,
to handle the noise existing in the cross-behavior integration and
within-behavior modeling. First, we represent the basket-item interactions as
the hypergraph to model the complex basket behavior, where all items appearing
in the same basket are treated as a single hyperedge. Second, cross-behavior
contrastive learning is designed to suppress the noise during the fusion of
diverse behaviors. Next, to further inhibit the within-behavior noise of the
user and basket interactions, we propose to exploit invariant properties of the
recommenders w.r.t augmentations through within-behavior contrastive learning.
A novel consistency-aware augmentation approach is further designed to better
identify noisy interactions with the consideration of the above two types of
interactions. Our framework BNCL offers a generic training paradigm that is
applicable to different backbones. Extensive experiments on three shopping
transaction datasets verify the effectiveness of our proposed method. Our code
is available.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16337" title="Abstract">arXiv:2311.16337</a> [<a href="/pdf/2311.16337" title="Download PDF">pdf</a>, <a href="/ps/2311.16337" title="Download PostScript">ps</a>, <a href="/format/2311.16337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-3D-Models Registration-Based Augmented Reality (AR) Instructions  for Assembly
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Canadinc%2C+S+T">Seda Tuzun Canadinc</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+W">Wei Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This paper introduces a novel, markerless, step-by-step, in-situ 3D Augmented
Reality (AR) instruction method and its application - BRICKxAR (Multi 3D
Models/M3D) - for small parts assembly. BRICKxAR (M3D) realistically visualizes
rendered 3D assembly parts at the assembly location of the physical assembly
model (Figure 1). The user controls the assembly process through a user
interface. BRICKxAR (M3D) utilizes deep learning-trained 3D model-based
registration. Object recognition and tracking become challenging as the
assembly model updates at each step. Additionally, not every part in a 3D
assembly may be visible to the camera during the assembly. BRICKxAR (M3D)
combines multiple assembly phases with a step count to address these
challenges. Thus, using fewer phases simplifies the complex assembly process
while step count facilitates accurate object recognition and precise
visualization of each step. A testing and heuristic evaluation of the BRICKxAR
(M3D) prototype and qualitative analysis were conducted with users and experts
in visualization and human-computer interaction. Providing robust 3D AR
instructions and allowing the handling of the assembly model, BRICKxAR (M3D)
has the potential to be used at different scales ranging from manufacturing
assembly to construction.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16338" title="Abstract">arXiv:2311.16338</a> [<a href="/pdf/2311.16338" title="Download PDF">pdf</a>, <a href="/format/2311.16338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Releasing the CRaQAn (Coreference Resolution in Question-Answering): An  open-source dataset and dataset creation methodology using  instruction-following models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grzywinski%2C+R">Rob Grzywinski</a>, 
<a href="/search/cs?searchtype=author&query=D%27Arcy%2C+J">Joshua D&#x27;Arcy</a>, 
<a href="/search/cs?searchtype=author&query=Naidoff%2C+R">Rob Naidoff</a>, 
<a href="/search/cs?searchtype=author&query=Shukla%2C+A">Ashish Shukla</a>, 
<a href="/search/cs?searchtype=author&query=Browne%2C+A">Alex Browne</a>, 
<a href="/search/cs?searchtype=author&query=Gibbons%2C+R">Ren Gibbons</a>, 
<a href="/search/cs?searchtype=author&query=Bent%2C+B">Brinnae Bent</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Workshop on Instruction Tuning and Instruction Following
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Instruction-following language models demand robust methodologies for
information retrieval to augment instructions for question-answering
applications. A primary challenge is the resolution of coreferences in the
context of chunking strategies for long documents. The critical barrier to
experimentation of handling coreferences is a lack of open source datasets,
specifically in question-answering tasks that require coreference resolution.
In this work we present our Coreference Resolution in Question-Answering
(CRaQAn) dataset, an open-source dataset that caters to the nuanced information
retrieval requirements of coreference resolution in question-answering tasks by
providing over 250 question-answer pairs containing coreferences. To develop
this dataset, we developed a novel approach for creating high-quality datasets
using an instruction-following model (GPT-4) and a Recursive Criticism and
Improvement Loop.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16339" title="Abstract">arXiv:2311.16339</a> [<a href="/pdf/2311.16339" title="Download PDF">pdf</a>, <a href="/format/2311.16339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reward Shaping for Improved Learning in Real-time Strategy Game Play
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kliem%2C+J">John Kliem</a>, 
<a href="/search/cs?searchtype=author&query=Dasgupta%2C+P">Prithviraj Dasgupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages 11 figures and 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We investigate the effect of reward shaping in improving the performance of
reinforcement learning in the context of the real-time strategy,
capture-the-flag game. The game is characterized by sparse rewards that are
associated with infrequently occurring events such as grabbing or capturing the
flag, or tagging the opposing player. We show that appropriately designed
reward shaping functions applied to different game events can significantly
improve the player's performance and training times of the player's learning
algorithm. We have validated our reward shaping functions within a simulated
environment for playing a marine capture-the-flag game between two players. Our
experimental results demonstrate that reward shaping can be used as an
effective means to understand the importance of different sub-tasks during
game-play towards winning the game, to encode a secondary objective functions
such as energy efficiency into a player's game-playing behavior, and, to
improve learning generalizable policies that can perform well against different
skill levels of the opponent.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16342" title="Abstract">arXiv:2311.16342</a> [<a href="/pdf/2311.16342" title="Download PDF">pdf</a>, <a href="/format/2311.16342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Matrix Multiplication in Quadratic Time and Energy? Towards a  Fine-Grained Energy-Centric Church-Turing Thesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Valiant%2C+G">Gregory Valiant</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We describe two algorithms for multiplying n x n matrices using time and
energy n^2 polylog(n) under basic models of classical physics. The first
algorithm is for multiplying integer-valued matrices, and the second, quite
different algorithm, is for Boolean matrix multiplication. We hope this work
inspires a deeper consideration of physically plausible/realizable models of
computing that might allow for algorithms which improve upon the runtimes and
energy usages suggested by the parallel RAM model in which each operation
requires one unit of time and one unit of energy.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16344" title="Abstract">arXiv:2311.16344</a> [<a href="/pdf/2311.16344" title="Download PDF">pdf</a>, <a href="/format/2311.16344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatially Adaptive Cloth Regression with Implicit Neural Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shu%2C+L">Lei Shu</a>, 
<a href="/search/cs?searchtype=author&query=Azevedo%2C+V">Vinicius Azevedo</a>, 
<a href="/search/cs?searchtype=author&query=Solenthaler%2C+B">Barbara Solenthaler</a>, 
<a href="/search/cs?searchtype=author&query=Gross%2C+M">Markus Gross</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">The accurate representation of fine-detailed cloth wrinkles poses significant
challenges in computer graphics. The inherently non-uniform structure of cloth
wrinkles mandates the employment of intricate discretization strategies, which
are frequently characterized by high computational demands and complex
methodologies. Addressing this, the research introduced in this paper
elucidates a novel anisotropic cloth regression technique that capitalizes on
the potential of implicit neural representations of surfaces. Our first core
contribution is an innovative mesh-free sampling approach, crafted to reduce
the reliance on traditional mesh structures, thereby offering greater
flexibility and accuracy in capturing fine cloth details. Our second
contribution is a novel adversarial training scheme, which is designed
meticulously to strike a harmonious balance between the sampling and simulation
objectives. The adversarial approach ensures that the wrinkles are represented
with high fidelity, while also maintaining computational efficiency. Our
results showcase through various cloth-object interaction scenarios that our
method, given the same memory constraints, consistently surpasses traditional
discrete representations, particularly when modelling highly-detailed localized
wrinkles.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16346" title="Abstract">arXiv:2311.16346</a> [<a href="/pdf/2311.16346" title="Download PDF">pdf</a>, <a href="/format/2311.16346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Small and Dim Target Detection in IR Imagery: A Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+N">Nikhil Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+P">Pravendra Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">While there has been significant progress in object detection using
conventional image processing and machine learning algorithms, exploring small
and dim target detection in the IR domain is a relatively new area of study.
The majority of small and dim target detection methods are derived from
conventional object detection algorithms, albeit with some alterations. The
task of detecting small and dim targets in IR imagery is complex. This is
because these targets often need distinct features, the background is cluttered
with unclear details, and the IR signatures of the scene can change over time
due to fluctuations in thermodynamics. The primary objective of this review is
to highlight the progress made in this field. This is the first review in the
field of small and dim target detection in infrared imagery, encompassing
various methodologies ranging from conventional image processing to
cutting-edge deep learning-based approaches. The authors have also introduced a
taxonomy of such approaches. There are two main types of approaches:
methodologies using several frames for detection, and single-frame-based
detection techniques. Single frame-based detection techniques encompass a
diverse range of methods, spanning from traditional image processing-based
approaches to more advanced deep learning methodologies. Our findings indicate
that deep learning approaches perform better than traditional image
processing-based approaches. In addition, a comprehensive compilation of
various available datasets has also been provided. Furthermore, this review
identifies the gaps and limitations in existing techniques, paving the way for
future research and development in this area.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16347" title="Abstract">arXiv:2311.16347</a> [<a href="/pdf/2311.16347" title="Download PDF">pdf</a>, <a href="/format/2311.16347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Random generation of group elements using combinatorial group theory and  automata theory, along with a hardware example
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vaez%2C+M">MohammadJavad Vaez</a>, 
<a href="/search/cs?searchtype=author&query=Kaedi%2C+M">Marjan Kaedi</a>, 
<a href="/search/cs?searchtype=author&query=Kalbasi%2C+M">Mahdi Kalbasi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO); Group Theory (math.GR)

</div>
<p class="mathjax">In this paper, we introduce a novel approach for generating random elements
of a finite group given a set of generators of that. Our method draws upon
combinatorial group theory and automata theory to achieve this objective.
Furthermore, we explore the application of this method in generating random
elements of a particularly significant group, namely the symmetric group (or
group of permutations on a set). Through rigorous analysis, we demonstrate that
our proposed method requires fewer average swaps to generate permutations
compared to existing approaches. However, recognizing the need for practical
applications, we propose a hardware-based implementation based on our
theoretical approach, and provide a comprehensive comparison with previous
methods. Our evaluation reveals that our method outperforms existing approaches
in certain scenarios. Although our primary proposed method only aims to speed
up the shuffling and does not decrease its time complexity, we also extend our
method to improve the time complexity.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16353" title="Abstract">arXiv:2311.16353</a> [<a href="/pdf/2311.16353" title="Download PDF">pdf</a>, <a href="/format/2311.16353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Denoising Diffusion Probabilistic Models via Exploiting Shared  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pirhayatifard%2C+D">Delaram Pirhayatifard</a>, 
<a href="/search/cs?searchtype=author&query=Toghani%2C+M+T">Mohammad Taha Toghani</a>, 
<a href="/search/cs?searchtype=author&query=Balakrishnan%2C+G">Guha Balakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Uribe%2C+C+A">C&#xe9;sar A. Uribe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV); Signal Processing (eess.SP)

</div>
<p class="mathjax">In this work, we address the challenge of multi-task image generation with
limited data for denoising diffusion probabilistic models (DDPM), a class of
generative models that produce high-quality images by reversing a noisy
diffusion process. We propose a novel method, SR-DDPM, that leverages
representation-based techniques from few-shot learning to effectively learn
from fewer samples across different tasks. Our method consists of a core meta
architecture with shared parameters, i.e., task-specific layers with exclusive
parameters. By exploiting the similarity between diverse data distributions,
our method can scale to multiple tasks without compromising the image quality.
We evaluate our method on standard image datasets and show that it outperforms
both unconditional and conditional DDPM in terms of FID and SSIM metrics.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16357" title="Abstract">arXiv:2311.16357</a> [<a href="/pdf/2311.16357" title="Download PDF">pdf</a>, <a href="/format/2311.16357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross Entropy in Deep Learning of Classifiers Is Unnecessary -- ISBE  Error is All You Need
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Skarbek%2C+W">Wladyslaw Skarbek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In deep learning classifiers, the cost function usually takes the form of a
combination of SoftMax and CrossEntropy functions. The SoftMax unit transforms
the scores predicted by the model network into assessments of the degree
(probabilities) of an object's membership to a given class. On the other hand,
CrossEntropy measures the divergence of this prediction from the distribution
of target scores. This work introduces the ISBE functionality, justifying the
thesis about the redundancy of cross entropy computation in deep learning of
classifiers. Not only can we omit the calculation of entropy, but also, during
back-propagation, there is no need to direct the error to the normalization
unit for its backward transformation. Instead, the error is sent directly to
the model's network. Using examples of perceptron and convolutional networks as
classifiers of images from the MNIST collection, it is observed for ISBE that
results are not degraded with SoftMax only, but also with other activation
functions such as Sigmoid, Tanh, or their hard variants HardSigmoid and
HardTanh. Moreover, up to three percent of time is saved within the total time
of forward and backward stages. The article is addressed mainly to programmers
and students interested in deep model learning. For example, it illustrates in
code snippets possible ways to implement ISBE units, but also formally proves
that the softmax trick only applies to the class of softmax functions with
relocations.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16361" title="Abstract">arXiv:2311.16361</a> [<a href="/pdf/2311.16361" title="Download PDF">pdf</a>, <a href="/format/2311.16361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Making Self-supervised Learning Robust to Spurious Correlation via  Learning-speed Aware Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Weicheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fernandez-Granda%2C+C">Carlos Fernandez-Granda</a>, 
<a href="/search/cs?searchtype=author&query=Razavian%2C+N">Narges Razavian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023 Workshop Self-Supervised Learning - Theory and Practice, 18 pages, 7 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Self-supervised learning (SSL) has emerged as a powerful technique for
learning rich representations from unlabeled data. The data representations are
able to capture many underlying attributes of data, and be useful in downstream
prediction tasks. In real-world settings, spurious correlations between some
attributes (e.g. race, gender and age) and labels for downstream tasks often
exist, e.g. cancer is usually more prevalent among elderly patients. In this
paper, we investigate SSL in the presence of spurious correlations and show
that the SSL training loss can be minimized by capturing only a subset of the
conspicuous features relevant to those sensitive attributes, despite the
presence of other important predictive features for the downstream tasks. To
address this issue, we investigate the learning dynamics of SSL and observe
that the learning is slower for samples that conflict with such correlations
(e.g. elder patients without cancer). Motivated by these findings, we propose a
learning-speed aware SSL (LA-SSL) approach, in which we sample each training
data with a probability that is inversely related to its learning speed. We
evaluate LA-SSL on three datasets that exhibit spurious correlations between
different attributes, demonstrating that it improves the robustness of
pretrained representations on downstream classification tasks.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16362" title="Abstract">arXiv:2311.16362</a> [<a href="/pdf/2311.16362" title="Download PDF">pdf</a>, <a href="/format/2311.16362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reducing Gender Bias in Machine Translation through Counterfactual Data  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naik%2C+R">Ranjita Naik</a>, 
<a href="/search/cs?searchtype=author&query=Rarrick%2C+S">Spencer Rarrick</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhary%2C+V">Vishal Chowdhary</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent advances in neural methods have led to substantial improvement in the
quality of Neural Machine Translation (NMT) systems. However, these systems
frequently produce translations with inaccurate gender (Stanovsky et al.,
2019), which can be traced to bias in training data. Saunders and Byrne (2020)
tackle this problem with a handcrafted dataset containing balanced gendered
profession words. By using this data to fine-tune an existing NMT model, they
show that gender bias can be significantly mitigated, albeit at the expense of
translation quality due to catastrophic forgetting. They recover some of the
lost quality with modified training objectives or additional models at
inference. We find, however, that simply supplementing the handcrafted dataset
with a random sample from the base model training corpus is enough to
significantly reduce the catastrophic forgetting. We also propose a novel
domain-adaptation technique that leverages in-domain data created with the
counterfactual data generation techniques proposed by Zmigrod et al. (2019) to
further improve accuracy on the WinoMT challenge test set without significant
loss in translation quality. We show its effectiveness in NMT systems from
English into three morphologically rich languages French, Spanish, and Italian.
The relevant dataset and code will be available at Github.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16367" title="Abstract">arXiv:2311.16367</a> [<a href="/pdf/2311.16367" title="Download PDF">pdf</a>, <a href="/format/2311.16367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regularized Reduced Order Lippman-Schwinger-Lanczos Method for Inverse  Scattering Problems in the Frequency Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Baker%2C+J">Justin Baker</a>, 
<a href="/search/math?searchtype=author&query=Cherkaev%2C+E">Elena Cherkaev</a>, 
<a href="/search/math?searchtype=author&query=Druskin%2C+V">Vladimir Druskin</a>, 
<a href="/search/math?searchtype=author&query=Moskow%2C+S">Shari Moskow</a>, 
<a href="/search/math?searchtype=author&query=Zaslavsky%2C+M">Mikhail Zaslavsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Inverse scattering has a broad applicability in quantum mechanics, remote
sensing, geophysical, and medical imaging. This paper presents a robust direct
reduced order model (ROM) method for solving inverse scattering problems based
on an efficient approximation of the resolvent operator regularizing the
Lippmann-Schwinger-Lanczos (LSL) algorithm. We show that the efficiency of the
method relies upon the weak dependence of the orthogonalized basis on the
unknown potential in the Schr\"odinger equation by demonstrating that the
Lanczos orthogonalization is equivalent to performing Gram-Schmidt on the ROM
time snapshots. We then develop the LSL algorithm in the frequency domain with
two levels of regularization. We show that the same procedure can be extended
beyond the Schr\"odinger formulation to the Helmholtz equation, e.g., to
imaging the conductivity using diffusive electromagnetic fields in conductive
media with localized positive conductivity perturbations. Numerical experiments
for Helmholtz and Schr\"odinger problems show that the proposed bi-level
regularization scheme significantly improves the performance of the LSL
algorithm, allowing for good reconstructions with noisy data and large data
sets.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16374" title="Abstract">arXiv:2311.16374</a> [<a href="/pdf/2311.16374" title="Download PDF">pdf</a>, <a href="/format/2311.16374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Informed Neural Network for Discovering Systems with  Unmeasurable States with Application to Lithium-Ion Batteries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kajiura%2C+Y">Yuichi Kajiura</a>, 
<a href="/search/cs?searchtype=author&query=Espin%2C+J">Jorge Espin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figure, submitted to American Control Conference 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Combining machine learning with physics is a trending approach for
discovering unknown dynamics, and one of the most intensively studied
frameworks is the physics-informed neural network (PINN). However, PINN often
fails to optimize the network due to its difficulty in concurrently minimizing
multiple losses originating from the system's governing equations. This problem
can be more serious when the system's states are unmeasurable, like lithium-ion
batteries (LiBs). In this work, we introduce a robust method for training PINN
that uses fewer loss terms and thus constructs a less complex landscape for
optimization. In particular, instead of having loss terms from each
differential equation, this method embeds the dynamics into a loss function
that quantifies the error between observed and predicted system outputs. This
is accomplished by numerically integrating the predicted states from the neural
network(NN) using known dynamics and transforming them to obtain a sequence of
predicted outputs. Minimizing such a loss optimizes the NN to predict states
consistent with observations given the physics. Further, the system's
parameters can be added to the optimization targets. To demonstrate the ability
of this method to perform various modeling and control tasks, we apply it to a
battery model to concurrently estimate its states and parameters.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16378" title="Abstract">arXiv:2311.16378</a> [<a href="/pdf/2311.16378" title="Download PDF">pdf</a>, <a href="/format/2311.16378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Formulations for Graph Spectral Denoising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leone%2C+S">Sam Leone</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xingzhi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Perlmutter%2C+M">Michael Perlmutter</a>, 
<a href="/search/cs?searchtype=author&query=Krishnaswamy%2C+S">Smita Krishnaswamy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">We consider noisy signals which are defined on the vertices of a graph and
present smoothing algorithms for the cases of Gaussian, dropout, and uniformly
distributed noise. The signals are assumed to follow a prior distribution
defined in the frequency domain which favors signals which are smooth across
the edges of the graph. By pairing this prior distribution with our three
models of noise generation, we propose \textit{Maximum A Posteriori} (M.A.P.)
estimates of the true signal in the presence of noisy data and provide
algorithms for computing the M.A.P. Finally, we demonstrate the algorithms'
ability to effectively restore white noise on image data, and from severe
dropout in toy \&amp; EHR data.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16379" title="Abstract">arXiv:2311.16379</a> [<a href="/pdf/2311.16379" title="Download PDF">pdf</a>, <a href="/format/2311.16379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhanced the Fast Fractional Fourier Transform (FRFT) scheme using the  closed Newton-Cotes rules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Nzokem%2C+A+H">A.H.Nzokem</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Probability (math.PR)

</div>
<p class="mathjax">The paper considers the fractional Fourier transform (FRFT)--based numerical
inversion of Fourier and Laplace transforms and the closed Newton Cotes
quadrature rules. It is shown that the fast FRFT of a QN-long weighted sequence
is the composite of two fast FRFTs: the fast FRFT of a Q-long weighted sequence
and the fast FRFT of an N-long sequence. The Newton-Cotes rules, the composite
fast FRFT, and non-weighted fast Fractional Fourier transform (FRFT) algorithms
are applied to the Variance Gamma distribution and the Generalized Tempered
Stable (GTS) distribution for illustrations. Compared to the non-weighted fast
FRFT, the composite fast FRFT provides more accurate results with a small
sample size, and the accuracy increases with the number of weights (Q).
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16380" title="Abstract">arXiv:2311.16380</a> [<a href="/pdf/2311.16380" title="Download PDF">pdf</a>, <a href="/format/2311.16380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Multimodal Latent Dynamics for Human-Robot Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prasad%2C+V">Vignesh Prasad</a>, 
<a href="/search/cs?searchtype=author&query=Heitlinger%2C+L">Lea Heitlinger</a>, 
<a href="/search/cs?searchtype=author&query=Koert%2C+D">Dorothea Koert</a>, 
<a href="/search/cs?searchtype=author&query=Stock-Homburg%2C+R">Ruth Stock-Homburg</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+J">Jan Peters</a>, 
<a href="/search/cs?searchtype=author&query=Chalvatzaki%2C+G">Georgia Chalvatzaki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 Pages, 10 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">This article presents a method for learning well-coordinated Human-Robot
Interaction (HRI) from Human-Human Interactions (HHI). We devise a hybrid
approach using Hidden Markov Models (HMMs) as the latent space priors for a
Variational Autoencoder to model a joint distribution over the interacting
agents. We leverage the interaction dynamics learned from HHI to learn HRI and
incorporate the conditional generation of robot motions from human observations
into the training, thereby predicting more accurate robot trajectories. The
generated robot motions are further adapted with Inverse Kinematics to ensure
the desired physical proximity with a human, combining the ease of joint space
learning and accurate task space reachability. For contact-rich interactions,
we modulate the robot's stiffness using HMM segmentation for a compliant
interaction. We verify the effectiveness of our approach deployed on a Humanoid
robot via a user study. Our method generalizes well to various humans despite
being trained on data from just two humans. We find that Users perceive our
method as more human-like, timely, and accurate and rank our method with a
higher degree of preference over other baselines.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16381" title="Abstract">arXiv:2311.16381</a> [<a href="/pdf/2311.16381" title="Download PDF">pdf</a>, <a href="/format/2311.16381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning for Time Series Classification of Parkinson&#x27;s Disease Eye  Tracking Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Uribarri%2C+G">Gonzalo Uribarri</a>, 
<a href="/search/cs?searchtype=author&query=von+Huth%2C+S+E">Simon Ekman von Huth</a>, 
<a href="/search/cs?searchtype=author&query=Waldthaler%2C+J">Josefine Waldthaler</a>, 
<a href="/search/cs?searchtype=author&query=Svenningsson%2C+P">Per Svenningsson</a>, 
<a href="/search/cs?searchtype=author&query=Frans%C3%A9n%2C+E">Erik Frans&#xe9;n</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2023, December 10th, 2023, New Orleans, United States, 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Eye-tracking is an accessible and non-invasive technology that provides
information about a subject's motor and cognitive abilities. As such, it has
proven to be a valuable resource in the study of neurodegenerative diseases
such as Parkinson's disease. Saccade experiments, in particular, have proven
useful in the diagnosis and staging of Parkinson's disease. However, to date,
no single eye-movement biomarker has been found to conclusively differentiate
patients from healthy controls. In the present work, we investigate the use of
state-of-the-art deep learning algorithms to perform Parkinson's disease
classification using eye-tracking data from saccade experiments. In contrast to
previous work, instead of using hand-crafted features from the saccades, we use
raw $\sim1.5\,s$ long fixation intervals recorded during the preparatory phase
before each trial. Using these short time series as input we implement two
different classification models, InceptionTime and ROCKET. We find that the
models are able to learn the classification task and generalize to unseen
subjects. InceptionTime achieves $78\%$ accuracy, while ROCKET achieves $88\%$
accuracy. We also employ a novel method for pruning the ROCKET model to improve
interpretability and generalizability, achieving an accuracy of $96\%$. Our
results suggest that fixation data has low inter-subject variability and
potentially carries useful information about brain cognitive and motor
conditions, making it suitable for use with machine learning in the discovery
of disease-relevant biomarkers.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16383" title="Abstract">arXiv:2311.16383</a> [<a href="/pdf/2311.16383" title="Download PDF">pdf</a>, <a href="/format/2311.16383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Do Users fall for Real Adversarial Phishing?&quot; Investigating the Human  response to Evasive Webpages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Draganovic%2C+A">Ajka Draganovic</a>, 
<a href="/search/cs?searchtype=author&query=Dambra%2C+S">Savino Dambra</a>, 
<a href="/search/cs?searchtype=author&query=Iuit%2C+J+A">Javier Aldana Iuit</a>, 
<a href="/search/cs?searchtype=author&query=Roundy%2C+K">Kevin Roundy</a>, 
<a href="/search/cs?searchtype=author&query=Apruzzese%2C+G">Giovanni Apruzzese</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Phishing websites are everywhere, and countermeasures based on static
blocklists cannot cope with such a threat. To address this problem,
state-of-the-art solutions entail the application of machine learning (ML) to
detect phishing websites by checking if they visually resemble webpages of
well-known brands. These techniques have achieved promising results in research
and, consequently, some security companies began to deploy them also in their
phishing detection systems (PDS). However, ML methods are not perfect and some
samples are bound to bypass even production-grade PDS.
<br />In this paper, we scrutinize whether 'genuine phishing websites' that evade
'commercial ML-based PDS' represent a problem "in reality". Although nobody
likes landing on a phishing webpage, a false negative may not lead to serious
consequences if the users (i.e., the actual target of phishing) can recognize
that "something is phishy". Practically, we carry out the first user-study
(N=126) wherein we assess whether unsuspecting users (having diverse
backgrounds) are deceived by 'adversarial' phishing webpages that evaded a real
PDS. We found that some well-crafted adversarial webpages can trick most
participants (even IT experts), albeit others are easily recognized by most
users. Our study is relevant for practitioners, since it allows prioritizing
phishing webpages that simultaneously fool (i) machines and (ii) humans --
i.e., their intended targets.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16388" title="Abstract">arXiv:2311.16388</a> [<a href="/pdf/2311.16388" title="Download PDF">pdf</a>, <a href="/format/2311.16388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Process of Data Labeling in Cybersecurity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Braun%2C+T">Tobias Braun</a>, 
<a href="/search/cs?searchtype=author&query=Pekaric%2C+I">Irdin Pekaric</a>, 
<a href="/search/cs?searchtype=author&query=Apruzzese%2C+G">Giovanni Apruzzese</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Many domains now leverage the benefits of Machine Learning (ML), which
promises solutions that can autonomously learn to solve complex tasks by
training over some data. Unfortunately, in cyberthreat detection, high-quality
data is hard to come by. Moreover, for some specific applications of ML, such
data must be labeled by human operators. Many works "assume" that labeling is
tough/challenging/costly in cyberthreat detection, thereby proposing solutions
to address such a hurdle. Yet, we found no work that specifically addresses the
process of labeling 'from the viewpoint of ML security practitioners'. This is
a problem: to this date, it is still mostly unknown how labeling is done in
practice -- thereby preventing one from pinpointing "what is needed" in the
real world.
<br />In this paper, we take the first step to build a bridge between academic
research and security practice in the context of data labeling. First, we reach
out to five subject matter experts and carry out open interviews to identify
pain points in their labeling routines. Then, by using our findings as a
scaffold, we conduct a user study with 13 practitioners from large security
companies, and ask detailed questions on subjects such as active learning,
costs of labeling, and revision of labels. Finally, we perform proof-of-concept
experiments addressing labeling-related aspects in cyberthreat detection that
are sometimes overlooked in research. Altogether, our contributions and
recommendations serve as a stepping stone to future endeavors aimed at
improving the quality and robustness of ML-driven security systems. We release
our resources.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16392" title="Abstract">arXiv:2311.16392</a> [<a href="/pdf/2311.16392" title="Download PDF">pdf</a>, <a href="/format/2311.16392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-defender Security Games with Schedules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zimeng Song</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+C+K">Chun Kai Ling</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+F">Fei Fang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of the paper accepted to GameSec 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Stackelberg Security Games are often used to model strategic interactions in
high-stakes security settings. The majority of existing models focus on
single-defender settings where a single entity assumes command of all security
assets. However, many realistic scenarios feature multiple heterogeneous
defenders with their own interests and priorities embedded in a more complex
system. Furthermore, defenders rarely choose targets to protect. Instead, they
have a multitude of defensive resources or schedules at its disposal, each with
different protective capabilities. In this paper, we study security games
featuring multiple defenders and schedules simultaneously. We show that unlike
prior work on multi-defender security games, the introduction of schedules can
cause non-existence of equilibrium even under rather restricted environments.
We prove that under the mild restriction that any subset of a schedule is also
a schedule, non-existence of equilibrium is not only avoided, but can be
computed in polynomial time in games with two defenders. Under additional
assumptions, our algorithm can be extended to games with more than two
defenders and its computation scaled up in special classes of games with
compactly represented schedules such as those used in patrolling applications.
Experimental results suggest that our methods scale gracefully with game size,
making our algorithms amongst the few that can tackle multiple heterogeneous
defenders.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16396" title="Abstract">arXiv:2311.16396</a> [<a href="/pdf/2311.16396" title="Download PDF">pdf</a>, <a href="/format/2311.16396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Effective Secure Code Reviews: An Empirical Study of  Security-Related Coding Weaknesses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Charoenwet%2C+W">Wachiraphan Charoenwet</a>, 
<a href="/search/cs?searchtype=author&query=Thongtanunam%2C+P">Patanamon Thongtanunam</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+V">Van-Thuan Pham</a>, 
<a href="/search/cs?searchtype=author&query=Treude%2C+C">Christoph Treude</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Identifying security issues early is encouraged to reduce the latent negative
impacts on software systems. Code review is a widely-used method that allows
developers to manually inspect modified code, catching security issues during a
software development cycle. However, existing code review studies often focus
on known vulnerabilities, neglecting coding weaknesses, which can introduce
real-world security issues that are more visible through code review. The
practices of code reviews in identifying such coding weaknesses are not yet
fully investigated.
<br />To better understand this, we conducted an empirical case study in two large
open-source projects, OpenSSL and PHP. Based on 135,560 code review comments,
we found that reviewers raised security concerns in 35 out of 40 coding
weakness categories. Surprisingly, some coding weaknesses related to past
vulnerabilities, such as memory errors and resource management, were discussed
less often than the vulnerabilities. Developers attempted to address raised
security concerns in many cases (39%-41%), but a substantial portion was merely
acknowledged (30%-36%), and some went unfixed due to disagreements about
solutions (18%-20%). This highlights that coding weaknesses can slip through
code review even when identified. Our findings suggest that reviewers can
identify various coding weaknesses leading to security issues during code
reviews. However, these results also reveal shortcomings in current code review
practices, indicating the need for more effective mechanisms or support for
increasing awareness of security issue management in code reviews.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16406" title="Abstract">arXiv:2311.16406</a> [<a href="/pdf/2311.16406" title="Download PDF">pdf</a>, <a href="/format/2311.16406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DIAC: Design Exploration of Intermittent-Aware Computing Realizing  Batteryless Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tabrizchi%2C+S">Sepehr Tabrizchi</a>, 
<a href="/search/cs?searchtype=author&query=Angizi%2C+S">Shaahin Angizi</a>, 
<a href="/search/cs?searchtype=author&query=Roohi%2C+A">Arman Roohi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, will be appeared in Design, Automation and Test in Europe Conference 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Battery-powered IoT devices face challenges like cost, maintenance, and
environmental sustainability, prompting the emergence of batteryless
energy-harvesting systems that harness ambient sources. However, their
intermittent behavior can disrupt program execution and cause data loss,
leading to unpredictable outcomes. Despite exhaustive studies employing
conventional checkpoint methods and intricate programming paradigms to address
these pitfalls, this paper proposes an innovative systematic methodology,
namely DIAC. The DIAC synthesis procedure enhances the performance and
efficiency of intermittent computing systems, with a focus on maximizing
forward progress and minimizing the energy overhead imposed by distinct memory
arrays for backup. Then, a finite-state machine is delineated, encapsulating
the core operations of an IoT node, sense, compute, transmit, and sleep states.
First, we validate the robustness and functionalities of a DIAC-based design in
the presence of power disruptions. DIAC is then applied to a wide range of
benchmarks, including ISCAS-89, MCNS, and ITC-99. The simulation results
substantiate the power-delay-product (PDP) benefits. For example, results for
complex MCNC benchmarks indicate a PDP improvement of 61%, 56%, and 38% on
average compared to three alternative techniques, evaluated at 45 nm.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16409" title="Abstract">arXiv:2311.16409</a> [<a href="/pdf/2311.16409" title="Download PDF">pdf</a>, <a href="/format/2311.16409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Deep Q-Learning based, Base-Station Connectivity-Aware, Decentralized  Pheromone Mobility Model for Autonomous UAV Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Devaraju%2C+S">Shreyas Devaraju</a>, 
<a href="/search/cs?searchtype=author&query=Ihler%2C+A">Alexander Ihler</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sunil Kumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">UAV networks consisting of low SWaP (size, weight, and power), fixed-wing
UAVs are used in many applications, including area monitoring, search and
rescue, surveillance, and tracking. Performing these operations efficiently
requires a scalable, decentralized, autonomous UAV network architecture with
high network connectivity. Whereas fast area coverage is needed for quickly
sensing the area, strong node degree and base station (BS) connectivity are
needed for UAV control and coordination and for transmitting sensed information
to the BS in real time. However, the area coverage and connectivity exhibit a
fundamental trade-off: maintaining connectivity restricts the UAVs' ability to
explore. In this paper, we first present a node degree and BS
connectivity-aware distributed pheromone (BS-CAP) mobility model to
autonomously coordinate the UAV movements in a decentralized UAV network. This
model maintains a desired connectivity among 1-hop neighbors and to the BS
while achieving fast area coverage. Next, we propose a deep Q-learning policy
based BS-CAP model (BSCAP-DQN) to further tune and improve the coverage and
connectivity trade-off. Since it is not practical to know the complete topology
of such a network in real time, the proposed mobility models work online, are
fully distributed, and rely on neighborhood information. Our simulations
demonstrate that both proposed models achieve efficient area coverage and
desired node degree and BS connectivity, improving significantly over existing
schemes.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16410" title="Abstract">arXiv:2311.16410</a> [<a href="/pdf/2311.16410" title="Download PDF">pdf</a>, <a href="/format/2311.16410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reduced-order modeling for parameterized PDEs via implicit neural  representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wen%2C+T">Tianshu Wen</a>, 
<a href="/search/math?searchtype=author&query=Lee%2C+K">Kookjin Lee</a>, 
<a href="/search/math?searchtype=author&query=Choi%2C+Y">Youngsoo Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures, Machine Learning and the Physical Sciences Workshop, NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">We present a new data-driven reduced-order modeling approach to efficiently
solve parametrized partial differential equations (PDEs) for many-query
problems. This work is inspired by the concept of implicit neural
representation (INR), which models physics signals in a continuous manner and
independent of spatial/temporal discretization. The proposed framework encodes
PDE and utilizes a parametrized neural ODE (PNODE) to learn latent dynamics
characterized by multiple PDE parameters. PNODE can be inferred by a
hypernetwork to reduce the potential difficulties in learning PNODE due to a
complex multilayer perceptron (MLP). The framework uses an INR to decode the
latent dynamics and reconstruct accurate PDE solutions. Further, a
physics-informed loss is also introduced to correct the prediction of unseen
parameter instances. Incorporating the physics-informed loss also enables the
model to be fine-tuned in an unsupervised manner on unseen PDE parameters. A
numerical experiment is performed on a two-dimensional Burgers equation with a
large variation of PDE parameters. We evaluate the proposed method at a large
Reynolds number and obtain up to speedup of O(10^3) and ~1% relative error to
the ground truth values.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16416" title="Abstract">arXiv:2311.16416</a> [<a href="/pdf/2311.16416" title="Download PDF">pdf</a>, <a href="/format/2311.16416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Combinatorial Approach to Robust PCA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kong%2C+W">Weihao Kong</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+M">Mingda Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+R">Rajat Sen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at ITCS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">We study the problem of recovering Gaussian data under adversarial
corruptions when the noises are low-rank and the corruptions are on the
coordinate level. Concretely, we assume that the Gaussian noises lie in an
unknown $k$-dimensional subspace $U \subseteq \mathbb{R}^d$, and $s$ randomly
chosen coordinates of each data point fall into the control of an adversary.
This setting models the scenario of learning from high-dimensional yet
structured data that are transmitted through a highly-noisy channel, so that
the data points are unlikely to be entirely clean.
<br />Our main result is an efficient algorithm that, when $ks^2 = O(d)$, recovers
every single data point up to a nearly-optimal $\ell_1$ error of $\tilde
O(ks/d)$ in expectation. At the core of our proof is a new analysis of the
well-known Basis Pursuit (BP) method for recovering a sparse signal, which is
known to succeed under additional assumptions (e.g., incoherence or the
restricted isometry property) on the underlying subspace $U$. In contrast, we
present a novel approach via studying a natural combinatorial problem and show
that, over the randomness in the support of the sparse signal, a
high-probability error bound is possible even if the subspace $U$ is arbitrary.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16417" title="Abstract">arXiv:2311.16417</a> [<a href="/pdf/2311.16417" title="Download PDF">pdf</a>, <a href="/format/2311.16417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Challenges and Opportunities to Enable Large-Scale Computing via  Heterogeneous Chiplets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhuoping Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shixin Ji</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xingzhen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+J">Jinming Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weifeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jani%2C+D">Dharmesh Jani</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Peipei Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Fast-evolving artificial intelligence (AI) algorithms such as large language
models have been driving the ever-increasing computing demands in today's data
centers. Heterogeneous computing with domain-specific architectures (DSAs)
brings many opportunities when scaling up and scaling out the computing system.
In particular, heterogeneous chiplet architecture is favored to keep scaling up
and scaling out the system as well as to reduce the design complexity and the
cost stemming from the traditional monolithic chip design. However, how to
interconnect computing resources and orchestrate heterogeneous chiplets is the
key to success. In this paper, we first discuss the diversity and evolving
demands of different AI workloads. We discuss how chiplet brings better cost
efficiency and shorter time to market. Then we discuss the challenges in
establishing chiplet interface standards, packaging, and security issues. We
further discuss the software programming challenges in chiplet systems.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16419" title="Abstract">arXiv:2311.16419</a> [<a href="/pdf/2311.16419" title="Download PDF">pdf</a>, <a href="/format/2311.16419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A review on the charging station planning and fleet operation for  electric freight vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Alam%2C+M+R">Md Rakibul Alam</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+Z">Zhaomiao Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 43 pages, 4 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Freight electrification introduces new opportunities and challenges for
planning and operation. Although research on charging infrastructure planning
and operation is widely available for general electric vehicles, unique
physical and operational characteristics of EFVs coupled with specific patterns
of logistics require dedicated research. This paper presents a comprehensive
literature review to gain a better understanding of the state-of-the-art
research efforts related to planning (charging station siting and sizing) and
operation (routing, charge scheduling, platoon scheduling, and fleet sizing)
for EFVs. We classified the existing literature based on the research topics,
innovations, methodologies, and solution approaches, and future research
directions are identified. Different types of methodologies, such as heuristic,
simulation, and mathematical programming approaches, were applied in the
reviewed literature where mathematical models account for the majority. We
further narrated the specific modeling considerations for different logistic
patterns and research goals with proper reasoning. To solve the proposed
models, different solution approaches, including exact algorithms,
metaheuristic algorithms, and software simulation, were evaluated in terms of
applicability, advantages, and disadvantages. This paper helps to draw more
attention to the planning and operation issues and solutions for freight
electrification and facilitates future studies on EFV to ensure a smooth
transition to a clean freight system.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16420" title="Abstract">arXiv:2311.16420</a> [<a href="/pdf/2311.16420" title="Download PDF">pdf</a>, <a href="/format/2311.16420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-free Test Time Adaptation for Out-Of-Distribution Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">YiFan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tian Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+K">Kun Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+R">Rong Jin</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+T">Tieniu Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Out-of-distribution (OOD) detection is essential for the reliability of ML
models. Most existing methods for OOD detection learn a fixed decision
criterion from a given in-distribution dataset and apply it universally to
decide if a data point is OOD. Recent work~\cite{fang2022is} shows that given
only in-distribution data, it is impossible to reliably detect OOD data without
extra assumptions. Motivated by the theoretical result and recent exploration
of test-time adaptation methods, we propose a Non-Parametric Test Time
\textbf{Ada}ptation framework for \textbf{O}ut-Of-\textbf{D}istribution
\textbf{D}etection (\abbr). Unlike conventional methods, \abbr utilizes online
test samples for model adaptation during testing, enhancing adaptability to
changing data distributions. The framework incorporates detected OOD instances
into decision-making, reducing false positive rates, particularly when ID and
OOD distributions overlap significantly. We demonstrate the effectiveness of
\abbr through comprehensive experiments on multiple OOD detection benchmarks,
extensive empirical studies show that \abbr significantly improves the
performance of OOD detection over state-of-the-art methods. Specifically, \abbr
reduces the false positive rate (FPR95) by $23.23\%$ on the CIFAR-10 benchmarks
and $38\%$ on the ImageNet-1k benchmarks compared to the advanced methods.
Lastly, we theoretically verify the effectiveness of \abbr.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16421" title="Abstract">arXiv:2311.16421</a> [<a href="/pdf/2311.16421" title="Download PDF">pdf</a>, <a href="/format/2311.16421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CDEval: A Benchmark for Measuring the Cultural Dimensions of Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuhang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yanxu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+C">Chao Kong</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+S">Shuyu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+X">Xiaoyuan Yi</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Sang%2C+J">Jitao Sang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in process
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">As the scaling of Large Language Models (LLMs) has dramatically enhanced
their capabilities, there has been a growing focus on the alignment problem to
ensure their responsible and ethical use. While existing alignment efforts
predominantly concentrate on universal values such as the HHH principle, the
aspect of culture, which is inherently pluralistic and diverse, has not
received adequate attention. This work introduces a new benchmark, CDEval,
aimed at evaluating the cultural dimensions of LLMs. CDEval is constructed by
incorporating both GPT-4's automated generation and human verification,
covering six cultural dimensions across seven domains. Our comprehensive
experiments provide intriguing insights into the culture of mainstream LLMs,
highlighting both consistencies and variations across different dimensions and
domains. The findings underscore the importance of integrating cultural
considerations in LLM development, particularly for applications in diverse
cultural settings. Through CDEval, we aim to broaden the horizon of LLM
alignment research by including cultural dimensions, thus providing a more
holistic framework for the future development and evaluation of LLMs. This
benchmark serves as a valuable resource for cultural studies in LLMs, paving
the way for more culturally aware and sensitive models.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16424" title="Abstract">arXiv:2311.16424</a> [<a href="/pdf/2311.16424" title="Download PDF">pdf</a>, <a href="/format/2311.16424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Manifold Preserving Guided Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yutong He</a>, 
<a href="/search/cs?searchtype=author&query=Murata%2C+N">Naoki Murata</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+C">Chieh-Hsin Lai</a>, 
<a href="/search/cs?searchtype=author&query=Takida%2C+Y">Yuhta Takida</a>, 
<a href="/search/cs?searchtype=author&query=Uesaka%2C+T">Toshimitsu Uesaka</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dongjun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+W">Wei-Hsiang Liao</a>, 
<a href="/search/cs?searchtype=author&query=Mitsufuji%2C+Y">Yuki Mitsufuji</a>, 
<a href="/search/cs?searchtype=author&query=Kolter%2C+J+Z">J. Zico Kolter</a>, 
<a href="/search/cs?searchtype=author&query=Salakhutdinov%2C+R">Ruslan Salakhutdinov</a>, 
<a href="/search/cs?searchtype=author&query=Ermon%2C+S">Stefano Ermon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Despite the recent advancements, conditional image generation still faces
challenges of cost, generalizability, and the need for task-specific training.
In this paper, we propose Manifold Preserving Guided Diffusion (MPGD), a
training-free conditional generation framework that leverages pretrained
diffusion models and off-the-shelf neural networks with minimal additional
inference cost for a broad range of tasks. Specifically, we leverage the
manifold hypothesis to refine the guided diffusion steps and introduce a
shortcut algorithm in the process. We then propose two methods for on-manifold
training-free guidance using pre-trained autoencoders and demonstrate that our
shortcut inherently preserves the manifolds when applied to latent diffusion
models. Our experiments show that MPGD is efficient and effective for solving a
variety of conditional generation applications in low-compute settings, and can
consistently offer up to 3.8x speed-ups with the same number of diffusion steps
while maintaining high sample quality compared to the baselines.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16429" title="Abstract">arXiv:2311.16429</a> [<a href="/pdf/2311.16429" title="Download PDF">pdf</a>, <a href="/format/2311.16429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Transformative Influence of Large Language Models on Software  Development
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jalil%2C+S">Sajed Jalil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 1 figure, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">The increasing adoption and commercialization of generalized Large Language
Models (LLMs) have profoundly impacted various aspects of our daily lives.
Initially embraced by the computer science community, the versatility of LLMs
has found its way into diverse domains. In particular, the software engineering
realm has witnessed the most transformative changes. With LLMs increasingly
serving as AI Pair Programming Assistants spurred the development of
specialized models aimed at aiding software engineers. Although this new
paradigm offers numerous advantages, it also presents critical challenges and
open problems. To identify the potential and prevailing obstacles, we
systematically reviewed contemporary scholarly publications, emphasizing the
perspectives of software developers and usability concerns. Preliminary
findings underscore pressing concerns about data privacy, bias, and
misinformation. Additionally, we identified several usability challenges,
including prompt engineering, increased cognitive demands, and mistrust.
Finally, we introduce 12 open problems that we have identified through our
survey, covering these various domains.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16431" title="Abstract">arXiv:2311.16431</a> [<a href="/pdf/2311.16431" title="Download PDF">pdf</a>, <a href="/format/2311.16431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An exact mathematical description of computation with transient  spatiotemporal dynamics in a complex-valued neural network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Budzinski%2C+R+C">Roberto C. Budzinski</a>, 
<a href="/search/cs?searchtype=author&query=Busch%2C+A+N">Alexandra N. Busch</a>, 
<a href="/search/cs?searchtype=author&query=Mestern%2C+S">Samuel Mestern</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+E">Erwan Martin</a>, 
<a href="/search/cs?searchtype=author&query=Liboni%2C+L+H+B">Luisa H. B. Liboni</a>, 
<a href="/search/cs?searchtype=author&query=Pasini%2C+F+W">Federico W. Pasini</a>, 
<a href="/search/cs?searchtype=author&query=Min%C3%A1%C4%8D%2C+J">J&#xe1;n Min&#xe1;&#x10d;</a>, 
<a href="/search/cs?searchtype=author&query=Coleman%2C+T">Todd Coleman</a>, 
<a href="/search/cs?searchtype=author&query=Inoue%2C+W">Wataru Inoue</a>, 
<a href="/search/cs?searchtype=author&query=Muller%2C+L+E">Lyle E. Muller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">We study a complex-valued neural network (cv-NN) with linear, time-delayed
interactions. We report the cv-NN displays sophisticated spatiotemporal
dynamics, including partially synchronized ``chimera'' states. We then use
these spatiotemporal dynamics, in combination with a nonlinear readout, for
computation. The cv-NN can instantiate dynamics-based logic gates, encode
short-term memories, and mediate secure message passing through a combination
of interactions and time delays. The computations in this system can be fully
described in an exact, closed-form mathematical expression. Finally, using
direct intracellular recordings of neurons in slices from neocortex, we
demonstrate that computations in the cv-NN are decodable by living biological
neurons. These results demonstrate that complex-valued linear systems can
perform sophisticated computations, while also being exactly solvable. Taken
together, these results open future avenues for design of highly adaptable,
bio-hybrid computing systems that can interface seamlessly with other neural
networks.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16432" title="Abstract">arXiv:2311.16432</a> [<a href="/pdf/2311.16432" title="Download PDF">pdf</a>, <a href="/format/2311.16432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text-Driven Image Editing via Learnable Regions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yuanze Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yi-Wen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+Y">Yi-Hsuan Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Lu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project webpage: <a href="https://yuanze-lin.me/LearnableRegions_page">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Language has emerged as a natural interface for image editing. In this paper,
we introduce a method for region-based image editing driven by textual prompts,
without the need for user-provided masks or sketches. Specifically, our
approach leverages an existing pretrained text-to-image model and introduces a
bounding box generator to find the edit regions that are aligned with the
textual prompts. We show that this simple approach enables flexible editing
that is compatible with current image generation models, and is able to handle
complex prompts featuring multiple objects, complex sentences or long
paragraphs. We conduct an extensive user study to compare our method against
state-of-the-art methods. Experiments demonstrate the competitive performance
of our method in manipulating images with high fidelity and realism that align
with the language descriptions provided. Our project webpage:
https://yuanze-lin.me/LearnableRegions_page.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16441" title="Abstract">arXiv:2311.16441</a> [<a href="/pdf/2311.16441" title="Download PDF">pdf</a>, <a href="/format/2311.16441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ControlRec: Bridging the Semantic Gap between Language Model and  Personalized Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+J">Junyan Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haitao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+Z">Zhaolin Hong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yiping Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xingxing Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">The successful integration of large language models (LLMs) into
recommendation systems has proven to be a major breakthrough in recent studies,
paving the way for more generic and transferable recommendations. However, LLMs
struggle to effectively utilize user and item IDs, which are crucial
identifiers for successful recommendations. This is mainly due to their
distinct representation in a semantic space that is different from the natural
language (NL) typically used to train LLMs. To tackle such issue, we introduce
ControlRec, an innovative Contrastive prompt learning framework for
Recommendation systems. ControlRec treats user IDs and NL as heterogeneous
features and encodes them individually. To promote greater alignment and
integration between them in the semantic space, we have devised two auxiliary
contrastive objectives: (1) Heterogeneous Feature Matching (HFM) aligning item
description with the corresponding ID or user's next preferred ID based on
their interaction sequence, and (2) Instruction Contrastive Learning (ICL)
effectively merging these two crucial data sources by contrasting probability
distributions of output sequences generated by diverse tasks. Experimental
results on four public real-world datasets demonstrate the effectiveness of the
proposed method on improving model performance.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16442" title="Abstract">arXiv:2311.16442</a> [<a href="/pdf/2311.16442" title="Download PDF">pdf</a>, <a href="/format/2311.16442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enabling Fast 2-bit LLM on GPUs: Memory Alignment, Sparse Outlier, and  Asynchronous Dequantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shiyao Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiaming Xu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+Y">Yaoxiu Lian</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+G">Guohao Dai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Large language models (LLMs) have demonstrated impressive abilities in
various domains while the inference cost is expensive. The state-of-the-art
methods use 2-bit quantization for mainstream LLMs. However, challenges still
exist: (1) Nonnegligible accuracy loss for 2-bit quantization. Weights are
quantized by groups, while the ranges of weights are large in some groups,
resulting in large quantization errors and nonnegligible accuracy loss (e.g.
&gt;3% for Llama2-7b with 2-bit quantization in GPTQ and Greenbit). (2) Limited
accuracy improvement by adding 4-bit weights. Increasing 10% extra average bit
more 4-bit weights only leads to &lt;0.5% accuracy improvement on a quantized
Llama2-7b. (3) Time-consuming dequantization operations on GPUs. The
dequantization operations lead to &gt;50% execution time, hindering the potential
of reducing LLM inference cost. To tackle these challenges, we propose the
following techniques: (1) We only quantize a small fraction of groups with the
larger range using 4-bit with memory alignment consideration on GPUs. (2) We
point out that the distribution of the sparse outliers with larger weights is
different in 2-bit and 4-bit groups, and only a small fraction of outliers
require 16-bit quantization. Such design leads to &gt;0.5% accuracy improvement
with &lt;3% average increased bit for Llama2-7b. (3) We design the asynchronous
dequantization on GPUs, leading to up to 3.92X speedup. We conduct extensive
experiments on different model families and model sizes. We achieve 2.85-bit
for each weight and the end-to-end speedup for Llama2-7b is 1.74X over the
original model, and we reduce both runtime cost and hardware cost by up to
2.70X and 2.81X with less GPU requirements.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16444" title="Abstract">arXiv:2311.16444</a> [<a href="/pdf/2311.16444" title="Download PDF">pdf</a>, <a href="/format/2311.16444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exo2EgoDVC: Dense Video Captioning of Egocentric Procedural Activities  Using Web Instructional Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ohkawa%2C+T">Takehiko Ohkawa</a>, 
<a href="/search/cs?searchtype=author&query=Yagi%2C+T">Takuma Yagi</a>, 
<a href="/search/cs?searchtype=author&query=Nishimura%2C+T">Taichi Nishimura</a>, 
<a href="/search/cs?searchtype=author&query=Furuta%2C+R">Ryosuke Furuta</a>, 
<a href="/search/cs?searchtype=author&query=Hashimoto%2C+A">Atsushi Hashimoto</a>, 
<a href="/search/cs?searchtype=author&query=Ushiku%2C+Y">Yoshitaka Ushiku</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+Y">Yoichi Sato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">We propose a novel benchmark for cross-view knowledge transfer of dense video
captioning, adapting models from web instructional videos with exocentric views
to an egocentric view. While dense video captioning (predicting time segments
and their captions) is primarily studied with exocentric videos (e.g.,
YouCook2), benchmarks with egocentric videos are restricted due to data
scarcity. To overcome the limited video availability, transferring knowledge
from abundant exocentric web videos is demanded as a practical approach.
However, learning the correspondence between exocentric and egocentric views is
difficult due to their dynamic view changes. The web videos contain mixed views
focusing on either human body actions or close-up hand-object interactions,
while the egocentric view is constantly shifting as the camera wearer moves.
This necessitates the in-depth study of cross-view transfer under complex view
changes. In this work, we first create a real-life egocentric dataset (EgoYC2)
whose captions are shared with YouCook2, enabling transfer learning between
these datasets assuming their ground-truth is accessible. To bridge the view
gaps, we propose a view-invariant learning method using adversarial training in
both the pre-training and fine-tuning stages. While the pre-training is
designed to learn invariant features against the mixed views in the web videos,
the view-invariant fine-tuning further mitigates the view gaps between both
datasets. We validate our proposed method by studying how effectively it
overcomes the view change problem and efficiently transfers the knowledge to
the egocentric domain. Our benchmark pushes the study of the cross-view
transfer into a new task domain of dense video captioning and will envision
methodologies to describe egocentric videos in natural language.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16445" title="Abstract">arXiv:2311.16445</a> [<a href="/pdf/2311.16445" title="Download PDF">pdf</a>, <a href="/format/2311.16445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLAP: Contrastive Learning with Augmented Prompts for Robustness on  Pretrained Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yichao Cai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuhang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J+Q">Javen Qinfeng Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Contrastive vision-language models, e.g., CLIP, have garnered substantial
attention for their exceptional generalization capabilities. However, their
robustness to perturbations has ignited concerns. Existing strategies typically
reinforce their resilience against adversarial examples by enabling the image
encoder to "see" these perturbed examples, often necessitating a complete
retraining of the image encoder on both natural and adversarial samples. In
this study, we propose a new method to enhance robustness solely through text
augmentation, eliminating the need for retraining the image encoder on
adversarial examples. Our motivation arises from the realization that text and
image data inherently occupy a shared latent space, comprising latent content
variables and style variables. This insight suggests the feasibility of
learning to disentangle these latent content variables using text data
exclusively. To accomplish this, we introduce an effective text augmentation
method that focuses on modifying the style while preserving the content in the
text data. By changing the style part of the text data, we empower the text
encoder to emphasize latent content variables, ultimately enhancing the
robustness of vision-language models. Our experiments across various datasets
demonstrate substantial improvements in the robustness of the pre-trained CLIP
model.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16446" title="Abstract">arXiv:2311.16446</a> [<a href="/pdf/2311.16446" title="Download PDF">pdf</a>, <a href="/format/2311.16446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Centre Stage: Centricity-based Audio-Visual Temporal Action Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hanyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mirmehdi%2C+M">Majid Mirmehdi</a>, 
<a href="/search/cs?searchtype=author&query=Damen%2C+D">Dima Damen</a>, 
<a href="/search/cs?searchtype=author&query=Perrett%2C+T">Toby Perrett</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to VUA workshop at BMVC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Previous one-stage action detection approaches have modelled temporal
dependencies using only the visual modality. In this paper, we explore
different strategies to incorporate the audio modality, using multi-scale
cross-attention to fuse the two modalities. We also demonstrate the correlation
between the distance from the timestep to the action centre and the accuracy of
the predicted boundaries. Thus, we propose a novel network head to estimate the
closeness of timesteps to the action centre, which we call the centricity
score. This leads to increased confidence for proposals that exhibit more
precise boundaries. Our method can be integrated with other one-stage
anchor-free architectures and we demonstrate this on three recent baselines on
the EPIC-Kitchens-100 action detection benchmark where we achieve
state-of-the-art performance. Detailed ablation studies showcase the benefits
of fusing audio and our proposed centricity scores. Code and models for our
proposed method are publicly available at
https://github.com/hanielwang/Audio-Visual-TAD.git
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16450" title="Abstract">arXiv:2311.16450</a> [<a href="/pdf/2311.16450" title="Download PDF">pdf</a>, <a href="/format/2311.16450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Typhoon Intensity Prediction with Vision Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huanxin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+P">Pengshuai Yin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Huichou Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingyao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruirui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiatian Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 figures, accepted by Tackling Climate Change with Machine Learning: workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Predicting typhoon intensity accurately across space and time is crucial for
issuing timely disaster warnings and facilitating emergency response. This has
vast potential for minimizing life losses and property damages as well as
reducing economic and environmental impacts. Leveraging satellite imagery for
scenario analysis is effective but also introduces additional challenges due to
the complex relations among clouds and the highly dynamic context. Existing
deep learning methods in this domain rely on convolutional neural networks
(CNNs), which suffer from limited per-layer receptive fields. This limitation
hinders their ability to capture long-range dependencies and global contextual
knowledge during inference. In response, we introduce a novel approach, namely
"Typhoon Intensity Transformer" (Tint), which leverages self-attention
mechanisms with global receptive fields per layer. Tint adopts a
sequence-to-sequence feature representation learning perspective. It begins by
cutting a given satellite image into a sequence of patches and recursively
employs self-attention operations to extract both local and global contextual
relations between all patch pairs simultaneously, thereby enhancing per-patch
feature representation learning. Extensive experiments on a publicly available
typhoon benchmark validate the efficacy of Tint in comparison with both
state-of-the-art deep learning and conventional meteorological methods. Our
code is available at https://github.com/chen-huanxin/Tint.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16452" title="Abstract">arXiv:2311.16452</a> [<a href="/pdf/2311.16452" title="Download PDF">pdf</a>, <a href="/format/2311.16452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case  Study in Medicine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nori%2C+H">Harsha Nori</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y+T">Yin Tat Lee</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Carignan%2C+D">Dean Carignan</a>, 
<a href="/search/cs?searchtype=author&query=Edgar%2C+R">Richard Edgar</a>, 
<a href="/search/cs?searchtype=author&query=Fusi%2C+N">Nicolo Fusi</a>, 
<a href="/search/cs?searchtype=author&query=King%2C+N">Nicholas King</a>, 
<a href="/search/cs?searchtype=author&query=Larson%2C+J">Jonathan Larson</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanzhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weishung Liu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+R">Renqian Luo</a>, 
<a href="/search/cs?searchtype=author&query=McKinney%2C+S+M">Scott Mayer McKinney</a>, 
<a href="/search/cs?searchtype=author&query=Ness%2C+R+O">Robert Osazuwa Ness</a>, 
<a href="/search/cs?searchtype=author&query=Poon%2C+H">Hoifung Poon</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+T">Tao Qin</a>, 
<a href="/search/cs?searchtype=author&query=Usuyama%2C+N">Naoto Usuyama</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+C">Chris White</a>, 
<a href="/search/cs?searchtype=author&query=Horvitz%2C+E">Eric Horvitz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Generalist foundation models such as GPT-4 have displayed surprising
capabilities in a wide variety of domains and tasks. Yet, there is a prevalent
assumption that they cannot match specialist capabilities of fine-tuned models.
For example, most explorations to date on medical competency benchmarks have
leveraged domain-specific training, as exemplified by efforts on BioGPT and
Med-PaLM. We build on a prior study of GPT-4's capabilities on medical
challenge benchmarks in the absence of special training. Rather than using
simple prompting to highlight the model's out-of-the-box capabilities, we
perform a systematic exploration of prompt engineering. We find that prompting
innovation can unlock deeper specialist capabilities and show that GPT-4 easily
tops prior leading results for medical benchmarks. The prompting methods we
explore are general purpose, and make no specific use of domain expertise,
removing the need for expert-curated content. Our experimental design carefully
controls for overfitting during the prompt engineering process. We introduce
Medprompt, based on a composition of several prompting strategies. With
Medprompt, GPT-4 achieves state-of-the-art results on all nine of the benchmark
datasets in the MultiMedQA suite. The method outperforms leading specialist
models such as Med-PaLM 2 by a significant margin with an order of magnitude
fewer calls to the model. Steering GPT-4 with Medprompt achieves a 27%
reduction in error rate on the MedQA dataset over the best methods to date
achieved with specialist models and surpasses a score of 90% for the first
time. Beyond medical problems, we show the power of Medprompt to generalize to
other domains and provide evidence for the broad applicability of the approach
via studies of the strategy on exams in electrical engineering, machine
learning, philosophy, accounting, law, nursing, and clinical psychology.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16454" title="Abstract">arXiv:2311.16454</a> [<a href="/pdf/2311.16454" title="Download PDF">pdf</a>, <a href="/format/2311.16454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An hp-Adaptive Sampling Algorithm on Dispersion Relation Reconstruction  for 2D Photonic Crystals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+Y">Yueqi Wang</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+G">Guanglian Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Computing the dispersion relation for two-dimensional photonic crystals is a
notoriously challenging task: It involves solving parameterized Helmholtz
eigenvalue problems with high-contrast coefficients. To resolve the challenge,
we propose a novel hp-adaptive sampling scheme that can detect singular points
via adaptive mesh refinement in the parameter domain, and meanwhile, allow for
adaptively enriching the local polynomial spaces on the elements that do not
contain singular points. In this way, we obtain an element-wise interpolation
on an adaptive mesh. We derive an exponential convergence rate when the number
of singular points is finite, and a first-order convergence rate otherwise.
Numerical tests are provided to illustrate its performance.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16456" title="Abstract">arXiv:2311.16456</a> [<a href="/pdf/2311.16456" title="Download PDF">pdf</a>, <a href="/format/2311.16456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spiking Neural Networks with Dynamic Time Steps for Vision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Datta%2C+G">Gourav Datta</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zeyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Anni Li</a>, 
<a href="/search/cs?searchtype=author&query=Beerel%2C+P+A">Peter A. Beerel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Spiking Neural Networks (SNNs) have emerged as a popular spatio-temporal
computing paradigm for complex vision tasks. Recently proposed SNN training
algorithms have significantly reduced the number of time steps (down to 1) for
improved latency and energy efficiency, however, they target only convolutional
neural networks (CNN). These algorithms, when applied on the recently
spotlighted vision transformers (ViT), either require a large number of time
steps or fail to converge. Based on analysis of the histograms of the ANN and
SNN activation maps, we hypothesize that each ViT block has a different
sensitivity to the number of time steps. We propose a novel training framework
that dynamically allocates the number of time steps to each ViT module
depending on a trainable score assigned to each timestep. In particular, we
generate a scalar binary time step mask that filters spikes emitted by each
neuron in a leaky-integrate-and-fire (LIF) layer. The resulting SNNs have high
activation sparsity and require only accumulate operations (AC), except for the
input embedding layer, in contrast to expensive multiply-and-accumulates (MAC)
needed in traditional ViTs. This yields significant improvements in energy
efficiency. We evaluate our training framework and resulting SNNs on image
recognition tasks including CIFAR10, CIFAR100, and ImageNet with different ViT
architectures. We obtain a test accuracy of 95.97% with 4.97 time steps with
direct encoding on CIFAR10.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16459" title="Abstract">arXiv:2311.16459</a> [<a href="/pdf/2311.16459" title="Download PDF">pdf</a>, <a href="/format/2311.16459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Effect of Defections in Federated Learning and How to Prevent  Them
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+M">Minbiao Han</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+K+K">Kumar Kshitij Patel</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+H">Han Shao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lingxiao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated learning is a machine learning protocol that enables a large
population of agents to collaborate over multiple rounds to produce a single
consensus model. There are several federated learning applications where agents
may choose to defect permanently$-$essentially withdrawing from the
collaboration$-$if they are content with their instantaneous model in that
round. This work demonstrates the detrimental impact of such defections on the
final model's robustness and ability to generalize. We also show that current
federated optimization algorithms fail to disincentivize these harmful
defections. We introduce a novel optimization algorithm with theoretical
guarantees to prevent defections while ensuring asymptotic convergence to an
effective solution for all participating agents. We also provide numerical
experiments to corroborate our findings and demonstrate the effectiveness of
our algorithm.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16460" title="Abstract">arXiv:2311.16460</a> [<a href="/pdf/2311.16460" title="Download PDF">pdf</a>, <a href="/format/2311.16460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Threshold Breaker: Can Counter-Based RowHammer Prevention Mechanisms  Truly Safeguard DRAM?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+R">Ranyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jacqueline Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+S">Sabbir Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Kochar%2C+N">Nakul Kochar</a>, 
<a href="/search/cs?searchtype=author&query=Rakin%2C+A+S">Adnan Siraj Rakin</a>, 
<a href="/search/cs?searchtype=author&query=Angizi%2C+S">Shaahin Angizi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">This paper challenges the existing victim-focused counter-based RowHammer
detection mechanisms by experimentally demonstrating a novel multi-sided fault
injection attack technique called Threshold Breaker. This mechanism can
effectively bypass the most advanced counter-based defense mechanisms by
soft-attacking the rows at a farther physical distance from the target rows.
While no prior work has demonstrated the effect of such an attack, our work
closes this gap by systematically testing 128 real commercial DDR4 DRAM
products and reveals that the Threshold Breaker affects various chips from
major DRAM manufacturers. As a case study, we compare the performance
efficiency between our mechanism and a well-known double-sided attack by
performing adversarial weight attacks on a modern Deep Neural Network (DNN).
The results demonstrate that the Threshold Breaker can deliberately deplete the
intelligence of the targeted DNN system while DRAM is fully protected.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16462" title="Abstract">arXiv:2311.16462</a> [<a href="/pdf/2311.16462" title="Download PDF">pdf</a>, <a href="/format/2311.16462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Viewport Prediction for Volumetric Video Streaming by Exploring Video  Saliency and Trajectory Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jie Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhixin Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Pengyuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+R">Richang Hong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qiyue Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Han Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Volumetric video, also known as hologram video, is a novel medium that
portrays natural content in Virtual Reality (VR), Augmented Reality (AR), and
Mixed Reality (MR). It is expected to be the next-gen video technology and a
prevalent use case for 5G and beyond wireless communication. Considering that
each user typically only watches a section of the volumetric video, known as
the viewport, it is essential to have precise viewport prediction for optimal
performance. However, research on this topic is still in its infancy. In the
end, this paper presents and proposes a novel approach, named Saliency and
Trajectory Viewport Prediction (STVP), which aims to improve the precision of
viewport prediction in volumetric video streaming. The STVP extensively
utilizes video saliency information and viewport trajectory. To our knowledge,
this is the first comprehensive study of viewport prediction in volumetric
video streaming. In particular, we introduce a novel sampling method, Uniform
Random Sampling (URS), to reduce computational complexity while still
preserving video features in an efficient manner. Then we present a saliency
detection technique that incorporates both spatial and temporal information for
detecting static, dynamic geometric, and color salient regions. Finally, we
intelligently fuse saliency and trajectory information to achieve more accurate
viewport prediction. We conduct extensive simulations to evaluate the
effectiveness of our proposed viewport prediction methods using
state-of-the-art volumetric video sequences. The experimental results show the
superiority of the proposed method over existing schemes. The dataset and
source code will be publicly accessible after acceptance.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16464" title="Abstract">arXiv:2311.16464</a> [<a href="/pdf/2311.16464" title="Download PDF">pdf</a>, <a href="/format/2311.16464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging the Gap: A Unified Video Comprehension Framework for Moment  Retrieval and Highlight Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yicheng Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zhuoyan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yue Ma</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+H">Hengwei Bian</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Y">Yatai Ji</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yujiu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiu Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Video Moment Retrieval (MR) and Highlight Detection (HD) have attracted
significant attention due to the growing demand for video analysis. Recent
approaches treat MR and HD as similar video grounding problems and address them
together with transformer-based architecture. However, we observe that the
emphasis of MR and HD differs, with one necessitating the perception of local
relationships and the other prioritizing the understanding of global contexts.
Consequently, the lack of task-specific design will inevitably lead to
limitations in associating the intrinsic specialty of two tasks. To tackle the
issue, we propose a Unified Video COMprehension framework (UVCOM) to bridge the
gap and jointly solve MR and HD effectively. By performing progressive
integration on intra and inter-modality across multi-granularity, UVCOM
achieves the comprehensive understanding in processing a video. Moreover, we
present multi-aspect contrastive learning to consolidate the local relation
modeling and global knowledge accumulation via well aligned multi-modal space.
Extensive experiments on QVHighlights, Charades-STA, TACoS , YouTube Highlights
and TVSum datasets demonstrate the effectiveness and rationality of UVCOM which
outperforms the state-of-the-art methods by a remarkable margin.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16465" title="Abstract">arXiv:2311.16465</a> [<a href="/pdf/2311.16465" title="Download PDF">pdf</a>, <a href="/format/2311.16465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TextDiffuser-2: Unleashing the Power of Language Models for Text  Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingye Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yupan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+T">Tengchao Lv</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+L">Lei Cui</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qifeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Furu Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The diffusion model has been proven a powerful generative model in recent
years, yet remains a challenge in generating visual text. Several methods
alleviated this issue by incorporating explicit text position and content as
guidance on where and what text to render. However, these methods still suffer
from several drawbacks, such as limited flexibility and automation, constrained
capability of layout prediction, and restricted style diversity. In this paper,
we present TextDiffuser-2, aiming to unleash the power of language models for
text rendering. Firstly, we fine-tune a large language model for layout
planning. The large language model is capable of automatically generating
keywords for text rendering and also supports layout modification through
chatting. Secondly, we utilize the language model within the diffusion model to
encode the position and texts at the line level. Unlike previous methods that
employed tight character-level guidance, this approach generates more diverse
text images. We conduct extensive experiments and incorporate user studies
involving human participants as well as GPT-4V, validating TextDiffuser-2's
capacity to achieve a more rational text layout and generation with enhanced
diversity. The code and model will be available at
\url{https://aka.ms/textdiffuser-2}.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16466" title="Abstract">arXiv:2311.16466</a> [<a href="/pdf/2311.16466" title="Download PDF">pdf</a>, <a href="/format/2311.16466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Human Persuasion With Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shin%2C+M">Minkyu Shin</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jin Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Although large language models (LLMs) are reshaping various aspects of human
life, our current understanding of their impacts remains somewhat constrained.
Here we investigate the impact of LLMs on human communication, in the context
of consumer complaints in the financial industry. Employing an AI detection
tool on more than 780K complaints gathered by the Consumer Financial Protection
Bureau (CFPB), we find evidence of LLM usage in the writing of complaints -
shortly after the release of ChatGPT. Our analyses reveal that LLM usage is
positively correlated with the likelihood of obtaining desirable outcomes
(i.e., offer of relief from financial firms) and suggest that this positive
correlation may be partly due to the linguistic features improved by LLMs. We
test this conjecture with a preregistered experiment, which reveals results
consistent with those from observational studies: Consumer complaints written
with ChatGPT for improved linguistic qualities were more likely to receive
hypothetical relief offers than the original consumer complaints, demonstrating
the LLM's ability to enhance message persuasiveness in human communication.
Being some of the earliest empirical evidence on LLM usage for enhancing
persuasion, our results highlight the transformative potential of LLMs in human
communication.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16468" title="Abstract">arXiv:2311.16468</a> [<a href="/pdf/2311.16468" title="Download PDF">pdf</a>, <a href="/format/2311.16468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AvatarGPT: All-in-One Framework for Motion Understanding, Planning,  Generation and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zixiang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Y">Yu Wan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Baoyuan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 21 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large Language Models(LLMs) have shown remarkable emergent abilities in
unifying almost all (if not every) NLP tasks. In the human motion-related
realm, however, researchers still develop siloed models for each task. Inspired
by InstuctGPT, and the generalist concept behind Gato, we introduce AvatarGPT,
an All-in-One framework for motion understanding, planning, generations as well
as other tasks such as motion in-between synthesis. AvatarGPT treats each task
as one type of instruction fine-tuned on the shared LLM. All the tasks are
seamlessly interconnected with language as the universal interface,
constituting a closed-loop within the framework. To achieve this, human motion
sequences are first encoded as discrete tokens, which serve as the extended
vocabulary of LLM. Then, an unsupervised pipeline to generate natural language
descriptions of human action sequences from in-the-wild videos is developed.
Finally, all tasks are jointly trained. Extensive experiments show that
AvatarGPT achieves SOTA on low-level tasks, and promising results on high-level
tasks, demonstrating the effectiveness of our proposed All-in-One framework.
Moreover, for the first time, AvatarGPT enables a principled approach by
iterative traversal of the tasks within the closed-loop for unlimited
long-motion synthesis.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16471" title="Abstract">arXiv:2311.16471</a> [<a href="/pdf/2311.16471" title="Download PDF">pdf</a>, <a href="/format/2311.16471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Framework for Multimodal, Multi-Part Human Motion Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zixiang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Y">Yu Wan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Baoyuan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 18 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The field has made significant progress in synthesizing realistic human
motion driven by various modalities. Yet, the need for different methods to
animate various body parts according to different control signals limits the
scalability of these techniques in practical scenarios. In this paper, we
introduce a cohesive and scalable approach that consolidates multimodal (text,
music, speech) and multi-part (hand, torso) human motion generation. Our
methodology unfolds in several steps: We begin by quantizing the motions of
diverse body parts into separate codebooks tailored to their respective
domains. Next, we harness the robust capabilities of pre-trained models to
transcode multimodal signals into a shared latent space. We then translate
these signals into discrete motion tokens by iteratively predicting subsequent
tokens to form a complete sequence. Finally, we reconstruct the continuous
actual motion from this tokenized sequence. Our method frames the multimodal
motion generation challenge as a token prediction task, drawing from
specialized codebooks based on the modality of the control signal. This
approach is inherently scalable, allowing for the easy integration of new
modalities. Extensive experiments demonstrated the effectiveness of our design,
emphasizing its potential for broad application.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16473" title="Abstract">arXiv:2311.16473</a> [<a href="/pdf/2311.16473" title="Download PDF">pdf</a>, <a href="/format/2311.16473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GS-IR: 3D Gaussian Splatting for Inverse Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+Z">Zhihao Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Ying Feng</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+K">Kui Jia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose GS-IR, a novel inverse rendering approach based on 3D Gaussian
Splatting (GS) that leverages forward mapping volume rendering to achieve
photorealistic novel view synthesis and relighting results. Unlike previous
works that use implicit neural representations and volume rendering (e.g.
NeRF), which suffer from low expressive power and high computational
complexity, we extend GS, a top-performance representation for novel view
synthesis, to estimate scene geometry, surface material, and environment
illumination from multi-view images captured under unknown lighting conditions.
There are two main problems when introducing GS to inverse rendering: 1) GS
does not support producing plausible normal natively; 2) forward mapping (e.g.
rasterization and splatting) cannot trace the occlusion like backward mapping
(e.g. ray tracing). To address these challenges, our GS-IR proposes an
efficient optimization scheme that incorporates a depth-derivation-based
regularization for normal estimation and a baking-based occlusion to model
indirect lighting. The flexible and expressive GS representation allows us to
achieve fast and compact geometry reconstruction, photorealistic novel view
synthesis, and effective physically-based rendering. We demonstrate the
superiority of our method over baseline methods through qualitative and
quantitative evaluations on various challenging scenes.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16474" title="Abstract">arXiv:2311.16474</a> [<a href="/pdf/2311.16474" title="Download PDF">pdf</a>, <a href="/format/2311.16474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Progressive Target-Styled Feature Augmentation for Unsupervised Domain  Adaptation on Point Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zicheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yiming Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Luping Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dong Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 6 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Unsupervised domain adaptation is a critical challenge in the field of point
cloud analysis, as models trained on one set of data often struggle to perform
well in new scenarios due to domain shifts. Previous works tackle the problem
by using adversarial training or self-supervised learning for feature extractor
adaptation, but ensuring that features extracted from the target domain can be
distinguished by the source-supervised classifier remains challenging. In this
work, we propose a novel approach called progressive target-styled feature
augmentation (PTSFA). Unlike previous works that focus on feature extractor
adaptation, our PTSFA approach focuses on classifier adaptation. It aims to
empower the classifier to recognize target-styled source features and
progressively adapt to the target domain. To enhance the reliability of
predictions within the PTSFA framework and encourage discriminative feature
extraction, we further introduce a new intermediate domain approaching (IDA)
strategy. We validate our method on the benchmark datasets, where our method
achieves new state-of-the-art performance. Our code is available at
https://github.com/xiaoyao3302/PTSFA.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16475" title="Abstract">arXiv:2311.16475</a> [<a href="/pdf/2311.16475" title="Download PDF">pdf</a>, <a href="/format/2311.16475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Human-Centric Visual Cues for Human-Object Interaction  Detection via Large Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Y">Yu-Wei Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+L">Liqiang Nie</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xin-Shun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Kankanhalli%2C+M">Mohan Kankanhalli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Human-object interaction (HOI) detection aims at detecting human-object pairs
and predicting their interactions. However, the complexity of human behavior
and the diverse contexts in which these interactions occur make it challenging.
Intuitively, human-centric visual cues, such as the involved participants, the
body language, and the surrounding environment, play crucial roles in shaping
these interactions. These cues are particularly vital in interpreting unseen
interactions. In this paper, we propose three prompts with VLM to generate
human-centric visual cues within an image from multiple perspectives of humans.
To capitalize on these rich Human-Centric Visual Cues, we propose a novel
approach named HCVC for HOI detection. Particularly, we develop a
transformer-based multimodal fusion module with multitower architecture to
integrate visual cue features into the instance and interaction decoders. Our
extensive experiments and analysis validate the efficacy of leveraging the
generated human-centric visual cues for HOI detection. Notably, the
experimental results indicate the superiority of the proposed model over the
existing state-of-the-art methods on two widely used datasets.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16476" title="Abstract">arXiv:2311.16476</a> [<a href="/pdf/2311.16476" title="Download PDF">pdf</a>, <a href="/format/2311.16476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LANS: A Layout-Aware Neural Solver for Plane Geometry Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Ming-Liang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhong-Zhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+F">Fei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cheng-Lin Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Geometry problem solving (GPS) is a challenging mathematical reasoning task
requiring multi-modal understanding, fusion and reasoning. Existing neural
solvers take GPS as a vision-language task but be short in the representation
of geometry diagrams which carry rich and complex layout information. In this
paper, we propose a layout-aware neural solver named LANS, integrated with two
new modules: multimodal layout-aware pre-trained language model (MLA-PLM) and
layout-aware fusion attention (LA-FA). MLA-PLM adopts structural and semantic
pre-training (SSP) to implement global relationship modeling, and point
matching pre-training (PMP) to achieve alignment between visual points and
textual points. LA-FA employs a layout-aware attention mask to realize
point-guided cross-modal fusion for further boosting layout awareness of LANS.
Extensive experiments on datasets Geometry3K and PGPS9K validate the
effectiveness of the layout-aware modules and superior problem solving
performance of our LANS solver, over existing symbolic solvers and neural
solvers. The code will make public available soon.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16477" title="Abstract">arXiv:2311.16477</a> [<a href="/pdf/2311.16477" title="Download PDF">pdf</a>, <a href="/format/2311.16477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniHPE: Towards Unified Human Pose Estimation via Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhongyu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+W">Wenhao Chai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhuoran Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Cheng-Yen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J">Jenq-Neng Hwang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent times, there has been a growing interest in developing effective
perception techniques for combining information from multiple modalities. This
involves aligning features obtained from diverse sources to enable more
efficient training with larger datasets and constraints, as well as leveraging
the wealth of information contained in each modality. 2D and 3D Human Pose
Estimation (HPE) are two critical perceptual tasks in computer vision, which
have numerous downstream applications, such as Action Recognition,
Human-Computer Interaction, Object tracking, etc. Yet, there are limited
instances where the correlation between Image and 2D/3D human pose has been
clearly researched using a contrastive paradigm. In this paper, we propose
UniHPE, a unified Human Pose Estimation pipeline, which aligns features from
all three modalities, i.e., 2D human pose estimation, lifting-based and
image-based 3D human pose estimation, in the same pipeline. To align more than
two modalities at the same time, we propose a novel singular value based
contrastive learning loss, which better aligns different modalities and further
boosts the performance. In our evaluation, UniHPE achieves remarkable
performance metrics: MPJPE $50.5$mm on the Human3.6M dataset and PAMPJPE
$51.6$mm on the 3DPW dataset. Our proposed method holds immense potential to
advance the field of computer vision and contribute to various applications.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16478" title="Abstract">arXiv:2311.16478</a> [<a href="/pdf/2311.16478" title="Download PDF">pdf</a>, <a href="/format/2311.16478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RetouchUAA: Unconstrained Adversarial Attack via Image Retouching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+M">Mengda Xie</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yiling He</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+M">Meie Fang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep Neural Networks (DNNs) are susceptible to adversarial examples.
Conventional attacks generate controlled noise-like perturbations that fail to
reflect real-world scenarios and hard to interpretable. In contrast, recent
unconstrained attacks mimic natural image transformations occurring in the real
world for perceptible but inconspicuous attacks, yet compromise realism due to
neglect of image post-processing and uncontrolled attack direction. In this
paper, we propose RetouchUAA, an unconstrained attack that exploits a real-life
perturbation: image retouching styles, highlighting its potential threat to
DNNs. Compared to existing attacks, RetouchUAA offers several notable
advantages. Firstly, RetouchUAA excels in generating interpretable and
realistic perturbations through two key designs: the image retouching attack
framework and the retouching style guidance module. The former custom-designed
human-interpretability retouching framework for adversarial attack by
linearizing images while modelling the local processing and retouching
decision-making in human retouching behaviour, provides an explicit and
reasonable pipeline for understanding the robustness of DNNs against
retouching. The latter guides the adversarial image towards standard retouching
styles, thereby ensuring its realism. Secondly, attributed to the design of the
retouching decision regularization and the persistent attack strategy,
RetouchUAA also exhibits outstanding attack capability and defense robustness,
posing a heavy threat to DNNs. Experiments on ImageNet and Place365 reveal that
RetouchUAA achieves nearly 100\% white-box attack success against three DNNs,
while achieving a better trade-off between image naturalness, transferability
and defense robustness than baseline attacks.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16479" title="Abstract">arXiv:2311.16479</a> [<a href="/pdf/2311.16479" title="Download PDF">pdf</a>, <a href="/format/2311.16479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Hallucination in Visual Language Models with Visual  Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhiyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yousong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Y">Yufei Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhaowen Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chaoyang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinqiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+M">Ming Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large vision-language models (LVLMs) suffer from hallucination a lot,
generating responses that apparently contradict to the image content
occasionally. The key problem lies in its weak ability to comprehend detailed
content in a multi-modal context, which can be mainly attributed to two factors
in training data and loss function. The vision instruction dataset primarily
focuses on global description, and the auto-regressive loss function favors
text modeling rather than image understanding. In this paper, we bring more
detailed vision annotations and more discriminative vision models to facilitate
the training of LVLMs, so that they can generate more precise responses without
encounter hallucination. On one hand, we generate image-text pairs with
detailed relationship annotations in panoptic scene graph dataset (PSG). These
conversations pay more attention on detailed facts in the image, encouraging
the model to answer questions based on multi-modal contexts. On the other hand,
we integrate SAM and mask prediction loss as auxiliary supervision, forcing the
LVLMs to have the capacity to identify context-related objects, so that they
can generate more accurate responses, mitigating hallucination. Moreover, to
provide a deeper evaluation on the hallucination in LVLMs, we propose a new
benchmark, RAH-Bench. It divides vision hallucination into three different
types that contradicts the image with wrong categories, attributes or
relations, and introduces False Positive Rate as detailed sub-metric for each
type. In this benchmark, our approach demonstrates an +8.4% enhancement
compared to original LLaVA and achieves widespread performance improvements
across other models.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16480" title="Abstract">arXiv:2311.16480</a> [<a href="/pdf/2311.16480" title="Download PDF">pdf</a>, <a href="/format/2311.16480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MI-Gen: Multiple Instance Generation of Pathology Reports for Gigapixel  Whole-Slide Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pingyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Honglin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chenglu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Sunyi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lin Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Whole slide images are the foundation of digital pathology for the diagnosis
and treatment of carcinomas. Writing pathology reports is laborious and
error-prone for inexperienced pathologists. To reduce the workload and improve
clinical automation, we investigate how to generate pathology reports given
whole slide images. On the data end, we curated the largest WSI-text dataset
(TCGA-PathoText). In specific, we collected nearly 10000 high-quality WSI-text
pairs for visual-language models by recognizing and cleaning pathology reports
which narrate diagnostic slides in TCGA. On the model end, we propose the
multiple instance generative model (MI-Gen) which can produce pathology reports
for gigapixel WSIs. We benchmark our model on the largest subset of
TCGA-PathoText. Experimental results show our model can generate pathology
reports which contain multiple clinical clues. Furthermore, WSI-text prediction
can be seen as an approach of visual-language pre-training, which enables our
model to be transferred to downstream diagnostic tasks like carcinoma grading
and phenotyping. We observe that simple semantic extraction from the pathology
reports can achieve the best performance (0.838 of F1 score) on BRCA subtyping
without adding extra parameters or tricky fine-tuning. Our collected dataset
and related code will all be publicly available.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16481" title="Abstract">arXiv:2311.16481</a> [<a href="/pdf/2311.16481" title="Download PDF">pdf</a>, <a href="/format/2311.16481" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Elucidating and Overcoming the Challenges of Label Noise in Supervised  Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Long%2C+Z">Zijun Long</a>, 
<a href="/search/cs?searchtype=author&query=Killick%2C+G">George Killick</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+L">Lipeng Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=McCreadie%2C+R">Richard McCreadie</a>, 
<a href="/search/cs?searchtype=author&query=Camarasa%2C+G+A">Gerardo Aragon Camarasa</a>, 
<a href="/search/cs?searchtype=author&query=Henderson%2C+P">Paul Henderson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image classification datasets exhibit a non-negligible fraction of mislabeled
examples, often due to human error when one class superficially resembles
another. This issue poses challenges in supervised contrastive learning (SCL),
where the goal is to cluster together data points of the same class in the
embedding space while distancing those of disparate classes. While such methods
outperform those based on cross-entropy, they are not immune to labeling
errors. However, while the detrimental effects of noisy labels in supervised
learning are well-researched, their influence on SCL remains largely
unexplored. Hence, we analyse the effect of label errors and examine how they
disrupt the SCL algorithm's ability to distinguish between positive and
negative sample pairs. Our analysis reveals that human labeling errors manifest
as easy positive samples in around 99% of cases. We, therefore, propose D-SCL,
a novel Debiased Supervised Contrastive Learning objective designed to mitigate
the bias introduced by labeling errors. We demonstrate that D-SCL consistently
outperforms state-of-the-art techniques for representation learning across
diverse vision benchmarks, offering improved robustness to label errors.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16482" title="Abstract">arXiv:2311.16482</a> [<a href="/pdf/2311.16482" title="Download PDF">pdf</a>, <a href="/format/2311.16482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Animatable 3D Gaussian: Fast and High-Quality Reconstruction of Multiple  Human Avatars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+M">Minghan Qin</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Q">Qinwei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoqian Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Neural radiance fields are capable of reconstructing high-quality drivable
human avatars but are expensive to train and render. To reduce consumption, we
propose Animatable 3D Gaussian, which learns human avatars from input images
and poses. We extend 3D Gaussians to dynamic human scenes by modeling a set of
skinned 3D Gaussians and a corresponding skeleton in canonical space and
deforming 3D Gaussians to posed space according to the input poses. We
introduce hash-encoded shape and appearance to speed up training and propose
time-dependent ambient occlusion to achieve high-quality reconstructions in
scenes containing complex motions and dynamic shadows. On both novel view
synthesis and novel pose synthesis tasks, our method outperforms existing
methods in terms of training time, rendering speed, and reconstruction quality.
Our method can be easily extended to multi-human scenes and achieve comparable
novel view synthesis results on a scene with ten people in only 25 seconds of
training.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16483" title="Abstract">arXiv:2311.16483</a> [<a href="/pdf/2311.16483" title="Download PDF">pdf</a>, <a href="/format/2311.16483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChartLlama: A Multimodal LLM for Chart Understanding and Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yucheng Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhibin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Gang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+B">Bin Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanwang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code and model on <a href="https://tingxueronghua.github.io/ChartLlama/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Multi-modal large language models have demonstrated impressive performances
on most vision-language tasks. However, the model generally lacks the
understanding capabilities for specific domain data, particularly when it comes
to interpreting chart figures. This is mainly due to the lack of relevant
multi-modal instruction tuning datasets. In this article, we create a
high-quality instruction-tuning dataset leveraging GPT-4. We develop a
multi-step data generation process in which different steps are responsible for
generating tabular data, creating chart figures, and designing instruction
tuning data separately. Our method's flexibility enables us to generate
diverse, high-quality instruction-tuning data consistently and efficiently
while maintaining a low resource expenditure. Additionally, it allows us to
incorporate a wider variety of chart and task types not yet featured in
existing datasets. Next, we introduce ChartLlama, a multi-modal large language
model that we've trained using our created dataset. ChartLlama outperforms all
prior methods in ChartQA, Chart-to-text, and Chart-extraction evaluation
benchmarks. Additionally, ChartLlama significantly improves upon the baseline
in our specially compiled chart dataset, which includes new chart and task
types. The results of ChartLlama confirm the value and huge potential of our
proposed data generation method in enhancing chart comprehension.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16484" title="Abstract">arXiv:2311.16484</a> [<a href="/pdf/2311.16484" title="Download PDF">pdf</a>, <a href="/format/2311.16484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eye vs. AI: Human Gaze and Model Attention in Video Memorability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+P">Prajneya Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Khandelwal%2C+E">Eshika Khandelwal</a>, 
<a href="/search/cs?searchtype=author&query=Tapaswi%2C+M">Makarand Tapaswi</a>, 
<a href="/search/cs?searchtype=author&query=Sreekumar%2C+V">Vishnu Sreekumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Understanding the factors that determine video memorability has important
applications in areas such as educational technology and advertising. Towards
this goal, we investigate the semantic and temporal attention mechanisms
underlying video memorability. We propose a Transformer-based model with
spatio-temporal attention that matches SoTA performance on video memorability
prediction on a large naturalistic video dataset. More importantly, the
self-attention patterns show us where the model looks to predict memorability.
We compare model attention against human gaze fixation density maps collected
through a small-scale eye-tracking experiment where humans perform a video
memory task. Quantitative saliency metrics show that the model attention and
human gaze follow similar patterns. Furthermore, while panoptic segmentation
confirms that the model and humans attend more to thing classes, stuff classes
that receive increased/decreased attention tend to have higher memorability
scores. We also observe that the model assigns greater importance to the
initial frames, mimicking temporal attention patterns found in humans.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16485" title="Abstract">arXiv:2311.16485</a> [<a href="/pdf/2311.16485" title="Download PDF">pdf</a>, <a href="/format/2311.16485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Class-Adaptive Sampling Policy for Efficient Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rezaei%2C+H">Hossein Rezaei</a>, 
<a href="/search/cs?searchtype=author&query=Sabokrou%2C+M">Mohammad Sabokrou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Continual learning (CL) aims to acquire new knowledge while preserving
information from previous experiences without forgetting. Though buffer-based
methods (i.e., retaining samples from previous tasks) have achieved acceptable
performance, determining how to allocate the buffer remains a critical
challenge. Most recent research focuses on refining these methods but often
fails to sufficiently consider the varying influence of samples on the learning
process, and frequently overlooks the complexity of the classes/concepts being
learned. Generally, these methods do not directly take into account the
contribution of individual classes. However, our investigation indicates that
more challenging classes necessitate preserving a larger number of samples
compared to less challenging ones. To address this issue, we propose a novel
method and policy named 'Class-Adaptive Sampling Policy' (CASP), which
dynamically allocates storage space within the buffer. By utilizing concepts of
class contribution and difficulty, CASP adaptively manages buffer space,
allowing certain classes to occupy a larger portion of the buffer while
reducing storage for others. This approach significantly improves the
efficiency of knowledge retention and utilization. CASP provides a versatile
solution to boost the performance and efficiency of CL. It meets the demand for
dynamic buffer allocation, accommodating the varying contributions of different
classes and their learning complexities over time.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16487" title="Abstract">arXiv:2311.16487</a> [<a href="/pdf/2311.16487" title="Download PDF">pdf</a>, <a href="/format/2311.16487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Robustness of Decision-Focused Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farhat%2C+Y">Yehya Farhat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 45 figures, submitted to AAAI artificial intelligence for operations research workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Decision-Focused Learning (DFL) is an emerging learning paradigm that tackles
the task of training a machine learning (ML) model to predict missing
parameters of an incomplete optimization problem, where the missing parameters
are predicted. DFL trains an ML model in an end-to-end system, by integrating
the prediction and optimization tasks, providing better alignment of the
training and testing objectives. DFL has shown a lot of promise and holds the
capacity to revolutionize decision-making in many real-world applications.
However, very little is known about the performance of these models under
adversarial attacks. We adopt ten unique DFL methods and benchmark their
performance under two distinctly focused attacks adapted towards the
Predict-then-Optimize problem setting. Our study proposes the hypothesis that
the robustness of a model is highly correlated with its ability to find
predictions that lead to optimal decisions without deviating from the
ground-truth label. Furthermore, we provide insight into how to target the
models that violate this condition and show how these models respond
differently depending on the achieved optimality at the end of their training
cycles.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16488" title="Abstract">arXiv:2311.16488</a> [<a href="/pdf/2311.16488" title="Download PDF">pdf</a>, <a href="/format/2311.16488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Multimodal Diffusion Models Using Joint Data Infilling with  Partially Shared U-Net
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zizhao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+S">Shaochong Jia</a>, 
<a href="/search/cs?searchtype=author&query=Rostami%2C+M">Mohammad Rostami</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently, diffusion models have been used successfully to fit distributions
for cross-modal data translation and multimodal data generation. However, these
methods rely on extensive scaling, overlooking the inefficiency and
interference between modalities. We develop Partially Shared U-Net (PS-U-Net)
architecture which is an efficient multimodal diffusion model that allows text
and image inputs to pass through dedicated layers and skip-connections for
preserving modality-specific fine-grained details. Inspired by image
inpainting, we also propose a new efficient multimodal sampling method that
introduces new scenarios for conditional generation while only requiring a
simple joint distribution to be learned. Our empirical exploration of the
MS-COCO dataset demonstrates that our method generates multimodal text and
image data with higher quality compared to existing multimodal diffusion models
while having a comparable size, faster training, faster multimodal sampling,
and more flexible generation.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16491" title="Abstract">arXiv:2311.16491</a> [<a href="/pdf/2311.16491" title="Download PDF">pdf</a>, <a href="/format/2311.16491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $Z^*$: Zero-shot Style Transfer via Attention Rearrangement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yingying Deng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiangyu He</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+F">Fan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+W">Weiming Dong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite the remarkable progress in image style transfer, formulating style in
the context of art is inherently subjective and challenging. In contrast to
existing learning/tuning methods, this study shows that vanilla diffusion
models can directly extract style information and seamlessly integrate the
generative prior into the content image without retraining. Specifically, we
adopt dual denoising paths to represent content/style references in latent
space and then guide the content image denoising process with style latent
codes. We further reveal that the cross-attention mechanism in latent diffusion
models tends to blend the content and style images, resulting in stylized
outputs that deviate from the original content image. To overcome this
limitation, we introduce a cross-attention rearrangement strategy. Through
theoretical analysis and experiments, we demonstrate the effectiveness and
superiority of the diffusion-based $\underline{Z}$ero-shot $\underline{S}$tyle
$\underline{T}$ransfer via $\underline{A}$ttention $\underline{R}$earrangement,
Z-STAR.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16492" title="Abstract">arXiv:2311.16492</a> [<a href="/pdf/2311.16492" title="Download PDF">pdf</a>, <a href="/format/2311.16492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VLPrompt: Vision-Language Prompting for Panoptic Scene Graph Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zijian Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+M">Miaojing Shi</a>, 
<a href="/search/cs?searchtype=author&query=Caesar%2C+H">Holger Caesar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Panoptic Scene Graph Generation (PSG) aims at achieving a comprehensive image
understanding by simultaneously segmenting objects and predicting relations
among objects. However, the long-tail problem among relations leads to
unsatisfactory results in real-world applications. Prior methods predominantly
rely on vision information or utilize limited language information, such as
object or relation names, thereby overlooking the utility of language
information. Leveraging the recent progress in Large Language Models (LLMs), we
propose to use language information to assist relation prediction, particularly
for rare relations. To this end, we propose the Vision-Language Prompting
(VLPrompt) model, which acquires vision information from images and language
information from LLMs. Then, through a prompter network based on attention
mechanism, it achieves precise relation prediction. Our extensive experiments
show that VLPrompt significantly outperforms previous state-of-the-art methods
on the PSG dataset, proving the effectiveness of incorporating language
information and alleviating the long-tail problem of relations.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16493" title="Abstract">arXiv:2311.16493</a> [<a href="/pdf/2311.16493" title="Download PDF">pdf</a>, <a href="/format/2311.16493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mip-Splatting: Alias-free 3D Gaussian Splatting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zehao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+A">Anpei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Binbin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sattler%2C+T">Torsten Sattler</a>, 
<a href="/search/cs?searchtype=author&query=Geiger%2C+A">Andreas Geiger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://niujinshuchong.github.io/mip-splatting/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, 3D Gaussian Splatting has demonstrated impressive novel view
synthesis results, reaching high fidelity and efficiency. However, strong
artifacts can be observed when changing the sampling rate, \eg, by changing
focal length or camera distance. We find that the source for this phenomenon
can be attributed to the lack of 3D frequency constraints and the usage of a 2D
dilation filter. To address this problem, we introduce a 3D smoothing filter
which constrains the size of the 3D Gaussian primitives based on the maximal
sampling frequency induced by the input views, eliminating high-frequency
artifacts when zooming in. Moreover, replacing 2D dilation with a 2D Mip
filter, which simulates a 2D box filter, effectively mitigates aliasing and
dilation issues. Our evaluation, including scenarios such a training on
single-scale images and testing on multiple scales, validates the effectiveness
of our approach.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16494" title="Abstract">arXiv:2311.16494</a> [<a href="/pdf/2311.16494" title="Download PDF">pdf</a>, <a href="/format/2311.16494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ArGue: Attribute-Guided Prompt Tuning for Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+X">Xinyu Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+S">Shu Zou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhaoyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Although soft prompt tuning is effective in efficiently adapting
Vision-Language (V&amp;L) models for downstream tasks, it shows limitations in
dealing with distribution shifts. We address this issue with Attribute-Guided
Prompt Tuning (ArGue), making three key contributions. 1) In contrast to the
conventional approach of directly appending soft prompts preceding class names,
we align the model with primitive visual attributes generated by Large Language
Models (LLMs). We posit that a model's ability to express high confidence in
these attributes signifies its capacity to discern the correct class
rationales. 2) We introduce attribute sampling to eliminate disadvantageous
attributes, thus only semantically meaningful attributes are preserved. 3) We
propose negative prompting, explicitly enumerating class-agnostic attributes to
activate spurious correlations and encourage the model to generate highly
orthogonal probability distributions in relation to these negative features. In
experiments, our method significantly outperforms current state-of-the-art
prompt tuning methods on both novel class prediction and out-of-distribution
generalization tasks.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16495" title="Abstract">arXiv:2311.16495</a> [<a href="/pdf/2311.16495" title="Download PDF">pdf</a>, <a href="/format/2311.16495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Egocentric Whole-Body Motion Capture with FisheyeViT and Diffusion-Based  Motion Refinement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhe Cao</a>, 
<a href="/search/cs?searchtype=author&query=Luvizon%2C+D">Diogo Luvizon</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingjie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+K">Kripasindhu Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+D">Danhang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Beeler%2C+T">Thabo Beeler</a>, 
<a href="/search/cs?searchtype=author&query=Theobalt%2C+C">Christian Theobalt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this work, we explore egocentric whole-body motion capture using a single
fisheye camera, which simultaneously estimates human body and hand motion. This
task presents significant challenges due to three factors: the lack of
high-quality datasets, fisheye camera distortion, and human body
self-occlusion. To address these challenges, we propose a novel approach that
leverages FisheyeViT to extract fisheye image features, which are subsequently
converted into pixel-aligned 3D heatmap representations for 3D human body pose
prediction. For hand tracking, we incorporate dedicated hand detection and hand
pose estimation networks for regressing 3D hand poses. Finally, we develop a
diffusion-based whole-body motion prior model to refine the estimated
whole-body motion while accounting for joint uncertainties. To train these
networks, we collect a large synthetic dataset, EgoWholeBody, comprising
840,000 high-quality egocentric images captured across a diverse range of
whole-body motion sequences. Quantitative and qualitative evaluations
demonstrate the effectiveness of our method in producing high-quality
whole-body motion estimates from a single egocentric camera.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16496" title="Abstract">arXiv:2311.16496</a> [<a href="/pdf/2311.16496" title="Download PDF">pdf</a>, <a href="/format/2311.16496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Out-of-Domain Data for Domain-Specific Prompt Tuning in  Multi-Modal Fake News Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brahma%2C+D">Debarshi Brahma</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+A">Amartya Bhattacharya</a>, 
<a href="/search/cs?searchtype=author&query=Mahadev%2C+S+N">Suraj Nagaje Mahadev</a>, 
<a href="/search/cs?searchtype=author&query=Asati%2C+A">Anmol Asati</a>, 
<a href="/search/cs?searchtype=author&query=Verma%2C+V">Vikas Verma</a>, 
<a href="/search/cs?searchtype=author&query=Biswas%2C+S">Soma Biswas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The spread of fake news using out-of-context images has become widespread and
is a challenging task in this era of information overload. Since annotating
huge amounts of such data requires significant time of domain experts, it is
imperative to develop methods which can work in limited annotated data
scenarios. In this work, we explore whether out-of-domain data can help to
improve out-of-context misinformation detection (termed here as multi-modal
fake news detection) of a desired domain, eg. politics, healthcare, etc.
Towards this goal, we propose a novel framework termed DPOD (Domain-specific
Prompt-tuning using Out-of-Domain data). First, to compute generalizable
features, we modify the Vision-Language Model, CLIP to extract features that
helps to align the representations of the images and corresponding text
captions of both the in-domain and out-of-domain data in a label-aware manner.
Further, we propose a domain-specific prompt learning technique which leverages
the training samples of all the available domains based on the the extent they
can be useful to the desired domain. Extensive experiments on a large-scale
benchmark dataset, namely NewsClippings demonstrate that the proposed framework
achieves state of-the-art performance, significantly surpassing the existing
approaches for this challenging task.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16497" title="Abstract">arXiv:2311.16497</a> [<a href="/pdf/2311.16497" title="Download PDF">pdf</a>, <a href="/format/2311.16497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GaitContour: Efficient Gait Recognition based on a Contour-Pose  Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuxiang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+A">Anshul Shah</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chellappa%2C+R">Rama Chellappa</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Cheng Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Gait recognition holds the promise to robustly identify subjects based on
walking patterns instead of appearance information. In recent years, this field
has been dominated by learning methods based on two principal input
representations: dense silhouette masks or sparse pose keypoints. In this work,
we propose a novel, point-based Contour-Pose representation, which compactly
expresses both body shape and body parts information. We further propose a
local-to-global architecture, called GaitContour, to leverage this novel
representation and efficiently compute subject embedding in two stages. The
first stage consists of a local transformer that extracts features from five
different body regions. The second stage then aggregates the regional features
to estimate a global human gait representation. Such a design significantly
reduces the complexity of the attention operation and improves efficiency and
performance simultaneously. Through large scale experiments, GaitContour is
shown to perform significantly better than previous point-based methods, while
also being significantly more efficient than silhouette-based methods. On
challenging datasets with significant distractors, GaitContour can even
outperform silhouette-based methods.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16498" title="Abstract">arXiv:2311.16498</a> [<a href="/pdf/2311.16498" title="Download PDF">pdf</a>, <a href="/format/2311.16498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MagicAnimate: Temporally Consistent Human Image Animation using  Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhongcong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianfeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liew%2C+J+H">Jun Hao Liew</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Hanshu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jia-Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenxu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiashi Feng</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page at <a href="https://showlab.github.io/magicanimate">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">This paper studies the human image animation task, which aims to generate a
video of a certain reference identity following a particular motion sequence.
Existing animation works typically employ the frame-warping technique to
animate the reference image towards the target motion. Despite achieving
reasonable results, these approaches face challenges in maintaining temporal
consistency throughout the animation due to the lack of temporal modeling and
poor preservation of reference identity. In this work, we introduce
MagicAnimate, a diffusion-based framework that aims at enhancing temporal
consistency, preserving reference image faithfully, and improving animation
fidelity. To achieve this, we first develop a video diffusion model to encode
temporal information. Second, to maintain the appearance coherence across
frames, we introduce a novel appearance encoder to retain the intricate details
of the reference image. Leveraging these two innovations, we further employ a
simple video fusion technique to encourage smooth transitions for long video
animation. Empirical results demonstrate the superiority of our method over
baseline approaches on two benchmarks. Notably, our approach outperforms the
strongest baseline by over 38% in terms of video fidelity on the challenging
TikTok dancing dataset. Code and model will be made available.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16499" title="Abstract">arXiv:2311.16499</a> [<a href="/pdf/2311.16499" title="Download PDF">pdf</a>, <a href="/format/2311.16499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deceptive-Human: Prompt-to-NeRF 3D Human Generation with 3D-Consistent  Synthetic Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kao%2C+S">Shiu-hong Kao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinhang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tai%2C+Y">Yu-Wing Tai</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chi-Keung Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Github project: <a href="https://github.com/DanielSHKao/DeceptiveHuman">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents Deceptive-Human, a novel Prompt-to-NeRF framework
capitalizing state-of-the-art control diffusion models (e.g., ControlNet) to
generate a high-quality controllable 3D human NeRF. Different from direct 3D
generative approaches, e.g., DreamFusion and DreamHuman, Deceptive-Human
employs a progressive refinement technique to elevate the reconstruction
quality. This is achieved by utilizing high-quality synthetic human images
generated through the ControlNet with view-consistent loss. Our method is
versatile and readily extensible, accommodating multimodal inputs, including a
text prompt and additional data such as 3D mesh, poses, and seed images. The
resulting 3D human NeRF model empowers the synthesis of highly photorealistic
novel views from 360-degree perspectives. The key to our Deceptive-Human for
hallucinating multi-view consistent synthetic human images lies in our
progressive finetuning strategy. This strategy involves iteratively enhancing
views using the provided multimodal inputs at each intermediate step to improve
the human NeRF model. Within this iterative refinement process, view-dependent
appearances are systematically eliminated to prevent interference with the
underlying density estimation. Extensive qualitative and quantitative
experimental comparison shows that our deceptive human models achieve
state-of-the-art application quality.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16500" title="Abstract">arXiv:2311.16500</a> [<a href="/pdf/2311.16500" title="Download PDF">pdf</a>, <a href="/format/2311.16500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMGA: Multimodal Large Language Model based Generation Assistant
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+B">Bin Xia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiyin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+Y">Yingfan Tao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yitong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jiaya Jia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we introduce a Multimodal Large Language Model-based
Generation Assistant (LLMGA), leveraging the vast reservoir of knowledge and
proficiency in reasoning, comprehension, and response inherent in Large
Language Models (LLMs) to assist users in image generation and editing.
Diverging from existing approaches where Multimodal Large Language Models
(MLLMs) generate fixed-size embeddings to control Stable Diffusion (SD), our
LLMGA provides a detailed language generation prompt for precise control over
SD. This not only augments LLM context understanding but also reduces noise in
generation prompts, yields images with more intricate and precise content, and
elevates the interpretability of the network. To this end, we curate a
comprehensive dataset comprising prompt refinement, similar image generation,
inpainting $\&amp;$ outpainting, and visual question answering. Moreover, we
propose a two-stage training scheme. In the first stage, we train the MLLM to
grasp the properties of image generation and editing, enabling it to generate
detailed prompts. In the second stage, we optimize SD to align with the MLLM's
generation prompts. Additionally, we propose a reference-based restoration
network to alleviate texture, brightness, and contrast disparities between
generated and preserved regions during image editing. Extensive results show
that LLMGA has promising generative capabilities and can enable wider
applications in an interactive manner.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16501" title="Abstract">arXiv:2311.16501</a> [<a href="/pdf/2311.16501" title="Download PDF">pdf</a>, <a href="/format/2311.16501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PISA: Point-cloud-based Instructed Scene Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yiyang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+K">Ke Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Indoor scene augmentation has become an emerging topic in the field of
computer vision with applications in augmented and virtual reality. However,
existing scene augmentation methods mostly require a pre-built object database
with a given position as the desired location. In this paper, we propose the
first end-to-end multi-modal deep neural network that can generate point cloud
objects consistent with their surroundings, conditioned on text instructions.
Our model generates a seemly object in the appropriate position based on the
inputs of a query and point clouds, thereby enabling the creation of new
scenarios involving previously unseen layouts of objects. Database of
pre-stored CAD models is no longer needed. We use Point-E as our generative
model and introduce methods including quantified position prediction and Top-K
estimation to mitigate the false negative problems caused by ambiguous language
description. Moreover, we evaluate the ability of our model by demonstrating
the diversity of generated objects, the effectiveness of instruction, and
quantitative metric results, which collectively indicate that our model is
capable of generating realistic in-door objects. For a more thorough
evaluation, we also incorporate visual grounding as a metric to assess the
quality of the scenes generated by our model.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16502" title="Abstract">arXiv:2311.16502</a> [<a href="/pdf/2311.16502" title="Download PDF">pdf</a>, <a href="/format/2311.16502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning  Benchmark for Expert AGI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+X">Xiang Yue</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+Y">Yuansheng Ni</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+T">Tianyu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruoqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Ge Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Stevens%2C+S">Samuel Stevens</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+D">Dongfu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+W">Weiming Ren</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuxuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+C">Cong Wei</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Botao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+R">Ruibin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+R">Renliang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+M">Ming Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Boyuan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhenzhu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yibo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wenhao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Huan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yu Su</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenhu Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 115 pages, 99 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We introduce MMMU: a new benchmark designed to evaluate multimodal models on
massive multi-discipline tasks demanding college-level subject knowledge and
deliberate reasoning. MMMU includes 11.5K meticulously collected multimodal
questions from college exams, quizzes, and textbooks, covering six core
disciplines: Art &amp; Design, Business, Science, Health &amp; Medicine, Humanities &amp;
Social Science, and Tech &amp; Engineering. These questions span 30 subjects and
183 subfields, comprising 30 highly heterogeneous image types, such as charts,
diagrams, maps, tables, music sheets, and chemical structures. Unlike existing
benchmarks, MMMU focuses on advanced perception and reasoning with
domain-specific knowledge, challenging models to perform tasks akin to those
faced by experts. Our evaluation of 14 open-source LMMs and the proprietary
GPT-4V(ision) highlights the substantial challenges posed by MMMU. Even the
advanced GPT-4V only achieves a 56% accuracy, indicating significant room for
improvement. We believe MMMU will stimulate the community to build
next-generation multimodal foundation models towards expert artificial general
intelligence.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16503" title="Abstract">arXiv:2311.16503</a> [<a href="/pdf/2311.16503" title="Download PDF">pdf</a>, <a href="/format/2311.16503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TFMQ-DM: Temporal Feature Maintenance Quantization for Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yushi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+R">Ruihao Gong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianlong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xianglong Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The Diffusion model, a prevalent framework for image generation, encounters
significant challenges in terms of broad applicability due to its extended
inference times and substantial memory requirements. Efficient Post-training
Quantization (PTQ) is pivotal for addressing these issues in traditional
models. Different from traditional models, diffusion models heavily depend on
the time-step $t$ to achieve satisfactory multi-round denoising. Usually, $t$
from the finite set $\{1, \ldots, T\}$ is encoded to a temporal feature by a
few modules totally irrespective of the sampling data. However, existing PTQ
methods do not optimize these modules separately. They adopt inappropriate
reconstruction targets and complex calibration methods, resulting in a severe
disturbance of the temporal feature and denoising trajectory, as well as a low
compression efficiency. To solve these, we propose a Temporal Feature
Maintenance Quantization (TFMQ) framework building upon a Temporal Information
Block which is just related to the time-step $t$ and unrelated to the sampling
data. Powered by the pioneering block design, we devise temporal information
aware reconstruction (TIAR) and finite set calibration (FSC) to align the
full-precision temporal features in a limited time. Equipped with the
framework, we can maintain the most temporal information and ensure the
end-to-end generation quality. Extensive experiments on various datasets and
diffusion models prove our state-of-the-art results. Remarkably, our
quantization approach, for the first time, achieves model performance nearly on
par with the full-precision model under 4-bit weight quantization.
Additionally, our method incurs almost no extra computational cost and
accelerates quantization time by $2.0 \times$ on LSUN-Bedrooms $256 \times 256$
compared to previous works.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16504" title="Abstract">arXiv:2311.16504</a> [<a href="/pdf/2311.16504" title="Download PDF">pdf</a>, <a href="/format/2311.16504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Directional Integration in Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+C">Congyue Deng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiawei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guibas%2C+L">Leonidas Guibas</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yue Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Recent works use the Neural radiance field (NeRF) to perform multi-view 3D
reconstruction, providing a significant leap in rendering photorealistic
scenes. However, despite its efficacy, NeRF exhibits limited capability of
learning view-dependent effects compared to light field rendering or
image-based view synthesis. To that end, we introduce a modification to the
NeRF rendering equation which is as simple as a few lines of code change for
any NeRF variations, while greatly improving the rendering quality of
view-dependent effects. By swapping the integration operator and the direction
decoder network, we only integrate the positional features along the ray and
move the directional terms out of the integration, resulting in a
disentanglement of the view-dependent and independent components. The modified
equation is equivalent to the classical volumetric rendering in ideal cases on
object surfaces with Dirac densities. Furthermore, we prove that with the
errors caused by network approximation and numerical integration, our rendering
equation exhibits better convergence properties with lower error accumulations
compared to the classical NeRF. We also show that the modified equation can be
interpreted as light field rendering with learned ray embeddings. Experiments
on different NeRF variations show consistent improvements in the quality of
view-dependent effects with our simple modification.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16507" title="Abstract">arXiv:2311.16507</a> [<a href="/pdf/2311.16507" title="Download PDF">pdf</a>, <a href="/format/2311.16507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Straighter Trajectories of Flow Matching with Diffusion  Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xing%2C+S">Siyu Xing</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jie Cao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Huaibo Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiao-Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ran He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Flow matching as a paradigm of generative model achieves notable success
across various domains. However, existing methods use either multi-round
training or knowledge within minibatches, posing challenges in finding a
favorable coupling strategy for straight trajectories. To address this issue,
we propose a novel approach, Straighter trajectories of Flow Matching
(StraightFM). It straightens trajectories with the coupling strategy guided by
diffusion model from entire distribution level. First, we propose a coupling
strategy to straighten trajectories, creating couplings between image and noise
samples under diffusion model guidance. Second, StraightFM also integrates real
data to enhance training, employing a neural network to parameterize another
coupling process from images to noise samples. StraightFM is jointly optimized
with couplings from above two mutually complementary directions, resulting in
straighter trajectories and enabling both one-step and few-step generation.
Extensive experiments demonstrate that StraightFM yields high quality samples
with fewer step. StraightFM generates visually appealing images with a lower
FID among diffusion and traditional flow matching methods within 5 sampling
steps when trained on pixel space. In the latent space (i.e., Latent
Diffusion), StraightFM achieves a lower KID value compared to existing methods
on the CelebA-HQ 256 dataset in fewer than 10 sampling steps.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16508" title="Abstract">arXiv:2311.16508</a> [<a href="/pdf/2311.16508" title="Download PDF">pdf</a>, <a href="/format/2311.16508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RandMSAugment: A Mixed-Sample Augmentation for Limited-Data Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ravindran%2C+S+K">Swarna Kamlam Ravindran</a>, 
<a href="/search/cs?searchtype=author&query=Tomasi%2C+C">Carlo Tomasi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The high costs of annotating large datasets suggests a need for effectively
training CNNs with limited data, and data augmentation is a promising
direction. We study foundational augmentation techniques, including Mixed
Sample Data Augmentations (MSDAs) and a no-parameter variant of RandAugment
termed Preset-RandAugment, in the fully supervised scenario. We observe that
Preset-RandAugment excels in limited-data contexts while MSDAs are moderately
effective. We show that low-level feature transforms play a pivotal role in
this performance difference, postulate a new property of augmentations related
to their data efficiency, and propose new ways to measure the diversity and
realism of augmentations. Building on these insights, we introduce a novel
augmentation technique called RandMSAugment that integrates complementary
strengths of existing methods. RandMSAugment significantly outperforms the
competition on CIFAR-100, STL-10, and Tiny-Imagenet. With very small training
sets (4, 25, 100 samples/class), RandMSAugment achieves compelling performance
gains between 4.1% and 6.75%. Even with more training data (500 samples/class)
we improve performance by 1.03% to 2.47%. RandMSAugment does not require
hyperparameter tuning, extra validation data, or cumbersome optimizations.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16509" title="Abstract">arXiv:2311.16509</a> [<a href="/pdf/2311.16509" title="Download PDF">pdf</a>, <a href="/ps/2311.16509" title="Download PostScript">ps</a>, <a href="/format/2311.16509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StyleCap: Automatic Speaking-Style Captioning from Speech Based on  Speech and Language Self-supervised Learning Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yamauchi%2C+K">Kazuki Yamauchi</a>, 
<a href="/search/cs?searchtype=author&query=Ijima%2C+Y">Yusuke Ijima</a>, 
<a href="/search/cs?searchtype=author&query=Saito%2C+Y">Yuki Saito</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We propose StyleCap, a method to generate natural language descriptions of
speaking styles appearing in speech. Although most of conventional techniques
for para-/non-linguistic information recognition focus on the category
classification or the intensity estimation of pre-defined labels, they cannot
provide the reasoning of the recognition result in an interpretable manner. As
a first step towards an end-to-end method for generating speaking-style prompts
from speech, i.e., automatic speaking-style captioning, StyleCap uses paired
data of speech and natural language descriptions to train neural networks that
predict prefix vectors fed into a large language model (LLM)-based text decoder
from a speech representation vector. We explore an appropriate text decoder and
speech feature representation suitable for this new task. The experimental
results demonstrate that our StyleCap leveraging richer LLMs for the text
decoder, speech self-supervised learning (SSL) features, and sentence
rephrasing augmentation improves the accuracy and diversity of generated
speaking-style captions. Samples of speaking-style captions generated by our
StyleCap are publicly available.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16510" title="Abstract">arXiv:2311.16510</a> [<a href="/pdf/2311.16510" title="Download PDF">pdf</a>, <a href="/format/2311.16510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Source-Free Domain Adaptation with Frozen Multimodal Foundation Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Song Tang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+W">Wenxin Su</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+M">Mao Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiatian Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Source-Free Domain Adaptation (SFDA) aims to adapt a source model for a
target domain, with only access to unlabeled target training data and the
source model pre-trained on a supervised source domain. Relying on pseudo
labeling and/or auxiliary supervision, conventional methods are inevitably
error-prone. To mitigate this limitation, in this work we for the first time
explore the potentials of off-the-shelf vision-language (ViL) multimodal models
(e.g.,CLIP) with rich whilst heterogeneous knowledge. We find that directly
applying the ViL model to the target domain in a zero-shot fashion is
unsatisfactory, as it is not specialized for this particular task but largely
generic. To make it task specific, we propose a novel Distilling multimodal
Foundation model(DIFO)approach. Specifically, DIFO alternates between two steps
during adaptation: (i) Customizing the ViL model by maximizing the mutual
information with the target model in a prompt learning manner, (ii) Distilling
the knowledge of this customized ViL model to the target model. For more
fine-grained and reliable distillation, we further introduce two effective
regularization terms, namely most-likely category encouragement and predictive
consistency. Extensive experiments show that DIFO significantly outperforms the
state-of-the-art alternatives. Our source code will be released.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16511" title="Abstract">arXiv:2311.16511</a> [<a href="/pdf/2311.16511" title="Download PDF">pdf</a>, <a href="/format/2311.16511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPT4Video: A Unified Multimodal Large Language Model for  lnstruction-Followed Understanding and Safety-Aware Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhanyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Longyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Minghao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+C">Chenyang Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huayang Li</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+D">Deng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Luping Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shuming Shi</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhaopeng Tu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">While the recent advances in Multimodal Large Language Models (MLLMs)
constitute a significant leap forward in the field, these models are
predominantly confined to the realm of input-side multimodal comprehension,
lacking the capacity for multimodal content generation. To fill this gap, we
present GPT4Video, a unified multi-model framework that empowers Large Language
Models (LLMs) with the capability of both video understanding and generation.
Specifically, we develop an instruction-following-based approach integrated
with the stable diffusion generative model, which has demonstrated to
effectively and securely handle video generation scenarios. GPT4Video offers
the following benefits: 1) It exhibits impressive capabilities in both video
understanding and generation scenarios. For example, GPT4Video outperforms
Valley by 11.8\% on the Video Question Answering task, and surpasses NExt-GPT
by 2.3\% on the Text to Video generation task. 2) it endows the LLM/MLLM with
video generation capabilities without requiring additional training parameters
and can flexibly interface with a wide range of models to perform video
generation. 3) it maintains a safe and healthy conversation not only in
output-side but also the input side in an end-to-end manner. Qualitative and
qualitative experiments demonstrate that GPT4Video holds the potential to
function as a effective, safe and Humanoid-like video assistant that can handle
both video understanding and generation scenarios.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16512" title="Abstract">arXiv:2311.16512</a> [<a href="/pdf/2311.16512" title="Download PDF">pdf</a>, <a href="/format/2311.16512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoSeR: Bridging Image and Language for Cognitive Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Haoze Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenbo Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianzhuang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haoyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+R">Renjing Pei</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+X">Xueyi Zou</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Youliang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yujiu Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://coser-main.github.io">this https URL</a> ; GitHub repository: <a href="https://github.com/VINHYU/CoSeR">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Existing super-resolution (SR) models primarily focus on restoring local
texture details, often neglecting the global semantic information within the
scene. This oversight can lead to the omission of crucial semantic details or
the introduction of inaccurate textures during the recovery process. In our
work, we introduce the Cognitive Super-Resolution (CoSeR) framework, empowering
SR models with the capacity to comprehend low-resolution images. We achieve
this by marrying image appearance and language understanding to generate a
cognitive embedding, which not only activates prior information from large
text-to-image diffusion models but also facilitates the generation of
high-quality reference images to optimize the SR process. To further improve
image fidelity, we propose a novel condition injection scheme called
"All-in-Attention", consolidating all conditional information into a single
module. Consequently, our method successfully restores semantically correct and
photorealistic details, demonstrating state-of-the-art performance across
multiple benchmarks.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16513" title="Abstract">arXiv:2311.16513</a> [<a href="/pdf/2311.16513" title="Download PDF">pdf</a>, <a href="/format/2311.16513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-grained Appearance Transfer with Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yuteng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanwen Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Jiale%2C+C">Cai Jiale</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Junqing Yu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yawei Luo</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zikai Song</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Q">Qilong Xing</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Youjia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wei Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image-to-image translation (I2I), and particularly its subfield of appearance
transfer, which seeks to alter the visual appearance between images while
maintaining structural coherence, presents formidable challenges. Despite
significant advancements brought by diffusion models, achieving fine-grained
transfer remains complex, particularly in terms of retaining detailed
structural elements and ensuring information fidelity. This paper proposes an
innovative framework designed to surmount these challenges by integrating
various aspects of semantic matching, appearance transfer, and latent
deviation. A pivotal aspect of our approach is the strategic use of the
predicted $x_0$ space by diffusion models within the latent space of diffusion
processes. This is identified as a crucial element for the precise and natural
transfer of fine-grained details. Our framework exploits this space to
accomplish semantic alignment between source and target images, facilitating
mask-wise appearance transfer for improved feature acquisition. A significant
advancement of our method is the seamless integration of these features into
the latent space, enabling more nuanced latent deviations without necessitating
extensive model retraining or fine-tuning. The effectiveness of our approach is
demonstrated through extensive experiments, which showcase its ability to
adeptly handle fine-grained appearance transfers across a wide range of
categories and domains. We provide our code at
https://github.com/babahui/Fine-grained-Appearance-Transfer
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16514" title="Abstract">arXiv:2311.16514</a> [<a href="/pdf/2311.16514" title="Download PDF">pdf</a>, <a href="/format/2311.16514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video Anomaly Detection via Spatio-Temporal Pseudo-Anomaly Generation :  A Unified Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rai%2C+A+K">Ayush K. Rai</a>, 
<a href="/search/cs?searchtype=author&query=Krishna%2C+T">Tarun Krishna</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+F">Feiyan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Drimbarean%2C+A">Alexandru Drimbarean</a>, 
<a href="/search/cs?searchtype=author&query=McGuinness%2C+K">Kevin McGuinness</a>, 
<a href="/search/cs?searchtype=author&query=Smeaton%2C+A+F">Alan F. Smeaton</a>, 
<a href="/search/cs?searchtype=author&query=O%27Connor%2C+N+E">Noel E. O&#x27;Connor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Video Anomaly Detection (VAD) is an open-set recognition task, which is
usually formulated as a one-class classification (OCC) problem, where training
data is comprised of videos with normal instances while test data contains both
normal and anomalous instances. Recent works have investigated the creation of
pseudo-anomalies (PAs) using only the normal data and making strong assumptions
about real-world anomalies with regards to abnormality of objects and speed of
motion to inject prior information about anomalies in an autoencoder (AE) based
reconstruction model during training. This work proposes a novel method for
generating generic spatio-temporal PAs by inpainting a masked out region of an
image using a pre-trained Latent Diffusion Model and further perturbing the
optical flow using mixup to emulate spatio-temporal distortions in the data. In
addition, we present a simple unified framework to detect real-world anomalies
under the OCC setting by learning three types of anomaly indicators, namely
reconstruction quality, temporal irregularity and semantic inconsistency.
Extensive experiments on four VAD benchmark datasets namely Ped2, Avenue,
ShanghaiTech and UBnormal demonstrate that our method performs on par with
other existing state-of-the-art PAs generation and reconstruction based methods
under the OCC setting. Our analysis also examines the transferability and
generalisation of PAs across these datasets, offering valuable insights by
identifying real-world anomalies through PAs.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16515" title="Abstract">arXiv:2311.16515</a> [<a href="/pdf/2311.16515" title="Download PDF">pdf</a>, <a href="/format/2311.16515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Word for Person: Zero-shot Composed Person Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Delong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haiwen Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhicheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+F">Fei Su</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+H">Hongying Meng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Searching for specific person has great security value and social benefits,
and it often involves a combination of visual and textual information.
Conventional person retrieval methods, whether image-based or text-based,
usually fall short in effectively harnessing both types of information, leading
to the loss of accuracy. In this paper, a whole new task called Composed Person
Retrieval (CPR) is proposed to jointly utilize both image and text information
for target person retrieval. However, the supervised CPR must depend on very
costly manual annotation dataset, while there are currently no available
resources. To mitigate this issue, we firstly introduce the Zero-shot Composed
Person Retrieval (ZS-CPR), which leverages existing domain-related data to
resolve the CPR problem without reliance on expensive annotations. Secondly, to
learn ZS-CPR model, we propose a two-stage learning framework, Word4Per, where
a lightweight Textual Inversion Network (TINet) and a text-based person
retrieval model based on fine-tuned Contrastive Language-Image Pre-training
(CLIP) network are learned without utilizing any CPR data. Thirdly, a finely
annotated Image-Text Composed Person Retrieval dataset (ITCPR) is built as the
benchmark to assess the performance of the proposed Word4Per framework.
Extensive experiments under both Rank-1 and mAP demonstrate the effectiveness
of Word4Per for the ZS-CPR task, surpassing the comparative methods by over
10%. The code and ITCPR dataset will be publicly available at
https://github.com/Delong-liu-bupt/Word4Per.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16516" title="Abstract">arXiv:2311.16516</a> [<a href="/pdf/2311.16516" title="Download PDF">pdf</a>, <a href="/format/2311.16516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segment Every Out-of-Distribution Object
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wenjie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xin Dong</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+Y">Yu Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yunhui Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Semantic segmentation models, while effective for in-distribution categories,
face challenges in real-world deployment due to encountering
out-of-distribution (OoD) objects. Detecting these OoD objects is crucial for
safety-critical applications. Existing methods rely on anomaly scores, but
choosing a suitable threshold for generating masks presents difficulties and
can lead to fragmentation and inaccuracy. This paper introduces a method to
convert anomaly Score To segmentation Mask, called S2M, a simple and effective
framework for OoD detection in semantic segmentation. Unlike assigning anomaly
scores to pixels, S2M directly segments the entire OoD object. By transforming
anomaly scores into prompts for a promptable segmentation model, S2M eliminates
the need for threshold selection. Extensive experiments demonstrate that S2M
outperforms the state-of-the-art by approximately 10\% in IoU and 30\% in mean
F1 score, on average, across various benchmarks including Fishyscapes,
Segment-Me-If-You-Can, and RoadAnomaly datasets.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16518" title="Abstract">arXiv:2311.16518</a> [<a href="/pdf/2311.16518" title="Download PDF">pdf</a>, <a href="/format/2311.16518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SeeSR: Towards Semantics-Aware Real-World Image Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Rongyuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lingchen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhengqiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuai Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Owe to the powerful generative priors, the pre-trained text-to-image (T2I)
diffusion models have become increasingly popular in solving the real-world
image super-resolution problem. However, as a consequence of the heavy quality
degradation of input low-resolution (LR) images, the destruction of local
structures can lead to ambiguous image semantics. As a result, the content of
reproduced high-resolution image may have semantic errors, deteriorating the
super-resolution performance. To address this issue, we present a
semantics-aware approach to better preserve the semantic fidelity of generative
real-world image super-resolution. First, we train a degradation-aware prompt
extractor, which can generate accurate soft and hard semantic prompts even
under strong degradation. The hard semantic prompts refer to the image tags,
aiming to enhance the local perception ability of the T2I model, while the soft
semantic prompts compensate for the hard ones to provide additional
representation information. These semantic prompts can encourage the T2I model
to generate detailed and semantically accurate results. Furthermore, during the
inference process, we integrate the LR images into the initial sampling noise
to mitigate the diffusion model's tendency to generate excessive random
details. The experiments show that our method can reproduce more realistic
image details and hold better the semantics.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16519" title="Abstract">arXiv:2311.16519</a> [<a href="/pdf/2311.16519" title="Download PDF">pdf</a>, <a href="/format/2311.16519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> B-LSTM-MIONet: Bayesian LSTM-based Neural Operators for Learning the  Response of Complex Dynamical Systems to Length-Variant Multiple Input  Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kong%2C+Z">Zhihao Kong</a>, 
<a href="/search/cs?searchtype=author&query=Mollaali%2C+A">Amirhossein Mollaali</a>, 
<a href="/search/cs?searchtype=author&query=Moya%2C+C">Christian Moya</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+N">Na Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Guang Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Deep Operator Network (DeepONet) is a neural network framework for learning
nonlinear operators such as those from ordinary differential equations (ODEs)
describing complex systems. Multiple-input deep neural operators (MIONet)
extended DeepONet to allow multiple input functions in different Banach spaces.
MIONet offers flexibility in training dataset grid spacing, without constraints
on output location. However, it requires offline inputs and cannot handle
varying sequence lengths in testing datasets, limiting its real-time
application in dynamic complex systems. This work redesigns MIONet, integrating
Long Short Term Memory (LSTM) to learn neural operators from time-dependent
data. This approach overcomes data discretization constraints and harnesses
LSTM's capability with variable-length, real-time data. Factors affecting
learning performance, like algorithm extrapolation ability are presented. The
framework is enhanced with uncertainty quantification through a novel Bayesian
method, sampling from MIONet parameter distributions. Consequently, we develop
the B-LSTM-MIONet, incorporating LSTM's temporal strengths with Bayesian
robustness, resulting in a more precise and reliable model for noisy datasets.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16520" title="Abstract">arXiv:2311.16520</a> [<a href="/pdf/2311.16520" title="Download PDF">pdf</a>, <a href="/format/2311.16520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Value Approximation for Two-Player General-Sum Differential Games with  State Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ghimire%2C+M">Mukesh Ghimire</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenlong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhe Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yi Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to TRO
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG)

</div>
<p class="mathjax">Solving Hamilton-Jacobi-Isaacs (HJI) PDEs enables equilibrial feedback
control in two-player differential games, yet faces the curse of dimensionality
(CoD). While physics-informed machine learning has been adopted to address CoD
in solving PDEs, this method falls short in learning discontinuous solutions
due to its sampling nature, leading to poor safety performance of the resulting
controllers in robotics applications where values are discontinuous due to
state or other temporal logic constraints. In this study, we explore three
potential solutions to this problem: (1) a hybrid learning method that uses
both equilibrium demonstrations and the HJI PDE, (2) a value-hardening method
where a sequence of HJIs are solved with increasing Lipschitz constant on the
constraint violation penalty, and (3) the epigraphical technique that lifts the
value to a higher dimensional auxiliary state space where the value becomes
continuous. Evaluations through 5D and 9D vehicle simulations and 13D drone
simulations reveal that the hybrid method outperforms others in terms of
generalization and safety performance.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16521" title="Abstract">arXiv:2311.16521</a> [<a href="/pdf/2311.16521" title="Download PDF">pdf</a>, <a href="/format/2311.16521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inspo: Writing Stories with a Flock of AIs and Humans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chieh-Yang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gautam%2C+S">Sanjana Gautam</a>, 
<a href="/search/cs?searchtype=author&query=Brooks%2C+S+M">Shannon McClellan Brooks</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Ya-Fang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T+%27">Ting-Hao &#x27;Kenneth&#x27; Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) have advanced automated writing assistance,
enabling complex tasks like co-writing novels and poems. However, real-world
writing typically requires various support and collaboration across stages and
scenarios. Existing research mainly examines how writers utilize single text
generators, neglecting this broader context. This paper introduces Inspo, a
web-based editor that incorporates various text generators and online crowd
workers. Through a three-phase user study, we examine writers' interactions
with Inspo for novel writing. Quantitative analyses of writing logs highlight
changes in participants' writing progress and the influence of various
text-generation models. Complementing this with qualitative insights from
semi-structured interviews, we illustrate participants' perceptions of these
models and the crowd. Based on the findings, we provide design recommendations
for the next generation of intelligent writing tools and discuss the potential
sociocultural implications of integrating AI and human input in the writing
process.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16522" title="Abstract">arXiv:2311.16522</a> [<a href="/pdf/2311.16522" title="Download PDF">pdf</a>, <a href="/ps/2311.16522" title="Download PostScript">ps</a>, <a href="/format/2311.16522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of dynamic characteristics of power grid based on GNN and  application on knowledge graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pei%2C+H">Hao Pei</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Si Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chuanfu Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Che Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haoming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sizhe Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Signal Processing (eess.SP)

</div>
<p class="mathjax">A novel method for detecting faults in power grids using a graph neural
network (GNN) has been developed, aimed at enhancing intelligent fault
diagnosis in network operation and maintenance. This GNN-based approach
identifies faulty nodes within the power grid through a specialized electrical
feature extraction model coupled with a knowledge graph. Incorporating temporal
data, the method leverages the status of nodes from preceding and subsequent
time periods to aid in current fault detection. To validate the effectiveness
of this GNN in extracting node features, a correlation analysis of the output
features from each node within the neural network layer was conducted. The
results from experiments show that this method can accurately locate fault
nodes in simulated scenarios with a remarkable 99.53% accuracy. Additionally,
the graph neural network's feature modeling allows for a qualitative
examination of how faults spread across nodes, providing valuable insights for
analyzing fault nodes.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16523" title="Abstract">arXiv:2311.16523</a> [<a href="/pdf/2311.16523" title="Download PDF">pdf</a>, <a href="/format/2311.16523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Phase Preservation of N-Port Networks under General Connections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Jianqi Chen</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+C">Chao Chen</a>, 
<a href="/search/eess?searchtype=author&query=Qiu%2C+L">Li Qiu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This study first introduces the frequency-wise phases of n-port linear
time-invariant networks based on recently defined phases of complex matrices.
Such a phase characterization can be used to quantify the well-known notion of
passivity for networks. Further, a class of matrix operations induced by fairly
common n-port network connections is examined. The intrinsic phase properties
of networks under such connections are preserved. Concretely, a scalable
phase-preserving criterion is proposed, which involves only the phase
properties of individual subnetworks, under the matrix operations featured by
connections. This criterion ensures that the phase range of the integrated
network can be verified effectively and that the scalability of the analyses
can be maintained. In addition, the inverse operations of the considered
connections, that is, network subtractions with correspondences are examined.
With the known phase ranges of the integrated network and one of its
subnetworks, the maximal allowable phase range of the remaining subnetwork can
also be determined explicitly in a unified form for all types of subtractions.
Finally, we extend the phase-preserving properties from the aforementioned
connections to more general matrix operations defined using a certain
indefinite inner product.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16524" title="Abstract">arXiv:2311.16524</a> [<a href="/pdf/2311.16524" title="Download PDF">pdf</a>, <a href="/format/2311.16524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Teeth Reconstruction from Panoramic Radiographs using Neural Implicit  Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Sihwa Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seongjun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+I">In-Seok Song</a>, 
<a href="/search/cs?searchtype=author&query=Baek%2C+S+J">Seung Jun Baek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 2 figures, accepted to International Conference on Medical Image Computing and Computer-Assisted Intervention MICCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Panoramic radiography is a widely used imaging modality in dental practice
and research. However, it only provides flattened 2D images, which limits the
detailed assessment of dental structures. In this paper, we propose Occudent, a
framework for 3D teeth reconstruction from panoramic radiographs using neural
implicit functions, which, to the best of our knowledge, is the first work to
do so. For a given point in 3D space, the implicit function estimates whether
the point is occupied by a tooth, and thus implicitly determines the boundaries
of 3D tooth shapes. Firstly, Occudent applies multi-label segmentation to the
input panoramic radiograph. Next, tooth shape embeddings as well as tooth class
embeddings are generated from the segmentation outputs, which are fed to the
reconstruction network. A novel module called Conditional eXcitation (CX) is
proposed in order to effectively incorporate the combined shape and class
embeddings into the implicit function. The performance of Occudent is evaluated
using both quantitative and qualitative measures. Importantly, Occudent is
trained and validated with actual panoramic radiographs as input, distinct from
recent works which used synthesized images. Experiments demonstrate the
superiority of Occudent over state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16526" title="Abstract">arXiv:2311.16526</a> [<a href="/pdf/2311.16526" title="Download PDF">pdf</a>, <a href="/format/2311.16526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On robust overfitting: adversarial training induced distribution matters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+R">Runzhi Tian</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yongyi Mao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Adversarial training may be regarded as standard training with a modified
loss function. But its generalization error appears much larger than standard
training under standard loss. This phenomenon, known as robust overfitting, has
attracted significant research attention and remains largely as a mystery. In
this paper, we first show empirically that robust overfitting correlates with
the increasing generalization difficulty of the perturbation-induced
distributions along the trajectory of adversarial training (specifically
PGD-based adversarial training). We then provide a novel upper bound for
generalization error with respect to the perturbation-induced distributions, in
which a notion of the perturbation operator, referred to "local dispersion",
plays an important role.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16532" title="Abstract">arXiv:2311.16532</a> [<a href="/pdf/2311.16532" title="Download PDF">pdf</a>, <a href="/format/2311.16532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Abusing Processor Exception for General Binary Instrumentation on  Bare-metal Embedded Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+S">Shipei Qu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaolin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+D">Dawu Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Analyzing the security of closed-source drivers and libraries in embedded
systems holds significant importance, given their fundamental role in the
supply chain. Unlike x86, embedded platforms lack comprehensive binary
manipulating tools, making it difficult for researchers and developers to
effectively detect and patch security issues in such closed-source components.
Existing works either depend on full-fledged operating system features or
suffer from tedious corner cases, restricting their application to bare-metal
firmware prevalent in embedded environments. In this paper, we present PIFER
(Practical Instrumenting Framework for Embedded fiRmware) that enables general
and fine-grained static binary instrumentation for embedded bare-metal
firmware. By abusing the built-in hardware exception-handling mechanism of the
embedded processors, PIFER can perform instrumentation on arbitrary target
addresses. Additionally, We propose an instruction translation-based scheme to
guarantee the correct execution of the original firmware after patching. We
evaluate PIFER against real-world, complex firmware, including Zephyr RTOS,
CoreMark benchmark, and a close-sourced commercial product. The results
indicate that PIFER correctly instrumented 98.9% of the instructions. Further,
a comprehensive performance evaluation was conducted, demonstrating the
practicality and efficiency of our work.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16533" title="Abstract">arXiv:2311.16533</a> [<a href="/pdf/2311.16533" title="Download PDF">pdf</a>, <a href="/format/2311.16533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motor State Prediction and Friction Compensation based on Data-driven  Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dasanayake%2C+N">Nimantha Dasanayake</a>, 
<a href="/search/eess?searchtype=author&query=Perera%2C+S">Shehara Perera</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In order to provide robust, reliable, and accurate position and velocity
control of motor drives, friction compensation has emerged as a key difficulty.
Non-characterised friction could give rise to large position errors and
vibrations which could be intensified by stick-slip motion and limit cycles.
This paper presents an application of two data-driven nonlinear model
identification techniques to discover the governing equations of motor dynamics
that also characterise friction. Namely, the extraction of low-power data from
time-delayed coordinates of motor velocity and sparse regression on nonlinear
terms was applied to data acquired from a Brushless DC (BLDC) motor, to
identify the underlying dynamics. The latter can be considered an extension of
the conventional linear motor model commonly used in many model-based
controllers. The identified nonlinear model was then contrasted with a
nonlinear model that included the LuGre friction model and a linear model
without friction. A nonlinear grey box model estimation method was used to
calculate the optimum friction parameters for the LuGre model. The resulting
nonlinear motor model with friction characteristics was then validated using a
feedback friction compensation algorithm. The novel model showed more than 90%
accuracy in predicting the motor states in all considered input excitation
signals. In addition, the model-based friction compensation scheme showed a
relative increase in performance when compared with a system without friction
compensation.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16534" title="Abstract">arXiv:2311.16534</a> [<a href="/pdf/2311.16534" title="Download PDF">pdf</a>, <a href="/format/2311.16534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Prompt Learning: A Comprehensive Survey and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiangguo Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiawen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xixi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hong Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yun Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Artificial General Intelligence (AGI) has revolutionized numerous fields, yet
its integration with graph data, a cornerstone in our interconnected world,
remains nascent. This paper presents a pioneering survey on the emerging domain
of graph prompts in AGI, addressing key challenges and opportunities in
harnessing graph data for AGI applications. Despite substantial advancements in
AGI across natural language processing and computer vision, the application to
graph data is relatively underexplored. This survey critically evaluates the
current landscape of AGI in handling graph data, highlighting the distinct
challenges in cross-modality, cross-domain, and cross-task applications
specific to graphs. Our work is the first to propose a unified framework for
understanding graph prompt learning, offering clarity on prompt tokens, token
structures, and insertion patterns in the graph domain. We delve into the
intrinsic properties of graph prompts, exploring their flexibility,
expressiveness, and interplay with existing graph models. A comprehensive
taxonomy categorizes over 100 works in this field, aligning them with
pre-training tasks across node-level, edge-level, and graph-level objectives.
Additionally, we present, ProG, a Python library, and an accompanying website,
to support and advance research in graph prompting. The survey culminates in a
discussion of current challenges and future directions, offering a roadmap for
research in graph prompting within AGI. Through this comprehensive analysis, we
aim to catalyze further exploration and practical applications of AGI in graph
data, underlining its potential to reshape AGI fields and beyond. ProG and the
website can be accessed by
\url{https://github.com/WxxShirley/Awesome-Graph-Prompt}, and
\url{https://github.com/sheldonresearch/ProG}, respectively.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16535" title="Abstract">arXiv:2311.16535</a> [<a href="/pdf/2311.16535" title="Download PDF">pdf</a>, <a href="/format/2311.16535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive encoder pre-training-based clustered federated learning for  heterogeneous data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tun%2C+Y+L">Ye Lin Tun</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+M+N+H">Minh N.H. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Thwal%2C+C+M">Chu Myaet Thwal</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jinwoo Choi</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+C+S">Choong Seon Hong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Neural Networks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated learning (FL) is a promising approach that enables distributed
clients to collaboratively train a global model while preserving their data
privacy. However, FL often suffers from data heterogeneity problems, which can
significantly affect its performance. To address this, clustered federated
learning (CFL) has been proposed to construct personalized models for different
client clusters. One effective client clustering strategy is to allow clients
to choose their own local models from a model pool based on their performance.
However, without pre-trained model parameters, such a strategy is prone to
clustering failure, in which all clients choose the same model. Unfortunately,
collecting a large amount of labeled data for pre-training can be costly and
impractical in distributed environments. To overcome this challenge, we
leverage self-supervised contrastive learning to exploit unlabeled data for the
pre-training of FL systems. Together, self-supervised pre-training and client
clustering can be crucial components for tackling the data heterogeneity issues
of FL. Leveraging these two crucial strategies, we propose contrastive
pre-training-based clustered federated learning (CP-CFL) to improve the model
convergence and overall performance of FL systems. In this work, we demonstrate
the effectiveness of CP-CFL through extensive experiments in heterogeneous FL
settings, and present various interesting observations.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16536" title="Abstract">arXiv:2311.16536</a> [<a href="/pdf/2311.16536" title="Download PDF">pdf</a>, <a href="/format/2311.16536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personalized Predictions of Glioblastoma Infiltration: Mathematical  Models, Physics-Informed Neural Networks and Multimodal Scans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R+Z">Ray Zirui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ezhov%2C+I">Ivan Ezhov</a>, 
<a href="/search/cs?searchtype=author&query=Balcerak%2C+M">Michal Balcerak</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+A">Andy Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wiestler%2C+B">Benedikt Wiestler</a>, 
<a href="/search/cs?searchtype=author&query=Menze%2C+B">Bjoern Menze</a>, 
<a href="/search/cs?searchtype=author&query=Lowengrub%2C+J">John Lowengrub</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Image and Video Processing (eess.IV); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Predicting the infiltration of Glioblastoma (GBM) from medical MRI scans is
crucial for understanding tumor growth dynamics and designing personalized
radiotherapy treatment plans.Mathematical models of GBM growth can complement
the data in the prediction of spatial distributions of tumor cells. However,
this requires estimating patient-specific parameters of the model from clinical
data, which is a challenging inverse problem due to limited temporal data and
the limited time between imaging and diagnosis. This work proposes a method
that uses Physics-Informed Neural Networks (PINNs) to estimate patient-specific
parameters of a reaction-diffusion PDE model of GBM growth from a single 3D
structural MRI snapshot. PINNs embed both the data and the PDE into a loss
function, thus integrating theory and data. Key innovations include the
identification and estimation of characteristic non-dimensional parameters, a
pre-training step that utilizes the non-dimensional parameters and a
fine-tuning step to determine the patient specific parameters. Additionally,
the diffuse domain method is employed to handle the complex brain geometry
within the PINN framework. Our method is validated both on synthetic and
patient datasets, and shows promise for real-time parametric inference in the
clinical setting for personalized GBM treatment.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16538" title="Abstract">arXiv:2311.16538</a> [<a href="/pdf/2311.16538" title="Download PDF">pdf</a>, <a href="/format/2311.16538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning with Diffusion Models for Privacy-Sensitive Vision  Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tun%2C+Y+L">Ye Lin Tun</a>, 
<a href="/search/cs?searchtype=author&query=Thwal%2C+C+M">Chu Myaet Thwal</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+J+S">Ji Su Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+S+M">Sun Moo Kang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chaoning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+C+S">Choong Seon Hong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Diffusion models have shown great potential for vision-related tasks,
particularly for image generation. However, their training is typically
conducted in a centralized manner, relying on data collected from publicly
available sources. This approach may not be feasible or practical in many
domains, such as the medical field, which involves privacy concerns over data
collection. Despite the challenges associated with privacy-sensitive data, such
domains could still benefit from valuable vision services provided by diffusion
models. Federated learning (FL) plays a crucial role in enabling decentralized
model training without compromising data privacy. Instead of collecting data,
an FL system gathers model parameters, effectively safeguarding the private
data of different parties involved. This makes FL systems vital for managing
decentralized learning tasks, especially in scenarios where privacy-sensitive
data is distributed across a network of clients. Nonetheless, FL presents its
own set of challenges due to its distributed nature and privacy-preserving
properties. Therefore, in this study, we explore the FL strategy to train
diffusion models, paving the way for the development of federated diffusion
models. We conduct experiments on various FL scenarios, and our findings
demonstrate that federated diffusion models have great potential to deliver
vision services to privacy-sensitive domains.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16540" title="Abstract">arXiv:2311.16540</a> [<a href="/pdf/2311.16540" title="Download PDF">pdf</a>, <a href="/format/2311.16540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication Efficiency Optimization of Federated Learning for  Computing and Network Convergence of 6G Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yizhuo Cai</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+B">Bo Lei</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qianying Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+J">Jing Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+M">Min Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yushun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xing Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 11 figures, accepted by Frontiers of Information Technology &amp; Electronic Engineering
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Federated learning effectively addresses issues such as data privacy by
collaborating across participating devices to train global models. However,
factors such as network topology and device computing power can affect its
training or communication process in complex network environments. A new
network architecture and paradigm with computing-measurable, perceptible,
distributable, dispatchable, and manageable capabilities, computing and network
convergence (CNC) of 6G networks can effectively support federated learning
training and improve its communication efficiency. By guiding the participating
devices' training in federated learning based on business requirements,
resource load, network conditions, and arithmetic power of devices, CNC can
reach this goal. In this paper, to improve the communication efficiency of
federated learning in complex networks, we study the communication efficiency
optimization of federated learning for computing and network convergence of 6G
networks, methods that gives decisions on its training process for different
network conditions and arithmetic power of participating devices in federated
learning. The experiments address two architectures that exist for devices in
federated learning and arrange devices to participate in training based on
arithmetic power while achieving optimization of communication efficiency in
the process of transferring model parameters. The results show that the method
we proposed can (1) cope well with complex network situations (2) effectively
balance the delay distribution of participating devices for local training (3)
improve the communication efficiency during the transfer of model parameters
(4) improve the resource utilization in the network.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16542" title="Abstract">arXiv:2311.16542</a> [<a href="/pdf/2311.16542" title="Download PDF">pdf</a>, <a href="/format/2311.16542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agents meet OKR: An Object and Key Results Driven Agent System with  Hierarchical Self-Collaboration and Self-Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chongyang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+K">Kanle Shi</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haibin Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this study, we introduce the concept of OKR-Agent designed to enhance the
capabilities of Large Language Models (LLMs) in task-solving. Our approach
utilizes both self-collaboration and self-correction mechanism, facilitated by
hierarchical agents, to address the inherent complexities in task-solving. Our
key observations are two-fold: first, effective task-solving demands in-depth
domain knowledge and intricate reasoning, for which deploying specialized
agents for individual sub-tasks can markedly enhance LLM performance. Second,
task-solving intrinsically adheres to a hierarchical execution structure,
comprising both high-level strategic planning and detailed task execution.
Towards this end, our OKR-Agent paradigm aligns closely with this hierarchical
structure, promising enhanced efficacy and adaptability across a range of
scenarios. Specifically, our framework includes two novel modules: hierarchical
Objects and Key Results generation and multi-level evaluation, each
contributing to more efficient and robust task-solving. In practical,
hierarchical OKR generation decomposes Objects into multiple sub-Objects and
assigns new agents based on key results and agent responsibilities. These
agents subsequently elaborate on their designated tasks and may further
decompose them as necessary. Such generation operates recursively and
hierarchically, culminating in a comprehensive set of detailed solutions. The
multi-level evaluation module of OKR-Agent refines solution by leveraging
feedback from all associated agents, optimizing each step of the process. This
ensures solution is accurate, practical, and effectively address intricate task
requirements, enhancing the overall reliability and quality of the outcome.
Experimental results also show our method outperforms the previous methods on
several tasks. Code and demo are available at https://okr-agent.github.io/
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16543" title="Abstract">arXiv:2311.16543</a> [<a href="/pdf/2311.16543" title="Download PDF">pdf</a>, <a href="/format/2311.16543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RTLFixer: Automatically Fixing RTL Syntax Errors with Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsai%2C+Y">YunDa Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mingjie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+H">Haoxing Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">This paper presents RTLFixer, a novel framework enabling automatic syntax
errors fixing for Verilog code with Large Language Models (LLMs). Despite LLM's
promising capabilities, our analysis indicates that approximately 55% of errors
in LLM-generated Verilog are syntax-related, leading to compilation failures.
To tackle this issue, we introduce a novel debugging framework that employs
Retrieval-Augmented Generation (RAG) and ReAct prompting, enabling LLMs to act
as autonomous agents in interactively debugging the code with feedback. This
framework demonstrates exceptional proficiency in resolving syntax errors,
successfully correcting about 98.5% of compilation errors in our debugging
dataset, comprising 212 erroneous implementations derived from the VerilogEval
benchmark. Our method leads to 32.3% and 10.1% increase in pass@1 success rates
in the VerilogEval-Machine and VerilogEval-Human benchmarks, respectively.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16544" title="Abstract">arXiv:2311.16544</a> [<a href="/pdf/2311.16544" title="Download PDF">pdf</a>, <a href="/format/2311.16544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Irreducible Spectral Synchronization for Robust Rotation Averaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Howell%2C+O">Owen Howell</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haoen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Rosen%2C+D">David Rosen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Group Theory (math.GR); Optimization and Control (math.OC)

</div>
<p class="mathjax">Rotation averaging (RA) is a fundamental problem in robotics and computer
vision. In RA, the goal is to estimate a set of $N$ unknown orientations
$R_{1}, ..., R_{N} \in SO(3)$, given noisy measurements $R_{ij} \sim R^{-1}_{i}
R_{j}$ of a subset of their pairwise relative rotations. This problem is both
nonconvex and NP-hard, and thus difficult to solve in the general case. We
apply harmonic analysis on compact groups to derive a (convex) spectral
relaxation constructed from truncated Fourier decompositions of the individual
summands appearing in the RA objective; we then recover an estimate of the RA
solution by computing a few extremal eigenpairs of this relaxation, and
(approximately) solving a consensus problem. Our approach affords several
notable advantages versus prior RA methods: it can be used in conjunction with
\emph{any} smooth loss function (including, but not limited to, robust
M-estimators), does not require any initialization, and is implemented using
only simple (and highly scalable) linear-algebraic computations and
parallelizable optimizations over band-limited functions of individual
rotational states. Moreover, under the (physically well-motivated) assumption
of multiplicative Langevin measurement noise, we derive explicit performance
guarantees for our spectral estimator (in the form of probabilistic tail bounds
on the estimation error) that are parameterized in terms of graph-theoretic
quantities of the underlying measurement network. By concretely linking
estimator performance with properties of the underlying measurement graph, our
results also indicate how to devise measurement networks that are
\emph{guaranteed} to achieve accurate estimation, enabling such downstream
tasks as sensor placement, network compression, and active sensing.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16545" title="Abstract">arXiv:2311.16545</a> [<a href="/pdf/2311.16545" title="Download PDF">pdf</a>, <a href="/ps/2311.16545" title="Download PostScript">ps</a>, <a href="/format/2311.16545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unravelling DNS Performance: A Historical Examination of F-ROOT in  Southeast Asia
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiajia Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+C">Chao Qi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages,4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The DNS root server system uses Anycast technology to provide resolution
through widely distributed root nodes. In recent years, the F-root node has
seen astonishing growth and now boasts the largest number of nodes among the 13
root servers. Based on Ripe Atlas measurement data, we examined the
availability and query latency of the F-root within the Southeast Asian region
historically. The collected data illustrates how latency varies with changes in
the number of root nodes, how the geographic distribution of responding root
nodes changes in different periods, and examines the most recent differences
between countries in terms of latency distribution. This study sheds light on
the evolving landscape of DNS infrastructure in Southeast Asia.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16552" title="Abstract">arXiv:2311.16552</a> [<a href="/pdf/2311.16552" title="Download PDF">pdf</a>, <a href="/format/2311.16552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HandyPriors: Physically Consistent Perception of Hand-Object  Interactions with Differentiable Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shutong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yi-Ling Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+G">Guanglei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Heiden%2C+E">Eric Heiden</a>, 
<a href="/search/cs?searchtype=author&query=Turpin%2C+D">Dylan Turpin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingzhou Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Ming Lin</a>, 
<a href="/search/cs?searchtype=author&query=Macklin%2C+M">Miles Macklin</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+A">Animesh Garg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Various heuristic objectives for modeling hand-object interaction have been
proposed in past work. However, due to the lack of a cohesive framework, these
objectives often possess a narrow scope of applicability and are limited by
their efficiency or accuracy. In this paper, we propose HandyPriors, a unified
and general pipeline for pose estimation in human-object interaction scenes by
leveraging recent advances in differentiable physics and rendering. Our
approach employs rendering priors to align with input images and segmentation
masks along with physics priors to mitigate penetration and relative-sliding
across frames. Furthermore, we present two alternatives for hand and object
pose estimation. The optimization-based pose estimation achieves higher
accuracy, while the filtering-based tracking, which utilizes the differentiable
priors as dynamics and observation models, executes faster. We demonstrate that
HandyPriors attains comparable or superior results in the pose estimation task,
and that the differentiable physics module can predict contact information for
pose refinement. We also show that our approach generalizes to perception
tasks, including robotic hand manipulation and human-object pose estimation in
the wild.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16555" title="Abstract">arXiv:2311.16555</a> [<a href="/pdf/2311.16555" title="Download PDF">pdf</a>, <a href="/format/2311.16555" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Scene Text Detectors with Realistic Text Image Synthesis Using  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+L">Ling Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zijie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yingying Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiang Bai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Scene text detection techniques have garnered significant attention due to
their wide-ranging applications. However, existing methods have a high demand
for training data, and obtaining accurate human annotations is labor-intensive
and time-consuming. As a solution, researchers have widely adopted synthetic
text images as a complementary resource to real text images during
pre-training. Yet there is still room for synthetic datasets to enhance the
performance of scene text detectors. We contend that one main limitation of
existing generation methods is the insufficient integration of foreground text
with the background. To alleviate this problem, we present the Diffusion Model
based Text Generator (DiffText), a pipeline that utilizes the diffusion model
to seamlessly blend foreground text regions with the background's intrinsic
features. Additionally, we propose two strategies to generate visually coherent
text with fewer spelling errors. With fewer text instances, our produced text
images consistently surpass other synthetic data in aiding text detectors.
Extensive experiments on detecting horizontal, rotated, curved, and line-level
texts demonstrate the effectiveness of DiffText in producing realistic text
images.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16556" title="Abstract">arXiv:2311.16556</a> [<a href="/pdf/2311.16556" title="Download PDF">pdf</a>, <a href="/format/2311.16556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Label Distribution Learning for Multi-Label Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xingyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+Y">Yuexuan An</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+L">Lei Qi</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+X">Xin Geng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Multi-label classification (MLC) refers to the problem of tagging a given
instance with a set of relevant labels. Most existing MLC methods are based on
the assumption that the correlation of two labels in each label pair is
symmetric, which is violated in many real-world scenarios. Moreover, most
existing methods design learning processes associated with the number of
labels, which makes their computational complexity a bottleneck when scaling up
to large-scale output space. To tackle these issues, we propose a novel MLC
learning method named Scalable Label Distribution Learning (SLDL) for
multi-label classification which can describe different labels as distributions
in a latent space, where the label correlation is asymmetric and the dimension
is independent of the number of labels. Specifically, SLDL first converts
labels into continuous distributions within a low-dimensional latent space and
leverages the asymmetric metric to establish the correlation between different
labels. Then, it learns the mapping from the feature space to the latent space,
resulting in the computational complexity is no longer related to the number of
labels. Finally, SLDL leverages a nearest-neighbor-based strategy to decode the
latent representations and obtain the final predictions. Our extensive
experiments illustrate that SLDL can achieve very competitive classification
performances with little computational consumption.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16564" title="Abstract">arXiv:2311.16564</a> [<a href="/pdf/2311.16564" title="Download PDF">pdf</a>, <a href="/format/2311.16564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-agent statistical discriminative sub-trajectory mining and an  application to NBA basketball
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bunker%2C+R">Rory Bunker</a>, 
<a href="/search/cs?searchtype=author&query=Duy%2C+V+N+L">Vo Nguyen Le Duy</a>, 
<a href="/search/cs?searchtype=author&query=Tabei%2C+Y">Yasuo Tabei</a>, 
<a href="/search/cs?searchtype=author&query=Takeuchi%2C+I">Ichiro Takeuchi</a>, 
<a href="/search/cs?searchtype=author&query=Fujii%2C+K">Keisuke Fujii</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">Improvements in tracking technology through optical and computer vision
systems have enabled a greater understanding of the movement-based behaviour of
multiple agents, including in team sports. In this study, a Multi-Agent
Statistically Discriminative Sub-Trajectory Mining (MA-Stat-DSM) method is
proposed that takes a set of binary-labelled agent trajectory matrices as input
and incorporates Hausdorff distance to identify sub-matrices that statistically
significantly discriminate between the two groups of labelled trajectory
matrices. Utilizing 2015/16 SportVU NBA tracking data, agent trajectory
matrices representing attacks consisting of the trajectories of five agents
(the ball, shooter, last passer, shooter defender, and last passer defender),
were truncated to correspond to the time interval following the receipt of the
ball by the last passer, and labelled as effective or ineffective based on a
definition of attack effectiveness that we devise in the current study. After
identifying appropriate parameters for MA-Stat-DSM by iteratively applying it
to all matches involving the two top- and two bottom-placed teams from the
2015/16 NBA season, the method was then applied to selected matches and could
identify and visualize the portions of plays, e.g., involving passing, on-,
and/or off-the-ball movements, which were most relevant in rendering attacks
effective or ineffective.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16565" title="Abstract">arXiv:2311.16565</a> [<a href="/pdf/2311.16565" title="Download PDF">pdf</a>, <a href="/format/2311.16565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffusionTalker: Personalization and Acceleration for Speech-Driven 3D  Face Diffuser
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xiaobao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+M">Ming Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yitong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+N">Naiming Yao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xingyu Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hui Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Speech-driven 3D facial animation has been an attractive task in both
academia and industry. Traditional methods mostly focus on learning a
deterministic mapping from speech to animation. Recent approaches start to
consider the non-deterministic fact of speech-driven 3D face animation and
employ the diffusion model for the task. However, personalizing facial
animation and accelerating animation generation are still two major limitations
of existing diffusion-based methods. To address the above limitations, we
propose DiffusionTalker, a diffusion-based method that utilizes contrastive
learning to personalize 3D facial animation and knowledge distillation to
accelerate 3D animation generation. Specifically, to enable personalization, we
introduce a learnable talking identity to aggregate knowledge in audio
sequences. The proposed identity embeddings extract customized facial cues
across different people in a contrastive learning manner. During inference,
users can obtain personalized facial animation based on input audio, reflecting
a specific talking style. With a trained diffusion model with hundreds of
steps, we distill it into a lightweight model with 8 steps for acceleration.
Extensive experiments are conducted to demonstrate that our method outperforms
state-of-the-art methods. The code will be released.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16566" title="Abstract">arXiv:2311.16566</a> [<a href="/pdf/2311.16566" title="Download PDF">pdf</a>, <a href="/format/2311.16566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Property Testing with Online Adversaries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ben-Eliezer%2C+O">Omri Ben-Eliezer</a>, 
<a href="/search/cs?searchtype=author&query=Kelman%2C+E">Esty Kelman</a>, 
<a href="/search/cs?searchtype=author&query=Meir%2C+U">Uri Meir</a>, 
<a href="/search/cs?searchtype=author&query=Raskhodnikova%2C+S">Sofya Raskhodnikova</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in 15th Innovations in Theoretical Computer Science (ITCS 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC); Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">The online manipulation-resilient testing model, proposed by Kalemaj,
Raskhodnikova and Varma (ITCS 2022 and Theory of Computing 2023), studies
property testing in situations where access to the input degrades continuously
and adversarially. Specifically, after each query made by the tester is
answered, the adversary can intervene and either erase or corrupt $t$ data
points. In this work, we investigate a more nuanced version of the online model
in order to overcome old and new impossibility results for the original model.
We start by presenting an optimal tester for linearity and a lower bound for
low-degree testing of Boolean functions in the original model. We overcome the
lower bound by allowing batch queries, where the tester gets a group of queries
answered between manipulations of the data. Our batch size is small enough so
that function values for a single batch on their own give no information about
whether the function is of low degree. Finally, to overcome the impossibility
results of Kalemaj et al. for sortedness and the Lipschitz property of
sequences, we extend the model to include $t&lt;1$, i.e., adversaries that make
less than one erasure per query. For sortedness, we characterize the rate of
erasures for which online testing can be performed, exhibiting a sharp
transition from optimal query complexity to impossibility of testability (with
any number of queries). Our online tester works for a general class of local
properties of sequences. One feature of our results is that we get new (and in
some cases, simpler) optimal algorithms for several properties in the standard
property testing model.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16567" title="Abstract">arXiv:2311.16567</a> [<a href="/pdf/2311.16567" title="Download PDF">pdf</a>, <a href="/format/2311.16567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MobileDiffusion: Subsecond Text-to-Image Generation on Mobile Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yanwu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zhisheng Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+T">Tingbo Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The deployment of large-scale text-to-image diffusion models on mobile
devices is impeded by their substantial model size and slow inference speed. In
this paper, we propose \textbf{MobileDiffusion}, a highly efficient
text-to-image diffusion model obtained through extensive optimizations in both
architecture and sampling techniques. We conduct a comprehensive examination of
model architecture design to reduce redundancy, enhance computational
efficiency, and minimize model's parameter count, while preserving image
generation quality. Additionally, we employ distillation and diffusion-GAN
finetuning techniques on MobileDiffusion to achieve 8-step and 1-step inference
respectively. Empirical studies, conducted both quantitatively and
qualitatively, demonstrate the effectiveness of our proposed techniques.
MobileDiffusion achieves a remarkable \textbf{sub-second} inference speed for
generating a $512\times512$ image on mobile devices, establishing a new state
of the art.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16568" title="Abstract">arXiv:2311.16568</a> [<a href="/pdf/2311.16568" title="Download PDF">pdf</a>, <a href="/ps/2311.16568" title="Download PostScript">ps</a>, <a href="/format/2311.16568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active RIS Enhanced Spectrum Sensing for Cognitive Radio Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ge%2C+J">Jungang Ge</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Ying-Chang Liang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Sumei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yonghong Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In opportunistic cognitive radio networks, when the primary signal is very
weak compared to the background noise, the secondary user requires long sensing
time to achieve a reliable spectrum sensing performance, leading to little
remaining time for the secondary transmission. To tackle this issue, we propose
an active reconfigurable intelligent surface (RIS) assisted spectrum sensing
system, where the received signal strength from the interested primary user can
be enhanced and underlying interference within the background noise can be
mitigated as well. In comparison with the passive RIS, the active RIS can not
only adapt the phase shift of each reflecting element but also amplify the
incident signals. Notably, we study the reflecting coefficient matrix (RCM)
optimization problem to improve the detection probability given a maximum
tolerable false alarm probability and limited sensing time. Then, we show that
the formulated problem can be equivalently transformed to a weighted mean
square error minimization problem using the principle of the well-known
weighted minimum mean square error (WMMSE) algorithm, and an iterative
optimization approach is proposed to obtain the optimal RCM. In addition, to
fairly compare passive RIS and active RIS, we study the required power budget
of the RIS to achieve a target detection probability under a special case where
the direct links are neglected and the RIS-related channels are line-of-sight.
Via extensive simulations, the effectiveness of the WMMSE-based RCM
optimization approach is demonstrated. Furthermore, the results reveal that the
active RIS can outperform the passive RIS when the underlying interference
within the background noise is relatively weak, whereas the passive RIS
performs better in strong interference scenarios because the same power budget
can support a vast number of passive reflecting elements for interference
mitigation.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16571" title="Abstract">arXiv:2311.16571</a> [<a href="/pdf/2311.16571" title="Download PDF">pdf</a>, <a href="/ps/2311.16571" title="Download PostScript">ps</a>, <a href="/format/2311.16571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Intervals and Symbolic Block Matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghesquiere%2C+M">Mike Ghesquiere</a>, 
<a href="/search/cs?searchtype=author&query=Watt%2C+S+M">Stephen M. Watt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>

</div>
<p class="mathjax">Structured matrices with symbolic sizes appear frequently in the literature,
especially in the description of algorithms for linear algebra. Recent work has
treated these symbolic structured matrices themselves as computational objects,
showing how to add matrices with blocks of different symbolic sizes in a
general way while avoiding a combinatorial explosion of cases. The present
article introduces the concept of hybrid intervals, in which points may have
negative multiplicity. Various operations on hybrid intervals have compact and
elegant formulations that do not require cases to handle different orders of
the end points. This makes them useful to represent symbolic block matrix
structures and to express arithmetic on symbolic block matrices compactly. We
use these ideas to formulate symbolic block matrix addition and multiplication
in a compact and uniform way.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16572" title="Abstract">arXiv:2311.16572</a> [<a href="/pdf/2311.16572" title="Download PDF">pdf</a>, <a href="/format/2311.16572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapting to climate change: Long-term impact of wind resource changes on  China&#x27;s power system resilience
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ruan%2C+J">Jiaqi Ruan</a>, 
<a href="/search/eess?searchtype=author&query=Meng%2C+X">Xiangrui Meng</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+Y">Yifan Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Liang%2C+G">Gaoqi Liang</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+X">Xianzhuo Sun</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+H">Huayi Wu</a>, 
<a href="/search/eess?searchtype=author&query=Xiao%2C+H">Huijuan Xiao</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+M">Mengqian Lu</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+P">Pin Gao</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+J">Jiapeng Li</a>, 
<a href="/search/eess?searchtype=author&query=Wong%2C+W">Wai-Kin Wong</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+Z">Zhao Xu</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+J">Junhua Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Atmospheric and Oceanic Physics (physics.ao-ph); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Modern society's reliance on power systems is at risk from the escalating
effects of wind-related climate change. Yet, failure to identify the intricate
relationship between wind-related climate risks and power systems could lead to
serious short- and long-term issues, including partial or complete blackouts.
Here, we develop a comprehensive framework to assess China's power system
resilience across various climate change scenarios, enabling a holistic
evaluation of the repercussions induced by wind-related climate change. Our
findings indicate that China's current wind projects and planning strategies
could be jeopardized by wind-related climate change, with up to a 12\% decline
in regional wind power availability. Moreover, our results underscore a
pronounced vulnerability of power system resilience amidst the rigors of
hastened climate change, unveiling a potential amplification of resilience
deterioration, even approaching fourfold by 2060 under the most severe
scenario, relative to the 2020 benchmark. This work advocates for strategic
financial deployment within the power sector aimed at climate adaptation,
enhancing power system resilience to avert profound losses from long-term,
wind-influenced climatic fluctuations.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16575" title="Abstract">arXiv:2311.16575</a> [<a href="/pdf/2311.16575" title="Download PDF">pdf</a>, <a href="/format/2311.16575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure Traversable Event logging for Responsible Identification of  Vertically Partitioned Health Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bose%2C+S">Sunanda Bose</a>, 
<a href="/search/cs?searchtype=author&query=Marijan%2C+D">Dusica Marijan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">We aim to provide a solution for the secure identification of sensitive
medical information. We consider a repository of de-identified medical data
that is stored in the custody of a Healthcare Institution. The identifying
information that is stored separately can be associated with the medical
information only by a subset of users referred to as custodians. This paper
intends to secure the process of associating identifying information with
sensitive medical information. We also enforce the responsibility of the
custodians by maintaining an immutable ledger documenting the events of such
information identification. The paper proposes a scheme for constructing ledger
entries that allow the custodians and patients to browse through the entries
which they are associated with. However, in order to respect their privacy,
such traversal requires appropriate credentials to ensure that a user cannot
gain any information regarding the other users involved in the system unless
they are both involved in the same operation.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16576" title="Abstract">arXiv:2311.16576</a> [<a href="/pdf/2311.16576" title="Download PDF">pdf</a>, <a href="/format/2311.16576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wireless Powered Metaverse: Joint Task Scheduling and Trajectory Design  for Multi-Devices and Multi-UAVs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaojie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiameng Li</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+Z">Zhaolong Ning</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Q">Qingyang Song</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+L">Lei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Jamalipour%2C+A">Abbas Jamalipour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">To support the running of human-centric metaverse applications on mobile
devices, Unmanned Aerial Vehicle (UAV)-assisted Wireless Powered Mobile Edge
Computing (WPMEC) is promising to compensate for limited computational
capabilities and energy supplies of mobile devices. The high-speed
computational processing demands and significant energy consumption of
metaverse applications require joint resource scheduling of multiple devices
and UAVs, but existing WPMEC solutions address either device or UAV scheduling
due to the complexity of combinatorial optimization. To solve the above
challenge, we propose a two-stage alternating optimization algorithm based on
multi-task Deep Reinforcement Learning (DRL) to jointly allocate charging time,
schedule computation tasks, and optimize trajectory of UAVs and mobile devices
in a wireless powered metaverse scenario. First, considering energy constraints
of both UAVs and mobile devices, we formulate an optimization problem to
maximize the computation efficiency of the system. Second, we propose a
heuristic algorithm to efficiently perform time allocation and charging
scheduling for mobile devices. Following this, we design a multi-task DRL
scheme to make charging scheduling and trajectory design decisions for UAVs.
Finally, theoretical analysis and performance results demonstrate that our
algorithm exhibits significant advantages over representative methods in terms
of convergence speed and average computation efficiency.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16577" title="Abstract">arXiv:2311.16577</a> [<a href="/pdf/2311.16577" title="Download PDF">pdf</a>, <a href="/format/2311.16577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Key-Based Adversarial Defense for ImageNet by Using  Pre-trained Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=MaungMaung%2C+A">AprilPyone MaungMaung</a>, 
<a href="/search/cs?searchtype=author&query=Echizen%2C+I">Isao Echizen</a>, 
<a href="/search/cs?searchtype=author&query=Kiya%2C+H">Hitoshi Kiya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we propose key-based defense model proliferation by leveraging
pre-trained models and utilizing recent efficient fine-tuning techniques on
ImageNet-1k classification. First, we stress that deploying key-based models on
edge devices is feasible with the latest model deployment advancements, such as
Apple CoreML, although the mainstream enterprise edge artificial intelligence
(Edge AI) has been focused on the Cloud. Then, we point out that the previous
key-based defense on on-device image classification is impractical for two
reasons: (1) training many classifiers from scratch is not feasible, and (2)
key-based defenses still need to be thoroughly tested on large datasets like
ImageNet. To this end, we propose to leverage pre-trained models and utilize
efficient fine-tuning techniques to proliferate key-based models even on
limited computing resources. Experiments were carried out on the ImageNet-1k
dataset using adaptive and non-adaptive attacks. The results show that our
proposed fine-tuned key-based models achieve a superior classification accuracy
(more than 10% increase) compared to the previous key-based models on
classifying clean and adversarial examples.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16579" title="Abstract">arXiv:2311.16579</a> [<a href="/pdf/2311.16579" title="Download PDF">pdf</a>, <a href="/format/2311.16579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recognizing Conditional Causal Relationships about Emotions and Their  Corresponding Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinhong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zongxi Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaowei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Haoran Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qing Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The study of causal relationships between emotions and causes in texts has
recently received much attention. Most works focus on extracting causally
related clauses from documents. However, none of these works has considered
that the causal relationships among the extracted emotion and cause clauses can
only be valid under some specific context clauses. To highlight the context in
such special causal relationships, we propose a new task to determine whether
or not an input pair of emotion and cause has a valid causal relationship under
different contexts and extract the specific context clauses that participate in
the causal relationship. Since the task is new for which no existing dataset is
available, we conduct manual annotation on a benchmark dataset to obtain the
labels for our tasks and the annotations of each context clause's type that can
also be used in some other applications. We adopt negative sampling to
construct the final dataset to balance the number of documents with and without
causal relationships. Based on the constructed dataset, we propose an
end-to-end multi-task framework, where we design two novel and general modules
to handle the two goals of our task. Specifically, we propose a context masking
module to extract the context clauses participating in the causal
relationships. We propose a prediction aggregation module to fine-tune the
prediction results according to whether the input emotion and causes depend on
specific context clauses. Results of extensive comparative experiments and
ablation studies demonstrate the effectiveness and generality of our proposed
framework.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16580" title="Abstract">arXiv:2311.16580</a> [<a href="/pdf/2311.16580" title="Download PDF">pdf</a>, <a href="/format/2311.16580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clean Label Disentangling for Medical Image Segmentation with Noisy  Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zicheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+E">Erjian Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Luping Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures, 11 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Current methods focusing on medical image segmentation suffer from incorrect
annotations, which is known as the noisy label issue. Most medical image
segmentation with noisy labels methods utilize either noise transition matrix,
noise-robust loss functions or pseudo-labeling methods, while none of the
current research focuses on clean label disentanglement. We argue that the main
reason is that the severe class-imbalanced issue will lead to the inaccuracy of
the selected ``clean'' labels, thus influencing the robustness of the model
against the noises. In this work, we come up with a simple but efficient
class-balanced sampling strategy to tackle the class-imbalanced problem, which
enables our newly proposed clean label disentangling framework to successfully
select clean labels from the given label sets and encourages the model to learn
from the correct annotations. However, such a method will filter out too many
annotations which may also contain useful information. Therefore, we further
extend our clean label disentangling framework to a new noisy feature-aided
clean label disentangling framework, which takes the full annotations into
utilization to learn more semantics. Extensive experiments have validated the
effectiveness of our methods, where our methods achieve new state-of-the-art
performance. Our code is available at https://github.com/xiaoyao3302/2BDenoise.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16581" title="Abstract">arXiv:2311.16581</a> [<a href="/pdf/2311.16581" title="Download PDF">pdf</a>, <a href="/format/2311.16581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GeoScaler: Geometry and Rendering-Aware Downsampling of 3D Mesh Textures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pentapati%2C+S+K">Sai Karthikey Pentapati</a>, 
<a href="/search/cs?searchtype=author&query=Rai%2C+A">Anshul Rai</a>, 
<a href="/search/cs?searchtype=author&query=Ten%2C+A">Arkady Ten</a>, 
<a href="/search/cs?searchtype=author&query=Atluru%2C+C">Chaitanya Atluru</a>, 
<a href="/search/cs?searchtype=author&query=Bovik%2C+A">Alan Bovik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">High-resolution texture maps are necessary for representing real-world
objects accurately with 3D meshes. The large sizes of textures can bottleneck
the real-time rendering of high-quality virtual 3D scenes on devices having low
computational budgets and limited memory. Downsampling the texture maps
directly addresses the issue, albeit at the cost of visual fidelity.
Traditionally, downsampling of texture maps is performed using methods like
bicubic interpolation and the Lanczos algorithm. These methods ignore the
geometric layout of the mesh and its UV parametrization and also do not account
for the rendering process used to obtain the final visualization that the users
will experience. Towards filling these gaps, we introduce GeoScaler, which is a
method of downsampling texture maps of 3D meshes while incorporating geometric
cues, and by maximizing the visual fidelity of the rendered views of the
textured meshes. We show that the textures generated by GeoScaler deliver
significantly better quality rendered images compared to those generated by
traditional downsampling methods
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16584" title="Abstract">arXiv:2311.16584</a> [<a href="/pdf/2311.16584" title="Download PDF">pdf</a>, <a href="/format/2311.16584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedAL: Black-Box Federated Knowledge Distillation Enabled by Adversarial  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+P">Pengchao Han</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xingyan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jianwei Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Knowledge distillation (KD) can enable collaborative learning among
distributed clients that have different model architectures and do not share
their local data and model parameters with others. Each client updates its
local model using the average model output/feature of all client models as the
target, known as federated KD. However, existing federated KD methods often do
not perform well when clients' local models are trained with heterogeneous
local datasets. In this paper, we propose Federated knowledge distillation
enabled by Adversarial Learning (FedAL) to address the data heterogeneity among
clients. First, to alleviate the local model output divergence across clients
caused by data heterogeneity, the server acts as a discriminator to guide
clients' local model training to achieve consensus model outputs among clients
through a min-max game between clients and the discriminator. Moreover,
catastrophic forgetting may happen during the clients' local training and
global knowledge transfer due to clients' heterogeneous local data. Towards
this challenge, we design the less-forgetting regularization for both local
training and global knowledge transfer to guarantee clients' ability to
transfer/learn knowledge to/from others. Experimental results show that FedAL
and its variants achieve higher accuracy than other federated KD baselines.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16585" title="Abstract">arXiv:2311.16585</a> [<a href="/pdf/2311.16585" title="Download PDF">pdf</a>, <a href="/format/2311.16585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sorting Out New York City&#x27;s Trash Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=DiSilvio%2C+S">Steven DiSilvio</a>, 
<a href="/search/cs?searchtype=author&query=Ozerov%2C+A">Anthony Ozerov</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Leon Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">To reduce waste and improve public health and sanitation in New York City,
innovative policies tailored to the city's unique urban landscape are
necessary. The first program we propose is the Dumpster and Compost
Accessibility Program. This program is affordable and utilizes dumpsters placed
near fire hydrants to keep waste off the street without eliminating parking
spaces. It also includes legal changes and the provision of compost bins to
single/two-family households, which together will increase composting rates.
The second program is the Pay-As-You-Throw Program. This requires New Yorkers
living in single/two-family households to purchase stickers for each refuse bag
they have collected by the city, incentivizing them to sort out compostable
waste and recyclables. We conduct a weighted multi-objective optimization to
determine the optimal sticker price based on the City's priorities. Roughly in
proportion to the price, this program will increase diversion rates and
decrease the net costs to New York City's Department of Sanitation. In
conjunction, these two programs will improve NYC's diversion rates, eliminate
garbage bags from the streets, and potentially save New York City money.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16586" title="Abstract">arXiv:2311.16586</a> [<a href="/pdf/2311.16586" title="Download PDF">pdf</a>, <a href="/format/2311.16586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SARDINE: A Simulator for Automated Recommendation in Dynamic and  Interactive Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deffayet%2C+R">Romain Deffayet</a>, 
<a href="/search/cs?searchtype=author&query=Thonet%2C+T">Thibaut Thonet</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+D">Dongyoon Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Lehoux%2C+V">Vassilissa Lehoux</a>, 
<a href="/search/cs?searchtype=author&query=Renders%2C+J">Jean-Michel Renders</a>, 
<a href="/search/cs?searchtype=author&query=de+Rijke%2C+M">Maarten de Rijke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Simulators can provide valuable insights for researchers and practitioners
who wish to improve recommender systems, because they allow one to easily tweak
the experimental setup in which recommender systems operate, and as a result
lower the cost of identifying general trends and uncovering novel findings
about the candidate methods. A key requirement to enable this accelerated
improvement cycle is that the simulator is able to span the various sources of
complexity that can be found in the real recommendation environment that it
simulates.
<br />With the emergence of interactive and data-driven methods - e.g.,
reinforcement learning or online and counterfactual learning-to-rank - that aim
to achieve user-related goals beyond the traditional accuracy-centric
objectives, adequate simulators are needed. In particular, such simulators must
model the various mechanisms that render the recommendation environment dynamic
and interactive, e.g., the effect of recommendations on the user or the effect
of biased data on subsequent iterations of the recommender system. We therefore
propose SARDINE, a flexible and interpretable recommendation simulator that can
help accelerate research in interactive and data-driven recommender systems. We
demonstrate its usefulness by studying existing methods within nine diverse
environments derived from SARDINE, and even uncover novel insights about them.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16587" title="Abstract">arXiv:2311.16587</a> [<a href="/pdf/2311.16587" title="Download PDF">pdf</a>, <a href="/format/2311.16587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameterized Inapproximability Hypothesis under ETH
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guruswami%2C+V">Venkatesan Guruswami</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B">Bingkai Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xuandi Ren</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yican Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kewen Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">The Parameterized Inapproximability Hypothesis (PIH) asserts that no fixed
parameter tractable (FPT) algorithm can distinguish a satisfiable CSP instance,
parameterized by the number of variables, from one where every assignment fails
to satisfy an $\varepsilon$ fraction of constraints for some absolute constant
$\varepsilon &gt; 0$. PIH plays the role of the PCP theorem in parameterized
complexity. However, PIH has only been established under Gap-ETH, a very strong
assumption with an inherent gap.
<br />In this work, we prove PIH under the Exponential Time Hypothesis (ETH). This
is the first proof of PIH from a gap-free assumption. Our proof is
self-contained and elementary. We identify an ETH-hard CSP whose variables take
vector values, and constraints are either linear or of a special parallel
structure. Both kinds of constraints can be checked with constant soundness via
a "parallel PCP of proximity" based on the Walsh-Hadamard code.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16588" title="Abstract">arXiv:2311.16588</a> [<a href="/pdf/2311.16588" title="Download PDF">pdf</a>, <a href="/ps/2311.16588" title="Download PostScript">ps</a>, <a href="/format/2311.16588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MedGen: A Python Natural Language Processing Toolkit for Medical Text  Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Rui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Q">Qingcheng Zeng</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+K">Keen You</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yujie Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Lucas Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+C">Chia-Chun Hsieh</a>, 
<a href="/search/cs?searchtype=author&query=Rosand%2C+B">Benjamin Rosand</a>, 
<a href="/search/cs?searchtype=author&query=Goldwasser%2C+J">Jeremy Goldwasser</a>, 
<a href="/search/cs?searchtype=author&query=Dave%2C+A+D">Amisha D Dave</a>, 
<a href="/search/cs?searchtype=author&query=Keenan%2C+T+D+L">Tiarnan D.L. Keenan</a>, 
<a href="/search/cs?searchtype=author&query=Chew%2C+E+Y">Emily Y Chew</a>, 
<a href="/search/cs?searchtype=author&query=Radev%2C+D">Dragomir Radev</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhiyong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hua Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qingyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+I">Irene Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This study introduces MedGen, a comprehensive natural language processing
(NLP) toolkit designed for medical text processing. MedGen is tailored for
biomedical researchers and healthcare professionals with an easy-to-use,
all-in-one solution that requires minimal programming expertise. It includes
(1) Generative Functions: For the first time, MedGen includes four advanced
generative functions: question answering, text summarization, text
simplification, and machine translation; (2) Basic NLP Functions: MedGen
integrates 12 essential NLP functions such as word tokenization and sentence
segmentation; and (3) Query and Search Capabilities: MedGen provides
user-friendly query and search functions on text corpora. We fine-tuned 32
domain-specific language models, evaluated them thoroughly on 24 established
benchmarks and conducted manual reviews with clinicians. Additionally, we
expanded our toolkit by introducing query and search functions, while also
standardizing and integrating functions from third-party libraries. The
toolkit, its models, and associated data are publicly available via
https://github.com/Yale-LILY/MedGen.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16589" title="Abstract">arXiv:2311.16589</a> [<a href="/pdf/2311.16589" title="Download PDF">pdf</a>, <a href="/format/2311.16589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Lane Detection Generalization: A Novel Framework using HD Maps  for Boosting Diversity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Daeun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Heo%2C+M">Minhyeok Heo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jiwon Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">Lane detection is a vital task for vehicles to navigate and localize their
position on the road. To ensure reliable results, lane detection algorithms
must have robust generalization performance in various road environments.
However, despite the significant performance improvement of deep learning-based
lane detection algorithms, their generalization performance in response to
changes in road environments still falls short of expectations. In this paper,
we present a novel framework for single-source domain generalization (SSDG) in
lane detection. By decomposing data into lane structures and surroundings, we
enhance diversity using High-Definition (HD) maps and generative models. Rather
than expanding data volume, we strategically select a core subset of data,
maximizing diversity and optimizing performance. Our extensive experiments
demonstrate that our framework enhances the generalization performance of lane
detection, comparable to the domain adaptation-based method.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16592" title="Abstract">arXiv:2311.16592</a> [<a href="/pdf/2311.16592" title="Download PDF">pdf</a>, <a href="/format/2311.16592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RGBGrasp: Image-based Object Grasping by Capturing Multiple Views during  Robot Arm Movement with Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+K">Kejian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kaichen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoxiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiyao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hao Dong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Robotic research encounters a significant hurdle when it comes to the
intricate task of grasping objects that come in various shapes, materials, and
textures. Unlike many prior investigations that heavily leaned on specialized
point-cloud cameras or abundant RGB visual data to gather 3D insights for
object-grasping missions, this paper introduces a pioneering approach called
RGBGrasp. This method depends on a limited set of RGB views to perceive the 3D
surroundings containing transparent and specular objects and achieve accurate
grasping. Our method utilizes pre-trained depth prediction models to establish
geometry constraints, enabling precise 3D structure estimation, even under
limited view conditions. Finally, we integrate hash encoding and a proposal
sampler strategy to significantly accelerate the 3D reconstruction process.
These innovations significantly enhance the adaptability and effectiveness of
our algorithm in real-world scenarios. Through comprehensive experimental
validation, we demonstrate that RGBGrasp achieves remarkable success across a
wide spectrum of object-grasping scenarios, establishing it as a promising
solution for real-world robotic manipulation tasks. The demo of our method can
be found on: https://sites.google.com/view/rgbgrasp
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16594" title="Abstract">arXiv:2311.16594</a> [<a href="/pdf/2311.16594" title="Download PDF">pdf</a>, <a href="/format/2311.16594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monitor Placement for Fault Localization in Deep Neural Network  Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei-Kai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+B">Benjamin Tan</a>, 
<a href="/search/cs?searchtype=author&query=Chakrabarty%2C+K">Krishnendu Chakrabarty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Systolic arrays are a prominent choice for deep neural network (DNN)
accelerators because they offer parallelism and efficient data reuse. Improving
the reliability of DNN accelerators is crucial as hardware faults can degrade
the accuracy of DNN inferencing. Systolic arrays make use of a large number of
processing elements (PEs) for parallel processing, but when one PE is faulty,
the error propagates and affects the outcomes of downstream PEs. Due to the
large number of PEs, the cost associated with implementing hardware-based
runtime monitoring of every single PE is infeasible. We present a solution to
optimize the placement of hardware monitors within systolic arrays. We first
prove that $2N-1$ monitors are needed to localize a single faulty PE and we
also derive the monitor placement. We show that a second placement optimization
problem, which minimizes the set of candidate faulty PEs for a given number of
monitors, is NP-hard. Therefore, we propose a heuristic approach to balance the
reliability and hardware resource utilization in DNN accelerators when number
of monitors is limited. Experimental evaluation shows that to localize a single
faulty PE, an area overhead of only 0.33% is incurred for a $256\times 256$
systolic array.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16595" title="Abstract">arXiv:2311.16595</a> [<a href="/pdf/2311.16595" title="Download PDF">pdf</a>, <a href="/format/2311.16595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> D4AM: A General Denoising Framework for Downstream Acoustic Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Chi-Chang Lee</a>, 
<a href="/search/cs?searchtype=author&query=Tsao%2C+Y">Yu Tsao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hsin-Min Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chu-Song Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The performance of acoustic models degrades notably in noisy environments.
Speech enhancement (SE) can be used as a front-end strategy to aid automatic
speech recognition (ASR) systems. However, existing training objectives of SE
methods are not fully effective at integrating speech-text and noisy-clean
paired data for training toward unseen ASR systems. In this study, we propose a
general denoising framework, D4AM, for various downstream acoustic models. Our
framework fine-tunes the SE model with the backward gradient according to a
specific acoustic model and the corresponding classification objective. In
addition, our method aims to consider the regression objective as an auxiliary
loss to make the SE model generalize to other unseen acoustic models. To
jointly train an SE unit with regression and classification objectives, D4AM
uses an adjustment scheme to directly estimate suitable weighting coefficients
rather than undergoing a grid search process with additional training costs.
The adjustment scheme consists of two parts: gradient calibration and
regression objective weighting. The experimental results show that D4AM can
consistently and effectively provide improvements to various unseen acoustic
models and outperforms other combination setups. Specifically, when evaluated
on the Google ASR API with real noisy data completely unseen during SE
training, D4AM achieves a relative WER reduction of 24.65% compared with the
direct feeding of noisy input. To our knowledge, this is the first work that
deploys an effective combination scheme of regression (denoising) and
classification (ASR) objectives to derive a general pre-processor applicable to
various unseen ASR systems. Our code is available at
https://github.com/ChangLee0903/D4AM.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16601" title="Abstract">arXiv:2311.16601</a> [<a href="/pdf/2311.16601" title="Download PDF">pdf</a>, <a href="/ps/2311.16601" title="Download PostScript">ps</a>, <a href="/format/2311.16601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing customized built-in elements -- Empowering Component-Based  Software Engineering and Design Systems with HTML5 Web Components
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shah%2C+H">Hardik Shah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures, 15th International Conference on Web services &amp; Semantic Technology (WeST 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Customized built-in elements in HTML5 significantly transform web
development. These elements enable developers to create unique HTML components
tailored with specific design and purpose. Customized built-in elements enable
developers to address the unique needs of web applications more quickly,
supporting consistent user interfaces and experiences across diverse digital
platforms. This study investigates the role of these features in
Component-Based Software Engineering (CBSE) and Design Systems, emphasizing the
benefits of code modularity, reusability, and scalability in web development.
Customized built-in elements enable developers to address the unique needs of
web applications more quickly, supporting consistent user interfaces and
experiences across diverse digital platforms. The paper also discusses the
difficulties and concerns that must be addressed when creating customized
built-in elements, such as browser compatibility, performance optimization,
accessibility, security, styling, and interoperability. It emphasizes the
importance of standardization, developer tooling, and community interaction in
order to fully realize the potential of these features. Looking ahead,
customized built-in elements have potential in a variety of applications,
including the Internet of Things (IoT), e-commerce, and educational
technologies. Their incorporation into Progressive Web Apps (PWAs) is expected
to further improve web experiences. While obstacles remain, the article
concludes that HTML5 customized built-in elements are a driver for web
development innovation, allowing the production of efficient, adaptive, and
user-centric web applications in an ever-changing digital context.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16603" title="Abstract">arXiv:2311.16603</a> [<a href="/pdf/2311.16603" title="Download PDF">pdf</a>, <a href="/format/2311.16603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> l2Match: Optimization Techniques on Subgraph Matching Algorithm using  Label Pair, Neighboring Label Index, and Jump-Redo method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+C+Q">C. Q. Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K+S">K. S. Wong</a>, 
<a href="/search/cs?searchtype=author&query=Soon%2C+L+K">L. K. Soon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This short version of this article (6 pages) is accepted by ICEIC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Graph database is designed to store bidirectional relationships between
objects and facilitate the traversal process to extract a subgraph. However,
the subgraph matching process is an NP-Complete problem. Existing solutions to
this problem usually employ a filter-and-verification framework and a
divide-and-conquer method. The filter-and-verification framework minimizes the
number of inputs to the verification stage by filtering and pruning invalid
candidates as much as possible. Meanwhile, subgraph matching is performed on
the substructure decomposed from the larger graph to yield partial embedding.
Subsequently, the recursive traversal or set intersection technique combines
the partial embedding into a complete subgraph. In this paper, we first present
a comprehensive literature review of the state-of-the-art solutions. l2Match, a
subgraph isomorphism algorithm for small queries utilizing a Label-Pair Index
and filtering method, is then proposed and presented as a proof of concept.
Empirical experimentation shows that l2Match outperforms related
state-of-the-art solutions, and the proposed methods optimize the existing
algorithms.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16605" title="Abstract">arXiv:2311.16605</a> [<a href="/pdf/2311.16605" title="Download PDF">pdf</a>, <a href="/format/2311.16605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LasTGL: An Industrial Framework for Large-Scale Temporal Graph Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jintang Li</a>, 
<a href="/search/cs?searchtype=author&query=Dan%2C+J">Jiawang Dan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Ruofan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jing Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+S">Sheng Tian</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yunfei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Baokun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+C">Changhua Meng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuchang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zibin Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint; Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Over the past few years, graph neural networks (GNNs) have become powerful
and practical tools for learning on (static) graph-structure data. However,
many real-world applications, such as social networks and e-commerce, involve
temporal graphs where nodes and edges are dynamically evolving. Temporal graph
neural networks (TGNNs) have progressively emerged as an extension of GNNs to
address time-evolving graphs and have gradually become a trending research
topic in both academics and industry. Advancing research in such an emerging
field requires new tools to compose TGNN models and unify their different
schemes in dealing with temporal graphs. To facilitate research and application
in temporal graph learning, we introduce LasTGL, an industrial framework that
integrates unified and extensible implementations of common temporal graph
learning algorithms for various advanced tasks. The purpose of LasTGL is to
provide the essential building blocks for solving temporal graph learning
tasks, focusing on the guiding principles of user-friendliness and quick
prototyping on which PyTorch is based. In particular, LasTGL provides
comprehensive temporal graph datasets, TGNN models and utilities along with
well-documented tutorials, making it suitable for both absolute beginners and
expert deep learning practitioners alike.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16607" title="Abstract">arXiv:2311.16607</a> [<a href="/pdf/2311.16607" title="Download PDF">pdf</a>, <a href="/format/2311.16607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extending the WMSO+U Logic With Quantification Over Tuples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Badyl%2C+A">Anita Badyl</a>, 
<a href="/search/cs?searchtype=author&query=Parys%2C+P">Pawe&#x142; Parys</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is an extended version of a paper published at the CSL 2024 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
<p class="mathjax">We study a new extension of the weak MSO logic, talking about boundedness.
Instead of a previously considered quantifier U, expressing the fact that there
exist arbitrarily large finite sets satisfying a given property, we consider a
generalized quantifier U, expressing the fact that there exist tuples of
arbitrarily large finite sets satisfying a given property. First, we prove that
the new logic WMSO+U_tup is strictly more expressive than WMSO+U. In
particular, WMSO+U_tup is able to express the so-called simultaneous
unboundedness property, for which we prove that it is not expressible in
WMSO+U. Second, we prove that it is decidable whether the tree generated by a
given higher-order recursion scheme satisfies a given sentence of WMSO+K_tup.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16608" title="Abstract">arXiv:2311.16608</a> [<a href="/pdf/2311.16608" title="Download PDF">pdf</a>, <a href="/format/2311.16608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fourier Features for Identifying Differential Equations (FourierIdent)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tang%2C+M">Mengyi Tang</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/math?searchtype=author&query=Liao%2C+W">Wenjing Liao</a>, 
<a href="/search/math?searchtype=author&query=Kang%2C+S+H">Sung Ha Kang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We investigate the benefits and challenges of utilizing the frequency
information in differential equation identification. Solving differential
equations and Fourier analysis are closely related, yet there is limited work
in exploring this connection in the identification of differential equations.
Given a single realization of the differential equation perturbed by noise, we
aim to identify the underlying differential equation governed by a linear
combination of linear and nonlinear differential and polynomial terms in the
frequency domain. This is challenging due to large magnitudes and sensitivity
to noise. We introduce a Fourier feature denoising, and define the meaningful
data region and the core regions of features to reduce the effect of noise in
the frequency domain. We use Subspace Pursuit on the core region of the time
derivative feature, and introduce a group trimming step to refine the support.
We further introduce a new energy based on the core regions of features for
coefficient identification. Utilizing the core regions of features serves two
critical purposes: eliminating the low-response regions dominated by noise, and
enhancing the accuracy in coefficient identification. The proposed method is
tested on various differential equations with linear, nonlinear, and high-order
derivative feature terms. Our results demonstrate the advantages of the
proposed method, particularly on complex and highly corrupted datasets.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16609" title="Abstract">arXiv:2311.16609</a> [<a href="/pdf/2311.16609" title="Download PDF">pdf</a>, <a href="/format/2311.16609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eigenmatrix for unstructured sparse recovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ying%2C+L">Lexing Ying</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper considers the unstructured sparse recovery problems in a general
form. Examples include rational approximation, spectral function estimation,
Fourier inversion, Laplace inversion, and sparse deconvolution. The main
challenges are the noise in the sample values and the unstructured nature of
the sample locations. This paper proposes the eigenmatrix, a data-driven
construction with desired approximate eigenvalues and eigenvectors. The
eigenmatrix offers a new way for these sparse recovery problems. Numerical
results are provided to demonstrate the efficiency of the proposed method.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16610" title="Abstract">arXiv:2311.16610</a> [<a href="/pdf/2311.16610" title="Download PDF">pdf</a>, <a href="/format/2311.16610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Empathic Metaverse: An Assistive Bioresponsive Platform For  Emotional Experience Sharing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pai%2C+Y+S">Yun Suen Pai</a>, 
<a href="/search/cs?searchtype=author&query=Armstrong%2C+M">Mark Armstrong</a>, 
<a href="/search/cs?searchtype=author&query=Skiers%2C+K">Kinga Skiers</a>, 
<a href="/search/cs?searchtype=author&query=Kundu%2C+A">Anish Kundu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+D">Danyang Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yixin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gunasekaran%2C+T+S">Tamil Selvan Gunasekaran</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chi-Lan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Minamizawa%2C+K">Kouta Minamizawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages including references, 4 figures, presented at the Towards an Inclusive and Accessible Metaverse (TIAM) Workshop at CHI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">The Metaverse is poised to be a future platform that redefines what it means
to communicate, socialize, and interact with each other. Yet, it is important
for us to consider avoiding the pitfalls of social media platforms we use
today; cyberbullying, lack of transparency and an overall false mental model of
society. In this paper, we propose the Empathic Metaverse, a virtual platform
that prioritizes emotional sharing for assistance. It aims to cultivate
prosocial behaviour, either egoistically or altruistically, so that our future
society can better feel for each other and assist one another. To achieve this,
we propose the platform to be bioresponsive; it reacts and adapts to an
individual's physiological and cognitive state and reflects this via carefully
designed avatars, environments, and interactions. We explore this concept in
terms of three research directions: bioresponsive avatars, mediated
communications and assistive tools.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16613" title="Abstract">arXiv:2311.16613</a> [<a href="/pdf/2311.16613" title="Download PDF">pdf</a>, <a href="/format/2311.16613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Filter-Pruning of Lightweight Face Detectors Using a Geometric Median  Criterion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gkrispanis%2C+K">Konstantinos Gkrispanis</a>, 
<a href="/search/cs?searchtype=author&query=Gkalelis%2C+N">Nikolaos Gkalelis</a>, 
<a href="/search/cs?searchtype=author&query=Mezaris%2C+V">Vasileios Mezaris</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in the IEEE/CVF WACV 2024 Workshops proceedings, Hawaii, USA, Jan. 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Face detectors are becoming a crucial component of many applications,
including surveillance, that often have to run on edge devices with limited
processing power and memory. Therefore, there's a pressing demand for compact
face detection models that can function efficiently across resource-constrained
devices. Over recent years, network pruning techniques have attracted a lot of
attention from researchers. These methods haven't been well examined in the
context of face detectors, despite their expanding popularity. In this paper,
we implement filter pruning on two already small and compact face detectors,
named EXTD (Extremely Tiny Face Detector) and EResFD (Efficient ResNet Face
Detector). The main pruning algorithm that we utilize is Filter Pruning via
Geometric Median (FPGM), combined with the Soft Filter Pruning (SFP) iterative
procedure. We also apply L1 Norm pruning, as a baseline to compare with the
proposed approach. The experimental evaluation on the WIDER FACE dataset
indicates that the proposed approach has the potential to further reduce the
model size of already lightweight face detectors, with limited accuracy loss,
or even with small accuracy gain for low pruning rates.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16616" title="Abstract">arXiv:2311.16616</a> [<a href="/pdf/2311.16616" title="Download PDF">pdf</a>, <a href="/ps/2311.16616" title="Download PostScript">ps</a>, <a href="/format/2311.16616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Distribution Balancing for Counterfactual Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schrod%2C+S">Stefan Schrod</a>, 
<a href="/search/cs?searchtype=author&query=Sinz%2C+F">Fabian Sinz</a>, 
<a href="/search/cs?searchtype=author&query=Altenbuchinger%2C+M">Michael Altenbuchinger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Implementation available at <a href="https://github.com/sschrod/ADBCR">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The development of causal prediction models is challenged by the fact that
the outcome is only observable for the applied (factual) intervention and not
for its alternatives (the so-called counterfactuals); in medicine we only know
patients' survival for the administered drug and not for other therapeutic
options. Machine learning approaches for counterfactual reasoning have to deal
with both unobserved outcomes and distributional differences due to non-random
treatment administration. Unsupervised domain adaptation (UDA) addresses
similar issues; one has to deal with unobserved outcomes -- the labels of the
target domain -- and distributional differences between source and target
domain. We propose Adversarial Distribution Balancing for Counterfactual
Reasoning (ADBCR), which directly uses potential outcome estimates of the
counterfactuals to remove spurious causal relations. We show that ADBCR
outcompetes state-of-the-art methods on three benchmark datasets, and
demonstrate that ADBCR's performance can be further improved if unlabeled
validation data are included in the training procedure to better adapt the
model to the validation domain.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16618" title="Abstract">arXiv:2311.16618</a> [<a href="/pdf/2311.16618" title="Download PDF">pdf</a>, <a href="/format/2311.16618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-level Attention with Overlapped Windows for Camouflaged Object  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiepan Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+F">Fangxiao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+N">Nan Xue</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuohong Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongyan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+W">Wei He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Camouflaged objects adaptively fit their color and texture with the
environment, which makes them indistinguishable from the surroundings. Current
methods revealed that high-level semantic features can highlight the
differences between camouflaged objects and the backgrounds. Consequently, they
integrate high-level semantic features with low-level detailed features for
accurate camouflaged object detection (COD). Unlike previous designs for
multi-level feature fusion, we state that enhancing low-level features is more
impending for COD. In this paper, we propose an overlapped window cross-level
attention (OWinCA) to achieve the low-level feature enhancement guided by the
highest-level features. By sliding an aligned window pair on both the highest-
and low-level feature maps, the high-level semantics are explicitly integrated
into the low-level details via cross-level attention. Additionally, it employs
an overlapped window partition strategy to alleviate the incoherence among
windows, which prevents the loss of global information. These adoptions enable
the proposed OWinCA to enhance low-level features by promoting the separability
of camouflaged objects. The associated proposed OWinCANet fuses these enhanced
multi-level features by simple convolution operation to achieve the final COD.
Experiments conducted on three large-scale COD datasets demonstrate that our
OWinCANet significantly surpasses the current state-of-the-art COD methods.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16620" title="Abstract">arXiv:2311.16620</a> [<a href="/pdf/2311.16620" title="Download PDF">pdf</a>, <a href="/format/2311.16620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Long Range Abilities of Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zimerman%2C+I">Itamar Zimerman</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+L">Lior Wolf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Despite their dominance in modern DL and, especially, NLP domains,
transformer architectures exhibit sub-optimal performance on long-range tasks
compared to recent layers that are specifically designed for this purpose. In
this work, drawing inspiration from key attributes of long-range layers, such
as state-space layers, linear RNN layers, and global convolution layers, we
demonstrate that minimal modifications to the transformer architecture can
significantly enhance performance on the Long Range Arena (LRA) benchmark, thus
narrowing the gap with these specialized layers. We identify that two key
principles for long-range tasks are (i) incorporating an inductive bias towards
smoothness, and (ii) locality. As we show, integrating these ideas into the
attention mechanism improves results with a negligible amount of additional
computation and without any additional trainable parameters. Our theory and
experiments also shed light on the reasons for the inferior performance of
transformers on long-range tasks and identify critical properties that are
essential for successfully capturing long-range dependencies.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16623" title="Abstract">arXiv:2311.16623</a> [<a href="/pdf/2311.16623" title="Download PDF">pdf</a>, <a href="/format/2311.16623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Semantic Navigation with Real Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guti%C3%A9rrez-%C3%81lvarez%2C+C">Carlos Guti&#xe9;rrez-&#xc1;lvarez</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%ADos-Navarro%2C+P">Pablo R&#xed;os-Navarro</a>, 
<a href="/search/cs?searchtype=author&query=Flor-Rodr%C3%ADguez%2C+R">Rafael Flor-Rodr&#xed;guez</a>, 
<a href="/search/cs?searchtype=author&query=Acevedo-Rodr%C3%ADguez%2C+F+J">Francisco Javier Acevedo-Rodr&#xed;guez</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez-Sastre%2C+R+J">Roberto J. L&#xf3;pez-Sastre</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Visual Semantic Navigation (VSN) is the ability of a robot to learn visual
semantic information for navigating in unseen environments. These VSN models
are typically tested in those virtual environments where they are trained,
mainly using reinforcement learning based approaches. Therefore, we do not yet
have an in-depth analysis of how these models would behave in the real world.
In this work, we propose a new solution to integrate VSN models into real
robots, so that we have true embodied agents. We also release a novel ROS-based
framework for VSN, ROS4VSN, so that any VSN-model can be easily deployed in any
ROS-compatible robot and tested in a real setting. Our experiments with two
different robots, where we have embedded two state-of-the-art VSN agents,
confirm that there is a noticeable performance difference of these VSN
solutions when tested in real-world and simulation environments. We hope that
this research will endeavor to provide a foundation for addressing this
consequential issue, with the ultimate aim of advancing the performance and
efficiency of embodied agents within authentic real-world scenarios. Code to
reproduce all our experiments can be found at
https://github.com/gramuah/ros4vsn.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16624" title="Abstract">arXiv:2311.16624</a> [<a href="/pdf/2311.16624" title="Download PDF">pdf</a>, <a href="/format/2311.16624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modelisation of a rolling disk with Sympy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jaulin%2C+L">Luc Jaulin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">This paper proposes a Lagrangian approach to find the state equations of a
disk rolling on a plane without friction. The approach takes advantage of a
symbolic computation to simplify the reasoning.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16625" title="Abstract">arXiv:2311.16625</a> [<a href="/pdf/2311.16625" title="Download PDF">pdf</a>, <a href="/format/2311.16625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian Processes for Monitoring Air-Quality in Kampala
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stoddart%2C+C">Clara Stoddart</a>, 
<a href="/search/cs?searchtype=author&query=Shrack%2C+L">Lauren Shrack</a>, 
<a href="/search/cs?searchtype=author&query=Sserunjogi%2C+R">Richard Sserunjogi</a>, 
<a href="/search/cs?searchtype=author&query=Abdul-Ganiy%2C+U">Usman Abdul-Ganiy</a>, 
<a href="/search/cs?searchtype=author&query=Bainomugisha%2C+E">Engineer Bainomugisha</a>, 
<a href="/search/cs?searchtype=author&query=Okure%2C+D">Deo Okure</a>, 
<a href="/search/cs?searchtype=author&query=Misener%2C+R">Ruth Misener</a>, 
<a href="/search/cs?searchtype=author&query=Folch%2C+J+P">Jose Pablo Folch</a>, 
<a href="/search/cs?searchtype=author&query=Sedgwick%2C+R">Ruby Sedgwick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Monitoring air pollution is of vital importance to the overall health of the
population. Unfortunately, devices that can measure air quality can be
expensive, and many cities in low and middle-income countries have to rely on a
sparse allocation of them. In this paper, we investigate the use of Gaussian
Processes for both nowcasting the current air-pollution in places where there
are no sensors and forecasting the air-pollution in the future at the sensor
locations. In particular, we focus on the city of Kampala in Uganda, using data
from AirQo's network of sensors. We demonstrate the advantage of removing
outliers, compare different kernel functions and additional inputs. We also
compare two sparse approximations to allow for the large amounts of temporal
data in the dataset.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16630" title="Abstract">arXiv:2311.16630</a> [<a href="/pdf/2311.16630" title="Download PDF">pdf</a>, <a href="/format/2311.16630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Outfit Completion via Conditional Set Transformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nakamura%2C+T">Takuma Nakamura</a>, 
<a href="/search/cs?searchtype=author&query=Saito%2C+Y">Yuki Saito</a>, 
<a href="/search/cs?searchtype=author&query=Goto%2C+R">Ryosuke Goto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this paper, we formulate the outfit completion problem as a set retrieval
task and propose a novel framework for solving this problem. The proposal
includes a conditional set transformation architecture with deep neural
networks and a compatibility-based regularization method. The proposed method
utilizes a map with permutation-invariant for the input set and
permutation-equivariant for the condition set. This allows retrieving a set
that is compatible with the input set while reflecting the properties of the
condition set. In addition, since this structure outputs the element of the
output set in a single inference, it can achieve a scalable inference speed
with respect to the cardinality of the output set. Experimental results on real
data reveal that the proposed method outperforms existing approaches in terms
of accuracy of the outfit completion task, condition satisfaction, and
compatibility of completion results.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16635" title="Abstract">arXiv:2311.16635</a> [<a href="/pdf/2311.16635" title="Download PDF">pdf</a>, <a href="/format/2311.16635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MotionZero:Exploiting Motion Priors for Zero-shot Text-to-Video  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+S">Sitong Su</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+L">Litao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Lianli Gao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Hengtao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jingkuan Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Zero-shot Text-to-Video synthesis generates videos based on prompts without
any videos. Without motion information from videos, motion priors implied in
prompts are vital guidance. For example, the prompt "airplane landing on the
runway" indicates motion priors that the "airplane" moves downwards while the
"runway" stays static. Whereas the motion priors are not fully exploited in
previous approaches, thus leading to two nontrivial issues: 1) the motion
variation pattern remains unaltered and prompt-agnostic for disregarding motion
priors; 2) the motion control of different objects is inaccurate and entangled
without considering the independent motion priors of different objects. To
tackle the two issues, we propose a prompt-adaptive and disentangled motion
control strategy coined as MotionZero, which derives motion priors from prompts
of different objects by Large-Language-Models and accordingly applies motion
control of different objects to corresponding regions in disentanglement.
Furthermore, to facilitate videos with varying degrees of motion amplitude, we
propose a Motion-Aware Attention scheme which adjusts attention among frames by
motion amplitude. Extensive experiments demonstrate that our strategy could
correctly control motion of different objects and support versatile
applications including zero-shot video edit.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16637" title="Abstract">arXiv:2311.16637</a> [<a href="/pdf/2311.16637" title="Download PDF">pdf</a>, <a href="/format/2311.16637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parallax-Tolerant Image Stitching with Epipolar Displacement Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Da%2C+F">Feipeng Da</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large parallax image stitching is a challenging task. Existing methods often
struggle to maintain both the local and global structures of the image while
reducing alignment artifacts and warping distortions. In this paper, we propose
a novel approach that utilizes epipolar geometry to establish a warping
technique based on the epipolar displacement field. Initially, the warping rule
for pixels in the epipolar geometry is established through the infinite
homography. Subsequently, Subsequently, the epipolar displacement field, which
represents the sliding distance of the warped pixel along the epipolar line, is
formulated by thin plate splines based on the principle of local elastic
deformation. The stitching result can be generated by inversely warping the
pixels according to the epipolar displacement field. This method incorporates
the epipolar constraints in the warping rule, which ensures high-quality
alignment and maintains the projectivity of the panorama. Qualitative and
quantitative comparative experiments demonstrate the competitiveness of the
proposed method in stitching images large parallax.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16638" title="Abstract">arXiv:2311.16638</a> [<a href="/pdf/2311.16638" title="Download PDF">pdf</a>, <a href="/format/2311.16638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simultaneous Analysis of Continuously Embedded Reissner-Mindlin Shells  in 3D Bulk Domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaiser%2C+M+W">Michael Wolfgang Kaiser</a>, 
<a href="/search/cs?searchtype=author&query=Fries%2C+T">Thomas-Peter Fries</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Article has been submitted to Internat. J. Numer. Methods Engrg
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">A mechanical model and numerical method for the simultaneous analysis of
Reissner-Mindlin shells with geometries implied by a continuous set of level
sets (isosurfaces) over some three-dimensional bulk domain is presented. A
three-dimensional mesh in the bulk domain is used in a tailored FEM formulation
where the elements are by no means conforming to the level sets representing
the shape of the individual shells. However, the shell geometries are bounded
by the intersection curves of the level sets with the boundary of the bulk
domain so that the boundaries are meshed conformingly. This results in a method
which was coined Bulk Trace FEM before. The simultaneously considered,
continuously embedded shells may be useful in the structural design process or
for the continuous reinforcement of bulk domains. Numerical results confirm
higher-order convergence rates.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16639" title="Abstract">arXiv:2311.16639</a> [<a href="/pdf/2311.16639" title="Download PDF">pdf</a>, <a href="/format/2311.16639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling Political Texts with ChatGPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mens%2C+G+L">Ga&#xeb;l Le Mens</a>, 
<a href="/search/cs?searchtype=author&query=Gallego%2C+A">Aina Gallego</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We use GPT-4 to obtain position estimates of political texts in continuous
spaces. We develop and validate a new approach by positioning British party
manifestos on the economic, social, and immigration policy dimensions and
tweets by members of the US Congress on the left-right ideological spectrum.
For the party manifestos, the correlation between the positions produced by
GPT-4 and experts is 93% or higher, a performance similar to or better than
that obtained with crowdsourced position estimates. For individual tweets, the
positions obtained with GPT-4 achieve a correlation of 91% with crowdsourced
position estimates. For senators of the 117th US Congress, the positions
obtained with GPT-4 achieve a correlation of 97% with estimates based on roll
call votes and of 96% with those based on campaign funding. Correlations are
also substantial within party, indicating that position estimates produced with
GPT-4 capture within-party differences between senators. Overall, using GPT-4
for ideological scaling is fast, cost-efficient, and reliable. This approach
provides a viable alternative to scaling by both expert raters and
crowdsourcing.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16644" title="Abstract">arXiv:2311.16644</a> [<a href="/pdf/2311.16644" title="Download PDF">pdf</a>, <a href="/ps/2311.16644" title="Download PostScript">ps</a>, <a href="/format/2311.16644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finnish 5th and 6th graders&#x27; misconceptions about Artificial  Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mertala%2C+P">Pekka Mertala</a>, 
<a href="/search/cs?searchtype=author&query=Fagerlund%2C+J">Janne Fagerlund</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Research on children's initial conceptions of AI is in an emerging state,
which, from a constructivist viewpoint, challenges the development of
pedagogically sound AI-literacy curricula, methods, and materials. To
contribute to resolving this need in the present paper, qualitative survey data
from 195 children were analyzed abductively to answer the following three
research questions: What kind of misconceptions do Finnish 5th and 6th graders'
have about the essence AI?; 2) How do these misconceptions relate to common
misconception types?; and 3) How profound are these misconceptions? As a
result, three misconception categories were identified: 1) Non-technological
AI, in which AI was conceptualized as peoples' cognitive processes (factual
misconception); 2) Anthropomorphic AI, in which AI was conceptualized as a
human-like entity (vernacular, non-scientific, and conceptual misconception);
and 3) AI as a machine with a pre-installed intelligence or knowledge (factual
misconception). Majority of the children evaluated their AI-knowledge low,
which implies that the misconceptions are more superficial than profound. The
findings suggest that context-specific linguistic features can contribute to
students' AI misconceptions. Implications for future research and AI literacy
education are discussed.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16645" title="Abstract">arXiv:2311.16645</a> [<a href="/pdf/2311.16645" title="Download PDF">pdf</a>, <a href="/format/2311.16645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deriving and Evaluating a Detailed Taxonomy of Game Bugs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Butt%2C+N+A">Nigar Azhar Butt</a>, 
<a href="/search/cs?searchtype=author&query=Sherin%2C+S">Salman Sherin</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+M+U">Muhammad Uzair Khan</a>, 
<a href="/search/cs?searchtype=author&query=Jilani%2C+A+A">Atif Aftab Jilani</a>, 
<a href="/search/cs?searchtype=author&query=Iqbal%2C+M+Z">Muhammad Zohaib Iqbal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Game development has become an extremely competitive multi-billion-dollar
industry. Many games fail even after years of development efforts because of
game-breaking bugs that disrupt the game-play and ruin the player experience.
The goal of this work is to provide a bug taxonomy for games that will help
game developers in developing bug-resistant games, game testers in designing
and executing fault-finding test cases, and researchers in evaluating game
testing approaches. For this purpose, we performed a Multivocal Literature
Review (MLR) by analyzing 436 sources, out of which 189 (78 academic and 111
grey) sources reporting bugs encountered in the game development industry were
selected for analysis. We validate the proposed taxonomy by conducting a survey
involving different game industry practitioners. The MLR allowed us to finalize
a detailed taxonomy of 63 game bug categories in end-user perspective including
eight first-tier categories: Gaming Balance, Implementation Response, Network,
Sound, Temporal, Unexpected Crash, Navigational, and Non-Temporal faults. We
observed that manual approaches towards game testing are still widely used.
Only one of the approaches targets sound bugs whereas game balancing and how to
incorporate machine learning in game testing is trending in the recent
literature. Most of the game testing techniques are specialized and dependent
on specific platforms.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16646" title="Abstract">arXiv:2311.16646</a> [<a href="/pdf/2311.16646" title="Download PDF">pdf</a>, <a href="/format/2311.16646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Backdoor Attacks on Dataset Distillation: A Kernel Method  Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chung%2C+M">Ming-Yu Chung</a>, 
<a href="/search/cs?searchtype=author&query=Chou%2C+S">Sheng-Yen Chou</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chia-Mu Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pin-Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kuo%2C+S">Sy-Yen Kuo</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+T">Tsung-Yi Ho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Dataset distillation offers a potential means to enhance data efficiency in
deep learning. Recent studies have shown its ability to counteract backdoor
risks present in original training samples. In this study, we delve into the
theoretical aspects of backdoor attacks and dataset distillation based on
kernel methods. We introduce two new theory-driven trigger pattern generation
methods specialized for dataset distillation. Following a comprehensive set of
analyses and experiments, we show that our optimization-based trigger design
framework informs effective backdoor attacks on dataset distillation. Notably,
datasets poisoned by our designed trigger prove resilient against conventional
backdoor attack detection and mitigation methods. Our empirical results
validate that the triggers developed using our approaches are proficient at
executing resilient backdoor attacks.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16650" title="Abstract">arXiv:2311.16650</a> [<a href="/pdf/2311.16650" title="Download PDF">pdf</a>, <a href="/format/2311.16650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text2Tree: Aligning Text Representation to the Label Tree Hierarchy for  Imbalanced Medical Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Jiahuan Yan</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Haojun Gao</a>, 
<a href="/search/cs?searchtype=author&query=Kai%2C+Z">Zhang Kai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weize Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Danny Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jintai Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 Findings. Code: <a href="https://github.com/jyansir/Text2Tree">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Deep learning approaches exhibit promising performances on various text
tasks. However, they are still struggling on medical text classification since
samples are often extremely imbalanced and scarce. Different from existing
mainstream approaches that focus on supplementary semantics with external
medical information, this paper aims to rethink the data challenges in medical
texts and present a novel framework-agnostic algorithm called Text2Tree that
only utilizes internal label hierarchy in training deep learning models. We
embed the ICD code tree structure of labels into cascade attention modules for
learning hierarchy-aware label representations. Two new learning schemes,
Similarity Surrogate Learning (SSL) and Dissimilarity Mixup Learning (DML), are
devised to boost text classification by reusing and distinguishing samples of
other labels following the label representation hierarchy, respectively.
Experiments on authoritative public datasets and real-world medical records
show that our approach stably achieves superior performances over classical and
advanced imbalanced classification methods.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16652" title="Abstract">arXiv:2311.16652</a> [<a href="/pdf/2311.16652" title="Download PDF">pdf</a>, <a href="/format/2311.16652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augmenting x-ray single particle imaging reconstruction with  self-supervised machine learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhantao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+M">Mingye Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+C+H">Chun Hong Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Thayer%2C+J+B">Jana B. Thayer</a>, 
<a href="/search/cs?searchtype=author&query=Turner%2C+J+J">Joshua J. Turner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV); Applied Physics (physics.app-ph); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">The development of X-ray Free Electron Lasers (XFELs) has opened numerous
opportunities to probe atomic structure and ultrafast dynamics of various
materials. Single Particle Imaging (SPI) with XFELs enables the investigation
of biological particles in their natural physiological states with unparalleled
temporal resolution, while circumventing the need for cryogenic conditions or
crystallization. However, reconstructing real-space structures from
reciprocal-space x-ray diffraction data is highly challenging due to the
absence of phase and orientation information, which is further complicated by
weak scattering signals and considerable fluctuations in the number of photons
per pulse. In this work, we present an end-to-end, self-supervised machine
learning approach to recover particle orientations and estimate reciprocal
space intensities from diffraction images only. Our method demonstrates great
robustness under demanding experimental conditions with significantly enhanced
reconstruction capabilities compared with conventional algorithms, and
signifies a paradigm shift in SPI as currently practiced at XFELs.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16654" title="Abstract">arXiv:2311.16654</a> [<a href="/pdf/2311.16654" title="Download PDF">pdf</a>, <a href="/ps/2311.16654" title="Download PostScript">ps</a>, <a href="/format/2311.16654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Elucidating Discrepancy in Explanations of Predictive Models Developed  using EMR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brankovic%2C+A">Aida Brankovic</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wenjie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Cook%2C+D">David Cook</a>, 
<a href="/search/cs?searchtype=author&query=Khanna%2C+S">Sankalp Khanna</a>, 
<a href="/search/cs?searchtype=author&query=Bialkowski%2C+K">Konstanty Bialkowski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The lack of transparency and explainability hinders the clinical adoption of
Machine learning (ML) algorithms. While explainable artificial intelligence
(XAI) methods have been proposed, little research has focused on the agreement
between these methods and expert clinical knowledge. This study applies current
state-of-the-art explainability methods to clinical decision support algorithms
developed for Electronic Medical Records (EMR) data to analyse the concordance
between these factors and discusses causes for identified discrepancies from a
clinical and technical perspective. Important factors for achieving trustworthy
XAI solutions for clinical decision support are also discussed.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16656" title="Abstract">arXiv:2311.16656</a> [<a href="/pdf/2311.16656" title="Download PDF">pdf</a>, <a href="/format/2311.16656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pseudo-Likelihood Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gruner%2C+T">Theo Gruner</a>, 
<a href="/search/cs?searchtype=author&query=Belousov%2C+B">Boris Belousov</a>, 
<a href="/search/cs?searchtype=author&query=Muratore%2C+F">Fabio Muratore</a>, 
<a href="/search/cs?searchtype=author&query=Palenicek%2C+D">Daniel Palenicek</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+J">Jan Peters</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 12 figures, Published as a conference paper at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Simulation-Based Inference (SBI) is a common name for an emerging family of
approaches that infer the model parameters when the likelihood is intractable.
Existing SBI methods either approximate the likelihood, such as Approximate
Bayesian Computation (ABC) or directly model the posterior, such as Sequential
Neural Posterior Estimation (SNPE). While ABC is efficient on low-dimensional
problems, on higher-dimensional tasks, it is generally outperformed by SNPE,
which leverages function approximation. In this paper, we propose
Pseudo-Likelihood Inference (PLI), a new method that brings neural
approximation into ABC, making it competitive on challenging Bayesian system
identification tasks. By utilizing integral probability metrics, we introduce a
smooth likelihood kernel with an adaptive bandwidth that is updated based on
information-theoretic trust regions. Thanks to this formulation, our method (i)
allows for optimizing neural posteriors via gradient descent, (ii) does not
rely on summary statistics, and (iii) enables multiple observations as input.
In comparison to SNPE, it leads to improved performance when more data is
available. The effectiveness of PLI is evaluated on four classical SBI
benchmark tasks and on a highly dynamic physical system, showing particular
advantages on stochastic simulations and multi-modal posterior landscapes.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16657" title="Abstract">arXiv:2311.16657</a> [<a href="/pdf/2311.16657" title="Download PDF">pdf</a>, <a href="/format/2311.16657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCALAR-NeRF: SCAlable LARge-scale Neural Radiance Fields for Scene  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+G+H">Gim Hee Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://aibluefisher.github.io/SCALAR-NeRF">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this work, we introduce SCALAR-NeRF, a novel framework tailored for
scalable large-scale neural scene reconstruction. We structure the neural
representation as an encoder-decoder architecture, where the encoder processes
3D point coordinates to produce encoded features, and the decoder generates
geometric values that include volume densities of signed distances and colors.
Our approach first trains a coarse global model on the entire image dataset.
Subsequently, we partition the images into smaller blocks using KMeans with
each block being modeled by a dedicated local model. We enhance the overlapping
regions across different blocks by scaling up the bounding boxes of each local
block. Notably, the decoder from the global model is shared across distinct
blocks and therefore promoting alignment in the feature space of local
encoders. We propose an effective and efficient methodology to fuse the outputs
from these local models to attain the final reconstruction. Employing this
refined coarse-to-fine strategy, our method outperforms state-of-the-art NeRF
methods and demonstrates scalability for large-scale scene reconstruction. The
code will be available on our project page at
https://aibluefisher.github.io/SCALAR-NeRF/
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16661" title="Abstract">arXiv:2311.16661</a> [<a href="/pdf/2311.16661" title="Download PDF">pdf</a>, <a href="/ps/2311.16661" title="Download PostScript">ps</a>, <a href="/format/2311.16661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cooperative Abnormal Node Detection with Adversary Resistance: A  Probabilistic Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Huangfu%2C+Y">Yingying Huangfu</a>, 
<a href="/search/eess?searchtype=author&query=Bai%2C+T">Tian Bai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Applications (stat.AP)

</div>
<p class="mathjax">This paper presents a novel probabilistic detection scheme called Cooperative
Statistical Detection (CSD) for abnormal node detection while defending against
adversarial attacks in cluster-tree networks. The CSD performs a two-phase
process: 1) designing a likelihood ratio test (LRT) for a non-root node at its
children from the perspective of packet loss; 2) making an overall decision at
the root node based on the aggregated detection data of the nodes over tree
branches. In most adversarial scenarios, malicious children knowing the
detection policy can generate falsified data to protect the abnormal parent
from being detected or frame its normal parent as an anomalous node. To resolve
this issue, a modified Z-score-based falsification-resistant mechanism is
presented in the CSD to remove untrustworthy information. Through theoretical
analysis, we show that the LRT-based method achieves perfect detection, i.e.,
both the false alarm and missed detection probabilities decay exponentially to
zero. Furthermore, the optimal removal threshold of the modified Z-score method
is derived for falsifications with uncertain strategies and guarantees perfect
detection of the CSD. As our simulation results show, the CSD approach is
robust to falsifications and can rapidly reach $99\%$ detection accuracy, even
in existing adversarial scenarios, which outperforms state-of-the-art
technology.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16664" title="Abstract">arXiv:2311.16664</a> [<a href="/pdf/2311.16664" title="Download PDF">pdf</a>, <a href="/format/2311.16664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DGNR: Density-Guided Neural Point Rendering of Large Driving Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuopeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chenming Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liangjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jianke Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite the recent success of Neural Radiance Field (NeRF), it is still
challenging to render large-scale driving scenes with long trajectories,
particularly when the rendering quality and efficiency are in high demand.
Existing methods for such scenes usually involve with spatial warping,
geometric supervision from zero-shot normal or depth estimation, or scene
division strategies, where the synthesized views are often blurry or fail to
meet the requirement of efficient rendering. To address the above challenges,
this paper presents a novel framework that learns a density space from the
scenes to guide the construction of a point-based renderer, dubbed as DGNR
(Density-Guided Neural Rendering). In DGNR, geometric priors are no longer
needed, which can be intrinsically learned from the density space through
volumetric rendering. Specifically, we make use of a differentiable renderer to
synthesize images from the neural density features obtained from the learned
density space. A density-based fusion module and geometric regularization are
proposed to optimize the density space. By conducting experiments on a widely
used autonomous driving dataset, we have validated the effectiveness of DGNR in
synthesizing photorealistic driving scenes and achieving real-time capable
rendering.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16666" title="Abstract">arXiv:2311.16666</a> [<a href="/pdf/2311.16666" title="Download PDF">pdf</a>, <a href="/format/2311.16666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MultiModal-Learning for Predicting Molecular Properties: A Framework  Based on Image and Graph Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhuoyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+J">Jiacong Mi</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shan Lu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jieyue He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Chemical Physics (physics.chem-ph); Biomolecules (q-bio.BM)

</div>
<p class="mathjax">The quest for accurate prediction of drug molecule properties poses a
fundamental challenge in the realm of Artificial Intelligence Drug Discovery
(AIDD). An effective representation of drug molecules emerges as a pivotal
component in this pursuit. Contemporary leading-edge research predominantly
resorts to self-supervised learning (SSL) techniques to extract meaningful
structural representations from large-scale, unlabeled molecular data,
subsequently fine-tuning these representations for an array of downstream
tasks. However, an inherent shortcoming of these studies lies in their singular
reliance on one modality of molecular information, such as molecule image or
SMILES representations, thus neglecting the potential complementarity of
various molecular modalities. In response to this limitation, we propose MolIG,
a novel MultiModaL molecular pre-training framework for predicting molecular
properties based on Image and Graph structures. MolIG model innovatively
leverages the coherence and correlation between molecule graph and molecule
image to execute self-supervised tasks, effectively amalgamating the strengths
of both molecular representation forms. This holistic approach allows for the
capture of pivotal molecular structural characteristics and high-level semantic
information. Upon completion of pre-training, Graph Neural Network (GNN)
Encoder is used for the prediction of downstream tasks. In comparison to
advanced baseline models, MolIG exhibits enhanced performance in downstream
tasks pertaining to molecular property prediction within benchmark groups such
as MoleculeNet Benchmark Group and ADMET Benchmark Group.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16668" title="Abstract">arXiv:2311.16668</a> [<a href="/pdf/2311.16668" title="Download PDF">pdf</a>, <a href="/format/2311.16668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LiveNVS: Neural View Synthesis on Live RGB-D Streams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fink%2C+L">Laura Fink</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%BCckert%2C+D">Darius R&#xfc;ckert</a>, 
<a href="/search/cs?searchtype=author&query=Franke%2C+L">Linus Franke</a>, 
<a href="/search/cs?searchtype=author&query=Keinert%2C+J">Joachim Keinert</a>, 
<a href="/search/cs?searchtype=author&query=Stamminger%2C+M">Marc Stamminger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> main paper: 8 pages, total number of pages: 15, 13 figures, to be published in SIGGRAPH Asia 2023 Conference Papers
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Existing real-time RGB-D reconstruction approaches, like Kinect Fusion, lack
real-time photo-realistic visualization. This is due to noisy, oversmoothed or
incomplete geometry and blurry textures which are fused from imperfect depth
maps and camera poses. Recent neural rendering methods can overcome many of
such artifacts but are mostly optimized for offline usage, hindering the
integration into a live reconstruction pipeline.
<br />In this paper, we present LiveNVS, a system that allows for neural novel view
synthesis on a live RGB-D input stream with very low latency and real-time
rendering. Based on the RGB-D input stream, novel views are rendered by
projecting neural features into the target view via a densely fused depth map
and aggregating the features in image-space to a target feature map. A
generalizable neural network then translates the target feature map into a
high-quality RGB image. LiveNVS achieves state-of-the-art neural rendering
quality of unknown scenes during capturing, allowing users to virtually explore
the scene and assess reconstruction quality in real-time.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16670" title="Abstract">arXiv:2311.16670</a> [<a href="/pdf/2311.16670" title="Download PDF">pdf</a>, <a href="/ps/2311.16670" title="Download PostScript">ps</a>, <a href="/format/2311.16670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PyTorch Geometric High Order: A Unified Library for High Order Graph  Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Muhan Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We introduce PyTorch Geometric High Order (PyGHO), a library for High Order
Graph Neural Networks (HOGNNs) that extends PyTorch Geometric (PyG). Unlike
ordinary Message Passing Neural Networks (MPNNs) that exchange messages between
nodes, HOGNNs, encompassing subgraph GNNs and k-WL GNNs, encode node tuples, a
method previously lacking a standardized framework and often requiring complex
coding. PyGHO's main objective is to provide an unified and user-friendly
interface for various HOGNNs. It accomplishes this through streamlined data
structures for node tuples, comprehensive data processing utilities, and a
flexible suite of operators for high-order GNN methodologies. In this work, we
present a detailed in-depth of PyGHO and compare HOGNNs implemented with PyGHO
with their official implementation on real-world tasks. PyGHO achieves up to
$50\%$ acceleration and reduces the code needed for implementation by an order
of magnitude. Our library is available at
\url{https://github.com/GraphPKU/PygHO}.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16671" title="Abstract">arXiv:2311.16671</a> [<a href="/pdf/2311.16671" title="Download PDF">pdf</a>, <a href="/format/2311.16671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SplitNeRF: Split Sum Approximation Neural Field for Joint Geometry,  Illumination, and Material Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zarzar%2C+J">Jesus Zarzar</a>, 
<a href="/search/cs?searchtype=author&query=Ghanem%2C+B">Bernard Ghanem</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">We present a novel approach for digitizing real-world objects by estimating
their geometry, material properties, and environmental lighting from a set of
posed images with fixed lighting. Our method incorporates into Neural Radiance
Field (NeRF) pipelines the split sum approximation used with image-based
lighting for real-time physical-based rendering. We propose modeling the
scene's lighting with a single scene-specific MLP representing pre-integrated
image-based lighting at arbitrary resolutions. We achieve accurate modeling of
pre-integrated lighting by exploiting a novel regularizer based on efficient
Monte Carlo sampling. Additionally, we propose a new method of supervising
self-occlusion predictions by exploiting a similar regularizer based on Monte
Carlo sampling. Experimental results demonstrate the efficiency and
effectiveness of our approach in estimating scene geometry, material
properties, and lighting. Our method is capable of attaining state-of-the-art
relighting quality after only ${\sim}1$ hour of training in a single NVIDIA
A100 GPU.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16673" title="Abstract">arXiv:2311.16673</a> [<a href="/pdf/2311.16673" title="Download PDF">pdf</a>, <a href="/format/2311.16673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models Meet Computer Vision: A Brief Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamadi%2C+R">Raby Hamadi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently, the intersection of Large Language Models (LLMs) and Computer
Vision (CV) has emerged as a pivotal area of research, driving significant
advancements in the field of Artificial Intelligence (AI). As transformers have
become the backbone of many state-of-the-art models in both Natural Language
Processing (NLP) and CV, understanding their evolution and potential
enhancements is crucial. This survey paper delves into the latest progressions
in the domain of transformers and their subsequent successors, emphasizing
their potential to revolutionize Vision Transformers (ViTs) and LLMs. This
survey also presents a comparative analysis, juxtaposing the performance
metrics of several leading paid and open-source LLMs, shedding light on their
strengths and areas of improvement as well as a literature review on how LLMs
are being used to tackle vision related tasks. Furthermore, the survey presents
a comprehensive collection of datasets employed to train LLMs, offering
insights into the diverse data available to achieve high performance in various
pre-training and downstream tasks of LLMs. The survey is concluded by
highlighting open directions in the field, suggesting potential venues for
future research and development. This survey aims to underscores the profound
intersection of LLMs on CV, leading to a new era of integrated and advanced AI
models.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16675" title="Abstract">arXiv:2311.16675</a> [<a href="/pdf/2311.16675" title="Download PDF">pdf</a>, <a href="/format/2311.16675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Distribution-Based Threshold for Determining Sentence Similarity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cadamuro%2C+G">Gioele Cadamuro</a>, 
<a href="/search/cs?searchtype=author&query=Gruppo%2C+M">Marco Gruppo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We hereby present a solution to a semantic textual similarity (STS) problem
in which it is necessary to match two sentences containing, as the only
distinguishing factor, highly specific information (such as names, addresses,
identification codes), and from which we need to derive a definition for when
they are similar and when they are not. The solution revolves around the use of
a neural network, based on the siamese architecture, to create the
distributions of the distances between similar and dissimilar pairs of
sentences. The goal of these distributions is to find a discriminating factor,
that we call "threshold", which represents a well-defined quantity that can be
used to distinguish vector distances of similar pairs from vector distances of
dissimilar pairs in new predictions and later analyses. In addition, we
developed a way to score the predictions by combining attributes from both the
distributions' features and the way the distance function works. Finally, we
generalize the results showing that they can be transferred to a wider range of
domains by applying the system discussed to a well-known and widely used
benchmark dataset for STS problems.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16678" title="Abstract">arXiv:2311.16678</a> [<a href="/pdf/2311.16678" title="Download PDF">pdf</a>, <a href="/format/2311.16678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Entity-Aspect-Opinion-Sentiment Quadruple Extraction for Fine-grained  Sentiment Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+D">Dan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zongyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xuezhi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Xian%2C+Y">Yunsen Xian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Product reviews often contain a large number of implicit aspects and
object-attribute co-existence cases. Unfortunately, many existing studies in
Aspect-Based Sentiment Analysis (ABSA) have overlooked this issue, which can
make it difficult to extract opinions comprehensively and fairly. In this
paper, we propose a new task called Entity-Aspect-Opinion-Sentiment Quadruple
Extraction (EASQE), which aims to hierarchically decompose aspect terms into
entities and aspects to avoid information loss, non-exclusive annotations, and
opinion misunderstandings in ABSA tasks. To facilitate research in this new
task, we have constructed four datasets (Res14-EASQE, Res15-EASQE, Res16-EASQE,
and Lap14-EASQE) based on the SemEval Restaurant and Laptop datasets. We have
also proposed a novel two-stage sequence-tagging based Trigger-Opinion
framework as the baseline for the EASQE task. Empirical evaluations show that
our Trigger-Opinion framework can generate satisfactory EASQE results and can
also be applied to other ABSA tasks, significantly outperforming
state-of-the-art methods. We have made the four datasets and source code of
Trigger-Opinion publicly available to facilitate further research in this area.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16680" title="Abstract">arXiv:2311.16680</a> [<a href="/pdf/2311.16680" title="Download PDF">pdf</a>, <a href="/format/2311.16680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ROSO: Improving Robotic Policy Inference via Synthetic Observations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miyashita%2C+Y">Yusuke Miyashita</a>, 
<a href="/search/cs?searchtype=author&query=Gahtidis%2C+D">Dimitris Gahtidis</a>, 
<a href="/search/cs?searchtype=author&query=La%2C+C">Colin La</a>, 
<a href="/search/cs?searchtype=author&query=Rabinowicz%2C+J">Jeremy Rabinowicz</a>, 
<a href="/search/cs?searchtype=author&query=Leitner%2C+J">Juxi Leitner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACRA 2023 Oral
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper, we propose the use of generative artificial intelligence (AI)
to improve zero-shot performance of a pre-trained policy by altering
observations during inference. Modern robotic systems, powered by advanced
neural networks, have demonstrated remarkable capabilities on pre-trained
tasks. However, generalizing and adapting to new objects and environments is
challenging, and fine-tuning visuomotor policies is time-consuming. To overcome
these issues we propose Robotic Policy Inference via Synthetic Observations
(ROSO). ROSO uses stable diffusion to pre-process a robot's observation of
novel objects during inference time to fit within its distribution of
observations of the pre-trained policies. This novel paradigm allows us to
transfer learned knowledge from known tasks to previously unseen scenarios,
enhancing the robot's adaptability without requiring lengthy fine-tuning. Our
experiments show that incorporating generative AI into robotic inference
significantly improves successful outcomes, finishing up to 57% of tasks
otherwise unsuccessful with the pre-trained policy.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16681" title="Abstract">arXiv:2311.16681</a> [<a href="/pdf/2311.16681" title="Download PDF">pdf</a>, <a href="/format/2311.16681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the (Extra-)Ordinary: Validating Deep Model Decisions with  Prototypical Concept-based Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dreyer%2C+M">Maximilian Dreyer</a>, 
<a href="/search/cs?searchtype=author&query=Achtibat%2C+R">Reduan Achtibat</a>, 
<a href="/search/cs?searchtype=author&query=Samek%2C+W">Wojciech Samek</a>, 
<a href="/search/cs?searchtype=author&query=Lapuschkin%2C+S">Sebastian Lapuschkin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages (9 pages manuscript, 2 pages references, 26 pages appendix)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Ensuring both transparency and safety is critical when deploying Deep Neural
Networks (DNNs) in high-risk applications, such as medicine. The field of
explainable AI (XAI) has proposed various methods to comprehend the
decision-making processes of opaque DNNs. However, only few XAI methods are
suitable of ensuring safety in practice as they heavily rely on repeated
labor-intensive and possibly biased human assessment. In this work, we present
a novel post-hoc concept-based XAI framework that conveys besides instance-wise
(local) also class-wise (global) decision-making strategies via prototypes.
What sets our approach apart is the combination of local and global strategies,
enabling a clearer understanding of the (dis-)similarities in model decisions
compared to the expected (prototypical) concept use, ultimately reducing the
dependence on human long-term assessment. Quantifying the deviation from
prototypical behavior not only allows to associate predictions with specific
model sub-strategies but also to detect outlier behavior. As such, our approach
constitutes an intuitive and explainable tool for model validation. We
demonstrate the effectiveness of our approach in identifying
out-of-distribution samples, spurious model behavior and data quality issues
across three datasets (ImageNet, CUB-200, and CIFAR-10) utilizing VGG, ResNet,
and EfficientNet architectures. Code is available on
https://github.com/maxdreyer/pcx.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16682" title="Abstract">arXiv:2311.16682</a> [<a href="/pdf/2311.16682" title="Download PDF">pdf</a>, <a href="/format/2311.16682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ContextSeg: Sketch Semantic Segmentation by Querying the Context with  Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiawei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Changjian Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Sketch semantic segmentation is a well-explored and pivotal problem in
computer vision involving the assignment of pre-defined part labels to
individual strokes. This paper presents ContextSeg - a simple yet highly
effective approach to tackling this problem with two stages. In the first
stage, to better encode the shape and positional information of strokes, we
propose to predict an extra dense distance field in an autoencoder network to
reinforce structural information learning. In the second stage, we treat an
entire stroke as a single entity and label a group of strokes within the same
semantic part using an auto-regressive Transformer with the default attention
mechanism. By group-based labeling, our method can fully leverage the context
information when making decisions for the remaining groups of strokes. Our
method achieves the best segmentation accuracy compared with state-of-the-art
approaches on two representative datasets and has been extensively evaluated
demonstrating its superior performance. Additionally, we offer insights into
solving part imbalance in training data and the preliminary experiment on
cross-category training, which can inspire future research in this field.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16683" title="Abstract">arXiv:2311.16683</a> [<a href="/pdf/2311.16683" title="Download PDF">pdf</a>, <a href="/format/2311.16683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyper-Relational Knowledge Graph Neural Network for Next POI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jixiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yongkang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+R">Ruotong Zou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jingyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zipei Fan</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xuan Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">With the advancement of mobile technology, Point of Interest (POI)
recommendation systems in Location-based Social Networks (LBSN) have brought
numerous benefits to both users and companies. Many existing works employ
Knowledge Graph (KG) to alleviate the data sparsity issue in LBSN. These
approaches primarily focus on modeling the pair-wise relations in LBSN to
enrich the semantics and thereby relieve the data sparsity issue. However,
existing approaches seldom consider the hyper-relations in LBSN, such as the
mobility relation (a 3-ary relation: user-POI-time). This makes the model hard
to exploit the semantics accurately. In addition, prior works overlook the rich
structural information inherent in KG, which consists of higher-order relations
and can further alleviate the impact of data sparsity.To this end, we propose a
Hyper-Relational Knowledge Graph Neural Network (HKGNN) model. In HKGNN, a
Hyper-Relational Knowledge Graph (HKG) that models the LBSN data is constructed
to maintain and exploit the rich semantics of hyper-relations. Then we proposed
a Hypergraph Neural Network to utilize the structural information of HKG in a
cohesive way. In addition, a self-attention network is used to leverage
sequential information and make personalized recommendations. Furthermore, side
information, essential in reducing data sparsity by providing background
knowledge of POIs, is not fully utilized in current methods. In light of this,
we extended the current dataset with available side information to further
lessen the impact of data sparsity. Results of experiments on four real-world
LBSN datasets demonstrate the effectiveness of our approach compared to
existing state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16684" title="Abstract">arXiv:2311.16684</a> [<a href="/pdf/2311.16684" title="Download PDF">pdf</a>, <a href="/format/2311.16684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Hardware-based Threat Detector for AI Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xiaobei Yan</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+H">Han Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianwei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The proliferation of AI technology gives rise to a variety of security
threats, which significantly compromise the confidentiality and integrity of AI
models and applications. Existing software-based solutions mainly target one
specific attack, and require the implementation into the models, rendering them
less practical. We design UniGuard, a novel unified and non-intrusive detection
methodology to safeguard FPGA-based AI accelerators. The core idea of UniGuard
is to harness power side-channel information generated during model inference
to spot any anomaly. We employ a Time-to-Digital Converter to capture power
fluctuations and train a supervised machine learning model to identify various
types of threats. Evaluations demonstrate that UniGuard can achieve 94.0%
attack detection accuracy, with high generalization over unknown or adaptive
attacks and robustness against varied configurations (e.g., sensor frequency
and location).
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16699" title="Abstract">arXiv:2311.16699</a> [<a href="/pdf/2311.16699" title="Download PDF">pdf</a>, <a href="/format/2311.16699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An extended discontinuous Galerkin shock tracking method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Vandergrift%2C+J">Jakob Vandergrift</a>, 
<a href="/search/math?searchtype=author&query=Kummer%2C+F">Florian Kummer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we introduce a novel high-order shock tracking method and
provide a proof of concept. Our method leverages concepts from implicit shock
tracking and extended discontinuous Galerkin methods, primarily designed for
solving partial differential equations featuring discontinuities. To address
this challenge, we solve a constrained optimization problem aiming at
accurately fitting the zero iso-contour of a level set function to the
discontinuities. Additionally, we discuss various robustness measures inspired
by both numerical experiments and existing literature. Finally, we showcase the
capabilities of our method through a series of two-dimensional problems,
progressively increasing in complexity.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16700" title="Abstract">arXiv:2311.16700</a> [<a href="/pdf/2311.16700" title="Download PDF">pdf</a>, <a href="/format/2311.16700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Intermediate Layers design in Knowledge Distillation for  Kidney and Liver Tumor Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gorade%2C+V">Vandan Gorade</a>, 
<a href="/search/cs?searchtype=author&query=Mittal%2C+S">Sparsh Mittal</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+D">Debesh Jha</a>, 
<a href="/search/cs?searchtype=author&query=Bagci%2C+U">Ulas Bagci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under-review at ISBI-2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Tissues and Organs (q-bio.TO)

</div>
<p class="mathjax">Knowledge distillation(KD) has demonstrated remarkable success across various
domains, but its application to medical imaging tasks, such as kidney and liver
tumor segmentation, has encountered challenges. Many existing KD methods are
not specifically tailored for these tasks. Moreover, prevalent KD methods often
lack a careful consideration of what and from where to distill knowledge from
the teacher to the student. This oversight may lead to issues like the
accumulation of training bias within shallower student layers, potentially
compromising the effectiveness of KD. To address these challenges, we propose
Hierarchical Layer-selective Feedback Distillation (HLFD). HLFD strategically
distills knowledge from a combination of middle layers to earlier layers and
transfers final layer knowledge to intermediate layers at both the feature and
pixel levels. This design allows the model to learn higher-quality
representations from earlier layers, resulting in a robust and compact student
model. Extensive quantitative evaluations reveal that HLFD outperforms existing
methods by a significant margin. For example, in the kidney segmentation task,
HLFD surpasses the student model (without KD) by over 10pp, significantly
improving its focus on tumor-specific features. From a qualitative standpoint,
the student model trained using HLFD excels at suppressing irrelevant
information and can focus sharply on tumor-specific details, which opens a new
pathway for more efficient and accurate diagnostic tools.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16703" title="Abstract">arXiv:2311.16703</a> [<a href="/pdf/2311.16703" title="Download PDF">pdf</a>, <a href="/format/2311.16703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CADTalk: An Algorithm and Benchmark for Semantic Commenting of CAD  Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Haocheng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+H">Hao Pan</a>, 
<a href="/search/cs?searchtype=author&query=Bousseau%2C+A">Adrien Bousseau</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+N">Niloy Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Changjian Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">CAD programs are a popular way to compactly encode shapes as a sequence of
operations that are easy to parametrically modify. However, without sufficient
semantic comments and structure, such programs can be challenging to
understand, let alone modify. We introduce the problem of semantic commenting
CAD programs, wherein the goal is to segment the input program into code blocks
corresponding to semantically meaningful shape parts and assign a semantic
label to each block. We solve the problem by combining program parsing with
visual-semantic analysis afforded by recent advances in foundational language
and vision models. Specifically, by executing the input programs, we create
shapes, which we use to generate conditional photorealistic images to make use
of semantic annotators for such images. We then distill the information across
the images and link back to the original programs to semantically comment on
them. Additionally, we collected and annotated a benchmark dataset, CADTalk,
consisting of 5,280 machine-made programs and 45 human-made programs with
ground truth semantic comments to foster future research. We extensively
evaluated our approach, compared to a GPT-based baseline approach, and an
open-set shape segmentation baseline, i.e., PartSLIP, and reported an 83.24%
accuracy on the new CADTalk dataset. Project page:
https://enigma-li.github.io/CADTalk/.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16706" title="Abstract">arXiv:2311.16706</a> [<a href="/pdf/2311.16706" title="Download PDF">pdf</a>, <a href="/ps/2311.16706" title="Download PostScript">ps</a>, <a href="/format/2311.16706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sinkhorn Flow: A Continuous-Time Framework for Understanding and  Generalizing the Sinkhorn Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karimi%2C+M+R">Mohammad Reza Karimi</a>, 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+Y">Ya-Ping Hsieh</a>, 
<a href="/search/cs?searchtype=author&query=Krause%2C+A">Andreas Krause</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Probability (math.PR); Machine Learning (stat.ML)

</div>
<p class="mathjax">Many problems in machine learning can be formulated as solving
entropy-regularized optimal transport on the space of probability measures. The
canonical approach involves the Sinkhorn iterates, renowned for their rich
mathematical properties. Recently, the Sinkhorn algorithm has been recast
within the mirror descent framework, thus benefiting from classical
optimization theory insights. Here, we build upon this result by introducing a
continuous-time analogue of the Sinkhorn algorithm. This perspective allows us
to derive novel variants of Sinkhorn schemes that are robust to noise and bias.
Moreover, our continuous-time dynamics not only generalize but also offer a
unified perspective on several recently discovered dynamics in machine learning
and mathematics, such as the "Wasserstein mirror flow" of (Deb et al. 2023) or
the "mean-field Schr\"odinger equation" of (Claisse et al. 2023).
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16711" title="Abstract">arXiv:2311.16711</a> [<a href="/pdf/2311.16711" title="Download PDF">pdf</a>, <a href="/format/2311.16711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LEDITS++: Limitless Image Editing using Text-to-Image Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brack%2C+M">Manuel Brack</a>, 
<a href="/search/cs?searchtype=author&query=Friedrich%2C+F">Felix Friedrich</a>, 
<a href="/search/cs?searchtype=author&query=Kornmeier%2C+K">Katharina Kornmeier</a>, 
<a href="/search/cs?searchtype=author&query=Tsaban%2C+L">Linoy Tsaban</a>, 
<a href="/search/cs?searchtype=author&query=Schramowski%2C+P">Patrick Schramowski</a>, 
<a href="/search/cs?searchtype=author&query=Kersting%2C+K">Kristian Kersting</a>, 
<a href="/search/cs?searchtype=author&query=Passos%2C+A">Apolin&#xe1;rio Passos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Text-to-image diffusion models have recently received increasing interest for
their astonishing ability to produce high-fidelity images from solely text
inputs. Subsequent research efforts aim to exploit and apply their capabilities
to real image editing. However, existing image-to-image methods are often
inefficient, imprecise, and of limited versatility. They either require
time-consuming fine-tuning, deviate unnecessarily strongly from the input
image, and/or lack support for multiple, simultaneous edits. To address these
issues, we introduce LEDITS++, an efficient yet versatile and precise textual
image manipulation technique. LEDITS++'s novel inversion approach requires no
tuning nor optimization and produces high-fidelity results with a few diffusion
steps. Second, our methodology supports multiple simultaneous edits and is
architecture-agnostic. Third, we use a novel implicit masking technique that
limits changes to relevant image regions. We propose the novel TEdBench++
benchmark as part of our exhaustive evaluation. Our results demonstrate the
capabilities of LEDITS++ and its improvements over previous methods. The
project page is available at https://leditsplusplus-project.static.hf.space .
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16714" title="Abstract">arXiv:2311.16714</a> [<a href="/pdf/2311.16714" title="Download PDF">pdf</a>, <a href="/format/2311.16714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Embodied Multi-Modal Agent trained by an LLM from a Parallel TextWorld
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yijun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kanxue Li</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dapeng Tao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lusong Li</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Li Shen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiaodong He</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jing Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yuhui Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">While large language models (LLMs) excel in a simulated world of texts, they
struggle to interact with the more realistic world without perceptions of other
modalities such as visual or audio signals. Although vision-language models
(VLMs) integrate LLM modules (1) aligned with static image features, and (2)
may possess prior knowledge of world dynamics (as demonstrated in the text
world), they have not been trained in an embodied visual world and thus cannot
align with its dynamics. On the other hand, training an embodied agent in a
noisy visual world without expert guidance is often challenging and
inefficient. In this paper, we train a VLM agent living in a visual world using
an LLM agent excelling in a parallel text world (but inapplicable to the visual
world). Specifically, we distill LLM's reflection outcomes (improved actions by
analyzing mistakes) in a text world's tasks to finetune the VLM on the same
tasks of the visual world, resulting in an Embodied Multi-Modal Agent (EMMA)
quickly adapting to the visual world dynamics. Such cross-modality imitation
learning between the two parallel worlds enables EMMA to generalize to a broad
scope of new tasks without any further guidance from the LLM expert. Extensive
evaluations on the ALFWorld benchmark highlight EMMA's superior performance to
SOTA VLM-based agents across diverse tasks, e.g., 20%-70% improvement in the
success rate.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16716" title="Abstract">arXiv:2311.16716</a> [<a href="/pdf/2311.16716" title="Download PDF">pdf</a>, <a href="/format/2311.16716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Pre-training and Prompt Learning for Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuhao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+L">Lianghao Xia</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+D">Da Luo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+K">Kangyi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">GNN-based recommenders have excelled in modeling intricate user-item
interactions through multi-hop message passing. However, existing methods often
overlook the dynamic nature of evolving user-item interactions, which impedes
the adaption to changing user preferences and distribution shifts in newly
arriving data. Thus, their scalability and performances in real-world dynamic
environments are limited. In this study, we propose GraphPL, a framework that
incorporates parameter-efficient and dynamic graph pre-training with prompt
learning. This novel combination empowers GNNs to effectively capture both
long-term user preferences and short-term behavior dynamics, enabling the
delivery of accurate and timely recommendations. Our GraphPL framework
addresses the challenge of evolving user preferences by seamlessly integrating
a temporal prompt mechanism and a graph-structural prompt learning mechanism
into the pre-trained GNN model. The temporal prompt mechanism encodes time
information on user-item interaction, allowing the model to naturally capture
temporal context, while the graph-structural prompt learning mechanism enables
the transfer of pre-trained knowledge to adapt to behavior dynamics without the
need for continuous incremental training. We further bring in a dynamic
evaluation setting for recommendation to mimic real-world dynamic scenarios and
bridge the offline-online gap to a better level. Our extensive experiments
including a large-scale industrial deployment showcases the lightweight plug-in
scalability of our GraphPL when integrated with various state-of-the-art
recommenders, emphasizing the advantages of GraphPL in terms of effectiveness,
robustness and efficiency.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16719" title="Abstract">arXiv:2311.16719</a> [<a href="/pdf/2311.16719" title="Download PDF">pdf</a>, <a href="/ps/2311.16719" title="Download PostScript">ps</a>, <a href="/format/2311.16719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proof-theoretic Semantics for the Logic of Bunched Implications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+T">Tao Gu</a>, 
<a href="/search/cs?searchtype=author&query=Gheorghiu%2C+A+V">Alexander V. Gheorghiu</a>, 
<a href="/search/cs?searchtype=author&query=Pym%2C+D+J">David J. Pym</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Typically, substructural logics are used in applications because of their
resource interpretations, and these interpretations often refer to the
celebrated number-of-uses reading of their implications. However, despite its
prominence, this reading is not at all reflected in the truth-functional
semantics of these logics. It is a proof-theoretic interpretation of the logic.
Hence, one desires a \emph{proof-theoretic semantics} of such logics in which
this reading is naturally expressed. This paper delivers such a semantics for
the logic of Bunched Implications (BI), generalizing earlier work on IMLL,
which is well-known as a logic of resources with numerous applications to
verification and modelling. Specifically, it delivers a base-extension
semantics (B-eS) for BI in which resources are \emph{bunches} of atoms that get
passed from antecedent to consequent in precisely the expected way.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16720" title="Abstract">arXiv:2311.16720</a> [<a href="/pdf/2311.16720" title="Download PDF">pdf</a>, <a href="/format/2311.16720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RankingGPT: Empowering Large Language Models in Text Ranking with  Progressive Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Longhui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanzhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+D">Dingkun Long</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+P">Pengjun Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Meishan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Text ranking is a critical task in various information retrieval
applications, and the recent success of Large Language Models (LLMs) in natural
language processing has sparked interest in their application to text ranking.
These methods primarily involve combining query and candidate documents and
leveraging prompt learning to determine query-document relevance using the
LLM's output probabilities for specific tokens or by directly generating a
ranked list of candidate documents. Although these approaches have demonstrated
promise, a noteworthy disparity arises between the training objective of LLMs,
which typically centers around next token prediction, and the objective of
evaluating query-document relevance. To address this gap and fully leverage LLM
potential in text ranking tasks, we propose a progressive multi-stage training
strategy. Firstly, we introduce a large-scale weakly supervised dataset of
relevance texts to enable the LLMs to acquire the ability to predict relevant
tokens without altering their original training objective. Subsequently, we
incorporate supervised training to further enhance LLM ranking capability. Our
experimental results on multiple benchmarks demonstrate the superior
performance of our proposed method compared to previous competitive approaches,
both in in-domain and out-of-domain scenarios.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16728" title="Abstract">arXiv:2311.16728</a> [<a href="/pdf/2311.16728" title="Download PDF">pdf</a>, <a href="/format/2311.16728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Photo-SLAM: Real-time Simultaneous Localization and Photorealistic  Mapping for Monocular, Stereo, and RGB-D Cameras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Huajian Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Longwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hui Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Yeung%2C+S">Sai-Kit Yeung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The integration of neural rendering and the SLAM system recently showed
promising results in joint localization and photorealistic view reconstruction.
However, existing methods, fully relying on implicit representations, are so
resource-hungry that they cannot run on portable devices, which deviates from
the original intention of SLAM. In this paper, we present Photo-SLAM, a novel
SLAM framework with a hyper primitives map. Specifically, we simultaneously
exploit explicit geometric features for localization and learn implicit
photometric features to represent the texture information of the observed
environment. In addition to actively densifying hyper primitives based on
geometric features, we further introduce a Gaussian-Pyramid-based training
method to progressively learn multi-level features, enhancing photorealistic
mapping performance. The extensive experiments with monocular, stereo, and
RGB-D datasets prove that our proposed system Photo-SLAM significantly
outperforms current state-of-the-art SLAM systems for online photorealistic
mapping, e.g., PSNR is 30% higher and rendering speed is hundreds of times
faster in the Replica dataset. Moreover, the Photo-SLAM can run at real-time
speed using an embedded platform such as Jetson AGX Orin, showing the potential
of robotics applications.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16733" title="Abstract">arXiv:2311.16733</a> [<a href="/pdf/2311.16733" title="Download PDF">pdf</a>, <a href="/ps/2311.16733" title="Download PostScript">ps</a>, <a href="/format/2311.16733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMs for Science: Usage for Code Generation and Data Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nejjar%2C+M">Mohamed Nejjar</a>, 
<a href="/search/cs?searchtype=author&query=Zacharias%2C+L">Luca Zacharias</a>, 
<a href="/search/cs?searchtype=author&query=Stiehle%2C+F">Fabian Stiehle</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+I">Ingo Weber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint; In Submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Large language models (LLMs) have been touted to enable increased
productivity in many areas of today's work life. Scientific research as an area
of work is no exception: the potential of LLM-based tools to assist in the
daily work of scientists has become a highly discussed topic across
disciplines. However, we are only at the very onset of this subject of study.
It is still unclear how the potential of LLMs will materialise in research
practice. With this study, we give first empirical evidence on the use of LLMs
in the research process. We have investigated a set of use cases for LLM-based
tools in scientific research, and conducted a first study to assess to which
degree current tools are helpful. In this paper we report specifically on use
cases related to software engineering, such as generating application code and
developing scripts for data analytics. While we studied seemingly simple use
cases, results across tools differ significantly. Our results highlight the
promise of LLM-based tools in general, yet we also observe various issues,
particularly regarding the integrity of the output these tools provide.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16737" title="Abstract">arXiv:2311.16737</a> [<a href="/pdf/2311.16737" title="Download PDF">pdf</a>, <a href="/format/2311.16737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Point&#x27;n Move: Interactive Scene Object Manipulation on Gaussian  Splatting Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiajun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hongchuan Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose Point'n Move, a method that achieves interactive scene object
manipulation with exposed region inpainting. Interactivity here further comes
from intuitive object selection and real-time editing. To achieve this, we
adopt Gaussian Splatting Radiance Field as the scene representation and fully
leverage its explicit nature and speed advantage. Its explicit representation
formulation allows us to devise a 2D prompt points to 3D mask dual-stage
self-prompting segmentation algorithm, perform mask refinement and merging,
minimize change as well as provide good initialization for scene inpainting and
perform editing in real-time without per-editing training, all leads to
superior quality and performance. We test our method by performing editing on
both forward-facing and 360 scenes. We also compare our method against existing
scene object removal methods, showing superior quality despite being more
capable and having a speed advantage.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16738" title="Abstract">arXiv:2311.16738</a> [<a href="/pdf/2311.16738" title="Download PDF">pdf</a>, <a href="/format/2311.16738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Riemannian Self-Attention Mechanism for SPD Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiao-Jun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hui Li</a>, 
<a href="/search/cs?searchtype=author&query=Kittler%2C+J">Josef Kittler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 10 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Symmetric positive definite (SPD) matrix has been demonstrated to be an
effective feature descriptor in many scientific areas, as it can encode
spatiotemporal statistics of the data adequately on a curved Riemannian
manifold, i.e., SPD manifold. Although there are many different ways to design
network architectures for SPD matrix nonlinear learning, very few solutions
explicitly mine the geometrical dependencies of features at different layers.
Motivated by the great success of self-attention mechanism in capturing
long-range relationships, an SPD manifold self-attention mechanism (SMSA) is
proposed in this paper using some manifold-valued geometric operations, mainly
the Riemannian metric, Riemannian mean, and Riemannian optimization. Then, an
SMSA-based geometric learning module (SMSA-GLM) is designed for the sake of
improving the discrimination of the generated deep structured representations.
Extensive experimental results achieved on three benchmarking datasets show
that our modification against the baseline network further alleviates the
information degradation problem and leads to improved accuracy.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16739" title="Abstract">arXiv:2311.16739</a> [<a href="/pdf/2311.16739" title="Download PDF">pdf</a>, <a href="/format/2311.16739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> As-Plausible-As-Possible: Plausibility-Aware Mesh Deformation Using 2D  Diffusion Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoo%2C+S">Seungwoo Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kunho Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+V+G">Vladimir G. Kim</a>, 
<a href="/search/cs?searchtype=author&query=Sung%2C+M">Minhyuk Sung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://as-plausible-as-possible.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We present As-Plausible-as-Possible (APAP) mesh deformation technique that
leverages 2D diffusion priors to preserve the plausibility of a mesh under
user-controlled deformation. Our framework uses per-face Jacobians to represent
mesh deformations, where mesh vertex coordinates are computed via a
differentiable Poisson Solve. The deformed mesh is rendered, and the resulting
2D image is used in the Score Distillation Sampling (SDS) process, which
enables extracting meaningful plausibility priors from a pretrained 2D
diffusion model. To better preserve the identity of the edited mesh, we
fine-tune our 2D diffusion model with LoRA. Gradients extracted by SDS and a
user-prescribed handle displacement are then backpropagated to the per-face
Jacobians, and we use iterative gradient descent to compute the final
deformation that balances between the user edit and the output plausibility. We
evaluate our method with 2D and 3D meshes and demonstrate qualitative and
quantitative improvements when using plausibility priors over
geometry-preservation or distortion-minimization priors used by previous
techniques.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16741" title="Abstract">arXiv:2311.16741</a> [<a href="/pdf/2311.16741" title="Download PDF">pdf</a>, <a href="/ps/2311.16741" title="Download PostScript">ps</a>, <a href="/format/2311.16741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asynchronous Wireless Federated Learning with Probabilistic Client  Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiarong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Fangjiong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Changle Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in IEEE Transactions on Wireless Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Federated learning (FL) is a promising distributed learning framework where
distributed clients collaboratively train a machine learning model coordinated
by a server. To tackle the stragglers issue in asynchronous FL, we consider
that each client keeps local updates and probabilistically transmits the local
model to the server at arbitrary times. We first derive the (approximate)
expression for the convergence rate based on the probabilistic client
selection. Then, an optimization problem is formulated to trade off the
convergence rate of asynchronous FL and mobile energy consumption by joint
probabilistic client selection and bandwidth allocation. We develop an
iterative algorithm to solve the non-convex problem globally optimally.
Experiments demonstrate the superiority of the proposed approach compared with
the traditional schemes.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16742" title="Abstract">arXiv:2311.16742</a> [<a href="/pdf/2311.16742" title="Download PDF">pdf</a>, <a href="/format/2311.16742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $k$-times bin packing and its application to fair electricity  distribution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baghel%2C+D+K">Dinesh Kumar Baghel</a>, 
<a href="/search/cs?searchtype=author&query=Segal-Halevi%2C+E">Erel Segal-Halevi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 5 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Given items of different sizes and a fixed bin capacity, the bin-packing
problem is to pack these items into a minimum number of bins such that the sum
of item sizes in a bin does not exceed the capacity. We define a new variant
called $k$-times bin packing ($k$BP), where the goal is to pack the items such
that each item appears exactly $k$ times, in $k$ different bins. We generalize
some existing approximation algorithms for bin-packing to solve $k$BP, and
analyze their performance ratio.
<br />The study of $k$BP is motivated by the problem of fair electricity
distribution. In many developing countries, the total electricity demand is
higher than the supply capacity. We show that $k$-times bin packing can be used
to distribute the electricity in a fair and efficient way. Particularly, we
implement generalizations of the First-Fit and First-Fit-Decreasing bin-packing
algorithms to solve $k$BP, and apply the generalizations to real electricity
demand data. We show that our generalizations outperform existing heuristic
solutions to the same problem.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16744" title="Abstract">arXiv:2311.16744</a> [<a href="/pdf/2311.16744" title="Download PDF">pdf</a>, <a href="/format/2311.16744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blockchain-based Zero Trust on the Edge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bicer%2C+C">Cem Bicer</a>, 
<a href="/search/cs?searchtype=author&query=Murturi%2C+I">Ilir Murturi</a>, 
<a href="/search/cs?searchtype=author&query=Donta%2C+P+K">Praveen Kumar Donta</a>, 
<a href="/search/cs?searchtype=author&query=Dustdar%2C+S">Schahram Dustdar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Internet of Things (IoT) devices pose significant security challenges due to
their heterogeneity (i.e., hardware and software) and vulnerability to
extensive attack surfaces. Today's conventional perimeter-based systems use
credential-based authentication (e.g., username/password, certificates, etc.)
to decide whether an actor can access a network. However, the verification
process occurs only at the system's perimeter because most IoT devices lack
robust security measures due to their limited hardware and software
capabilities, making them highly vulnerable. Therefore, this paper proposes a
novel approach based on Zero Trust Architecture (ZTA) extended with blockchain
to further enhance security. The blockchain component serves as an immutable
database for storing users' requests and is used to verify trustworthiness by
analyzing and identifying potentially malicious user activities. We discuss the
framework, processes of the approach, and the experiments carried out on a
testbed to validate its feasibility and applicability in the smart city
context. Lastly, the evaluation focuses on non-functional properties such as
performance, scalability, and complexity.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16751" title="Abstract">arXiv:2311.16751</a> [<a href="/pdf/2311.16751" title="Download PDF">pdf</a>, <a href="/format/2311.16751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MultiCBR: Multi-view Contrastive Learning for Bundle Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yunshan Ma</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yingzhi He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yinwei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xiaoyu Du</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yuyangzi Fu</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Bundle recommendation seeks to recommend a bundle of related items to users
to improve both user experience and the profits of platform. Existing bundle
recommendation models have progressed from capturing only user-bundle
interactions to the modeling of multiple relations among users, bundles and
items. CrossCBR, in particular, incorporates cross-view contrastive learning
into a two-view preference learning framework, significantly improving SOTA
performance. It does, however, have two limitations: 1) the two-view
formulation does not fully exploit all the heterogeneous relations among users,
bundles and items; and 2) the "early contrast and late fusion" framework is
less effective in capturing user preference and difficult to generalize to
multiple views. In this paper, we present MultiCBR, a novel Multi-view
Contrastive learning framework for Bundle Recommendation. First, we devise a
multi-view representation learning framework capable of capturing all the
user-bundle, user-item and bundle-item relations, especially better utilizing
the bundle-item affiliations to enhance sparse bundles' representations.
Second, we innovatively adopt an "early fusion and late contrast" design that
first fuses the multi-view representations before performing self-supervised
contrastive learning. In comparison to existing approaches, our framework
reverses the order of fusion and contrast, introducing the following
advantages: 1)our framework is capable of modeling both cross-view and ego-view
preferences, allowing us to achieve enhanced user preference modeling; and 2)
instead of requiring quadratic number of cross-view contrastive losses, we only
require two self-supervised contrastive losses, resulting in minimal extra
costs. Experimental results on three public datasets indicate that our method
outperforms SOTA methods.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16754" title="Abstract">arXiv:2311.16754</a> [<a href="/pdf/2311.16754" title="Download PDF">pdf</a>, <a href="/format/2311.16754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Full-scene Domain Generalization in Multi-agent Collaborative  Bird&#x27;s Eye View Segmentation for Connected and Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Senkang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhengru Fang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xianhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuguang Fang</a>, 
<a href="/search/cs?searchtype=author&query=Kwong%2C+S">Sam Kwong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Collaborative perception has recently gained significant attention in
autonomous driving, improving perception quality by enabling the exchange of
additional information among vehicles. However, deploying collaborative
perception systems can lead to domain shifts due to diverse environmental
conditions and data heterogeneity among connected and autonomous vehicles
(CAVs). To address these challenges, we propose a unified domain generalization
framework applicable in both training and inference stages of collaborative
perception. In the training phase, we introduce an Amplitude Augmentation
(AmpAug) method to augment low-frequency image variations, broadening the
model's ability to learn across various domains. We also employ a
meta-consistency training scheme to simulate domain shifts, optimizing the
model with a carefully designed consistency loss to encourage domain-invariant
representations. In the inference phase, we introduce an intra-system domain
alignment mechanism to reduce or potentially eliminate the domain discrepancy
among CAVs prior to inference. Comprehensive experiments substantiate the
effectiveness of our method in comparison with the existing state-of-the-art
works. Code will be released at https://github.com/DG-CAVs/DG-CoPerception.git.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16759" title="Abstract">arXiv:2311.16759</a> [<a href="/pdf/2311.16759" title="Download PDF">pdf</a>, <a href="/format/2311.16759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient-based Local Next-best-view Planning for Improved Perception of  Targeted Plant Nodes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Burusa%2C+A+K">Akshay K. Burusa</a>, 
<a href="/search/cs?searchtype=author&query=van+Henten%2C+E+J">Eldert J. van Henten</a>, 
<a href="/search/cs?searchtype=author&query=Kootstra%2C+G">Gert Kootstra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Robots are increasingly used in tomato greenhouses to automate
labour-intensive tasks such as selective harvesting and de-leafing. To perform
these tasks, robots must be able to accurately and efficiently perceive the
plant nodes that need to be cut, despite the high levels of occlusion from
other plant parts. We formulate this problem as a local next-best-view (NBV)
planning task where the robot has to plan an efficient set of camera viewpoints
to overcome occlusion and improve the quality of perception. Our formulation
focuses on quickly improving the perception accuracy of a single target node to
maximise its chances of being cut. Previous methods of NBV planning mostly
focused on global view planning and used random sampling of candidate
viewpoints for exploration, which could suffer from high computational costs,
ineffective view selection due to poor candidates, or non-smooth trajectories
due to inefficient sampling. We propose a gradient-based NBV planner using
differential ray sampling, which directly estimates the local gradient
direction for viewpoint planning to overcome occlusion and improve perception.
Through simulation experiments, we showed that our planner can handle
occlusions and improve the 3D reconstruction and position estimation of nodes
equally well as a sampling-based NBV planner, while taking ten times less
computation and generating 28% more efficient trajectories.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16760" title="Abstract">arXiv:2311.16760</a> [<a href="/pdf/2311.16760" title="Download PDF">pdf</a>, <a href="/ps/2311.16760" title="Download PostScript">ps</a>, <a href="/format/2311.16760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fair Interventions in Weighted Congestion Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fischer%2C+M">Miriam Fischer</a>, 
<a href="/search/cs?searchtype=author&query=Gairing%2C+M">Martin Gairing</a>, 
<a href="/search/cs?searchtype=author&query=Paccagnan%2C+D">Dario Paccagnan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Computational Complexity (cs.CC); Optimization and Control (math.OC)

</div>
<p class="mathjax">In this work we study the power and limitations of fair interventions in
weighted congestion games. Specifically, we focus on interventions that aim at
improving the equilibrium quality (price of anarchy) and are fair in the sense
that identical players receive identical treatment. Within this setting, we
provide three key contributions: First, we show that no fair intervention can
reduce the price of anarchy below a given factor depending solely on the class
of latencies considered. Interestingly, this lower bound is unconditional,
i.e., it applies regardless of how much computation interventions are allowed
to use. Second, we propose a taxation mechanism that is fair and show that the
resulting price of anarchy matches this lower bound, while the mechanism can be
efficiently computed in polynomial time. Third, we complement these results by
showing that no intervention (fair or not) can achieve a better approximation
if polynomial computability is required. We do so by proving that the minimum
social cost is NP-hard to approximate below a factor identical to the one
previously introduced. In doing so, we also show that the randomized algorithm
proposed by Makarychev and Sviridenko (Journal of the ACM, 2018) for the class
of optimization problems with a "diseconomy of scale" is optimal, and provide a
novel way to derandomize its solution via equilibrium computation.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16764" title="Abstract">arXiv:2311.16764</a> [<a href="/pdf/2311.16764" title="Download PDF">pdf</a>, <a href="/format/2311.16764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Radiology-Aware Model-Based Evaluation Metric for Report Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Calamida%2C+A">Amos Calamida</a>, 
<a href="/search/cs?searchtype=author&query=Nooralahzadeh%2C+F">Farhad Nooralahzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Rohanian%2C+M">Morteza Rohanian</a>, 
<a href="/search/cs?searchtype=author&query=Fujimoto%2C+K">Koji Fujimoto</a>, 
<a href="/search/cs?searchtype=author&query=Nishio%2C+M">Mizuho Nishio</a>, 
<a href="/search/cs?searchtype=author&query=Krauthammer%2C+M">Michael Krauthammer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We propose a new automated evaluation metric for machine-generated radiology
reports using the successful COMET architecture adapted for the radiology
domain. We train and publish four medically-oriented model checkpoints,
including one trained on RadGraph, a radiology knowledge graph. Our results
show that our metric correlates moderately to high with established metrics
such as BERTscore, BLEU, and CheXbert scores. Furthermore, we demonstrate that
one of our checkpoints exhibits a high correlation with human judgment, as
assessed using the publicly available annotations of six board-certified
radiologists, using a set of 200 reports. We also performed our own analysis
gathering annotations with two radiologists on a collection of 100 reports. The
results indicate the potential effectiveness of our method as a
radiology-specific evaluation metric. The code, data, and model checkpoints to
reproduce our findings will be publicly available.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16766" title="Abstract">arXiv:2311.16766</a> [<a href="/pdf/2311.16766" title="Download PDF">pdf</a>, <a href="/format/2311.16766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rescuing referral failures during automated diagnosis of domain-shifted  medical images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+A">Anuj Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+K">Karm Patel</a>, 
<a href="/search/cs?searchtype=author&query=Shenoy%2C+P">Pradeep Shenoy</a>, 
<a href="/search/cs?searchtype=author&query=Sridharan%2C+D">Devarajan Sridharan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The success of deep learning models deployed in the real world depends
critically on their ability to generalize well across diverse data domains.
Here, we address a fundamental challenge with selective classification during
automated diagnosis with domain-shifted medical images. In this scenario,
models must learn to avoid making predictions when label confidence is low,
especially when tested with samples far removed from the training set
(covariate shift). Such uncertain cases are typically referred to the clinician
for further analysis and evaluation. Yet, we show that even state-of-the-art
domain generalization approaches fail severely during referral when tested on
medical images acquired from a different demographic or using a different
technology. We examine two benchmark diagnostic medical imaging datasets
exhibiting strong covariate shifts: i) diabetic retinopathy prediction with
retinal fundus images and ii) multilabel disease prediction with chest X-ray
images. We show that predictive uncertainty estimates do not generalize well
under covariate shifts leading to non-monotonic referral curves, and severe
drops in performance (up to 50%) at high referral rates (&gt;70%). We evaluate
novel combinations of robust generalization and post hoc referral approaches,
that rescue these failures and achieve significant performance improvements,
typically &gt;10%, over baseline methods. Our study identifies a critical
challenge with referral in domain-shifted medical images and finds key
applications in reliable, automated disease diagnosis.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16769" title="Abstract">arXiv:2311.16769</a> [<a href="/pdf/2311.16769" title="Download PDF">pdf</a>, <a href="/format/2311.16769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Equilibrium in the Computing Continuum through Active Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sedlak%2C+B">Boris Sedlak</a>, 
<a href="/search/cs?searchtype=author&query=Pujol%2C+V+C">Victor Casamayor Pujol</a>, 
<a href="/search/cs?searchtype=author&query=Donta%2C+P+K">Praveen Kumar Donta</a>, 
<a href="/search/cs?searchtype=author&query=Dustdar%2C+S">Schahram Dustdar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Performance (cs.PF); Systems and Control (eess.SY)

</div>
<p class="mathjax">Computing Continuum (CC) systems are challenged to ensure the intricate
requirements of each computational tier. Given the system's scale, the Service
Level Objectives (SLOs) which are expressed as these requirements, must be
broken down into smaller parts that can be decentralized. We present our
framework for collaborative edge intelligence enabling individual edge devices
to (1) develop a causal understanding of how to enforce their SLOs, and (2)
transfer knowledge to speed up the onboarding of heterogeneous devices. Through
collaboration, they (3) increase the scope of SLO fulfillment. We implemented
the framework and evaluated a use case in which a CC system is responsible for
ensuring Quality of Service (QoS) and Quality of Experience (QoE) during video
streaming. Our results showed that edge devices required only ten training
rounds to ensure four SLOs; furthermore, the underlying causal structures were
also rationally explainable. The addition of new types of devices can be done a
posteriori, the framework allowed them to reuse existing models, even though
the device type had been unknown. Finally, rebalancing the load within a device
cluster allowed individual edge devices to recover their SLO compliance after a
network failure from 22% to 89%.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16770" title="Abstract">arXiv:2311.16770</a> [<a href="/pdf/2311.16770" title="Download PDF">pdf</a>, <a href="/ps/2311.16770" title="Download PostScript">ps</a>, <a href="/format/2311.16770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The inversion paradox, and classification of fairness notions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feige%2C+U">Uriel Feige</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Several different fairness notions have been introduced in the context of
fair allocation of goods. In this manuscript, we compare between some fairness
notions that are used in settings in which agents have arbitrary (perhaps
unequal) entitlements to the goods. This includes the proportional share, the
anyprice share, the weighted maximin share, weighted envy freeness, maximum
weight Nash social welfare and competitive equilibrium. We perform this
comparison in two settings, that of a divisible homogeneous good and arbitrary
valuations, and that of indivisible goods and additive valuations.
<br />Different fairness notions are not always compatible with each other, and
might dictate selecting different allocations. The purpose of our work is to
clarify various properties of fairness notions, so as to allow, when needed, to
make an educated choice among them. Also, such a study may motivate introducing
new fairness notions, or modifications to existing fairness notions.
<br />Among other properties, we introduce definitions for monotonicity that
postulate that having higher entitlement should be better to the agent than
having lower entitlement. Some monotonicity notions, such as population
monotonicity and weight monotonicity, appeared in previous work, but we prefer
to consider other monotonicity properties that we refer to as global
monotonicity and individual monotonicity. We find that some of the fairness
notions (but not all) violate our monotonicity notions in a strong sense, that
we refer to as the inversion paradox. Under this paradox, a fairness notion
enforces that the value received by an agent decreases when the entitlement of
the agent increases.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16772" title="Abstract">arXiv:2311.16772</a> [<a href="/pdf/2311.16772" title="Download PDF">pdf</a>, <a href="/ps/2311.16772" title="Download PostScript">ps</a>, <a href="/format/2311.16772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Progress on Integrating Quantum Communications in Optical Systems  Testbeds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Horgan%2C+J">Jerry Horgan</a>, 
<a href="/search/cs?searchtype=author&query=Briantcev%2C+D">Dmitrii Briantcev</a>, 
<a href="/search/cs?searchtype=author&query=Kaszubowska-Anandarajah%2C+A">Aleksandra Kaszubowska-Anandarajah</a>, 
<a href="/search/cs?searchtype=author&query=Ruffini%2C+M">Marco Ruffini</a>, 
<a href="/search/cs?searchtype=author&query=Kilper%2C+D">Dan Kilper</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 tables, 1 figure, Asia Communications and Photonics Conference 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Experimental methods are being developed to enable quantum communication
systems research in testbeds. We describe testbed architectures for emerging
quantum technologies and how they can integrate with existing fibre optical
testbeds, specifically OpenIreland.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16773" title="Abstract">arXiv:2311.16773</a> [<a href="/pdf/2311.16773" title="Download PDF">pdf</a>, <a href="/format/2311.16773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Channel Cross Modal Detection of Synthetic Face Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ibsen%2C+M">M. Ibsen</a>, 
<a href="/search/cs?searchtype=author&query=Rathgeb%2C+C">C. Rathgeb</a>, 
<a href="/search/cs?searchtype=author&query=Marcel%2C+S">S. Marcel</a>, 
<a href="/search/cs?searchtype=author&query=Busch%2C+C">C. Busch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Synthetically generated face images have shown to be indistinguishable from
real images by humans and as such can lead to a lack of trust in digital
content as they can, for instance, be used to spread misinformation. Therefore,
the need to develop algorithms for detecting entirely synthetic face images is
apparent. Of interest are images generated by state-of-the-art deep
learning-based models, as these exhibit a high level of visual realism. Recent
works have demonstrated that detecting such synthetic face images under
realistic circumstances remains difficult as new and improved generative models
are proposed with rapid speed and arbitrary image post-processing can be
applied. In this work, we propose a multi-channel architecture for detecting
entirely synthetic face images which analyses information both in the frequency
and visible spectra using Cross Modal Focal Loss. We compare the proposed
architecture with several related architectures trained using Binary Cross
Entropy and show in cross-model experiments that the proposed architecture
supervised using Cross Modal Focal Loss, in general, achieves most competitive
performance.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16780" title="Abstract">arXiv:2311.16780</a> [<a href="/pdf/2311.16780" title="Download PDF">pdf</a>, <a href="/ps/2311.16780" title="Download PostScript">ps</a>, <a href="/format/2311.16780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Creating inclusive mobility systems: towards age and education sensitive  interventions for enhancing autonomous vehicle acceptance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kacperski%2C+C">Celina Kacperski</a>, 
<a href="/search/cs?searchtype=author&query=Ulloa%2C+R">Roberto Ulloa</a>, 
<a href="/search/cs?searchtype=author&query=Wautelet%2C+J">Jeremy Wautelet</a>, 
<a href="/search/cs?searchtype=author&query=Vogel%2C+T">Tobias Vogel</a>, 
<a href="/search/cs?searchtype=author&query=Kutzner%2C+F">Florian Kutzner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">The familiarity principle posits that acceptance increases with exposure,
which has previously been shown with in vivo and simulated experiences with
connected and autonomous vehicles (CAVs). We investigate the impact of a
simulated video-based first-person drive on CAV acceptance, as well as the
impact of information customization, with a particular focus on acceptance by
older individuals and those with lower education. Findings from an online
experiment with N=799 German residents reveal that the simulated experience
improved acceptance across response variables such as intention to use and ease
of use, particularly among older individuals. However, the opportunity to
customize navigation information decreased acceptance of older individuals and
those with university degrees and increased acceptance for younger individuals
and those with lower educational levels.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16781" title="Abstract">arXiv:2311.16781</a> [<a href="/pdf/2311.16781" title="Download PDF">pdf</a>, <a href="/format/2311.16781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generation of Games for Opponent Model Differentiation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Milec%2C+D">David Milec</a>, 
<a href="/search/cs?searchtype=author&query=Lis%C3%BD%2C+V">Viliam Lis&#xfd;</a>, 
<a href="/search/cs?searchtype=author&query=Kiekintveld%2C+C">Christopher Kiekintveld</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Protecting against adversarial attacks is a common multiagent problem.
Attackers in the real world are predominantly human actors, and the protection
methods often incorporate opponent models to improve the performance when
facing humans. Previous results show that modeling human behavior can
significantly improve the performance of the algorithms. However, modeling
humans correctly is a complex problem, and the models are often simplified and
assume humans make mistakes according to some distribution or train parameters
for the whole population from which they sample. In this work, we use data
gathered by psychologists who identified personality types that increase the
likelihood of performing malicious acts. However, in the previous work, the
tests on a handmade game could not show strategic differences between the
models. We created a novel model that links its parameters to psychological
traits. We optimized over parametrized games and created games in which the
differences are profound. Our work can help with automatic game generation when
we need a game in which some models will behave differently and to identify
situations in which the models do not align.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16782" title="Abstract">arXiv:2311.16782</a> [<a href="/pdf/2311.16782" title="Download PDF">pdf</a>, <a href="/format/2311.16782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The curse of language biases in remote sensing VQA: the role of spatial  attributes, language diversity, and the need for clear evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chappuis%2C+C">Christel Chappuis</a>, 
<a href="/search/cs?searchtype=author&query=Walt%2C+E">Eliot Walt</a>, 
<a href="/search/cs?searchtype=author&query=Mendez%2C+V">Vincent Mendez</a>, 
<a href="/search/cs?searchtype=author&query=Lobry%2C+S">Sylvain Lobry</a>, 
<a href="/search/cs?searchtype=author&query=Saux%2C+B+L">Bertrand Le Saux</a>, 
<a href="/search/cs?searchtype=author&query=Tuia%2C+D">Devis Tuia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Remote sensing visual question answering (RSVQA) opens new opportunities for
the use of overhead imagery by the general public, by enabling human-machine
interaction with natural language. Building on the recent advances in natural
language processing and computer vision, the goal of RSVQA is to answer a
question formulated in natural language about a remote sensing image. Language
understanding is essential to the success of the task, but has not yet been
thoroughly examined in RSVQA. In particular, the problem of language biases is
often overlooked in the remote sensing community, which can impact model
robustness and lead to wrong conclusions about the performances of the model.
Thus, the present work aims at highlighting the problem of language biases in
RSVQA with a threefold analysis strategy: visual blind models, adversarial
testing and dataset analysis. This analysis focuses both on model and data.
Moreover, we motivate the use of more informative and complementary evaluation
metrics sensitive to the issue. The gravity of language biases in RSVQA is then
exposed for all of these methods with the training of models discarding the
image data and the manipulation of the visual input during inference. Finally,
a detailed analysis of question-answer distribution demonstrates the root of
the problem in the data itself. Thanks to this analytical study, we observed
that biases in remote sensing are more severe than in standard VQA, likely due
to the specifics of existing remote sensing datasets for the task, e.g.
geographical similarities and sparsity, as well as a simpler vocabulary and
question generation strategies. While new, improved and less-biased datasets
appear as a necessity for the development of the promising field of RSVQA, we
demonstrate that more informed, relative evaluation metrics remain much needed
to transparently communicate results of future RSVQA methods.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16787" title="Abstract">arXiv:2311.16787</a> [<a href="/pdf/2311.16787" title="Download PDF">pdf</a>, <a href="/format/2311.16787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Optimal Reference Translations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zouhar%2C+V">Vil&#xe9;m Zouhar</a>, 
<a href="/search/cs?searchtype=author&query=Kloudov%C3%A1%2C+V">V&#x11b;ra Kloudov&#xe1;</a>, 
<a href="/search/cs?searchtype=author&query=Popel%2C+M">Martin Popel</a>, 
<a href="/search/cs?searchtype=author&query=Bojar%2C+O">Ond&#x159;ej Bojar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in Natural Language Engineering 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The overall translation quality reached by current machine translation (MT)
systems for high-resourced language pairs is remarkably good. Standard methods
of evaluation are not suitable nor intended to uncover the many translation
errors and quality deficiencies that still persist. Furthermore, the quality of
standard reference translations is commonly questioned and comparable quality
levels have been reached by MT alone in several language pairs. Navigating
further research in these high-resource settings is thus difficult. In this
article, we propose a methodology for creating more reliable document-level
human reference translations, called "optimal reference translations," with the
simple aim to raise the bar of what should be deemed "human translation
quality." We evaluate the obtained document-level optimal reference
translations in comparison with "standard" ones, confirming a significant
quality increase and also documenting the relationship between evaluation and
translation editing.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16789" title="Abstract">arXiv:2311.16789</a> [<a href="/pdf/2311.16789" title="Download PDF">pdf</a>, <a href="/format/2311.16789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of the Evolution of Language Model-Based Dialogue Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongru Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lingzhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yiming Du</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingyan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yufei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K">Kam-Fai Wong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Dialogue systems, including task-oriented_dialogue_system (TOD) and
open-domain_dialogue_system (ODD), have undergone significant transformations,
with language_models (LM) playing a central role. This survey delves into the
historical trajectory of dialogue systems, elucidating their intricate
relationship with advancements in language models by categorizing this
evolution into four distinct stages, each marked by pivotal LM breakthroughs:
1) Early_Stage: characterized by statistical LMs, resulting in rule-based or
machine-learning-driven dialogue_systems; 2) Independent development of TOD and
ODD based on neural_language_models (NLM; e.g., LSTM and GRU), since NLMs lack
intrinsic knowledge in their parameters; 3) fusion between different types of
dialogue systems with the advert of pre-trained_language_models (PLMs),
starting from the fusion between four_sub-tasks_within_TOD, and then
TOD_with_ODD; and 4) current LLM-based_dialogue_system, wherein LLMs can be
used to conduct TOD and ODD seamlessly. Thus, our survey provides a
chronological perspective aligned with LM breakthroughs, offering a
comprehensive review of state-of-the-art research outcomes. What's more, we
focus on emerging topics and discuss open challenges, providing valuable
insights into future directions for LLM-based_dialogue_systems. Through this
exploration, we pave the way for a deeper_comprehension of the evolution,
guiding future developments in LM-based dialogue_systems.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16804" title="Abstract">arXiv:2311.16804</a> [<a href="/pdf/2311.16804" title="Download PDF">pdf</a>, <a href="/format/2311.16804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancements in Arc Fault Detection for Electrical Distribution Systems:  A Comprehensive Review from Artificial Intelligence Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Thakur%2C+K">Kriti Thakur</a>, 
<a href="/search/eess?searchtype=author&query=Dwivedi%2C+D">Divyanshi Dwivedi</a>, 
<a href="/search/eess?searchtype=author&query=Babu%2C+K+V+S+M">K. Victor Sam Moses Babu</a>, 
<a href="/search/eess?searchtype=author&query=Parimi%2C+A+M">Alivelu Manga Parimi</a>, 
<a href="/search/eess?searchtype=author&query=Yemula%2C+P+K">Pradeep Kumar Yemula</a>, 
<a href="/search/eess?searchtype=author&query=Chakraborty%2C+P">Pratyush Chakraborty</a>, 
<a href="/search/eess?searchtype=author&query=Pal%2C+M">Mayukha Pal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This comprehensive review paper provides a thorough examination of current
advancements and research in the field of arc fault detection for electrical
distribution systems. The increasing demand for electricity, coupled with the
increasing utilization of renewable energy sources, has necessitated vigilance
in safeguarding electrical distribution systems against arc faults. Such faults
could lead to catastrophic accidents, including fires, equipment damage, loss
of human life, and other critical issues. To mitigate these risks, this review
article focuses on the identification and early detection of arc faults, with a
particular emphasis on the vital role of artificial intelligence (AI) in the
detection and prediction of arc faults. The paper explores a wide range of
methodologies for arc fault detection and highlights the superior performance
of AI-based methods in accurately identifying arc faults when compared to other
approaches. A thorough evaluation of existing methodologies is conducted by
categorizing them into distinct groups, which provides a structured framework
for understanding the current state of arc fault detection techniques. This
categorization serves as a foundation for identifying the existing constraints
and future research avenues in the domain of arc fault detection for electrical
distribution systems. This review paper provides the state of the art in arc
fault detection, aiming to enhance safety and reliability in electrical
distribution systems and guide future research efforts.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16807" title="Abstract">arXiv:2311.16807</a> [<a href="/pdf/2311.16807" title="Download PDF">pdf</a>, <a href="/format/2311.16807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agent-Aware Training for Agent-Agnostic Action Advising in Deep  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yaoquan Wei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shunyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jie Song</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+T">Tongya Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kaixuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Mingli Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Action advising endeavors to leverage supplementary guidance from expert
teachers to alleviate the issue of sampling inefficiency in Deep Reinforcement
Learning (DRL). Previous agent-specific action advising methods are hindered by
imperfections in the agent itself, while agent-agnostic approaches exhibit
limited adaptability to the learning agent. In this study, we propose a novel
framework called Agent-Aware trAining yet Agent-Agnostic Action Advising (A7)
to strike a balance between the two. The underlying concept of A7 revolves
around utilizing the similarity of state features as an indicator for
soliciting advice. However, unlike prior methodologies, the measurement of
state feature similarity is performed by neither the error-prone learning agent
nor the agent-agnostic advisor. Instead, we employ a proxy model to extract
state features that are both discriminative (adaptive to the agent) and
generally applicable (robust to agent noise). Furthermore, we utilize behavior
cloning to train a model for reusing advice and introduce an intrinsic reward
for the advised samples to incentivize the utilization of expert guidance.
Experiments are conducted on the GridWorld, LunarLander, and six prominent
scenarios from Atari games. The results demonstrate that A7 significantly
accelerates the learning process and surpasses existing methods (both
agent-specific and agent-agnostic) by a substantial margin. Our code will be
made publicly available.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16809" title="Abstract">arXiv:2311.16809</a> [<a href="/pdf/2311.16809" title="Download PDF">pdf</a>, <a href="/format/2311.16809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design and trajectory tracking control of CuRobot: A Cubic Reversible  Robot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kai Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiahui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+Y">Yuchen Weng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Baolei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fuqiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jihong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In field environments, numerous robots necessitate manual intervention for
restoration of functionality post a turnover, resulting in diminished
operational efficiency. This study presents an innovative design solution for a
reversible omnidirectional mobile robot denoted as CuRobot, featuring a cube
structure, thereby facilitating uninterrupted omnidirectional movement even in
the event of flipping. The incorporation of eight conical wheels at the cube
vertices ensures consistent omnidirectional motion no matter which face of the
cube contacts the ground. Additionally, a kinematic model is formulated for
CuRobot, accompanied by the development of a trajectory tracking controller
utilizing model predictive control. Through simulation experiments, the
correlation between trajectory tracking accuracy and the robot's motion
direction is examined. Furthermore, the robot's proficiency in omnidirectional
mobility and sustained movement post-flipping is substantiated via both
simulation and prototype experiments. This design reduces the inefficiencies
associated with manual intervention, thereby increasing the operational
robustness of robots in field environments.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16810" title="Abstract">arXiv:2311.16810</a> [<a href="/pdf/2311.16810" title="Download PDF">pdf</a>, <a href="/format/2311.16810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Short Overview of 6G V2X Communication Standards
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+D">Donglin Wang</a>, 
<a href="/search/eess?searchtype=author&query=Nganso%2C+Y+N">Yann Nana Nganso</a>, 
<a href="/search/eess?searchtype=author&query=Schotten%2C+H+D">Hans D. Schotten</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures, IEEE ICN 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Networking and Internet Architecture (cs.NI); Systems and Control (eess.SY)

</div>
<p class="mathjax">We are on the verge of a new age of linked autonomous cars with unheard-of
user experiences, dramatically improved air quality and road safety, extremely
varied transportation settings, and a plethora of cutting-edge apps. A
substantially improved Vehicle-to-Everything (V2X) communication network that
can simultaneously support massive hyper-fast, ultra-reliable, and low-latency
information exchange is necessary to achieve this ambitious goal. These needs
of the upcoming V2X are expected to be satisfied by the Sixth Generation (6G)
communication system. In this article, we start by introducing the history of
V2X communications by giving details on the current, developing, and future
developments. We compare the applications of communication technologies such as
Wi-Fi, LTE, 5G, and 6G. we focus on the new technologies for 6G V2X which are
brain-vehicle interface, blocked-based V2X, and Machine Learning (ML). To
achieve this, we provide a summary of the most recent ML developments in 6G
vehicle networks. we discuss the security challenges of 6G V2X. We address the
strengths, open challenges, development, and improving areas of further study
in this field.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16813" title="Abstract">arXiv:2311.16813</a> [<a href="/pdf/2311.16813" title="Download PDF">pdf</a>, <a href="/format/2311.16813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Panacea: Panoramic and Controllable Video Generation for Autonomous  Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yuqing Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yucheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yingfei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+F">Fan Jia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanhui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+C">Chong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tiancai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaoyan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangyu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://panacea-ad.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The field of autonomous driving increasingly demands high-quality annotated
training data. In this paper, we propose Panacea, an innovative approach to
generate panoramic and controllable videos in driving scenarios, capable of
yielding an unlimited numbers of diverse, annotated samples pivotal for
autonomous driving advancements. Panacea addresses two critical challenges:
'Consistency' and 'Controllability.' Consistency ensures temporal and
cross-view coherence, while Controllability ensures the alignment of generated
content with corresponding annotations. Our approach integrates a novel 4D
attention and a two-stage generation pipeline to maintain coherence,
supplemented by the ControlNet framework for meticulous control by the
Bird's-Eye-View (BEV) layouts. Extensive qualitative and quantitative
evaluations of Panacea on the nuScenes dataset prove its effectiveness in
generating high-quality multi-view driving-scene videos. This work notably
propels the field of autonomous driving by effectively augmenting the training
dataset used for advanced BEV perception techniques.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16818" title="Abstract">arXiv:2311.16818</a> [<a href="/pdf/2311.16818" title="Download PDF">pdf</a>, <a href="/format/2311.16818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DI-Net : Decomposed Implicit Garment Transfer Network for Digital  Clothed 3D Human
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+X">Xiaojing Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yukun Su</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhonghua Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Guosheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingyao Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D virtual try-on enjoys many potential applications and hence has attracted
wide attention. However, it remains a challenging task that has not been
adequately solved. Existing 2D virtual try-on methods cannot be directly
extended to 3D since they lack the ability to perceive the depth of each pixel.
Besides, 3D virtual try-on approaches are mostly built on the fixed topological
structure and with heavy computation. To deal with these problems, we propose a
Decomposed Implicit garment transfer network (DI-Net), which can effortlessly
reconstruct a 3D human mesh with the newly try-on result and preserve the
texture from an arbitrary perspective. Specifically, DI-Net consists of two
modules: 1) A complementary warping module that warps the reference image to
have the same pose as the source image through dense correspondence learning
and sparse flow learning; 2) A geometry-aware decomposed transfer module that
decomposes the garment transfer into image layout based transfer and texture
based transfer, achieving surface and texture reconstruction by constructing
pixel-aligned implicit functions. Experimental results show the effectiveness
and superiority of our method in the 3D virtual try-on task, which can yield
more high-quality results over other existing methods.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16822" title="Abstract">arXiv:2311.16822</a> [<a href="/pdf/2311.16822" title="Download PDF">pdf</a>, <a href="/format/2311.16822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models Suffer From Their Own Output: An Analysis of the  Self-Consuming Training Loop
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Briesch%2C+M">Martin Briesch</a>, 
<a href="/search/cs?searchtype=author&query=Sobania%2C+D">Dominik Sobania</a>, 
<a href="/search/cs?searchtype=author&query=Rothlauf%2C+F">Franz Rothlauf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Large language models (LLM) have become state of the art in many benchmarks
and conversational LLM applications like ChatGPT are now widely used by the
public. Those LLMs can be used to generate large amounts of content which is
posted on the internet to various platforms. As LLMs are trained on datasets
usually collected from the internet, this LLM-generated content might be used
to train the next generation of LLMs. Therefore, a self-consuming training loop
emerges in which new LLM generations are trained on the output from the
previous generations. We empirically study this self-consuming training loop
using a novel dataset to analytically and accurately measure quality and
diversity of generated outputs. We find that this self-consuming training loop
initially improves both quality and diversity. However, after a few generations
the output inevitably degenerates in diversity. We find that the rate of
degeneration depends on the proportion of real and generated data.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16825" title="Abstract">arXiv:2311.16825</a> [<a href="/pdf/2311.16825" title="Download PDF">pdf</a>, <a href="/format/2311.16825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Test for IP-ECN Propagation by a Remote Tunnel Endpoint
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Briscoe%2C+B">Bob Briscoe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4pp; 5 figs
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">This memo defines a brief set of tests to determine the decapsulation
behaviour of an unknown remote tunnel endpoint with respect to the Explicit
Congestion Notification (ECN) field in the Internet Protocol (IP) header. The
tests could be automated to be used by a tunnel ingress to determine whether
the egress that it is paired with will propagate ECN correctly.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16826" title="Abstract">arXiv:2311.16826</a> [<a href="/pdf/2311.16826" title="Download PDF">pdf</a>, <a href="/format/2311.16826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative analysis of numerical approaches for fracture simulation in  multiphase materials containing interfaces: Unveiling the potential of  microstructural design to enhance fracture properties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koopas%2C+R+N">Rasoul Najafi Koopas</a>, 
<a href="/search/cs?searchtype=author&query=Rezaei%2C+S">Shahed Rezaei</a>, 
<a href="/search/cs?searchtype=author&query=Rauter%2C+N">Natalie Rauter</a>, 
<a href="/search/cs?searchtype=author&query=Ostwald%2C+R">Richard Ostwald</a>, 
<a href="/search/cs?searchtype=author&query=Lammering%2C+R">Rolf Lammering</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">This study evaluates four fracture simulation methods, comparing their
computational expenses and implementation complexities within the Finite
Element (FE) framework when employed on multiphase materials. Fracture methods
considered encompass the Cohesive Zone Model (CZM) using zero-thickness
cohesive interface elements (CIEs), the Standard Phase-Field Fracture (SPFM)
approach, the Cohesive Phase-Field fracture (CPFM) approach, and an innovative
hybrid model. The hybrid approach combines the CPFM fracture method with the
CZM, specifically applying the CZM within the interface zone. The finite
element model studied is characterized by three specific phases: Inclusions,
matrix, and interface zone. The thorough assessment of these modeling
techniques indicates that the CPFM approach stands out as the most effective
computational model provided that the thickness of the interface zone is not
significantly smaller than that of the other phases. In materials like concrete
the interface thickness is notably small when compared to other phases. This
leads to the hybrid model standing as the most authentic finite element model,
utilizing CIEs within the interface to simulate interface debonding. A
significant finding from this investigation is that the CPFM method is in
agreement with the hybrid model when the interface zone thickness is not
excessively small. This implies that the CPFM fracture methodology may serve as
a unified fracture approach for multiphase materials, provided the interface
zone's thickness is comparable to that of the other phases. In addition, this
research provides valuable insights that can advance efforts to fine-tune
material microstructures. An investigation of the influence of the interface
material properties, morphological features and spatial arrangement of
inclusions showes a pronounced effect of these parameters on the fracture
toughness of the material.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16828" title="Abstract">arXiv:2311.16828</a> [<a href="/pdf/2311.16828" title="Download PDF">pdf</a>, <a href="/format/2311.16828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SARA: Controllable Makeup Transfer with Spatial Alignment and  Region-Adaptive Normalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+X">Xiaojing Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xinyi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhonghua Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Guosheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingyao Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Makeup transfer is a process of transferring the makeup style from a
reference image to the source images, while preserving the source images'
identities. This technique is highly desirable and finds many applications.
However, existing methods lack fine-level control of the makeup style, making
it challenging to achieve high-quality results when dealing with large spatial
misalignments. To address this problem, we propose a novel Spatial Alignment
and Region-Adaptive normalization method (SARA) in this paper. Our method
generates detailed makeup transfer results that can handle large spatial
misalignments and achieve part-specific and shade-controllable makeup transfer.
Specifically, SARA comprises three modules: Firstly, a spatial alignment module
that preserves the spatial context of makeup and provides a target semantic map
for guiding the shape-independent style codes. Secondly, a region-adaptive
normalization module that decouples shape and makeup style using per-region
encoding and normalization, which facilitates the elimination of spatial
misalignments. Lastly, a makeup fusion module blends identity features and
makeup style by injecting learned scale and bias parameters. Experimental
results show that our SARA method outperforms existing methods and achieves
state-of-the-art performance on two public datasets.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16829" title="Abstract">arXiv:2311.16829</a> [<a href="/pdf/2311.16829" title="Download PDF">pdf</a>, <a href="/format/2311.16829" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decomposer: Semi-supervised Learning of Image Restoration and Image  Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meinardus%2C+B">Boris Meinardus</a>, 
<a href="/search/cs?searchtype=author&query=Trzeciakiewicz%2C+M">Mariusz Trzeciakiewicz</a>, 
<a href="/search/cs?searchtype=author&query=Herzig%2C+T">Tim Herzig</a>, 
<a href="/search/cs?searchtype=author&query=Kwiatkowski%2C+M">Monika Kwiatkowski</a>, 
<a href="/search/cs?searchtype=author&query=Matern%2C+S">Simon Matern</a>, 
<a href="/search/cs?searchtype=author&query=Hellwich%2C+O">Olaf Hellwich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We present Decomposer, a semi-supervised reconstruction model that decomposes
distorted image sequences into their fundamental building blocks - the original
image and the applied augmentations, i.e., shadow, light, and occlusions. To
solve this problem, we use the SIDAR dataset that provides a large number of
distorted image sequences: each sequence contains images with shadows,
lighting, and occlusions applied to an undistorted version. Each distortion
changes the original signal in different ways, e.g., additive or multiplicative
noise. We propose a transformer-based model to explicitly learn this
decomposition. The sequential model uses 3D Swin-Transformers for
spatio-temporal encoding and 3D U-Nets as prediction heads for individual parts
of the decomposition. We demonstrate that by separately pre-training our model
on weakly supervised pseudo labels, we can steer our model to optimize for our
ambiguous problem definition and learn to differentiate between the different
image distortions.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16831" title="Abstract">arXiv:2311.16831</a> [<a href="/pdf/2311.16831" title="Download PDF">pdf</a>, <a href="/format/2311.16831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tracking a Year of Polarized Twitter Discourse on Abortion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rao%2C+A">Ashwin Rao</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+R">Rong-Ching Chang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Q">Qiankun Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Lerman%2C+K">Kristina Lerman</a>, 
<a href="/search/cs?searchtype=author&query=Wojcieszak%2C+M">Magdalena Wojcieszak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Abortion is one of the most contentious issues in American politics. The
Dobbs v. Jackson Women's Health Organization ruling in 2022, which shifted the
authority to regulate abortion from the federal government to the states,
triggering intense protests and emotional debates across the nation. Yet,
little is known about how online discourse about abortion rights fluctuated on
social media platforms. This study analyzes a corpus of over 57M
abortion-related tweets from January 2022 to January 2023 to show how emotions,
hateful rhetoric, toxic speech, use of obscenities and insults, and also
framing strategies fluctuated over the span of one year among liberal and
conservative users. We offer three key findings. (1) Fluctuations in emotions
were temporary; key events during the analyzed period did not bring about
lasting shifts in expressed emotions. (2) We observe significant ideological
differences in the use of hate speech: conservatives resorted to hateful
rhetoric more than liberals. Yet, liberals were especially likely to use
obscenities and insults, especially on the days the ruling was leaked and after
the Dobbs decision. In turn, toxic language sharply increased among both groups
following the leak and after the SCOTUS ruling. (3) Conservatives employ
religious and fetal personhood frames, while liberals emphasize women's health
and bodily autonomy, with each group reacting negatively to the other group's
frames. Our results offer an in-depth insight into the dynamics of online
discourse on one of the most contentious issues in contemporary America.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16832" title="Abstract">arXiv:2311.16832</a> [<a href="/pdf/2311.16832" title="Download PDF">pdf</a>, <a href="/format/2311.16832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CharacterGLM: Customizing Chinese Conversational AI Characters with  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jinfeng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+D">Dazhen Wan</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+B">Bosi Wen</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yi Song</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jifan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yongkang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+L">Libiao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiaming Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xiyao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Sabour%2C+S">Sahand Sabour</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaohan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+W">Wenjing Hou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yijia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yuxiao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jie Tang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Minlie Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper, we present CharacterGLM, a series of models built upon
ChatGLM, with model sizes ranging from 6B to 66B parameters. Our CharacterGLM
is designed for generating Character-based Dialogues (CharacterDial), which
aims to equip a conversational AI system with character customization for
satisfying people's inherent social desires and emotional needs. On top of
CharacterGLM, we can customize various AI characters or social agents by
configuring their attributes (identities, interests, viewpoints, experiences,
achievements, social relationships, etc.) and behaviors (linguistic features,
emotional expressions, interaction patterns, etc.). Our model outperforms most
mainstream close-source large langauge models, including the GPT series,
especially in terms of consistency, human-likeness, and engagement according to
manual evaluations. We will release our 6B version of CharacterGLM and a subset
of training data to facilitate further research development in the direction of
character-based dialogue generation.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16833" title="Abstract">arXiv:2311.16833</a> [<a href="/pdf/2311.16833" title="Download PDF">pdf</a>, <a href="/format/2311.16833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 1-Lipschitz Layers Compared: Memory, Speed, and Certifiable Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prach%2C+B">Bernd Prach</a>, 
<a href="/search/cs?searchtype=author&query=Brau%2C+F">Fabio Brau</a>, 
<a href="/search/cs?searchtype=author&query=Buttazzo%2C+G">Giorgio Buttazzo</a>, 
<a href="/search/cs?searchtype=author&query=Lampert%2C+C+H">Christoph H. Lampert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">The robustness of neural networks against input perturbations with bounded
magnitude represents a serious concern in the deployment of deep learning
models in safety-critical systems. Recently, the scientific community has
focused on enhancing certifiable robustness guarantees by crafting 1-Lipschitz
neural networks that leverage Lipschitz bounded dense and convolutional layers.
Although different methods have been proposed in the literature to achieve this
goal, understanding the performance of such methods is not straightforward,
since different metrics can be relevant (e.g., training time, memory usage,
accuracy, certifiable robustness) for different applications. For this reason,
this work provides a thorough theoretical and empirical comparison between
methods by evaluating them in terms of memory usage, speed, and certifiable
robust accuracy. The paper also provides some guidelines and recommendations to
support the user in selecting the methods that work best depending on the
available resources. We provide code at
https://github.com/berndprach/1LipschitzLayersCompared.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16834" title="Abstract">arXiv:2311.16834</a> [<a href="/pdf/2311.16834" title="Download PDF">pdf</a>, <a href="/format/2311.16834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modular Neural Networks for Time Series Forecasting: Interpretability  and Feature Selection using Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+Q">Qiqi Su</a>, 
<a href="/search/cs?searchtype=author&query=Kloukinas%2C+C">Christos Kloukinas</a>, 
<a href="/search/cs?searchtype=author&query=d%27Garcez%2C+A">Artur d&#x27;Garcez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multivariate time series have many applications, from healthcare and
meteorology to life science. Although deep learning models have shown excellent
predictive performance for time series, they have been criticised for being
"black-boxes" or non-interpretable. This paper proposes a novel modular neural
network model for multivariate time series prediction that is interpretable by
construction. A recurrent neural network learns the temporal dependencies in
the data while an attention-based feature selection component selects the most
relevant features and suppresses redundant features used in the learning of the
temporal dependencies. A modular deep network is trained from the selected
features independently to show the users how features influence outcomes,
making the model interpretable. Experimental results show that this approach
can outperform state-of-the-art interpretable Neural Additive Models (NAM) and
variations thereof in both regression and classification of time series tasks,
achieving a predictive performance that is comparable to the top
non-interpretable methods for time series, LSTM and XGBoost.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16835" title="Abstract">arXiv:2311.16835</a> [<a href="/pdf/2311.16835" title="Download PDF">pdf</a>, <a href="/format/2311.16835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unified-modal Salient Object Detection via Adaptive Prompt Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kunpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenglong Li</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhengzheng Tu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+B">Bin Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing single-modal and multi-modal salient object detection (SOD) methods
focus on designing specific architectures tailored for their respective tasks.
However, developing completely different models for different tasks leads to
labor and time consumption, as well as high computational and practical
deployment costs. In this paper, we make the first attempt to address both
single-modal and multi-modal SOD in a unified framework called UniSOD.
Nevertheless, assigning appropriate strategies to modality variable inputs is
challenging. To this end, UniSOD learns modality-aware prompts with
task-specific hints through adaptive prompt learning, which are plugged into
the proposed pre-trained baseline SOD model to handle corresponding tasks,
while only requiring few learnable parameters compared to training the entire
model. Each modality-aware prompt is generated from a switchable prompt
generation block, which performs structural switching solely relied on
single-modal and multi-modal inputs. UniSOD achieves consistent performance
improvement on 14 benchmark datasets for RGB, RGB-D, and RGB-T SOD, which
demonstrates that our method effectively and efficiently unifies single-modal
and multi-modal SOD tasks.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16838" title="Abstract">arXiv:2311.16838</a> [<a href="/pdf/2311.16838" title="Download PDF">pdf</a>, <a href="/format/2311.16838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Increasing Transparency of Reinforcement Learning using Shielding for  Human Preferences and Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Angelopoulos%2C+G">Georgios Angelopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Mangiacapra%2C+L">Luigi Mangiacapra</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+A">Alessandra Rossi</a>, 
<a href="/search/cs?searchtype=author&query=Di+Napoli%2C+C">Claudia Di Napoli</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+S">Silvia Rossi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The adoption of Reinforcement Learning (RL) in several human-centred
applications provides robots with autonomous decision-making capabilities and
adaptability based on the observations of the operating environment. In such
scenarios, however, the learning process can make robots' behaviours unclear
and unpredictable to humans, thus preventing a smooth and effective Human-Robot
Interaction (HRI). As a consequence, it becomes crucial to avoid robots
performing actions that are unclear to the user. In this work, we investigate
whether including human preferences in RL (concerning the actions the robot
performs during learning) improves the transparency of a robot's behaviours.
For this purpose, a shielding mechanism is included in the RL algorithm to
include human preferences and to monitor the learning agent's decisions. We
carried out a within-subjects study involving 26 participants to evaluate the
robot's transparency in terms of Legibility, Predictability, and Expectability
in different settings. Results indicate that considering human preferences
during learning improves Legibility with respect to providing only
Explanations, and combining human preferences with explanations elucidating the
rationale behind the robot's decisions further amplifies transparency. Results
also confirm that an increase in transparency leads to an increase in the
safety, comfort, and reliability of the robot. These findings show the
importance of transparency during learning and suggest a paradigm for robotic
applications with human in the loop.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16839" title="Abstract">arXiv:2311.16839</a> [<a href="/pdf/2311.16839" title="Download PDF">pdf</a>, <a href="/format/2311.16839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Hallucinations: Enhancing LVLMs through Hallucination-Aware  Direct Preference Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhiyuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+L">Linke Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xiaoyi Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Conghui He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Multimodal large language models have made significant advancements in recent
years, yet they still suffer from a common issue known as the "hallucination
problem" where the models generate textual descriptions that contain inaccurate
or non-existent content from the image. To address this issue, this paper
introduces a novel strategy: Hallucination-Aware Direct Preference Optimization
(HA-DPO). Our approach treats the hallucination problem as a unique preference
selection issue, where the model is trained to favor the non-hallucinating
response when presented with two responses of the same image (one accurate and
one hallucinating). This paper also presents an efficient process for
constructing hallucination sample pairs to ensure high-quality,
style-consistent pairs for stable HA-DPO training. We applied this strategy to
two mainstream multimodal models, and the results showed a significant
reduction in the hallucination problem and an enhancement in the models'
generalization capabilities. With HA-DPO, the MiniGPT-4 model demonstrates
significant advancements: POPE accuracy increases from 51.13% to 85.66% (34.5%
absolute improvement), and the MME score escalates from 968.58 to 1365.76 (41%
relative improvement). The code, models, and datasets will be made publicly
available.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16840" title="Abstract">arXiv:2311.16840</a> [<a href="/pdf/2311.16840" title="Download PDF">pdf</a>, <a href="/ps/2311.16840" title="Download PostScript">ps</a>, <a href="/format/2311.16840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Claire French Dialogue Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hunter%2C+J">Julie Hunter</a>, 
<a href="/search/cs?searchtype=author&query=Louradour%2C+J">J&#xe9;r&#xf4;me Louradour</a>, 
<a href="/search/cs?searchtype=author&query=Rennard%2C+V">Virgile Rennard</a>, 
<a href="/search/cs?searchtype=author&query=Harrando%2C+I">Isma&#xef;l Harrando</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+G">Guokan Shang</a>, 
<a href="/search/cs?searchtype=author&query=Lorr%C3%A9%2C+J">Jean-Pierre Lorr&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present the Claire French Dialogue Dataset (CFDD), a resource created by
members of LINAGORA Labs in the context of the OpenLLM France initiative. CFDD
is a corpus containing roughly 160 million words from transcripts and stage
plays in French that we have assembled and publicly released in an effort to
further the development of multilingual, open source language models. This
paper describes the 24 individual corpora of which CFDD is composed and
provides links and citations to their original sources. It also provides our
proposed breakdown of the full CFDD dataset into eight categories of subcorpora
and describes the process we followed to standardize the format of the final
dataset. We conclude with a discussion of similar work and future directions.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16841" title="Abstract">arXiv:2311.16841</a> [<a href="/pdf/2311.16841" title="Download PDF">pdf</a>, <a href="/format/2311.16841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two-step dynamic obstacle avoidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hart%2C+F">Fabian Hart</a>, 
<a href="/search/cs?searchtype=author&query=Waltz%2C+M">Martin Waltz</a>, 
<a href="/search/cs?searchtype=author&query=Okhrin%2C+O">Ostap Okhrin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Dynamic obstacle avoidance (DOA) is a fundamental challenge for any
autonomous vehicle, independent of whether it operates in sea, air, or land.
This paper proposes a two-step architecture for handling DOA tasks by combining
supervised and reinforcement learning (RL). In the first step, we introduce a
data-driven approach to estimate the collision risk of an obstacle using a
recurrent neural network, which is trained in a supervised fashion and offers
robustness to non-linear obstacle movements. In the second step, we include
these collision risk estimates into the observation space of an RL agent to
increase its situational awareness.~We illustrate the power of our two-step
approach by training different RL agents in a challenging environment that
requires to navigate amid multiple obstacles. The non-linear movements of
obstacles are exemplarily modeled based on stochastic processes and periodic
patterns, although our architecture is suitable for any obstacle dynamics. The
experiments reveal that integrating our collision risk metrics into the
observation space doubles the performance in terms of reward, which is
equivalent to halving the number of collisions in the considered environment.
Furthermore, we show that the architecture's performance improvement is
independent of the applied RL algorithm.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16842" title="Abstract">arXiv:2311.16842</a> [<a href="/pdf/2311.16842" title="Download PDF">pdf</a>, <a href="/format/2311.16842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RELIC: Investigating Large Language Model Responses using  Self-Consistency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+F">Furui Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zouhar%2C+V">Vil&#xe9;m Zouhar</a>, 
<a href="/search/cs?searchtype=author&query=Arora%2C+S">Simran Arora</a>, 
<a href="/search/cs?searchtype=author&query=Sachan%2C+M">Mrinmaya Sachan</a>, 
<a href="/search/cs?searchtype=author&query=Strobelt%2C+H">Hendrik Strobelt</a>, 
<a href="/search/cs?searchtype=author&query=El-Assady%2C+M">Mennatallah El-Assady</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large Language Models (LLMs) are notorious for blending fact with fiction and
generating non-factual content, known as hallucinations. To tackle this
challenge, we propose an interactive system that helps users obtain insights
into the reliability of the generated text. Our approach is based on the idea
that the self-consistency of multiple samples generated by the same LLM relates
to its confidence in individual claims in the generated texts. Using this idea,
we design RELIC, an interactive system that enables users to investigate and
verify semantic-level variations in multiple long-form responses. This allows
users to recognize potentially inaccurate information in the generated text and
make necessary corrections. From a user study with ten participants, we
demonstrate that our approach helps users better verify the reliability of the
generated text. We further summarize the design implications and lessons
learned from this research for inspiring future studies on reliable human-LLM
interactions.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16843" title="Abstract">arXiv:2311.16843</a> [<a href="/pdf/2311.16843" title="Download PDF">pdf</a>, <a href="/ps/2311.16843" title="Download PostScript">ps</a>, <a href="/format/2311.16843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-training solutions for the ICCV 2023 GeoNet Challenge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sheng%2C+L">Lijun Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhengbo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jian Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> technical report; 1st in the ICCV-2023 GeoUniDA challenge
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">GeoNet is a recently proposed domain adaptation benchmark consisting of three
challenges (i.e., GeoUniDA, GeoImNet, and GeoPlaces). Each challenge contains
images collected from the USA and Asia where there are huge geographical gaps.
Our solution adopts a two-stage source-free domain adaptation framework with a
Swin Transformer backbone to achieve knowledge transfer from the USA (source)
domain to Asia (target) domain. In the first stage, we train a source model
using labeled source data with a re-sampling strategy and two types of
cross-entropy loss. In the second stage, we generate pseudo labels for
unlabeled target data to fine-tune the model. Our method achieves an H-score of
74.56% and ultimately ranks 1st in the GeoUniDA challenge. In GeoImNet and
GeoPlaces challenges, our solution also reaches a top-3 accuracy of 64.46% and
51.23%, respectively.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16844" title="Abstract">arXiv:2311.16844</a> [<a href="/pdf/2311.16844" title="Download PDF">pdf</a>, <a href="/format/2311.16844" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Direct Lazy Sampling Proof Technique in Probabilistic Relational Hoare  Logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Metere%2C+R">Roberto Metere</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+C">Changyu Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 13 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
<p class="mathjax">Programs using random values can either make all choices in advance (eagerly)
or sample as needed (lazily). In formal proofs, we focus on
indistinguishability between two lazy programs, a common requirement in the
random oracle model (ROM). While rearranging sampling instructions often solves
this, it gets complex when sampling is spread across procedures. The
traditional approach, introduced by Bellare and Rogaway in 2004, converts
programs to eager sampling, but requires assuming finite memory, a polynomial
bound, and artificial resampling functions. We introduce a novel approach in
probabilistic Relational Hoare Logic (pRHL) that directly proves
indistinguishability, eliminating the need for conversions and the mentioned
assumptions. We also implement this approach in the EasyCrypt theorem prover,
showing that it can be a convenient alternative to the traditional method.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16845" title="Abstract">arXiv:2311.16845</a> [<a href="/pdf/2311.16845" title="Download PDF">pdf</a>, <a href="/format/2311.16845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wavelet-based Fourier Information Interaction with Frequency Diffusion  Adjustment for Underwater Image Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+W">Weiling Cai</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+C">Chenyu Dong</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chengwei Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Underwater images are subject to intricate and diverse degradation,
inevitably affecting the effectiveness of underwater visual tasks. However,
most approaches primarily operate in the raw pixel space of images, which
limits the exploration of the frequency characteristics of underwater images,
leading to an inadequate utilization of deep models' representational
capabilities in producing high-quality images. In this paper, we introduce a
novel Underwater Image Enhancement (UIE) framework, named WF-Diff, designed to
fully leverage the characteristics of frequency domain information and
diffusion models. WF-Diff consists of two detachable networks: Wavelet-based
Fourier information interaction network (WFI2-net) and Frequency Residual
Diffusion Adjustment Module (FRDAM). With our full exploration of the frequency
domain information, WFI2-net aims to achieve preliminary enhancement of
frequency information in the wavelet space. Our proposed FRDAM can further
refine the high- and low-frequency information of the initial enhanced images,
which can be viewed as a plug-and-play universal module to adjust the detail of
the underwater images. With the above techniques, our algorithm can show SOTA
performance on real-world underwater image datasets, and achieves competitive
performance in visual quality.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16847" title="Abstract">arXiv:2311.16847</a> [<a href="/pdf/2311.16847" title="Download PDF">pdf</a>, <a href="/format/2311.16847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Introducing STRAUSS: A flexible sonification Python package
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Trayford%2C+J+W">James W. Trayford</a>, 
<a href="/search/cs?searchtype=author&query=Harrison%2C+C+M">Chris M. Harrison</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures, 28th International Conference on Auditory Display, see here for linked resources: <a href="https://data.ncl.ac.uk/articles/media/Trayford_2023_STRAUSS_ICAD_examples/22241182">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Human-Computer Interaction (cs.HC); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We introduce STRAUSS (Sonification Tools and Resources for Analysis Using
Sound Synthesis) a modular, self-contained and flexible Python sonification
package, operating in a free and open source (FOSS) capacity. STRAUSS is
intended to be a flexible tool suitable for both scientific data exploration
and analysis as well as for producing sonifications that are suitable for
public outreach and artistic contexts. We explain the motivations behind
STRAUSS, and how these lead to our design choices. We also describe the basic
code structure and concepts. We then present output sonification examples,
specifically: (1) multiple representations of univariate data (i.e., single
data series) for data exploration; (2) how multi-variate data can be mapped
onto sound to help interpret how those data variables are related and; (3) a
full spatial audio example for immersive Virtual Reality. We summarise,
alluding to some of the future functionality as STRAUSS development
accelerates.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16851" title="Abstract">arXiv:2311.16851</a> [<a href="/pdf/2311.16851" title="Download PDF">pdf</a>, <a href="/format/2311.16851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Edge AI for Internet of Energy: Challenges and Perspectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Himeur%2C+Y">Yassine Himeur</a>, 
<a href="/search/cs?searchtype=author&query=Sayed%2C+A+N">Aya Nabil Sayed</a>, 
<a href="/search/cs?searchtype=author&query=Alsalemi%2C+A">Abdullah Alsalemi</a>, 
<a href="/search/cs?searchtype=author&query=Bensaali%2C+F">Faycal Bensaali</a>, 
<a href="/search/cs?searchtype=author&query=Amira%2C+A">Abbes Amira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">The digital landscape of the Internet of Energy (IoE) is on the brink of a
revolutionary transformation with the integration of edge Artificial
Intelligence (AI). This comprehensive review elucidates the promise and
potential that edge AI holds for reshaping the IoE ecosystem. Commencing with a
meticulously curated research methodology, the article delves into the myriad
of edge AI techniques specifically tailored for IoE. The myriad benefits,
spanning from reduced latency and real-time analytics to the pivotal aspects of
information security, scalability, and cost-efficiency, underscore the
indispensability of edge AI in modern IoE frameworks. As the narrative
progresses, readers are acquainted with pragmatic applications and techniques,
highlighting on-device computation, secure private inference methods, and the
avant-garde paradigms of AI training on the edge. A critical analysis follows,
offering a deep dive into the present challenges including security concerns,
computational hurdles, and standardization issues. However, as the horizon of
technology ever expands, the review culminates in a forward-looking
perspective, envisaging the future symbiosis of 5G networks, federated edge AI,
deep reinforcement learning, and more, painting a vibrant panorama of what the
future beholds. For anyone vested in the domains of IoE and AI, this review
offers both a foundation and a visionary lens, bridging the present realities
with future possibilities.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16854" title="Abstract">arXiv:2311.16854</a> [<a href="/pdf/2311.16854" title="Download PDF">pdf</a>, <a href="/format/2311.16854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Approach for Text- and Image-guided 4D Scene Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yufeng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xueting Li</a>, 
<a href="/search/cs?searchtype=author&query=Nagano%2C+K">Koki Nagano</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sifei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hilliges%2C+O">Otmar Hilliges</a>, 
<a href="/search/cs?searchtype=author&query=De+Mello%2C+S">Shalini De Mello</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://dream-in-4d.github.io/dream-in-4D/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large-scale diffusion generative models are greatly simplifying image, video
and 3D asset creation from user-provided text prompts and images. However, the
challenging problem of text-to-4D dynamic 3D scene generation with diffusion
guidance remains largely unexplored. We propose Dream-in-4D, which features a
novel two-stage approach for text-to-4D synthesis, leveraging (1) 3D and 2D
diffusion guidance to effectively learn a high-quality static 3D asset in the
first stage; (2) a deformable neural radiance field that explicitly
disentangles the learned static asset from its deformation, preserving quality
during motion learning; and (3) a multi-resolution feature grid for the
deformation field with a displacement total variation loss to effectively learn
motion with video diffusion guidance in the second stage. Through a user
preference study, we demonstrate that our approach significantly advances image
and motion quality, 3D consistency and text fidelity for text-to-4D generation
compared to baseline approaches. Thanks to its motion-disentangled
representation, Dream-in-4D can also be easily adapted for controllable
generation where appearance is defined by one or multiple images, without the
need to modify the motion learning stage. Thus, our method offers, for the
first time, a unified approach for text-to-4D, image-to-4D and personalized 4D
generation tasks.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16856" title="Abstract">arXiv:2311.16856</a> [<a href="/pdf/2311.16856" title="Download PDF">pdf</a>, <a href="/format/2311.16856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attentional Graph Neural Networks for Robust Massive Network  Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+W">Wenzhong Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Juntao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+F">Feng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zoubir%2C+A+M">Abdelhak M. Zoubir</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Machine Learning (stat.ML)

</div>
<p class="mathjax">Graph neural networks (GNNs) have gained significant popularity for
classification tasks in machine learning, yet their applications to regression
problems remain limited. Concurrently, attention mechanisms have emerged as
powerful tools in sequential learning tasks. In this paper, we employ GNNs and
attention mechanisms to address a classical but challenging nonlinear
regression problem: network localization. We propose a novel GNN-based network
localization method that achieves exceptional stability and accuracy in the
presence of severe non-line-of-sight (NLOS) propagations, while eliminating the
need for laborious offline calibration or NLOS identification. Extensive
experimental results validate the effectiveness and high accuracy of our
GNN-based localization model, particularly in challenging NLOS scenarios.
However, the proposed GNN-based model exhibits limited flexibility, and its
accuracy is highly sensitive to a specific hyperparameter that determines the
graph structure. To address the limitations and extend the applicability of the
GNN-based model to real scenarios, we introduce two attentional graph neural
networks (AGNNs) that offer enhanced flexibility and the ability to
automatically learn the optimal hyperparameter for each node. Experimental
results confirm that the AGNN models are able to enhance localization accuracy,
providing a promising solution for real-world applications. We also provide
some analyses of the improved performance achieved by the AGNN models from the
perspectives of dynamic attention and signal denoising characteristics.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16860" title="Abstract">arXiv:2311.16860</a> [<a href="/pdf/2311.16860" title="Download PDF">pdf</a>, <a href="/format/2311.16860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-efficient operator learning for solving high Mach number fluid flow  problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ford%2C+N">Noah Ford</a>, 
<a href="/search/cs?searchtype=author&query=Leon%2C+V+J">Victor J. Leon</a>, 
<a href="/search/cs?searchtype=author&query=Merman%2C+H">Honest Merman</a>, 
<a href="/search/cs?searchtype=author&query=Gilbert%2C+J">Jeffrey Gilbert</a>, 
<a href="/search/cs?searchtype=author&query=New%2C+A">Alexander New</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">We consider the problem of using SciML to predict solutions of high Mach
fluid flows over irregular geometries. In this setting, data is limited, and so
it is desirable for models to perform well in the low-data setting. We show
that Neural Basis Functions (NBF), which learns a basis of behavior modes from
the data and then uses this basis to make predictions, is more effective than a
basis-unaware baseline model. In addition, we identify continuing challenges in
the space of predicting solutions for this type of problem.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16863" title="Abstract">arXiv:2311.16863</a> [<a href="/pdf/2311.16863" title="Download PDF">pdf</a>, <a href="/format/2311.16863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Power Hungry Processing: Watts Driving the Cost of AI Deployment?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luccioni%2C+A+S">Alexandra Sasha Luccioni</a>, 
<a href="/search/cs?searchtype=author&query=Jernite%2C+Y">Yacine Jernite</a>, 
<a href="/search/cs?searchtype=author&query=Strubell%2C+E">Emma Strubell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Recent years have seen a surge in the popularity of commercial AI products
based on generative, multi-purpose AI systems promising a unified approach to
building machine learning (ML) models into technology. However, this ambition
of "generality" comes at a steep cost to the environment, given the amount of
energy these systems require and the amount of carbon that they emit. In this
work, we propose the first systematic comparison of the ongoing inference cost
of various categories of ML systems, covering both task-specific (i.e.
finetuned models that carry out a single task) and `general-purpose' models,
(i.e. those trained for multiple tasks). We measure deployment cost as the
amount of energy and carbon required to perform 1,000 inferences on
representative benchmark dataset using these models. We find that
multi-purpose, generative architectures are orders of magnitude more expensive
than task-specific systems for a variety of tasks, even when controlling for
the number of model parameters. We conclude with a discussion around the
current trend of deploying multi-purpose generative ML systems, and caution
that their utility should be more intentionally weighed against increased costs
in terms of energy and emissions. All the data from our study can be accessed
via an interactive demo to carry out further exploration and analysis.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16865" title="Abstract">arXiv:2311.16865</a> [<a href="/pdf/2311.16865" title="Download PDF">pdf</a>, <a href="/format/2311.16865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Benchmark for Evaluating Machine Translation Metrics on Dialects  Without Standard Orthography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aepli%2C+N">No&#xeb;mi Aepli</a>, 
<a href="/search/cs?searchtype=author&query=Amrhein%2C+C">Chantal Amrhein</a>, 
<a href="/search/cs?searchtype=author&query=Schottmann%2C+F">Florian Schottmann</a>, 
<a href="/search/cs?searchtype=author&query=Sennrich%2C+R">Rico Sennrich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WMT 2023 Research Paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">For sensible progress in natural language processing, it is important that we
are aware of the limitations of the evaluation metrics we use. In this work, we
evaluate how robust metrics are to non-standardized dialects, i.e. spelling
differences in language varieties that do not have a standard orthography. To
investigate this, we collect a dataset of human translations and human
judgments for automatic machine translations from English to two Swiss German
dialects. We further create a challenge set for dialect variation and benchmark
existing metrics' performances. Our results show that existing metrics cannot
reliably evaluate Swiss German text generation outputs, especially on segment
level. We propose initial design adaptations that increase robustness in the
face of non-standardized dialects, although there remains much room for further
improvement. The dataset, code, and models are available here:
https://github.com/textshuttle/dialect_eval
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16867" title="Abstract">arXiv:2311.16867</a> [<a href="/pdf/2311.16867" title="Download PDF">pdf</a>, <a href="/format/2311.16867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Falcon Series of Open Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Almazrouei%2C+E">Ebtesam Almazrouei</a>, 
<a href="/search/cs?searchtype=author&query=Alobeidli%2C+H">Hamza Alobeidli</a>, 
<a href="/search/cs?searchtype=author&query=Alshamsi%2C+A">Abdulaziz Alshamsi</a>, 
<a href="/search/cs?searchtype=author&query=Cappelli%2C+A">Alessandro Cappelli</a>, 
<a href="/search/cs?searchtype=author&query=Cojocaru%2C+R">Ruxandra Cojocaru</a>, 
<a href="/search/cs?searchtype=author&query=Hesslow%2C+D">Daniel Hesslow</a>, 
<a href="/search/cs?searchtype=author&query=Launay%2C+J">Julien Launay</a>, 
<a href="/search/cs?searchtype=author&query=Malartic%2C+Q">Quentin Malartic</a>, 
<a href="/search/cs?searchtype=author&query=Mazzotta%2C+D">Daniele Mazzotta</a>, 
<a href="/search/cs?searchtype=author&query=Noune%2C+B">Badreddine Noune</a>, 
<a href="/search/cs?searchtype=author&query=Pannier%2C+B">Baptiste Pannier</a>, 
<a href="/search/cs?searchtype=author&query=Penedo%2C+G">Guilherme Penedo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We introduce the Falcon series: 7B, 40B, and 180B parameters causal
decoder-only models trained on a diverse high-quality corpora predominantly
assembled from web data. The largest model, Falcon-180B, has been trained on
over 3.5 trillion tokens of text--the largest openly documented pretraining
run. Falcon-180B significantly outperforms models such as PaLM or Chinchilla,
and improves upon concurrently developed models such as LLaMA 2 or
Inflection-1. It nears the performance of PaLM-2-Large at a reduced pretraining
and inference cost, making it, to our knowledge, one of the three best language
models in the world along with GPT-4 and PaLM-2-Large. We report detailed
evaluations, as well as a deep dive into the methods and custom tooling
employed to pretrain Falcon. Notably, we report on our custom distributed
training codebase, allowing us to efficiently pretrain these models on up to
4,096 A100s on cloud AWS infrastructure with limited interconnect. We release a
600B tokens extract of our web dataset, as well as the Falcon-7/40/180B models
under a permissive license to foster open-science and accelerate the
development of an open ecosystem of large language models.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16872" title="Abstract">arXiv:2311.16872</a> [<a href="/pdf/2311.16872" title="Download PDF">pdf</a>, <a href="/format/2311.16872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A unified weighting framework for evaluating nearest neighbour  classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lenz%2C+O+U">Oliver Urs Lenz</a>, 
<a href="/search/cs?searchtype=author&query=Bollaert%2C+H">Henri Bollaert</a>, 
<a href="/search/cs?searchtype=author&query=Cornelis%2C+C">Chris Cornelis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We present the first comprehensive and large-scale evaluation of classical
(NN), fuzzy (FNN) and fuzzy rough (FRNN) nearest neighbour classification. We
show that existing proposals for nearest neighbour weighting can be
standardised in the form of kernel functions, applied to the distance values
and/or ranks of the nearest neighbours of a test instance. Furthermore, we
identify three commonly used distance functions and four scaling measures. We
systematically evaluate these choices on a collection of 85 real-life
classification datasets. We find that NN, FNN and FRNN all perform best with
Boscovich distance. NN and FRNN perform best with a combination of Samworth
rank- and distance weights and scaling by the mean absolute deviation around
the median ($r_1$), the standard deviaton ($r_2$) or the interquartile range
($r_{\infty}^*$), while FNN performs best with only Samworth distance-weights
and $r_1$- or $r_2$-scaling. We also introduce a new kernel based on fuzzy
Yager negation, and show that NN achieves comparable performance with Yager
distance-weights, which are simpler to implement than a combination of Samworth
distance- and rank-weights. Finally, we demonstrate that FRNN generally
outperforms NN, which in turns performs systematically better than FNN.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16876" title="Abstract">arXiv:2311.16876</a> [<a href="/pdf/2311.16876" title="Download PDF">pdf</a>, <a href="/format/2311.16876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digital Twin-Enhanced Deep Reinforcement Learning for Resource  Management in Networks Slicing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhengming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yongming Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Q">Qingbi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Luxi Yang</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+X">Xiaohu You</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Network slicing-based communication systems can dynamically and efficiently
allocate resources for diversified services. However, due to the limitation of
the network interface on channel access and the complexity of the resource
allocation, it is challenging to achieve an acceptable solution in the
practical system without precise prior knowledge of the dynamics probability
model of the service requests. Existing work attempts to solve this problem
using deep reinforcement learning (DRL), however, such methods usually require
a lot of interaction with the real environment in order to achieve good
results. In this paper, a framework consisting of a digital twin and
reinforcement learning agents is present to handle the issue. Specifically, we
propose to use the historical data and the neural networks to build a digital
twin model to simulate the state variation law of the real environment. Then,
we use the data generated by the network slicing environment to calibrate the
digital twin so that it is in sync with the real environment. Finally, DRL for
slice optimization optimizes its own performance in this virtual
pre-verification environment. We conducted an exhaustive verification of the
proposed digital twin framework to confirm its scalability. Specifically, we
propose to use loss landscapes to visualize the generalization of DRL
solutions. We explore a distillation-based optimization scheme for lightweight
slicing strategies. In addition, we also extend the framework to offline
reinforcement learning, where solutions can be used to obtain intelligent
decisions based solely on historical data. Numerical simulation experiments
show that the proposed digital twin can significantly improve the performance
of the slice optimization strategy.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16877" title="Abstract">arXiv:2311.16877</a> [<a href="/pdf/2311.16877" title="Download PDF">pdf</a>, <a href="/format/2311.16877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imputation using training labels and classification via label imputation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Thu Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Halvorsen%2C+P">P&#xe5;l Halvorsen</a>, 
<a href="/search/cs?searchtype=author&query=Riegler%2C+M+A">Michael A. Riegler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Missing data is a common problem in practical settings. Various imputation
methods have been developed to deal with missing data. However, even though the
label is usually available in the training data, the common practice of
imputation usually only relies on the input and ignores the label. In this
work, we illustrate how stacking the label into the input can significantly
improve the imputation of the input. In addition, we propose a classification
strategy that initializes the predicted test label with missing values and
stacks the label with the input for imputation. This allows imputing the label
and the input at the same time. Also, the technique is capable of handling data
training with missing labels without any prior imputation and is applicable to
continuous, categorical, or mixed-type data. Experiments show promising results
in terms of accuracy.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16878" title="Abstract">arXiv:2311.16878</a> [<a href="/pdf/2311.16878" title="Download PDF">pdf</a>, <a href="/format/2311.16878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal Importance Factor for Loss Functions for CTR Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=T%C3%BCrksoy%2C+R+T">Ramazan Tar&#x131;k T&#xfc;rksoy</a>, 
<a href="/search/cs?searchtype=author&query=T%C3%BCrkmen%2C+B">Beyza T&#xfc;rkmen</a>, 
<a href="/search/cs?searchtype=author&query=Durmu%C5%9F%2C+F">Furkan Durmu&#x15f;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Click-through rate (CTR) prediction is an important task for the companies to
recommend products which better match user preferences. User behavior in
digital advertising is dynamic and changes over time. It is crucial for the
companies to capture the most recent trends to provide more accurate
recommendations for users. In CTR prediction, most models use binary
cross-entropy loss function. However, it does not focus on the data
distribution shifts occurring over time. To address this problem, we propose a
factor for the loss functions by utilizing the sequential nature of user-item
interactions. This approach aims to focus on the most recent samples by
penalizing them more through the loss function without forgetting the long-term
information. Our solution is model-agnostic, and the temporal importance factor
can be used with different loss functions. Offline experiments in both public
and company datasets show that the temporal importance factor for loss
functions outperforms the baseline loss functions considered.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16882" title="Abstract">arXiv:2311.16882</a> [<a href="/pdf/2311.16882" title="Download PDF">pdf</a>, <a href="/format/2311.16882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimisation-Based Multi-Modal Semantic Image Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bowen Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yongxin Yang</a>, 
<a href="/search/cs?searchtype=author&query=McDonagh%2C+S">Steven McDonagh</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shifeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tudosiu%2C+P">Petru-Daniel Tudosiu</a>, 
<a href="/search/cs?searchtype=author&query=Parisot%2C+S">Sarah Parisot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Image editing affords increased control over the aesthetics and content of
generated images. Pre-existing works focus predominantly on text-based
instructions to achieve desired image modifications, which limit edit precision
and accuracy. In this work, we propose an inference-time editing optimisation,
designed to extend beyond textual edits to accommodate multiple editing
instruction types (e.g. spatial layout-based; pose, scribbles, edge maps). We
propose to disentangle the editing task into two competing subtasks: successful
local image modifications and global content consistency preservation, where
subtasks are guided through two dedicated loss functions. By allowing to adjust
the influence of each loss function, we build a flexible editing solution that
can be adjusted to user preferences. We evaluate our method using text, pose
and scribble edit conditions, and highlight our ability to achieve complex
edits, through both qualitative and quantitative experiments.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16883" title="Abstract">arXiv:2311.16883</a> [<a href="/pdf/2311.16883" title="Download PDF">pdf</a>, <a href="/format/2311.16883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compressing the Backward Pass of Large-Scale Neural Architectures by  Structured Activation Pruning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barley%2C+D">Daniel Barley</a>, 
<a href="/search/cs?searchtype=author&query=Fr%C3%B6ning%2C+H">Holger Fr&#xf6;ning</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 10 figures, submitted to the 6th AccML workshop at HiPEAC conference 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Performance (cs.PF)

</div>
<p class="mathjax">The rise of Deep Neural Networks (DNNs) has led to an increase in model size
and complexity, straining the memory capacity of GPUs. Sparsity in DNNs,
characterized as structural or ephemeral, has gained attention as a solution.
This work focuses on ephemeral sparsity, aiming to reduce memory consumption
during training. It emphasizes the significance of activations, an often
overlooked component, and their role in memory usage. This work employs
structured pruning in Block Sparse Compressed Row (BSR) format in combination
with a magnitude-based criterion to efficiently prune activations. We
furthermore introduce efficient block-sparse operators for GPUs and showcase
their effectiveness, as well as the superior compression offered by block
sparsity. We report the effectiveness of activation pruning by evaluating
training speed, accuracy, and memory usage of large-scale neural architectures
on the example of ResMLP on image classification tasks. As a result, we observe
a memory reduction of up to 32\% while maintaining accuracy. Ultimately, our
approach aims to democratize large-scale model training, reduce GPU
requirements, and address ecological concerns.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16888" title="Abstract">arXiv:2311.16888</a> [<a href="/pdf/2311.16888" title="Download PDF">pdf</a>, <a href="/format/2311.16888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Technological Challenges of Ambient Serious Games in Higher Education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brandl%2C+L+C">Lea C. Brandl</a>, 
<a href="/search/cs?searchtype=author&query=Kordts%2C+B">B&#xf6;rge Kordts</a>, 
<a href="/search/cs?searchtype=author&query=Schrader%2C+A">Andreas Schrader</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Naturally, university courses should be designed to attract students,
engaging them to achieve learning goals. Toward this end, the use of Serious
Games has been proposed in the literature. To address positive effects, such as
content memorability and attendance rates, we propose Ambient Serious Games as
games embedded in a computer-enriched environment, which is only partially
perceived mentally by players. In this paper, we describe five technological
key challenges that must be overcome to seamlessly and beneficially integrate
an Ambient Serious Game into teaching. These challenges, derived from a
scenario, focus on the technological provision and conduct of such games based
on a software platform. They include (1) the integration of physical smart
learning objects in heterogeneous environments under dynamic constraints, (2)
the representation of abstract subject matter using smart learning objects, (3)
the guided or automatic connection of all involved components, (4) the
explanation of the components, their interaction, as well as the serious game
itself, and (5) feedback on the game state.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16892" title="Abstract">arXiv:2311.16892</a> [<a href="/pdf/2311.16892" title="Download PDF">pdf</a>, <a href="/format/2311.16892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Item-level Bundle Representation for Bundle Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xiaoyu Du</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+K">Kun Qian</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yunshan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+X">Xinguang Xiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Bundle recommendation approaches offer users a set of related items on a
particular topic. The current state-of-the-art (SOTA) method utilizes
contrastive learning to learn representations at both the bundle and item
levels. However, due to the inherent difference between the bundle-level and
item-level preferences, the item-level representations may not receive
sufficient information from the bundle affiliations to make accurate
predictions. In this paper, we propose a novel approach EBRec, short of
Enhanced Bundle Recommendation, which incorporates two enhanced modules to
explore inherent item-level bundle representations. First, we propose to
incorporate the bundle-user-item (B-U-I) high-order correlations to explore
more collaborative information, thus to enhance the previous bundle
representation that solely relies on the bundle-item affiliation information.
Second, we further enhance the B-U-I correlations by augmenting the observed
user-item interactions with interactions generated from pre-trained models,
thus improving the item-level bundle representations. We conduct extensive
experiments on three public datasets, and the results justify the effectiveness
of our approach as well as the two core modules. Codes and datasets are
available at https://github.com/answermycode/EBRec.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16894" title="Abstract">arXiv:2311.16894</a> [<a href="/pdf/2311.16894" title="Download PDF">pdf</a>, <a href="/format/2311.16894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dendrogram distance: an evaluation metric for generative networks using  hierarchical clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carvalho%2C+G+S">Gustavo Sutter Carvalho</a>, 
<a href="/search/cs?searchtype=author&query=Ponti%2C+M+A">Moacir Antonelli Ponti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We present a novel metric for generative modeling evaluation, focusing
primarily on generative networks. The method uses dendrograms to represent real
and fake data, allowing for the divergence between training and generated
samples to be computed. This metric focus on mode collapse, targeting
generators that are not able to capture all modes in the training set. To
evaluate the proposed method it is introduced a validation scheme based on
sampling from real datasets, therefore the metric is evaluated in a controlled
environment and proves to be competitive with other state-of-the-art
approaches.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16895" title="Abstract">arXiv:2311.16895</a> [<a href="/pdf/2311.16895" title="Download PDF">pdf</a>, <a href="/format/2311.16895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimization Theory Based Deep Reinforcement Learning for Resource  Allocation in Ultra-Reliable Wireless Networked Control Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ali%2C+H+Q">Hamida Qumber Ali</a>, 
<a href="/search/eess?searchtype=author&query=Darabi%2C+A+B">Amirhassan Babazadeh Darabi</a>, 
<a href="/search/eess?searchtype=author&query=Coleri%2C+S">Sinem Coleri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT)

</div>
<p class="mathjax">The design of Wireless Networked Control System (WNCS) requires addressing
critical interactions between control and communication systems with minimal
complexity and communication overhead while providing ultra-high reliability.
This paper introduces a novel optimization theory based deep reinforcement
learning (DRL) framework for the joint design of controller and communication
systems. The objective of minimum power consumption is targeted while
satisfying the schedulability and rate constraints of the communication system
in the finite blocklength regime and stability constraint of the control
system. Decision variables include the sampling period in the control system,
and blocklength and packet error probability in the communication system. The
proposed framework contains two stages: optimization theory and DRL. In the
optimization theory stage, following the formulation of the joint optimization
problem, optimality conditions are derived to find the mathematical relations
between the optimal values of the decision variables. These relations allow the
decomposition of the problem into multiple building blocks. In the DRL stage,
the blocks that are simplified but not tractable are replaced by DRL. Via
extensive simulations, the proposed optimization theory based DRL approach is
demonstrated to outperform the optimization theory and pure DRL based
approaches, with close to optimal performance and much lower complexity.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16900" title="Abstract">arXiv:2311.16900</a> [<a href="/pdf/2311.16900" title="Download PDF">pdf</a>, <a href="/format/2311.16900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lane-Keeping Control of Autonomous Vehicles Through a Soft-Constrained  Iterative LQR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Der-Hau Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 figures, 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO); Systems and Control (eess.SY)

</div>
<p class="mathjax">The accurate prediction of smooth steering inputs is crucial for autonomous
vehicle applications because control actions with jitter might cause the
vehicle system to become unstable. To address this problem in automobile
lane-keeping control without the use of additional smoothing algorithms, we
developed a soft-constrained iterative linear-quadratic regulator (soft-CILQR)
algorithm by integrating CILQR algorithm and a model predictive control (MPC)
constraint relaxation method. We incorporated slack variables into the state
and control barrier functions of the soft-CILQR solver to soften the
constraints in the optimization process so that stabilizing control inputs can
be calculated in a relatively simple manner. Two types of automotive
lane-keeping experiments were conducted with a linear system dynamics model to
test the performance of the proposed soft-CILQR algorithm and to compare its
performance with that of the CILQR algorithm: numerical simulations and
experiments involving challenging vision-based maneuvers. In the numerical
simulations, the soft-CILQR and CILQR solvers managed to drive the system
toward the reference state asymptotically; however, the soft-CILQR solver
obtained smooth steering input trajectories more easily than did the CILQR
solver under conditions involving additive disturbances. In the experiments
with visual inputs, the soft-CILQR controller outperformed the CILQR controller
in terms of tracking accuracy and steering smoothness during the driving of an
ego vehicle on TORCS.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16905" title="Abstract">arXiv:2311.16905</a> [<a href="/pdf/2311.16905" title="Download PDF">pdf</a>, <a href="/format/2311.16905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing the Influence of Language Model-Generated Responses in  Mitigating Hate Speech on Social Media Directed at Ukrainian Refugees in  Poland
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Podolak%2C+J">Jakub Podolak</a>, 
<a href="/search/cs?searchtype=author&query=%C5%81ukasik%2C+S">Szymon &#x141;ukasik</a>, 
<a href="/search/cs?searchtype=author&query=Balawender%2C+P">Pawe&#x142; Balawender</a>, 
<a href="/search/cs?searchtype=author&query=Ossowski%2C+J">Jan Ossowski</a>, 
<a href="/search/cs?searchtype=author&query=B%C4%85kowicz%2C+K">Katarzyna B&#x105;kowicz</a>, 
<a href="/search/cs?searchtype=author&query=Sankowski%2C+P">Piotr Sankowski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">In the context of escalating hate speech and polarization on social media,
this study investigates the potential of employing responses generated by Large
Language Models (LLM), complemented with pertinent verified knowledge links, to
counteract such trends. Through extensive A/B testing involving the posting of
753 automatically generated responses, the goal was to minimize the propagation
of hate speech directed at Ukrainian refugees in Poland.
<br />The results indicate that deploying LLM-generated responses as replies to
harmful tweets effectively diminishes user engagement, as measured by
likes/impressions. When we respond to an original tweet, i.e., which is not a
reply, we reduce the engagement of users by over 20\% without increasing the
number of impressions. On the other hand, our responses increase the ratio of
the number of replies to a harmful tweet to impressions, especially if the
harmful tweet is not original. Additionally, the study examines how generated
responses influence the overall sentiment of tweets in the discussion,
revealing that our intervention does not significantly alter the mean
sentiment.
<br />This paper suggests the implementation of an automatic moderation system to
combat hate speech on social media and provides an in-depth analysis of the A/B
experiment, covering methodology, data collection, and statistical outcomes.
Ethical considerations and challenges are also discussed, offering guidance for
the development of discourse moderation systems leveraging the capabilities of
generative AI.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16912" title="Abstract">arXiv:2311.16912</a> [<a href="/pdf/2311.16912" title="Download PDF">pdf</a>, <a href="/format/2311.16912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous optimization methods for the graph isomorphism problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klus%2C+S">Stefan Klus</a>, 
<a href="/search/cs?searchtype=author&query=Gel%C3%9F%2C+P">Patrick Gel&#xdf;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">The graph isomorphism problem looks deceptively simple, but although
polynomial-time algorithms exist for certain types of graphs such as planar
graphs and graphs with bounded degree or eigenvalue multiplicity, its
complexity class is still unknown. Information about potential isomorphisms
between two graphs is contained in the eigenvalues and eigenvectors of their
adjacency matrices. However, symmetries of graphs often lead to repeated
eigenvalues so that associated eigenvectors are determined only up to basis
rotations, which complicates graph isomorphism testing. We consider orthogonal
and doubly stochastic relaxations of the graph isomorphism problem, analyze the
geometric properties of the resulting solution spaces, and show that their
complexity increases significantly if repeated eigenvalues exist. By
restricting the search space to suitable subspaces, we derive an efficient
Frank-Wolfe based continuous optimization approach for detecting isomorphisms.
We illustrate the efficacy of the algorithm with the aid of various highly
symmetric graphs.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16913" title="Abstract">arXiv:2311.16913</a> [<a href="/pdf/2311.16913" title="Download PDF">pdf</a>, <a href="/format/2311.16913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Which Quantum Circuit Mutants Shall Be Used? An Empirical Evaluation of  Quantum Circuit Mutations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Usandizaga%2C+E+M">E&#xf1;aut Mendiluze Usandizaga</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+T">Tao Yue</a>, 
<a href="/search/cs?searchtype=author&query=Arcaini%2C+P">Paolo Arcaini</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+S">Shaukat Ali</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">As a new research area, quantum software testing lacks systematic testing
benchmarks to assess testing techniques' effectiveness. Recently, some
open-source benchmarks and mutation analysis tools have emerged. However, there
is insufficient evidence on how various quantum circuit characteristics (e.g.,
circuit depth, number of quantum gates), algorithms (e.g., Quantum Approximate
Optimization Algorithm), and mutation characteristics (e.g., mutation
operators) affect the most mutant detection in quantum circuits. Studying such
relations is important to systematically design faulty benchmarks with varied
attributes (e.g., the difficulty in detecting a seeded fault) to facilitate
assessing the cost-effectiveness of quantum software testing techniques
efficiently. To this end, we present a large-scale empirical evaluation with
more than 700K faulty benchmarks (quantum circuits) generated by mutating 382
real-world quantum circuits. Based on the results, we provide valuable insights
for researchers to define systematic quantum mutation analysis techniques. We
also provide a tool to recommend mutants to users based on chosen
characteristics (e.g., a quantum algorithm type) and the required difficulty of
killing mutants. Finally, we also provide faulty benchmarks that can already be
used to assess the cost-effectiveness of quantum software testing techniques.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16914" title="Abstract">arXiv:2311.16914</a> [<a href="/pdf/2311.16914" title="Download PDF">pdf</a>, <a href="/format/2311.16914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Brain-ID: Learning Robust Feature Representations for Brain Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Peirong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Puonti%2C+O">Oula Puonti</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaoling Hu</a>, 
<a href="/search/cs?searchtype=author&query=Alexander%2C+D+C">Daniel C. Alexander</a>, 
<a href="/search/cs?searchtype=author&query=Iglesias%2C+J+E">Juan Eugenio Iglesias</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent learning-based approaches have made astonishing advances in calibrated
medical imaging like computerized tomography, yet they struggle to generalize
in uncalibrated modalities -- notoriously magnetic resonance imaging (MRI),
where performance is highly sensitive to the differences in MR contrast,
resolution, and orientation between the training and testing data. This
prevents broad applicability to the diverse clinical acquisition protocols in
the real world. We introduce Brain-ID, a robust feature representation learning
strategy for brain imaging, which is contrast-agnostic, and robust to the brain
anatomy of each subject regardless of the appearance of acquired images (i.e.,
deformation, contrast, resolution, orientation, artifacts, etc). Brain-ID is
trained entirely on synthetic data, and easily adapts to downstream tasks with
our proposed simple one-layer solution. We validate the robustness of Brain-ID
features, and evaluate their performance in a variety of downstream
applications, including both contrast-independent (anatomy
reconstruction/contrast synthesis, brain segmentation), and contrast-dependent
(super-resolution, bias field estimation) tasks. Extensive experiments on 6
public datasets demonstrate that Brain-ID achieves state-of-the-art performance
in all tasks, and more importantly, preserves its performance when only limited
training data is available.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16916" title="Abstract">arXiv:2311.16916</a> [<a href="/pdf/2311.16916" title="Download PDF">pdf</a>, <a href="/format/2311.16916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stein Variational Belief Propagation for Multi-Robot Coordination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pavlasek%2C+J">Jana Pavlasek</a>, 
<a href="/search/cs?searchtype=author&query=Mah%2C+J+J+Z">Joshua Jing Zhi Mah</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ruihan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jenkins%2C+O+C">Odest Chadwicke Jenkins</a>, 
<a href="/search/cs?searchtype=author&query=Ramos%2C+F">Fabio Ramos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Decentralized coordination for multi-robot systems involves planning in
challenging, high-dimensional spaces. The planning problem is particularly
challenging in the presence of obstacles and different sources of uncertainty
such as inaccurate dynamic models and sensor noise. In this paper, we introduce
Stein Variational Belief Propagation (SVBP), a novel algorithm for performing
inference over nonparametric marginal distributions of nodes in a graph. We
apply SVBP to multi-robot coordination by modelling a robot swarm as a
graphical model and performing inference for each robot. We demonstrate our
algorithm on a simulated multi-robot perception task, and on a multi-robot
planning task within a Model-Predictive Control (MPC) framework, on both
simulated and real-world mobile robots. Our experiments show that SVBP
represents multi-modal distributions better than sampling-based or Gaussian
baselines, resulting in improved performance on perception and planning tasks.
Furthermore, we show that SVBP's ability to represent diverse trajectories for
decentralized multi-robot planning makes it less prone to deadlock scenarios
than leading baselines.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16917" title="Abstract">arXiv:2311.16917</a> [<a href="/pdf/2311.16917" title="Download PDF">pdf</a>, <a href="/format/2311.16917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UGG: Unified Generative Grasping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiaxin Lu</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+H">Hao Kang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoxiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yiding Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qixing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+G">Gang Hua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Dexterous grasping aims to produce diverse grasping postures with a high
grasping success rate. Regression-based methods that directly predict grasping
parameters given the object may achieve a high success rate but often lack
diversity. Generation-based methods that generate grasping postures conditioned
on the object can often produce diverse grasping, but they are insufficient for
high grasping success due to lack of discriminative information. To mitigate,
we introduce a unified diffusion-based dexterous grasp generation model, dubbed
the name UGG, which operates within the object point cloud and hand parameter
spaces. Our all-transformer architecture unifies the information from the
object, the hand, and the contacts, introducing a novel representation of
contact points for improved contact modeling. The flexibility and quality of
our model enable the integration of a lightweight discriminator, benefiting
from simulated discriminative data, which pushes for a high success rate while
preserving high diversity. Beyond grasp generation, our model can also generate
objects based on hand information, offering valuable insights into object
design and studying how the generative model perceives objects. Our model
achieves state-of-the-art dexterous grasping on the large-scale DexGraspNet
dataset while facilitating human-centric object design, marking a significant
advancement in dexterous grasping research. Our project page is
https://jiaxin-lu.github.io/ugg/ .
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16918" title="Abstract">arXiv:2311.16918</a> [<a href="/pdf/2311.16918" title="Download PDF">pdf</a>, <a href="/format/2311.16918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RichDreamer: A Generalizable Normal-Depth Diffusion Model for Detail  Richness in Text-to-3D
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+L">Lingteng Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guanying Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+X">Xiaodong Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+Q">Qi Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mutian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yushuang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Weihao Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zilong Dong</a>, 
<a href="/search/cs?searchtype=author&query=Bo%2C+L">Liefeng Bo</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiaoguang Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://lingtengqiu.github.io/RichDreamer/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Lifting 2D diffusion for 3D generation is a challenging problem due to the
lack of geometric prior and the complex entanglement of materials and lighting
in natural images. Existing methods have shown promise by first creating the
geometry through score-distillation sampling (SDS) applied to rendered surface
normals, followed by appearance modeling. However, relying on a 2D RGB
diffusion model to optimize surface normals is suboptimal due to the
distribution discrepancy between natural images and normals maps, leading to
instability in optimization. In this paper, recognizing that the normal and
depth information effectively describe scene geometry and be automatically
estimated from images, we propose to learn a generalizable Normal-Depth
diffusion model for 3D generation. We achieve this by training on the
large-scale LAION dataset together with the generalizable image-to-depth and
normal prior models. In an attempt to alleviate the mixed illumination effects
in the generated materials, we introduce an albedo diffusion model to impose
data-driven constraints on the albedo component. Our experiments show that when
integrated into existing text-to-3D pipelines, our models significantly enhance
the detail richness, achieving state-of-the-art results. Our project page is
https://lingtengqiu.github.io/RichDreamer/.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16921" title="Abstract">arXiv:2311.16921</a> [<a href="/pdf/2311.16921" title="Download PDF">pdf</a>, <a href="/format/2311.16921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing intrusive and non-intrusive polynomial chaos for a class of  exponential time differencing schemes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Clausnitzer%2C+J">Julian Clausnitzer</a>, 
<a href="/search/math?searchtype=author&query=Kleefeld%2C+A">Andreas Kleefeld</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 13 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We consider the numerical approximation of different ordinary differential
equations (ODEs) and partial differential equations (PDEs) with periodic
boundary conditions involving a one-dimensional random parameter, comparing the
intrusive and non-intrusive polynomial chaos expansion (PCE) method. We
demonstrate how to modify two schemes for intrusive PCE (iPCE) which are highly
efficient in solving nonlinear reaction-diffusion equations: A second-order
exponential time differencing scheme (ETD-RDP-IF) as well as a spectral
exponential time differencing fourth-order Runge-Kutta scheme (ETDRK4). In
numerical experiments, we show that these schemes show superior accuracy to
simpler schemes such as the EE scheme for a range of model equations and we
investigate whether they are competitive with non-intrusive PCE (niPCE)
methods. We observe that the iPCE schemes are competitive with niPCE for some
model equations, but that iPCE breaks down for complex pattern formation models
such as the Gray-Scott system.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16922" title="Abstract">arXiv:2311.16922</a> [<a href="/pdf/2311.16922" title="Download PDF">pdf</a>, <a href="/format/2311.16922" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Object Hallucinations in Large Vision-Language Models through  Visual Contrastive Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leng%2C+S">Sicong Leng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guanzheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shijian Lu</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+C">Chunyan Miao</a>, 
<a href="/search/cs?searchtype=author&query=Bing%2C+L">Lidong Bing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Large Vision-Language Models (LVLMs) have advanced considerably, intertwining
visual recognition and language understanding to generate content that is not
only coherent but also contextually attuned. Despite their success, LVLMs still
suffer from the issue of object hallucinations, where models generate plausible
yet incorrect outputs that include objects that do not exist in the images. To
mitigate this issue, we introduce Visual Contrastive Decoding (VCD), a simple
and training-free method that contrasts output distributions derived from
original and distorted visual inputs. The proposed VCD effectively reduces the
over-reliance on statistical bias and unimodal priors, two essential causes of
object hallucinations. This adjustment ensures the generated content is closely
grounded to visual inputs, resulting in contextually accurate outputs. Our
experiments show that VCD, without either additional training or the usage of
external tools, significantly mitigates the object hallucination issue across
different LVLM families. Beyond mitigating object hallucinations, VCD also
excels in general LVLM benchmarks, highlighting its wide-ranging applicability.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16923" title="Abstract">arXiv:2311.16923</a> [<a href="/pdf/2311.16923" title="Download PDF">pdf</a>, <a href="/format/2311.16923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Super-Resolution through StyleGAN Regularized Latent Search: A  Realism-Fidelity Trade-off
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gheisari%2C+M">Marzieh Gheisari</a>, 
<a href="/search/cs?searchtype=author&query=Genovesio%2C+A">Auguste Genovesio</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper addresses the problem of super-resolution: constructing a highly
resolved (HR) image from a low resolved (LR) one. Recent unsupervised
approaches search the latent space of a StyleGAN pre-trained on HR images, for
the image that best downscales to the input LR image. However, they tend to
produce out-of-domain images and fail to accurately reconstruct HR images that
are far from the original domain. Our contribution is twofold. Firstly, we
introduce a new regularizer to constrain the search in the latent space,
ensuring that the inverted code lies in the original image manifold. Secondly,
we further enhanced the reconstruction through expanding the image prior around
the optimal latent code. Our results show that the proposed approach recovers
realistic high-quality images for large magnification factors. Furthermore, for
low magnification factors, it can still reconstruct details that the generator
could not have produced otherwise. Altogether, our approach achieves a good
trade-off between fidelity and realism for the super-resolution task.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16926" title="Abstract">arXiv:2311.16926</a> [<a href="/pdf/2311.16926" title="Download PDF">pdf</a>, <a href="/format/2311.16926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLaFS: When Large-Language Models Meet Few-Shot Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lanyun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianrun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+D">Deyi Ji</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jieping Ye</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper proposes LLaFS, the first attempt to leverage large language
models (LLMs) in few-shot segmentation. In contrast to the conventional
few-shot segmentation methods that only rely on the limited and biased
information from the annotated support images, LLaFS leverages the vast prior
knowledge gained by LLM as an effective supplement and directly uses the LLM to
segment images in a few-shot manner. To enable the text-based LLM to handle
image-related tasks, we carefully design an input instruction that allows the
LLM to produce segmentation results represented as polygons, and propose a
region-attribute table to simulate the human visual mechanism and provide
multi-modal guidance. We also synthesize pseudo samples and use curriculum
learning for pretraining to augment data and achieve better optimization. LLaFS
achieves state-of-the-art results on multiple datasets, showing the potential
of using LLMs for few-shot computer vision tasks. Code will be available at
https://github.com/lanyunzhu99/LLaFS.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16933" title="Abstract">arXiv:2311.16933</a> [<a href="/pdf/2311.16933" title="Download PDF">pdf</a>, <a href="/format/2311.16933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SparseCtrl: Adding Sparse Controls to Text-to-Video Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuwei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Ceyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+A">Anyi Rao</a>, 
<a href="/search/cs?searchtype=author&query=Agrawala%2C+M">Maneesh Agrawala</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Bo Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://guoyww.github.io/projects/SparseCtrl">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The development of text-to-video (T2V), i.e., generating videos with a given
text prompt, has been significantly advanced in recent years. However, relying
solely on text prompts often results in ambiguous frame composition due to
spatial uncertainty. The research community thus leverages the dense structure
signals, e.g., per-frame depth/edge sequences, to enhance controllability,
whose collection accordingly increases the burden of inference. In this work,
we present SparseCtrl to enable flexible structure control with temporally
sparse signals, requiring only one or a few inputs, as shown in Figure 1. It
incorporates an additional condition encoder to process these sparse signals
while leaving the pre-trained T2V model untouched. The proposed approach is
compatible with various modalities, including sketches, depth maps, and RGB
images, providing more practical control for video generation and promoting
applications such as storyboarding, depth rendering, keyframe animation, and
interpolation. Extensive experiments demonstrate the generalization of
SparseCtrl on both original and personalized T2V generators. Codes and models
will be publicly available at https://guoyww.github.io/projects/SparseCtrl .
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16937" title="Abstract">arXiv:2311.16937</a> [<a href="/pdf/2311.16937" title="Download PDF">pdf</a>, <a href="/format/2311.16937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Sky&#x27;s the Limit: Re-lightable Outdoor Scenes via a Sky-pixel  Constrained Illumination Prior and Outside-In Visibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gardner%2C+J+A+D">James A. D. Gardner</a>, 
<a href="/search/cs?searchtype=author&query=Kashin%2C+E">Evgenii Kashin</a>, 
<a href="/search/cs?searchtype=author&query=Egger%2C+B">Bernhard Egger</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+W+A+P">William A. P. Smith</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Inverse rendering of outdoor scenes from unconstrained image collections is a
challenging task, particularly illumination/albedo ambiguities and occlusion of
the illumination environment (shadowing) caused by geometry. However, there are
many cues in an image that can aid in the disentanglement of geometry, albedo
and shadows. We exploit the fact that any sky pixel provides a direct
measurement of distant lighting in the corresponding direction and, via a
neural illumination prior, a statistical cue as to the remaining illumination
environment. We also introduce a novel `outside-in' method for computing
differentiable sky visibility based on a neural directional distance function.
This is efficient and can be trained in parallel with the neural scene
representation, allowing gradients from appearance loss to flow from shadows to
influence estimation of illumination and geometry. Our method estimates
high-quality albedo, geometry, illumination and sky visibility, achieving
state-of-the-art results on the NeRF-OSR relighting benchmark. Our code and
models can be found https://github.com/JADGardner/neusky
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16940" title="Abstract">arXiv:2311.16940</a> [<a href="/pdf/2311.16940" title="Download PDF">pdf</a>, <a href="/format/2311.16940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FP-Fed: Privacy-Preserving Federated Detection of Browser Fingerprinting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Annamalai%2C+M+S+M+S">Meenatchi Sundaram Muthu Selva Annamalai</a>, 
<a href="/search/cs?searchtype=author&query=Bilogrevic%2C+I">Igor Bilogrevic</a>, 
<a href="/search/cs?searchtype=author&query=De+Cristofaro%2C+E">Emiliano De Cristofaro</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Published in the Proceedings of the 31st Network and Distributed
  System Security Symposium (NDSS 2024), please cite accordingly
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Browser fingerprinting often provides an attractive alternative to
third-party cookies for tracking users across the web. In fact, the increasing
restrictions on third-party cookies placed by common web browsers and recent
regulations like the GDPR may accelerate the transition. To counter browser
fingerprinting, previous work proposed several techniques to detect its
prevalence and severity. However, these rely on 1) centralized web crawls
and/or 2) computationally intensive operations to extract and process signals
(e.g., information-flow and static analysis). To address these limitations, we
present FP-Fed, the first distributed system for browser fingerprinting
detection. Using FP-Fed, users can collaboratively train on-device models based
on their real browsing patterns, without sharing their training data with a
central entity, by relying on Differentially Private Federated Learning
(DP-FL). To demonstrate its feasibility and effectiveness, we evaluate FP-Fed's
performance on a set of 18.3k popular websites with different privacy levels,
numbers of participants, and features extracted from the scripts. Our
experiments show that FP-Fed achieves reasonably high detection performance and
can perform both training and inference efficiently, on-device, by only relying
on runtime signals extracted from the execution trace, without requiring any
resource-intensive operation.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16941" title="Abstract">arXiv:2311.16941</a> [<a href="/pdf/2311.16941" title="Download PDF">pdf</a>, <a href="/format/2311.16941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Debiasing Multimodal Models via Causal Information Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patil%2C+V">Vaidehi Patil</a>, 
<a href="/search/cs?searchtype=author&query=Maharana%2C+A">Adyasha Maharana</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+M">Mohit Bansal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 Findings (16 pages)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Methodology (stat.ME)

</div>
<p class="mathjax">Most existing debiasing methods for multimodal models, including causal
intervention and inference methods, utilize approximate heuristics to represent
the biases, such as shallow features from early stages of training or unimodal
features for multimodal tasks like VQA, etc., which may not be accurate. In
this paper, we study bias arising from confounders in a causal graph for
multimodal data and examine a novel approach that leverages causally-motivated
information minimization to learn the confounder representations. Robust
predictive features contain diverse information that helps a model generalize
to out-of-distribution data. Hence, minimizing the information content of
features obtained from a pretrained biased model helps learn the simplest
predictive features that capture the underlying data distribution. We treat
these features as confounder representations and use them via methods motivated
by causal theory to remove bias from models. We find that the learned
confounder representations indeed capture dataset biases, and the proposed
debiasing methods improve out-of-distribution (OOD) performance on multiple
multimodal datasets without sacrificing in-distribution performance.
Additionally, we introduce a novel metric to quantify the sufficiency of
spurious features in models' predictions that further demonstrates the
effectiveness of our proposed methods. Our code is available at:
https://github.com/Vaidehi99/CausalInfoMin
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16942" title="Abstract">arXiv:2311.16942</a> [<a href="/pdf/2311.16942" title="Download PDF">pdf</a>, <a href="/format/2311.16942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing state estimation for lithium-ion batteries with hysteresis:  systematic extended Kalman filter tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Knox%2C+J">Jasper Knox</a>, 
<a href="/search/eess?searchtype=author&query=Blyth%2C+M">Mark Blyth</a>, 
<a href="/search/eess?searchtype=author&query=Hales%2C+A">Alastair Hales</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 8 figures. Journal submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Knowledge of remaining battery charge is fundamental to electric vehicle
deployment. Accurate measurements of state-of-charge (SOC) cannot be directly
obtained, and estimation methods must be used instead. This requires both a
good model of a battery and a well-designed state estimator. Here, hysteretic
reduced-order battery models and adaptive extended Kalman filter estimators are
shown to be highly effective, accurate SOC estimators. A battery model
parameterisation framework is proposed, which enhances standardised methods to
capture hysteresis effects. The hysteretic model is parameterised for three
independent NMC811 lithium-ion cells and is shown to reduce voltage RMS error
by 50% across 18-hour automotive drive-cycles. Parameterised models are used
alongside an extended Kalman filter, which demonstrates the value of adaptive
filter parameterisation schemes. When used alongside an extended Kalman filter,
adaptive covariance matrices yield highly accurate SOC estimates, reducing SOC
estimation error by 85%, compared to the industry standard battery model.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16943" title="Abstract">arXiv:2311.16943</a> [<a href="/pdf/2311.16943" title="Download PDF">pdf</a>, <a href="/format/2311.16943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image segmentation with traveling waves in an exactly solvable recurrent  neural network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liboni%2C+L+H+B">Luisa H. B. Liboni</a>, 
<a href="/search/cs?searchtype=author&query=Budzinski%2C+R+C">Roberto C. Budzinski</a>, 
<a href="/search/cs?searchtype=author&query=Busch%2C+A+N">Alexandra N. Busch</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B6we%2C+S">Sindy L&#xf6;we</a>, 
<a href="/search/cs?searchtype=author&query=Keller%2C+T+A">Thomas A. Keller</a>, 
<a href="/search/cs?searchtype=author&query=Welling%2C+M">Max Welling</a>, 
<a href="/search/cs?searchtype=author&query=Muller%2C+L+E">Lyle E. Muller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">We study image segmentation using spatiotemporal dynamics in a recurrent
neural network where the state of each unit is given by a complex number. We
show that this network generates sophisticated spatiotemporal dynamics that can
effectively divide an image into groups according to a scene's structural
characteristics. Using an exact solution of the recurrent network's dynamics,
we present a precise description of the mechanism underlying object
segmentation in this network, providing a clear mathematical interpretation of
how the network performs this task. We then demonstrate a simple algorithm for
object segmentation that generalizes across inputs ranging from simple
geometric objects in grayscale images to natural images. Object segmentation
across all images is accomplished with one recurrent neural network that has a
single, fixed set of weights. This demonstrates the expressive potential of
recurrent neural networks when constructed using a mathematical approach that
brings together their structure, dynamics, and computation.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16944" title="Abstract">arXiv:2311.16944</a> [<a href="/pdf/2311.16944" title="Download PDF">pdf</a>, <a href="/ps/2311.16944" title="Download PostScript">ps</a>, <a href="/format/2311.16944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Teaching DevOps Security Education with Hands-on Labware: Automated  Detection of Security Weakness in Python
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akter%2C+M+S">Mst Shapna Akter</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez-Cardenas%2C+J">Juanjose Rodriguez-Cardenas</a>, 
<a href="/search/cs?searchtype=author&query=Shahriar%2C+H">Hossain Shahriar</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+A">Akond Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fan Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The field of DevOps security education necessitates innovative approaches to
effectively address the ever-evolving challenges of cybersecurity. In adopting
a student-centered ap-proach, there is the need for the design and development
of a comprehensive set of hands-on learning modules. In this paper, we
introduce hands-on learning modules that enable learners to be familiar with
identifying known security weaknesses, based on taint tracking to accurately
pinpoint vulnerable code. To cultivate an engaging and motivating learning
environment, our hands-on approach includes a pre-lab, hands-on and post lab
sections. They all provide introduction to specific DevOps topics and software
security problems at hand, followed by practicing with real world code examples
having security issues to detect them using tools. The initial evaluation
results from a number of courses across multiple schools show that the hands-on
modules are enhancing the interests among students on software security and
cybersecurity, while preparing them to address DevOps security vulnerabilities.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16945" title="Abstract">arXiv:2311.16945</a> [<a href="/pdf/2311.16945" title="Download PDF">pdf</a>, <a href="/format/2311.16945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UC-NeRF: Neural Radiance Field for Under-Calibrated multi-view cameras  in autonomous driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+K">Kai Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+X">Xiaoxiao Long</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+W">Wei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhiqiang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yuexin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kaixuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaozhi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuejin Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> See the project page for code, data: <a href="https://kcheng1021.github.io/ucnerf.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multi-camera setups find widespread use across various applications, such as
autonomous driving, as they greatly expand sensing capabilities. Despite the
fast development of Neural radiance field (NeRF) techniques and their wide
applications in both indoor and outdoor scenes, applying NeRF to multi-camera
systems remains very challenging. This is primarily due to the inherent
under-calibration issues in multi-camera setup, including inconsistent imaging
effects stemming from separately calibrated image signal processing units in
diverse cameras, and system errors arising from mechanical vibrations during
driving that affect relative camera poses. In this paper, we present UC-NeRF, a
novel method tailored for novel view synthesis in under-calibrated multi-view
camera systems. Firstly, we propose a layer-based color correction to rectify
the color inconsistency in different image regions. Second, we propose virtual
warping to generate more viewpoint-diverse but color-consistent virtual views
for color correction and 3D recovery. Finally, a spatiotemporally constrained
pose refinement is designed for more robust and accurate pose calibration in
multi-camera systems. Our method not only achieves state-of-the-art performance
of novel view synthesis in multi-camera setups, but also effectively
facilitates depth estimation in large-scale outdoor scenes with the synthesized
novel views.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16948" title="Abstract">arXiv:2311.16948</a> [<a href="/pdf/2311.16948" title="Download PDF">pdf</a>, <a href="/format/2311.16948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-end Reinforcement Learning for Time-Optimal Quadcopter Flight
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferede%2C+R">Robin Ferede</a>, 
<a href="/search/cs?searchtype=author&query=De+Wagter%2C+C">Christophe De Wagter</a>, 
<a href="/search/cs?searchtype=author&query=Izzo%2C+D">Dario Izzo</a>, 
<a href="/search/cs?searchtype=author&query=de+Croon%2C+G+C+H+E">Guido C.H.E. de Croon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Aggressive time-optimal control of quadcopters poses a significant challenge
in the field of robotics. The state-of-the-art approach leverages reinforcement
learning (RL) to train optimal neural policies. However, a critical hurdle is
the sim-to-real gap, often addressed by employing a robust inner loop
controller -an abstraction that, in theory, constrains the optimality of the
trained controller, necessitating margins to counter potential disturbances. In
contrast, our novel approach introduces high-speed quadcopter control using
end-to-end RL (E2E) that gives direct motor commands. To bridge the reality
gap, we incorporate a learned residual model and an adaptive method that can
compensate for modeling errors in thrust and moments. We compare our E2E
approach against a state-of-the-art network that commands thrust and body rates
to an INDI inner loop controller, both in simulated and real-world flight. E2E
showcases a significant 1.39-second advantage in simulation and a 0.17-second
edge in real-world testing, highlighting end-to-end reinforcement learning's
potential. The performance drop observed from simulation to reality shows
potential for further improvement, including refining strategies to address the
reality gap or exploring offline reinforcement learning with real flight data.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16953" title="Abstract">arXiv:2311.16953</a> [<a href="/pdf/2311.16953" title="Download PDF">pdf</a>, <a href="/format/2311.16953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local certification of geometric graph classes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Defrain%2C+O">Oscar Defrain</a>, 
<a href="/search/cs?searchtype=author&query=Esperet%2C+L">Louis Esperet</a>, 
<a href="/search/cs?searchtype=author&query=Lagoutte%2C+A">Aur&#xe9;lie Lagoutte</a>, 
<a href="/search/cs?searchtype=author&query=Morin%2C+P">Pat Morin</a>, 
<a href="/search/cs?searchtype=author&query=Raymond%2C+J">Jean-Florent Raymond</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">The goal of local certification is to locally convince the vertices of a
graph $G$ that $G$ satisfies a given property. A prover assigns short
certificates to the vertices of the graph, then the vertices are allowed to
check their certificates and the certificates of their neighbors, and based
only on this local view, they must decide whether $G$ satisfies the given
property. If the graph indeed satisfies the property, all vertices must accept
the instance, and otherwise at least one vertex must reject the instance (for
any possible assignment of certificates). The goal is to minimize to size of
the certificates.
<br />In this paper we study the local certification of geometric and topological
graph classes. While it is known that in $n$-vertex graphs, planarity can be
certified locally with certificates of size $O(\log n)$, we show that several
closely related graph classes require certificates of size $\Omega(n)$. This
includes penny graphs, unit-distance graphs, (induced) subgraphs of the square
grid, 1-planar graphs, and unit-square graphs. For unit-disk graphs we obtain a
lower bound of $\Omega(n^{1-\delta})$ for any $\delta&gt;0$ on the size of the
certificates. All our results are tight up to a $n^{o(1)}$ factor, and give the
first known examples of hereditary (and even monotone) graph classes for which
the certificates must have polynomial size. The lower bounds are obtained by
proving rigidity properties of the considered graphs, which might be of
independent interest.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16957" title="Abstract">arXiv:2311.16957</a> [<a href="/pdf/2311.16957" title="Download PDF">pdf</a>, <a href="/ps/2311.16957" title="Download PostScript">ps</a>, <a href="/format/2311.16957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Space-Efficient Data Structures for Polyominoes and Bar Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berg%2C+M">Magnus Berg</a>, 
<a href="/search/cs?searchtype=author&query=Kamali%2C+S">Shahin Kamali</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+K">Katherine Ling</a>, 
<a href="/search/cs?searchtype=author&query=Sigrist%2C+C">Cooper Sigrist</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We provide a compact data structure for representing polyominoes that
supports neighborhood and visibility queries. Neighborhood queries concern
reporting adjacent cells to a given cell, and visibility queries determine
whether a straight line can be drawn within the polyomino that connects two
specified cells. For an arbitrary small $\epsilon &gt;0$, our data structure can
encode a polyomino with $n$ cells in $(3+\epsilon)n + o(n)$ bits while
supporting all queries in constant time. The space complexity can be improved
to $3n+o(n)$, while supporting neighborhood queries in $\mathcal{O}(1)$ and
visibility queries in $\mathcal{O}(t(n))$ for any arbitrary $t(n) \in
\omega(1)$. Previous attempts at enumerating polyominoes have indicated that at
least $2.00091n - o(n)$ bits are required to differentiate between distinct
polyominoes, which shows our data structure is compact.
<br />In addition, we introduce a succinct data structure tailored for bar graphs,
a specific subclass of polyominoes resembling histograms. We demonstrate that a
bar graph comprising $n$ cells can be encoded using only $n + o(n)$ bits,
enabling constant-time query processing. Meanwhile, $n-1$ bits are necessary to
represent any bar graph, proving our data structure is succinct.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16958" title="Abstract">arXiv:2311.16958</a> [<a href="/pdf/2311.16958" title="Download PDF">pdf</a>, <a href="/ps/2311.16958" title="Download PostScript">ps</a>, <a href="/format/2311.16958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Simulations to Reality: Enhancing Multi-Robot Exploration for Urban  Search and Rescue
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kashyap%2C+G+S">Gautam Siddharth Kashyap</a>, 
<a href="/search/cs?searchtype=author&query=Mahajan%2C+D">Deepkashi Mahajan</a>, 
<a href="/search/cs?searchtype=author&query=Phukan%2C+O+C">Orchid Chetia Phukan</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Ankit Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Brownlee%2C+A+E+I">Alexander E.I. Brownlee</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jiechao Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">In this study, we present a novel hybrid algorithm, combining Levy Flight
(LF) and Particle Swarm Optimization (PSO) (LF-PSO), tailored for efficient
multi-robot exploration in unknown environments with limited communication and
no global positioning information. The research addresses the growing interest
in employing multiple autonomous robots for exploration tasks, particularly in
scenarios such as Urban Search and Rescue (USAR) operations. Multiple robots
offer advantages like increased task coverage, robustness, flexibility, and
scalability. However, existing approaches often make assumptions such as search
area, robot positioning, communication restrictions, and target information
that may not hold in real-world situations. The hybrid algorithm leverages LF,
known for its effectiveness in large space exploration with sparse targets, and
incorporates inter-robot repulsion as a social component through PSO. This
combination enhances area exploration efficiency. We redefine the local best
and global best positions to suit scenarios without continuous target
information. Experimental simulations in a controlled environment demonstrate
the algorithm's effectiveness, showcasing improved area coverage compared to
traditional methods. In the process of refining our approach and testing it in
complex, obstacle-rich environments, the presented work holds promise for
enhancing multi-robot exploration in scenarios with limited information and
communication capabilities.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16959" title="Abstract">arXiv:2311.16959</a> [<a href="/pdf/2311.16959" title="Download PDF">pdf</a>, <a href="/format/2311.16959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Principal-Agent Problem with Third Party: Information Design from Social  Planner&#x27;s Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shiyun Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhihua Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We study the principal-agent problem with a third party that we call social
planner, whose responsibility is to reconcile the conflicts of interest between
the two players and induce socially optimal outcome in terms of some given
social utility function. The social planner owns no contractual power but
manages to control the information flow between the principal and the agent. We
design a simple workflow with two stages for the social planner. In the first
stage, the problem is reformulated as an optimization problem whose solution is
the optimal utility profile. In the second stage, we investigate information
design and show that binary-signal information structure suffices to induce the
socially optimal outcome determined in the first stage. The result shows that
information plays a key role in social planning in the principal-agent model.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16961" title="Abstract">arXiv:2311.16961</a> [<a href="/pdf/2311.16961" title="Download PDF">pdf</a>, <a href="/format/2311.16961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HumanRef: Single Image to 3D Human Generation via Reference-Guided  Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jingbo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yanpei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+J">Jing Liao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Homepage: <a href="https://eckertzhang.github.io/HumanRef.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generating a 3D human model from a single reference image is challenging
because it requires inferring textures and geometries in invisible views while
maintaining consistency with the reference image. Previous methods utilizing 3D
generative models are limited by the availability of 3D training data.
Optimization-based methods that lift text-to-image diffusion models to 3D
generation often fail to preserve the texture details of the reference image,
resulting in inconsistent appearances in different views. In this paper, we
propose HumanRef, a 3D human generation framework from a single-view input. To
ensure the generated 3D model is photorealistic and consistent with the input
image, HumanRef introduces a novel method called reference-guided score
distillation sampling (Ref-SDS), which effectively incorporates image guidance
into the generation process. Furthermore, we introduce region-aware attention
to Ref-SDS, ensuring accurate correspondence between different body regions.
Experimental results demonstrate that HumanRef outperforms state-of-the-art
methods in generating 3D clothed humans with fine geometry, photorealistic
textures, and view-consistent appearances.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16965" title="Abstract">arXiv:2311.16965</a> [<a href="/pdf/2311.16965" title="Download PDF">pdf</a>, <a href="/ps/2311.16965" title="Download PostScript">ps</a>, <a href="/format/2311.16965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Natural Language Processing Through Transfer Learning: A Case Study on  Sentiment Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yadav%2C+A">Aman Yadav</a>, 
<a href="/search/cs?searchtype=author&query=Vichare%2C+A">Abhishek Vichare</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 1 table, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Artificial intelligence and machine learning have significantly bolstered the
technological world. This paper explores the potential of transfer learning in
natural language processing focusing mainly on sentiment analysis. The models
trained on the big data can also be used where data are scarce. The claim is
that, compared to training models from scratch, transfer learning, using
pre-trained BERT models, can increase sentiment classification accuracy. The
study adopts a sophisticated experimental design that uses the IMDb dataset of
sentimentally labelled movie reviews. Pre-processing includes tokenization and
encoding of text data, making it suitable for NLP models. The dataset is used
on a BERT based model, measuring its performance using accuracy. The result
comes out to be 100 per cent accurate. Although the complete accuracy could
appear impressive, it might be the result of overfitting or a lack of
generalization. Further analysis is required to ensure the model's ability to
handle diverse and unseen data. The findings underscore the effectiveness of
transfer learning in NLP, showcasing its potential to excel in sentiment
analysis tasks. However, the research calls for a cautious interpretation of
perfect accuracy and emphasizes the need for additional measures to validate
the model's generalization.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16973" title="Abstract">arXiv:2311.16973</a> [<a href="/pdf/2311.16973" title="Download PDF">pdf</a>, <a href="/format/2311.16973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DemoFusion: Democratising High-Resolution Image Generation With No $$$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+R">Ruoyi Du</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+D">Dongliang Chang</a>, 
<a href="/search/cs?searchtype=author&query=Hospedales%2C+T">Timothy Hospedales</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yi-Zhe Song</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhanyu Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">High-resolution image generation with Generative Artificial Intelligence
(GenAI) has immense potential but, due to the enormous capital investment
required for training, it is increasingly centralised to a few large
corporations, and hidden behind paywalls. This paper aims to democratise
high-resolution GenAI by advancing the frontier of high-resolution generation
while remaining accessible to a broad audience. We demonstrate that existing
Latent Diffusion Models (LDMs) possess untapped potential for higher-resolution
image generation. Our novel DemoFusion framework seamlessly extends open-source
GenAI models, employing Progressive Upscaling, Skip Residual, and Dilated
Sampling mechanisms to achieve higher-resolution image generation. The
progressive nature of DemoFusion requires more passes, but the intermediate
results can serve as "previews", facilitating rapid prompt iteration.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16974" title="Abstract">arXiv:2311.16974</a> [<a href="/pdf/2311.16974" title="Download PDF">pdf</a>, <a href="/format/2311.16974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COLE: A Hierarchical Generation Framework for Graphic Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+P">Peidong Jia</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zeyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yichao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xingru Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yuhui Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yinglin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Ji Li</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaodong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shanghang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+B">Baining Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report. Project page: <a href="https://graphic-design-generation.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Graphic design, which has been evolving since the 15th century, plays a
crucial role in advertising. The creation of high-quality designs demands
creativity, innovation, and lateral thinking. This intricate task involves
understanding the objective, crafting visual elements such as the background,
decoration, font, color, and shape, formulating diverse professional layouts,
and adhering to fundamental visual design principles. In this paper, we
introduce COLE, a hierarchical generation framework designed to comprehensively
address these challenges. This COLE system can transform a straightforward
intention prompt into a high-quality graphic design, while also supporting
flexible editing based on user input. Examples of such input might include
directives like ``design a poster for Hisaishi's concert.'' The key insight is
to dissect the complex task of text-to-design generation into a hierarchy of
simpler sub-tasks, each addressed by specialized models working
collaboratively. The results from these models are then consolidated to produce
a cohesive final output. Our hierarchical task decomposition can streamline the
complex process and significantly enhance generation reliability. Our COLE
system consists of multiple fine-tuned Large Language Models (LLMs), Large
Multimodal Models (LMMs), and Diffusion Models (DMs), each specifically
tailored for a design-aware text or image generation task. Furthermore, we
construct the DESIGNERINTENTION benchmark to highlight the superiority of our
COLE over existing methods in generating high-quality graphic designs from user
intent. We perceive our COLE as an important step towards addressing more
complex visual design generation tasks in the future.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16977" title="Abstract">arXiv:2311.16977</a> [<a href="/pdf/2311.16977" title="Download PDF">pdf</a>, <a href="/ps/2311.16977" title="Download PostScript">ps</a>, <a href="/format/2311.16977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bidirectional Reactive Programming for Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Butucaru%2C+D+P">Dumitru Potop Butucaru</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+A">Albert Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Plotkin%2C+G">Gordon Plotkin</a>, 
<a href="/search/cs?searchtype=author&query=Pompougnac%2C+H">Hugo Pompougnac</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Reactive languages are dedicated to the programming of systems which interact
continuously and concurrently with their environment. Values take the form of
unbounded streams modeling the (discrete) passing of time or the sequence of
concurrent interactions. While conventional reactivity models recurrences
forward in time, we introduce a symmetric reactive construct enabling backward
recurrences. Constraints on the latter allow to make the implementation
practical. Machine Learning (ML) systems provide numerous motivations for all
of this: we demonstrate that reverse-mode automatic differentiation,
backpropagation, batch normalization, bidirectional recurrent neural networks,
training and reinforcement learning algorithms, are all naturally captured as
bidirectional reactive programs.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16978" title="Abstract">arXiv:2311.16978</a> [<a href="/pdf/2311.16978" title="Download PDF">pdf</a>, <a href="/format/2311.16978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing the influence of attractor-verb distance on grammatical  agreement in humans and language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zacharopoulos%2C+C">Christos-Nikolaos Zacharopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Desbordes%2C+T">Th&#xe9;o Desbordes</a>, 
<a href="/search/cs?searchtype=author&query=Sabl%C3%A9-Meyer%2C+M">Mathias Sabl&#xe9;-Meyer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages (5 main, 2 refs, 3 supplementary) ; 5 figures (3 main, 2 supplementary) ; accepted at EMNLP 2023 (no DOI yet)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Subject-verb agreement in the presence of an attractor noun located between
the main noun and the verb elicits complex behavior: judgments of
grammaticality are modulated by the grammatical features of the attractor. For
example, in the sentence "The girl near the boys likes climbing", the attractor
(boys) disagrees in grammatical number with the verb (likes), creating a
locally implausible transition probability. Here, we parametrically modulate
the distance between the attractor and the verb while keeping the length of the
sentence equal. We evaluate the performance of both humans and two artificial
neural network models: both make more mistakes when the attractor is closer to
the verb, but neural networks get close to the chance level while humans are
mostly able to overcome the attractor interference. Additionally, we report a
linear effect of attractor distance on reaction times. We hypothesize that a
possible reason for the proximity effect is the calculation of transition
probabilities between adjacent words. Nevertheless, classical models of
attraction such as the cue-based model might suffice to explain this
phenomenon, thus paving the way for new research. Data and analyses available
at https://osf.io/d4g6k
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16989" title="Abstract">arXiv:2311.16989</a> [<a href="/pdf/2311.16989" title="Download PDF">pdf</a>, <a href="/format/2311.16989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatGPT&#x27;s One-year Anniversary: Are Open-Source Large Language Models  Catching up?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hailin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+F">Fangkai Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+C">Chengwei Qin</a>, 
<a href="/search/cs?searchtype=author&query=Ravaut%2C+M">Mathieu Ravaut</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Ruochen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+C">Caiming Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Joty%2C+S">Shafiq Joty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Upon its release in late 2022, ChatGPT has brought a seismic shift in the
entire landscape of AI, both in research and commerce. Through
instruction-tuning a large language model (LLM) with supervised fine-tuning and
reinforcement learning from human feedback, it showed that a model could answer
human questions and follow instructions on a broad panel of tasks. Following
this success, interests in LLMs have intensified, with new LLMs flourishing at
frequent interval across academia and industry, including many start-ups
focused on LLMs. While closed-source LLMs (e.g., OpenAI's GPT, Anthropic's
Claude) generally outperform their open-source counterparts, the progress on
the latter has been rapid with claims of achieving parity or even better on
certain tasks. This has crucial implications not only on research but also on
business. In this work, on the first anniversary of ChatGPT, we provide an
exhaustive overview of this success, surveying all tasks where an open-source
LLM has claimed to be on par or better than ChatGPT.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16992" title="Abstract">arXiv:2311.16992</a> [<a href="/pdf/2311.16992" title="Download PDF">pdf</a>, <a href="/ps/2311.16992" title="Download PostScript">ps</a>, <a href="/format/2311.16992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nested Integrals and Rationalizing Transformations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raab%2C+C+G">Clemens G. Raab</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> manuscript of 25 February 2021, in "Anti-Differentiation and the Calculation of Feynman Amplitudes", Springer
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Mathematical Physics (math-ph)

</div>
<p class="mathjax">A brief overview of some computer algebra methods for computations with
nested integrals is given. The focus is on nested integrals over integrands
involving square roots. Rewrite rules for conversion to and from associated
nested sums are discussed. We also include a short discussion comparing the
holonomic systems approach and the differential field approach. For
simplification to rational integrands, we give a comprehensive list of
univariate rationalizing transformations, including transformations tuned to
map the interval $[0,1]$ bijectively to itself.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16996" title="Abstract">arXiv:2311.16996</a> [<a href="/pdf/2311.16996" title="Download PDF">pdf</a>, <a href="/format/2311.16996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Goal-conditioned Offline Planning from Curious Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bagatella%2C+M">Marco Bagatella</a>, 
<a href="/search/cs?searchtype=author&query=Martius%2C+G">Georg Martius</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Curiosity has established itself as a powerful exploration strategy in deep
reinforcement learning. Notably, leveraging expected future novelty as
intrinsic motivation has been shown to efficiently generate exploratory
trajectories, as well as a robust dynamics model. We consider the challenge of
extracting goal-conditioned behavior from the products of such unsupervised
exploration techniques, without any additional environment interaction. We find
that conventional goal-conditioned reinforcement learning approaches for
extracting a value function and policy fall short in this difficult offline
setting. By analyzing the geometry of optimal goal-conditioned value functions,
we relate this issue to a specific class of estimation artifacts in learned
values. In order to mitigate their occurrence, we propose to combine
model-based planning over learned value landscapes with a graph-based value
aggregation scheme. We show how this combination can correct both local and
global artifacts, obtaining significant improvements in zero-shot goal-reaching
performance across diverse simulated environments.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17001" title="Abstract">arXiv:2311.17001</a> [<a href="/pdf/2311.17001" title="Download PDF">pdf</a>, <a href="/ps/2311.17001" title="Download PostScript">ps</a>, <a href="/format/2311.17001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Approximation Bounds for Small-Set Vertex Expansion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghoshal%2C+S">Suprovat Ghoshal</a>, 
<a href="/search/cs?searchtype=author&query=Louis%2C+A">Anand Louis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 55 Pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">The vertex expansion of the graph is a fundamental graph parameter. Given a
graph $G=(V,E)$ and a parameter $\delta \in (0,1/2]$, its $\delta$-Small-Set
Vertex Expansion (SSVE) is defined as \[ \min_{S : |S| = \delta |V|}
\frac{|{\partial^V(S)}|}{ \min \{ |S|, |S^c| \} } \] where $\partial^V(S)$ is
the vertex boundary of a set $S$. The SSVE~problem, in addition to being of
independent interest as a natural graph partitioning problem, is also of
interest due to its connections to the Strong Unique Games problem. We give a
randomized algorithm running in time $n^{{\sf poly}(1/\delta)}$, which outputs
a set $S$ of size $\Theta(\delta n)$, having vertex expansion at most \[
\max\left(O(\sqrt{\phi^* \log d \log (1/\delta)}) ,
\tilde{O}(d\log^2(1/\delta)) \cdot \phi^* \right), \] where $d$ is the largest
vertex degree of the graph, and $\phi^*$ is the optimal $\delta$-SSVE. The
previous best-known guarantees for this were the bi-criteria bounds of
$\tilde{O}(1/\delta)\sqrt{\phi^* \log d}$ and $\tilde{O}(1/\delta)\phi^*
\sqrt{\log n}$ due to Louis-Makarychev [TOC'16].
<br />Our algorithm uses the basic SDP relaxation of the problem augmented with
${\rm poly}(1/\delta)$ rounds of the Lasserre/SoS hierarchy. Our rounding
algorithm is a combination of the rounding algorithms of Raghavendra-Tan
[SODA'12] and Austrin-Benabbas-Georgiou [SODA'13]. A key component of our
analysis is novel Gaussian rounding lemma for hyperedges which might be of
independent interest.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17002" title="Abstract">arXiv:2311.17002</a> [<a href="/pdf/2311.17002" title="Download PDF">pdf</a>, <a href="/format/2311.17002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ranni: Taming Text-to-Image Diffusion for Accurate Instruction Following
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yutong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+B">Biao Gong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Di Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yujun Shen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingren Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing text-to-image (T2I) diffusion models usually struggle in
interpreting complex prompts, especially those with quantity, object-attribute
binding, and multi-subject descriptions. In this work, we introduce a semantic
panel as the middleware in decoding texts to images, supporting the generator
to better follow instructions. The panel is obtained through arranging the
visual concepts parsed from the input text by the aid of large language models,
and then injected into the denoising network as a detailed control signal to
complement the text condition. To facilitate text-to-panel learning, we come up
with a carefully designed semantic formatting protocol, accompanied by a
fully-automatic data preparation pipeline. Thanks to such a design, our
approach, which we call Ranni, manages to enhance a pre-trained T2I generator
regarding its textual controllability. More importantly, the introduction of
the generative middleware brings a more convenient form of interaction (i.e.,
directly adjusting the elements in the panel or using language instructions)
and further allows users to finely customize their generation, based on which
we develop a practical system and showcase its potential in continuous
generation and chatting-based editing.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17005" title="Abstract">arXiv:2311.17005</a> [<a href="/pdf/2311.17005" title="Download PDF">pdf</a>, <a href="/format/2311.17005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MVBench: A Comprehensive Multi-modal Video Understanding Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kunchang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yali Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yinan He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yizhuo Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jilan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Limin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 7 figures, 19 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the rapid development of Multi-modal Large Language Models (MLLMs), a
number of diagnostic benchmarks have recently emerged to evaluate the
comprehension capabilities of these models. However, most benchmarks
predominantly assess spatial understanding in the static image tasks, while
overlooking temporal understanding in the dynamic video tasks. To alleviate
this issue, we introduce a comprehensive Multi-modal Video understanding
Benchmark, namely MVBench, which covers 20 challenging video tasks that cannot
be effectively solved with a single frame. Specifically, we first introduce a
novel static-to-dynamic method to define these temporal-related tasks. By
transforming various static tasks into dynamic ones, we enable the systematic
generation of video tasks that require a broad spectrum of temporal skills,
ranging from perception to cognition. Then, guided by the task definition, we
automatically convert public video annotations into multiple-choice QA to
evaluate each task. On one hand, such a distinct paradigm allows us to build
MVBench efficiently, without much manual intervention. On the other hand, it
guarantees evaluation fairness with ground-truth video annotations, avoiding
the biased scoring of LLMs. Moreover, we further develop a robust video MLLM
baseline, i.e., VideoChat2, by progressive multi-modal training with diverse
instruction-tuning data. The extensive results on our MVBench reveal that, the
existing MLLMs are far from satisfactory in temporal understanding, while our
VideoChat2 largely surpasses these leading models by over 15% on MVBench. All
models and data are available at https://github.com/OpenGVLab/Ask-Anything.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17006" title="Abstract">arXiv:2311.17006</a> [<a href="/pdf/2311.17006" title="Download PDF">pdf</a>, <a href="/format/2311.17006" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Impact of Sampling on Deep Sequential State Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Calatrava%2C+H">Helena Calatrava</a>, 
<a href="/search/cs?searchtype=author&query=Borsoi%2C+R+A">Ricardo Augusto Borsoi</a>, 
<a href="/search/cs?searchtype=author&query=Imbiriba%2C+T">Tales Imbiriba</a>, 
<a href="/search/cs?searchtype=author&query=Closas%2C+P">Pau Closas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the Proceedings of the Asilomar Conference on Signals, Systems, and Computers, October 2023, 5 pages, 3 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">State inference and parameter learning in sequential models can be
successfully performed with approximation techniques that maximize the evidence
lower bound to the marginal log-likelihood of the data distribution. These
methods may be referred to as Dynamical Variational Autoencoders, and our
specific focus lies on the deep Kalman filter. It has been shown that the ELBO
objective can oversimplify data representations, potentially compromising
estimation quality. Tighter Monte Carlo objectives have been proposed in the
literature to enhance generative modeling performance. For instance, the IWAE
objective uses importance weights to reduce the variance of marginal
log-likelihood estimates. In this paper, importance sampling is applied to the
DKF framework for learning deep Markov models, resulting in the IW-DKF, which
shows an improvement in terms of log-likelihood estimates and KL divergence
between the variational distribution and the transition model. The framework
using the sampled DKF update rule is also accommodated to address sequential
state and parameter estimation when working with highly non-linear
physics-based models. An experiment with the 3-space Lorenz attractor shows an
enhanced generative modeling performance and also a decrease in RMSE when
estimating the model parameters and latent states, indicating that tighter MCOs
lead to improved state inference performance.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17007" title="Abstract">arXiv:2311.17007</a> [<a href="/pdf/2311.17007" title="Download PDF">pdf</a>, <a href="/format/2311.17007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computational Hypergraph Discovery, a Gaussian Process framework for  connecting the dots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bourdais%2C+T">Th&#xe9;o Bourdais</a>, 
<a href="/search/cs?searchtype=author&query=Batlle%2C+P">Pau Batlle</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xianjin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Baptista%2C+R">Ricardo Baptista</a>, 
<a href="/search/cs?searchtype=author&query=Rouquette%2C+N">Nicolas Rouquette</a>, 
<a href="/search/cs?searchtype=author&query=Owhadi%2C+H">Houman Owhadi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The code for the algorithm introduced in this paper and its application to various examples are available for download (and as as an installable python library/package) at <a href="https://github.com/TheoBourdais/ComputationalHypergraphDiscovery">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI); Numerical Analysis (math.NA); Machine Learning (stat.ML)

</div>
<p class="mathjax">Most scientific challenges can be framed into one of the following three
levels of complexity of function approximation. Type 1: Approximate an unknown
function given input/output data. Type 2: Consider a collection of variables
and functions, some of which are unknown, indexed by the nodes and hyperedges
of a hypergraph (a generalized graph where edges can connect more than two
vertices). Given partial observations of the variables of the hypergraph
(satisfying the functional dependencies imposed by its structure), approximate
all the unobserved variables and unknown functions. Type 3: Expanding on Type
2, if the hypergraph structure itself is unknown, use partial observations of
the variables of the hypergraph to discover its structure and approximate its
unknown functions. While most Computational Science and Engineering and
Scientific Machine Learning challenges can be framed as Type 1 and Type 2
problems, many scientific problems can only be categorized as Type 3. Despite
their prevalence, these Type 3 challenges have been largely overlooked due to
their inherent complexity. Although Gaussian Process (GP) methods are sometimes
perceived as well-founded but old technology limited to Type 1 curve fitting,
their scope has recently been expanded to Type 2 problems. In this paper, we
introduce an interpretable GP framework for Type 3 problems, targeting the
data-driven discovery and completion of computational hypergraphs. Our approach
is based on a kernel generalization of Row Echelon Form reduction from linear
systems to nonlinear ones and variance-based analysis. Here, variables are
linked via GPs and those contributing to the highest data variance unveil the
hypergraph's structure. We illustrate the scope and efficiency of the proposed
approach with applications to (algebraic) equation discovery, network discovery
(gene pathways, chemical, and mechanical) and raw data analysis.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17008" title="Abstract">arXiv:2311.17008</a> [<a href="/pdf/2311.17008" title="Download PDF">pdf</a>, <a href="/format/2311.17008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Investigation of Time Reversal Symmetry in Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barkley%2C+B">Brett Barkley</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Amy Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fridovich-Keil%2C+D">David Fridovich-Keil</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">One of the fundamental challenges associated with reinforcement learning (RL)
is that collecting sufficient data can be both time-consuming and expensive. In
this paper, we formalize a concept of time reversal symmetry in a Markov
decision process (MDP), which builds upon the established structure of
dynamically reversible Markov chains (DRMCs) and time-reversibility in
classical physics. Specifically, we investigate the utility of this concept in
reducing the sample complexity of reinforcement learning. We observe that
utilizing the structure of time reversal in an MDP allows every environment
transition experienced by an agent to be transformed into a feasible
reverse-time transition, effectively doubling the number of experiences in the
environment. To test the usefulness of this newly synthesized data, we develop
a novel approach called time symmetric data augmentation (TSDA) and investigate
its application in both proprioceptive and pixel-based state within the realm
of off-policy, model-free RL. Empirical evaluations showcase how these
synthetic transitions can enhance the sample efficiency of RL agents in time
reversible scenarios without friction or contact. We also test this method in
more realistic environments where these assumptions are not globally satisfied.
We find that TSDA can significantly degrade sample efficiency and policy
performance, but can also improve sample efficiency under the right conditions.
Ultimately we conclude that time symmetry shows promise in enhancing the sample
efficiency of reinforcement learning and provide guidance when the environment
and reward structures are of an appropriate form for TSDA to be employed
effectively.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17009" title="Abstract">arXiv:2311.17009</a> [<a href="/pdf/2311.17009" title="Download PDF">pdf</a>, <a href="/format/2311.17009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Space-Time Diffusion Features for Zero-Shot Text-Driven Motion Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yatim%2C+D">Danah Yatim</a>, 
<a href="/search/cs?searchtype=author&query=Fridman%2C+R">Rafail Fridman</a>, 
<a href="/search/cs?searchtype=author&query=Tal%2C+O+B">Omer Bar Tal</a>, 
<a href="/search/cs?searchtype=author&query=Kasten%2C+Y">Yoni Kasten</a>, 
<a href="/search/cs?searchtype=author&query=Dekel%2C+T">Tali Dekel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://diffusion-motion-transfer.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present a new method for text-driven motion transfer - synthesizing a
video that complies with an input text prompt describing the target objects and
scene while maintaining an input video's motion and scene layout. Prior methods
are confined to transferring motion across two subjects within the same or
closely related object categories and are applicable for limited domains (e.g.,
humans). In this work, we consider a significantly more challenging setting in
which the target and source objects differ drastically in shape and
fine-grained motion characteristics (e.g., translating a jumping dog into a
dolphin). To this end, we leverage a pre-trained and fixed text-to-video
diffusion model, which provides us with generative and motion priors. The
pillar of our method is a new space-time feature loss derived directly from the
model. This loss guides the generation process to preserve the overall motion
of the input video while complying with the target object in terms of shape and
fine-grained motion traits.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17010" title="Abstract">arXiv:2311.17010</a> [<a href="/pdf/2311.17010" title="Download PDF">pdf</a>, <a href="/ps/2311.17010" title="Download PostScript">ps</a>, <a href="/format/2311.17010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Node Connectivity Augmentation of Highly Connected Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Galvez%2C+W">Waldo Galvez</a>, 
<a href="/search/cs?searchtype=author&query=Hyatt-Denesik%2C+D">Dylan Hyatt-Denesik</a>, 
<a href="/search/cs?searchtype=author&query=Ameli%2C+A+J">Afrouz Jabal Ameli</a>, 
<a href="/search/cs?searchtype=author&query=Sanita%2C+L">Laura Sanita</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Node-connectivity augmentation is a fundamental network design problem. We
are given a $k$-node connected graph $G$ together with an additional set of
links, and the goal is to add a cheap subset of links to $G$ to make it
$(k+1)$-node connected.
<br />In this work, we characterize completely the computational complexity status
of the problem, by showing hardness for all values of $k$ which were not
addressed previously in the literature.
<br />We then focus on $k$-node connectivity augmentation for $k=n-4$, which
corresponds to the highest value of $k$ for which the problem is NP-hard. We
improve over the previously best known approximation bounds for this problem,
by developing a $\frac{3}{2}$-approximation algorithm for the weighted setting,
and a $\frac{4}{3}$-approximation algorithm for the unweighted setting.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17012" title="Abstract">arXiv:2311.17012</a> [<a href="/pdf/2311.17012" title="Download PDF">pdf</a>, <a href="/format/2311.17012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Counter-terrorism in cyber-physical spaces: Best practices and  technologies from the state of the art
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cascavilla%2C+G">Giuseppe Cascavilla</a>, 
<a href="/search/cs?searchtype=author&query=Tamburri%2C+D+A">Damian A. Tamburri</a>, 
<a href="/search/cs?searchtype=author&query=Leotta%2C+F">Francesco Leotta</a>, 
<a href="/search/cs?searchtype=author&query=Mecella%2C+M">Massimo Mecella</a>, 
<a href="/search/cs?searchtype=author&query=Van+Den+Heuvel%2C+W">WillemJan Van Den Heuvel</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Information and Software Technology, Volume 161, 2023, 107260,
  ISSN 0950-5849
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Cryptography and Security (cs.CR); Information Theory (cs.IT); Software Engineering (cs.SE)

</div>
<p class="mathjax">Context: The demand for protection and security of physical spaces and urban
areas increased with the escalation of terroristic attacks in recent years. We
envision with the proposed cyber-physical systems and spaces, a city that would
indeed become a smarter urbanistic object, proactively providing alerts and
being protective against any threat. Objectives: This survey intend to provide
a systematic multivocal literature survey comprised of an updated,
comprehensive and timely overview of state of the art in counter-terrorism
cyber-physical systems, hence aimed at the protection of cyber-physical spaces.
Hence, provide guidelines to law enforcement agencies and practitioners
providing a description of technologies and best practices for the protection
of public spaces. Methods: We analyzed 112 papers collected from different
online sources, both from the academic field and from websites and blogs
ranging from 2004 till mid-2022. Results: a) There is no one single
bullet-proof solution available for the protection of public spaces. b) From
our analysis we found three major active fields for the protection of public
spaces: Information Technologies, Architectural approaches, Organizational
field. c) While the academic suggest best practices and methodologies for the
protection of urban areas, the market did not provide any type of
implementation of such suggested approaches, which shows a lack of
fertilization between academia and industry. Conclusion: The overall analysis
has led us to state that there is no one single solution available, conversely,
multiple methods and techniques can be put in place to guarantee safety and
security in public spaces. The techniques range from architectural design to
rethink the design of public spaces keeping security into account in
continuity, to emerging technologies such as AI and predictive surveillance.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17017" title="Abstract">arXiv:2311.17017</a> [<a href="/pdf/2311.17017" title="Download PDF">pdf</a>, <a href="/format/2311.17017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Foundational Moral Values for AI Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+B+L">Betty Li Hou</a>, 
<a href="/search/cs?searchtype=author&query=Green%2C+B+P">Brian Patrick Green</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AI meets Moral Philosophy and Moral Psychology Workshop, 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Solving the AI alignment problem requires having clear, defensible values
towards which AI systems can align. Currently, targets for alignment remain
underspecified and do not seem to be built from a philosophically robust
structure. We begin the discussion of this problem by presenting five core,
foundational values, drawn from moral philosophy and built on the requisites
for human existence: survival, sustainable intergenerational existence,
society, education, and truth. We show that these values not only provide a
clearer direction for technical alignment work, but also serve as a framework
to highlight threats and opportunities from AI systems to both obtain and
sustain these values.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17019" title="Abstract">arXiv:2311.17019</a> [<a href="/pdf/2311.17019" title="Download PDF">pdf</a>, <a href="/format/2311.17019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Homogeneous Algebraic Complexity Theory and Algebraic Formulas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dutta%2C+P">Pranjal Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Gesmundo%2C+F">Fulvio Gesmundo</a>, 
<a href="/search/cs?searchtype=author&query=Ikenmeyer%2C+C">Christian Ikenmeyer</a>, 
<a href="/search/cs?searchtype=author&query=Jindal%2C+G">Gorav Jindal</a>, 
<a href="/search/cs?searchtype=author&query=Lysikov%2C+V">Vladimir Lysikov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is edited part of preprint <a href="/abs/2211.07055">arXiv:2211.07055</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Algebraic Geometry (math.AG)

</div>
<p class="mathjax">We study algebraic complexity classes and their complete polynomials under
\emph{homogeneous linear} projections, not just under the usual affine linear
projections that were originally introduced by Valiant in 1979. These
reductions are weaker yet more natural from a geometric complexity theory (GCT)
standpoint, because the corresponding orbit closure formulations do not require
the padding of polynomials. We give the \emph{first} complete polynomials for
VF, the class of sequences of polynomials that admit small algebraic formulas,
under homogeneous linear projections: The sum of the entries of the
non-commutative elementary symmetric polynomial in 3 by 3 matrices of
homogeneous linear forms.
<br />Even simpler variants of the elementary symmetric polynomial are hard for the
topological closure of a large subclass of VF: the sum of the entries of the
non-commutative elementary symmetric polynomial in 2 by 2 matrices of
homogeneous linear forms, and homogeneous variants of the continuant polynomial
(Bringmann, Ikenmeyer, Zuiddam, JACM '18). This requires a careful study of
circuits with arity-3 product gates.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17022" title="Abstract">arXiv:2311.17022</a> [<a href="/pdf/2311.17022" title="Download PDF">pdf</a>, <a href="/format/2311.17022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Message Recovery Attack in NTRU through VFK Lattices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Poimenidou%2C+E">Eirini Poimenidou</a>, 
<a href="/search/cs?searchtype=author&query=Adamoudis%2C+M">Marios Adamoudis</a>, 
<a href="/search/cs?searchtype=author&query=Draziotis%2C+K+A">Konstantinos A. Draziotis</a>, 
<a href="/search/cs?searchtype=author&query=Tsichlas%2C+K">Kostas Tsichlas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">In the present paper, we implement a message recovery attack to all variants
of the NTRU cryptosystem. Our approach involves a reduction from the
NTRU-lattice to a Voronoi First Kind lattice, enabling the application of a
polynomial CVP exact algorithm crucial for executing the Message Recovery. The
efficacy of our attack relies on a specific oracle that permits us to
approximate an unknown quantity. Furthermore, we outline the mathematical
conditions under which the attack is successful. Finally, we delve into a
well-established polynomial algorithm for CVP on VFK lattices and its
implementation, shedding light on its efficacy in our attack. Subsequently, we
present comprehensive experimental results on the NTRU-HPS and the NTRU-Prime
variants of the NIST submissions and propose a method that could indicate the
resistance of the NTRU cryptosystem to our attack.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17024" title="Abstract">arXiv:2311.17024</a> [<a href="/pdf/2311.17024" title="Download PDF">pdf</a>, <a href="/format/2311.17024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion 3D Features (Diff3F): Decorating Untextured Shapes with  Distilled Semantic Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dutt%2C+N+S">Niladri Shekhar Dutt</a>, 
<a href="/search/cs?searchtype=author&query=Muralikrishnan%2C+S">Sanjeev Muralikrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+N+J">Niloy J. Mitra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We present Diff3F as a simple, robust, and class-agnostic feature descriptor
that can be computed for untextured input shapes (meshes or point clouds). Our
method distills diffusion features from image foundational models onto input
shapes. Specifically, we use the input shapes to produce depth and normal maps
as guidance for conditional image synthesis, and in the process produce
(diffusion) features in 2D that we subsequently lift and aggregate on the
original surface. Our key observation is that even if the conditional image
generations obtained from multi-view rendering of the input shapes are
inconsistent, the associated image features are robust and can be directly
aggregated across views. This produces semantic features on the input shapes,
without requiring additional data or training. We perform extensive experiments
on multiple benchmarks (SHREC'19, SHREC'20, and TOSCA) and demonstrate that our
features, being semantic instead of geometric, produce reliable correspondence
across both isometeric and non-isometrically related shape families.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17026" title="Abstract">arXiv:2311.17026</a> [<a href="/pdf/2311.17026" title="Download PDF">pdf</a>, <a href="/format/2311.17026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When the Few Outweigh the Many: Illicit Content Recognition with  Few-Shot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cascavilla%2C+G">G. Cascavilla</a>, 
<a href="/search/cs?searchtype=author&query=Catolino%2C+G">G. Catolino</a>, 
<a href="/search/cs?searchtype=author&query=Conti%2C+M">M. Conti</a>, 
<a href="/search/cs?searchtype=author&query=Mellios%2C+D">D. Mellios</a>, 
<a href="/search/cs?searchtype=author&query=Tamburri%2C+D+A">D.A. Tamburri</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Proceedings of the 20th International Conference on Security
  and Cryptography - SECRYPT; 2023; ISBN 978-989-758-666-8; ISSN 2184-7711,
  pages 324-334
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">The anonymity and untraceability benefits of the Dark web account for the
exponentially-increased potential of its popularity while creating a suitable
womb for many illicit activities, to date. Hence, in collaboration with
cybersecurity and law enforcement agencies, research has provided approaches
for recognizing and classifying illicit activities with most exploiting textual
dark web markets' content recognition; few such approaches use images that
originated from dark web content. This paper investigates this alternative
technique for recognizing illegal activities from images. In particular, we
investigate label-agnostic learning techniques like One-Shot and Few-Shot
learning featuring the use Siamese neural networks, a state-of-the-art approach
in the field. Our solution manages to handle small-scale datasets with
promising accuracy. In particular, Siamese neural networks reach 90.9% on
20-Shot experiments over a 10-class dataset; this leads us to conclude that
such models are a promising and cheaper alternative to the definition of
automated law-enforcing machinery over the dark web.
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17030" title="Abstract">arXiv:2311.17030</a> [<a href="/pdf/2311.17030" title="Download PDF">pdf</a>, <a href="/format/2311.17030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is This the Subspace You Are Looking for? An Interpretability Illusion  for Subspace Activation Patching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Makelov%2C+A">Aleksandar Makelov</a>, 
<a href="/search/cs?searchtype=author&query=Lange%2C+G">Georg Lange</a>, 
<a href="/search/cs?searchtype=author&query=Nanda%2C+N">Neel Nanda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Workshop on Attributing Model Behavior at Scale
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Mechanistic interpretability aims to understand model behaviors in terms of
specific, interpretable features, often hypothesized to manifest as
low-dimensional subspaces of activations. Specifically, recent studies have
explored subspace interventions (such as activation patching) as a way to
simultaneously manipulate model behavior and attribute the features behind it
to given subspaces.
<br />In this work, we demonstrate that these two aims diverge, potentially leading
to an illusory sense of interpretability. Counterintuitively, even if a
subspace intervention makes the model's output behave as if the value of a
feature was changed, this effect may be achieved by activating a dormant
parallel pathway leveraging another subspace that is causally disconnected from
model outputs. We demonstrate this phenomenon in a distilled mathematical
example, in two real-world domains (the indirect object identification task and
factual recall), and present evidence for its prevalence in practice. In the
context of factual recall, we further show a link to rank-1 fact editing,
providing a mechanistic explanation for previous work observing an
inconsistency between fact editing performance and fact localization.
<br />However, this does not imply that activation patching of subspaces is
intrinsically unfit for interpretability. To contextualize our findings, we
also show what a success case looks like in a task (indirect object
identification) where prior manual circuit analysis informs an understanding of
the location of a feature. We explore the additional evidence needed to argue
that a patched subspace is faithful.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17032" title="Abstract">arXiv:2311.17032</a> [<a href="/pdf/2311.17032" title="Download PDF">pdf</a>, <a href="/format/2311.17032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stability estimates of Nystr&#xf6;m discretizations of Helmholtz  decomposition boundary integral equation formulations for the solution of  Navier scattering problems in two dimensions with Dirichlet boundary  conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dominguez%2C+V">Victor Dominguez</a>, 
<a href="/search/math?searchtype=author&query=Turc%2C+C">Catalin Turc</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Helmholtz decompositions of elastic fields is a common approach for the
solution of Navier scattering problems. Used in the context of Boundary
Integral Equations (BIE), this approach affords solutions of Navier problems
via the simpler Helmholtz boundary integral operators (BIOs). Approximations of
Helmholtz Dirichlet-to-Neumann (DtN) can be employed within a regularizing
combined field strategy to deliver BIE formulations of the second kind for the
solution of Navier scattering problems in two dimensions with Dirichlet
boundary conditions, at least in the case of smooth boundaries. Unlike the case
of scattering and transmission Helmholtz problems, the approximations of the
DtN maps we use in the Helmholtz decomposition BIE in the Navier case require
incorporation of lower order terms in their pseudodifferential asymptotic
expansions. The presence of these lower order terms in the Navier regularized
BIE formulations complicates the stability analysis of their Nystr\"om
discretizations in the framework of global trigonometric interpolation and the
Kussmaul-Martensen kernel singularity splitting strategy. The main difficulty
stems from compositions of pseudodifferential operators of opposite orders,
whose Nystr\"om discretization must be performed with care via
pseudodifferential expansions beyond the principal symbol. The error analysis
is significantly simpler in the case of arclength boundary parametrizations and
considerably more involved in the case of general smooth parametrizations which
are typically encountered in the description of one dimensional closed curves.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17034" title="Abstract">arXiv:2311.17034</a> [<a href="/pdf/2311.17034" title="Download PDF">pdf</a>, <a href="/format/2311.17034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Telling Left from Right: Identifying Geometry-Aware Semantic  Correspondence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Herrmann%2C+C">Charles Herrmann</a>, 
<a href="/search/cs?searchtype=author&query=Hur%2C+J">Junhwa Hur</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+E">Eric Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jampani%2C+V">Varun Jampani</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+D">Deqing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://telling-left-from-right.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">While pre-trained large-scale vision models have shown significant promise
for semantic correspondence, their features often struggle to grasp the
geometry and orientation of instances. This paper identifies the importance of
being geometry-aware for semantic correspondence and reveals a limitation of
the features of current foundation models under simple post-processing. We show
that incorporating this information can markedly enhance semantic
correspondence performance with simple but effective solutions in both
zero-shot and supervised settings. We also construct a new challenging
benchmark for semantic correspondence built from an existing animal pose
estimation dataset, for both pre-training validating models. Our method
achieves a PCK@0.10 score of 64.2 (zero-shot) and 85.6 (supervised) on the
challenging SPair-71k dataset, outperforming the state-of-the-art by 4.3p and
11.0p absolute gains, respectively. Our code and datasets will be publicly
available.
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17035" title="Abstract">arXiv:2311.17035</a> [<a href="/pdf/2311.17035" title="Download PDF">pdf</a>, <a href="/format/2311.17035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Extraction of Training Data from (Production) Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nasr%2C+M">Milad Nasr</a>, 
<a href="/search/cs?searchtype=author&query=Carlini%2C+N">Nicholas Carlini</a>, 
<a href="/search/cs?searchtype=author&query=Hayase%2C+J">Jonathan Hayase</a>, 
<a href="/search/cs?searchtype=author&query=Jagielski%2C+M">Matthew Jagielski</a>, 
<a href="/search/cs?searchtype=author&query=Cooper%2C+A+F">A. Feder Cooper</a>, 
<a href="/search/cs?searchtype=author&query=Ippolito%2C+D">Daphne Ippolito</a>, 
<a href="/search/cs?searchtype=author&query=Choquette-Choo%2C+C+A">Christopher A. Choquette-Choo</a>, 
<a href="/search/cs?searchtype=author&query=Wallace%2C+E">Eric Wallace</a>, 
<a href="/search/cs?searchtype=author&query=Tram%C3%A8r%2C+F">Florian Tram&#xe8;r</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Katherine Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">This paper studies extractable memorization: training data that an adversary
can efficiently extract by querying a machine learning model without prior
knowledge of the training dataset. We show an adversary can extract gigabytes
of training data from open-source language models like Pythia or GPT-Neo,
semi-open models like LLaMA or Falcon, and closed models like ChatGPT. Existing
techniques from the literature suffice to attack unaligned models; in order to
attack the aligned ChatGPT, we develop a new divergence attack that causes the
model to diverge from its chatbot-style generations and emit training data at a
rate 150x higher than when behaving properly. Our methods show practical
attacks can recover far more data than previously thought, and reveal that
current alignment techniques do not eliminate memorization.
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17037" title="Abstract">arXiv:2311.17037</a> [<a href="/pdf/2311.17037" title="Download PDF">pdf</a>, <a href="/format/2311.17037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concurrent Stochastic Lossy Channel Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stan%2C+D">Daniel Stan</a>, 
<a href="/search/cs?searchtype=author&query=Najib%2C+M">Muhammad Najib</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+A+W">Anthony Widjaja Lin</a>, 
<a href="/search/cs?searchtype=author&query=Abdulla%2C+P+A">Parosh Aziz Abdulla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at CSL 2024. Extended version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
<p class="mathjax">Concurrent stochastic games are an important formalism for the rational
verification of probabilistic multi-agent systems, which involves verifying
whether a temporal logic property is satisfied in some or all game-theoretic
equilibria of such systems. In this work, we study the rational verification of
probabilistic multi-agent systems where agents can cooperate by communicating
over unbounded lossy channels. To model such systems, we present concurrent
stochastic lossy channel games (CSLCG) and employ an equilibrium concept from
cooperative game theory known as the core, which is the most fundamental and
widely studied cooperative equilibrium concept. Our main contribution is
twofold. First, we show that the rational verification problem is undecidable
for systems whose agents have almost-sure LTL objectives. Second, we provide a
decidable fragment of such a class of objectives that subsumes almost-sure
reachability and safety. Our techniques involve reductions to solving
infinite-state zero-sum games with conjunctions of qualitative objectives. To
the best of our knowledge, our result represents the first decidability result
on the rational verification of stochastic multi-agent systems on infinite
arenas.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17038" title="Abstract">arXiv:2311.17038</a> [<a href="/pdf/2311.17038" title="Download PDF">pdf</a>, <a href="/ps/2311.17038" title="Download PostScript">ps</a>, <a href="/format/2311.17038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extension of Minimax for Algorithmic Lower Bounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hartline%2C+J">Jason Hartline</a>, 
<a href="/search/cs?searchtype=author&query=Johnsen%2C+A">Aleck Johnsen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">This paper considers the use of Yao's Minimax Theorem in robust algorithm
design, e.g., for online algorithms, where the algorithm designer aims to
minimize the ratio of the algorithm's performance to the optimal performance.
When applying Minimax, the objective becomes the expectation of these ratios.
The main result of the paper is that it is equally valid for the objective
(after applying Minimax) to be the ratio of the expectations.
</p>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17040" title="Abstract">arXiv:2311.17040</a> [<a href="/pdf/2311.17040" title="Download PDF">pdf</a>, <a href="/ps/2311.17040" title="Download PostScript">ps</a>, <a href="/format/2311.17040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rumors with Changing Credibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Out%2C+C">Charlotte Out</a>, 
<a href="/search/cs?searchtype=author&query=Rivera%2C+N">Nicol&#xe1;s Rivera</a>, 
<a href="/search/cs?searchtype=author&query=Sauerwald%2C+T">Thomas Sauerwald</a>, 
<a href="/search/cs?searchtype=author&query=Sylvester%2C+J">John Sylvester</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 53 pages, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Combinatorics (math.CO); Probability (math.PR)

</div>
<p class="mathjax">Randomized rumor spreading processes diffuse information on an undirected
graph and have been widely studied. In this work, we present a generic
framework for analyzing a broad class of such processes on regular graphs. Our
analysis is protocol-agnostic, as it only requires the expected proportion of
newly informed vertices in each round to be bounded, and a natural negative
correlation property.
<br />This framework allows us to analyze various protocols, including PUSH, PULL,
and PUSH-PULL, thereby extending prior research. Unlike previous work, our
framework accommodates message failures at any time $t\geq 0$ with a
probability of $1-q(t)$, where the credibility $q(t)$ is any function of time.
This enables us to model real-world scenarios in which the transmissibility of
rumors may fluctuate, as seen in the spread of ``fake news'' and viruses.
Additionally, our framework is sufficiently broad to cover dynamic graphs.
</p>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17041" title="Abstract">arXiv:2311.17041</a> [<a href="/pdf/2311.17041" title="Download PDF">pdf</a>, <a href="/format/2311.17041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient In-Context Learning in Vision-Language Models for Egocentric  Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+K+P">Keunwoo Peter Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+F">Fengyuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+J">Joyce Chai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Recent advancements in text-only large language models (LLMs) have
highlighted the benefit of in-context learning for adapting to new tasks with a
few demonstrations. However, extending in-context learning to large
vision-language models (VLMs) using a huge amount of naturalistic
vision-language data has shown limited success, particularly for egocentric
videos, due to high data collection costs. We propose a novel training method
$\mathbb{E}$fficient $\mathbb{I}$n-context $\mathbb{L}$earning on
$\mathbb{E}$gocentric $\mathbb{V}$ideos ($\mathbb{EILEV}$), which elicits
in-context learning in VLMs for egocentric videos without requiring massive,
naturalistic egocentric video datasets. $\mathbb{EILEV}$ involves architectural
and training data adaptations to allow the model to process contexts
interleaved with video clips and narrations, sampling of in-context examples
with clusters of similar verbs and nouns, use of data with skewed marginal
distributions with a long tail of infrequent verbs and nouns, as well as
homonyms and synonyms. Our evaluations show that $\mathbb{EILEV}$-trained
models outperform larger VLMs trained on a huge amount of naturalistic data in
in-context learning. Furthermore, they can generalize to not only
out-of-distribution, but also novel, rare egocentric videos and texts via
in-context learning, demonstrating potential for applications requiring
cost-effective training, and rapid post-deployment adaptability. Our code and
demo are available at \url{https://github.com/yukw777/EILEV}.
</p>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17042" title="Abstract">arXiv:2311.17042</a> [<a href="/pdf/2311.17042" title="Download PDF">pdf</a>, <a href="/format/2311.17042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Diffusion Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sauer%2C+A">Axel Sauer</a>, 
<a href="/search/cs?searchtype=author&query=Lorenz%2C+D">Dominik Lorenz</a>, 
<a href="/search/cs?searchtype=author&query=Blattmann%2C+A">Andreas Blattmann</a>, 
<a href="/search/cs?searchtype=author&query=Rombach%2C+R">Robin Rombach</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce Adversarial Diffusion Distillation (ADD), a novel training
approach that efficiently samples large-scale foundational image diffusion
models in just 1-4 steps while maintaining high image quality. We use score
distillation to leverage large-scale off-the-shelf image diffusion models as a
teacher signal in combination with an adversarial loss to ensure high image
fidelity even in the low-step regime of one or two sampling steps. Our analyses
show that our model clearly outperforms existing few-step methods (GANs, Latent
Consistency Models) in a single step and reaches the performance of
state-of-the-art diffusion models (SDXL) in only four steps. ADD is the first
method to unlock single-step, real-time image synthesis with foundation models.
Code and weights available under
https://github.com/Stability-AI/generative-models and
https://huggingface.co/stabilityai/ .
</p>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17043" title="Abstract">arXiv:2311.17043</a> [<a href="/pdf/2311.17043" title="Download PDF">pdf</a>, <a href="/format/2311.17043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLaMA-VID: An Image is Worth 2 Tokens in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengyao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jiaya Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is available at <a href="https://github.com/dvlab-research/LLaMA-VID">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">In this work, we present a novel method to tackle the token generation
challenge in Vision Language Models (VLMs) for video and image understanding,
called LLaMA-VID. Current VLMs, while proficient in tasks like image captioning
and visual question answering, face computational burdens when processing long
videos due to the excessive visual tokens. LLaMA-VID addresses this issue by
representing each frame with two distinct tokens, namely context token and
content token. The context token encodes the overall image context based on
user input, whereas the content token encapsulates visual cues in each frame.
This dual-token strategy significantly reduces the overload of long videos
while preserving critical information. Generally, LLaMA-VID empowers existing
frameworks to support hour-long videos and pushes their upper limit with an
extra context token. It is proved to surpass previous methods on most of video-
or image-based benchmarks. Code is available
https://github.com/dvlab-research/LLaMA-VID}{https://github.com/dvlab-research/LLaMA-VID
</p>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17048" title="Abstract">arXiv:2311.17048</a> [<a href="/pdf/2311.17048" title="Download PDF">pdf</a>, <a href="/format/2311.17048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-shot Referring Expression Comprehension via Structural Similarity  Between Images and Captions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zeyu Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Fangrui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lao%2C+Q">Qianru Lao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Huaizu Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Zero-shot referring expression comprehension aims at localizing bounding
boxes in an image corresponding to the provided textual prompts, which
requires: (i) a fine-grained disentanglement of complex visual scene and
textual context, and (ii) a capacity to understand relationships among
disentangled entities. Unfortunately, existing large vision-language alignment
(VLA) models, e.g., CLIP, struggle with both aspects so cannot be directly used
for this task. To mitigate this gap, we leverage large foundation models to
disentangle both images and texts into triplets in the format of (subject,
predicate, object). After that, grounding is accomplished by calculating the
structural similarity matrix between visual and textual triplets with a VLA
model, and subsequently propagate it to an instance-level similarity matrix.
Furthermore, to equip VLA models with the ability of relationship
understanding, we design a triplet-matching objective to fine-tune the VLA
models on a collection of curated dataset containing abundant entity
relationships. Experiments demonstrate that our visual grounding performance
increase of up to 19.5% over the SOTA zero-shot model on RefCOCO/+/g. On the
more challenging Who's Waldo dataset, our zero-shot approach achieves
comparable accuracy to the fully supervised model.
</p>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17049" title="Abstract">arXiv:2311.17049</a> [<a href="/pdf/2311.17049" title="Download PDF">pdf</a>, <a href="/format/2311.17049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MobileCLIP: Fast Image-Text Models through Multi-Modal Reinforced  Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vasu%2C+P+K+A">Pavan Kumar Anasosalu Vasu</a>, 
<a href="/search/cs?searchtype=author&query=Pouransari%2C+H">Hadi Pouransari</a>, 
<a href="/search/cs?searchtype=author&query=Faghri%2C+F">Fartash Faghri</a>, 
<a href="/search/cs?searchtype=author&query=Vemulapalli%2C+R">Raviteja Vemulapalli</a>, 
<a href="/search/cs?searchtype=author&query=Tuzel%2C+O">Oncel Tuzel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Contrastive pretraining of image-text foundation models, such as CLIP,
demonstrated excellent zero-shot performance and improved robustness on a wide
range of downstream tasks. However, these models utilize large
transformer-based encoders with significant memory and latency overhead which
pose challenges for deployment on mobile devices. In this work, we introduce
MobileCLIP -- a new family of efficient image-text models optimized for runtime
performance along with a novel and efficient training approach, namely
multi-modal reinforced training. The proposed training approach leverages
knowledge transfer from an image captioning model and an ensemble of strong
CLIP encoders to improve the accuracy of efficient models. Our approach avoids
train-time compute overhead by storing the additional knowledge in a reinforced
dataset. MobileCLIP sets a new state-of-the-art latency-accuracy tradeoff for
zero-shot classification and retrieval tasks on several datasets. Our
MobileCLIP-S2 variant is 2.3$\times$ faster while more accurate compared to
previous best CLIP model based on ViT-B/16. We further demonstrate the
effectiveness of our multi-modal reinforced training by training a CLIP model
based on ViT-B/16 image backbone and achieving +2.9% average performance
improvement on 38 evaluation benchmarks compared to the previous best.
Moreover, we show that the proposed approach achieves 10$\times$-1000$\times$
improved learning efficiency when compared with non-reinforced CLIP training.
</p>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17050" title="Abstract">arXiv:2311.17050</a> [<a href="/pdf/2311.17050" title="Download PDF">pdf</a>, <a href="/format/2311.17050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Surf-D: High-Quality Surface Generation for Arbitrary Topologies using  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhengming Yu</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Z">Zhiyang Dou</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+X">Xiaoxiao Long</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Cheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zekun Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+N">Norman M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Komura%2C+T">Taku Komura</a>, 
<a href="/search/cs?searchtype=author&query=Habermann%2C+M">Marc Habermann</a>, 
<a href="/search/cs?searchtype=author&query=Theobalt%2C+C">Christian Theobalt</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenping Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://yzmblog.github.io/projects/SurfD/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">In this paper, we present Surf-D, a novel method for generating high-quality
3D shapes as Surfaces with arbitrary topologies using Diffusion models.
Specifically, we adopt Unsigned Distance Field (UDF) as the surface
representation, as it excels in handling arbitrary topologies, enabling the
generation of complex shapes. While the prior methods explored shape generation
with different representations, they suffer from limited topologies and
geometry details. Moreover, it's non-trivial to directly extend prior diffusion
models to UDF because they lack spatial continuity due to the discrete volume
structure. However, UDF requires accurate gradients for mesh extraction and
learning. To tackle the issues, we first leverage a point-based auto-encoder to
learn a compact latent space, which supports gradient querying for any input
point through differentiation to effectively capture intricate geometry at a
high resolution. Since the learning difficulty for various shapes can differ, a
curriculum learning strategy is employed to efficiently embed various surfaces,
enhancing the whole embedding process. With pretrained shape latent space, we
employ a latent diffusion model to acquire the distribution of various shapes.
Our approach demonstrates superior performance in shape generation across
multiple modalities and conducts extensive experiments in unconditional
generation, category conditional generation, 3D reconstruction from images, and
text-to-shape tasks.
</p>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17053" title="Abstract">arXiv:2311.17053</a> [<a href="/pdf/2311.17053" title="Download PDF">pdf</a>, <a href="/format/2311.17053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffuseBot: Breeding Soft Robots With Physics-Augmented Generative  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tsun-Hsuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Juntian Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+P">Pingchuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yilun Du</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+B">Byungchul Kim</a>, 
<a href="/search/cs?searchtype=author&query=Spielberg%2C+A">Andrew Spielberg</a>, 
<a href="/search/cs?searchtype=author&query=Tenenbaum%2C+J">Joshua Tenenbaum</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+C">Chuang Gan</a>, 
<a href="/search/cs?searchtype=author&query=Rus%2C+D">Daniela Rus</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023. Project page: <a href="https://diffusebot.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Nature evolves creatures with a high complexity of morphological and
behavioral intelligence, meanwhile computational methods lag in approaching
that diversity and efficacy. Co-optimization of artificial creatures'
morphology and control in silico shows promise for applications in physical
soft robotics and virtual character creation; such approaches, however, require
developing new learning algorithms that can reason about function atop pure
structure. In this paper, we present DiffuseBot, a physics-augmented diffusion
model that generates soft robot morphologies capable of excelling in a wide
spectrum of tasks. DiffuseBot bridges the gap between virtually generated
content and physical utility by (i) augmenting the diffusion process with a
physical dynamical simulation which provides a certificate of performance, and
(ii) introducing a co-design procedure that jointly optimizes physical design
and control by leveraging information about physical sensitivities from
differentiable simulation. We showcase a range of simulated and fabricated
robots along with their capabilities. Check our website at
https://diffusebot.github.io/
</p>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17055" title="Abstract">arXiv:2311.17055</a> [<a href="/pdf/2311.17055" title="Download PDF">pdf</a>, <a href="/format/2311.17055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> No Representation Rules Them All in Category Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vaze%2C+S">Sagar Vaze</a>, 
<a href="/search/cs?searchtype=author&query=Vedaldi%2C+A">Andrea Vedaldi</a>, 
<a href="/search/cs?searchtype=author&query=Zisserman%2C+A">Andrew Zisserman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper we tackle the problem of Generalized Category Discovery (GCD).
Specifically, given a dataset with labelled and unlabelled images, the task is
to cluster all images in the unlabelled subset, whether or not they belong to
the labelled categories. Our first contribution is to recognize that most
existing GCD benchmarks only contain labels for a single clustering of the
data, making it difficult to ascertain whether models are using the available
labels to solve the GCD task, or simply solving an unsupervised clustering
problem. As such, we present a synthetic dataset, named 'Clevr-4', for category
discovery. Clevr-4 contains four equally valid partitions of the data, i.e
based on object shape, texture, color or count. To solve the task, models are
required to extrapolate the taxonomy specified by the labelled set, rather than
simply latching onto a single natural grouping of the data. We use this dataset
to demonstrate the limitations of unsupervised clustering in the GCD setting,
showing that even very strong unsupervised models fail on Clevr-4. We further
use Clevr-4 to examine the weaknesses of existing GCD algorithms, and propose a
new method which addresses these shortcomings, leveraging consistent findings
from the representation learning literature to do so. Our simple solution,
which is based on 'mean teachers' and termed $\mu$GCD, substantially
outperforms implemented baselines on Clevr-4. Finally, when we transfer these
findings to real data on the challenging Semantic Shift Benchmark (SSB), we
find that $\mu$GCD outperforms all prior work, setting a new state-of-the-art.
For the project webpage, see https://www.robots.ox.ac.uk/~vgg/data/clevr4/
</p>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17056" title="Abstract">arXiv:2311.17056</a> [<a href="/pdf/2311.17056" title="Download PDF">pdf</a>, <a href="/format/2311.17056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Motion Magnification by Backpropagating Through Optical  Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zhaoying Pan</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+D">Daniel Geng</a>, 
<a href="/search/cs?searchtype=author&query=Owens%2C+A">Andrew Owens</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Thirty-seventh Conference on Neural Information Processing Systems
  (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents a simple, self-supervised method for magnifying subtle
motions in video: given an input video and a magnification factor, we
manipulate the video such that its new optical flow is scaled by the desired
amount. To train our model, we propose a loss function that estimates the
optical flow of the generated video and penalizes how far if deviates from the
given magnification factor. Thus, training involves differentiating through a
pretrained optical flow network. Since our model is self-supervised, we can
further improve its performance through test-time adaptation, by finetuning it
on the input video. It can also be easily extended to magnify the motions of
only user-selected objects. Our approach avoids the need for synthetic
magnification datasets that have been used to train prior learning-based
approaches. Instead, it leverages the existing capabilities of off-the-shelf
motion estimators. We demonstrate the effectiveness of our method through
evaluations of both visual quality and quantitative metrics on a range of
real-world and synthetic videos, and we show our method works for both
supervised and unsupervised optical flow methods.
</p>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17057" title="Abstract">arXiv:2311.17057</a> [<a href="/pdf/2311.17057" title="Download PDF">pdf</a>, <a href="/format/2311.17057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReMoS: Reactive 3D Motion Synthesis for Two-Person Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+A">Anindita Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Dabral%2C+R">Rishabh Dabral</a>, 
<a href="/search/cs?searchtype=author&query=Golyanik%2C+V">Vladislav Golyanik</a>, 
<a href="/search/cs?searchtype=author&query=Theobalt%2C+C">Christian Theobalt</a>, 
<a href="/search/cs?searchtype=author&query=Slusallek%2C+P">Philipp Slusallek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Current approaches for 3D human motion synthesis can generate high-quality 3D
animations of digital humans performing a wide variety of actions and gestures.
However, there is still a notable technological gap in addressing the complex
dynamics of multi-human interactions within this paradigm. In this work, we
introduce ReMoS, a denoising diffusion-based probabilistic model for reactive
motion synthesis that explores two-person interactions. Given the motion of one
person, we synthesize the reactive motion of the second person to complete the
interactions between the two. In addition to synthesizing the full-body
motions, we also synthesize plausible hand interactions. We show the
performance of ReMoS under a wide range of challenging two-person scenarios
including pair-dancing, Ninjutsu, kickboxing, and acrobatics, where one
person's movements have complex and diverse influences on the motions of the
other. We further propose the ReMoCap dataset for two-person interactions
consisting of full-body and hand motions. We evaluate our approach through
multiple quantitative metrics, qualitative visualizations, and a user study.
Our results are usable in interactive applications while also providing an
adequate amount of control for animators.
</p>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17058" title="Abstract">arXiv:2311.17058</a> [<a href="/pdf/2311.17058" title="Download PDF">pdf</a>, <a href="/format/2311.17058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Panoptic Video Scene Graph Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jingkang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Wenxuan Peng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangtai Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zujin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liangyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zheng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kaiyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wayne Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Loy%2C+C+C">Chen Change Loy</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR 2023. Project Page: <a href="https://jingkang50.github.io/PVSG/.">this https URL</a> Codebase: <a href="https://github.com/LilyDaytoy/OpenPVSG.">this https URL</a> We provide 400 long videos with frame-level panoptic segmentation, scene graph, dense captions, and QA annotations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Towards building comprehensive real-world visual perception systems, we
propose and study a new problem called panoptic scene graph generation (PVSG).
PVSG relates to the existing video scene graph generation (VidSGG) problem,
which focuses on temporal interactions between humans and objects grounded with
bounding boxes in videos. However, the limitation of bounding boxes in
detecting non-rigid objects and backgrounds often causes VidSGG to miss key
details crucial for comprehensive video understanding. In contrast, PVSG
requires nodes in scene graphs to be grounded by more precise, pixel-level
segmentation masks, which facilitate holistic scene understanding. To advance
research in this new area, we contribute the PVSG dataset, which consists of
400 videos (289 third-person + 111 egocentric videos) with a total of 150K
frames labeled with panoptic segmentation masks as well as fine, temporal scene
graphs. We also provide a variety of baseline methods and share useful design
practices for future work.
</p>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17059" title="Abstract">arXiv:2311.17059</a> [<a href="/pdf/2311.17059" title="Download PDF">pdf</a>, <a href="/format/2311.17059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mission-driven Exploration for Accelerated Deep Reinforcement Learning  with Temporal Logic Task Specifications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hasanbeig%2C+H">Hosein Hasanbeig</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+K">Kaiyuan Tan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zihe Sun</a>, 
<a href="/search/cs?searchtype=author&query=Kantaros%2C+Y">Yiannis Kantaros</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper addresses the problem of designing optimal control policies for
mobile robots with mission and safety requirements specified using Linear
Temporal Logic (LTL). We consider robots with unknown stochastic dynamics
operating in environments with unknown geometric structure. The robots are
equipped with sensors allowing them to detect obstacles. Our goal is to
synthesize a control policy that maximizes the probability of satisfying an
LTL-encoded task in the presence of motion and environmental uncertainty.
Several deep reinforcement learning (DRL) algorithms have been proposed
recently to address similar problems. A common limitation in related works is
that of slow learning performance. In order to address this issue, we propose a
novel DRL algorithm, which has the capability to learn control policies at a
notably faster rate compared to similar methods. Its sample efficiency is due
to a mission-driven exploration strategy that prioritizes exploration towards
directions that may contribute to mission accomplishment. Identifying these
directions relies on an automaton representation of the LTL task as well as a
learned neural network that (partially) models the unknown system dynamics. We
provide comparative experiments demonstrating the efficiency of our algorithm
on robot navigation tasks in unknown environments.
</p>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17060" title="Abstract">arXiv:2311.17060</a> [<a href="/pdf/2311.17060" title="Download PDF">pdf</a>, <a href="/format/2311.17060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Material Palette: Extraction of Materials from a Single Image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lopes%2C+I">Ivan Lopes</a>, 
<a href="/search/cs?searchtype=author&query=Pizzati%2C+F">Fabio Pizzati</a>, 
<a href="/search/cs?searchtype=author&query=de+Charette%2C+R">Raoul de Charette</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 11 figures, 2 tables. Webpage <a href="https://astra-vision.github.io/MaterialPalette/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">In this paper, we propose a method to extract physically-based rendering
(PBR) materials from a single real-world image. We do so in two steps: first,
we map regions of the image to material concepts using a diffusion model, which
allows the sampling of texture images resembling each material in the scene.
Second, we benefit from a separate network to decompose the generated textures
into Spatially Varying BRDFs (SVBRDFs), providing us with materials ready to be
used in rendering applications. Our approach builds on existing synthetic
material libraries with SVBRDF ground truth, but also exploits a
diffusion-generated RGB texture dataset to allow generalization to new samples
using unsupervised domain adaptation (UDA). Our contributions are thoroughly
evaluated on synthetic and real-world datasets. We further demonstrate the
applicability of our method for editing 3D scenes with materials estimated from
real photographs. The code and models will be made open-source. Project page:
https://astra-vision.github.io/MaterialPalette/
</p>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17061" title="Abstract">arXiv:2311.17061</a> [<a href="/pdf/2311.17061" title="Download PDF">pdf</a>, <a href="/format/2311.17061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HumanGaussian: Text-Driven 3D Human Generation with Gaussian Splatting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+X">Xiaohang Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiaxiang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+G">Gang Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xihui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://alvinliu0.github.io/projects/HumanGaussian">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Realistic 3D human generation from text prompts is a desirable yet
challenging task. Existing methods optimize 3D representations like mesh or
neural fields via score distillation sampling (SDS), which suffers from
inadequate fine details or excessive training time. In this paper, we propose
an efficient yet effective framework, HumanGaussian, that generates
high-quality 3D humans with fine-grained geometry and realistic appearance. Our
key insight is that 3D Gaussian Splatting is an efficient renderer with
periodic Gaussian shrinkage or growing, where such adaptive density control can
be naturally guided by intrinsic human structures. Specifically, 1) we first
propose a Structure-Aware SDS that simultaneously optimizes human appearance
and geometry. The multi-modal score function from both RGB and depth space is
leveraged to distill the Gaussian densification and pruning process. 2)
Moreover, we devise an Annealed Negative Prompt Guidance by decomposing SDS
into a noisier generative score and a cleaner classifier score, which well
addresses the over-saturation issue. The floating artifacts are further
eliminated based on Gaussian size in a prune-only phase to enhance generation
smoothness. Extensive experiments demonstrate the superior efficiency and
competitive quality of our framework, rendering vivid 3D humans under diverse
scenarios. Project Page: https://alvinliu0.github.io/projects/HumanGaussian
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Wed, 29 Nov 23</h3>
<dl>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03688" title="Abstract">arXiv:2304.03688</a> (cross-list from math.CO) [<a href="/pdf/2304.03688" title="Download PDF">pdf</a>, <a href="/format/2304.03688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Parameters, Universal Obstructions, and WQO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Paul%2C+C">Christophe Paul</a>, 
<a href="/search/math?searchtype=author&query=Protopapas%2C+E">Evangelos Protopapas</a>, 
<a href="/search/math?searchtype=author&query=Thilikos%2C+D+M">Dimitrios M. Thilikos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We introduce the notion of universal obstruction of a graph parameter, with
respect to some quasi-ordering relation. Universal obstructions may serve as
compact characterizations of the asymptotic behavior of graph parameters. We
provide order-theoretic conditions which imply that such a characterization is
finite and, when this is the case, we present some algorithmic implications on
the existence of fixed-parameter algorithms.
</p>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10328" title="Abstract">arXiv:2311.10328</a> (cross-list from eess.IV) [<a href="/pdf/2311.10328" title="Download PDF">pdf</a>, <a href="/ps/2311.10328" title="Download PostScript">ps</a>, <a href="/format/2311.10328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TransONet: Automatic Segmentation of Vasculature in Computed Tomographic  Angiograms Using Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rajeoni%2C+A+B">Alireza Bagheri Rajeoni</a>, 
<a href="/search/eess?searchtype=author&query=Pederson%2C+B">Breanna Pederson</a>, 
<a href="/search/eess?searchtype=author&query=Firooz%2C+A">Ali Firooz</a>, 
<a href="/search/eess?searchtype=author&query=Abdollahi%2C+H">Hamed Abdollahi</a>, 
<a href="/search/eess?searchtype=author&query=Smith%2C+A+K">Andrew K. Smith</a>, 
<a href="/search/eess?searchtype=author&query=Clair%2C+D+G">Daniel G. Clair</a>, 
<a href="/search/eess?searchtype=author&query=Lessner%2C+S+M">Susan M. Lessner</a>, 
<a href="/search/eess?searchtype=author&query=Valafar%2C+H">Homayoun Valafar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for the 2023 International Conference on Computational Science and Computational Intelligence (CSCI), Las Vegas, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Pathological alterations in the human vascular system underlie many chronic
diseases, such as atherosclerosis and aneurysms. However, manually analyzing
diagnostic images of the vascular system, such as computed tomographic
angiograms (CTAs) is a time-consuming and tedious process. To address this
issue, we propose a deep learning model to segment the vascular system in CTA
images of patients undergoing surgery for peripheral arterial disease (PAD).
Our study focused on accurately segmenting the vascular system (1) from the
descending thoracic aorta to the iliac bifurcation and (2) from the descending
thoracic aorta to the knees in CTA images using deep learning techniques. Our
approach achieved average Dice accuracies of 93.5% and 80.64% in test dataset
for (1) and (2), respectively, highlighting its high accuracy and potential
clinical utility. These findings demonstrate the use of deep learning
techniques as a valuable tool for medical professionals to analyze the health
of the vascular system efficiently and accurately. Please visit the GitHub page
for this paper at https://github.com/pip-alireza/TransOnet.
</p>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16111" title="Abstract">arXiv:2311.16111</a> (cross-list from q-bio.NC) [<a href="/pdf/2311.16111" title="Download PDF">pdf</a>, <a href="/ps/2311.16111" title="Download PostScript">ps</a>, <a href="/format/2311.16111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Explainability: Spin-Geometrical Neural Meta-Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Karamintziou%2C+S">Sofia Karamintziou</a>, 
<a href="/search/q-bio?searchtype=author&query=Meditskos%2C+G">Georgios Meditskos</a>, 
<a href="/search/q-bio?searchtype=author&query=Ntioudis%2C+D">Dimos Ntioudis</a>, 
<a href="/search/q-bio?searchtype=author&query=Mavropoulos%2C+T">Thanassis Mavropoulos</a>, 
<a href="/search/q-bio?searchtype=author&query=Vrochidis%2C+S">Stefanos Vrochidis</a>, 
<a href="/search/q-bio?searchtype=author&query=Ioannis">Ioannis</a> (Yiannis)
<a href="/search/q-bio?searchtype=author&query=Kompatsiaris">Kompatsiaris</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages; 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We face up to the challenge of explainability in multimodal artificial
intelligence. At the nexus of neuroscience-inspired and quantum computing,
interpretable and transparent spin-geometrical meta-architectures for early
fusion of large-scale, heterogeneous, graph-structured data are envisioned,
harnessing recent evidence for relativistic quantum neural coding of
(co-)behavioral states in the self-organizing brain, under competitive,
multidimensional dynamics. The designs draw on a self-dual classical
description - via special Clifford-Lipschitz operations - of spinorial quantum
states within registers of at most 16 qubits for efficient encoding of
exponentially large neural structures. Formally 'trained', Lorentz neural
architectures with precisely one lateral layer of exclusively inhibitory
interneurons accounting for anti-modalities, as well as their co-architectures
with intra-layer connections are highlighted. In principle, the approach
accommodates the fusion of up to 16 time-invariant interconnected
(anti-)modalities and the explicit recognition of underlying multidimensional
patterns. Comprehensive insights are expected to be gained through applications
to multimodal big data, under real-world scenarios.
</p>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16126" title="Abstract">arXiv:2311.16126</a> (cross-list from q-bio.BM) [<a href="/pdf/2311.16126" title="Download PDF">pdf</a>, <a href="/format/2311.16126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hierarchical Training Paradigm for Antibody Structure-sequence  Co-design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Wu%2C+F">Fang Wu</a>, 
<a href="/search/q-bio?searchtype=author&query=Li%2C+S+Z">Stan Z. Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)

</div>
<p class="mathjax">Therapeutic antibodies are an essential and rapidly expanding drug modality.
The binding specificity between antibodies and antigens is decided by
complementarity-determining regions (CDRs) at the tips of these Y-shaped
proteins. In this paper, we propose a hierarchical training paradigm (HTP) for
the antibody sequence-structure co-design. HTP consists of four levels of
training stages, each corresponding to a specific protein modality within a
particular protein domain. Through carefully crafted tasks in different stages,
HTP seamlessly and effectively integrates geometric graph neural networks
(GNNs) with large-scale protein language models to excavate evolutionary
information from not only geometric structures but also vast antibody and
non-antibody sequence databases, which determines ligand binding pose and
strength. Empirical experiments show that HTP sets the new state-of-the-art
performance in the co-design problem as well as the fix-backbone design. Our
research offers a hopeful path to unleash the potential of deep generative
architectures and seeks to illuminate the way forward for the antibody sequence
and structure co-design challenge.
</p>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16132" title="Abstract">arXiv:2311.16132</a> (cross-list from q-bio.BM) [<a href="/pdf/2311.16132" title="Download PDF">pdf</a>, <a href="/format/2311.16132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A novel RNA pseudouridine site prediction model using Utility Kernel and  data-driven parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Patil%2C+S">Sourabh Patil</a>, 
<a href="/search/q-bio?searchtype=author&query=Mathur%2C+A">Archana Mathur</a>, 
<a href="/search/q-bio?searchtype=author&query=Aduri%2C+R">Raviprasad Aduri</a>, 
<a href="/search/q-bio?searchtype=author&query=Saha%2C+S">Snehanshu Saha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">RNA protein Interactions (RPIs) play an important role in biological systems.
Recently, we have enumerated the RPIs at the residue level and have elucidated
the minimum structural unit (MSU) in these interactions to be a stretch of five
residues (Nucleotides/amino acids). Pseudouridine is the most frequent
modification in RNA. The conversion of uridine to pseudouridine involves
interactions between pseudouridine synthase and RNA. The existing models to
predict the pseudouridine sites in a given RNA sequence mainly depend on
user-defined features such as mono and dinucleotide composition/propensities of
RNA sequences. Predicting pseudouridine sites is a non-linear classification
problem with limited data points. Deep Learning models are efficient
discriminators when the data set size is reasonably large and fail when there
is a paucity of data ($&lt;1000$ samples). To mitigate this problem, we propose a
Support Vector Machine (SVM) Kernel based on utility theory from Economics, and
using data-driven parameters (i.e. MSU) as features. For this purpose, we have
used position-specific tri/quad/pentanucleotide composition/propensity
(PSPC/PSPP) besides nucleotide and dineculeotide composition as features. SVMs
are known to work well in small data regimes and kernels in SVM are designed to
classify non-linear data. The proposed model outperforms the existing
state-of-the-art models significantly (10%-15% on average).
</p>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16135" title="Abstract">arXiv:2311.16135</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2311.16135" title="Download PDF">pdf</a>, <a href="/format/2311.16135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Use of Deep Neural Networks for Uncertain Stress Functions with  Extensions to Impact Mechanics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Blum%2C+G">Garrett Blum</a>, 
<a href="/search/cond-mat?searchtype=author&query=Doris%2C+R">Ryan Doris</a>, 
<a href="/search/cond-mat?searchtype=author&query=Klabjan%2C+D">Diego Klabjan</a>, 
<a href="/search/cond-mat?searchtype=author&query=Espinosa%2C+H">Horacio Espinosa</a>, 
<a href="/search/cond-mat?searchtype=author&query=Szalkowski%2C+R">Ron Szalkowski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 9 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Stress-strain curves, or more generally, stress functions, are an extremely
important characterization of a material's mechanical properties. However,
stress functions are often difficult to derive and are narrowly tailored to a
specific material. Further, large deformations, high strain-rates, temperature
sensitivity, and effect of material parameters compound modeling challenges. We
propose a generalized deep neural network approach to model stress as a state
function with quantile regression to capture uncertainty. We extend these
models to uniaxial impact mechanics using stochastic differential equations to
demonstrate a use case and provide a framework for implementing this
uncertainty-aware stress function. We provide experiments benchmarking our
approach against leading constitutive, machine learning, and transfer learning
approaches to stress and impact mechanics modeling on publicly available and
newly presented data sets. We also provide a framework to optimize material
parameters given multiple competing impact scenarios.
</p>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16155" title="Abstract">arXiv:2311.16155</a> (cross-list from eess.SP) [<a href="/pdf/2311.16155" title="Download PDF">pdf</a>, <a href="/format/2311.16155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning-Based Frequency Offset Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+T">Tao Chen</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+S">Shilian Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+J">Jiawei Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Xuan%2C+Q">Qi Xuan</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+X">Xiaoniu Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In wireless communication systems, the asynchronization of the oscillators in
the transmitter and the receiver along with the Doppler shift due to relative
movement may lead to the presence of carrier frequency offset (CFO) in the
received signals. Estimation of CFO is crucial for subsequent processing such
as coherent demodulation. In this brief, we demonstrate the utilization of deep
learning for CFO estimation by employing a residual network (ResNet) to learn
and extract signal features from the raw in-phase (I) and quadrature (Q)
components of the signals. We use multiple modulation schemes in the training
set to make the trained model adaptable to multiple modulations or even new
signals. In comparison to the commonly used traditional CFO estimation methods,
our proposed IQ-ResNet method exhibits superior performance across various
scenarios including different oversampling ratios, various signal lengths, and
different channels
</p>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16160" title="Abstract">arXiv:2311.16160</a> (cross-list from q-bio.BM) [<a href="/pdf/2311.16160" title="Download PDF">pdf</a>, <a href="/format/2311.16160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Protein-ligand binding representation learning from fine-grained  interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Feng%2C+S">Shikun Feng</a>, 
<a href="/search/q-bio?searchtype=author&query=Li%2C+M">Minghao Li</a>, 
<a href="/search/q-bio?searchtype=author&query=Jia%2C+Y">Yinjun Jia</a>, 
<a href="/search/q-bio?searchtype=author&query=Ma%2C+W">Weiying Ma</a>, 
<a href="/search/q-bio?searchtype=author&query=Lan%2C+Y">Yanyan Lan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The binding between proteins and ligands plays a crucial role in the realm of
drug discovery. Previous deep learning approaches have shown promising results
over traditional computationally intensive methods, but resulting in poor
generalization due to limited supervised data. In this paper, we propose to
learn protein-ligand binding representation in a self-supervised learning
manner. Different from existing pre-training approaches which treat proteins
and ligands individually, we emphasize to discern the intricate binding
patterns from fine-grained interactions. Specifically, this self-supervised
learning problem is formulated as a prediction of the conclusive binding
complex structure given a pocket and ligand with a Transformer based
interaction module, which naturally emulates the binding process. To ensure the
representation of rich binding information, we introduce two pre-training
tasks, i.e.~atomic pairwise distance map prediction and mask ligand
reconstruction, which comprehensively model the fine-grained interactions from
both structure and feature space. Extensive experiments have demonstrated the
superiority of our method across various binding tasks, including
protein-ligand affinity prediction, virtual screening and protein-ligand
docking.
</p>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16163" title="Abstract">arXiv:2311.16163</a> (cross-list from eess.IV) [<a href="/pdf/2311.16163" title="Download PDF">pdf</a>, <a href="/format/2311.16163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IODeep: an IOD for the introduction of deep learning in the DICOM  standard
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Contino%2C+S">Salvatore Contino</a>, 
<a href="/search/eess?searchtype=author&query=Cruciata%2C+L">Luca Cruciata</a>, 
<a href="/search/eess?searchtype=author&query=Gambino%2C+O">Orazio Gambino</a>, 
<a href="/search/eess?searchtype=author&query=Pirrone%2C+R">Roberto Pirrone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">In recent years, Artificial Intelligence (AI) and in particular Deep Neural
Networks (DNN) became a relevant research topic in biomedical image
segmentation due to the availability of more and more data sets along with the
establishment of well known competitions. Despite the popularity of DNN based
segmentation on the research side, these techniques are almost unused in the
daily clinical practice even if they could support effectively the physician
during the diagnostic process. Apart from the issues related to the
explainability of the predictions of a neural model, such systems are not
integrated in the diagnostic workflow, and a standardization of their use is
needed to achieve this goal. This paper presents \textit{IODeep} a new DICOM
Information Object Definition (IOD) aimed at storing both the weights and the
architecture of a DNN already trained on a particular image dataset that is
labeled as regards the acquisition modality, the anatomical region, and the
disease under investigation. The IOD architecture is presented along with a DNN
selection algorithm from the PACS server based on the labels outlined above,
and a simple PACS viewer purposely designed for demonstrating the effectiveness
of the DICOM integration, while no modifications are required on the PACS
server side. The source code are freely available at
https://github.com/CHILab1/IODeep.git
</p>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16181" title="Abstract">arXiv:2311.16181</a> (cross-list from q-bio.GN) [<a href="/pdf/2311.16181" title="Download PDF">pdf</a>, <a href="/format/2311.16181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> mvlearnR and Shiny App for multiview learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Palzer%2C+E+F">Elise F. Palzer</a>, 
<a href="/search/q-bio?searchtype=author&query=Safo%2C+S+E">Sandra E. Safo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Machine Learning (cs.LG); Applications (stat.AP); Methodology (stat.ME)

</div>
<p class="mathjax">The package mvlearnR and accompanying Shiny App is intended for integrating
data from multiple sources or views or modalities (e.g. genomics, proteomics,
clinical and demographic data). Most existing software packages for multiview
learning are decentralized and offer limited capabilities, making it difficult
for users to perform comprehensive integrative analysis. The new package wraps
statistical and machine learning methods and graphical tools, providing a
convenient and easy data integration workflow. For users with limited
programming language, we provide a Shiny Application to facilitate data
integration anywhere and on any device. The methods have potential to offer
deeper insights into complex disease mechanisms.
<br />Availability and Implementation: mvlearnR is available from the following
GitHub repository: https://github.com/lasandrall/mvlearnR. The web application
is hosted on shinyapps.io and available at:
https://multi-viewlearn.shinyapps.io/MultiView_Modeling/
</p>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16190" title="Abstract">arXiv:2311.16190</a> (cross-list from quant-ph) [<a href="/pdf/2311.16190" title="Download PDF">pdf</a>, <a href="/format/2311.16190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Q-Pilot: Field Programmable Quantum Array Compilation with Flying  Ancillas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+H">Hanrui Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tan%2C+B">Bochen Tan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+P">Pengyu Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+Y">Yilian Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gu%2C+J">Jiaqi Gu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Cong%2C+J">Jason Cong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Han%2C+S">Song Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Hardware Architecture (cs.AR); Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Neutral atom arrays have become a promising platform for quantum computing,
especially the \textit{field programmable qubit array} (FPQA) endowed with the
unique capability of atom movement. This feature allows dynamic alterations in
qubit connectivity during runtime, which can reduce the cost of executing
long-range gates and improve parallelism. However, this added flexibility
introduces new challenges in circuit compilation. Inspired by the placement and
routing strategies for FPGAs, we propose to map all data qubits to fixed atoms
while utilizing movable atoms to route for 2-qubit gates between data qubits.
Coined \textit{flying ancillas}, these mobile atoms function as ancilla qubits,
dynamically generated and recycled during execution. We present Q-Pilot, a
scalable compiler for FPQA employing flying ancillas to maximize circuit
parallelism. For two important quantum applications, quantum simulation and the
Quantum Approximate Optimization Algorithm (QAOA), we devise domain-specific
routing strategies. In comparison to alternative technologies such as
superconducting devices or fixed atom arrays, Q-Pilot effectively harnesses the
flexibility of FPQA, achieving reductions of 1.4$\times$, 27.7$\times$, and
6.3$\times$ in circuit depth for 100-qubit random, quantum simulation, and QAOA
circuits, respectively.
</p>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16197" title="Abstract">arXiv:2311.16197</a> (cross-list from eess.IV) [<a href="/pdf/2311.16197" title="Download PDF">pdf</a>, <a href="/format/2311.16197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generation of patient specific cardiac chamber models using generative  neural networks under a Bayesian framework for electroanatomical mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mathew%2C+S">Sunil Mathew</a>, 
<a href="/search/eess?searchtype=author&query=Sra%2C+J">Jasbir Sra</a>, 
<a href="/search/eess?searchtype=author&query=Rowe%2C+D+B">Daniel B. Rowe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Electroanatomical mapping is a technique used in cardiology to create a
detailed 3D map of the electrical activity in the heart. It is useful for
diagnosis, treatment planning and real time guidance in cardiac ablation
procedures to treat arrhythmias like atrial fibrillation. A probabilistic
machine learning model trained on a library of CT/MRI scans of the heart can be
used during electroanatomical mapping to generate a patient-specific 3D model
of the chamber being mapped. The use of probabilistic machine learning models
under a Bayesian framework provides a way to quantify uncertainty in results
and provide a natural framework of interpretability of the model. Here we
introduce a Bayesian approach to surface reconstruction of cardiac chamber
models from a sparse 3D point cloud data acquired during electroanatomical
mapping. We show how probabilistic graphical models trained on segmented CT/MRI
data can be used to generate cardiac chamber models from few acquired locations
thereby reducing procedure time and x-ray exposure. We show how they provide
insight into what the neural network learns from the segmented CT/MRI images
used to train the network, which provides explainability to the resulting
cardiac chamber models generated by the model.
</p>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16200" title="Abstract">arXiv:2311.16200</a> (cross-list from eess.IV) [<a href="/pdf/2311.16200" title="Download PDF">pdf</a>, <a href="/format/2311.16200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Streaming Lossless Volumetric Compression of Medical Images Using Gated  Recurrent Convolutional Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+Q">Qianhao Chen</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Jietao Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Hardware Architecture (cs.AR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep learning-based lossless compression methods offer substantial advantages
in compressing medical volumetric images. Nevertheless, many learning-based
algorithms encounter a trade-off between practicality and compression
performance. This paper introduces a hardware-friendly streaming lossless
volumetric compression framework, utilizing merely one-thousandth of the model
weights compared to other learning-based compression frameworks. We propose a
gated recurrent convolutional neural network that combines diverse
convolutional structures and fusion gate mechanisms to capture the inter-slice
dependencies in volumetric images. Based on such contextual information, we can
predict the pixel-by-pixel distribution for entropy coding. Guided by
hardware/software co-design principles, we implement the proposed framework on
Field Programmable Gate Array to achieve enhanced real-time performance.
Extensive experimental results indicate that our method outperforms traditional
lossless volumetric compressors and state-of-the-art learning-based lossless
compression methods across various medical image benchmarks. Additionally, our
method exhibits robust generalization ability and competitive compression speed
</p>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16204" title="Abstract">arXiv:2311.16204</a> (cross-list from q-fin.PM) [<a href="/pdf/2311.16204" title="Download PDF">pdf</a>, <a href="/format/2311.16204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Planning for the Efficient Updating of Mutual Fund Portfolios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=de+la+Rosa%2C+T">Tom&#xe1;s de la Rosa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Portfolio Management (q-fin.PM)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Once there is a decision of rebalancing or updating a portfolio of funds, the
process of changing the current portfolio to the target one, involves a set of
transactions that are susceptible of being optimized. This is particularly
relevant when managers have to handle the implications of different types of
instruments. In this work we present linear programming and heuristic search
approaches that produce plans for executing the update. The evaluation of our
proposals shows cost improvements over the compared based strategy. The models
can be easily extended to other realistic scenarios in which a holistic
portfolio management is required
</p>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16207" title="Abstract">arXiv:2311.16207</a> (cross-list from q-bio.QM) [<a href="/pdf/2311.16207" title="Download PDF">pdf</a>, <a href="/format/2311.16207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Graph Convolutional Network with Multi-representation Alignment for  Drug Synergy Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Yang%2C+X">Xinxing Yang</a>, 
<a href="/search/q-bio?searchtype=author&query=Yang%2C+G">Genke Yang</a>, 
<a href="/search/q-bio?searchtype=author&query=Chu%2C+J">Jian Chu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages;
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Drug combination refers to the use of two or more drugs to treat a specific
disease at the same time. It is currently the mainstream way to treat complex
diseases. Compared with single drugs, drug combinations have better efficacy
and can better inhibit toxicity and drug resistance. The computational model
based on deep learning concatenates the representation of multiple drugs and
the corresponding cell line feature as input, and the output is whether the
drug combination can have an inhibitory effect on the cell line. However, this
strategy of concatenating multiple representations has the following defects:
the alignment of drug representation and cell line representation is ignored,
resulting in the synergistic relationship not being reflected positionally in
the embedding space. Moreover, the alignment measurement function in deep
learning cannot be suitable for drug synergy prediction tasks due to
differences in input types. Therefore, in this work, we propose a graph
convolutional network with multi-representation alignment (GCNMRA) for
predicting drug synergy. In the GCNMRA model, we designed a
multi-representation alignment function suitable for the drug synergy
prediction task so that the positional relationship between drug
representations and cell line representation is reflected in the embedding
space. In addition, the vector modulus of drug representations and cell line
representation is considered to improve the accuracy of calculation results and
accelerate model convergence. Finally, many relevant experiments were run on
multiple drug synergy datasets to verify the effectiveness of the above
innovative elements and the excellence of the GCNMRA model.
</p>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16208" title="Abstract">arXiv:2311.16208</a> (cross-list from q-bio.BM) [<a href="/pdf/2311.16208" title="Download PDF">pdf</a>, <a href="/format/2311.16208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InstructMol: Multi-Modal Integration for Building a Versatile and  Reliable Molecular Assistant in Drug Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Cao%2C+H">He Cao</a>, 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+Z">Zijing Liu</a>, 
<a href="/search/q-bio?searchtype=author&query=Lu%2C+X">Xingyu Lu</a>, 
<a href="/search/q-bio?searchtype=author&query=Yao%2C+Y">Yuan Yao</a>, 
<a href="/search/q-bio?searchtype=author&query=Li%2C+Y">Yu Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The rapid evolution of artificial intelligence in drug discovery encounters
challenges with generalization and extensive training, yet Large Language
Models (LLMs) offer promise in reshaping interactions with complex molecular
data. Our novel contribution, InstructMol, a multi-modal LLM, effectively
aligns molecular structures with natural language via an instruction-tuning
approach, utilizing a two-stage training strategy that adeptly combines limited
domain-specific data with molecular and textual information. InstructMol
showcases substantial performance improvements in drug discovery-related
molecular tasks, surpassing leading LLMs and significantly reducing the gap
with specialized models, thereby establishing a robust foundation for a
versatile and dependable drug discovery assistant.
</p>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16213" title="Abstract">arXiv:2311.16213</a> (cross-list from eess.IV) [<a href="/pdf/2311.16213" title="Download PDF">pdf</a>, <a href="/format/2311.16213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seeing Beyond Cancer: Multi-Institutional Validation of Object  Localization and 3D Semantic Segmentation using Deep Learning for Breast MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pekis%2C+A">Arda Pekis</a>, 
<a href="/search/eess?searchtype=author&query=Kannan%2C+V">Vignesh Kannan</a>, 
<a href="/search/eess?searchtype=author&query=Kaklamanos%2C+E">Evandros Kaklamanos</a>, 
<a href="/search/eess?searchtype=author&query=Antony%2C+A">Anu Antony</a>, 
<a href="/search/eess?searchtype=author&query=Patel%2C+S">Snehal Patel</a>, 
<a href="/search/eess?searchtype=author&query=Earnest%2C+T">Tyler Earnest</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 figures, to appear in SPIE: Medical Imaging 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">The clinical management of breast cancer depends on an accurate understanding
of the tumor and its anatomical context to adjacent tissues and landmark
structures. This context may be provided by semantic segmentation methods;
however, previous works have been largely limited to a singular focus on the
tumor alone and rarely other tissue types. In contrast, we present a method
that exploits tissue-tissue interactions to accurately segment every major
tissue type in the breast including: chest wall, skin, adipose tissue,
fibroglandular tissue, vasculature and tumor via standard-of-care Dynamic
Contrast Enhanced MRI. Comparing our method to prior state-of-the-art, we
achieved a superior Dice score on tumor segmentation while maintaining
competitive performance on other studied tissues across multiple institutions.
Briefly, our method proceeds by localizing the tumor using 2D object detectors,
then segmenting the tumor and surrounding tissues independently using two 3D
U-nets, and finally integrating these results while mitigating false positives
by checking for anatomically plausible tissue-tissue contacts. The object
detection models were pre-trained on ImageNet and COCO, and operated on MIP
(maximum intensity projection) images in the axial and sagittal planes,
establishing a 3D tumor bounding box. By integrating multiple relevant
peri-tumoral tissues, our work enables clinical applications in breast cancer
staging, prognosis and surgical planning.
</p>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16214" title="Abstract">arXiv:2311.16214</a> (cross-list from quant-ph) [<a href="/pdf/2311.16214" title="Download PDF">pdf</a>, <a href="/format/2311.16214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DGR: Tackling Drifted and Correlated Noise in Quantum Error Correction  via Decoding Graph Re-weighting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+H">Hanrui Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+P">Pengyu Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+Y">Yilian Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gu%2C+J">Jiaqi Gu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Baker%2C+J">Jonathan Baker</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chong%2C+F+T">Frederic T. Chong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Han%2C+S">Song Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Hardware Architecture (cs.AR); Emerging Technologies (cs.ET); Machine Learning (cs.LG)

</div>
<p class="mathjax">Quantum hardware suffers from high error rates and noise, which makes
directly running applications on them ineffective. Quantum Error Correction
(QEC) is a critical technique towards fault tolerance which encodes the quantum
information distributively in multiple data qubits and uses syndrome qubits to
check parity. Minimum-Weight-Perfect-Matching (MWPM) is a popular QEC decoder
that takes the syndromes as input and finds the matchings between syndromes
that infer the errors. However, there are two paramount challenges for MWPM
decoders. First, as noise in real quantum systems can drift over time, there is
a potential misalignment with the decoding graph's initial weights, leading to
a severe performance degradation in the logical error rates. Second, while the
MWPM decoder addresses independent errors, it falls short when encountering
correlated errors typical on real hardware, such as those in the 2Q
depolarizing channel.
<br />We propose DGR, an efficient decoding graph edge re-weighting strategy with
no quantum overhead. It leverages the insight that the statistics of matchings
across decoding iterations offer rich information about errors on real quantum
hardware. By counting the occurrences of edges and edge pairs in decoded
matchings, we can statistically estimate the up-to-date probabilities of each
edge and the correlations between them. The reweighting process includes two
vital steps: alignment re-weighting and correlation re-weighting. The former
updates the MWPM weights based on statistics to align with actual noise, and
the latter adjusts the weight considering edge correlations.
<br />Extensive evaluations on surface code and honeycomb code under various
settings show that DGR reduces the logical error rate by 3.6x on average-case
noise mismatch with exceeding 5000x improvement under worst-case mismatch.
</p>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16284" title="Abstract">arXiv:2311.16284</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2311.16284" title="Download PDF">pdf</a>, <a href="/ps/2311.16284" title="Download PostScript">ps</a>, <a href="/format/2311.16284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simultaneous Energy Harvesting and Hand Gesture Recognition in Large  Area Monolithic Dye-Sensitized Solar Cells
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Thomas%2C+G">Gethin Thomas</a>, 
<a href="/search/cond-mat?searchtype=author&query=Pockett%2C+A">Adam Pockett</a>, 
<a href="/search/cond-mat?searchtype=author&query=Seunarine%2C+K">Kris Seunarine</a>, 
<a href="/search/cond-mat?searchtype=author&query=Carnie%2C+M">Matt Carnie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Main body: 10 pages, 6 figures, 3 tables. Document includes supplementary info: 30 pages, 47 supplementary figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Human-Computer Interaction (cs.HC); Signal Processing (eess.SP)

</div>
<p class="mathjax">Internet of Things (IoT) devices have become prevalent, embedding
intelligence into our environment. It is projected that over 75 billion IoT
devices will be connected by 2025 worldwide, with the majority being operated
indoors. Dye-sensitized solar cells (DSSC) have recently been optimized for
ambient light, having the capabilities of providing sufficient energy for
self-powered IoT devices. Interaction with digital technologies, termed Human
Computer Interaction (HCI), is often achieved via physical mechanisms (e.g.
remote controls, cell phones) which can hinder the natural interface between
users and IoT devices, a key consideration for HCI. What if the solar cell that
is powering the IoT device can also recognize hand gestures which would allow
the user to naturally interact with the system? Previous attempts to achieve
this have necessarily employed an array of solar cell/photodiodes to detect
directionality. In this work, we demonstrate that by monitoring the
photocurrent output of an asymmetrically patterned monolithic (i.e., single
cell) DSSC, and using machine learning, we can recognize simple hand gestures,
achieving an accuracy prediction of 97.71%. This work shows that, DSSCs are the
perfect choice for self-powered interactive technologies, both in terms of
powering IoT devices in ambient light conditions and having aesthetic qualities
that are prioritized by users. As well as powering interactive technologies,
they can also provide a means of interactive control.
</p>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16286" title="Abstract">arXiv:2311.16286</a> (cross-list from stat.ME) [<a href="/pdf/2311.16286" title="Download PDF">pdf</a>, <a href="/format/2311.16286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A statistical approach to latent dynamic modeling with differential  equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Hackenberg%2C+M">Maren Hackenberg</a>, 
<a href="/search/stat?searchtype=author&query=Pechmann%2C+A">Astrid Pechmann</a>, 
<a href="/search/stat?searchtype=author&query=Kreutz%2C+C">Clemens Kreutz</a>, 
<a href="/search/stat?searchtype=author&query=Kirschner%2C+J">Janbernd Kirschner</a>, 
<a href="/search/stat?searchtype=author&query=Binder%2C+H">Harald Binder</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Applications (stat.AP); Machine Learning (stat.ML)

</div>
<p class="mathjax">Ordinary differential equations (ODEs) can provide mechanistic models of
temporally local changes of processes, where parameters are often informed by
external knowledge. While ODEs are popular in systems modeling, they are less
established for statistical modeling of longitudinal cohort data, e.g., in a
clinical setting. Yet, modeling of local changes could also be attractive for
assessing the trajectory of an individual in a cohort in the immediate future
given its current status, where ODE parameters could be informed by further
characteristics of the individual. However, several hurdles so far limit such
use of ODEs, as compared to regression-based function fitting approaches. The
potentially higher level of noise in cohort data might be detrimental to ODEs,
as the shape of the ODE solution heavily depends on the initial value. In
addition, larger numbers of variables multiply such problems and might be
difficult to handle for ODEs. To address this, we propose to use each
observation in the course of time as the initial value to obtain multiple local
ODE solutions and build a combined estimator of the underlying dynamics. Neural
networks are used for obtaining a low-dimensional latent space for dynamic
modeling from a potentially large number of variables, and for obtaining
patient-specific ODE parameters from baseline variables. Simultaneous
identification of dynamic models and of a latent space is enabled by recently
developed differentiable programming techniques. We illustrate the proposed
approach in an application with spinal muscular atrophy patients and a
corresponding simulation study. In particular, modeling of local changes in
health status at any point in time is contrasted to the interpretation of
functions obtained from a global regression. This more generally highlights how
different application settings might demand different modeling strategies.
</p>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16297" title="Abstract">arXiv:2311.16297</a> (cross-list from hep-th) [<a href="/pdf/2311.16297" title="Download PDF">pdf</a>, <a href="/format/2311.16297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum-classical simulation of quantum field theory by quantum circuit  learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-th?searchtype=author&query=Ikeda%2C+K">Kazuki Ikeda</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Theory (hep-th)</span>; Machine Learning (cs.LG); High Energy Physics - Phenomenology (hep-ph); Nuclear Theory (nucl-th); Quantum Physics (quant-ph)

</div>
<p class="mathjax">We employ quantum circuit learning to simulate quantum field theories (QFTs).
Typically, when simulating QFTs with quantum computers, we encounter
significant challenges due to the technical limitations of quantum devices when
implementing the Hamiltonian using Pauli spin matrices. To address this
challenge, we leverage quantum circuit learning, employing a compact
configuration of qubits and low-depth quantum circuits to predict real-time
dynamics in quantum field theories. The key advantage of this approach is that
a single-qubit measurement can accurately forecast various physical parameters,
including fully-connected operators. To demonstrate the effectiveness of our
method, we use it to predict quench dynamics, chiral dynamics and jet
production in a 1+1-dimensional model of quantum electrodynamics. We find that
our predictions closely align with the results of rigorous classical
calculations, exhibiting a high degree of accuracy. This hybrid
quantum-classical approach illustrates the feasibility of efficiently
simulating large-scale QFTs on cutting-edge quantum devices.
</p>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16308" title="Abstract">arXiv:2311.16308</a> (cross-list from q-bio.QM) [<a href="/pdf/2311.16308" title="Download PDF">pdf</a>, <a href="/format/2311.16308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compression-based inference of network motif sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=B%C3%A9nichou%2C+A">Alexis B&#xe9;nichou</a>, 
<a href="/search/q-bio?searchtype=author&query=Masson%2C+J">Jean-Baptiste Masson</a>, 
<a href="/search/q-bio?searchtype=author&query=Vestergaard%2C+C+L">Christian L. Vestergaard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Statistical Mechanics (cond-mat.stat-mech); Social and Information Networks (cs.SI); Data Analysis, Statistics and Probability (physics.data-an); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Physical and functional constraints on biological networks lead to complex
topological patterns across multiple scales in their organization. A particular
type of higher-order network feature that has received considerable interest is
network motifs, defined as statistically regular subgraphs. These may implement
fundamental logical and computational circuits and are referred as ``building
blocks of complex networks''. Their well-defined structures and small sizes
also enables the testing of their functions in synthetic and natural biological
experiments. The statistical inference of network motifs is however fraught
with difficulties, from defining and sampling the right null model to
accounting for the large number of possible motifs and their potential
correlations in statistical testing. Here we develop a framework for motif
mining based on lossless network compression using subgraph contractions. The
minimum description length principle allows us to select the most significant
set of motifs as well as other prominent network features in terms of their
combined compression of the network. The approach inherently accounts for
multiple testing and correlations between subgraphs and does not rely on a
priori specification of an appropriate null model. This provides an alternative
definition of motif significance which guarantees more robust statistical
inference. Our approach overcomes the common problems in classic testing-based
motif analysis. We apply our methodology to perform comparative connectomics by
evaluating the compressibility and the circuit motifs of a range of
synaptic-resolution neural connectomes.
</p>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16332" title="Abstract">arXiv:2311.16332</a> (cross-list from math.OC) [<a href="/pdf/2311.16332" title="Download PDF">pdf</a>, <a href="/format/2311.16332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistical Proper Orthogonal Decomposition for model reduction in  feedback control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dolgov%2C+S">Sergey Dolgov</a>, 
<a href="/search/math?searchtype=author&query=Kalise%2C+D">Dante Kalise</a>, 
<a href="/search/math?searchtype=author&query=Saluzzi%2C+L">Luca Saluzzi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Feedback control synthesis for nonlinear, parameter-dependent fluid flow
control problems is considered. The optimal feedback law requires the solution
of the Hamilton-Jacobi-Bellman (HJB) PDE suffering the curse of dimensionality.
This is mitigated by Model Order Reduction (MOR) techniques, where the system
is projected onto a lower-dimensional subspace, over which the feedback
synthesis becomes feasible. However, existing MOR methods assume at least one
relaxation of generality, that is, the system should be linear, or stable, or
deterministic.
<br />We propose a MOR method called Statistical POD (SPOD), which is inspired by
the Proper Orthogonal Decomposition (POD), but extends to more general systems.
Random samples of the original dynamical system are drawn, treating time and
initial condition as random variables similarly to possible parameters in the
model, and employing a stabilizing closed-loop control. The reduced subspace is
chosen to minimize the empirical risk, which is shown to estimate the expected
risk of the MOR solution with respect to the distribution of all possible
outcomes of the controlled system. This reduced model is then used to compute a
surrogate of the feedback control function in the Tensor Train (TT) format that
is computationally fast to evaluate online. Using unstable Burgers' and
Navier-Stokes equations, it is shown that the SPOD control is more accurate
than Linear Quadratic Regulator or optimal control derived from a model reduced
onto the standard POD basis, and faster than the direct optimal control of the
original system.
</p>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16333" title="Abstract">arXiv:2311.16333</a> (cross-list from econ.EM) [<a href="/pdf/2311.16333" title="Download PDF">pdf</a>, <a href="/format/2311.16333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Reactive to Proactive Volatility Modeling with Hemisphere Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Coulombe%2C+P+G">Philippe Goulet Coulombe</a>, 
<a href="/search/econ?searchtype=author&query=Frenette%2C+M">Mikael Frenette</a>, 
<a href="/search/econ?searchtype=author&query=Klieber%2C+K">Karin Klieber</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Econometrics (econ.EM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We reinvigorate maximum likelihood estimation (MLE) for macroeconomic density
forecasting through a novel neural network architecture with dedicated mean and
variance hemispheres. Our architecture features several key ingredients making
MLE work in this context. First, the hemispheres share a common core at the
entrance of the network which accommodates for various forms of time variation
in the error variance. Second, we introduce a volatility emphasis constraint
that breaks mean/variance indeterminacy in this class of overparametrized
nonlinear models. Third, we conduct a blocked out-of-bag reality check to curb
overfitting in both conditional moments. Fourth, the algorithm utilizes
standard deep learning software and thus handles large data sets - both
computationally and statistically. Ergo, our Hemisphere Neural Network (HNN)
provides proactive volatility forecasts based on leading indicators when it
can, and reactive volatility based on the magnitude of previous prediction
errors when it must. We evaluate point and density forecasts with an extensive
out-of-sample experiment and benchmark against a suite of models ranging from
classics to more modern machine learning-based offerings. In all cases, HNN
fares well by consistently providing accurate mean/variance forecasts for all
targets and horizons. Studying the resulting volatility paths reveals its
versatility, while probabilistic forecasting evaluation metrics showcase its
enviable reliability. Finally, we also demonstrate how this machinery can be
merged with other structured deep learning models by revisiting Goulet Coulombe
(2022)'s Neural Phillips Curve.
</p>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16390" title="Abstract">arXiv:2311.16390</a> (cross-list from math.CO) [<a href="/pdf/2311.16390" title="Download PDF">pdf</a>, <a href="/format/2311.16390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relative Fractional Packing Number and Its Properties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Taziki%2C+M">Mehrshad Taziki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">The concept of the \textit{relative fractional packing number} between two
graphs $G$ and $H$, initially introduced in <a href="/abs/2307.06155">arXiv:2307.06155</a> [math.CO], serves
as an upper bound for the ratio of the zero-error Shannon capacity of these
graphs. Defined as: \begin{equation*} \sup\limits_{W} \frac{\alpha(G \boxtimes
W)}{\alpha(H \boxtimes W)} \end{equation*} where the supremum is computed over
all arbitrary graphs and $\boxtimes$ denotes the strong product of graphs.
<br />This article delves into various critical theorems regarding the computation
of this number. Specifically, we address its NP-hardness and the complexity of
approximating it. Furthermore, we develop a conjecture for necessary and
sufficient conditions for this number to be less than one. We also validate
this conjecture for specific graph families. Additionally, we present
miscellaneous concepts and introduce a generalized version of the independence
number that gives insights that could significantly contribute to the study of
the relative fractional packing number.
</p>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16401" title="Abstract">arXiv:2311.16401</a> (cross-list from quant-ph) [<a href="/pdf/2311.16401" title="Download PDF">pdf</a>, <a href="/ps/2311.16401" title="Download PostScript">ps</a>, <a href="/format/2311.16401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the quantum time complexity of divide and conquer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Allcock%2C+J">Jonathan Allcock</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bao%2C+J">Jinge Bao</a>, 
<a href="/search/quant-ph?searchtype=author&query=Belovs%2C+A">Aleksandrs Belovs</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lee%2C+T">Troy Lee</a>, 
<a href="/search/quant-ph?searchtype=author&query=Santha%2C+M">Miklos Santha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages, accepted to QIP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We initiate a systematic study of the time complexity of quantum divide and
conquer algorithms for classical problems. We establish generic conditions
under which search and minimization problems with classical divide and conquer
algorithms are amenable to quantum speedup and apply these theorems to an array
of problems involving strings, integers, and geometric objects. They include
LONGEST DISTINCT SUBSTRING, KLEE'S COVERAGE, several optimization problems on
stock transactions, and k-INCREASING SUBSEQUENCE. For most of these results,
our quantum time upper bound matches the quantum query lower bound for the
problem, up to polylogarithmic factors.
</p>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16427" title="Abstract">arXiv:2311.16427</a> (cross-list from math.OC) [<a href="/pdf/2311.16427" title="Download PDF">pdf</a>, <a href="/format/2311.16427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finite-Time Computation of Polyhedral Input-Saturated Output-Admissible  Sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gautam%2C+Y">Yaashia Gautam</a>, 
<a href="/search/math?searchtype=author&query=Nicotra%2C+M+M">Marco M. Nicotra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Transactions on Automatic Control
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The paper introduces a novel algorithm for computing the output admissible
set of linear discrete-time systems subject to input saturation. The proposed
method takes advantage of the piecewise-affine dynamics to propagate the output
constraints within the non-saturated and saturated regions. The constraints are
then shared between regions to ensure a proper transition from one region to
another. The resulting algorithm generates a set that is proven to be
polyhedral, safe, positively invariant, and finitely determined. Moreover, the
set is also proven to be strictly larger than the maximal output admissible set
that would be obtained by treating input saturation as a constraint.
</p>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16447" title="Abstract">arXiv:2311.16447</a> (cross-list from eess.IV) [<a href="/pdf/2311.16447" title="Download PDF">pdf</a>, <a href="/format/2311.16447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TopoSemiSeg: Enforcing Topological Consistency for Semi-Supervised  Segmentation of Histopathology Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xu%2C+M">Meilong Xu</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+X">Xiaoling Hu</a>, 
<a href="/search/eess?searchtype=author&query=Gupta%2C+S">Saumya Gupta</a>, 
<a href="/search/eess?searchtype=author&query=Abousamra%2C+S">Shahira Abousamra</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+C">Chao Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In computational pathology, segmenting densely distributed objects like
glands and nuclei is crucial for downstream analysis. To alleviate the burden
of obtaining pixel-wise annotations, semi-supervised learning methods learn
from large amounts of unlabeled data. Nevertheless, existing semi-supervised
methods overlook the topological information hidden in the unlabeled images and
are thus prone to topological errors, e.g., missing or incorrectly
merged/separated glands or nuclei. To address this issue, we propose
TopoSemiSeg, the first semi-supervised method that learns the topological
representation from unlabeled data. In particular, we propose a topology-aware
teacher-student approach in which the teacher and student networks learn shared
topological representations. To achieve this, we introduce topological
consistency loss, which contains signal consistency and noise removal losses to
ensure the learned representation is robust and focuses on true topological
signals. Extensive experiments on public pathology image datasets show the
superiority of our method, especially on topology-wise evaluation metrics. Code
is available at https://github.com/Melon-Xu/TopoSemiSeg.
</p>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16490" title="Abstract">arXiv:2311.16490</a> (cross-list from eess.IV) [<a href="/pdf/2311.16490" title="Download PDF">pdf</a>, <a href="/format/2311.16490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SIRAN: Sinkhorn Distance Regularized Adversarial Network for DEM  Super-resolution using Discriminative Spatial Self-attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Paul%2C+S">Subhajit Paul</a>, 
<a href="/search/eess?searchtype=author&query=Gupta%2C+A">Ashutosh Gupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Digital Elevation Model (DEM) is an essential aspect in the remote sensing
domain to analyze and explore different applications related to surface
elevation information. In this study, we intend to address the generation of
high-resolution DEMs using high-resolution multi-spectral (MX) satellite
imagery by incorporating adversarial learning. To promptly regulate this
process, we utilize the notion of polarized self-attention of discriminator
spatial maps as well as introduce a Densely connected Multi-Residual Block
(DMRB) module to assist in efficient gradient flow. Further, we present an
objective function related to optimizing Sinkhorn distance with traditional GAN
to improve the stability of adversarial learning. In this regard, we provide
both theoretical and empirical substantiation of better performance in terms of
vanishing gradient issues and numerical convergence. We demonstrate both
qualitative and quantitative outcomes with available state-of-the-art methods.
Based on our experiments on DEM datasets of Shuttle Radar Topographic Mission
(SRTM) and Cartosat-1, we show that the proposed model performs preferably
against other learning-based state-of-the-art methods. We also generate and
visualize several high-resolution DEMs covering terrains with diverse
signatures to show the performance of our model.
</p>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16517" title="Abstract">arXiv:2311.16517</a> (cross-list from eess.IV) [<a href="/pdf/2311.16517" title="Download PDF">pdf</a>, <a href="/format/2311.16517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LFSRDiff: Light Field Image Super-Resolution via Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chao%2C+W">Wentao Chao</a>, 
<a href="/search/eess?searchtype=author&query=Duan%2C+F">Fuqing Duan</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xuechun Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yingqian Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+G">Guanghui Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Light field (LF) image super-resolution (SR) is a challenging problem due to
its inherent ill-posed nature, where a single low-resolution (LR) input LF
image can correspond to multiple potential super-resolved outcomes. Despite
this complexity, mainstream LF image SR methods typically adopt a deterministic
approach, generating only a single output supervised by pixel-wise loss
functions. This tendency often results in blurry and unrealistic results.
Although diffusion models can capture the distribution of potential SR results
by iteratively predicting Gaussian noise during the denoising process, they are
primarily designed for general images and struggle to effectively handle the
unique characteristics and information present in LF images. To address these
limitations, we introduce LFSRDiff, the first diffusion-based LF image SR
model, by incorporating the LF disentanglement mechanism. Our novel
contribution includes the introduction of a disentangled U-Net for diffusion
models, enabling more effective extraction and fusion of both spatial and
angular information within LF images. Through comprehensive experimental
evaluations and comparisons with the state-of-the-art LF image SR methods, the
proposed approach consistently produces diverse and realistic SR results. It
achieves the highest perceptual metric in terms of LPIPS. It also demonstrates
the ability to effectively control the trade-off between perception and
distortion. The code is available at
\url{https://github.com/chaowentao/LFSRDiff}.
</p>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16528" title="Abstract">arXiv:2311.16528</a> (cross-list from stat.ML) [<a href="/pdf/2311.16528" title="Download PDF">pdf</a>, <a href="/format/2311.16528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Utility Fairness in Contextual Dynamic Pricing with Demand Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/stat?searchtype=author&query=Simchi-Levi%2C+D">David Simchi-Levi</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+Y">Yining Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper introduces a novel contextual bandit algorithm for personalized
pricing under utility fairness constraints in scenarios with uncertain demand,
achieving an optimal regret upper bound. Our approach, which incorporates
dynamic pricing and demand learning, addresses the critical challenge of
fairness in pricing strategies. We first delve into the static full-information
setting to formulate an optimal pricing policy as a constrained optimization
problem. Here, we propose an approximation algorithm for efficiently and
approximately computing the ideal policy.
<br />We also use mathematical analysis and computational studies to characterize
the structures of optimal contextual pricing policies subject to fairness
constraints, deriving simplified policies which lays the foundations of more
in-depth research and extensions.
<br />Further, we extend our study to dynamic pricing problems with demand
learning, establishing a non-standard regret lower bound that highlights the
complexity added by fairness constraints. Our research offers a comprehensive
analysis of the cost of fairness and its impact on the balance between utility
and revenue maximization. This work represents a step towards integrating
ethical considerations into algorithmic efficiency in data-driven dynamic
pricing.
</p>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16531" title="Abstract">arXiv:2311.16531</a> (cross-list from physics.app-ph) [<a href="/pdf/2311.16531" title="Download PDF">pdf</a>, <a href="/ps/2311.16531" title="Download PostScript">ps</a>, <a href="/format/2311.16531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Channel Modeling for Terahertz Communications in Rain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Li%2C+P">Peian Li</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+W">Wenbo Liu</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+J">Jiacheng Liu</a>, 
<a href="/search/physics?searchtype=author&query=Li%2C+D">Da Li</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+G">Guohao Liu</a>, 
<a href="/search/physics?searchtype=author&query=Lei%2C+Y">Yuanshuai Lei</a>, 
<a href="/search/physics?searchtype=author&query=Zhao%2C+J">Jiabiao Zhao</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+X">Xiaopeng Wang</a>, 
<a href="/search/physics?searchtype=author&query=Sun%2C+H">Houjun Sun</a>, 
<a href="/search/physics?searchtype=author&query=Ma%2C+J">Jianjun Ma</a>, 
<a href="/search/physics?searchtype=author&query=Federici%2C+J+F">John F. Federici</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to IEEE Transactions on Antennas and Propagation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applied Physics (physics.app-ph)</span>; Systems and Control (eess.SY); Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
<p class="mathjax">Terahertz (THz) communication channels, integral to outdoor applications, are
critically influenced by natural factors like rainfall. Our research focused on
the nuanced effects of rain on these channels, employing an advanced rainfall
emulation system. By analyzing key parameters such as rain rate, altitude based
variations in rainfall, and diverse raindrop sizes, we identified the paramount
significance of the number of raindrops in the THz channel, particularly in
scenarios with constant rain rates but varying drop sizes. Central to our
findings is a novel model grounded in Mie scattering theory, which adeptly
incorporates the variability of raindrop size distributions at different
altitudes. This model has displayed strong congruence with our experimental
results. In essence, our study underscores the inadequacy of solely depending
on a fixed ground-based rain rate and emphasizes the imperative of calibrating
distribution metrics to cater to specific environmental and operational
contexts.
</p>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16583" title="Abstract">arXiv:2311.16583</a> (cross-list from math.CV) [<a href="/pdf/2311.16583" title="Download PDF">pdf</a>, <a href="/format/2311.16583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Inverse of the Complex Gamma Function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jeffrey%2C+D+J">David J. Jeffrey</a>, 
<a href="/search/math?searchtype=author&query=Watt%2C+S+M">Stephen M. Watt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Complex Variables (math.CV)</span>; Symbolic Computation (cs.SC)

</div>
<p class="mathjax">We consider the functional inverse of the Gamma function in the complex
plane, where it is multi-valued, and define a set of suitable branches by
proposing a natural extension from the real case.
</p>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16593" title="Abstract">arXiv:2311.16593</a> (cross-list from eess.IV) [<a href="/pdf/2311.16593" title="Download PDF">pdf</a>, <a href="/format/2311.16593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empowering COVID-19 Detection: Optimizing Performance Through Fine-Tuned  EfficientNet Deep Learning Architecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Talukder%2C+M+A">Md. Alamin Talukder</a>, 
<a href="/search/eess?searchtype=author&query=Layek%2C+M+A">Md. Abu Layek</a>, 
<a href="/search/eess?searchtype=author&query=Kazi%2C+M">Mohsin Kazi</a>, 
<a href="/search/eess?searchtype=author&query=Uddin%2C+M+A">Md Ashraf Uddin</a>, 
<a href="/search/eess?searchtype=author&query=Aryal%2C+S">Sunil Aryal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Computers in Biology and Medicine [Q1, IF: 7.7, CS: 9.2]
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computers in Biology and Medicine, Elsevier 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">The worldwide COVID-19 pandemic has profoundly influenced the health and
everyday experiences of individuals across the planet. It is a highly
contagious respiratory disease requiring early and accurate detection to curb
its rapid transmission. Initial testing methods primarily revolved around
identifying the genetic composition of the coronavirus, exhibiting a relatively
low detection rate and requiring a time-intensive procedure. To address this
challenge, experts have suggested using radiological imagery, particularly
chest X-rays, as a valuable approach within the diagnostic protocol. This study
investigates the potential of leveraging radiographic imaging (X-rays) with
deep learning algorithms to swiftly and precisely identify COVID-19 patients.
The proposed approach elevates the detection accuracy by fine-tuning with
appropriate layers on various established transfer learning models. The
experimentation was conducted on a COVID-19 X-ray dataset containing 2000
images. The accuracy rates achieved were impressive of 100% for EfficientNetB4
model. The fine-tuned EfficientNetB4 achieved an excellent accuracy score,
showcasing its potential as a robust COVID-19 detection model. Furthermore,
EfficientNetB4 excelled in identifying Lung disease using Chest X-ray dataset
containing 4,350 Images, achieving remarkable performance with an accuracy of
99.17%, precision of 99.13%, recall of 99.16%, and f1-score of 99.14%. These
results highlight the promise of fine-tuned transfer learning for efficient
lung detection through medical imaging, especially with X-ray images. This
research offers radiologists an effective means of aiding rapid and precise
COVID-19 diagnosis and contributes valuable assistance for healthcare
professionals in accurately identifying affected patients.
</p>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16602" title="Abstract">arXiv:2311.16602</a> (cross-list from eess.SP) [<a href="/pdf/2311.16602" title="Download PDF">pdf</a>, <a href="/format/2311.16602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GSP-KalmanNet: Tracking Graph Signals via Neural-Aided Kalman Filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Buchnik%2C+I">Itay Buchnik</a>, 
<a href="/search/eess?searchtype=author&query=Sagi%2C+G">Guy Sagi</a>, 
<a href="/search/eess?searchtype=author&query=Leinwand%2C+N">Nimrod Leinwand</a>, 
<a href="/search/eess?searchtype=author&query=Loya%2C+Y">Yuval Loya</a>, 
<a href="/search/eess?searchtype=author&query=Shlezinger%2C+N">Nir Shlezinger</a>, 
<a href="/search/eess?searchtype=author&query=Routtenberg%2C+T">Tirza Routtenberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for possible publication in the IEEE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Dynamic systems of graph signals are encountered in various applications,
including social networks, power grids, and transportation. While such systems
can often be described as state space (SS) models, tracking graph signals via
conventional tools based on the Kalman filter (KF) and its variants is
typically challenging. This is due to the nonlinearity, high dimensionality,
irregularity of the domain, and complex modeling associated with real-world
dynamic systems of graph signals. In this work, we study the tracking of graph
signals using a hybrid model-based/data-driven approach. We develop the
GSP-KalmanNet, which tracks the hidden graphical states from the graphical
measurements by jointly leveraging graph signal processing (GSP) tools and deep
learning (DL) techniques. The derivations of the GSP-KalmanNet are based on
extending the KF to exploit the inherent graph structure via graph frequency
domain filtering, which considerably simplifies the computational complexity
entailed in processing high-dimensional signals and increases the robustness to
small topology changes. Then, we use data to learn the Kalman gain following
the recently proposed KalmanNet framework, which copes with partial and
approximated modeling, without forcing a specific model over the noise
statistics. Our empirical results demonstrate that the proposed GSP-KalmanNet
achieves enhanced accuracy and run time performance as well as improved
robustness to model misspecifications compared with both model-based and
data-driven benchmarks.
</p>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16604" title="Abstract">arXiv:2311.16604</a> (cross-list from eess.AS) [<a href="/pdf/2311.16604" title="Download PDF">pdf</a>, <a href="/format/2311.16604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LC4SV: A Denoising Framework Learning to Compensate for Unseen Speaker  Verification Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lee%2C+C">Chi-Chang Lee</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+H">Hong-Wei Chen</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+C">Chu-Song Chen</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Hsin-Min Wang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+T">Tsung-Te Liu</a>, 
<a href="/search/eess?searchtype=author&query=Tsao%2C+Y">Yu Tsao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The performance of speaker verification (SV) models may drop dramatically in
noisy environments. A speech enhancement (SE) module can be used as a front-end
strategy. However, existing SE methods may fail to bring performance
improvements to downstream SV systems due to artifacts in the predicted signals
of SE models. To compensate for artifacts, we propose a generic denoising
framework named LC4SV, which can serve as a pre-processor for various unknown
downstream SV models. In LC4SV, we employ a learning-based interpolation agent
to automatically generate the appropriate coefficients between the enhanced
signal and its noisy input to improve SV performance in noisy environments. Our
experimental results demonstrate that LC4SV consistently improves the
performance of various unseen SV systems. To the best of our knowledge, this
work is the first attempt to develop a learning-based interpolation scheme
aiming at improving SV performance in noisy environments.
</p>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16614" title="Abstract">arXiv:2311.16614</a> (cross-list from stat.ME) [<a href="/pdf/2311.16614" title="Download PDF">pdf</a>, <a href="/ps/2311.16614" title="Download PostScript">ps</a>, <a href="/format/2311.16614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multivariate Unimodality Test Harnenssing the Dip Statistic of  Mahalanobis Distances Over Random Projections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Kolyvakis%2C+P">Prodromos Kolyvakis</a>, 
<a href="/search/stat?searchtype=author&query=Likas%2C+A">Aristidis Likas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Unimodality, pivotal in statistical analysis, offers insights into dataset
structures and drives sophisticated analytical procedures. While unimodality's
confirmation is straightforward for one-dimensional data using methods like
Silverman's approach and Hartigans' dip statistic, its generalization to higher
dimensions remains challenging. By extrapolating one-dimensional unimodality
principles to multi-dimensional spaces through linear random projections and
leveraging point-to-point distancing, our method, rooted in
$\alpha$-unimodality assumptions, presents a novel multivariate unimodality
test named mud-pod. Both theoretical and empirical studies confirm the efficacy
of our method in unimodality assessment of multidimensional datasets as well as
in estimating the number of clusters.
</p>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16621" title="Abstract">arXiv:2311.16621</a> (cross-list from stat.ML) [<a href="/pdf/2311.16621" title="Download PDF">pdf</a>, <a href="/format/2311.16621" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Labels: Advancing Cluster Analysis with the Entropy of Distance  Distribution (EDD)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Metzner%2C+C">Claus Metzner</a>, 
<a href="/search/stat?searchtype=author&query=Schilling%2C+A">Achim Schilling</a>, 
<a href="/search/stat?searchtype=author&query=Krauss%2C+P">Patrick Krauss</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In the evolving landscape of data science, the accurate quantification of
clustering in high-dimensional data sets remains a significant challenge,
especially in the absence of predefined labels. This paper introduces a novel
approach, the Entropy of Distance Distribution (EDD), which represents a
paradigm shift in label-free clustering analysis. Traditional methods, reliant
on discrete labels, often struggle to discern intricate cluster patterns in
unlabeled data. EDD, however, leverages the characteristic differences in
pairwise point-to-point distances to discern clustering tendencies, independent
of data labeling.
<br />Our method employs the Shannon information entropy to quantify the
'peakedness' or 'flatness' of distance distributions in a data set. This
entropy measure, normalized against its maximum value, effectively
distinguishes between strongly clustered data (indicated by pronounced peaks in
distance distribution) and more homogeneous, non-clustered data sets. This
label-free quantification is resilient against global translations and
permutations of data points, and with an additional dimension-wise z-scoring,
it becomes invariant to data set scaling.
<br />We demonstrate the efficacy of EDD through a series of experiments involving
two-dimensional data spaces with Gaussian cluster centers. Our findings reveal
a monotonic increase in the EDD value with the widening of cluster widths,
moving from well-separated to overlapping clusters. This behavior underscores
the method's sensitivity and accuracy in detecting varying degrees of
clustering. EDD's potential extends beyond conventional clustering analysis,
offering a robust, scalable tool for unraveling complex data structures without
reliance on pre-assigned labels.
</p>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16628" title="Abstract">arXiv:2311.16628</a> (cross-list from stat.ML) [<a href="/pdf/2311.16628" title="Download PDF">pdf</a>, <a href="/ps/2311.16628" title="Download PostScript">ps</a>, <a href="/format/2311.16628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symmetry-regularized neural ordinary differential equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Hao%2C+W">Wenbo Hao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Neural Ordinary Differential Equations (Neural ODEs) is a class of deep
neural network models that interpret the hidden state dynamics of neural
networks as an ordinary differential equation, thereby capable of capturing
system dynamics in a continuous time framework. In this work, I integrate
symmetry regularization into Neural ODEs. In particular, I use continuous Lie
symmetry of ODEs and PDEs associated with the model to derive conservation laws
and add them to the loss function, making it physics-informed. This
incorporation of inherent structural properties into the loss function could
significantly improve robustness and stability of the model during training. To
illustrate this method, I employ a toy model that utilizes a cosine rate of
change in the hidden state, showcasing the process of identifying Lie
symmetries, deriving conservation laws, and constructing a new loss function.
</p>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16632" title="Abstract">arXiv:2311.16632</a> (cross-list from stat.ML) [<a href="/pdf/2311.16632" title="Download PDF">pdf</a>, <a href="/format/2311.16632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Opening the Black Box: Towards inherently interpretable energy data  imputation models using building physics insight
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Liguori%2C+A">Antonio Liguori</a>, 
<a href="/search/stat?searchtype=author&query=Quintana%2C+M">Matias Quintana</a>, 
<a href="/search/stat?searchtype=author&query=Fu%2C+C">Chun Fu</a>, 
<a href="/search/stat?searchtype=author&query=Miller%2C+C">Clayton Miller</a>, 
<a href="/search/stat?searchtype=author&query=Frisch%2C+J">J&#xe9;r&#xf4;me Frisch</a>, 
<a href="/search/stat?searchtype=author&query=van+Treeck%2C+C">Christoph van Treeck</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review in Energy and Buildings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Missing data are frequently observed by practitioners and researchers in the
building energy modeling community. In this regard, advanced data-driven
solutions, such as Deep Learning methods, are typically required to reflect the
non-linear behavior of these anomalies. As an ongoing research question related
to Deep Learning, a model's applicability to limited data settings can be
explored by introducing prior knowledge in the network. This same strategy can
also lead to more interpretable predictions, hence facilitating the field
application of the approach. For that purpose, the aim of this paper is to
propose the use of Physics-informed Denoising Autoencoders (PI-DAE) for missing
data imputation in commercial buildings. In particular, the presented method
enforces physics-inspired soft constraints to the loss function of a Denoising
Autoencoder (DAE). In order to quantify the benefits of the physical component,
an ablation study between different DAE configurations is conducted. First,
three univariate DAEs are optimized separately on indoor air temperature,
heating, and cooling data. Then, two multivariate DAEs are derived from the
previous configurations. Eventually, a building thermal balance equation is
coupled to the last multivariate configuration to obtain PI-DAE. Additionally,
two commonly used benchmarks are employed to support the findings. It is shown
how introducing physical knowledge in a multivariate Denoising Autoencoder can
enhance the inherent model interpretability through the optimized physics-based
coefficients. While no significant improvement is observed in terms of
reconstruction error with the proposed PI-DAE, its enhanced robustness to
varying rates of missing data and the valuable insights derived from the
physics-based coefficients create opportunities for wider applications within
building systems and the built environment.
</p>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16643" title="Abstract">arXiv:2311.16643</a> (cross-list from math.CO) [<a href="/pdf/2311.16643" title="Download PDF">pdf</a>, <a href="/format/2311.16643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simplifying modular lattices by removing doubly irreducible elements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kohonen%2C+J">Jukka Kohonen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">Lattices are simplified by removing some of their doubly irreducible
elements, resulting in smaller lattices called racks. All vertically
indecomposable modular racks of $n \le 40$ elements are listed, and the numbers
of all modular lattices of $n \le 40$ elements are obtained by P\'olya
counting. SageMath code is provided that allows easy access both to the listed
racks, and to the modular lattices that were not listed. More than 3000-fold
savings in storage space are demonstrated.
</p>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16663" title="Abstract">arXiv:2311.16663</a> (cross-list from quant-ph) [<a href="/pdf/2311.16663" title="Download PDF">pdf</a>, <a href="/ps/2311.16663" title="Download PostScript">ps</a>, <a href="/format/2311.16663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unclonable Cryptography in the Plain Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Chevalier%2C+C">C&#xe9;line Chevalier</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hermouet%2C+P">Paul Hermouet</a>, 
<a href="/search/quant-ph?searchtype=author&query=Vu%2C+Q">Quoc-Huy Vu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">By leveraging the no-cloning principle of quantum mechanics, unclonable
cryptography enables us to achieve novel cryptographic protocols that are
otherwise impossible classically. Two most notable examples of unclonable
cryptography are quantum copy-protection and unclonable encryption. Despite
receiving a lot of attention in recent years, two important open questions
still remain: copy-protection for point functions in the plain model, which is
usually considered as feasibility demonstration, and unclonable encryption with
unclonable indistinguishability security in the plain model.
<br />In this work, by relying on previous works of Coladangelo, Liu, Liu, and
Zhandry (Crypto'21) and Culf and Vidick (Quantum'22), we establish a new
monogamy-of-entanglement property for subspace coset states, which allows us to
obtain the following new results:
<br />- We show that copy-protection of point functions exists in the plain model,
with different challenge distributions (including arguably the most natural
ones).
<br />- We show, for the first time, that unclonable encryption with unclonable
indistinguishability security exists in the plain model.
</p>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16702" title="Abstract">arXiv:2311.16702</a> (cross-list from eess.AS) [<a href="/pdf/2311.16702" title="Download PDF">pdf</a>, <a href="/format/2311.16702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> iMagLS: Interaural Level Difference with Magnitude Least-Squares Loss  for Optimized First-Order Head-Related Transfer Function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Berebi%2C+O">Or Berebi</a>, 
<a href="/search/eess?searchtype=author&query=Ben-Hur%2C+Z">Zamir Ben-Hur</a>, 
<a href="/search/eess?searchtype=author&query=Alon%2C+D+L">David Lou Alon</a>, 
<a href="/search/eess?searchtype=author&query=Rafaely%2C+B">Boaz Rafaely</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages, 2 figures, Forum Acusticum 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Binaural reproduction for headphone-based listening is an active research
area due to its widespread use in evolving technologies such as augmented and
virtual reality (AR and VR). On the one hand, these applications demand high
quality spatial audio perception to preserve the sense of immersion. On the
other hand, recording devices may only have a few microphones, leading to
low-order representations such as first-order Ambisonics (FOA). However,
first-order Ambisonics leads to limited externalization and spatial resolution.
In this paper, a novel head-related transfer function (HRTF) preprocessing
optimization loss is proposed, and is minimized using nonlinear programming.
The new method, denoted iMagLS, involves the introduction of an interaural
level difference (ILD) error term to the now widely used MagLS optimization
loss for the lateral plane angles. Results indicate that the ILD error could be
substantially reduced, while the HRTF magnitude error remains similar to that
obtained with MagLS. These results could prove beneficial to the overall
spatial quality of first-order Ambisonics, while other reproduction methods
could also benefit from considering this modified loss.
</p>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16707" title="Abstract">arXiv:2311.16707</a> (cross-list from eess.IV) [<a href="/pdf/2311.16707" title="Download PDF">pdf</a>, <a href="/ps/2311.16707" title="Download PostScript">ps</a>, <a href="/format/2311.16707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Full-resolution MLPs Empower Medical Dense Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Meng%2C+M">Mingyuan Meng</a>, 
<a href="/search/eess?searchtype=author&query=Xue%2C+Y">Yuxin Xue</a>, 
<a href="/search/eess?searchtype=author&query=Feng%2C+D">Dagan Feng</a>, 
<a href="/search/eess?searchtype=author&query=Bi%2C+L">Lei Bi</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+J">Jinman Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Dense prediction is a fundamental requirement for many medical vision tasks
such as medical image restoration, registration, and segmentation. The most
popular vision model, Convolutional Neural Networks (CNNs), has reached
bottlenecks due to the intrinsic locality of convolution operations. Recently,
transformers have been widely adopted for dense prediction for their capability
to capture long-range visual dependence. However, due to the high computational
complexity and large memory consumption of self-attention operations,
transformers are usually used at downsampled feature resolutions. Such usage
cannot effectively leverage the tissue-level textural information available
only at the full image resolution. This textural information is crucial for
medical dense prediction as it can differentiate the subtle human anatomy in
medical images. In this study, we hypothesize that Multi-layer Perceptrons
(MLPs) are superior alternatives to transformers in medical dense prediction
where tissue-level details dominate the performance, as MLPs enable long-range
dependence at the full image resolution. To validate our hypothesis, we develop
a full-resolution hierarchical MLP framework that uses MLPs beginning from the
full image resolution. We evaluate this framework with various MLP blocks on a
wide range of medical dense prediction tasks including restoration,
registration, and segmentation. Extensive experiments on six public
well-benchmarked datasets show that, by simply using MLPs at full resolution,
our framework outperforms its CNN and transformer counterparts and achieves
state-of-the-art performance on various medical dense prediction tasks.
</p>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16712" title="Abstract">arXiv:2311.16712</a> (cross-list from q-bio.QM) [<a href="/pdf/2311.16712" title="Download PDF">pdf</a>, <a href="/format/2311.16712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Onedata4Sci: Life science data management solution based on Onedata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Svoboda%2C+T">Tom&#xe1;&#x161; Svoboda</a>, 
<a href="/search/q-bio?searchtype=author&query=Ra%C4%8Dek%2C+T">Tom&#xe1;&#x161; Ra&#x10d;ek</a>, 
<a href="/search/q-bio?searchtype=author&query=Handl%2C+J">Josef Handl</a>, 
<a href="/search/q-bio?searchtype=author&query=Sabo%2C+J">Jozef Sabo</a>, 
<a href="/search/q-bio?searchtype=author&query=Ro%C5%A1inec%2C+A">Adri&#xe1;n Ro&#x161;inec</a>, 
<a href="/search/q-bio?searchtype=author&query=Opio%C5%82a%2C+%C5%81">&#x141;ukasz Opio&#x142;a</a>, 
<a href="/search/q-bio?searchtype=author&query=Jesionek%2C+W">Wojciech Jesionek</a>, 
<a href="/search/q-bio?searchtype=author&query=E%C5%A1ner%2C+M">Milan E&#x161;ner</a>, 
<a href="/search/q-bio?searchtype=author&query=Pernisov%C3%A1%2C+M">Mark&#xe9;ta Pernisov&#xe1;</a>, 
<a href="/search/q-bio?searchtype=author&query=Valasevich%2C+N+M">Natallia Madzia Valasevich</a>, 
<a href="/search/q-bio?searchtype=author&query=K%C5%99enek%2C+A">Ale&#x161; K&#x159;enek</a>, 
<a href="/search/q-bio?searchtype=author&query=Svobodov%C3%A1%2C+R">Radka Svobodov&#xe1;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Life-science experimental methods generate vast and ever-increasing volumes
of data, which provide highly valuable research resources. However, management
of these data is nontrivial and applicable software solutions are currently
subject to intensive development. The solutions mainly fall into one of the two
groups: general data management systems (e.g. Onedata, iRODS, B2SHARE, CERNBox)
or very specialised data management solutions (e.g. solutions for biomolecular
simulation data, biological imaging data, genomic data).
<br />To bridge this gap between them, we provide Onedata4Sci, a prototype data
management solution, which is focused on the management of life science data
and covers four key steps of the data life cycle, i.e. data acquisition, user
access, computational processing and archiving. Onedata4Sci is based on the
Onedata data management system. It is written in Python, fully containerised,
with the support for processing the stored data in Kubernetes. The
applicability of Onedata4Sci is shown in three distinct use cases -- plant
imaging data, cellular imaging data, and cryo-electron microscopy data. Despite
the use cases covering very different types of data and user patterns,
Onedata4Sci demonstrated an ability to successfully handle all these
conditions. Complete source codes of Onedata4Sci are available on GitHub
(https://github.com/CERIT-SC/onedata4sci), and its documentation and manual for
installation are also provided.
</p>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16727" title="Abstract">arXiv:2311.16727</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2311.16727" title="Download PDF">pdf</a>, <a href="/ps/2311.16727" title="Download PostScript">ps</a>, <a href="/format/2311.16727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sluggish and Chemically-Biased Interstitial Diffusion in Concentrated  Solid Solution Alloys: Mechanisms and Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Xu%2C+B">Biao Xu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Fu%2C+H">Haijun Fu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Huang%2C+S">Shasha Huang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Ma%2C+S">Shihua Ma</a>, 
<a href="/search/cond-mat?searchtype=author&query=Xiong%2C+Y">Yaoxu Xiong</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Xiang%2C+X">Xuepeng Xiang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Lu%2C+W">Wenyu Lu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Kai%2C+J">Ji-Jung Kai</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zhao%2C+S">Shijun Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages,9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG); Atomic and Molecular Clusters (physics.atm-clus)

</div>
<p class="mathjax">Interstitial diffusion is a pivotal process that governs the phase stability
and irradiation response of materials in non-equilibrium conditions. In this
work, we study sluggish and chemically-biased interstitial diffusion in Fe-Ni
concentrated solid solution alloys (CSAs) by combining machine learning (ML)
and kinetic Monte Carlo (kMC), where ML is used to accurately and efficiently
predict the migration energy barriers on-the-fly. The ML-kMC reproduces the
diffusivity that was reported by molecular dynamics results at high
temperatures. With this powerful tool, we find that the observed sluggish
diffusion and the "Ni-Ni-Ni"-biased diffusion in Fe-Ni alloys are ascribed to a
unique "Barrier Lock" mechanism, whereas the "Fe-Fe-Fe"-biased diffusion is
influenced by a "Component Dominance" mechanism. Inspired by the mentioned
mechanisms, a practical AvgS-kMC method is proposed for conveniently and
swiftly determining interstitial-mediated diffusivity by only relying on the
mean energy barriers of migration patterns. Combining the AvgS-kMC with the
differential evolutionary algorithm, an inverse design strategy for optimizing
sluggish diffusion properties is applied to emphasize the crucial role of
favorable migration patterns.
</p>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16771" title="Abstract">arXiv:2311.16771</a> (cross-list from stat.ML) [<a href="/pdf/2311.16771" title="Download PDF">pdf</a>, <a href="/format/2311.16771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The HR-Calculus: Enabling Information Processing with Quaternion Algebra
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Mandic%2C+D+P">Danilo P. Mandic</a>, 
<a href="/search/stat?searchtype=author&query=Talebi%2C+S+P">Sayed Pouria Talebi</a>, 
<a href="/search/stat?searchtype=author&query=Took%2C+C+C">Clive Cheong Took</a>, 
<a href="/search/stat?searchtype=author&query=Xia%2C+Y">Yili Xia</a>, 
<a href="/search/stat?searchtype=author&query=Xu%2C+D">Dongpo Xu</a>, 
<a href="/search/stat?searchtype=author&query=Xiang%2C+M">Min Xiang</a>, 
<a href="/search/stat?searchtype=author&query=Bourigault%2C+P">Pauline Bourigault</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">From their inception, quaternions and their division algebra have proven to
be advantageous in modelling rotation/orientation in three-dimensional spaces
and have seen use from the initial formulation of electromagnetic filed theory
through to forming the basis of quantum filed theory. Despite their impressive
versatility in modelling real-world phenomena, adaptive information processing
techniques specifically designed for quaternion-valued signals have only
recently come to the attention of the machine learning, signal processing, and
control communities. The most important development in this direction is
introduction of the HR-calculus, which provides the required mathematical
foundation for deriving adaptive information processing techniques directly in
the quaternion domain. In this article, the foundations of the HR-calculus are
revised and the required tools for deriving adaptive learning techniques
suitable for dealing with quaternion-valued signals, such as the gradient
operator, chain and product derivative rules, and Taylor series expansion are
presented. This serves to establish the most important applications of adaptive
information processing in the quaternion domain for both single-node and
multi-node formulations. The article is supported by Supplementary Material,
which will be referred to as SM.
</p>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16806" title="Abstract">arXiv:2311.16806</a> (cross-list from math.NT) [<a href="/pdf/2311.16806" title="Download PDF">pdf</a>, <a href="/ps/2311.16806" title="Download PostScript">ps</a>, <a href="/format/2311.16806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Summing the sum of digits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Allouche%2C+J">Jean-Paul Allouche</a>, 
<a href="/search/math?searchtype=author&query=Stipulanti%2C+M">Manon Stipulanti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Number Theory (math.NT)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
<p class="mathjax">We revisit and generalize inequalities for the summatory function of the sum
of digits in a given integer base. We prove that several known results can be
deduced from a theorem in a 2023 paper by Mohanty, Greenbury, Sarkany,
Narayanan, Dingle, Ahnert, and Louis, whose primary scope is the maximum
mutational robustness in genotype-phenotype maps.
</p>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16816" title="Abstract">arXiv:2311.16816</a> (cross-list from math.CO) [<a href="/pdf/2311.16816" title="Download PDF">pdf</a>, <a href="/format/2311.16816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Packing even directed circuits quarter-integrally
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gorsky%2C+M">Maximilian Gorsky</a>, 
<a href="/search/math?searchtype=author&query=Kawarabayashi%2C+K">Ken-ichi Kawarabayashi</a>, 
<a href="/search/math?searchtype=author&query=Kreutzer%2C+S">Stephan Kreutzer</a>, 
<a href="/search/math?searchtype=author&query=Wiederrecht%2C+S">Sebastian Wiederrecht</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 144 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We prove the existence of a computable function
$f\colon\mathbb{N}\to\mathbb{N}$ such that for every integer $k$ and every
digraph $D$ either contains a collection $\mathcal{C}$ of directed cycles of
even length such that no vertex of $D$ belongs to more than four cycles in
$\mathcal{C}$, or there exists a set $S\subseteq V(D)$ of size at most $f(k)$
such that $D-S$ has no directed cycle of even length. Moreover, we provide an
algorithm that finds one of the two outcomes of this statement in time
$g(k)n^{\mathcal{O}(1)}$ for some computable function $g\colon
\mathbb{N}\to\mathbb{N}$.
<br />Our result unites two deep fields of research from the algorithmic theory for
digraphs: The study of the Erd\H{o}s-P\'osa property of digraphs and the study
of the Even Dicycle Problem. The latter is the decision problem which asks if a
given digraph contains an even dicycle and can be traced back to a question of
P\'olya from 1913. It remained open until a polynomial time algorithm was
finally found by Robertson, Seymour, and Thomas (Ann. of Math. (2) 1999) and,
independently, McCuaig (Electron. J. Combin. 2004; announced jointly at STOC
1997). The Even Dicycle Problem is equivalent to the recognition problem of
Pfaffian bipartite graphs and has applications even beyond discrete mathematics
and theoretical computer science. On the other hand, Younger's Conjecture
(1973), states that dicycles have the Erd\H{o}s-P\'osa property. The conjecture
was proven more than two decades later by Reed, Robertson, Seymour, and Thomas
(Combinatorica 1996) and opened the path for structural digraph theory as well
as the algorithmic study of the directed feedback vertex set problem. Our
approach builds upon the techniques used to resolve both problems and combines
them into a powerful structural theorem that yields further algorithmic
applications for other prominent problems.
</p>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16821" title="Abstract">arXiv:2311.16821</a> (cross-list from eess.IV) [<a href="/pdf/2311.16821" title="Download PDF">pdf</a>, <a href="/format/2311.16821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Denoising Diffusion Probabilistic Models for Image Inpainting of Cell  Distributions in the Human Brain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kropp%2C+J">Jan-Oliver Kropp</a>, 
<a href="/search/eess?searchtype=author&query=Schiffer%2C+C">Christian Schiffer</a>, 
<a href="/search/eess?searchtype=author&query=Amunts%2C+K">Katrin Amunts</a>, 
<a href="/search/eess?searchtype=author&query=Dickscheid%2C+T">Timo Dickscheid</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ISBI-2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Recent advances in imaging and high-performance computing have made it
possible to image the entire human brain at the cellular level. This is the
basis to study the multi-scale architecture of the brain regarding its
subdivision into brain areas and nuclei, cortical layers, columns, and cell
clusters down to single cell morphology Methods for brain mapping and cell
segmentation exploit such images to enable rapid and automated analysis of
cytoarchitecture and cell distribution in complete series of histological
sections. However, the presence of inevitable processing artifacts in the image
data caused by missing sections, tears in the tissue, or staining variations
remains the primary reason for gaps in the resulting image data. To this end we
aim to provide a model that can fill in missing information in a reliable way,
following the true cell distribution at different scales. Inspired by the
recent success in image generation, we propose a denoising diffusion
probabilistic model (DDPM), trained on light-microscopic scans of cell-body
stained sections. We extend this model with the RePaint method to impute
missing or replace corrupted image data. We show that our trained DDPM is able
to generate highly realistic image information for this purpose, generating
plausible cell statistics and cytoarchitectonic patterns. We validate its
outputs using two established downstream task models trained on the same data.
</p>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16848" title="Abstract">arXiv:2311.16848</a> (cross-list from eess.SP) [<a href="/pdf/2311.16848" title="Download PDF">pdf</a>, <a href="/format/2311.16848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Localization of a Passive Source with a Sensor Network based  Experimental Molecular Communication Platform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gulec%2C+F">Fatih Gulec</a>, 
<a href="/search/eess?searchtype=author&query=Koda%2C+D+Y">Damla Yagmur Koda</a>, 
<a href="/search/eess?searchtype=author&query=Atakan%2C+B">Baris Atakan</a>, 
<a href="/search/eess?searchtype=author&query=Eckford%2C+A+W">Andrew W. Eckford</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">In a practical molecular communication scenario such as monitoring air
pollutants released from an unknown source, it is essential to estimate the
location of the molecular transmitter (TX). This paper presents a novel Sensor
Network-based Localization Algorithm (SNCLA) for passive transmission by using
a novel experimental platform which mainly comprises a clustered sensor network
(SN) with $24$ sensor nodes and evaporating ethanol molecules as the passive
TX. In SNCLA, a Gaussian plume model is employed to derive the location
estimator. The parameters such as transmitted mass, wind velocity, detection
time, and actual concentration are calculated or estimated from the measured
signals via the SN to be employed as the input for the location estimator. The
numerical results show that the performance of SNCLA is better for stronger
winds in the medium. Our findings show that evaporated molecules do not
propagate homogeneously through the SN due to the presence of the wind. In
addition, our statistical analysis based on the measured experimental data
shows that the sensed signals by the SN have a log-normal distribution, while
the additive noise follows a Student's t-distribution in contrast to the
Gaussian assumption in the literature.
</p>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16849" title="Abstract">arXiv:2311.16849</a> (cross-list from stat.ML) [<a href="/pdf/2311.16849" title="Download PDF">pdf</a>, <a href="/format/2311.16849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifiable Feature Learning for Spatial Data with Nonlinear ICA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=H%C3%A4lv%C3%A4%2C+H">Hermanni H&#xe4;lv&#xe4;</a>, 
<a href="/search/stat?searchtype=author&query=So%2C+J">Jonathan So</a>, 
<a href="/search/stat?searchtype=author&query=Turner%2C+R+E">Richard E. Turner</a>, 
<a href="/search/stat?searchtype=author&query=Hyv%C3%A4rinen%2C+A">Aapo Hyv&#xe4;rinen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recently, nonlinear ICA has surfaced as a popular alternative to the many
heuristic models used in deep representation learning and disentanglement. An
advantage of nonlinear ICA is that a sophisticated identifiability theory has
been developed; in particular, it has been proven that the original components
can be recovered under sufficiently strong latent dependencies. Despite this
general theory, practical nonlinear ICA algorithms have so far been mainly
limited to data with one-dimensional latent dependencies, especially
time-series data. In this paper, we introduce a new nonlinear ICA framework
that employs $t$-process (TP) latent components which apply naturally to data
with higher-dimensional dependency structures, such as spatial and
spatio-temporal data. In particular, we develop a new learning and inference
algorithm that extends variational inference methods to handle the combination
of a deep neural network mixing function with the TP prior, and employs the
method of inducing points for computational efficacy. On the theoretical side,
we show that such TP independent components are identifiable under very general
conditions. Further, Gaussian Process (GP) nonlinear ICA is established as a
limit of the TP Nonlinear ICA model, and we prove that the identifiability of
the latent components at this GP limit is more restricted. Namely, those
components are identifiable if and only if they have distinctly different
covariance kernels. Our algorithm and identifiability theorems are explored on
simulated spatial data and real world spatio-temporal data.
</p>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16896" title="Abstract">arXiv:2311.16896</a> (cross-list from physics.optics) [<a href="/pdf/2311.16896" title="Download PDF">pdf</a>, <a href="/format/2311.16896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 65 GOPS/neuron Photonic Tensor Core with Thin-film Lithium Niobate  Photonics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Lin%2C+Z">Zhongjin Lin</a>, 
<a href="/search/physics?searchtype=author&query=Shastri%2C+B+J">Bhavin J. Shastri</a>, 
<a href="/search/physics?searchtype=author&query=Yu%2C+S">Shangxuan Yu</a>, 
<a href="/search/physics?searchtype=author&query=Song%2C+J">Jingxiang Song</a>, 
<a href="/search/physics?searchtype=author&query=Zhu%2C+Y">Yuntao Zhu</a>, 
<a href="/search/physics?searchtype=author&query=Safarnejadian%2C+A">Arman Safarnejadian</a>, 
<a href="/search/physics?searchtype=author&query=Cai%2C+W">Wangning Cai</a>, 
<a href="/search/physics?searchtype=author&query=Lin%2C+Y">Yanmei Lin</a>, 
<a href="/search/physics?searchtype=author&query=Ke%2C+W">Wei Ke</a>, 
<a href="/search/physics?searchtype=author&query=Hammood%2C+M">Mustafa Hammood</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+T">Tianye Wang</a>, 
<a href="/search/physics?searchtype=author&query=Xu%2C+M">Mengyue Xu</a>, 
<a href="/search/physics?searchtype=author&query=Zheng%2C+Z">Zibo Zheng</a>, 
<a href="/search/physics?searchtype=author&query=Al-Qadasi%2C+M">Mohammed Al-Qadasi</a>, 
<a href="/search/physics?searchtype=author&query=Esmaeeli%2C+O">Omid Esmaeeli</a>, 
<a href="/search/physics?searchtype=author&query=Rahim%2C+M">Mohamed Rahim</a>, 
<a href="/search/physics?searchtype=author&query=Pakulski%2C+G">Grzegorz Pakulski</a>, 
<a href="/search/physics?searchtype=author&query=Schmid%2C+J">Jens Schmid</a>, 
<a href="/search/physics?searchtype=author&query=Barrios%2C+P">Pedro Barrios</a>, 
<a href="/search/physics?searchtype=author&query=Jiang%2C+W">Weihong Jiang</a>, 
<a href="/search/physics?searchtype=author&query=Morison%2C+H">Hugh Morison</a>, 
<a href="/search/physics?searchtype=author&query=Mitchell%2C+M">Matthew Mitchell</a>, 
<a href="/search/physics?searchtype=author&query=Qiang%2C+X">Xiaogang Qiang</a>, 
<a href="/search/physics?searchtype=author&query=Guan%2C+X">Xun Guan</a>, 
<a href="/search/physics?searchtype=author&query=Jaeger%2C+N+A+F">Nicolas A. F. Jaeger</a>, 
<a href="/search/physics?searchtype=author&query=Rusch%2C+L+A+n">Leslie A.n Rusch</a>, 
<a href="/search/physics?searchtype=author&query=Shekhar%2C+S">Sudip Shekhar</a>, 
<a href="/search/physics?searchtype=author&query=Shi%2C+W">Wei Shi</a>, 
<a href="/search/physics?searchtype=author&query=Yu%2C+S">Siyuan Yu</a>, 
<a href="/search/physics?searchtype=author&query=Cai%2C+X">Xinlun Cai</a>, 
<a href="/search/physics?searchtype=author&query=Chrostowski%2C+L">Lukas Chrostowski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Emerging Technologies (cs.ET); Applied Physics (physics.app-ph)

</div>
<p class="mathjax">Photonics offers a transformative approach to artificial intelligence (AI)
and neuromorphic computing by providing low latency, high bandwidth, and
energy-efficient computations. Here, we introduce a photonic tensor core
processor enabled by time-multiplexed inputs and charge-integrated outputs.
This fully integrated processor, comprising only two thin-film lithium niobate
(TFLN) modulators, a III-V laser, and a charge-integration photoreceiver, can
implement an entire layer of a neural network. It can execute 65 billion
operations per second (GOPS) per neuron, including simultaneous weight
updates-a hitherto unachieved speed. Our processor stands out from conventional
photonic processors, which have static weights set during training, as it
supports fast "hardware-in-the-loop" training, and can dynamically adjust the
inputs (fan-in) and outputs (fan-out) within a layer, thereby enhancing its
versatility. Our processor can perform large-scale dot-product operations with
vector dimensions up to 131,072. Furthermore, it successfully classifies
(supervised learning) and clusters (unsupervised learning) 112*112-pixel images
after "hardware-in-the-loop" training. To handle "hardware-in-the-loop"
training for clustering AI tasks, we provide a solution for multiplications
involving two negative numbers based on our processor.
</p>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16904" title="Abstract">arXiv:2311.16904</a> (cross-list from eess.SP) [<a href="/pdf/2311.16904" title="Download PDF">pdf</a>, <a href="/format/2311.16904" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Study of BSM Inter-Packet Gap Tails in C-V2X Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fouda%2C+A">Abdurrahman Fouda</a>, 
<a href="/search/eess?searchtype=author&query=Berry%2C+R">Randall Berry</a>, 
<a href="/search/eess?searchtype=author&query=Vukovic%2C+I">Ivan Vukovic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2110.00056">arXiv:2110.00056</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Cellular vehicle-to-everything (C-V2X) enables safety-critical connected
vehicular service by exchanging basic safety messages (BSMs) among nearby
vehicular users (VUEs). Timely transmission of BSMs is crucial to avoid stale
information at VUEs. However, successive packet losses can lead to large
inter-packet gaps (IPGs), reducing the BSMs' reliability. This paper
investigates the tail behavior of IPG and information age (IA) distributions in
C-V2X mode 4, a decentralized resource allocation method based on
semi-persistent scheduling (SPS). We study the improvements and trade-offs
introduced by SAE one-shot transmission to decrease the number of successive
BSM losses at destination VUEs. The study employs high-fidelity system-level
simulations that closely follow the SPS process of CV2X mode 4 to evaluate the
performance of interleaved one-shot SPS transmissions. The numerical results
demonstrate significant improvement in the IPG and IA tail distributions in
various simulation scenarios. Additionally, we propose an accurate analytical
model to characterize the IPG tail behavior of C-V2X BSM transmissions. The
proposed model is validated by comparing its results with those obtained using
the system-level simulations. Our validation shows that the proposed model
generates analytical results that coincide with the asymptotic slopes of IPG
distribution in different BSM transmission modes.
</p>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16909" title="Abstract">arXiv:2311.16909</a> (cross-list from stat.ML) [<a href="/pdf/2311.16909" title="Download PDF">pdf</a>, <a href="/ps/2311.16909" title="Download PostScript">ps</a>, <a href="/format/2311.16909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multinomial belief networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Donker%2C+H+C">H. C. Donker</a>, 
<a href="/search/stat?searchtype=author&query=Neijzen%2C+D">D. Neijzen</a>, 
<a href="/search/stat?searchtype=author&query=Lunter%2C+G+A">G. A. Lunter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 3 figs; supplement: 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Applications (stat.AP)

</div>
<p class="mathjax">A Bayesian approach to machine learning is attractive when we need to
quantify uncertainty, deal with missing observations, when samples are scarce,
or when the data is sparse. All of these commonly apply when analysing
healthcare data. To address these analytical requirements, we propose a deep
generative model for multinomial count data where both the weights and hidden
units of the network are Dirichlet distributed. A Gibbs sampling procedure is
formulated that takes advantage of a series of augmentation relations,
analogous to the Zhou-Cong-Chen model. We apply the model on small handwritten
digits, and a large experimental dataset of DNA mutations in cancer, and we
show how the model is able to extract biologically meaningful meta-signatures
in a fully data-driven way.
</p>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16956" title="Abstract">arXiv:2311.16956</a> (cross-list from math.OC) [<a href="/pdf/2311.16956" title="Download PDF">pdf</a>, <a href="/format/2311.16956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Step Sizes for Preconditioned Stochastic Gradient Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=K%C3%B6hne%2C+F">Frederik K&#xf6;hne</a>, 
<a href="/search/math?searchtype=author&query=Kreis%2C+L">Leonie Kreis</a>, 
<a href="/search/math?searchtype=author&query=Schiela%2C+A">Anton Schiela</a>, 
<a href="/search/math?searchtype=author&query=Herzog%2C+R">Roland Herzog</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper proposes a novel approach to adaptive step sizes in stochastic
gradient descent (SGD) by utilizing quantities that we have identified as
numerically traceable -- the Lipschitz constant for gradients and a concept of
the local variance in search directions. Our findings yield a nearly
hyperparameter-free algorithm for stochastic optimization, which has provable
convergence properties when applied to quadratic problems and exhibits truly
problem adaptive behavior on classical image classification tasks. Our
framework enables the potential inclusion of a preconditioner, thereby enabling
the implementation of adaptive step sizes for stochastic second-order
optimization methods.
</p>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16964" title="Abstract">arXiv:2311.16964</a> (cross-list from cond-mat.dis-nn) [<a href="/pdf/2311.16964" title="Download PDF">pdf</a>, <a href="/format/2311.16964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine learning force-field models for metallic spin glass
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Shi%2C+M">Menglin Shi</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zhang%2C+S">Sheng Zhang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Chern%2C+G">Gia-Wei Chern</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Disordered Systems and Neural Networks (cond-mat.dis-nn)</span>; Materials Science (cond-mat.mtrl-sci); Machine Learning (cs.LG)

</div>
<p class="mathjax">Metallic spin glass systems, such as dilute magnetic alloys, are
characterized by randomly distributed local moments coupled to each other
through a long-range electron-mediated effective interaction. We present a
scalable machine learning (ML) framework for dynamical simulations of metallic
spin glasses. A Behler-Parrinello type neural-network model, based on the
principle of locality, is developed to accurately and efficiently predict
electron-induced local magnetic fields that drive the spin dynamics. A crucial
component of the ML model is a proper symmetry-invariant representation of
local magnetic environment which is direct input to the neural net. We develop
such a magnetic descriptor by incorporating the spin degrees of freedom into
the atom-centered symmetry function methods which are widely used in ML
force-field models for quantum molecular dynamics. We apply our approach to
study the relaxation dynamics of an amorphous generalization of the s-d model.
Our work highlights the promising potential of ML models for large-scale
dynamical modeling of itinerant magnets with quenched disorder.
</p>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16975" title="Abstract">arXiv:2311.16975</a> (cross-list from math.OC) [<a href="/pdf/2311.16975" title="Download PDF">pdf</a>, <a href="/format/2311.16975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Managing Vehicle Charging During Emergencies via Conservative  Distribution System Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Aquino%2C+A+D+O">Alejandro D. Owen Aquino</a>, 
<a href="/search/math?searchtype=author&query=Talkington%2C+S">Samuel Talkington</a>, 
<a href="/search/math?searchtype=author&query=Molzahn%2C+D+K">Daniel K. Molzahn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Combinatorial distribution system optimization problems, such as scheduling
electric vehicle (EV) charging during evacuations, present significant
computational challenges. These challenges stem from the large numbers of
constraints, continuous variables, and discrete variables, coupled with the
unbalanced nature of distribution systems. In response to the escalating
frequency of extreme events impacting electric power systems, this paper
introduces a method that integrates sample-based conservative linear power flow
approximations (CLAs) into an optimization framework. In particular, this
integration aims to ameliorate the aforementioned challenges of distribution
system optimization in the context of efficiently minimizing the charging time
required for EVs in urban evacuation scenarios.
</p>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16983" title="Abstract">arXiv:2311.16983</a> (cross-list from eess.SP) [<a href="/pdf/2311.16983" title="Download PDF">pdf</a>, <a href="/format/2311.16983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HARQ Retransmissions in C-V2X: A BSM Latency Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fouda%2C+A">Abdurrahman Fouda</a>, 
<a href="/search/eess?searchtype=author&query=Berry%2C+R">Randall Berry</a>, 
<a href="/search/eess?searchtype=author&query=Vukovic%2C+I">Ivan Vukovic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Cellular vehicular-to-everything (C-V2X) systems offer the potential for
improving road safety, in part through the exchange of periodic basic safety
messages (BSMs) between nearby vehicles. The reliability and latency of these
messages is a key metric. Hybrid automatic repeat request (HARQ)
retransmissions are one technique used to this end. However, HARQ may come at
the expense of consuming the limited available wireless resources, especially
in highly congested scenarios. This paper studies BSM transmission latency and
reliability when HARQ retransmissions are used with the semi-persistent
scheduling (SPS) in C-V2X transmission mode 4. We do so through extensive
system-level simulations that closely follow the SPS process. Furthermore, we
provide an analytical model for the tail behavior of the BSM latency
distribution with HARQ retransmissions that is a good approximation to the
simulation results. Our study reveals the impact of several deployment settings
(e.g., bandwidth configurations and vehicle density).
</p>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16984" title="Abstract">arXiv:2311.16984</a> (cross-list from stat.ME) [<a href="/pdf/2311.16984" title="Download PDF">pdf</a>, <a href="/format/2311.16984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedECA: A Federated External Control Arm Method for Causal Inference  with Time-To-Event Data in Distributed Settings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Terrail%2C+J+O+d">Jean Ogier du Terrail</a>, 
<a href="/search/stat?searchtype=author&query=Klopfenstein%2C+Q">Quentin Klopfenstein</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+H">Honghao Li</a>, 
<a href="/search/stat?searchtype=author&query=Mayer%2C+I">Imke Mayer</a>, 
<a href="/search/stat?searchtype=author&query=Loiseau%2C+N">Nicolas Loiseau</a>, 
<a href="/search/stat?searchtype=author&query=Hallal%2C+M">Mohammad Hallal</a>, 
<a href="/search/stat?searchtype=author&query=Balazard%2C+F">F&#xe9;lix Balazard</a>, 
<a href="/search/stat?searchtype=author&query=Andreux%2C+M">Mathieu Andreux</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> code available at: <a href="https://github.com/owkin/fedeca">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
<p class="mathjax">External control arms (ECA) can inform the early clinical development of
experimental drugs and provide efficacy evidence for regulatory approval in
non-randomized settings. However, the main challenge of implementing ECA lies
in accessing real-world data or historical clinical trials. Indeed, data
sharing is often not feasible due to privacy considerations related to data
leaving the original collection centers, along with pharmaceutical companies'
competitive motives. In this paper, we leverage a privacy-enhancing technology
called federated learning (FL) to remove some of the barriers to data sharing.
We introduce a federated learning inverse probability of treatment weighted
(IPTW) method for time-to-event outcomes called FedECA which eases the
implementation of ECA by limiting patients' data exposure. We show with
extensive experiments that FedECA outperforms its closest competitor,
matching-adjusted indirect comparison (MAIC), in terms of statistical power and
ability to balance the treatment and control groups. To encourage the use of
such methods, we publicly release our code which relies on Substra, an
open-source FL software with proven experience in privacy-sensitive contexts.
</p>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17052" title="Abstract">arXiv:2311.17052</a> (cross-list from math.PR) [<a href="/pdf/2311.17052" title="Download PDF">pdf</a>, <a href="/format/2311.17052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A large-scale particle system with independent jumps and distributed  synchronization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Baryshnikov%2C+Y">Yuliy Baryshnikov</a>, 
<a href="/search/math?searchtype=author&query=Stolyar%2C+A">Alexander Stolyar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">We study a system consisting of $n$ particles, moving forward in jumps on the
real line. Each particle can make both independent jumps, whose sizes have some
distribution, or ``synchronization'' jumps, which allow it to join a randomly
chosen other particle if the latter happens to be ahead of it. The mean-field
asymptotic regime, where $n\to\infty$, is considered. As $n\to\infty$, we prove
the convergence of the system dynamics to that of a deterministic mean-field
limit (MFL). We obtain results on the average speed of advance of a
``benchmark'' MFL (BMFL) and the liminf of the steady-state speed of advance,
in terms of MFLs that are traveling waves. For the special case of
exponentially distributed independent jump sizes, we prove that a traveling
wave MFL with speed $v$ exists if and only if $v\ge v_*$, with $v_*$ having
simple explicit form; this allows us to show that the average speed of the BMFL
is equal to $v_*$ and the liminf of the steady-state speeds is lower bounded by
$v_*$. Finally, we put forward a conjecture that both the average speed of the
BMFL and the exact limit of the steady-state speeds, under general distribution
of an independent jump size, are equal to number $v_{**}$, which is easily
found from a ``minimum speed principle.'' This general conjecture is consistent
with our results for the exponentially distributed jumps and is confirmed by
simulations.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Wed, 29 Nov 23</h3>
<dl>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2006.06160" title="Abstract">arXiv:2006.06160</a> (replaced) [<a href="/e-print/2006.06160" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The block mutual coherence property condition for signal recovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jianwen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hailin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Feng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianjun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jinping Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The content and structure of the article have been greatly adjusted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2007.10784" title="Abstract">arXiv:2007.10784</a> (replaced) [<a href="/pdf/2007.10784" title="Download PDF">pdf</a>, <a href="/format/2007.10784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OccamNet: A Fast Neural Model for Symbolic Regression at Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dugan%2C+O">Owen Dugan</a>, 
<a href="/search/cs?searchtype=author&query=Dangovski%2C+R">Rumen Dangovski</a>, 
<a href="/search/cs?searchtype=author&query=Costa%2C+A">Allan Costa</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Samuel Kim</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+P">Pawan Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Jacobson%2C+J">Joseph Jacobson</a>, 
<a href="/search/cs?searchtype=author&query=Solja%C4%8Di%C4%87%2C+M">Marin Solja&#x10d;i&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2102.10509" title="Abstract">arXiv:2102.10509</a> (replaced) [<a href="/pdf/2102.10509" title="Download PDF">pdf</a>, <a href="/ps/2102.10509" title="Download PostScript">ps</a>, <a href="/format/2102.10509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Partition and Analytic Rank are Equivalent over Large Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cohen%2C+A">Alex Cohen</a>, 
<a href="/search/math?searchtype=author&query=Moshkovitz%2C+G">Guy Moshkovitz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appeared in Duke Mathematical Journal
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Duke Mathematical Journal 172 (2023), 2433-2470
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Complexity (cs.CC); Algebraic Geometry (math.AG)

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2105.08124" title="Abstract">arXiv:2105.08124</a> (replaced) [<a href="/pdf/2105.08124" title="Download PDF">pdf</a>, <a href="/format/2105.08124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Planar Drawings with Few Slopes of Halin Graphs and Nested Pseudotrees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chaplick%2C+S">Steven Chaplick</a>, 
<a href="/search/cs?searchtype=author&query=Da+Lozzo%2C+G">Giordano Da Lozzo</a>, 
<a href="/search/cs?searchtype=author&query=Di+Giacomo%2C+E">Emilio Di Giacomo</a>, 
<a href="/search/cs?searchtype=author&query=Liotta%2C+G">Giuseppe Liotta</a>, 
<a href="/search/cs?searchtype=author&query=Montecchiani%2C+F">Fabrizio Montecchiani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of "Planar Drawings with Few Slopes of Halin Graphs and Nested Pseudotrees" appeared in the Proceedings of the 17th Algorithms and Data Structures Symposium (WADS 2021)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.14756" title="Abstract">arXiv:2106.14756</a> (replaced) [<a href="/pdf/2106.14756" title="Download PDF">pdf</a>, <a href="/format/2106.14756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially Private Algorithms for Graphs Under Continual Observation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fichtenberger%2C+H">Hendrik Fichtenberger</a>, 
<a href="/search/cs?searchtype=author&query=Henzinger%2C+M">Monika Henzinger</a>, 
<a href="/search/cs?searchtype=author&query=Ost%2C+W">Wolfgang Ost</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Corrected typos in lower bounds in Table 1. Fixed missing factor $\ell$ in statement of Theorem 45
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.02541" title="Abstract">arXiv:2108.02541</a> (replaced) [<a href="/pdf/2108.02541" title="Download PDF">pdf</a>, <a href="/format/2108.02541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Foundations of User-Centric Cell-Free Massive MIMO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Demir%2C+%C3%96+T">&#xd6;zlem Tu&#x11f;fe Demir</a>, 
<a href="/search/cs?searchtype=author&query=Bj%C3%B6rnson%2C+E">Emil Bj&#xf6;rnson</a>, 
<a href="/search/cs?searchtype=author&query=Sanguinetti%2C+L">Luca Sanguinetti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the authors' version of the manuscript: \"Ozlem Tugfe Demir, Emil Bj\"ornson and Luca Sanguinetti (2021), "Foundations of User-Centric Cell-Free Massive MIMO", Foundations and Trends in Signal Processing: Vol. 14, No. 3-4, pp 162-472
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Foundations and Trends in Signal Processing: Vol. 14, No. 3-4, pp
  162-472 (2021)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.04840" title="Abstract">arXiv:2108.04840</a> (replaced) [<a href="/pdf/2108.04840" title="Download PDF">pdf</a>, <a href="/format/2108.04840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Post-hoc Interpretability for Neural NLP: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Madsen%2C+A">Andreas Madsen</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+S">Siva Reddy</a>, 
<a href="/search/cs?searchtype=author&query=Chandar%2C+S">Sarath Chandar</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM Comput. Surv. 55, 8, Article 155 (December 2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.06296" title="Abstract">arXiv:2109.06296</a> (replaced) [<a href="/pdf/2109.06296" title="Download PDF">pdf</a>, <a href="/format/2109.06296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monocular Camera Localization for Automated Vehicles Using Image  Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joa%2C+E">Eunhyek Joa</a>, 
<a href="/search/cs?searchtype=author&query=Borrelli%2C+F">Francesco Borrelli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.01566" title="Abstract">arXiv:2111.01566</a> (replaced) [<a href="/pdf/2111.01566" title="Download PDF">pdf</a>, <a href="/format/2111.01566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strategyproof and Proportionally Fair Facility Location
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aziz%2C+H">Haris Aziz</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+A">Alexander Lam</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+B+E">Barton E. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Walsh%2C+T">Toby Walsh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Theoretical Economics (econ.TH)

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.09957" title="Abstract">arXiv:2111.09957</a> (replaced) [<a href="/pdf/2111.09957" title="Download PDF">pdf</a>, <a href="/format/2111.09957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Dilated Convolution for Real-time Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+R">Roland Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2023 Efficient CV workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.10085" title="Abstract">arXiv:2111.10085</a> (replaced) [<a href="/pdf/2111.10085" title="Download PDF">pdf</a>, <a href="/format/2111.10085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mate! Are You Really Aware? An Explainability-Guided Testing Framework  for Robustness of Malware Detectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+R">Ruoxi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+M">Minhui Xue</a>, 
<a href="/search/cs?searchtype=author&query=Tyson%2C+G">Gareth Tyson</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+T">Tian Dong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shaofeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Haojin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Camtepe%2C+S">Seyit Camtepe</a>, 
<a href="/search/cs?searchtype=author&query=Nepal%2C+S">Surya Nepal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ESEC/FSE 2023. <a href="https://doi.org/10.1145/3611643.3616309">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.03002" title="Abstract">arXiv:2112.03002</a> (replaced) [<a href="/pdf/2112.03002" title="Download PDF">pdf</a>, <a href="/format/2112.03002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraphPrompt: Graph-Based Prompt Templates for Biomedical Synonym  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hanwen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiayou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhirui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shizhuo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bhalerao%2C+M+M">Megh Manoj Bhalerao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yucong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+D">Dawei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sheng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.05760" title="Abstract">arXiv:2201.05760</a> (replaced) [<a href="/pdf/2201.05760" title="Download PDF">pdf</a>, <a href="/ps/2201.05760" title="Download PostScript">ps</a>, <a href="/format/2201.05760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Big Data Analytics for Network Level Short-Term Travel Time Prediction  with Hierarchical LSTM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T+T">Tianya T. Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.04664" title="Abstract">arXiv:2203.04664</a> (replaced) [<a href="/pdf/2203.04664" title="Download PDF">pdf</a>, <a href="/format/2203.04664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Complete combinatorial characterization of greedy-drawable trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Miyata%2C+H">Hiroyuki Miyata</a>, 
<a href="/search/math?searchtype=author&query=Nosaka%2C+R">Reiya Nosaka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 30 fugures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Geometry (cs.CG)

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.01930" title="Abstract">arXiv:2204.01930</a> (replaced) [<a href="/pdf/2204.01930" title="Download PDF">pdf</a>, <a href="/format/2204.01930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Control Barrier Function Based Design of Gradient Flows for Constrained  Nonlinear Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Allibhoy%2C+A">Ahmed Allibhoy</a>, 
<a href="/search/math?searchtype=author&query=Cort%C3%A9s%2C+J">Jorge Cort&#xe9;s</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.01370" title="Abstract">arXiv:2206.01370</a> (replaced) [<a href="/pdf/2206.01370" title="Download PDF">pdf</a>, <a href="/format/2206.01370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Improving the Generation Quality of Autoregressive Slot VAEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Emami%2C+P">Patrick Emami</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+P">Pan He</a>, 
<a href="/search/cs?searchtype=author&query=Ranka%2C+S">Sanjay Ranka</a>, 
<a href="/search/cs?searchtype=author&query=Rangarajan%2C+A">Anand Rangarajan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Neural Computation. 38 pages, 18 figures. Code and videos available at <a href="https://github.com/pemami4911/segregate-relate-imagine">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.02541" title="Abstract">arXiv:2206.02541</a> (replaced) [<a href="/pdf/2206.02541" title="Download PDF">pdf</a>, <a href="/ps/2206.02541" title="Download PostScript">ps</a>, <a href="/format/2206.02541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PCPT and ACPT: Copyright Protection and Traceability Scheme for DNN  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xuefeng Fan</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+D">Dahao Fu</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+H">Hangyu Gui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinpeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaoyi Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.06573" title="Abstract">arXiv:2206.06573</a> (replaced) [<a href="/pdf/2206.06573" title="Download PDF">pdf</a>, <a href="/ps/2206.06573" title="Download PostScript">ps</a>, <a href="/format/2206.06573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speech intelligibility of simulated hearing loss sounds and its  prediction using the Gammachirp Envelope Similarity Index (GESI)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Irino%2C+T">Toshio Irino</a>, 
<a href="/search/cs?searchtype=author&query=Tamaru%2C+H">Honoka Tamaru</a>, 
<a href="/search/cs?searchtype=author&query=Yamamoto%2C+A">Ayako Yamamoto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This preprint is a copy of the final version accepted for Interspeech 2022. See <a href="https://doi.org/10.21437/Interspeech.2022-211">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proc. Interspeech 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.06604" title="Abstract">arXiv:2206.06604</a> (replaced) [<a href="/pdf/2206.06604" title="Download PDF">pdf</a>, <a href="/format/2206.06604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WHIS: Hearing impairment simulator based on the gammachirp auditory  filterbank
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Irino%2C+T">Toshio Irino</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This preprint was an original version that was unsuccessfully submitted to Trends in Hearing on June 5, 2022. The revised version has been accepted for publication in IEEE access. See <a href="https://doi.org/10.1109/ACCESS.2023.3298673">this https URL</a> ( <a href="https://ieeexplore.ieee.org/document/10193769">this https URL</a> )
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE access, 25 July 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.08164" title="Abstract">arXiv:2206.08164</a> (replaced) [<a href="/pdf/2206.08164" title="Download PDF">pdf</a>, <a href="/format/2206.08164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Long Range Graph Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dwivedi%2C+V+P">Vijay Prakash Dwivedi</a>, 
<a href="/search/cs?searchtype=author&query=Ramp%C3%A1%C5%A1ek%2C+L">Ladislav Ramp&#xe1;&#x161;ek</a>, 
<a href="/search/cs?searchtype=author&query=Galkin%2C+M">Mikhail Galkin</a>, 
<a href="/search/cs?searchtype=author&query=Parviz%2C+A">Ali Parviz</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+G">Guy Wolf</a>, 
<a href="/search/cs?searchtype=author&query=Luu%2C+A+T">Anh Tuan Luu</a>, 
<a href="/search/cs?searchtype=author&query=Beaini%2C+D">Dominique Beaini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Added reference to T\"onshoff et al., 2023 in Sec. 4.1; NeurIPS 2022 Track on D&amp;B; Open-sourced at: <a href="https://github.com/vijaydwivedi75/lrgb">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.10479" title="Abstract">arXiv:2206.10479</a> (replaced) [<a href="/pdf/2206.10479" title="Download PDF">pdf</a>, <a href="/format/2206.10479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Policy Learning with Asymmetric Counterfactual Utilities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ben-Michael%2C+E">Eli Ben-Michael</a>, 
<a href="/search/stat?searchtype=author&query=Imai%2C+K">Kosuke Imai</a>, 
<a href="/search/stat?searchtype=author&query=Jiang%2C+Z">Zhichao Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.11792" title="Abstract">arXiv:2206.11792</a> (replaced) [<a href="/pdf/2206.11792" title="Download PDF">pdf</a>, <a href="/format/2206.11792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two-dimensional total absorption spectroscopy with conditional  generative adversarial networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/nucl-ex?searchtype=author&query=Dembski%2C+C">Cade Dembski</a>, 
<a href="/search/nucl-ex?searchtype=author&query=Kuchera%2C+M+P">Michelle P. Kuchera</a>, 
<a href="/search/nucl-ex?searchtype=author&query=Liddick%2C+S">Sean Liddick</a>, 
<a href="/search/nucl-ex?searchtype=author&query=Ramanujan%2C+R">Raghu Ramanujan</a>, 
<a href="/search/nucl-ex?searchtype=author&query=Spyrou%2C+A">Artemis Spyrou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Nuclear Experiment (nucl-ex)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.12938" title="Abstract">arXiv:2206.12938</a> (replaced) [<a href="/pdf/2206.12938" title="Download PDF">pdf</a>, <a href="/ps/2206.12938" title="Download PostScript">ps</a>, <a href="/format/2206.12938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stackelberg Risk Preference Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+S">Shutian Liu</a>, 
<a href="/search/math?searchtype=author&query=Zhu%2C+Q">Quanyan Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 0 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.13269" title="Abstract">arXiv:2206.13269</a> (replaced) [<a href="/pdf/2206.13269" title="Download PDF">pdf</a>, <a href="/format/2206.13269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wasserstein Distributionally Robust Estimation in High Dimensions:  Performance Analysis and Optimal Hyperparameter Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Aolaritei%2C+L">Liviu Aolaritei</a>, 
<a href="/search/stat?searchtype=author&query=Shafiee%2C+S">Soroosh Shafiee</a>, 
<a href="/search/stat?searchtype=author&query=D%C3%B6rfler%2C+F">Florian D&#xf6;rfler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was previously titled "The Performance of Wasserstein Distributionally Robust M-Estimators in High Dimensions"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.03017" title="Abstract">arXiv:2207.03017</a> (replaced) [<a href="/pdf/2207.03017" title="Download PDF">pdf</a>, <a href="/format/2207.03017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ACHO: Adaptive Conformal Hyperparameter Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doyle%2C+R">Riccardo Doyle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 tables, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.08892" title="Abstract">arXiv:2207.08892</a> (replaced) [<a href="/pdf/2207.08892" title="Download PDF">pdf</a>, <a href="/format/2207.08892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Differentiable Dynamic Game for Multi-robot Coordination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yizhi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+W">Wanxin Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.02705" title="Abstract">arXiv:2208.02705</a> (replaced) [<a href="/pdf/2208.02705" title="Download PDF">pdf</a>, <a href="/format/2208.02705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 360Roam: Real-Time Indoor Roaming Using Geometry-Aware 360$^\circ$  Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Huajian Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yingshu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianjia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yeung%2C+S">Sai-Kit Yeung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.13465" title="Abstract">arXiv:2208.13465</a> (replaced) [<a href="/pdf/2208.13465" title="Download PDF">pdf</a>, <a href="/format/2208.13465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Semantic Attributes from A Foundation Model for Federated  Learning of Disjoint Label Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shitong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+C">Chenyang Si</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+G">Guile Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+S">Shaogang Gong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.08289" title="Abstract">arXiv:2209.08289</a> (replaced) [<a href="/pdf/2209.08289" title="Download PDF">pdf</a>, <a href="/format/2209.08289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuously Controllable Facial Expression Editing in Talking Face  Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhiyao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yu-Hui Wen</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+T">Tian Lv</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yanan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaoyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong-Jin Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Affective Computing (DOI: 10.1109/TAFFC.2023.3334511). Demo video: <a href="https://youtu.be/WD-bNVya6kM">this https URL</a> . Project page: <a href="https://raineggplant.github.io/FEE4TV">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.02804" title="Abstract">arXiv:2210.02804</a> (replaced) [<a href="/pdf/2210.02804" title="Download PDF">pdf</a>, <a href="/format/2210.02804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Just ClozE! A Novel Framework for Evaluating the Factual Consistency  Faster in Abstractive Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Litvak%2C+M">Marina Litvak</a>, 
<a href="/search/cs?searchtype=author&query=Vanetik%2C+N">Natalia Vanetik</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+D">Dingxin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuze Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yanquan Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The manuscript for JAIR
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.10173" title="Abstract">arXiv:2210.10173</a> (replaced) [<a href="/pdf/2210.10173" title="Download PDF">pdf</a>, <a href="/format/2210.10173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster Matrix Multiplication via Asymmetric Hashing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+R">Ran Duan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hongxun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+R">Renfei Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 87 pages, in FOCS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.13788" title="Abstract">arXiv:2210.13788</a> (replaced) [<a href="/pdf/2210.13788" title="Download PDF">pdf</a>, <a href="/format/2210.13788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Axioms for a theory of signature bases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lairez%2C+P">Pierre Lairez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Commutative Algebra (math.AC)

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.00573" title="Abstract">arXiv:2211.00573</a> (replaced) [<a href="/pdf/2211.00573" title="Download PDF">pdf</a>, <a href="/format/2211.00573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Analysis and Optimization of Fast Conditional Handover with Hand  Blockage for Mobility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Iqbal%2C+S+B">Subhyal Bin Iqbal</a>, 
<a href="/search/cs?searchtype=author&query=Nadaf%2C+S">Salman Nadaf</a>, 
<a href="/search/cs?searchtype=author&query=Awada%2C+A">Ahmad Awada</a>, 
<a href="/search/cs?searchtype=author&query=Karabulut%2C+U">Umur Karabulut</a>, 
<a href="/search/cs?searchtype=author&query=Schulz%2C+P">Philipp Schulz</a>, 
<a href="/search/cs?searchtype=author&query=Fettweis%2C+G+P">Gerhard P. Fettweis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted IEEE Access journal publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.02760" title="Abstract">arXiv:2211.02760</a> (replaced) [<a href="/pdf/2211.02760" title="Download PDF">pdf</a>, <a href="/ps/2211.02760" title="Download PostScript">ps</a>, <a href="/format/2211.02760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Development and evaluation of automated localisation and reconstruction  of all fruits on tomato plants in a greenhouse based on multi-view perception  and 3D multi-object tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rincon%2C+D+R">David Rapado Rincon</a>, 
<a href="/search/cs?searchtype=author&query=van+Henten%2C+E+J">Eldert J. van Henten</a>, 
<a href="/search/cs?searchtype=author&query=Kootstra%2C+G">Gert Kootstra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.04601" title="Abstract">arXiv:2211.04601</a> (replaced) [<a href="/pdf/2211.04601" title="Download PDF">pdf</a>, <a href="/format/2211.04601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unifying Instance Optimality for Static Problems: A Case Study on  Sorting a DAG
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goswami%2C+M">Mayank Goswami</a>, 
<a href="/search/cs?searchtype=author&query=Jacob%2C+R">Riko Jacob</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.05228" title="Abstract">arXiv:2211.05228</a> (replaced) [<a href="/pdf/2211.05228" title="Download PDF">pdf</a>, <a href="/format/2211.05228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FIXED: Frustratingly Easy Domain Generalization with Mixup
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Wang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jindong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Han Yu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Lei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiqiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> First Conference on Parsimony and Learning (CPAL) 2024; code for DG at: <a href="https://github.com/jindongwang/transferlearning/tree/master/code/DeepDG">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.13131" title="Abstract">arXiv:2211.13131</a> (replaced) [<a href="/pdf/2211.13131" title="Download PDF">pdf</a>, <a href="/format/2211.13131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FeTrIL: Feature Translation for Exemplar-Free Class-Incremental Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Petit%2C+G">Gr&#xe9;goire Petit</a>, 
<a href="/search/cs?searchtype=author&query=Popescu%2C+A">Adrian Popescu</a>, 
<a href="/search/cs?searchtype=author&query=Schindler%2C+H">Hugo Schindler</a>, 
<a href="/search/cs?searchtype=author&query=Picard%2C+D">David Picard</a>, 
<a href="/search/cs?searchtype=author&query=Delezoide%2C+B">Bertrand Delezoide</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.03085" title="Abstract">arXiv:2212.03085</a> (replaced) [<a href="/pdf/2212.03085" title="Download PDF">pdf</a>, <a href="/format/2212.03085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthesizing nested relational queries from implicit specifications: via  model theory and via proof theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Benedikt%2C+M">Michael Benedikt</a>, 
<a href="/search/cs?searchtype=author&query=Pradic%2C+C">C&#xe9;cilia Pradic</a>, 
<a href="/search/cs?searchtype=author&query=Wernhard%2C+C">Christoph Wernhard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2209.08299">arXiv:2209.08299</a>, <a href="/abs/2005.06503">arXiv:2005.06503</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.04548" title="Abstract">arXiv:2212.04548</a> (replaced) [<a href="/e-print/2212.04548" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STLGRU: Spatio-Temporal Lightweight Graph GRU for Traffic Flow  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhaumik%2C+K+K">Kishor Kumar Bhaumik</a>, 
<a href="/search/cs?searchtype=author&query=Niloy%2C+F+F">Fahim Faisal Niloy</a>, 
<a href="/search/cs?searchtype=author&query=Mahmud%2C+S">Saif Mahmud</a>, 
<a href="/search/cs?searchtype=author&query=Woo%2C+S">Simon Woo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We withdraw for now and shall further work on the manuscript and upload it again
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.09744" title="Abstract">arXiv:2212.09744</a> (replaced) [<a href="/pdf/2212.09744" title="Download PDF">pdf</a>, <a href="/format/2212.09744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DSI++: Updating Transformer Memory with New Documents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mehta%2C+S+V">Sanket Vaibhav Mehta</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+J">Jai Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Tay%2C+Y">Yi Tay</a>, 
<a href="/search/cs?searchtype=author&query=Dehghani%2C+M">Mostafa Dehghani</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+V+Q">Vinh Q. Tran</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+J">Jinfeng Rao</a>, 
<a href="/search/cs?searchtype=author&query=Najork%2C+M">Marc Najork</a>, 
<a href="/search/cs?searchtype=author&query=Strubell%2C+E">Emma Strubell</a>, 
<a href="/search/cs?searchtype=author&query=Metzler%2C+D">Donald Metzler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP 2023 main conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.03178" title="Abstract">arXiv:2301.03178</a> (replaced) [<a href="/pdf/2301.03178" title="Download PDF">pdf</a>, <a href="/format/2301.03178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Planar Parallax for Monocular Depth Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+H">Haoqian Liang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhichao Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Ya Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Naiyan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.03574" title="Abstract">arXiv:2301.03574</a> (replaced) [<a href="/pdf/2301.03574" title="Download PDF">pdf</a>, <a href="/ps/2301.03574" title="Download PostScript">ps</a>, <a href="/format/2301.03574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sharp preasymptotic error bounds for the Helmholtz $h$-FEM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Galkowski%2C+J">Jeffrey Galkowski</a>, 
<a href="/search/math?searchtype=author&query=Spence%2C+E+A">Euan A. Spence</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.08988" title="Abstract">arXiv:2301.08988</a> (replaced) [<a href="/pdf/2301.08988" title="Download PDF">pdf</a>, <a href="/ps/2301.08988" title="Download PostScript">ps</a>, <a href="/format/2301.08988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Matchings under distance constraints II
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Madarasi%2C+P">P&#xe9;ter Madarasi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10575" title="Abstract">arXiv:2301.10575</a> (replaced) [<a href="/pdf/2301.10575" title="Download PDF">pdf</a>, <a href="/format/2301.10575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trainable Loss Weights in Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mellatshahi%2C+A+C">Arash Chaichi Mellatshahi</a>, 
<a href="/search/cs?searchtype=author&query=Kasaei%2C+S">Shohreh Kasaei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures, 2 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12115" title="Abstract">arXiv:2301.12115</a> (replaced) [<a href="/pdf/2301.12115" title="Download PDF">pdf</a>, <a href="/format/2301.12115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing expected moments of the R&#xe9;nyi parking problem on the circle
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hegland%2C+M">Markus Hegland</a>, 
<a href="/search/math?searchtype=author&query=Burden%2C+C+J">Conrad J. Burden</a>, 
<a href="/search/math?searchtype=author&query=Stachurski%2C+Z">Zbigniew Stachurski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.13098" title="Abstract">arXiv:2301.13098</a> (replaced) [<a href="/pdf/2301.13098" title="Download PDF">pdf</a>, <a href="/format/2301.13098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CHeart: A Conditional Spatio-Temporal Generative Model for Cardiac  Anatomy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Qiao%2C+M">Mengyun Qiao</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+S">Shuo Wang</a>, 
<a href="/search/eess?searchtype=author&query=Qiu%2C+H">Huaqi Qiu</a>, 
<a href="/search/eess?searchtype=author&query=de+Marvao%2C+A">Antonio de Marvao</a>, 
<a href="/search/eess?searchtype=author&query=O%27Regan%2C+D+P">Declan P. O&#x27;Regan</a>, 
<a href="/search/eess?searchtype=author&query=Rueckert%2C+D">Daniel Rueckert</a>, 
<a href="/search/eess?searchtype=author&query=Bai%2C+W">Wenjia Bai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.04023" title="Abstract">arXiv:2302.04023</a> (replaced) [<a href="/pdf/2302.04023" title="Download PDF">pdf</a>, <a href="/format/2302.04023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on  Reasoning, Hallucination, and Interactivity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bang%2C+Y">Yejin Bang</a>, 
<a href="/search/cs?searchtype=author&query=Cahyawijaya%2C+S">Samuel Cahyawijaya</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+N">Nayeon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+W">Wenliang Dai</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+D">Dan Su</a>, 
<a href="/search/cs?searchtype=author&query=Wilie%2C+B">Bryan Wilie</a>, 
<a href="/search/cs?searchtype=author&query=Lovenia%2C+H">Holy Lovenia</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Z">Ziwei Ji</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tiezheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+W">Willy Chung</a>, 
<a href="/search/cs?searchtype=author&query=Do%2C+Q+V">Quyet V. Do</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Fung%2C+P">Pascale Fung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages, AACL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.07221" title="Abstract">arXiv:2302.07221</a> (replaced) [<a href="/pdf/2302.07221" title="Download PDF">pdf</a>, <a href="/format/2302.07221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Role of Randomization in Adversarially Robust Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gnecco-Heredia%2C+L">Lucas Gnecco-Heredia</a>, 
<a href="/search/cs?searchtype=author&query=Chevaleyre%2C+Y">Yann Chevaleyre</a>, 
<a href="/search/cs?searchtype=author&query=Negrevergne%2C+B">Benjamin Negrevergne</a>, 
<a href="/search/cs?searchtype=author&query=Meunier%2C+L">Laurent Meunier</a>, 
<a href="/search/cs?searchtype=author&query=Pydi%2C+M+S">Muni Sreenivas Pydi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages main paper (27 total), 2 figures in main paper. Neurips 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09554" title="Abstract">arXiv:2302.09554</a> (replaced) [<a href="/pdf/2302.09554" title="Download PDF">pdf</a>, <a href="/format/2302.09554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixed Hierarchy Network for Image Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Hu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+D">Depeng Dang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.10498" title="Abstract">arXiv:2302.10498</a> (replaced) [<a href="/pdf/2302.10498" title="Download PDF">pdf</a>, <a href="/ps/2302.10498" title="Download PostScript">ps</a>, <a href="/format/2302.10498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Output Feedback Stochastic MPC with Hard Input Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Joa%2C+E">Eunhyek Joa</a>, 
<a href="/search/eess?searchtype=author&query=Bujarbaruah%2C+M">Monimoy Bujarbaruah</a>, 
<a href="/search/eess?searchtype=author&query=Borrelli%2C+F">Francesco Borrelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE American Control Conference (ACC) 2023, May 31 - June 2, San Diego, CA, USA
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 American Control Conference (ACC) (pp. 2034-2039). IEEE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.12353" title="Abstract">arXiv:2302.12353</a> (replaced) [<a href="/pdf/2302.12353" title="Download PDF">pdf</a>, <a href="/ps/2302.12353" title="Download PostScript">ps</a>, <a href="/format/2302.12353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous Restructuring of Asteroids into Rotating Space Stations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Jensen%2C+D+W">David W. Jensen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 65 pages, 53 figures, 25 tables; Version 2 includes editorial changes, improved dumbbell stability details, and reference updates and additions
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Popular Physics (physics.pop-ph)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00208" title="Abstract">arXiv:2303.00208</a> (replaced) [<a href="/pdf/2303.00208" title="Download PDF">pdf</a>, <a href="/format/2303.00208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Myersonian Framework for Optimal Liquidity Provision in Automated  Market Makers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Milionis%2C+J">Jason Milionis</a>, 
<a href="/search/cs?searchtype=author&query=Moallemi%2C+C+C">Ciamac C. Moallemi</a>, 
<a href="/search/cs?searchtype=author&query=Roughgarden%2C+T">Tim Roughgarden</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, to appear in the 15th Innovations in Theoretical Computer Science conference (ITCS 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH); Mathematical Finance (q-fin.MF); Trading and Market Microstructure (q-fin.TR)

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01345" title="Abstract">arXiv:2303.01345</a> (replaced) [<a href="/pdf/2303.01345" title="Download PDF">pdf</a>, <a href="/format/2303.01345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PlaNet-ClothPick: Effective Fabric Flattening Based on Latent Dynamic  Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kadi%2C+H+A">Halid Abdulrahim Kadi</a>, 
<a href="/search/cs?searchtype=author&query=Terzic%2C+K">Kasim Terzic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 2 tables, and 14 figures. It has been accepted to The 2024 16th IEEE/SICE International Symposium on System Integration, Ha Long, Vietnam 8-11th January, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01928" title="Abstract">arXiv:2303.01928</a> (replaced) [<a href="/pdf/2303.01928" title="Download PDF">pdf</a>, <a href="/format/2303.01928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FairShap: A Data Re-weighting Approach for Algorithmic Fairness based on  Shapley Values
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arnaiz-Rodriguez%2C+A">Adrian Arnaiz-Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Oliver%2C+N">Nuria Oliver</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 11 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05244" title="Abstract">arXiv:2303.05244</a> (replaced) [<a href="/pdf/2303.05244" title="Download PDF">pdf</a>, <a href="/ps/2303.05244" title="Download PostScript">ps</a>, <a href="/format/2303.05244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transport via Partial Galois Connections and Equivalences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kappelmann%2C+K">Kevin Kappelmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages; extended version from 21st Asian Symposium on Programming Languages and Systems, 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Asian Symposium on Programming Languages and Systems APLAS 2023:
  Programming Languages and Systems, 225-245
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06222" title="Abstract">arXiv:2303.06222</a> (replaced) [<a href="/pdf/2303.06222" title="Download PDF">pdf</a>, <a href="/format/2303.06222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust MADER: Decentralized Multiagent Trajectory Planner Robust to  Communication Delay in Dynamic Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kondo%2C+K">Kota Kondo</a>, 
<a href="/search/cs?searchtype=author&query=Figueroa%2C+R">Reinaldo Figueroa</a>, 
<a href="/search/cs?searchtype=author&query=Rached%2C+J">Juan Rached</a>, 
<a href="/search/cs?searchtype=author&query=Tordesillas%2C+J">Jesus Tordesillas</a>, 
<a href="/search/cs?searchtype=author&query=Lusk%2C+P+C">Parker C. Lusk</a>, 
<a href="/search/cs?searchtype=author&query=How%2C+J+P">Jonathan P. How</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pagers, 10 figures,. arXiv admin note: substantial text overlap with <a href="/abs/2209.13667">arXiv:2209.13667</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06842" title="Abstract">arXiv:2303.06842</a> (replaced) [<a href="/pdf/2303.06842" title="Download PDF">pdf</a>, <a href="/format/2303.06842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Relationships: A New Perspective to Enhance Scene Graph  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Bowen Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Taylor%2C+C+J">Camillo J. Taylor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 New Frontiers in Graph Learning Workshop (NeurIPS GLFrontiers 2023); NeurIPS 2023 Queer in AI Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08549" title="Abstract">arXiv:2303.08549</a> (replaced) [<a href="/pdf/2303.08549" title="Download PDF">pdf</a>, <a href="/format/2303.08549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Bregman-Kaczmarz method for nonlinear systems of equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Winkler%2C+M">Maximilian Winkler</a>, 
<a href="/search/math?searchtype=author&query=Lorenz%2C+D+A">Dirk A. Lorenz</a>, 
<a href="/search/math?searchtype=author&query=Gower%2C+R">Robert Gower</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09373" title="Abstract">arXiv:2303.09373</a> (replaced) [<a href="/pdf/2303.09373" title="Download PDF">pdf</a>, <a href="/format/2303.09373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAPSeg: Unified Unsupervised Domain Adaptation for Heterogeneous Medical  Image Segmentation Based on 3D Masked Autoencoding and Pseudo-Labeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuzhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuhao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Angelini%2C+E">Elsa Angelini</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Ang Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jia Guo</a>, 
<a href="/search/cs?searchtype=author&query=Rasmussen%2C+J+M">Jerod M. Rasmussen</a>, 
<a href="/search/cs?searchtype=author&query=O%27Connor%2C+T+G">Thomas G. O&#x27;Connor</a>, 
<a href="/search/cs?searchtype=author&query=Wadhwa%2C+P+D">Pathik D. Wadhwa</a>, 
<a href="/search/cs?searchtype=author&query=Jackowski%2C+A+P">Andrea Parolin Jackowski</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hai Li</a>, 
<a href="/search/cs?searchtype=author&query=Posner%2C+J">Jonathan Posner</a>, 
<a href="/search/cs?searchtype=author&query=Laine%2C+A+F">Andrew F. Laine</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yun Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages and 7 figures. Revised and extended to test-time and federated domain adaptation. Xuzhe Zhang and Yuhao Wu are co-first authors. Andrew F. Laine and Yun Wang are co-senior supervising authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09656" title="Abstract">arXiv:2303.09656</a> (replaced) [<a href="/pdf/2303.09656" title="Download PDF">pdf</a>, <a href="/format/2303.09656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revealing complexities when adult readers engage in the credibility  evaluation of social media posts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuutila%2C+M">Miikka Kuutila</a>, 
<a href="/search/cs?searchtype=author&query=Kiili%2C+C">Carita Kiili</a>, 
<a href="/search/cs?searchtype=author&query=Kupiainen%2C+R">Reijo Kupiainen</a>, 
<a href="/search/cs?searchtype=author&query=Huusko%2C+E">Eetu Huusko</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Hosio%2C+S">Simo Hosio</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%A4ntyl%C3%A4%2C+M">Mika M&#xe4;ntyl&#xe4;</a>, 
<a href="/search/cs?searchtype=author&query=Coiro%2C+J">Julie Coiro</a>, 
<a href="/search/cs?searchtype=author&query=Kiili%2C+K">Kristian Kiili</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 5 figures including the appendix. Accepted to Computers in Human Behavior
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10276" title="Abstract">arXiv:2303.10276</a> (replaced) [<a href="/pdf/2303.10276" title="Download PDF">pdf</a>, <a href="/format/2303.10276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unleashing the Potential of Spiking Neural Networks by Dynamic  Confidence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chen Li</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+E">Edward Jones</a>, 
<a href="/search/cs?searchtype=author&query=Furber%2C+S">Steve Furber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11153" title="Abstract">arXiv:2303.11153</a> (replaced) [<a href="/pdf/2303.11153" title="Download PDF">pdf</a>, <a href="/ps/2303.11153" title="Download PostScript">ps</a>, <a href="/format/2303.11153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistical Age-of-Information Optimization for Status Update over  Multi-State Fading Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yuquan Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Q">Qinghe Du</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by IEEE Transactions on Vehicular Technology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11712" title="Abstract">arXiv:2303.11712</a> (replaced) [<a href="/pdf/2303.11712" title="Download PDF">pdf</a>, <a href="/format/2303.11712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficiently Explaining CSPs with Unsatisfiable Subset Optimization  (extended algorithms and examples)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gamba%2C+E">Emilio Gamba</a>, 
<a href="/search/cs?searchtype=author&query=Bogaerts%2C+B">Bart Bogaerts</a>, 
<a href="/search/cs?searchtype=author&query=Guns%2C+T">Tias Guns</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2105.11763">arXiv:2105.11763</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Artificial Intelligence Research (JAIR) Volume 78
  (2023): pages 709-746
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12976" title="Abstract">arXiv:2303.12976</a> (replaced) [<a href="/pdf/2303.12976" title="Download PDF">pdf</a>, <a href="/format/2303.12976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NVAutoNet: Fast and Accurate 360$^{\circ}$ 3D Visual Perception For Self  Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pham%2C+T">Trung Pham</a>, 
<a href="/search/cs?searchtype=author&query=Maghoumi%2C+M">Mehran Maghoumi</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wanli Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Jujjavarapu%2C+B+S+S">Bala Siva Sashank Jujjavarapu</a>, 
<a href="/search/cs?searchtype=author&query=Sajjadi%2C+M">Mehdi Sajjadi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hsuan-Chu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bor-Jeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Truong%2C+G">Giang Truong</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Chao Fang</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+J">Junghyun Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+M">Minwoo Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WACV 2024. Link to video <a href="https://www.youtube.com/watch?v=cPxVhCJ7kyY">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17742" title="Abstract">arXiv:2303.17742</a> (replaced) [<a href="/pdf/2303.17742" title="Download PDF">pdf</a>, <a href="/format/2303.17742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MemPool: A Scalable Manycore Architecture with a Low-Latency Shared L1  Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Riedel%2C+S">Samuel Riedel</a>, 
<a href="/search/cs?searchtype=author&query=Cavalcante%2C+M">Matheus Cavalcante</a>, 
<a href="/search/cs?searchtype=author&query=Andri%2C+R">Renzo Andri</a>, 
<a href="/search/cs?searchtype=author&query=Benini%2C+L">Luca Benini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 17 figures, 2 tables, Published in IEEE Transactions on Computers
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Computers, vol. 72, no. 12, pp. 3561-3575,
  Dec. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.18158" title="Abstract">arXiv:2303.18158</a> (replaced) [<a href="/pdf/2303.18158" title="Download PDF">pdf</a>, <a href="/format/2303.18158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constrained Optimization of Rank-One Functions with Indicator Variables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Shafiee%2C+S">Soroosh Shafiee</a>, 
<a href="/search/math?searchtype=author&query=K%C4%B1l%C4%B1n%C3%A7-Karzan%2C+F">Fatma K&#x131;l&#x131;n&#xe7;-Karzan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08576" title="Abstract">arXiv:2304.08576</a> (replaced) [<a href="/pdf/2304.08576" title="Download PDF">pdf</a>, <a href="/format/2304.08576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-Efficient Lane Changes Planning and Control for Connected  Autonomous Vehicles on Urban Roads
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joa%2C+E">Eunhyek Joa</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hotae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+E+Y">Eric Yongkeun Choi</a>, 
<a href="/search/cs?searchtype=author&query=Borrelli%2C+F">Francesco Borrelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Intelligent Vehicle Symposium, Anchorage, Alaska, June 4-7, 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE Intelligent Vehicles Symposium (IV). 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08822" title="Abstract">arXiv:2304.08822</a> (replaced) [<a href="/pdf/2304.08822" title="Download PDF">pdf</a>, <a href="/format/2304.08822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modal-graph 3D shape servoing of deformable objects with raw point  clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bohan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Sui%2C+C">Congying Sui</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+F">Fangxun Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yun-Hui Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by the International Journal of The International Journal of Robotics Research. SAGE copyright
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11310" title="Abstract">arXiv:2304.11310</a> (replaced) [<a href="/pdf/2304.11310" title="Download PDF">pdf</a>, <a href="/format/2304.11310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Twilight SLAM: Navigating Low-Light Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+S+P">Surya Pratap Singh</a>, 
<a href="/search/cs?searchtype=author&query=Rajani%2C+D+M">Dhyey Manish Rajani</a>, 
<a href="/search/cs?searchtype=author&query=Mazotti%2C+B">Billy Mazotti</a>, 
<a href="/search/cs?searchtype=author&query=Mayilvahanan%2C+S">Sarvesh Mayilvahanan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guoyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Ghaffari%2C+M">Maani Ghaffari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12308" title="Abstract">arXiv:2304.12308</a> (replaced) [<a href="/pdf/2304.12308" title="Download PDF">pdf</a>, <a href="/format/2304.12308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segment Anything in 3D with NeRFs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cen%2C+J">Jiazhong Cen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zanwei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+J">Jiemin Fang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Wei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lingxi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+D">Dongsheng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaopeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qi Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023. Project page: <a href="https://jumpat.github.io/SA3D/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12479" title="Abstract">arXiv:2304.12479</a> (replaced) [<a href="/pdf/2304.12479" title="Download PDF">pdf</a>, <a href="/format/2304.12479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AGI: Artificial General Intelligence for Education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Latif%2C+E">Ehsan Latif</a>, 
<a href="/search/cs?searchtype=author&query=Mai%2C+G">Gengchen Mai</a>, 
<a href="/search/cs?searchtype=author&query=Nyaaba%2C+M">Matthew Nyaaba</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xuansheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Ninghao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+G">Guoyu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xiaoming Zhai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Position Paper on AGI for Education, SUbmitted to Applied Artificial Intelligence (AI for Education)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14373" title="Abstract">arXiv:2304.14373</a> (replaced) [<a href="/pdf/2304.14373" title="Download PDF">pdf</a>, <a href="/ps/2304.14373" title="Download PostScript">ps</a>, <a href="/format/2304.14373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Versatile Low-Complexity Feedback Scheme for FDD Systems via  Generative Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Turan%2C+N">Nurettin Turan</a>, 
<a href="/search/cs?searchtype=author&query=Fesl%2C+B">Benedikt Fesl</a>, 
<a href="/search/cs?searchtype=author&query=Koller%2C+M">Michael Koller</a>, 
<a href="/search/cs?searchtype=author&query=Joham%2C+M">Michael Joham</a>, 
<a href="/search/cs?searchtype=author&query=Utschick%2C+W">Wolfgang Utschick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Copyright IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See <a href="https://www.ieee.org/publications/rights/index.html">this https URL</a> for more information
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.00126" title="Abstract">arXiv:2305.00126</a> (replaced) [<a href="/pdf/2305.00126" title="Download PDF">pdf</a>, <a href="/format/2305.00126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Event-Free Moving Object Segmentation from Moving Ego Vehicle
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhuyun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zongwei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Paudel%2C+D+P">Danda Pani Paudel</a>, 
<a href="/search/cs?searchtype=author&query=Boutteau%2C+R">R&#xe9;mi Boutteau</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>, 
<a href="/search/cs?searchtype=author&query=Timofte%2C+R">Radu Timofte</a>, 
<a href="/search/cs?searchtype=author&query=Ginhac%2C+D">Dominique Ginhac</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03427" title="Abstract">arXiv:2305.03427</a> (replaced) [<a href="/pdf/2305.03427" title="Download PDF">pdf</a>, <a href="/ps/2305.03427" title="Download PostScript">ps</a>, <a href="/format/2305.03427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhanced Low-Complexity FDD System Feedback with Variable Bit Lengths  via Generative Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Turan%2C+N">Nurettin Turan</a>, 
<a href="/search/cs?searchtype=author&query=Fesl%2C+B">Benedikt Fesl</a>, 
<a href="/search/cs?searchtype=author&query=Utschick%2C+W">Wolfgang Utschick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04104" title="Abstract">arXiv:2305.04104</a> (replaced) [<a href="/pdf/2305.04104" title="Download PDF">pdf</a>, <a href="/format/2305.04104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Feedback for Affine Nonlinear Systems with Application to Global  Obstacle Avoidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+M">Miaomiao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Tayebi%2C+A">Abdelhamid Tayebi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 figues
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08415" title="Abstract">arXiv:2305.08415</a> (replaced) [<a href="/pdf/2305.08415" title="Download PDF">pdf</a>, <a href="/format/2305.08415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Marsellus: A Heterogeneous RISC-V AI-IoT End-Node SoC with 2-to-8b DNN  Acceleration and 30%-Boost Adaptive Body Biasing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Conti%2C+F">Francesco Conti</a>, 
<a href="/search/cs?searchtype=author&query=Paulin%2C+G">Gianna Paulin</a>, 
<a href="/search/cs?searchtype=author&query=Garofalo%2C+A">Angelo Garofalo</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+D">Davide Rossi</a>, 
<a href="/search/cs?searchtype=author&query=Di+Mauro%2C+A">Alfio Di Mauro</a>, 
<a href="/search/cs?searchtype=author&query=Rutishauser%2C+G">Georg Rutishauser</a>, 
<a href="/search/cs?searchtype=author&query=Ottavi%2C+G">Gianmarco Ottavi</a>, 
<a href="/search/cs?searchtype=author&query=Eggimann%2C+M">Manuel Eggimann</a>, 
<a href="/search/cs?searchtype=author&query=Okuhara%2C+H">Hayate Okuhara</a>, 
<a href="/search/cs?searchtype=author&query=Benini%2C+L">Luca Benini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Post-print accepted by IEEE Journal of Solid-State Circuits. Fixed metadata (was missing one co-author), added DOI of IEEE JSSC
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10300" title="Abstract">arXiv:2305.10300</a> (replaced) [<a href="/pdf/2305.10300" title="Download PDF">pdf</a>, <a href="/format/2305.10300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-Prompt to Segment All Medical Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wu%2C+J">Junde Wu</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+M">Min Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2304.12620">arXiv:2304.12620</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10498" title="Abstract">arXiv:2305.10498</a> (replaced) [<a href="/pdf/2305.10498" title="Download PDF">pdf</a>, <a href="/format/2305.10498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Edge Directionality Improves Learning on Heterophilic Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rossi%2C+E">Emanuele Rossi</a>, 
<a href="/search/cs?searchtype=author&query=Charpentier%2C+B">Bertrand Charpentier</a>, 
<a href="/search/cs?searchtype=author&query=Di+Giovanni%2C+F">Francesco Di Giovanni</a>, 
<a href="/search/cs?searchtype=author&query=Frasca%2C+F">Fabrizio Frasca</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCnnemann%2C+S">Stephan G&#xfc;nnemann</a>, 
<a href="/search/cs?searchtype=author&query=Bronstein%2C+M">Michael Bronstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11475" title="Abstract">arXiv:2305.11475</a> (replaced) [<a href="/pdf/2305.11475" title="Download PDF">pdf</a>, <a href="/format/2305.11475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Curve Your Enthusiasm: Concurvity Regularization in Differentiable  Generalized Additive Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Siems%2C+J">Julien Siems</a>, 
<a href="/search/cs?searchtype=author&query=Ditschuneit%2C+K">Konstantin Ditschuneit</a>, 
<a href="/search/cs?searchtype=author&query=Ripken%2C+W">Winfried Ripken</a>, 
<a href="/search/cs?searchtype=author&query=Lindborg%2C+A">Alma Lindborg</a>, 
<a href="/search/cs?searchtype=author&query=Schambach%2C+M">Maximilian Schambach</a>, 
<a href="/search/cs?searchtype=author&query=Otterbach%2C+J+S">Johannes S. Otterbach</a>, 
<a href="/search/cs?searchtype=author&query=Genzel%2C+M">Martin Genzel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12476" title="Abstract">arXiv:2305.12476</a> (replaced) [<a href="/pdf/2305.12476" title="Download PDF">pdf</a>, <a href="/format/2305.12476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-shot Visual Relation Detection via Composite Visual Cues from Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lin Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jun Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guikun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Jian Shao</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Y">Yueting Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Long Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14457" title="Abstract">arXiv:2305.14457</a> (replaced) [<a href="/pdf/2305.14457" title="Download PDF">pdf</a>, <a href="/format/2305.14457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-training Language Models for Comparative Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+M">Mengxia Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhihan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenhao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Meng Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 - Camera Ready. Typos fixed
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14561" title="Abstract">arXiv:2305.14561</a> (replaced) [<a href="/pdf/2305.14561" title="Download PDF">pdf</a>, <a href="/format/2305.14561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Negative Feedback Training: A Novel Concept to Improve Robustness of  NVCIM DNN Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yifan Qin</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zheyu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+W">Wujie Wen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X+S">Xiaobo Sharon Hu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yiyu Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR)

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14726" title="Abstract">arXiv:2305.14726</a> (replaced) [<a href="/pdf/2305.14726" title="Download PDF">pdf</a>, <a href="/format/2305.14726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-Context Demonstration Selection with Cross Entropy Difference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Iter%2C+D">Dan Iter</a>, 
<a href="/search/cs?searchtype=author&query=Pryzant%2C+R">Reid Pryzant</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ruochen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuohang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yichong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chenguang Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15150" title="Abstract">arXiv:2305.15150</a> (replaced) [<a href="/pdf/2305.15150" title="Download PDF">pdf</a>, <a href="/format/2305.15150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fault-Tolerant Computing with Unreliable Channels (Extended Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naser-Pastoriza%2C+A">Alejandro Naser-Pastoriza</a>, 
<a href="/search/cs?searchtype=author&query=Chockler%2C+G">Gregory Chockler</a>, 
<a href="/search/cs?searchtype=author&query=Gotsman%2C+A">Alexey Gotsman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of a paper in the 27th International Conference on Principles of Distributed Systems (OPODIS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15347" title="Abstract">arXiv:2305.15347</a> (replaced) [<a href="/pdf/2305.15347" title="Download PDF">pdf</a>, <a href="/format/2305.15347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Tale of Two Features: Stable Diffusion Complements DINO for Zero-Shot  Semantic Correspondence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Herrmann%2C+C">Charles Herrmann</a>, 
<a href="/search/cs?searchtype=author&query=Hur%2C+J">Junhwa Hur</a>, 
<a href="/search/cs?searchtype=author&query=Cabrera%2C+L+P">Luisa Polania Cabrera</a>, 
<a href="/search/cs?searchtype=author&query=Jampani%2C+V">Varun Jampani</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+D">Deqing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 23, project page: <a href="https://sd-complements-dino.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16037" title="Abstract">arXiv:2305.16037</a> (replaced) [<a href="/pdf/2305.16037" title="Download PDF">pdf</a>, <a href="/format/2305.16037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GenerateCT: Text-Conditional Generation of 3D Chest CT Volumes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamamci%2C+I+E">Ibrahim Ethem Hamamci</a>, 
<a href="/search/cs?searchtype=author&query=Er%2C+S">Sezgin Er</a>, 
<a href="/search/cs?searchtype=author&query=Simsar%2C+E">Enis Simsar</a>, 
<a href="/search/cs?searchtype=author&query=Sekuboyina%2C+A">Anjany Sekuboyina</a>, 
<a href="/search/cs?searchtype=author&query=Prabhakar%2C+C">Chinmay Prabhakar</a>, 
<a href="/search/cs?searchtype=author&query=Tezcan%2C+A">Alperen Tezcan</a>, 
<a href="/search/cs?searchtype=author&query=Simsek%2C+A+G">Ayse Gulnihan Simsek</a>, 
<a href="/search/cs?searchtype=author&query=Esirgun%2C+S+N">Sevval Nil Esirgun</a>, 
<a href="/search/cs?searchtype=author&query=Almas%2C+F">Furkan Almas</a>, 
<a href="/search/cs?searchtype=author&query=Do%C4%9Fan%2C+I">Irem Do&#x11f;an</a>, 
<a href="/search/cs?searchtype=author&query=Dasdelen%2C+M+F">Muhammed Furkan Dasdelen</a>, 
<a href="/search/cs?searchtype=author&query=Reynaud%2C+H">Hadrien Reynaud</a>, 
<a href="/search/cs?searchtype=author&query=Pati%2C+S">Sarthak Pati</a>, 
<a href="/search/cs?searchtype=author&query=Bluethgen%2C+C">Christian Bluethgen</a>, 
<a href="/search/cs?searchtype=author&query=Ozdemir%2C+M+K">Mehmet Kemal Ozdemir</a>, 
<a href="/search/cs?searchtype=author&query=Menze%2C+B">Bjoern Menze</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16154" title="Abstract">arXiv:2305.16154</a> (replaced) [<a href="/pdf/2305.16154" title="Download PDF">pdf</a>, <a href="/format/2305.16154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling and Control of a Novel Variable Stiffness three DoFs Wrist
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Milazzo%2C+G">Giuseppe Milazzo</a>, 
<a href="/search/cs?searchtype=author&query=Catalano%2C+M+G">Manuel Giuseppe Catalano</a>, 
<a href="/search/cs?searchtype=author&query=Bicchi%2C+A">Antonio Bicchi</a>, 
<a href="/search/cs?searchtype=author&query=Grioli%2C+G">Giorgio Grioli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages + appendix (3 pages), 18 figures, submitted to IJRR
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16378" title="Abstract">arXiv:2305.16378</a> (replaced) [<a href="/pdf/2305.16378" title="Download PDF">pdf</a>, <a href="/format/2305.16378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sim-Suction: Learning a Suction Grasp Policy for Cluttered Environments  Using a Synthetic Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Juncheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Cappelleri%2C+D+J">David J. Cappelleri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Transactions on Robotics
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Robotics (2023) 1-16
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17098" title="Abstract">arXiv:2305.17098</a> (replaced) [<a href="/pdf/2305.17098" title="Download PDF">pdf</a>, <a href="/format/2305.17098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ControlVideo: Conditional Control for One-shot Text-driven Video Editing  and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+M">Min Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rongzhen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+F">Fan Bao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chongxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jun Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18228" title="Abstract">arXiv:2305.18228</a> (replaced) [<a href="/pdf/2305.18228" title="Download PDF">pdf</a>, <a href="/format/2305.18228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SR-OOD: Out-of-Distribution Detection via Sample Repairing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+R">Rui Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Andi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haiming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jinke Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruimao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Shuguang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhen Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is an updated version of the paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18766" title="Abstract">arXiv:2305.18766</a> (replaced) [<a href="/pdf/2305.18766" title="Download PDF">pdf</a>, <a href="/format/2305.18766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HiFA: High-fidelity Text-to-3D Generation with Advanced Diffusion  Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Junzhe Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+P">Peiye Zhuang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://hifa-team.github.io/HiFA-site/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19056" title="Abstract">arXiv:2305.19056</a> (replaced) [<a href="/pdf/2305.19056" title="Download PDF">pdf</a>, <a href="/ps/2305.19056" title="Download PostScript">ps</a>, <a href="/format/2305.19056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Drivers of social influence in the Twitter migration to Mastodon
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=La+Cava%2C+L">Lucio La Cava</a>, 
<a href="/search/cs?searchtype=author&query=Aiello%2C+L+M">Luca Maria Aiello</a>, 
<a href="/search/cs?searchtype=author&query=Tagarelli%2C+A">Andrea Tagarelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Please refer to the accepted version of this paper on Scientific Reports. DOI: 10.1038/s41598-023-48200-7
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00519" title="Abstract">arXiv:2306.00519</a> (replaced) [<a href="/pdf/2306.00519" title="Download PDF">pdf</a>, <a href="/format/2306.00519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffInDScene: Diffusion-based High-Quality 3D Indoor Scene Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ju%2C+X">Xiaoliang Ju</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhaoyang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yijin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guofeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongsheng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated: new work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00544" title="Abstract">arXiv:2306.00544</a> (replaced) [<a href="/pdf/2306.00544" title="Download PDF">pdf</a>, <a href="/format/2306.00544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Codebook Configuration for RIS-aided Systems via Implicit Neural  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Huiying Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+R">Rujing Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zhijie Fan</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+T">Tiebin Mi</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+R+C">Robert Caiming Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+Z">Zenan Ling</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03089" title="Abstract">arXiv:2306.03089</a> (replaced) [<a href="/pdf/2306.03089" title="Download PDF">pdf</a>, <a href="/format/2306.03089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Brain Diffusion for Visual Exploration: Cortical Discovery using Large  Scale Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+A+F">Andrew F. Luo</a>, 
<a href="/search/cs?searchtype=author&query=Henderson%2C+M+M">Margaret M. Henderson</a>, 
<a href="/search/cs?searchtype=author&query=Wehbe%2C+L">Leila Wehbe</a>, 
<a href="/search/cs?searchtype=author&query=Tarr%2C+M+J">Michael J. Tarr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 (Oral). Project page: <a href="https://www.cs.cmu.edu/~afluo/BrainDiVE/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07745" title="Abstract">arXiv:2306.07745</a> (replaced) [<a href="/pdf/2306.07745" title="Download PDF">pdf</a>, <a href="/format/2306.07745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kernelized Reinforcement Learning with Order Optimal Regret Bounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vakili%2C+S">Sattar Vakili</a>, 
<a href="/search/cs?searchtype=author&query=Olkhovskaya%2C+J">Julia Olkhovskaya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Advances in Neural Information Processing Systems (NeurIPS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09729" title="Abstract">arXiv:2306.09729</a> (replaced) [<a href="/pdf/2306.09729" title="Download PDF">pdf</a>, <a href="/format/2306.09729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameter-efficient is not sufficient: Exploring Parameter, Memory, and  Time Efficient Adapter Tuning for Dense Predictions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+D">Dongshuo Yin</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xueting Han</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bin Li</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+H">Hao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jing Bai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 4 figures, 5 tables, Submitted to NeurIPS2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11363" title="Abstract">arXiv:2306.11363</a> (replaced) [<a href="/pdf/2306.11363" title="Download PDF">pdf</a>, <a href="/format/2306.11363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masked Diffusion Models Are Fast Distribution Learners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+J">Jiachen Lei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qinglong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Peng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Ba%2C+Z">Zhongjie Ba</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhan Qin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhibo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhenguang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+K">Kui Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11613" title="Abstract">arXiv:2306.11613</a> (replaced) [<a href="/pdf/2306.11613" title="Download PDF">pdf</a>, <a href="/ps/2306.11613" title="Download PostScript">ps</a>, <a href="/format/2306.11613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polynomial approximation on disjoint segments and amplification of  approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Malykhin%2C+Y">Yuri Malykhin</a>, 
<a href="/search/math?searchtype=author&query=Ryutin%2C+K">Konstantin Ryutin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Functional Analysis (math.FA)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13029" title="Abstract">arXiv:2306.13029</a> (replaced) [<a href="/pdf/2306.13029" title="Download PDF">pdf</a>, <a href="/format/2306.13029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralized Online Federated G-Network Learning for Lightweight  Intrusion Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nak%C4%B1p%2C+M">Mert Nak&#x131;p</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCl%2C+B+C">Baran Can G&#xfc;l</a>, 
<a href="/search/cs?searchtype=author&query=Gelenbe%2C+E">Erol Gelenbe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13053" title="Abstract">arXiv:2306.13053</a> (replaced) [<a href="/pdf/2306.13053" title="Download PDF">pdf</a>, <a href="/ps/2306.13053" title="Download PostScript">ps</a>, <a href="/format/2306.13053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-lumpable stochastic bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Chung-Wei Lee</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qinghua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Abbasi-Yadkori%2C+Y">Yasin Abbasi-Yadkori</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+C">Chi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Lattimore%2C+T">Tor Lattimore</a>, 
<a href="/search/cs?searchtype=author&query=Szepesv%C3%A1ri%2C+C">Csaba Szepesv&#xe1;ri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14153" title="Abstract">arXiv:2306.14153</a> (replaced) [<a href="/pdf/2306.14153" title="Download PDF">pdf</a>, <a href="/format/2306.14153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DomainStudio: Fine-Tuning Diffusion Models for Domain-Driven Image  Generation using Limited Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jingyuan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Huimin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiansheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jian Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> extended from DDPM-PA (<a href="/abs/2211.03264">arXiv:2211.03264</a>), 33 pages, 34 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15868" title="Abstract">arXiv:2306.15868</a> (replaced) [<a href="/pdf/2306.15868" title="Download PDF">pdf</a>, <a href="/format/2306.15868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraSS: Contrastive Learning with Gradient Guided Sampling Strategy for  Remote Sensing Image Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zhen Ren</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+C">Chao Tao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yunsheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Chengli Peng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haifeng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 10 figures, 4 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Geoscience and Remote Sensing 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15943" title="Abstract">arXiv:2306.15943</a> (replaced) [<a href="/pdf/2306.15943" title="Download PDF">pdf</a>, <a href="/format/2306.15943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> No Transfers Required: Integrating Last Mile with Public Transit Using  Opti-Mile
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Altaf%2C+R">Raashid Altaf</a>, 
<a href="/search/cs?searchtype=author&query=Biyani%2C+P">Pravesh Biyani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00154" title="Abstract">arXiv:2307.00154</a> (replaced) [<a href="/pdf/2307.00154" title="Download PDF">pdf</a>, <a href="/format/2307.00154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stitched ViTs are Flexible Vision Backbones
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zizheng Pan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jing Liu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+H">Haoyu He</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+J">Jianfei Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+B">Bohan Zhuang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Tech report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04870" title="Abstract">arXiv:2307.04870</a> (replaced) [<a href="/pdf/2307.04870" title="Download PDF">pdf</a>, <a href="/format/2307.04870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RACH-Space: Reconstructing Adaptive Convex Hull Space with applications  in weak supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Na%2C+W">Woojoo Na</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06985" title="Abstract">arXiv:2307.06985</a> (replaced) [<a href="/pdf/2307.06985" title="Download PDF">pdf</a>, <a href="/ps/2307.06985" title="Download PostScript">ps</a>, <a href="/format/2307.06985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Patent Documents to Engineering Design Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Siddharth%2C+L">L Siddharth</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jianxi Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Databases (cs.DB); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07131" title="Abstract">arXiv:2307.07131</a> (replaced) [<a href="/pdf/2307.07131" title="Download PDF">pdf</a>, <a href="/ps/2307.07131" title="Download PostScript">ps</a>, <a href="/format/2307.07131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parallelising Glauber dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Holden Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v3: Corrected proposal distribution for Parallel Ising, obtained polylog dependence on epsilon, added p-spin model
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07382" title="Abstract">arXiv:2307.07382</a> (replaced) [<a href="/pdf/2307.07382" title="Download PDF">pdf</a>, <a href="/format/2307.07382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Rate-Splitting Multiple Access for Multilayer Satellite  Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yunnuo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+L">Longfei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yijie Mao</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+W">Wonjae Shin</a>, 
<a href="/search/cs?searchtype=author&query=Clerckx%2C+B">Bruno Clerckx</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07984" title="Abstract">arXiv:2307.07984</a> (replaced) [<a href="/pdf/2307.07984" title="Download PDF">pdf</a>, <a href="/ps/2307.07984" title="Download PostScript">ps</a>, <a href="/format/2307.07984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Lie derivative and Noether&#x27;s theorem on the aromatic bicomplex for  the study of volume-preserving numerical integrators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Laurent%2C+A">Adrien Laurent</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08890" title="Abstract">arXiv:2307.08890</a> (replaced) [<a href="/pdf/2307.08890" title="Download PDF">pdf</a>, <a href="/format/2307.08890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Predicted-Updates Dynamic Model: Offline, Incremental, and  Decremental to Fully Dynamic Transformations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q+C">Quanquan C. Liu</a>, 
<a href="/search/cs?searchtype=author&query=Srinivas%2C+V">Vaidehi Srinivas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The previous version focused on incremental to fully dynamic transformation. The new version includes a more general framework including offline to fully dynamic transformations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09850" title="Abstract">arXiv:2307.09850</a> (replaced) [<a href="/pdf/2307.09850" title="Download PDF">pdf</a>, <a href="/ps/2307.09850" title="Download PostScript">ps</a>, <a href="/format/2307.09850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication-Efficient Distribution-Free Inference Over Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Pournaderi%2C+M">Mehrdad Pournaderi</a>, 
<a href="/search/stat?searchtype=author&query=Xiang%2C+Y">Yu Xiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented in the Asilomar Conference on Signals, Systems, and Computers (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11957" title="Abstract">arXiv:2307.11957</a> (replaced) [<a href="/pdf/2307.11957" title="Download PDF">pdf</a>, <a href="/format/2307.11957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-performance real-world optical computing trained by in situ  model-free optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Zhao%2C+G">Guangyuan Zhao</a>, 
<a href="/search/physics?searchtype=author&query=Shu%2C+X">Xin Shu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Computer Vision and Pattern Recognition (cs.CV); Emerging Technologies (cs.ET); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12226" title="Abstract">arXiv:2307.12226</a> (replaced) [<a href="/pdf/2307.12226" title="Download PDF">pdf</a>, <a href="/format/2307.12226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometry-Aware Adaptation for Pretrained Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roberts%2C+N">Nicholas Roberts</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xintong Li</a>, 
<a href="/search/cs?searchtype=author&query=Adila%2C+D">Dyah Adila</a>, 
<a href="/search/cs?searchtype=author&query=Cromp%2C+S">Sonia Cromp</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tzu-Heng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jitian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Sala%2C+F">Frederic Sala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12301" title="Abstract">arXiv:2307.12301</a> (replaced) [<a href="/pdf/2307.12301" title="Download PDF">pdf</a>, <a href="/format/2307.12301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Image Outlier Detection using RANSAC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsai%2C+C">Chen-Han Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yu-Shao Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12689" title="Abstract">arXiv:2307.12689</a> (replaced) [<a href="/pdf/2307.12689" title="Download PDF">pdf</a>, <a href="/format/2307.12689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Addressing the Impact of Localized Training Data in Graph Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=A%2C+A">Akansha A</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE 7th international conference CERA2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16769" title="Abstract">arXiv:2307.16769</a> (replaced) [<a href="/pdf/2307.16769" title="Download PDF">pdf</a>, <a href="/format/2307.16769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 2-Level Reinforcement Learning for Ships on Inland Waterways
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Waltz%2C+M">Martin Waltz</a>, 
<a href="/search/cs?searchtype=author&query=Paulig%2C+N">Niklas Paulig</a>, 
<a href="/search/cs?searchtype=author&query=Okhrin%2C+O">Ostap Okhrin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00929" title="Abstract">arXiv:2308.00929</a> (replaced) [<a href="/pdf/2308.00929" title="Download PDF">pdf</a>, <a href="/format/2308.00929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Discriminative Representation with Meta-learning for  Colonoscopic Polyp Re-Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiang%2C+S">Suncheng Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qingzhong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+S">Shilun Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chengfeng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+C">Crystal Cai</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+S">Sijia Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhengjie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yunshi Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+D">Dahong Qian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02816" title="Abstract">arXiv:2308.02816</a> (replaced) [<a href="/pdf/2308.02816" title="Download PDF">pdf</a>, <a href="/format/2308.02816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PromptCARE: Prompt Copyright Protection by Watermark Injection and  Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+H">Hongwei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+J">Jian Lou</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+K">Kui Ren</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhan Qin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To Appear in the 45th IEEE Symposium on Security and Privacy 2024, code is available at: <a href="https://github.com/grasses/PromptCARE">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03268" title="Abstract">arXiv:2308.03268</a> (replaced) [<a href="/pdf/2308.03268" title="Download PDF">pdf</a>, <a href="/format/2308.03268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Carbon-Free Electricity: A Flow-Based Framework for Power Grid  Carbon Accounting and Decarbonization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+X">Xin Chen</a>, 
<a href="/search/eess?searchtype=author&query=Chao%2C+H">Hungpo Chao</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+W">Wenbo Shi</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+N">Na Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10099" title="Abstract">arXiv:2308.10099</a> (replaced) [<a href="/pdf/2308.10099" title="Download PDF">pdf</a>, <a href="/format/2308.10099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometric instability of graph neural networks on large graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morris%2C+E">Emily Morris</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Haotian Shen</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+W">Weiling Du</a>, 
<a href="/search/cs?searchtype=author&query=Sajjad%2C+M+H">Muhammad Hamza Sajjad</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Borun Shi</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> the Second Learning on Graphs Conference (LoG 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10364" title="Abstract">arXiv:2308.10364</a> (replaced) [<a href="/pdf/2308.10364" title="Download PDF">pdf</a>, <a href="/format/2308.10364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SE(3) Equivariant Augmented Coupling Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Midgley%2C+L+I">Laurence I. Midgley</a>, 
<a href="/search/cs?searchtype=author&query=Stimper%2C+V">Vincent Stimper</a>, 
<a href="/search/cs?searchtype=author&query=Antor%C3%A1n%2C+J">Javier Antor&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=Mathieu%2C+E">Emile Mathieu</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6lkopf%2C+B">Bernhard Sch&#xf6;lkopf</a>, 
<a href="/search/cs?searchtype=author&query=Hern%C3%A1ndez-Lobato%2C+J+M">Jos&#xe9; Miguel Hern&#xe1;ndez-Lobato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12532" title="Abstract">arXiv:2308.12532</a> (replaced) [<a href="/pdf/2308.12532" title="Download PDF">pdf</a>, <a href="/format/2308.12532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedSOL: Stabilized Orthogonal Learning in Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+G">Gihun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+M">Minchan Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sangmook Kim</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+J">Jaehoon Oh</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+S">Se-Young Yun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14610" title="Abstract">arXiv:2308.14610</a> (replaced) [<a href="/pdf/2308.14610" title="Download PDF">pdf</a>, <a href="/format/2308.14610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PolarRec: Radio Interferometric Data Reconstruction with Polar  Coordinate Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Wang%2C+R">Ruoqi Wang</a>, 
<a href="/search/astro-ph?searchtype=author&query=Chen%2C+Z">Zhuoyang Chen</a>, 
<a href="/search/astro-ph?searchtype=author&query=Zhu%2C+J">Jiayi Zhu</a>, 
<a href="/search/astro-ph?searchtype=author&query=Luo%2C+Q">Qiong Luo</a>, 
<a href="/search/astro-ph?searchtype=author&query=Wang%2C+F">Feng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15568" title="Abstract">arXiv:2308.15568</a> (replaced) [<a href="/pdf/2308.15568" title="Download PDF">pdf</a>, <a href="/ps/2308.15568" title="Download PostScript">ps</a>, <a href="/format/2308.15568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Over-Squashing in Graph Neural Networks: A Comprehensive survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akansha%2C+S">Singh Akansha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16847" title="Abstract">arXiv:2308.16847</a> (replaced) [<a href="/pdf/2308.16847" title="Download PDF">pdf</a>, <a href="/ps/2308.16847" title="Download PostScript">ps</a>, <a href="/format/2308.16847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Models for Interferometric Satellite Aperture Radar
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tuel%2C+A">Alexandre Tuel</a>, 
<a href="/search/cs?searchtype=author&query=Kerdreux%2C+T">Thomas Kerdreux</a>, 
<a href="/search/cs?searchtype=author&query=Hulbert%2C+C">Claudia Hulbert</a>, 
<a href="/search/cs?searchtype=author&query=Rouet-Leduc%2C+B">Bertrand Rouet-Leduc</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01291" title="Abstract">arXiv:2309.01291</a> (replaced) [<a href="/pdf/2309.01291" title="Download PDF">pdf</a>, <a href="/format/2309.01291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Social Choice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fish%2C+S">Sara Fish</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B6lz%2C+P">Paul G&#xf6;lz</a>, 
<a href="/search/cs?searchtype=author&query=Parkes%2C+D+C">David C. Parkes</a>, 
<a href="/search/cs?searchtype=author&query=Procaccia%2C+A+D">Ariel D. Procaccia</a>, 
<a href="/search/cs?searchtype=author&query=Rusak%2C+G">Gili Rusak</a>, 
<a href="/search/cs?searchtype=author&query=Shapira%2C+I">Itai Shapira</a>, 
<a href="/search/cs?searchtype=author&query=W%C3%BCthrich%2C+M">Manuel W&#xfc;thrich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Substantially revised with non-approval utility model, new representation axiom (balanced justified representation), and real-world case study
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02168" title="Abstract">arXiv:2309.02168</a> (replaced) [<a href="/pdf/2309.02168" title="Download PDF">pdf</a>, <a href="/format/2309.02168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impact of SAR-ADC Mismatch on Quantized Massive MU-MIMO Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guichemerre%2C+J">J&#xe9;r&#xe9;my Guichemerre</a>, 
<a href="/search/cs?searchtype=author&query=Studer%2C+C">Christoph Studer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the Asilomar Conference on Signals, Systems, and Computers 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02705" title="Abstract">arXiv:2309.02705</a> (replaced) [<a href="/pdf/2309.02705" title="Download PDF">pdf</a>, <a href="/format/2309.02705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Certifying LLM Safety against Adversarial Prompting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Aounon Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+C">Chirag Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Srinivas%2C+S">Suraj Srinivas</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A+J">Aaron Jiaxun Li</a>, 
<a href="/search/cs?searchtype=author&query=Feizi%2C+S">Soheil Feizi</a>, 
<a href="/search/cs?searchtype=author&query=Lakkaraju%2C+H">Himabindu Lakkaraju</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03592" title="Abstract">arXiv:2309.03592</a> (replaced) [<a href="/pdf/2309.03592" title="Download PDF">pdf</a>, <a href="/format/2309.03592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cybercrime Bitcoin Revenue Estimations: Quantifying the Impact of  Methodology and Coverage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gomez%2C+G">Gibran Gomez</a>, 
<a href="/search/cs?searchtype=author&query=van+Liebergen%2C+K">Kevin van Liebergen</a>, 
<a href="/search/cs?searchtype=author&query=Caballero%2C+J">Juan Caballero</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06705" title="Abstract">arXiv:2309.06705</a> (replaced) [<a href="/pdf/2309.06705" title="Download PDF">pdf</a>, <a href="/format/2309.06705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Learning Dynamics for Coalitional Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamed%2C+A">Aya Hamed</a>, 
<a href="/search/cs?searchtype=author&query=Shamma%2C+J+S">Jeff S. Shamma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures; accepted for CDC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07055" title="Abstract">arXiv:2309.07055</a> (replaced) [<a href="/pdf/2309.07055" title="Download PDF">pdf</a>, <a href="/format/2309.07055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unraveling the Geography of Infection Spread: Harnessing Super-Agents  for Predictive Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sikaroudi%2C+A+M+E">Amir Mohammad Esmaieeli Sikaroudi</a>, 
<a href="/search/cs?searchtype=author&query=Efrat%2C+A">Alon Efrat</a>, 
<a href="/search/cs?searchtype=author&query=Chertkov%2C+M">Michael Chertkov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08906" title="Abstract">arXiv:2309.08906</a> (replaced) [<a href="/pdf/2309.08906" title="Download PDF">pdf</a>, <a href="/ps/2309.08906" title="Download PostScript">ps</a>, <a href="/format/2309.08906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Multiuser Immersive Communications with Multi-numerology and  Mini-slot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+M">Ming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+J">Jiazhi Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lifeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K">Kai-Kit Wong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09919" title="Abstract">arXiv:2309.09919</a> (replaced) [<a href="/pdf/2309.09919" title="Download PDF">pdf</a>, <a href="/format/2309.09919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Plug in the Safety Chip: Enforcing Constraints for LLM-driven Robot  Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Ziyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Raman%2C+S+S">Shreyas S. Raman</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+A">Ankit Shah</a>, 
<a href="/search/cs?searchtype=author&query=Tellex%2C+S">Stefanie Tellex</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10399" title="Abstract">arXiv:2309.10399</a> (replaced) [<a href="/pdf/2309.10399" title="Download PDF">pdf</a>, <a href="/format/2309.10399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Causality Signals in Medical Images: A Pilot Study with  Empirical Results
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carloni%2C+G">Gianluca Carloni</a>, 
<a href="/search/cs?searchtype=author&query=Colantonio%2C+S">Sara Colantonio</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Repeated analyses with new dataset, provided more visual/algorithmic insights, improved clarity, remarked significance and novelty; 17 pages, 8 figures, second round review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11087" title="Abstract">arXiv:2309.11087</a> (replaced) [<a href="/pdf/2309.11087" title="Download PDF">pdf</a>, <a href="/format/2309.11087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Embed-Search-Align: DNA Sequence Alignment using Transformer Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Holur%2C+P">Pavan Holur</a>, 
<a href="/search/q-bio?searchtype=author&query=Enevoldsen%2C+K+C">K. C. Enevoldsen</a>, 
<a href="/search/q-bio?searchtype=author&query=Mboning%2C+L">Lajoyce Mboning</a>, 
<a href="/search/q-bio?searchtype=author&query=Georgiou%2C+T">Thalia Georgiou</a>, 
<a href="/search/q-bio?searchtype=author&query=Bouchard%2C+L">Louis-S. Bouchard</a>, 
<a href="/search/q-bio?searchtype=author&query=Pellegrini%2C+M">Matteo Pellegrini</a>, 
<a href="/search/q-bio?searchtype=author&query=Roychowdhury%2C+V">Vwani Roychowdhury</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, Tables 7, Figures 5
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11526" title="Abstract">arXiv:2309.11526</a> (replaced) [<a href="/pdf/2309.11526" title="Download PDF">pdf</a>, <a href="/format/2309.11526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Likelihood-based Sensor Calibration using Affine Transformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Machhamer%2C+R">R&#xfc;diger Machhamer</a>, 
<a href="/search/cs?searchtype=author&query=Fazlic%2C+L+B">Lejla Begic Fazlic</a>, 
<a href="/search/cs?searchtype=author&query=Guven%2C+E">Eray Guven</a>, 
<a href="/search/cs?searchtype=author&query=Junk%2C+D">David Junk</a>, 
<a href="/search/cs?searchtype=author&query=Kurt%2C+G+K">Gunes Karabulut Kurt</a>, 
<a href="/search/cs?searchtype=author&query=Naumann%2C+S">Stefan Naumann</a>, 
<a href="/search/cs?searchtype=author&query=Didas%2C+S">Stephan Didas</a>, 
<a href="/search/cs?searchtype=author&query=Gollmer%2C+K">Klaus-Uwe Gollmer</a>, 
<a href="/search/cs?searchtype=author&query=Bergmann%2C+R">Ralph Bergmann</a>, 
<a href="/search/cs?searchtype=author&query=Timm%2C+I+J">Ingo J. Timm</a>, 
<a href="/search/cs?searchtype=author&query=Dartmann%2C+G">Guido Dartmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13411" title="Abstract">arXiv:2309.13411</a> (replaced) [<a href="/pdf/2309.13411" title="Download PDF">pdf</a>, <a href="/format/2309.13411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Attributions of Input Variables in a Coalition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xinhao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+H">Huiqi Deng</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+B">Bo Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Quanshi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13607" title="Abstract">arXiv:2309.13607</a> (replaced) [<a href="/pdf/2309.13607" title="Download PDF">pdf</a>, <a href="/format/2309.13607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MM-NeRF: Multimodal-Guided 3D Multi-Style Transfer of Neural Radiance  Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zijiang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Z">Zhongwei Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+D">Dongmei Fu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13620" title="Abstract">arXiv:2309.13620</a> (replaced) [<a href="/pdf/2309.13620" title="Download PDF">pdf</a>, <a href="/ps/2309.13620" title="Download PostScript">ps</a>, <a href="/format/2309.13620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PRIS: Practical robust invertible network for image steganography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yitian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuhua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaodong Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13658" title="Abstract">arXiv:2309.13658</a> (replaced) [<a href="/pdf/2309.13658" title="Download PDF">pdf</a>, <a href="/format/2309.13658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fantastic Generalization Measures are Nowhere to be Found
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gastpar%2C+M">Michael Gastpar</a>, 
<a href="/search/cs?searchtype=author&query=Nachum%2C+I">Ido Nachum</a>, 
<a href="/search/cs?searchtype=author&query=Shafer%2C+J">Jonathan Shafer</a>, 
<a href="/search/cs?searchtype=author&query=Weinberger%2C+T">Thomas Weinberger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 1 figure. Minor fix: subsection 6.2 -&amp;gt; section 7
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14008" title="Abstract">arXiv:2309.14008</a> (replaced) [<a href="/pdf/2309.14008" title="Download PDF">pdf</a>, <a href="/format/2309.14008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Carrier Aggregation Enabled Integrated Sensing and Communication Signal  Design and Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wei%2C+Z">Zhiqing Wei</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+H">Haotian Liu</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+X">Xinyi Yang</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+W">Wangjun Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+H">Huici Wu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xingwang Li</a>, 
<a href="/search/eess?searchtype=author&query=Feng%2C+Z">Zhiyong Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17pages, 17 figures, already early access in IEEE Transactions on Vehicular Technology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14053" title="Abstract">arXiv:2309.14053</a> (replaced) [<a href="/pdf/2309.14053" title="Download PDF">pdf</a>, <a href="/format/2309.14053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting LARS for Large Batch Training Generalization of Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Do%2C+K">Khoi Do</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D">Duong Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H">Hoa Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Tran-Thanh%2C+L">Long Tran-Thanh</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+Q">Quoc-Viet Pham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14289" title="Abstract">arXiv:2309.14289</a> (replaced) [<a href="/pdf/2309.14289" title="Download PDF">pdf</a>, <a href="/format/2309.14289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLIP-DIY: CLIP Dense Inference Yields Open-Vocabulary Semantic  Segmentation For-Free
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wysocza%C5%84ska%2C+M">Monika Wysocza&#x144;ska</a>, 
<a href="/search/cs?searchtype=author&query=Ramamonjisoa%2C+M">Micha&#xeb;l Ramamonjisoa</a>, 
<a href="/search/cs?searchtype=author&query=Trzci%C5%84ski%2C+T">Tomasz Trzci&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Sim%C3%A9oni%2C+O">Oriane Sim&#xe9;oni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14872" title="Abstract">arXiv:2309.14872</a> (replaced) [<a href="/pdf/2309.14872" title="Download PDF">pdf</a>, <a href="/format/2309.14872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Directional Texture Editing for 3D Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shengqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jingnan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yichao Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenhan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+K">Ke Gao</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+J">Jiangjing Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaokang Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project page: <a href="https://shengqiliu1.github.io/ITEM3D">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16064" title="Abstract">arXiv:2309.16064</a> (replaced) [<a href="/pdf/2309.16064" title="Download PDF">pdf</a>, <a href="/format/2309.16064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masked Autoencoders are Scalable Learners of Cellular Morphology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kraus%2C+O">Oren Kraus</a>, 
<a href="/search/cs?searchtype=author&query=Kenyon-Dean%2C+K">Kian Kenyon-Dean</a>, 
<a href="/search/cs?searchtype=author&query=Saberian%2C+S">Saber Saberian</a>, 
<a href="/search/cs?searchtype=author&query=Fallah%2C+M">Maryam Fallah</a>, 
<a href="/search/cs?searchtype=author&query=McLean%2C+P">Peter McLean</a>, 
<a href="/search/cs?searchtype=author&query=Leung%2C+J">Jess Leung</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+V">Vasudev Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A">Ayla Khan</a>, 
<a href="/search/cs?searchtype=author&query=Balakrishnan%2C+J">Jia Balakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Celik%2C+S">Safiye Celik</a>, 
<a href="/search/cs?searchtype=author&query=Sypetkowski%2C+M">Maciej Sypetkowski</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+C+V">Chi Vicky Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Morse%2C+K">Kristen Morse</a>, 
<a href="/search/cs?searchtype=author&query=Makes%2C+M">Maureen Makes</a>, 
<a href="/search/cs?searchtype=author&query=Mabey%2C+B">Ben Mabey</a>, 
<a href="/search/cs?searchtype=author&query=Earnshaw%2C+B">Berton Earnshaw</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Spotlight at NeurIPS 2023 Generative AI and Biology (GenBio) Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00741" title="Abstract">arXiv:2310.00741</a> (replaced) [<a href="/pdf/2310.00741" title="Download PDF">pdf</a>, <a href="/format/2310.00741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FELM: Benchmarking Factuality Evaluation of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shiqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yiran Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jinghan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chern%2C+I">I-Chun Chern</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Siyang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Pengfei Liu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junxian He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023 Track on Datasets and Benchmarks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00826" title="Abstract">arXiv:2310.00826</a> (replaced) [<a href="/pdf/2310.00826" title="Download PDF">pdf</a>, <a href="/format/2310.00826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Scale Masked Autoencoding for Reducing Label Requirements on SAR  Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Allen%2C+M">Matt Allen</a>, 
<a href="/search/cs?searchtype=author&query=Dorr%2C+F">Francisco Dorr</a>, 
<a href="/search/cs?searchtype=author&query=Gallego-Mejia%2C+J+A">Joseph A. Gallego-Mejia</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADnez-Ferrer%2C+L">Laura Mart&#xed;nez-Ferrer</a>, 
<a href="/search/cs?searchtype=author&query=Jungbluth%2C+A">Anna Jungbluth</a>, 
<a href="/search/cs?searchtype=author&query=Kalaitzis%2C+F">Freddie Kalaitzis</a>, 
<a href="/search/cs?searchtype=author&query=Ramos-Poll%C3%A1n%2C+R">Ra&#xfa;l Ramos-Poll&#xe1;n</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01288" title="Abstract">arXiv:2310.01288</a> (replaced) [<a href="/pdf/2310.01288" title="Download PDF">pdf</a>, <a href="/format/2310.01288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Offline Tracking with Object Permanence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xianzhong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Caesar%2C+H">Holger Caesar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01837" title="Abstract">arXiv:2310.01837</a> (replaced) [<a href="/pdf/2310.01837" title="Download PDF">pdf</a>, <a href="/format/2310.01837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extending CAM-based XAI methods for Remote Sensing Imagery Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gizzini%2C+A+K">Abdul Karim Gizzini</a>, 
<a href="/search/cs?searchtype=author&query=Shukor%2C+M">Mustafa Shukor</a>, 
<a href="/search/cs?searchtype=author&query=Ghandour%2C+A+J">Ali J. Ghandour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02071" title="Abstract">arXiv:2310.02071</a> (replaced) [<a href="/pdf/2310.02071" title="Download PDF">pdf</a>, <a href="/format/2310.02071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards End-to-End Embodied Decision Making via Multi-modal Large  Language Model: Explorations with GPT4-Vision and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yichi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Shuhuai Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Haozhe Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zefan Cai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuchi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peiyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+B">Baobao Chang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> FMDM@NeurIPS2023, Code and data: <a href="https://github.com/pkunlp-icler/PCA-EVAL/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02691" title="Abstract">arXiv:2310.02691</a> (replaced) [<a href="/pdf/2310.02691" title="Download PDF">pdf</a>, <a href="/format/2310.02691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Ocean Subgrid-Scale Parameterizations Using Fourier Neural  Operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mangeleer%2C+V">Victor Mangeleer</a>, 
<a href="/search/cs?searchtype=author&query=Louppe%2C+G">Gilles Louppe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03059" title="Abstract">arXiv:2310.03059</a> (replaced) [<a href="/pdf/2310.03059" title="Download PDF">pdf</a>, <a href="/format/2310.03059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Point-PEFT: Parameter-Efficient Fine-Tuning for 3D Pre-trained Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+I">Ivan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ray Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zoey Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhigang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuelong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages. The specialized PEFT framework for 3D pre-trained models, which achieves competitive performance to full fine-tuning, and significantly reduces the computational resources. Project page: <a href="https://github.com/Even-JK/PEFT-3D">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03211" title="Abstract">arXiv:2310.03211</a> (replaced) [<a href="/pdf/2310.03211" title="Download PDF">pdf</a>, <a href="/format/2310.03211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Performance of Multimodal Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garg%2C+U">Utsav Garg</a>, 
<a href="/search/cs?searchtype=author&query=Bas%2C+E">Erhan Bas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04438" title="Abstract">arXiv:2310.04438</a> (replaced) [<a href="/pdf/2310.04438" title="Download PDF">pdf</a>, <a href="/ps/2310.04438" title="Download PostScript">ps</a>, <a href="/format/2310.04438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Brief History of Prompt: Leveraging Language Models. (Through Advanced  Prompting)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Muktadir%2C+G+M">Golam Md Muktadir</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04486" title="Abstract">arXiv:2310.04486</a> (replaced) [<a href="/pdf/2310.04486" title="Download PDF">pdf</a>, <a href="/format/2310.04486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> T-Rep: Representation Learning for Time Series using Time-Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fraikin%2C+A">Archibald Fraikin</a>, 
<a href="/search/cs?searchtype=author&query=Bennetot%2C+A">Adrien Bennetot</a>, 
<a href="/search/cs?searchtype=author&query=Allassonni%C3%A8re%2C+S">St&#xe9;phanie Allassonni&#xe8;re</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05204" title="Abstract">arXiv:2310.05204</a> (replaced) [<a href="/pdf/2310.05204" title="Download PDF">pdf</a>, <a href="/format/2310.05204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Optimizing with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+P">Pei-Fu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Ying-Hsuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+Y">Yun-Da Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shou-De Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05898" title="Abstract">arXiv:2310.05898</a> (replaced) [<a href="/pdf/2310.05898" title="Download PDF">pdf</a>, <a href="/format/2310.05898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lion Secretly Solves Constrained Optimization: As Lyapunov Predicts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lizhang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+K">Kaizhao Liang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qiang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC); Applications (stat.AP); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06328" title="Abstract">arXiv:2310.06328</a> (replaced) [<a href="/pdf/2310.06328" title="Download PDF">pdf</a>, <a href="/format/2310.06328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Antenna Response Consistency Driven Self-supervised Learning for  WIFI-based Human Activity Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Ke Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiangtao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hongyuan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+D">Dingchang Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06627" title="Abstract">arXiv:2310.06627</a> (replaced) [<a href="/pdf/2310.06627" title="Download PDF">pdf</a>, <a href="/format/2310.06627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What If the TV Was Off? Examining Counterfactual Reasoning Abilities of  Multi-modal Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Letian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xiaotong Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhongkai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zong%2C+Y">Yongshuo Zong</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+X">Xin Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bingchen Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08006" title="Abstract">arXiv:2310.08006</a> (replaced) [<a href="/pdf/2310.08006" title="Download PDF">pdf</a>, <a href="/ps/2310.08006" title="Download PostScript">ps</a>, <a href="/format/2310.08006" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MCPNS: A Macropixel Collocated Position and Its Neighbors Search for  Plenoptic 2.0 Video Coding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Van+Duong%2C+V">Vinh Van Duong</a>, 
<a href="/search/cs?searchtype=author&query=Huu%2C+T+N">Thuc Nguyen Huu</a>, 
<a href="/search/cs?searchtype=author&query=Yim%2C+J">Jonghoon Yim</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+B">Byeungwoo Jeon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
</div>
</dd>
<dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08164" title="Abstract">arXiv:2310.08164</a> (replaced) [<a href="/pdf/2310.08164" title="Download PDF">pdf</a>, <a href="/format/2310.08164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpreting Reward Models in RLHF-Tuned Language Models Using Sparse  Autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marks%2C+L">Luke Marks</a>, 
<a href="/search/cs?searchtype=author&query=Abdullah%2C+A">Amir Abdullah</a>, 
<a href="/search/cs?searchtype=author&query=Mendez%2C+L">Luna Mendez</a>, 
<a href="/search/cs?searchtype=author&query=Arike%2C+R">Rauno Arike</a>, 
<a href="/search/cs?searchtype=author&query=Torr%2C+P">Philip Torr</a>, 
<a href="/search/cs?searchtype=author&query=Barez%2C+F">Fazl Barez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08165" title="Abstract">arXiv:2310.08165</a> (replaced) [<a href="/pdf/2310.08165" title="Download PDF">pdf</a>, <a href="/ps/2310.08165" title="Download PostScript">ps</a>, <a href="/format/2310.08165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COVID-19 detection using ViT transformer-based approach from Computed  Tomography Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Morani%2C+K">Kenan Morani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08559" title="Abstract">arXiv:2310.08559</a> (replaced) [<a href="/pdf/2310.08559" title="Download PDF">pdf</a>, <a href="/format/2310.08559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of  Language Models with Hypothesis Refinement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+L">Linlu Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Liwei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Ximing Lu</a>, 
<a href="/search/cs?searchtype=author&query=Sclar%2C+M">Melanie Sclar</a>, 
<a href="/search/cs?searchtype=author&query=Pyatkin%2C+V">Valentina Pyatkin</a>, 
<a href="/search/cs?searchtype=author&query=Bhagavatula%2C+C">Chandra Bhagavatula</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bailin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yejin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Dziri%2C+N">Nouha Dziri</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiang Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item637">[637]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08659" title="Abstract">arXiv:2310.08659</a> (replaced) [<a href="/pdf/2310.08659" title="Download PDF">pdf</a>, <a href="/format/2310.08659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LoftQ: LoRA-Fine-Tuning-Aware Quantization for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yixiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yifan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+C">Chen Liang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+P">Pengcheng He</a>, 
<a href="/search/cs?searchtype=author&query=Karampatziakis%2C+N">Nikos Karampatziakis</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weizhu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tuo Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item638">[638]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08992" title="Abstract">arXiv:2310.08992</a> (replaced) [<a href="/pdf/2310.08992" title="Download PDF">pdf</a>, <a href="/format/2310.08992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CodeChain: Towards Modular Code Generation Through Chain of  Self-revisions with Representative Sub-modules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+H">Hung Le</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hailin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+A">Amrita Saha</a>, 
<a href="/search/cs?searchtype=author&query=Gokul%2C+A">Akash Gokul</a>, 
<a href="/search/cs?searchtype=author&query=Sahoo%2C+D">Doyen Sahoo</a>, 
<a href="/search/cs?searchtype=author&query=Joty%2C+S">Shafiq Joty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item639">[639]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09843" title="Abstract">arXiv:2310.09843</a> (replaced) [<a href="/pdf/2310.09843" title="Download PDF">pdf</a>, <a href="/ps/2310.09843" title="Download PostScript">ps</a>, <a href="/format/2310.09843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoCoFormer: A controllable feature-rich polyphonic music generation  method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiuyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+T">Tengfei Niu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xingping Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item640">[640]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10213" title="Abstract">arXiv:2310.10213</a> (replaced) [<a href="/pdf/2310.10213" title="Download PDF">pdf</a>, <a href="/format/2310.10213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Multi-Connectivity in Beyond 5G Non-Terrestrial Networks:  Challenges and Possible Solutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Majamaa%2C+M">Mikko Majamaa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item641">[641]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10404" title="Abstract">arXiv:2310.10404</a> (replaced) [<a href="/pdf/2310.10404" title="Download PDF">pdf</a>, <a href="/format/2310.10404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM4SGG: Large Language Model for Weakly Supervised Scene Graph  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kibum Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+K">Kanghoon Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+J">Jaehyeong Jeon</a>, 
<a href="/search/cs?searchtype=author&query=In%2C+Y">Yeonjun In</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+J">Jinyoung Moon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Donghyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+C">Chanyoung Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item642">[642]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11270" title="Abstract">arXiv:2310.11270</a> (replaced) [<a href="/pdf/2310.11270" title="Download PDF">pdf</a>, <a href="/format/2310.11270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Neural Networks for Recommendation: Reproducibility, Graph  Topology, and Node Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malitesta%2C+D">Daniele Malitesta</a>, 
<a href="/search/cs?searchtype=author&query=Pomo%2C+C">Claudio Pomo</a>, 
<a href="/search/cs?searchtype=author&query=Di+Noia%2C+T">Tommaso Di Noia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item643">[643]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11676" title="Abstract">arXiv:2310.11676</a> (replaced) [<a href="/pdf/2310.11676" title="Download PDF">pdf</a>, <a href="/format/2310.11676" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PREM: A Simple Yet Effective Approach for Node-Level Graph Anomaly  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Junjun Pan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yixin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yizhen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shirui Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE International Conference of Data Mining 2023 (ICDM 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item644">[644]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13164" title="Abstract">arXiv:2310.13164</a> (replaced) [<a href="/pdf/2310.13164" title="Download PDF">pdf</a>, <a href="/format/2310.13164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Almost Equivariance via Lie Algebra Convolutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McNeela%2C+D">Daniel McNeela</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item645">[645]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13595" title="Abstract">arXiv:2310.13595</a> (replaced) [<a href="/pdf/2310.13595" title="Download PDF">pdf</a>, <a href="/format/2310.13595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The History and Risks of Reinforcement Learning and Human Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lambert%2C+N">Nathan Lambert</a>, 
<a href="/search/cs?searchtype=author&query=Gilbert%2C+T+K">Thomas Krendl Gilbert</a>, 
<a href="/search/cs?searchtype=author&query=Zick%2C+T">Tom Zick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item646">[646]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14045" title="Abstract">arXiv:2310.14045</a> (replaced) [<a href="/pdf/2310.14045" title="Download PDF">pdf</a>, <a href="/format/2310.14045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training Image Derivatives: Increased Accuracy and Universal Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Avrutskiy%2C+V+I">Vsevolod I. Avrutskiy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> converted to two-column format, shortened abstract, improved readability, removed unnecessary graphics, fixed typos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item647">[647]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14714" title="Abstract">arXiv:2310.14714</a> (replaced) [<a href="/pdf/2310.14714" title="Download PDF">pdf</a>, <a href="/format/2310.14714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BatteryML:An Open-source platform for Machine Learning on Battery  Degradation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Han Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+X">Xiaofan Gui</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shun Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Ziheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+J">Jiang Bian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item648">[648]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16236" title="Abstract">arXiv:2310.16236</a> (replaced) [<a href="/pdf/2310.16236" title="Download PDF">pdf</a>, <a href="/format/2310.16236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Query-Efficient Algorithms to Find the Unique Nash Equilibrium in a  Two-Player Zero-Sum Matrix Game
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maiti%2C+A">Arnab Maiti</a>, 
<a href="/search/cs?searchtype=author&query=Boczar%2C+R">Ross Boczar</a>, 
<a href="/search/cs?searchtype=author&query=Jamieson%2C+K">Kevin Jamieson</a>, 
<a href="/search/cs?searchtype=author&query=Ratliff%2C+L+J">Lillian J. Ratliff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item649">[649]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16252" title="Abstract">arXiv:2310.16252</a> (replaced) [<a href="/pdf/2310.16252" title="Download PDF">pdf</a>, <a href="/format/2310.16252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Near-Optimal Pure Exploration in Matrix Games: A Generalization of  Stochastic Bandits &amp; Dueling Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maiti%2C+A">Arnab Maiti</a>, 
<a href="/search/cs?searchtype=author&query=Boczar%2C+R">Ross Boczar</a>, 
<a href="/search/cs?searchtype=author&query=Jamieson%2C+K">Kevin Jamieson</a>, 
<a href="/search/cs?searchtype=author&query=Ratliff%2C+L+J">Lillian J. Ratliff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item650">[650]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17025" title="Abstract">arXiv:2310.17025</a> (replaced) [<a href="/pdf/2310.17025" title="Download PDF">pdf</a>, <a href="/format/2310.17025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> netFound: Foundation Model for Network Security
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guthula%2C+S">Satyandra Guthula</a>, 
<a href="/search/cs?searchtype=author&query=Battula%2C+N">Navya Battula</a>, 
<a href="/search/cs?searchtype=author&query=Beltiukov%2C+R">Roman Beltiukov</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Wenbo Guo</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Arpit Gupta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item651">[651]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17357" title="Abstract">arXiv:2310.17357</a> (replaced) [<a href="/pdf/2310.17357" title="Download PDF">pdf</a>, <a href="/ps/2310.17357" title="Download PostScript">ps</a>, <a href="/format/2310.17357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controlling Automated Vehicles on Large Lane-free Roundabouts (Extended  Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Naderi%2C+M">Mehdi Naderi</a>, 
<a href="/search/eess?searchtype=author&query=Papageorgiou%2C+M">Markos Papageorgiou</a>, 
<a href="/search/eess?searchtype=author&query=Troullinos%2C+D">Dimitrios Troullinos</a>, 
<a href="/search/eess?searchtype=author&query=Karafyllis%2C+I">Iasson Karafyllis</a>, 
<a href="/search/eess?searchtype=author&query=Papamichail%2C+I">Ioannis Papamichail</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 21 figures, 1 table, and 47 equations As compared with the previous version: - Some minor changes in the text - The first simulation is replaced with a new one to have more clear figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item652">[652]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17639" title="Abstract">arXiv:2310.17639</a> (replaced) [<a href="/pdf/2310.17639" title="Download PDF">pdf</a>, <a href="/format/2310.17639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-Context Learning Dynamics with Random Binary Sequences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bigelow%2C+E+J">Eric J. Bigelow</a>, 
<a href="/search/cs?searchtype=author&query=Lubana%2C+E+S">Ekdeep Singh Lubana</a>, 
<a href="/search/cs?searchtype=author&query=Dick%2C+R+P">Robert P. Dick</a>, 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+H">Hidenori Tanaka</a>, 
<a href="/search/cs?searchtype=author&query=Ullman%2C+T+D">Tomer D. Ullman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item653">[653]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18021" title="Abstract">arXiv:2310.18021</a> (replaced) [<a href="/pdf/2310.18021" title="Download PDF">pdf</a>, <a href="/format/2310.18021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FormalGeo: The First Step Toward Human-like IMO-level Geometric  Automated Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaokai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+N">Na Zhu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yiming He</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">Jia Zou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qike Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xiaoxiao Jin</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yanjun Guo</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+C">Chenyang Mao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhe Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+D">Dengfeng Yue</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Fangzhen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yiwen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Runan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+C">Cheng Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zhenbing Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Shaorong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiangfeng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Leng%2C+T">Tuo Leng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 43 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item654">[654]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18515" title="Abstract">arXiv:2310.18515</a> (replaced) [<a href="/pdf/2310.18515" title="Download PDF">pdf</a>, <a href="/format/2310.18515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to design protein-protein interactions with enhanced  generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bushuiev%2C+A">Anton Bushuiev</a>, 
<a href="/search/cs?searchtype=author&query=Bushuiev%2C+R">Roman Bushuiev</a>, 
<a href="/search/cs?searchtype=author&query=Kouba%2C+P">Petr Kouba</a>, 
<a href="/search/cs?searchtype=author&query=Filkin%2C+A">Anatolii Filkin</a>, 
<a href="/search/cs?searchtype=author&query=Gabrielova%2C+M">Marketa Gabrielova</a>, 
<a href="/search/cs?searchtype=author&query=Gabriel%2C+M">Michal Gabriel</a>, 
<a href="/search/cs?searchtype=author&query=Sedlar%2C+J">Jiri Sedlar</a>, 
<a href="/search/cs?searchtype=author&query=Pluskal%2C+T">Tomas Pluskal</a>, 
<a href="/search/cs?searchtype=author&query=Damborsky%2C+J">Jiri Damborsky</a>, 
<a href="/search/cs?searchtype=author&query=Mazurenko%2C+S">Stanislav Mazurenko</a>, 
<a href="/search/cs?searchtype=author&query=Sivic%2C+J">Josef Sivic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item655">[655]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20246" title="Abstract">arXiv:2310.20246</a> (replaced) [<a href="/pdf/2310.20246" title="Download PDF">pdf</a>, <a href="/format/2310.20246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Breaking Language Barriers in Multilingual Mathematical Reasoning:  Insights and Observations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+N">Nuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zinan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+N">Ning Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+M">Ming Gong</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yangqiu Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongmei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in Progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item656">[656]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20323" title="Abstract">arXiv:2310.20323</a> (replaced) [<a href="/pdf/2310.20323" title="Download PDF">pdf</a>, <a href="/format/2310.20323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SemanticBoost: Elevating Motion Generation with Augmented Textual Cues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xin He</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shaoli Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+X">Xiaohang Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+C">Chao Weng</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item657">[657]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20604" title="Abstract">arXiv:2310.20604</a> (replaced) [<a href="/pdf/2310.20604" title="Download PDF">pdf</a>, <a href="/format/2310.20604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhanced Synthetic MRI Generation from CT Scans Using CycleGAN with  Feature Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Nikbakhsh%2C+S">Saba Nikbakhsh</a>, 
<a href="/search/eess?searchtype=author&query=Naghashyar%2C+L">Lachin Naghashyar</a>, 
<a href="/search/eess?searchtype=author&query=Valizadeh%2C+M">Morteza Valizadeh</a>, 
<a href="/search/eess?searchtype=author&query=Amirani%2C+M+C">Mehdi Chehel Amirani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item658">[658]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01270" title="Abstract">arXiv:2311.01270</a> (replaced) [<a href="/pdf/2311.01270" title="Download PDF">pdf</a>, <a href="/format/2311.01270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> People Make Better Edits: Measuring the Efficacy of LLM-Generated  Counterfactually Augmented Data for Harmful Language Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sen%2C+I">Indira Sen</a>, 
<a href="/search/cs?searchtype=author&query=Assenmacher%2C+D">Dennis Assenmacher</a>, 
<a href="/search/cs?searchtype=author&query=Samory%2C+M">Mattia Samory</a>, 
<a href="/search/cs?searchtype=author&query=Augenstein%2C+I">Isabelle Augenstein</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Aalst%2C+W">Wil van der Aalst</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+C">Claudia Wagner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint of EMNLP'23 paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item659">[659]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01790" title="Abstract">arXiv:2311.01790</a> (replaced) [<a href="/pdf/2311.01790" title="Download PDF">pdf</a>, <a href="/format/2311.01790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A First Order Theory of Diagram Chasing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahboubi%2C+A">Assia Mahboubi</a> (LS2N, GALLINETTE), 
<a href="/search/cs?searchtype=author&query=Piquerez%2C+M">Matthieu Piquerez</a> (GALLINETTE, LS2N)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item660">[660]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03782" title="Abstract">arXiv:2311.03782</a> (replaced) [<a href="/pdf/2311.03782" title="Download PDF">pdf</a>, <a href="/format/2311.03782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CapST: An Enhanced and Lightweight Model Attribution Approach for  Synthetic Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+W">Wasim Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yan-Tsung Peng</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Yuan-Hao Chang</a>, 
<a href="/search/cs?searchtype=author&query=Ganfure%2C+G+O">Gaddisa Olani Ganfure</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S">Sarwar Khan</a>, 
<a href="/search/cs?searchtype=author&query=Shahzad%2C+S+A">Sahibzada Adil Shahzad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item661">[661]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04742" title="Abstract">arXiv:2311.04742</a> (replaced) [<a href="/pdf/2311.04742" title="Download PDF">pdf</a>, <a href="/format/2311.04742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using large language models to study human memory for meaningful  narratives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Georgiou%2C+A">Antonios Georgiou</a>, 
<a href="/search/cs?searchtype=author&query=Can%2C+T">Tankut Can</a>, 
<a href="/search/cs?searchtype=author&query=Katkov%2C+M">Mikhail Katkov</a>, 
<a href="/search/cs?searchtype=author&query=Tsodyks%2C+M">Misha Tsodyks</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v2: 43 pages, with added discussion and a new appendix C
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item662">[662]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04942" title="Abstract">arXiv:2311.04942</a> (replaced) [<a href="/pdf/2311.04942" title="Download PDF">pdf</a>, <a href="/format/2311.04942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CSAM: A 2.5D Cross-Slice Attention Module for Anisotropic Volumetric  Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hung%2C+A+L+Y">Alex Ling Yu Hung</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+H">Haoxin Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+K">Kai Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Du%2C+X">Xiaoxi Du</a>, 
<a href="/search/eess?searchtype=author&query=Pang%2C+K">Kaifeng Pang</a>, 
<a href="/search/eess?searchtype=author&query=Miao%2C+Q">Qi Miao</a>, 
<a href="/search/eess?searchtype=author&query=Raman%2C+S+S">Steven S. Raman</a>, 
<a href="/search/eess?searchtype=author&query=Terzopoulos%2C+D">Demetri Terzopoulos</a>, 
<a href="/search/eess?searchtype=author&query=Sung%2C+K">Kyunghyun Sung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item663">[663]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05332" title="Abstract">arXiv:2311.05332</a> (replaced) [<a href="/pdf/2311.05332" title="Download PDF">pdf</a>, <a href="/format/2311.05332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Road with GPT-4V(ision): Early Explorations of Visual-Language  Model on Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+L">Licheng Wen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xuemeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+D">Daocheng Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaofeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+P">Pinlong Cai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+T">Tao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yingxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Linran Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+D">Dengke Shang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shaoyan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yeqi Bai</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xinyu Cai</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+M">Min Dou</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shuanglu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Botian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item664">[664]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05521" title="Abstract">arXiv:2311.05521</a> (replaced) [<a href="/pdf/2311.05521" title="Download PDF">pdf</a>, <a href="/format/2311.05521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BakedAvatar: Baking Neural Fields for Real-Time Head Avatar Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+H">Hao-Bin Duan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Miao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jin-Chuan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xu-Chuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yan-Pei Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM Transactions on Graphics (SIGGRAPH Asia 2023). Project Page: <a href="https://buaavrcg.github.io/BakedAvatar">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM Trans. Graph. 42, 6, Article 225 (December 2023), 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item665">[665]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06542" title="Abstract">arXiv:2311.06542</a> (replaced) [<a href="/pdf/2311.06542" title="Download PDF">pdf</a>, <a href="/ps/2311.06542" title="Download PostScript">ps</a>, <a href="/format/2311.06542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generation Of Colors using Bidirectional Long Short Term Memory Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sinha%2C+A">A. Sinha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item666">[666]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06864" title="Abstract">arXiv:2311.06864</a> (replaced) [<a href="/pdf/2311.06864" title="Download PDF">pdf</a>, <a href="/format/2311.06864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Practices around Computational News Discovery Tools in the  Domain of Science Journalism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nishal%2C+S">Sachita Nishal</a>, 
<a href="/search/cs?searchtype=author&query=Sinchai%2C+J">Jasmine Sinchai</a>, 
<a href="/search/cs?searchtype=author&query=Diakopoulos%2C+N">Nicholas Diakopoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in CSCW 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item667">[667]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06965" title="Abstract">arXiv:2311.06965</a> (replaced) [<a href="/pdf/2311.06965" title="Download PDF">pdf</a>, <a href="/format/2311.06965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anchor Data Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schneider%2C+N">Nora Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Goshtasbpour%2C+S">Shirin Goshtasbpour</a>, 
<a href="/search/cs?searchtype=author&query=Perez-Cruz%2C+F">Fernando Perez-Cruz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item668">[668]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07089" title="Abstract">arXiv:2311.07089</a> (replaced) [<a href="/pdf/2311.07089" title="Download PDF">pdf</a>, <a href="/ps/2311.07089" title="Download PostScript">ps</a>, <a href="/format/2311.07089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recursive and non-recursive filters for sequential smoothing and  prediction with instantaneous phase and frequency estimation applications  (extended version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kennedy%2C+H+L">Hugh Lachlan Kennedy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Reduced page count from 80 down to 50 by removing page breaks between figures and reducing figure size. Added page numbers. Added (extended version) to title
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item669">[669]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07222" title="Abstract">arXiv:2311.07222</a> (replaced) [<a href="/pdf/2311.07222" title="Download PDF">pdf</a>, <a href="/format/2311.07222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural General Circulation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Kochkov%2C+D">Dmitrii Kochkov</a>, 
<a href="/search/physics?searchtype=author&query=Yuval%2C+J">Janni Yuval</a>, 
<a href="/search/physics?searchtype=author&query=Langmore%2C+I">Ian Langmore</a>, 
<a href="/search/physics?searchtype=author&query=Norgaard%2C+P">Peter Norgaard</a>, 
<a href="/search/physics?searchtype=author&query=Smith%2C+J">Jamie Smith</a>, 
<a href="/search/physics?searchtype=author&query=Mooers%2C+G">Griffin Mooers</a>, 
<a href="/search/physics?searchtype=author&query=Lottes%2C+J">James Lottes</a>, 
<a href="/search/physics?searchtype=author&query=Rasp%2C+S">Stephan Rasp</a>, 
<a href="/search/physics?searchtype=author&query=D%C3%BCben%2C+P">Peter D&#xfc;ben</a>, 
<a href="/search/physics?searchtype=author&query=Kl%C3%B6wer%2C+M">Milan Kl&#xf6;wer</a>, 
<a href="/search/physics?searchtype=author&query=Hatfield%2C+S">Sam Hatfield</a>, 
<a href="/search/physics?searchtype=author&query=Battaglia%2C+P">Peter Battaglia</a>, 
<a href="/search/physics?searchtype=author&query=Sanchez-Gonzalez%2C+A">Alvaro Sanchez-Gonzalez</a>, 
<a href="/search/physics?searchtype=author&query=Willson%2C+M">Matthew Willson</a>, 
<a href="/search/physics?searchtype=author&query=Brenner%2C+M+P">Michael P. Brenner</a>, 
<a href="/search/physics?searchtype=author&query=Hoyer%2C+S">Stephan Hoyer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 67 pages, 34 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item670">[670]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08223" title="Abstract">arXiv:2311.08223</a> (replaced) [<a href="/pdf/2311.08223" title="Download PDF">pdf</a>, <a href="/format/2311.08223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Image Captioning via Predicting Structured Concepts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Ting Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weidong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuanhe Tian</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yan Song</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Z">Zhendong Mao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EMNLP 2023 (Main Conference, Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item671">[671]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08269" title="Abstract">arXiv:2311.08269</a> (replaced) [<a href="/pdf/2311.08269" title="Download PDF">pdf</a>, <a href="/format/2311.08269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Defining the boundaries: challenges and advances in identifying cells in  microscopy images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Gogoberidze%2C+N">Nodar Gogoberidze</a>, 
<a href="/search/q-bio?searchtype=author&query=Cimini%2C+B+A">Beth A. Cimini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 1 figure, submitted to "Current Opinion in Biotechnology"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item672">[672]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08313" title="Abstract">arXiv:2311.08313</a> (replaced) [<a href="/pdf/2311.08313" title="Download PDF">pdf</a>, <a href="/ps/2311.08313" title="Download PostScript">ps</a>, <a href="/format/2311.08313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Fast Track to Full Gold Open Access
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kudeli%C4%87%2C+R">Robert Kudeli&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
</div>
</dd>
<dt><a name="item673">[673]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08379" title="Abstract">arXiv:2311.08379</a> (replaced) [<a href="/pdf/2311.08379" title="Download PDF">pdf</a>, <a href="/format/2311.08379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scheming AIs: Will AIs fake alignment during training in order to get  power?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carlsmith%2C+J">Joe Carlsmith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 127 pages, 8 figures. Revised again to correct typos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item674">[674]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09049" title="Abstract">arXiv:2311.09049</a> (replaced) [<a href="/pdf/2311.09049" title="Download PDF">pdf</a>, <a href="/format/2311.09049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapting Large Language Models by Integrating Collaborative Semantics  for Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Bowen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yupeng Hou</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hongyu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W+X">Wayne Xin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Ming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Ji-Rong Wen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item675">[675]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09312" title="Abstract">arXiv:2311.09312</a> (replaced) [<a href="/pdf/2311.09312" title="Download PDF">pdf</a>, <a href="/format/2311.09312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> H-Packer: Holographic Rotationally Equivariant Convolutional Neural  Network for Protein Side-Chain Packing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Visani%2C+G+M">Gian Marco Visani</a>, 
<a href="/search/q-bio?searchtype=author&query=Galvin%2C+W">William Galvin</a>, 
<a href="/search/q-bio?searchtype=author&query=Pun%2C+M+N">Michael Neal Pun</a>, 
<a href="/search/q-bio?searchtype=author&query=Nourmohammad%2C+A">Armita Nourmohammad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a conference paper at MLCB 2023. 8 pages main body, 20 pages with appendix. 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item676">[676]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09506" title="Abstract">arXiv:2311.09506</a> (replaced) [<a href="/pdf/2311.09506" title="Download PDF">pdf</a>, <a href="/format/2311.09506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating the Impact of Weight Sharing Decisions on Knowledge  Transfer in Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Andle%2C+J">Josh Andle</a>, 
<a href="/search/cs?searchtype=author&query=Payani%2C+A">Ali Payani</a>, 
<a href="/search/cs?searchtype=author&query=Yasaei-Sekeh%2C+S">Salimeh Yasaei-Sekeh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 Figures, 4 Tables, 2 Algorithms
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item677">[677]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09790" title="Abstract">arXiv:2311.09790</a> (replaced) [<a href="/pdf/2311.09790" title="Download PDF">pdf</a>, <a href="/format/2311.09790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Breaking Boundaries: Balancing Performance and Robustness in Deep  Wireless Traffic Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ilbert%2C+R">Romain Ilbert</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+T+V">Thai V. Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zonghua Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Palpanas%2C+T">Themis Palpanas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation at the ARTMAN workshop, part of the ACM Conference on Computer and Communications Security (CCS), 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 2023 Workshop on Recent Advances in Resilient
  and Trustworthy ML Systems in Autonomous Networks; pp.17-28
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item678">[678]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10776" title="Abstract">arXiv:2311.10776</a> (replaced) [<a href="/pdf/2311.10776" title="Download PDF">pdf</a>, <a href="/format/2311.10776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards an Automatic AI Agent for Reaction Condition Recommendation in  Chemical Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kexin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junyou Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kunyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yuyang Du</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jiahui Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiamin Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lanqing Li</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+J">Jiezhong Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Q">Qun Fang</a>, 
<a href="/search/cs?searchtype=author&query=Heng%2C+P+A">Pheng Ann Heng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guangyong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item679">[679]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11255" title="Abstract">arXiv:2311.11255</a> (replaced) [<a href="/pdf/2311.11255" title="Download PDF">pdf</a>, <a href="/format/2311.11255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> M$^{2}$UGen: Multi-modal Music Understanding and Generation with the  Power of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hussain%2C+A+S">Atin Sakkeer Hussain</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shansong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Chenshuo Sun</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item680">[680]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11567" title="Abstract">arXiv:2311.11567</a> (replaced) [<a href="/pdf/2311.11567" title="Download PDF">pdf</a>, <a href="/format/2311.11567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CORE-MM: Complex Open-Ended Reasoning Evaluation For Multi-Modal Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiaotian Han</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Q">Quanzeng You</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yongfei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wentao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Huangjie Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Mrini%2C+K">Khalil Mrini</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xudong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+B">Bohan Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jianbo Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Heng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hongxia Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item681">[681]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11876" title="Abstract">arXiv:2311.11876</a> (replaced) [<a href="/pdf/2311.11876" title="Download PDF">pdf</a>, <a href="/format/2311.11876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forward Gradients for Data-Driven CFD Wall Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=H%C3%BCckelheim%2C+J">Jan H&#xfc;ckelheim</a>, 
<a href="/search/physics?searchtype=author&query=Kumar%2C+T">Tadbhagya Kumar</a>, 
<a href="/search/physics?searchtype=author&query=Raghavan%2C+K">Krishnan Raghavan</a>, 
<a href="/search/physics?searchtype=author&query=Pal%2C+P">Pinaki Pal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item682">[682]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12089" title="Abstract">arXiv:2311.12089</a> (replaced) [<a href="/pdf/2311.12089" title="Download PDF">pdf</a>, <a href="/ps/2311.12089" title="Download PostScript">ps</a>, <a href="/format/2311.12089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explaining Deep Learning Models for Age-related Gait Classification  based on time series acceleration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiaoping Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Otten%2C+B">Bert Otten</a>, 
<a href="/search/cs?searchtype=author&query=Reneman%2C+M+F">Michiel F Reneman</a>, 
<a href="/search/cs?searchtype=author&query=Lamoth%2C+C+J">Claudine JC Lamoth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item683">[683]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12144" title="Abstract">arXiv:2311.12144</a> (replaced) [<a href="/pdf/2311.12144" title="Download PDF">pdf</a>, <a href="/ps/2311.12144" title="Download PostScript">ps</a>, <a href="/format/2311.12144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applications of Large Scale Foundation Models for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yue Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhu Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages. arXiv admin note: text overlap with <a href="/abs/2304.03589">arXiv:2304.03589</a>, <a href="/abs/2306.03000">arXiv:2306.03000</a>, <a href="/abs/2310.01415">arXiv:2310.01415</a>, <a href="/abs/2310.14414">arXiv:2310.14414</a>, <a href="/abs/2309.10228">arXiv:2309.10228</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item684">[684]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12399" title="Abstract">arXiv:2311.12399</a> (replaced) [<a href="/pdf/2311.12399" title="Download PDF">pdf</a>, <a href="/format/2311.12399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Graph Meets Large Language Model: Progress and Future  Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuhan Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhixun Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peisong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiangguo Sun</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hong Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J+X">Jeffrey Xu Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress; 13 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item685">[685]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12609" title="Abstract">arXiv:2311.12609</a> (replaced) [<a href="/pdf/2311.12609" title="Download PDF">pdf</a>, <a href="/format/2311.12609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Learning for the Near-Optimal Design of Zero-Delay Codes  for Markov Sources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cregg%2C+L">Liam Cregg</a>, 
<a href="/search/cs?searchtype=author&query=Linder%2C+T">Tamas Linder</a>, 
<a href="/search/cs?searchtype=author&query=Yuksel%2C+S">Serdar Yuksel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 3 figures; added discussion and references to literature review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item686">[686]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12702" title="Abstract">arXiv:2311.12702</a> (replaced) [<a href="/pdf/2311.12702" title="Download PDF">pdf</a>, <a href="/ps/2311.12702" title="Download PostScript">ps</a>, <a href="/format/2311.12702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;There Has To Be a Lot That We&#x27;re Missing&quot;: Moderating AI-Generated  Content on Reddit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lloyd%2C+T">Travis Lloyd</a>, 
<a href="/search/cs?searchtype=author&query=Reagle%2C+J">Joseph Reagle</a>, 
<a href="/search/cs?searchtype=author&query=Naaman%2C+M">Mor Naaman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item687">[687]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12793" title="Abstract">arXiv:2311.12793</a> (replaced) [<a href="/pdf/2311.12793" title="Download PDF">pdf</a>, <a href="/format/2311.12793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ShareGPT4V: Improving Large Multi-Modal Models with Better Captions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinsong Li</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xiaoyi Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Conghui He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+F">Feng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project: <a href="https://ShareGPT4V.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item688">[688]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12824" title="Abstract">arXiv:2311.12824</a> (replaced) [<a href="/pdf/2311.12824" title="Download PDF">pdf</a>, <a href="/ps/2311.12824" title="Download PostScript">ps</a>, <a href="/format/2311.12824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative Analysis of Shear Strength Prediction Models for Reinforced  Concrete Slab-Column Connections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wahab%2C+S">Sarmed Wahab</a>, 
<a href="/search/cs?searchtype=author&query=Mahmoudabadi%2C+N+S">Nasim Shakouri Mahmoudabadi</a>, 
<a href="/search/cs?searchtype=author&query=Waqas%2C+S">Sarmad Waqas</a>, 
<a href="/search/cs?searchtype=author&query=Herl%2C+N">Nouman Herl</a>, 
<a href="/search/cs?searchtype=author&query=Iqbal%2C+M">Muhammad Iqbal</a>, 
<a href="/search/cs?searchtype=author&query=Alam%2C+K">Khurshid Alam</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+A">Afaq Ahmad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 Pages,25 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item689">[689]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12878" title="Abstract">arXiv:2311.12878</a> (replaced) [<a href="/pdf/2311.12878" title="Download PDF">pdf</a>, <a href="/format/2311.12878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Bayesian Learning with Action and State-Dependent Signal  Variance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Hou%2C+K">Kaiwen Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Econometrics (econ.EM); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item690">[690]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12890" title="Abstract">arXiv:2311.12890</a> (replaced) [<a href="/pdf/2311.12890" title="Download PDF">pdf</a>, <a href="/format/2311.12890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> De-fine: Decomposing and Refining Visual Programs with Auto-Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+M">Minghe Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Juncheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Fei%2C+H">Hao Fei</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+L">Liang Pang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+W">Wei Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guoming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenqiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Siliang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Y">Yueting Zhuang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item691">[691]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13148" title="Abstract">arXiv:2311.13148</a> (replaced) [<a href="/pdf/2311.13148" title="Download PDF">pdf</a>, <a href="/format/2311.13148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building the Future of Responsible AI: A Reference Architecture for  Designing Large Language Model based Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Q">Qinghua Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Liming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Z">Zhenchang Xing</a>, 
<a href="/search/cs?searchtype=author&query=Harrer%2C+S">Stefan Harrer</a>, 
<a href="/search/cs?searchtype=author&query=Whittle%2C+J">Jon Whittle</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item692">[692]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13409" title="Abstract">arXiv:2311.13409</a> (replaced) [<a href="/pdf/2311.13409" title="Download PDF">pdf</a>, <a href="/format/2311.13409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CompenHR: Efficient Full Compensation for High-resolution Projector
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+H">Haibin Ling</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Bingyao Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item693">[693]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13846" title="Abstract">arXiv:2311.13846</a> (replaced) [<a href="/pdf/2311.13846" title="Download PDF">pdf</a>, <a href="/format/2311.13846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Progressive Learning with Visual Prompt Tuning for Variable-Rate Image  Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+S">Shiyu Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yimin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bin Chen</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+B">Baoyi An</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+T">Tao Dai</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Shu-Tao Xia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item694">[694]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13847" title="Abstract">arXiv:2311.13847</a> (replaced) [<a href="/pdf/2311.13847" title="Download PDF">pdf</a>, <a href="/format/2311.13847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perceptual Image Compression with Cooperative Cross-Modal Side  Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+S">Shiyu Qin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yujun Huang</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+B">Baoyi An</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+T">Tao Dai</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Shu-Tao Xia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Theory (cs.IT); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item695">[695]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14494" title="Abstract">arXiv:2311.14494</a> (replaced) [<a href="/pdf/2311.14494" title="Download PDF">pdf</a>, <a href="/format/2311.14494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MVControl: Adding Conditional Control to Multi-view Diffusion for  Controllable Text-to-3D Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lingzhe Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Peidong Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://lizhiqi49.github.io/MVControl/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item696">[696]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14552" title="Abstract">arXiv:2311.14552</a> (replaced) [<a href="/pdf/2311.14552" title="Download PDF">pdf</a>, <a href="/format/2311.14552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Griffon: Spelling out All Object Locations at Any Granularity with Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Y">Yufei Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yousong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhiyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+M">Ming Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinqiao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report. The codes and dataset will be released soon at <a href="https://github.com/jefferyZhan/Griffon">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item697">[697]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14646" title="Abstract">arXiv:2311.14646</a> (replaced) [<a href="/pdf/2311.14646" title="Download PDF">pdf</a>, <a href="/format/2311.14646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> More is Better in Modern Machine Learning: when Infinite  Overparameterization is Optimal and Overfitting is Obligatory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Simon%2C+J+B">James B. Simon</a>, 
<a href="/search/cs?searchtype=author&query=Karkada%2C+D">Dhruva Karkada</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+N">Nikhil Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Belkin%2C+M">Mikhail Belkin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item698">[698]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14679" title="Abstract">arXiv:2311.14679</a> (replaced) [<a href="/pdf/2311.14679" title="Download PDF">pdf</a>, <a href="/ps/2311.14679" title="Download PostScript">ps</a>, <a href="/format/2311.14679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Medium-n studies&quot; in computing education conferences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guerzhoy%2C+M">Michael Guerzhoy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Koli Calling 2023: 23rd International Conference on Computing Education Research
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item699">[699]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14680" title="Abstract">arXiv:2311.14680</a> (replaced) [<a href="/pdf/2311.14680" title="Download PDF">pdf</a>, <a href="/ps/2311.14680" title="Download PostScript">ps</a>, <a href="/format/2311.14680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> E-polis: A serious game for the gamification of sociological surveys
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gazis%2C+A">Alexandros Gazis</a>, 
<a href="/search/cs?searchtype=author&query=Katsiri%2C+E">Eleftheria Katsiri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 11 figures, Proceedings of the International Conference on Applied Mathematics &amp; Computer Science (ICAMCS) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Graphics (cs.GR); Multimedia (cs.MM); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item700">[700]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14829" title="Abstract">arXiv:2311.14829</a> (replaced) [<a href="/e-print/2311.14829" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proximal Algorithms for Accelerated Langevin Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thai%2C+D+H">Duy H. Thai</a>, 
<a href="/search/cs?searchtype=author&query=Young%2C+A+L">Alexander L. Young</a>, 
<a href="/search/cs?searchtype=author&query=Dunson%2C+D+B">David B. Dunson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The technical proofs for the paper will be revised
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item701">[701]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14875" title="Abstract">arXiv:2311.14875</a> (replaced) [<a href="/pdf/2311.14875" title="Download PDF">pdf</a>, <a href="/format/2311.14875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty Aware AI for 2D MRI Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Konathala%2C+L">Lohith Konathala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 Pages, 9 Figures Updated to Correct Typos, Revise Title
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item702">[702]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14968" title="Abstract">arXiv:2311.14968</a> (replaced) [<a href="/pdf/2311.14968" title="Download PDF">pdf</a>, <a href="/format/2311.14968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hide Your Model: A Parameter Transmission-free Federated Recommender  System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Wei Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chaoqun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+L">Liang Qu</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q+V+H">Quoc Viet Hung Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hongzhi Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item703">[703]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14971" title="Abstract">arXiv:2311.14971</a> (replaced) [<a href="/pdf/2311.14971" title="Download PDF">pdf</a>, <a href="/ps/2311.14971" title="Download PostScript">ps</a>, <a href="/format/2311.14971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segmentation of diagnostic tissue compartments on whole slide images  with renal thrombotic microangiopathies (TMAs)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vo%2C+H+Q">Huy Q. Vo</a>, 
<a href="/search/cs?searchtype=author&query=Cicalese%2C+P+A">Pietro A. Cicalese</a>, 
<a href="/search/cs?searchtype=author&query=Seshan%2C+S">Surya Seshan</a>, 
<a href="/search/cs?searchtype=author&query=Rizvi%2C+S+A">Syed A. Rizvi</a>, 
<a href="/search/cs?searchtype=author&query=Vathul%2C+A">Aneesh Vathul</a>, 
<a href="/search/cs?searchtype=author&query=Bueno%2C+G">Gloria Bueno</a>, 
<a href="/search/cs?searchtype=author&query=Dorado%2C+A+P">Anibal Pedraza Dorado</a>, 
<a href="/search/cs?searchtype=author&query=Grabe%2C+N">Niels Grabe</a>, 
<a href="/search/cs?searchtype=author&query=Stolle%2C+K">Katharina Stolle</a>, 
<a href="/search/cs?searchtype=author&query=Pesce%2C+F">Francesco Pesce</a>, 
<a href="/search/cs?searchtype=author&query=Roelofs%2C+J+J+T+H">Joris J.T.H. Roelofs</a>, 
<a href="/search/cs?searchtype=author&query=Kers%2C+J">Jesper Kers</a>, 
<a href="/search/cs?searchtype=author&query=Bevilacqua%2C+V">Vitoantonio Bevilacqua</a>, 
<a href="/search/cs?searchtype=author&query=Altini%2C+N">Nicola Altini</a>, 
<a href="/search/cs?searchtype=author&query=Schr%C3%B6ppel%2C+B">Bernd Schr&#xf6;ppel</a>, 
<a href="/search/cs?searchtype=author&query=Roccatello%2C+D">Dario Roccatello</a>, 
<a href="/search/cs?searchtype=author&query=Barreca%2C+A">Antonella Barreca</a>, 
<a href="/search/cs?searchtype=author&query=Sciascia%2C+S">Savino Sciascia</a>, 
<a href="/search/cs?searchtype=author&query=Mohan%2C+C">Chandra Mohan</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H+V">Hien V. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Becker%2C+J+U">Jan U. Becker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Tissues and Organs (q-bio.TO)

</div>
</div>
</dd>
<dt><a name="item704">[704]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15111" title="Abstract">arXiv:2311.15111</a> (replaced) [<a href="/pdf/2311.15111" title="Download PDF">pdf</a>, <a href="/format/2311.15111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAMv2: A Unified Framework for Learning Appearance, Semantic and  Cross-Modality Anatomical Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiaoyu Bai</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+F">Fan Bai</a>, 
<a href="/search/cs?searchtype=author&query=Huo%2C+X">Xiaofei Huo</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+J">Jia Ge</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jingjing Lu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+X">Xianghua Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+K">Ke Yan</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yong Xia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item705">[705]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15243" title="Abstract">arXiv:2311.15243</a> (replaced) [<a href="/pdf/2311.15243" title="Download PDF">pdf</a>, <a href="/format/2311.15243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ID-like Prompt Learning for Few-Shot Out-of-Distribution Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yichen Bai</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zongbo Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Changqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+B">Bing Cao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xiaoheng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qinghua Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item706">[706]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15376" title="Abstract">arXiv:2311.15376</a> (replaced) [<a href="/pdf/2311.15376" title="Download PDF">pdf</a>, <a href="/ps/2311.15376" title="Download PostScript">ps</a>, <a href="/format/2311.15376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constructive validity of a generalized Kreisel-Putnam rule
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pezlar%2C+I">Ivo Pezlar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Logic (math.LO)

</div>
</div>
</dd>
<dt><a name="item707">[707]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15544" title="Abstract">arXiv:2311.15544</a> (replaced) [<a href="/pdf/2311.15544" title="Download PDF">pdf</a>, <a href="/format/2311.15544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The effect of source disclosure on evaluation of AI-generated messages:  A two-part study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lim%2C+S">Sue Lim</a>, 
<a href="/search/cs?searchtype=author&query=Schm%C3%A4lzle%2C+R">Ralf Schm&#xe4;lzle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Manuscript currently under review. Paper presented at 109th Annual National Communication Association (NCA) Conference, November 16-19, 2023. 10 pages, 5 figures. Supplementary file formatting updated in current version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item708">[708]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15830" title="Abstract">arXiv:2311.15830</a> (replaced) [<a href="/pdf/2311.15830" title="Download PDF">pdf</a>, <a href="/format/2311.15830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A-JEPA: Joint-Embedding Predictive Architecture Can Listen
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fei%2C+Z">Zhengcong Fei</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+M">Mingyuan Fan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Junshi Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computer Vision and Pattern Recognition (cs.CV); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item709">[709]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15936" title="Abstract">arXiv:2311.15936</a> (replaced) [<a href="/pdf/2311.15936" title="Download PDF">pdf</a>, <a href="/format/2311.15936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Responsible Governance of Biological Design Tools
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moulange%2C+R">Richard Moulange</a>, 
<a href="/search/cs?searchtype=author&query=Langenkamp%2C+M">Max Langenkamp</a>, 
<a href="/search/cs?searchtype=author&query=Alexanian%2C+T">Tessa Alexanian</a>, 
<a href="/search/cs?searchtype=author&query=Curtis%2C+S">Samuel Curtis</a>, 
<a href="/search/cs?searchtype=author&query=Livingston%2C+M">Morgan Livingston</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages + references, 1 figure, accepted at NeurIPS 2023 Workshop on Regulatable ML as oral presentation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item710">[710]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15951" title="Abstract">arXiv:2311.15951</a> (replaced) [<a href="/pdf/2311.15951" title="Download PDF">pdf</a>, <a href="/format/2311.15951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Replay across Experiments: A Natural Extension of Off-Policy RL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tirumala%2C+D">Dhruva Tirumala</a>, 
<a href="/search/cs?searchtype=author&query=Lampe%2C+T">Thomas Lampe</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J+E">Jose Enrique Chen</a>, 
<a href="/search/cs?searchtype=author&query=Haarnoja%2C+T">Tuomas Haarnoja</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Sandy Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lever%2C+G">Guy Lever</a>, 
<a href="/search/cs?searchtype=author&query=Moran%2C+B">Ben Moran</a>, 
<a href="/search/cs?searchtype=author&query=Hertweck%2C+T">Tim Hertweck</a>, 
<a href="/search/cs?searchtype=author&query=Hasenclever%2C+L">Leonard Hasenclever</a>, 
<a href="/search/cs?searchtype=author&query=Riedmiller%2C+M">Martin Riedmiller</a>, 
<a href="/search/cs?searchtype=author&query=Heess%2C+N">Nicolas Heess</a>, 
<a href="/search/cs?searchtype=author&query=Wulfmeier%2C+M">Markus Wulfmeier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item711">[711]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16103" title="Abstract">arXiv:2311.16103</a> (replaced) [<a href="/pdf/2311.16103" title="Download PDF">pdf</a>, <a href="/format/2311.16103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video-Bench: A Comprehensive Benchmark and Toolkit for Evaluating  Video-based Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ning%2C+M">Munan Ning</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Bin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yujia Xie</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B">Bin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Jiaxi Cui</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Lu Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dongdong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Li Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Benchmark is available at <a href="https://github.com/PKU-YuanGroup/Video-Bench">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item412">Cross-lists</a></li>
<li><a href="#item473">Replacements</a></li>
</ul>
<small>[ total of 711 entries:  <b>1-711</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2311">2311</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
