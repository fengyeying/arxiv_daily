<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Wed 22 Nov 23  to  Fri 24 Nov 23, announced Mon, 27 Nov 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item419">Cross-lists</a></li>
<li><a href="#item520">Replacements</a></li>
</ul>
<small>[ total of 803 entries:  <b>1-803</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Mon, 27 Nov 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13603" title="Abstract">arXiv:2311.13603</a> [<a href="/pdf/2311.13603" title="Download PDF">pdf</a>, <a href="/format/2311.13603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-layer scheme for low latency multiple description video streaming  over Vehicular Ad-hoc NETworks (VANETs)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Labiod%2C+M+A">Mohamed Aymen Labiod</a>, 
<a href="/search/cs?searchtype=author&query=Gharbi%2C+M">Mohamed Gharbi</a>, 
<a href="/search/cs?searchtype=author&query=Coudoux%2C+F">Francois-Xavier Coudoux</a>, 
<a href="/search/cs?searchtype=author&query=Corlay%2C+P">Patrick Corlay</a>, 
<a href="/search/cs?searchtype=author&query=Doghmane%2C+N">Noureddine Doghmane</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> AEU - International Journal of Electronics and Communications,
  Volume 104, 2019, Pages 23-34, ISSN 1434-8411
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM); Networking and Internet Architecture (cs.NI); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">There is nowadays a growing demand in vehicular communications for real-time
applications requiring video assistance. The new state-of-the-art
high-efficiency video coding (HEVC) standard is very promising for real-time
video streaming. It offers high coding efficiency, as well as dedicated low
delay coding structures. Among these, the all intra (AI) coding structure
guarantees minimal coding time at the expense of higher video bitrates, which
therefore penalizes transmission performances. In this work, we propose an
original cross-layer system in order to enhance received video quality in
vehicular communications. The system is low complex and relies on a multiple
description coding (MDC) approach. It is based on an adaptive mapping mechanism
applied at the IEEE 802.11p standard medium access control (MAC) layer.
Simulation results in a realistic vehicular environment demonstrate that for
low delay video communications, the proposed method provides significant video
quality improvements on the receiver side.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13608" title="Abstract">arXiv:2311.13608</a> [<a href="/pdf/2311.13608" title="Download PDF">pdf</a>, <a href="/format/2311.13608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Breathing Life Into Sketches Using Text-to-Video Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gal%2C+R">Rinon Gal</a>, 
<a href="/search/cs?searchtype=author&query=Vinker%2C+Y">Yael Vinker</a>, 
<a href="/search/cs?searchtype=author&query=Alaluf%2C+Y">Yuval Alaluf</a>, 
<a href="/search/cs?searchtype=author&query=Bermano%2C+A+H">Amit H. Bermano</a>, 
<a href="/search/cs?searchtype=author&query=Cohen-Or%2C+D">Daniel Cohen-Or</a>, 
<a href="/search/cs?searchtype=author&query=Shamir%2C+A">Ariel Shamir</a>, 
<a href="/search/cs?searchtype=author&query=Chechik%2C+G">Gal Chechik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://livesketch.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">A sketch is one of the most intuitive and versatile tools humans use to
convey their ideas visually. An animated sketch opens another dimension to the
expression of ideas and is widely used by designers for a variety of purposes.
Animating sketches is a laborious process, requiring extensive experience and
professional design skills. In this work, we present a method that
automatically adds motion to a single-subject sketch (hence, "breathing life
into it"), merely by providing a text prompt indicating the desired motion. The
output is a short animation provided in vector representation, which can be
easily edited. Our method does not require extensive training, but instead
leverages the motion prior of a large pretrained text-to-video diffusion model
using a score-distillation loss to guide the placement of strokes. To promote
natural and smooth motion and to better preserve the sketch's appearance, we
model the learned motion through two components. The first governs small local
deformations and the second controls global affine transformations.
Surprisingly, we find that even models that struggle to generate sketch videos
on their own can still serve as a useful backbone for animating abstract
representations.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13609" title="Abstract">arXiv:2311.13609</a> [<a href="/pdf/2311.13609" title="Download PDF">pdf</a>, <a href="/ps/2311.13609" title="Download PostScript">ps</a>, <a href="/format/2311.13609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Analysis on the Effects of Evolving the Monte Carlo Tree Search Upper  Confidence for Trees Selection Policy on Unimodal, Multimodal and Deceptive  Landscapes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Galvan%2C+E">Edgar Galvan</a>, 
<a href="/search/cs?searchtype=author&query=Ameneyro%2C+F+V">Fred Valdez Ameneyro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 7 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Monte Carlo Tree Search (MCTS) is a best-first sampling method employed in
the search for optimal decisions. The effectiveness of MCTS relies on the
construction of its statistical tree, with the selection policy playing a
crucial role. A selection policy that works particularly well in MCTS is the
Upper Confidence Bounds for Trees, referred to as UCT. The research community
has also put forth more sophisticated bounds aimed at enhancing MCTS
performance on specific problem domains. Thus, while MCTS UCT generally
performs well, there may be variants that outperform it. This has led to
various efforts to evolve selection policies for use in MCTS. While all of
these previous works are inspiring, none have undertaken an in-depth analysis
to shed light on the circumstances in which an evolved alternative to MCTS UCT
might prove advantageous. Most of these studies have focused on a single type
of problem. In sharp contrast, this work explores the use of five functions of
different natures, ranging from unimodal to multimodal and deceptive functions.
We illustrate how the evolution of MCTS UCT can yield benefits in multimodal
and deceptive scenarios, whereas MCTS UCT is robust in all of the functions
used in this work.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13610" title="Abstract">arXiv:2311.13610</a> [<a href="/pdf/2311.13610" title="Download PDF">pdf</a>, <a href="/format/2311.13610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TRIDENT: The Nonlinear Trilogy for Implicit Neural Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zhenda Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yanqi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+R+H">Raymond H. Chan</a>, 
<a href="/search/cs?searchtype=author&query=Li%C3%B2%2C+P">Pietro Li&#xf2;</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6nlieb%2C+C">Carola-Bibiane Sch&#xf6;nlieb</a>, 
<a href="/search/cs?searchtype=author&query=Aviles-Rivero%2C+A+I">Angelica I Aviles-Rivero</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Implicit neural representations (INRs) have garnered significant interest
recently for their ability to model complex, high-dimensional data without
explicit parameterisation. In this work, we introduce TRIDENT, a novel function
for implicit neural representations characterised by a trilogy of
nonlinearities. Firstly, it is designed to represent high-order features
through order compactness. Secondly, TRIDENT efficiently captures frequency
information, a feature called frequency compactness. Thirdly, it has the
capability to represent signals or images such that most of its energy is
concentrated in a limited spatial region, denoting spatial compactness. We
demonstrated through extensive experiments on various inverse problems that our
proposed function outperforms existing implicit neural representation
functions.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13612" title="Abstract">arXiv:2311.13612</a> [<a href="/pdf/2311.13612" title="Download PDF">pdf</a>, <a href="/format/2311.13612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Descriptor and Word Soups: Overcoming the Parameter Efficiency Accuracy  Tradeoff for Out-of-Distribution Few-shot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+C">Christopher Liao</a>, 
<a href="/search/cs?searchtype=author&query=Tsiligkaridis%2C+T">Theodoros Tsiligkaridis</a>, 
<a href="/search/cs?searchtype=author&query=Kulis%2C+B">Brian Kulis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Over the past year, a large body of multimodal research has emerged around
zero-shot evaluation using GPT descriptors. These studies boost the zero-shot
accuracy of pretrained VL models with an ensemble of label-specific text
generated by GPT. A recent study, WaffleCLIP, demonstrated that similar
zero-shot accuracy can be achieved with an ensemble of random descriptors.
However, both zero-shot methods are un-trainable and consequently sub-optimal
when some few-shot out-of-distribution (OOD) training data is available.
Inspired by these prior works, we present two more flexible methods called
descriptor and word soups, which do not require an LLM at test time and can
leverage training data to increase OOD target accuracy. Descriptor soup
greedily selects a small set of textual descriptors using generic few-shot
training data, then calculates robust class embeddings using the selected
descriptors. Word soup greedily assembles a chain of words in a similar manner.
Compared to existing few-shot soft prompt tuning methods, word soup requires
fewer parameters by construction and less GPU memory, since it does not require
backpropagation. Both soups outperform current published few-shot methods, even
when combined with SoTA zero-shot methods, on cross-dataset and domain
generalization benchmarks. Compared with SoTA prompt and descriptor ensembling
methods, such as ProDA and WaffleCLIP, word soup achieves higher OOD accuracy
with fewer ensemble members. Please checkout our code:
github.com/Chris210634/word_soups
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13613" title="Abstract">arXiv:2311.13613</a> [<a href="/pdf/2311.13613" title="Download PDF">pdf</a>, <a href="/format/2311.13613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spanning Training Progress: Temporal Dual-Depth Scoring (TDDS) for  Enhanced Dataset Pruning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+J">Jiawei Du</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunsong Li</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Weiying Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J+T">Joey Tianyi Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Dataset pruning aims to construct a coreset capable of achieving performance
comparable to the original, full dataset. Most existing dataset pruning methods
rely on snapshot-based criteria to identify representative samples, often
resulting in poor generalization across various pruning and cross-architecture
scenarios. Recent studies have addressed this issue by expanding the scope of
training dynamics considered, including factors such as forgetting event and
probability change, typically using an averaging approach. However, these works
struggle to integrate a broader range of training dynamics without overlooking
well-generalized samples, which may not be sufficiently highlighted in an
averaging manner. In this study, we propose a novel dataset pruning method
termed as Temporal Dual-Depth Scoring (TDDS), to tackle this problem. TDDS
utilizes a dual-depth strategy to achieve a balance between incorporating
extensive training dynamics and identifying representative samples for dataset
pruning. In the first depth, we estimate the series of each sample's individual
contributions spanning the training progress, ensuring comprehensive
integration of training dynamics. In the second depth, we focus on the
variability of the sample-wise contributions identified in the first depth to
highlight well-generalized samples. Extensive experiments conducted on CIFAR
and ImageNet datasets verify the superiority of TDDS over previous SOTA
methods. Specifically on CIFAR-100, our method achieves 54.51% accuracy with
only 10% training data, surpassing random selection by 7.83% and other
comparison methods by at least 12.69%.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13614" title="Abstract">arXiv:2311.13614</a> [<a href="/pdf/2311.13614" title="Download PDF">pdf</a>, <a href="/format/2311.13614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HalluciDoctor: Mitigating Hallucinatory Toxicity in Visual Instruction  Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qifan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Juncheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+L">Longhui Wei</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+L">Liang Pang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+W">Wentao Ye</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+B">Bosheng Qin</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Siliang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qi Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Y">Yueting Zhuang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multi-modal Large Language Models (MLLMs) tuned on machine-generated
instruction-following data have demonstrated remarkable performance in various
multi-modal understanding and generation tasks. However, the hallucinations
inherent in machine-generated data, which could lead to hallucinatory outputs
in MLLMs, remain under-explored. This work aims to investigate various
hallucinations (i.e., object, relation, attribute hallucinations) and mitigate
those hallucinatory toxicities in large-scale machine-generated visual
instruction datasets. Drawing on the human ability to identify factual errors,
we present a novel hallucination detection and elimination framework,
HalluciDoctor, based on the cross-checking paradigm. We use our framework to
identify and eliminate hallucinations in the training data automatically.
Interestingly, HalluciDoctor also indicates that spurious correlations arising
from long-tail object co-occurrences contribute to hallucinations. Based on
that, we execute counterfactual visual instruction expansion to balance data
distribution, thereby enhancing MLLMs' resistance to hallucinations.
Comprehensive experiments on hallucination evaluation benchmarks show that our
method successfully mitigates 44.6% hallucinations relatively and maintains
competitive performance compared to LLaVA.The source code will be released at
\url{https://github.com/Yuqifan1117/HalluciDoctor}.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13615" title="Abstract">arXiv:2311.13615</a> [<a href="/pdf/2311.13615" title="Download PDF">pdf</a>, <a href="/format/2311.13615" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HEViTPose: High-Efficiency Vision Transformer for Human Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chengpeng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+G">Guangxing Tan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chunyu Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Human pose estimation in complicated situations has always been a challenging
task. Many Transformer-based pose networks have been proposed recently,
achieving encouraging progress in improving performance. However, the
remarkable performance of pose networks is always accompanied by heavy
computation costs and large network scale. In order to deal with this problem,
this paper proposes a High-Efficiency Vision Transformer for Human Pose
Estimation (HEViTPose). In HEViTPose, a Cascaded Group Spatial Reduction
Multi-Head Attention Module (CGSR-MHA) is proposed, which reduces the
computational cost through feature grouping and spatial degradation mechanisms,
while preserving feature diversity through multiple low-dimensional attention
heads. Moreover, a concept of Patch Embedded Overlap Width (PEOW) is defined to
help understand the relationship between the amount of overlap and local
continuity. By optimising PEOW, our model gains improvements in performance,
parameters and GFLOPs.
<br />Comprehensive experiments on two benchmark datasets (MPII and COCO)
demonstrate that the small and large HEViTPose models are on par with
state-of-the-art models while being more lightweight. Specifically, HEViTPose-B
achieves 90.7 PCK@0.5 on the MPII test set and 72.6 AP on the COCO test-dev2017
set. Compared with HRNet-W32 and Swin-S, our HEViTPose-B significantly reducing
Params ($\downarrow$62.1%,$\downarrow$80.4%,) and GFLOPs
($\downarrow$43.4%,$\downarrow$63.8%,). Code and models are available at
\url{here}.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13617" title="Abstract">arXiv:2311.13617</a> [<a href="/pdf/2311.13617" title="Download PDF">pdf</a>, <a href="/format/2311.13617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting3D: High-Fidelity Image-to-3D by Boosting 2D Diffusion Prior to  3D Prior with Progressive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kai Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinlin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+M">Mengyang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+M">Miaomiao Cui</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xuansong Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present Boosting3D, a multi-stage single image-to-3D generation method
that can robustly generate reasonable 3D objects in different data domains. The
point of this work is to solve the view consistency problem in single
image-guided 3D generation by modeling a reasonable geometric structure. For
this purpose, we propose to utilize better 3D prior to training the NeRF. More
specifically, we train an object-level LoRA for the target object using
original image and the rendering output of NeRF. And then we train the LoRA and
NeRF using a progressive training strategy. The LoRA and NeRF will boost each
other while training. After the progressive training, the LoRA learns the 3D
information of the generated object and eventually turns to an object-level 3D
prior. In the final stage, we extract the mesh from the trained NeRF and use
the trained LoRA to optimize the structure and appearance of the mesh. The
experiments demonstrate the effectiveness of the proposed method. Boosting3D
learns object-specific 3D prior which is beyond the ability of pre-trained
diffusion priors and achieves state-of-the-art performance in the single
image-to-3d generation task.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13619" title="Abstract">arXiv:2311.13619</a> [<a href="/pdf/2311.13619" title="Download PDF">pdf</a>, <a href="/format/2311.13619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Steal My Artworks for Fine-tuning? A Watermarking Framework for  Detecting Art Theft Mimicry in Text-to-Image Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+G">Ge Luo</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Junqiang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Manman Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Z">Zhenxing Qian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinpeng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A Watermarking Framework for Detecting Art Theft Mimicry in Text-to-Image Models
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The advancement in text-to-image models has led to astonishing artistic
performances. However, several studios and websites illegally fine-tune these
models using artists' artworks to mimic their styles for profit, which violates
the copyrights of artists and diminishes their motivation to produce original
works. Currently, there is a notable lack of research focusing on this issue.
In this paper, we propose a novel watermarking framework that detects mimicry
in text-to-image models through fine-tuning. This framework embeds subtle
watermarks into digital artworks to protect their copyrights while still
preserving the artist's visual expression. If someone takes watermarked
artworks as training data to mimic an artist's style, these watermarks can
serve as detectable indicators. By analyzing the distribution of these
watermarks in a series of generated images, acts of fine-tuning mimicry using
stolen victim data will be exposed. In various fine-tune scenarios and against
watermark attack methods, our research confirms that analyzing the distribution
of watermarks in artificially generated images reliably detects unauthorized
mimicry.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13620" title="Abstract">arXiv:2311.13620</a> [<a href="/pdf/2311.13620" title="Download PDF">pdf</a>, <a href="/format/2311.13620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Challenges of Image Generation Models in Generating Multi-Component  Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Foong%2C+T+Y">Tham Yik Foong</a>, 
<a href="/search/cs?searchtype=author&query=Kotyan%2C+S">Shashank Kotyan</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+P+Y">Po Yuan Mao</a>, 
<a href="/search/cs?searchtype=author&query=Vargas%2C+D+V">Danilo Vasconcellos Vargas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures, and 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advances in text-to-image generators have led to substantial
capabilities in image generation. However, the complexity of prompts acts as a
bottleneck in the quality of images generated. A particular under-explored
facet is the ability of generative models to create high-quality images
comprising multiple components given as a prior. In this paper, we propose and
validate a metric called Components Inclusion Score (CIS) to evaluate the
extent to which a model can correctly generate multiple components. Our results
reveal that the evaluated models struggle to incorporate all the visual
elements from prompts with multiple components (8.53% drop in CIS per component
for all evaluated models). We also identify a significant decline in the
quality of the images and context awareness within an image as the number of
components increased (15.91% decrease in inception Score and 9.62% increase in
Frechet Inception Distance). To remedy this issue, we fine-tuned Stable
Diffusion V2 on a custom-created test dataset with multiple components,
outperforming its vanilla counterpart. To conclude, these findings reveal a
critical limitation in existing text-to-image generators, shedding light on the
challenge of generating multiple components within a single image using a
complex prompt.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13621" title="Abstract">arXiv:2311.13621</a> [<a href="/pdf/2311.13621" title="Download PDF">pdf</a>, <a href="/format/2311.13621" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge From the Dark Side: Entropy-Reweighted Knowledge Distillation  for Balanced Knowledge Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+C">Chi-Ping Su</a>, 
<a href="/search/cs?searchtype=author&query=Tseng%2C+C">Ching-Hsun Tseng</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Shin-Jye Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Knowledge Distillation (KD) transfers knowledge from a larger "teacher" model
to a compact "student" model, guiding the student with the "dark knowledge"
$\unicode{x2014}$ the implicit insights present in the teacher's soft
predictions. Although existing KDs have shown the potential of transferring
knowledge, the gap between the two parties still exists. With a series of
investigations, we argue the gap is the result of the student's overconfidence
in prediction, signaling an imbalanced focus on pronounced features while
overlooking the subtle yet crucial dark knowledge. To overcome this, we
introduce the Entropy-Reweighted Knowledge Distillation (ER-KD), a novel
approach that leverages the entropy in the teacher's predictions to reweight
the KD loss on a sample-wise basis. ER-KD precisely refocuses the student on
challenging instances rich in the teacher's nuanced insights while reducing the
emphasis on simpler cases, enabling a more balanced knowledge transfer.
Consequently, ER-KD not only demonstrates compatibility with various
state-of-the-art KD methods but also further enhances their performance at
negligible cost. This approach offers a streamlined and effective strategy to
refine the knowledge transfer process in KD, setting a new paradigm in the
meticulous handling of dark knowledge. Our code is available at
https://github.com/cpsu00/ER-KD.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13622" title="Abstract">arXiv:2311.13622</a> [<a href="/pdf/2311.13622" title="Download PDF">pdf</a>, <a href="/format/2311.13622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TDiffDe: A Truncated Diffusion Model for Remote Sensing Hyperspectral  Image Denoising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiang He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yajie Li</a>, 
<a href="/search/cs?searchtype=author&query=L%2C+J">Jie L</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Q">Qiangqiang Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Hyperspectral images play a crucial role in precision agriculture,
environmental monitoring or ecological analysis. However, due to sensor
equipment and the imaging environment, the observed hyperspectral images are
often inevitably corrupted by various noise. In this study, we proposed a
truncated diffusion model, called TDiffDe, to recover the useful information in
hyperspectral images gradually. Rather than starting from a pure noise, the
input data contains image information in hyperspectral image denoising. Thus,
we cut the trained diffusion model from small steps to avoid the destroy of
valid information.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13623" title="Abstract">arXiv:2311.13623</a> [<a href="/pdf/2311.13623" title="Download PDF">pdf</a>, <a href="/format/2311.13623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Density Distribution-based Learning Framework for Addressing Online  Continual Learning Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shilin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiahui Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In this paper, we address the challenges of online Continual Learning (CL) by
introducing a density distribution-based learning framework. CL, especially the
Class Incremental Learning, enables adaptation to new test distributions while
continuously learning from a single-pass training data stream, which is more in
line with the practical application requirements of real-world scenarios.
However, existing CL methods often suffer from catastrophic forgetting and
higher computing costs due to complex algorithm designs, limiting their
practical use. Our proposed framework overcomes these limitations by achieving
superior average accuracy and time-space efficiency, bridging the performance
gap between CL and classical machine learning. Specifically, we adopt an
independent Generative Kernel Density Estimation (GKDE) model for each CL task.
During the testing stage, the GKDEs utilize a self-reported max probability
density value to determine which one is responsible for predicting incoming
test instances. A GKDE-based learning objective can ensure that samples with
the same label are grouped together, while dissimilar instances are pushed
farther apart. Extensive experiments conducted on multiple CL datasets validate
the effectiveness of our proposed framework. Our method outperforms popular CL
approaches by a significant margin, while maintaining competitive time-space
efficiency, making our framework suitable for real-world applications. Code
will be available at https://github.com/xxxx/xxxx.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13624" title="Abstract">arXiv:2311.13624</a> [<a href="/pdf/2311.13624" title="Download PDF">pdf</a>, <a href="/format/2311.13624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Theoretical Insight into Attack and Defense of Gradient Leakage in  Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhao Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weixin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chiwun Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The Deep Leakage from Gradient (DLG) attack has emerged as a prevalent and
highly effective method for extracting sensitive training data by inspecting
exchanged gradients. This approach poses a substantial threat to the privacy of
individuals and organizations alike. This research presents a comprehensive
analysis of the gradient leakage method when applied specifically to
transformer-based models. Through meticulous examination, we showcase the
capability to accurately recover data solely from gradients and rigorously
investigate the conditions under which gradient attacks can be executed,
providing compelling evidence. Furthermore, we reevaluate the approach of
introducing additional noise on gradients as a protective measure against
gradient attacks. To address this, we outline a theoretical proof that analyzes
the associated privacy costs within the framework of differential privacy.
Additionally, we affirm the convergence of the Stochastic Gradient Descent
(SGD) algorithm under perturbed gradients. The primary objective of this study
is to augment the understanding of gradient leakage attack and defense
strategies while actively contributing to the development of privacy-preserving
techniques specifically tailored for transformer-based models. By shedding
light on the vulnerabilities and countermeasures associated with gradient
leakage, this research aims to foster advancements in safeguarding sensitive
data and upholding privacy in the context of transformer-based models.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13627" title="Abstract">arXiv:2311.13627</a> [<a href="/pdf/2311.13627" title="Download PDF">pdf</a>, <a href="/format/2311.13627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vamos: Versatile Action Models for Video Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shijie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Do%2C+M+Q">Minh Quan Do</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+N">Nakul Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kwonjoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Chen Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under submission. Code and models will be released at <a href="https://brown-palm.github.io/Vamos/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">What makes good video representations for video understanding, such as
anticipating future activities, or answering video-conditioned questions? While
earlier approaches focus on end-to-end learning directly from video pixels, we
propose to revisit text-based representations, such as discrete action labels,
or free-form video captions, which are interpretable and can be directly
consumed by large language models (LLMs). Intuitively, different video
understanding tasks may require representations that are complementary and at
different granularities. To this end, we propose versatile action models
(Vamos), a learning framework powered by a large language model as the
"reasoner", and can flexibly leverage visual embeddings, action labels, and
free-form descriptions extracted from videos as its input. We evaluate Vamos on
four complementary video understanding benchmarks, Ego4D, Next-QA, IntentQA,
and EgoSchema, on its capability to model temporal dynamics, encode visual
history, and perform reasoning. Surprisingly, we observe that text-based
representations consistently achieve competitive performance on all benchmarks,
and that visual embeddings provide marginal or no performance improvement,
demonstrating the effectiveness of text-based video representation in the LLM
era. We perform extensive ablation study and qualitative analysis to support
our observations, and achieve state-of-the-art performance on three benchmarks.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13628" title="Abstract">arXiv:2311.13628</a> [<a href="/pdf/2311.13628" title="Download PDF">pdf</a>, <a href="/format/2311.13628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt Risk Control: A Rigorous Framework for Responsible Deployment of  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zollo%2C+T+P">Thomas P. Zollo</a>, 
<a href="/search/cs?searchtype=author&query=Morrill%2C+T">Todd Morrill</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhun Deng</a>, 
<a href="/search/cs?searchtype=author&query=Snell%2C+J+C">Jake C. Snell</a>, 
<a href="/search/cs?searchtype=author&query=Pitassi%2C+T">Toniann Pitassi</a>, 
<a href="/search/cs?searchtype=author&query=Zemel%2C+R">Richard Zemel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 10 figures, and accepted to the Socially Responsible Language Modelling Research (SoLaR) workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">The recent explosion in the capabilities of large language models has led to
a wave of interest in how best to prompt a model to perform a given task. While
it may be tempting to simply choose a prompt based on average performance on a
validation set, this can lead to a deployment where unexpectedly poor responses
are generated, especially for the worst-off users. To mitigate this prospect,
we propose Prompt Risk Control, a lightweight framework for selecting a prompt
based on rigorous upper bounds on families of informative risk measures. We
offer methods for producing bounds on a diverse set of metrics, including
quantities that measure worst-case responses and disparities in generation
quality across the population of users. In addition, we extend the underlying
statistical bounding techniques to accommodate the possibility of distribution
shifts in deployment. Experiments on applications such as open-ended chat,
medical question summarization, and code generation highlight how such a
framework can foster responsible deployment by reducing the risk of the worst
outcomes.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13629" title="Abstract">arXiv:2311.13629</a> [<a href="/pdf/2311.13629" title="Download PDF">pdf</a>, <a href="/format/2311.13629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion models meet image counter-forensics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tailanian%2C+M">Mat&#xed;as Tailanian</a>, 
<a href="/search/cs?searchtype=author&query=Gardella%2C+M">Marina Gardella</a>, 
<a href="/search/cs?searchtype=author&query=Pardo%2C+%C3%81">&#xc1;lvaro Pardo</a>, 
<a href="/search/cs?searchtype=author&query=Mus%C3%A9%2C+P">Pablo Mus&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">From its acquisition in the camera sensors to its storage, different
operations are performed to generate the final image. This pipeline imprints
specific traces into the image to form a natural watermark. Tampering with an
image disturbs these traces; these disruptions are clues that are used by most
methods to detect and locate forgeries. In this article, we assess the
capabilities of diffusion models to erase the traces left by forgers and,
therefore, deceive forensics methods. Such an approach has been recently
introduced for adversarial purification, achieving significant performance. We
show that diffusion purification methods are well suited for counter-forensics
tasks. Such approaches outperform already existing counter-forensics techniques
both in deceiving forensics methods and in preserving the natural look of the
purified images. The source code is publicly available at
https://github.com/mtailanian/diff-cf.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13647" title="Abstract">arXiv:2311.13647</a> [<a href="/pdf/2311.13647" title="Download PDF">pdf</a>, <a href="/format/2311.13647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Model Inversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morris%2C+J+X">John X. Morris</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wenting Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chiu%2C+J+T">Justin T. Chiu</a>, 
<a href="/search/cs?searchtype=author&query=Shmatikov%2C+V">Vitaly Shmatikov</a>, 
<a href="/search/cs?searchtype=author&query=Rush%2C+A+M">Alexander M. Rush</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Language models produce a distribution over the next token; can we use this
information to recover the prompt tokens? We consider the problem of language
model inversion and show that next-token probabilities contain a surprising
amount of information about the preceding text. Often we can recover the text
in cases where it is hidden from the user, motivating a method for recovering
unknown prompts given only the model's current distribution output. We consider
a variety of model access scenarios, and show how even without predictions for
every token in the vocabulary we can recover the probability vector through
search. On Llama-2 7b, our inversion method reconstructs prompts with a BLEU of
$59$ and token-level F1 of $78$ and recovers $27\%$ of prompts exactly. Code
for reproducing all experiments is available at
<a href="http://github.com/jxmorris12/vec2text.">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13648" title="Abstract">arXiv:2311.13648</a> [<a href="/pdf/2311.13648" title="Download PDF">pdf</a>, <a href="/format/2311.13648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Pretrained models for Deployable Lifelong Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lekkala%2C+K">Kiran Lekkala</a>, 
<a href="/search/cs?searchtype=author&query=Bhargava%2C+E">Eshan Bhargava</a>, 
<a href="/search/cs?searchtype=author&query=Itti%2C+L">Laurent Itti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In submission to CoLLA 2024. Also published in the Proceedings of WACV 2024 Workshop on Pretraining
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We create a novel benchmark for evaluating a Deployable Lifelong Learning
system for Visual Reinforcement Learning (RL) that is pretrained on a curated
dataset, and propose a novel Scalable Lifelong Learning system capable of
retaining knowledge from the previously learnt RL tasks. Our benchmark measures
the efficacy of a deployable Lifelong Learning system that is evaluated on
scalability, performance and resource utilization. Our proposed system, once
pretrained on the dataset, can be deployed to perform continual learning on
unseen tasks. Our proposed method consists of a Few Shot Class Incremental
Learning (FSCIL) based task-mapper and an encoder/backbone trained entirely
using the pretrain dataset. The policy parameters corresponding to the
recognized task are then loaded to perform the task. We show that this system
can be scaled to incorporate a large number of tasks due to the small memory
footprint and fewer computational resources. We perform experiments on our DeLL
(Deployment for Lifelong Learning) benchmark on the Atari games to determine
the efficacy of the system.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13652" title="Abstract">arXiv:2311.13652</a> [<a href="/pdf/2311.13652" title="Download PDF">pdf</a>, <a href="/format/2311.13652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differences of communication activity and mobility patterns between  urban and rural people
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ogushi%2C+F">Fumiko Ogushi</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+C">Chandreyee Roy</a>, 
<a href="/search/cs?searchtype=author&query=Kaski%2C+K">Kimmo Kaski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 9 figures in main text
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Human mobility and other social activity patterns influence various aspects
of society such as urban planning, traffic predictions, crisis resilience, and
epidemic prevention. The behaviour of individuals, like their communication
frequencies and movements, are shaped by societal and socio-economic factors.
In addition, the differences in the geolocation of people as well as their
gender and age cast effects on their activity patterns. In this study we focus
on investigating these patterns by using mobile phone data, specifically the
call detail records (CDRs), to analyze the social communication and mobility
patterns of people. This dataset can provide us insight into the individual and
population-level behaviours in rural and urban environments on a daily, weekly
and seasonal basis. The results of our analyses show that in the urban areas
people have high calling activity but low mobility, while in the rural areas
they show the opposite behaviour, i.e. low calling activity combined with high
mobility. Overall, there is a decreasing trend in people's mobility through the
year even though their calling activity remained consistent except for the
holidays during which time the communication frequency drops markedly. We have
also observed that there are significant differences in the mobility between
the work days and free days. Finally, the age and gender of individuals have
also been observed to play a role in the seasonal patterns differently in urban
and rural areas.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13655" title="Abstract">arXiv:2311.13655</a> [<a href="/pdf/2311.13655" title="Download PDF">pdf</a>, <a href="/format/2311.13655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GAN-Avatar: Controllable Personalized GAN-based Human Head Avatar
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kabadayi%2C+B">Berna Kabadayi</a>, 
<a href="/search/cs?searchtype=author&query=Zielonka%2C+W">Wojciech Zielonka</a>, 
<a href="/search/cs?searchtype=author&query=Bhatnagar%2C+B+L">Bharat Lal Bhatnagar</a>, 
<a href="/search/cs?searchtype=author&query=Pons-Moll%2C+G">Gerard Pons-Moll</a>, 
<a href="/search/cs?searchtype=author&query=Thies%2C+J">Justus Thies</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Website: <a href="https://ganavatar.github.io/">this https URL</a> , Video: <a href="https://www.youtube.com/watch?v=uAi5IVrzzZY">this https URL</a>&amp;ab_channel=JustusThies , Accepted to 3DV2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Digital humans and, especially, 3D facial avatars have raised a lot of
attention in the past years, as they are the backbone of several applications
like immersive telepresence in AR or VR. Despite the progress, facial avatars
reconstructed from commodity hardware are incomplete and miss out on parts of
the side and back of the head, severely limiting the usability of the avatar.
This limitation in prior work stems from their requirement of face tracking,
which fails for profile and back views. To address this issue, we propose to
learn person-specific animatable avatars from images without assuming to have
access to precise facial expression tracking. At the core of our method, we
leverage a 3D-aware generative model that is trained to reproduce the
distribution of facial expressions from the training data. To train this
appearance model, we only assume to have a collection of 2D images with the
corresponding camera parameters. For controlling the model, we learn a mapping
from 3DMM facial expression parameters to the latent space of the generative
model. This mapping can be learned by sampling the latent space of the
appearance model and reconstructing the facial parameters from a normalized
frontal view, where facial expression estimation performs well. With this
scheme, we decouple 3D appearance reconstruction and animation control to
achieve high fidelity in image synthesis. In a series of experiments, we
compare our proposed technique to state-of-the-art monocular methods and show
superior quality while not requiring expression tracking of the training data.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13656" title="Abstract">arXiv:2311.13656</a> [<a href="/pdf/2311.13656" title="Download PDF">pdf</a>, <a href="/format/2311.13656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Panda or not Panda? Understanding Adversarial Attacks with Interactive  Visualization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=You%2C+Y">Yuzhe You</a>, 
<a href="/search/cs?searchtype=author&query=Tse%2C+J">Jarvis Tse</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jian Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Adversarial machine learning (AML) studies attacks that can fool machine
learning algorithms into generating incorrect outcomes as well as the defenses
against worst-case attacks to strengthen model robustness. Specifically for
image classification, it is challenging to understand adversarial attacks due
to their use of subtle perturbations that are not human-interpretable, as well
as the variability of attack impacts influenced by diverse methodologies,
instance differences, and model architectures. Through a design study with AML
learners and teachers, we introduce AdvEx, a multi-level interactive
visualization system that comprehensively presents the properties and impacts
of evasion attacks on different image classifiers for novice AML learners. We
quantitatively and qualitatively assessed AdvEx in a two-part evaluation
including user studies and expert interviews. Our results show that AdvEx is
not only highly effective as a visualization tool for understanding AML
mechanisms, but also provides an engaging and enjoyable learning experience,
thus demonstrating its overall benefits for AML learners.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13657" title="Abstract">arXiv:2311.13657</a> [<a href="/pdf/2311.13657" title="Download PDF">pdf</a>, <a href="/format/2311.13657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Transformer Knowledge Distillation: A Performance Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brown%2C+N">Nathan Brown</a>, 
<a href="/search/cs?searchtype=author&query=Williamson%2C+A">Ashton Williamson</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+T">Tahj Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Lawrence%2C+L">Logan Lawrence</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023. 12 pages, 1 figure, 11 tables. Models and data available at <a href="https://huggingface.co/giant-oak">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">As pretrained transformer language models continue to achieve
state-of-the-art performance, the Natural Language Processing community has
pushed for advances in model compression and efficient attention mechanisms to
address high computational requirements and limited input sequence length.
Despite these separate efforts, no investigation has been done into the
intersection of these two fields. In this work, we provide an evaluation of
model compression via knowledge distillation on efficient attention
transformers. We provide cost-performance trade-offs for the compression of
state-of-the-art efficient attention architectures and the gains made in
performance in comparison to their full attention counterparts. Furthermore, we
introduce a new long-context Named Entity Recognition dataset, GONERD, to train
and test the performance of NER models on long sequences. We find that
distilled efficient attention transformers can preserve a significant amount of
original model performance, preserving up to 98.6% across short-context tasks
(GLUE, SQUAD, CoNLL-2003), up to 94.6% across long-context
Question-and-Answering tasks (HotpotQA, TriviaQA), and up to 98.8% on
long-context Named Entity Recognition (GONERD), while decreasing inference
times by up to 57.8%. We find that, for most models on most tasks, performing
knowledge distillation is an effective method to yield high-performing
efficient attention models with low costs.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13661" title="Abstract">arXiv:2311.13661</a> [<a href="/pdf/2311.13661" title="Download PDF">pdf</a>, <a href="/format/2311.13661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BenthIQ: a Transformer-Based Benthic Classification Model for Coral  Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kurinchi-Vendhan%2C+R">Rupa Kurinchi-Vendhan</a>, 
<a href="/search/cs?searchtype=author&query=Gray%2C+D">Drew Gray</a>, 
<a href="/search/cs?searchtype=author&query=Cole%2C+E">Elijah Cole</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Coral reefs are vital for marine biodiversity, coastal protection, and
supporting human livelihoods globally. However, they are increasingly
threatened by mass bleaching events, pollution, and unsustainable practices
with the advent of climate change. Monitoring the health of these ecosystems is
crucial for effective restoration and management. Current methods for creating
benthic composition maps often compromise between spatial coverage and
resolution. In this paper, we introduce BenthIQ, a multi-label semantic
segmentation network designed for high-precision classification of underwater
substrates, including live coral, algae, rock, and sand. Although commonly
deployed CNNs are limited in learning long-range semantic information,
transformer-based models have recently achieved state-of-the-art performance in
vision tasks such as object detection and image classification. We integrate
the hierarchical Swin Transformer as the backbone of a U-shaped encoder-decoder
architecture for local-global semantic feature learning. Using a real-world
case study in French Polynesia, we demonstrate that our approach outperforms
traditional CNN and attention-based models on pixel-wise classification of
shallow reef imagery.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13664" title="Abstract">arXiv:2311.13664</a> [<a href="/pdf/2311.13664" title="Download PDF">pdf</a>, <a href="/format/2311.13664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample as You Infer: Predictive Coding With Langevin Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zahid%2C+U">Umais Zahid</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qinghai Guo</a>, 
<a href="/search/cs?searchtype=author&query=Fountas%2C+Z">Zafeirios Fountas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">We present a novel algorithm for parameter learning in generic deep
generative models that builds upon the predictive coding (PC) framework of
computational neuroscience. Our approach modifies the standard PC algorithm to
bring performance on-par and exceeding that obtained from standard variational
auto-encoder (VAE) training. By injecting Gaussian noise into the PC inference
procedure we re-envision it as an overdamped Langevin sampling, which
facilitates optimisation with respect to a tight evidence lower bound (ELBO).
We improve the resultant encoder-free training method by incorporating an
encoder network to provide an amortised warm-start to our Langevin sampling and
test three different objectives for doing so. Finally, to increase robustness
to the sampling step size and reduce sensitivity to curvature, we validate a
lightweight and easily computable form of preconditioning, inspired by Riemann
Manifold Langevin and adaptive optimizers from the SGD literature. We compare
against VAEs by training like-for-like generative models using our technique
against those trained with standard reparameterisation-trick-based ELBOs. We
observe our method out-performs or matches performance across a number of
metrics, including sample quality, while converging in a fraction of the number
of SGD training iterations.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13665" title="Abstract">arXiv:2311.13665</a> [<a href="/pdf/2311.13665" title="Download PDF">pdf</a>, <a href="/format/2311.13665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Joint Gradient and Loss Based Clustered Federated Learning Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Licheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mingzhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhaohui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yusen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuchen Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this paper, a novel clustered FL framework that enables distributed edge
devices with non-IID data to independently form several clusters in a
distributed manner and implement FL training within each cluster is proposed.
In particular, our designed clustered FL algorithm must overcome two challenges
associated with FL training. First, the server has limited FL training
information (i.e., the parameter server can only obtain the FL model
information of each device) and limited computational power for finding the
differences among a large amount of devices. Second, each device does not have
the data information of other devices for device clustering and can only use
global FL model parameters received from the server and its data information to
determine its cluster identity, which will increase the difficulty of device
clustering. To overcome these two challenges, we propose a joint gradient and
loss based distributed clustering method in which each device determines its
cluster identity considering the gradient similarity and training loss. The
proposed clustering method not only considers how a local FL model of one
device contributes to each cluster but also the direction of gradient descent
thus improving clustering speed. By delegating clustering decisions to edge
devices, each device can fully leverage its private data information to
determine its own cluster identity, thereby reducing clustering overhead and
improving overall clustering performance. Simulation results demonstrate that
our proposed clustered FL algorithm can reduce clustering iterations by up to
99% compared to the existing baseline.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13668" title="Abstract">arXiv:2311.13668</a> [<a href="/pdf/2311.13668" title="Download PDF">pdf</a>, <a href="/format/2311.13668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAIRA-1: A specialised large multimodal model for radiology report  generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hyland%2C+S+L">Stephanie L. Hyland</a>, 
<a href="/search/cs?searchtype=author&query=Bannur%2C+S">Shruthi Bannur</a>, 
<a href="/search/cs?searchtype=author&query=Bouzid%2C+K">Kenza Bouzid</a>, 
<a href="/search/cs?searchtype=author&query=Castro%2C+D+C">Daniel C. Castro</a>, 
<a href="/search/cs?searchtype=author&query=Ranjit%2C+M">Mercy Ranjit</a>, 
<a href="/search/cs?searchtype=author&query=Schwaighofer%2C+A">Anton Schwaighofer</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez-Garc%C3%ADa%2C+F">Fernando P&#xe9;rez-Garc&#xed;a</a>, 
<a href="/search/cs?searchtype=author&query=Salvatelli%2C+V">Valentina Salvatelli</a>, 
<a href="/search/cs?searchtype=author&query=Srivastav%2C+S">Shaury Srivastav</a>, 
<a href="/search/cs?searchtype=author&query=Thieme%2C+A">Anja Thieme</a>, 
<a href="/search/cs?searchtype=author&query=Codella%2C+N">Noel Codella</a>, 
<a href="/search/cs?searchtype=author&query=Lungren%2C+M+P">Matthew P. Lungren</a>, 
<a href="/search/cs?searchtype=author&query=Wetscherek%2C+M+T">Maria Teodora Wetscherek</a>, 
<a href="/search/cs?searchtype=author&query=Oktay%2C+O">Ozan Oktay</a>, 
<a href="/search/cs?searchtype=author&query=Alvarez-Valle%2C+J">Javier Alvarez-Valle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 9 tables, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We present a radiology-specific multimodal model for the task for generating
radiological reports from chest X-rays (CXRs). Our work builds on the idea that
large language model(s) can be equipped with multimodal capabilities through
alignment with pre-trained vision encoders. On natural images, this has been
shown to allow multimodal models to gain image understanding and description
capabilities. Our proposed model (MAIRA-1) leverages a CXR-specific image
encoder in conjunction with a fine-tuned large language model based on
Vicuna-7B, and text-based data augmentation, to produce reports with
state-of-the-art quality. In particular, MAIRA-1 significantly improves on the
radiologist-aligned RadCliQ metric and across all lexical metrics considered.
Manual review of model outputs demonstrates promising fluency and accuracy of
generated reports while uncovering failure modes not captured by existing
evaluation practices. More information and resources can be found on the
project website: https://aka.ms/maira.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13673" title="Abstract">arXiv:2311.13673</a> [<a href="/pdf/2311.13673" title="Download PDF">pdf</a>, <a href="/format/2311.13673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Size Overhead of Pairwise Spanners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neiman%2C+O">Ofer Neiman</a>, 
<a href="/search/cs?searchtype=author&query=Shabat%2C+I">Idan Shabat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 46 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Given an undirected possibly weighted $n$-vertex graph $G=(V,E)$ and a set
$\mathcal{P}\subseteq V^2$ of pairs, a subgraph $S=(V,E')$ is called a ${\cal
P}$-pairwise $\alpha$-spanner of $G$, if for every pair $(u,v)\in\mathcal{P}$
we have $d_S(u,v)\leq\alpha\cdot d_G(u,v)$. The parameter $\alpha$ is called
the stretch of the spanner, and its size overhead is define as
$\frac{|E'|}{|{\cal P}|}$.
<br />A surprising connection was recently discussed between the additive stretch
of $(1+\epsilon,\beta)$-spanners, to the hopbound of
$(1+\epsilon,\beta)$-hopsets. A long sequence of works showed that if the
spanner/hopset has size $\approx n^{1+1/k}$ for some parameter $k\ge 1$, then
$\beta\approx\left(\frac1\epsilon\right)^{\log k}$. In this paper we establish
a new connection to the size overhead of pairwise spanners. In particular, we
show that if $|{\cal P}|\approx n^{1+1/k}$, then a ${\cal P}$-pairwise
$(1+\epsilon)$-spanner must have size at least $\beta\cdot |{\cal P}|$ with
$\beta\approx\left(\frac1\epsilon\right)^{\log k}$ (a near matching upper bound
was recently shown in \cite{ES23}).
<br />We also extend the connection between pairwise spanners and hopsets to the
large stretch regime, by showing nearly matching upper and lower bounds for
${\cal P}$-pairwise $\alpha$-spanners. In particular, we show that if $|{\cal
P}|\approx n^{1+1/k}$, then the size overhead is $\beta\approx\frac k\alpha$.
<br />A source-wise spanner is a special type of pairwise spanner, for which ${\cal
P}=A\times V$ for some $A\subseteq V$. A prioritized spanner is given also a
ranking of the vertices $V=(v_1,\dots,v_n)$, and is required to provide
improved stretch for pairs containing higher ranked vertices. By using a
sequence of reductions, we improve on the state-of-the-art results for
source-wise and prioritized spanners.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13681" title="Abstract">arXiv:2311.13681</a> [<a href="/pdf/2311.13681" title="Download PDF">pdf</a>, <a href="/format/2311.13681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compact 3D Gaussian Representation for Radiance Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+C">Joo Chan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Rho%2C+D">Daniel Rho</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiangyu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ko%2C+J+H">Jong Hwan Ko</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+E">Eunbyung Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="http://maincold2.github.io/c3dgs/">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Neural Radiance Fields (NeRFs) have demonstrated remarkable potential in
capturing complex 3D scenes with high fidelity. However, one persistent
challenge that hinders the widespread adoption of NeRFs is the computational
bottleneck due to the volumetric rendering. On the other hand, 3D Gaussian
splatting (3DGS) has recently emerged as an alternative representation that
leverages a 3D Gaussisan-based representation and adopts the rasterization
pipeline to render the images rather than volumetric rendering, achieving very
fast rendering speed and promising image quality. However, a significant
drawback arises as 3DGS entails a substantial number of 3D Gaussians to
maintain the high fidelity of the rendered images, which requires a large
amount of memory and storage. To address this critical issue, we place a
specific emphasis on two key objectives: reducing the number of Gaussian points
without sacrificing performance and compressing the Gaussian attributes, such
as view-dependent color and covariance. To this end, we propose a learnable
mask strategy that significantly reduces the number of Gaussians while
preserving high performance. In addition, we propose a compact but effective
representation of view-dependent color by employing a grid-based neural field
rather than relying on spherical harmonics. Finally, we learn codebooks to
compactly represent the geometric attributes of Gaussian by vector
quantization. In our extensive experiments, we consistently show over
10$\times$ reduced storage and enhanced rendering speed, while maintaining the
quality of the scene representation, compared to 3DGS. Our work provides a
comprehensive framework for 3D scene representation, achieving high
performance, fast training, compactness, and real-time rendering. Our project
page is available at https://maincold2.github.io/c3dgs/.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13682" title="Abstract">arXiv:2311.13682</a> [<a href="/pdf/2311.13682" title="Download PDF">pdf</a>, <a href="/format/2311.13682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single-Shot Plug-and-Play Methods for Inverse Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yanqi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lipei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zhenda Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shujun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lequan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+R+H">Raymond H. Chan</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6nlieb%2C+C">Carola-Bibiane Sch&#xf6;nlieb</a>, 
<a href="/search/cs?searchtype=author&query=Aviles-Rivero%2C+A+I">Angelica I Aviles-Rivero</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">The utilisation of Plug-and-Play (PnP) priors in inverse problems has become
increasingly prominent in recent years. This preference is based on the
mathematical equivalence between the general proximal operator and the
regularised denoiser, facilitating the adaptation of various off-the-shelf
denoiser priors to a wide range of inverse problems. However, existing PnP
models predominantly rely on pre-trained denoisers using large datasets. In
this work, we introduce Single-Shot PnP methods (SS-PnP), shifting the focus to
solving inverse problems with minimal data. First, we integrate Single-Shot
proximal denoisers into iterative methods, enabling training with single
instances. Second, we propose implicit neural priors based on a novel function
that preserves relevant frequencies to capture fine details while avoiding the
issue of vanishing gradients. We demonstrate, through extensive numerical and
visual experiments, that our method leads to better approximations.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13686" title="Abstract">arXiv:2311.13686</a> [<a href="/pdf/2311.13686" title="Download PDF">pdf</a>, <a href="/ps/2311.13686" title="Download PostScript">ps</a>, <a href="/format/2311.13686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Private Inference in Quantized Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zirui Deng</a>, 
<a href="/search/cs?searchtype=author&query=Ramkumar%2C+V">Vinayak Ramkumar</a>, 
<a href="/search/cs?searchtype=author&query=Bitar%2C+R">Rawad Bitar</a>, 
<a href="/search/cs?searchtype=author&query=Raviv%2C+N">Netanel Raviv</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">A typical setup in many machine learning scenarios involves a server that
holds a model and a user that possesses data, and the challenge is to perform
inference while safeguarding the privacy of both parties. Private Inference has
been extensively explored in recent years, mainly from a cryptographic
standpoint via techniques like homomorphic encryption and multiparty
computation. These approaches often come with high computational overhead and
may degrade the accuracy of the model. In our work, we take a different
approach inspired by the Private Information Retrieval literature. We view
private inference as the task of retrieving inner products of parameter vectors
with the data, a fundamental operation in many machine learning models. We
introduce schemes that enable such retrieval of inner products for models with
quantized (i.e., restricted to a finite set) weights; such models are
extensively used in practice due to a wide range of benefits. In addition, our
schemes uncover a fundamental tradeoff between user and server privacy. Our
information-theoretic approach is applicable to a wide range of problems and
robust in privacy guarantees for both the user and the server.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13687" title="Abstract">arXiv:2311.13687</a> [<a href="/pdf/2311.13687" title="Download PDF">pdf</a>, <a href="/format/2311.13687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beat-Aligned Spectrogram-to-Sequence Generation of Rhythm-Game Charts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+J">Jayeon Yi</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sungho Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kyogu Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ISMIR 2023 LBD. Demo videos and code at stet-stet.github.io/goct
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In the heart of "rhythm games" - games where players must perform actions in
sync with a piece of music - are "charts", the directives to be given to
players. We newly formulate chart generation as a sequence generation task and
train a Transformer using a large dataset. We also introduce tempo-informed
preprocessing and training procedures, some of which are suggested to be
integral for a successful training. Our model is found to outperform the
baselines on a large dataset, and is also found to benefit from pretraining and
finetuning.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13692" title="Abstract">arXiv:2311.13692</a> [<a href="/pdf/2311.13692" title="Download PDF">pdf</a>, <a href="/ps/2311.13692" title="Download PostScript">ps</a>, <a href="/format/2311.13692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Molly: A Verified Compiler for Cryptoprotocol Roles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dougherty%2C+D+J">Daniel J. Dougherty</a>, 
<a href="/search/cs?searchtype=author&query=Guttman%2C+J+D">Joshua D. Guttman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Molly is a program that compiles cryptographic protocol roles written in a
high-level notation into straight-line programs in an intermediate-level
imperative language, suitable for implementation in a conventional programming
language. We define a denotational semantics for protocol roles based on an
axiomatization of the runtime. A notable feature of our approach is that we
assume that encryption is randomized. Thus, at the runtime level we treat
encryption as a relation rather than a function. Molly is written in Coq, and
generates a machine-checked proof that the procedure it constructs is correct
with respect to the runtime semantics. Using Coq's extraction mechanism, one
can build an efficient functional program for compilation.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13693" title="Abstract">arXiv:2311.13693</a> [<a href="/pdf/2311.13693" title="Download PDF">pdf</a>, <a href="/format/2311.13693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable CP Decomposition for Tensor Learning using GPU Tensor Cores
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zeliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhuo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+S">Susan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhiyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yifan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+C">Chen Ding</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chenliang Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">CP decomposition is a powerful tool for data science, especially gene
analysis, deep learning, and quantum computation. However, the application of
tensor decomposition is largely hindered by the exponential increment of the
computational complexity and storage consumption with the size of tensors.
While the data in our real world is usually presented as trillion- or even
exascale-scale tensors, existing work can only support billion-scale scale
tensors. In our work, we propose the Exascale-Tensor to mitigate the
significant gap. Specifically, we propose a compression-based tensor
decomposition framework, namely the exascale-tensor, to support exascale tensor
decomposition. Then, we carefully analyze the inherent parallelism and propose
a bag of strategies to improve computational efficiency. Last, we conduct
experiments to decompose tensors ranging from million-scale to trillion-scale
for evaluation. Compared to the baselines, the exascale-tensor supports 8,000x
larger tensors and a speedup up to 6.95x. We also apply our method to two
real-world applications, including gene analysis and tensor layer neural
networks, of which the numeric results demonstrate the scalability and
effectiveness of our method.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13695" title="Abstract">arXiv:2311.13695</a> [<a href="/pdf/2311.13695" title="Download PDF">pdf</a>, <a href="/ps/2311.13695" title="Download PostScript">ps</a>, <a href="/format/2311.13695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BackboneLearn: A Library for Scaling Mixed-Integer Optimization-Based  Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Digalakis%2C+V">Vassilis Digalakis Jr</a>, 
<a href="/search/cs?searchtype=author&query=Ziakas%2C+C">Christos Ziakas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">We present BackboneLearn: an open-source software package and framework for
scaling mixed-integer optimization (MIO) problems with indicator variables to
high-dimensional problems. This optimization paradigm can naturally be used to
formulate fundamental problems in interpretable supervised learning (e.g.,
sparse regression and decision trees), in unsupervised learning (e.g.,
clustering), and beyond; BackboneLearn solves the aforementioned problems
faster than exact methods and with higher accuracy than commonly used
heuristics. The package is built in Python and is user-friendly and easily
extensible: users can directly implement a backbone algorithm for their MIO
problem at hand. The source code of BackboneLearn is available on GitHub (link:
https://github.com/chziakas/backbone_learn).
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13708" title="Abstract">arXiv:2311.13708</a> [<a href="/pdf/2311.13708" title="Download PDF">pdf</a>, <a href="/ps/2311.13708" title="Download PostScript">ps</a>, <a href="/format/2311.13708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Analysis Method for Hidden Dangers in Substation Based on  Knowledge Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weiwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sizhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Hui Fan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">To address the challenge of identifying and understanding hidden dangers in
substations from unstructured text data, a novel dynamic analysis method is
proposed. This approach begins by analyzing and extracting data from the
unstructured text related to hidden dangers. It then leverages a flexible,
distributed data search engine built on Elastic-Search to handle this
information. Following this, the hidden Markov model is employed to train the
data within the engine. The Viterbi algorithm is integrated to decipher the
hidden state sequences, facilitating the segmentation and labeling of entities
related to hidden dangers. The final step involves using the Neo4j graph
database to dynamically create a knowledge map that visualizes hidden dangers
in the substation. This method's effectiveness is demonstrated through an
example analysis using data from a specific substation's hidden dangers.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13712" title="Abstract">arXiv:2311.13712</a> [<a href="/pdf/2311.13712" title="Download PDF">pdf</a>, <a href="/format/2311.13712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Acquisition: A New Frontier in Data-centric AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lingjiao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Acun%2C+B">Bilge Acun</a>, 
<a href="/search/cs?searchtype=author&query=Ardalani%2C+N">Newsha Ardalani</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yifan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+F">Feiyang Kang</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+H">Hanrui Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+Y">Yongchan Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+R">Ruoxi Jia</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Carole-Jean Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zaharia%2C+M">Matei Zaharia</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">James Zou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">As Machine Learning (ML) systems continue to grow, the demand for relevant
and comprehensive datasets becomes imperative. There is limited study on the
challenges of data acquisition due to ad-hoc processes and lack of consistent
methodologies. We first present an investigation of current data marketplaces,
revealing lack of platforms offering detailed information about datasets,
transparent pricing, standardized data formats. With the objective of inciting
participation from the data-centric AI community, we then introduce the DAM
challenge, a benchmark to model the interaction between the data providers and
acquirers. The benchmark was released as a part of DataPerf. Our evaluation of
the submitted strategies underlines the need for effective data acquisition
strategies in ML.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13713" title="Abstract">arXiv:2311.13713</a> [<a href="/pdf/2311.13713" title="Download PDF">pdf</a>, <a href="/format/2311.13713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Somewhat Robust Image Watermark against Diffusion-based Editing Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+M">Mingtian Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+S">Somesh Jha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recently, diffusion models (DMs) have become the state-of-the-art method for
image synthesis. Editing models based on DMs, known for their high fidelity and
precision, have inadvertently introduced new challenges related to image
copyright infringement and malicious editing. Our work is the first to
formalize and address this issue. After assessing and attempting to enhance
traditional image watermarking techniques, we recognize their limitations in
this emerging context. In response, we develop a novel technique, RIW (Robust
Invisible Watermarking), to embed invisible watermarks leveraging adversarial
example techniques. Our technique ensures a high extraction accuracy of $96\%$
for the invisible watermark after editing, compared to the $0\%$ offered by
conventional methods. We provide access to our code at
https://github.com/BennyTMT/RIW.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13714" title="Abstract">arXiv:2311.13714</a> [<a href="/pdf/2311.13714" title="Download PDF">pdf</a>, <a href="/format/2311.13714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Safe Control for Multi-Robot Systems: Methods, Verification,  and Open Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garg%2C+K">Kunal Garg</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Songyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=So%2C+O">Oswin So</a>, 
<a href="/search/cs?searchtype=author&query=Dawson%2C+C">Charles Dawson</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Chuchu Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Annual Reviews in Control
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Multiagent Systems (cs.MA); Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
<p class="mathjax">In this survey, we review the recent advances in control design methods for
robotic multi-agent systems (MAS), focussing on learning-based methods with
safety considerations. We start by reviewing various notions of safety and
liveness properties, and modeling frameworks used for problem formulation of
MAS. Then we provide a comprehensive review of learning-based methods for safe
control design for multi-robot systems. We start with various types of
shielding-based methods, such as safety certificates, predictive filters, and
reachability tools. Then, we review the current state of control barrier
certificate learning in both a centralized and distributed manner, followed by
a comprehensive review of multi-agent reinforcement learning with a particular
focus on safety. Next, we discuss the state-of-the-art verification tools for
the correctness of learning-based methods. Based on the capabilities and the
limitations of the state of the art methods in learning and verification for
MAS, we identify various broad themes for open challenges: how to design
methods that can achieve good performance along with safety guarantees; how to
decompose single-agent based centralized methods for MAS; how to account for
communication-related practical issues; and how to assess transfer of
theoretical guarantees to practice.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13716" title="Abstract">arXiv:2311.13716</a> [<a href="/pdf/2311.13716" title="Download PDF">pdf</a>, <a href="/format/2311.13716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiverseNet: Decision Diversified Semi-supervised Semantic Segmentation  Networks for Remote Sensing Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Wanli Ma</a>, 
<a href="/search/cs?searchtype=author&query=Karakus%2C+O">Oktay Karakus</a>, 
<a href="/search/cs?searchtype=author&query=Rosin%2C+P+L">Paul L. Rosin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Semi-supervised learning is designed to help reduce the cost of the manual
labelling process by exploiting the use of useful features from a large
quantity of unlabelled data during training. Since pixel-level manual labelling
in large-scale remote sensing imagery is expensive, semi-supervised learning
becomes an appropriate solution to this. However, most of the existing
semi-supervised learning methods still lack efficient perturbation methods to
promote diversity of features and the precision of pseudo labels during
training. In order to fill this gap, we propose DiverseNet architectures which
explore multi-head and multi-model semi-supervised learning algorithms by
simultaneously promoting precision and diversity during training. The two
proposed methods of DiverseNet, namely the DiverseHead and DiverseModel,
achieve the highest semantic segmentation performance in four widely utilised
remote sensing imagery data sets compared to state-of-the-art semi-supervised
learning methods. Meanwhile, the proposed DiverseHead architecture is
relatively lightweight in terms of parameter space compared to the
state-of-the-art methods whilst reaching high-performance results for all the
tested data sets.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13717" title="Abstract">arXiv:2311.13717</a> [<a href="/pdf/2311.13717" title="Download PDF">pdf</a>, <a href="/ps/2311.13717" title="Download PostScript">ps</a>, <a href="/format/2311.13717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Importance of Feature Extraction in the Calculation of Fr&#xe9;chet  Distance for Medical Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Woodland%2C+M">McKell Woodland</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Taie%2C+M+A">Mais Al Taie</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+J+A+M">Jessica Albuquerque Marques Silva</a> (1), 
<a href="/search/cs?searchtype=author&query=Eltaher%2C+M">Mohamed Eltaher</a> (1), 
<a href="/search/cs?searchtype=author&query=Mohn%2C+F">Frank Mohn</a> (1), 
<a href="/search/cs?searchtype=author&query=Shieh%2C+A">Alexander Shieh</a> (1), 
<a href="/search/cs?searchtype=author&query=Castelo%2C+A">Austin Castelo</a> (1), 
<a href="/search/cs?searchtype=author&query=Kundu%2C+S">Suprateek Kundu</a> (1), 
<a href="/search/cs?searchtype=author&query=Yung%2C+J+P">Joshua P. Yung</a> (1), 
<a href="/search/cs?searchtype=author&query=Patel%2C+A+B">Ankit B. Patel</a> (2 and 3), 
<a href="/search/cs?searchtype=author&query=Brock%2C+K+K">Kristy K. Brock</a> (1) ((1) The University of Texas MD Anderson Cancer Center, (2) Rice University, (3) Baylor College of Medicine)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Fr\'echet Inception Distance is a widely used metric for evaluating synthetic
image quality that utilizes an ImageNet-trained InceptionV3 network as a
feature extractor. However, its application in medical imaging lacks a standard
feature extractor, leading to biased and inconsistent comparisons. This study
aimed to compare state-of-the-art feature extractors for computing Fr\'echet
Distances (FDs) in medical imaging. A StyleGAN2 network was trained with data
augmentation techniques tailored for limited data domains on datasets
comprising three medical imaging modalities and four anatomical locations.
Human evaluation of generative quality (via a visual Turing test) was compared
to FDs calculated using ImageNet-trained InceptionV3, ResNet50, SwAV, DINO, and
Swin Transformer architectures, in addition to an InceptionV3 network trained
on a large medical dataset, RadImageNet. All ImageNet-based extractors were
consistent with each other, but only SwAV was significantly correlated with
medical expert judgment. The RadImageNet-based FD showed volatility and lacked
correlation with human judgment. Caution is advised when using medical
image-trained extraction networks in the FD calculation. These networks should
be rigorously evaluated on the imaging modality under consideration and
publicly released. ImageNet-based extractors, while imperfect, are consistent
and widely understood. Training extraction networks with SwAV is a promising
approach for synthetic medical image evaluation.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13718" title="Abstract">arXiv:2311.13718</a> [<a href="/pdf/2311.13718" title="Download PDF">pdf</a>, <a href="/format/2311.13718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Approach to Count-Based Weakly-Supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shukla%2C+V">Vinay Shukla</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zhe Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+K">Kareem Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Van+den+Broeck%2C+G">Guy Van den Broeck</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">High-quality labels are often very scarce, whereas unlabeled data with
inferred weak labels occurs more naturally. In many cases, these weak labels
dictate the frequency of each respective class over a set of instances. In this
paper, we develop a unified approach to learning from such weakly-labeled data,
which we call count-based weakly-supervised learning. At the heart of our
approach is the ability to compute the probability of exactly k out of n
outputs being set to true. This computation is differentiable, exact, and
efficient. Building upon the previous computation, we derive a count loss
penalizing the model for deviations in its distribution from an arithmetic
constraint defined over label counts. We evaluate our approach on three common
weakly-supervised learning paradigms and observe that our proposed approach
achieves state-of-the-art or highly competitive results across all three of the
paradigms.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13720" title="Abstract">arXiv:2311.13720</a> [<a href="/pdf/2311.13720" title="Download PDF">pdf</a>, <a href="/format/2311.13720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards More Likely Models for AI Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caglar%2C+T">Turgay Caglar</a>, 
<a href="/search/cs?searchtype=author&query=Belhaj%2C+S">Sirine Belhaj</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborti%2C+T">Tathagata Chakraborti</a>, 
<a href="/search/cs?searchtype=author&query=Katz%2C+M">Michael Katz</a>, 
<a href="/search/cs?searchtype=author&query=Sreedharan%2C+S">Sarath Sreedharan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This is the first work to look at the application of large language models
(LLMs) for the purpose of model space edits in automated planning tasks. To set
the stage for this sangam, we explore two different flavors of model space
problems that have been studied in the AI planning literature and explore the
effect of an LLM on those tasks. We empirically demonstrate how the performance
of an LLM contrasts with combinatorial search (CS) - an approach that has been
traditionally used to solve model space tasks in planning, both with the LLM in
the role of a standalone model space reasoner as well as in the role of a
statistical signal in concert with the CS approach as part of a two-stage
process. Our experiments show promising results suggesting further forays of
LLMs into the exciting world of model space reasoning for planning tasks in the
future.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13721" title="Abstract">arXiv:2311.13721</a> [<a href="/pdf/2311.13721" title="Download PDF">pdf</a>, <a href="/format/2311.13721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nova$^+$: Generative Language Models for Binaries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+N">Nan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengxiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kevin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiangzhe Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+L">Lin Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangyu Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generative large language models (LLMs) pre-trained on code have shown
impressive effectiveness in code generation, program repair, and document
analysis. However, existing generative LLMs focus on source code and are not
specialized for binaries. There are three main challenges for LLMs to model and
learn binary code: hex-decimal values, complex global dependencies, and
compiler optimization levels.To bring the benefit of LLMs to the binary domain,
we develop Nova and Nova$^+$, which are LLMs pre-trained on binary corpora.
Nova is pre-trained with the standard language modeling task, showing
significantly better capability on five benchmarks for three downstream tasks:
binary code similarity detection (BCSD), binary code translation (BCT), and
binary code recovery (BCR), over GPT-3.5 and other existing techniques. We
build Nova$^+$ to further boost Nova using two new pre-training tasks, i.e.,
optimization generation and optimization level prediction, which are designed
to learn binary optimization and align equivalent binaries. Nova$^+$ shows
overall the best performance for all three downstream tasks on five benchmarks,
demonstrating the contributions of the new pre-training tasks.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13724" title="Abstract">arXiv:2311.13724</a> [<a href="/pdf/2311.13724" title="Download PDF">pdf</a>, <a href="/ps/2311.13724" title="Download PostScript">ps</a>, <a href="/format/2311.13724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Infectious disease surveillance needs for the United States: lessons  from COVID-19
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lipsitch%2C+M">Marc Lipsitch</a>, 
<a href="/search/cs?searchtype=author&query=Bassett%2C+M+T">Mary T. Bassett</a>, 
<a href="/search/cs?searchtype=author&query=Brownstein%2C+J+S">John S. Brownstein</a>, 
<a href="/search/cs?searchtype=author&query=Elliott%2C+P">Paul Elliott</a>, 
<a href="/search/cs?searchtype=author&query=Eyre%2C+D">David Eyre</a>, 
<a href="/search/cs?searchtype=author&query=Grabowski%2C+M+K">M. Kate Grabowski</a>, 
<a href="/search/cs?searchtype=author&query=Hay%2C+J+A">James A. Hay</a>, 
<a href="/search/cs?searchtype=author&query=Johansson%2C+M">Michael Johansson</a>, 
<a href="/search/cs?searchtype=author&query=Kissler%2C+S+M">Stephen M. Kissler</a>, 
<a href="/search/cs?searchtype=author&query=Larremore%2C+D+B">Daniel B. Larremore</a>, 
<a href="/search/cs?searchtype=author&query=Layden%2C+J">Jennifer Layden</a>, 
<a href="/search/cs?searchtype=author&query=Lessler%2C+J">Justin Lessler</a>, 
<a href="/search/cs?searchtype=author&query=Lynfield%2C+R">Ruth Lynfield</a>, 
<a href="/search/cs?searchtype=author&query=MacCannell%2C+D">Duncan MacCannell</a>, 
<a href="/search/cs?searchtype=author&query=Madoff%2C+L+C">Lawrence C. Madoff</a>, 
<a href="/search/cs?searchtype=author&query=Metcalf%2C+C+J+E">C. Jessica E. Metcalf</a>, 
<a href="/search/cs?searchtype=author&query=Meyers%2C+L+A">Lauren A. Meyers</a>, 
<a href="/search/cs?searchtype=author&query=Ofori%2C+S+K">Sylvia K. Ofori</a>, 
<a href="/search/cs?searchtype=author&query=Quinn%2C+C">Celia Quinn</a>, 
<a href="/search/cs?searchtype=author&query=Bento%2C+A+I+R">Ana I. Ramos Bento</a>, 
<a href="/search/cs?searchtype=author&query=Reich%2C+N">Nick Reich</a>, 
<a href="/search/cs?searchtype=author&query=Riley%2C+S">Steven Riley</a>, 
<a href="/search/cs?searchtype=author&query=Rosenfeld%2C+R">Roni Rosenfeld</a>, 
<a href="/search/cs?searchtype=author&query=Samore%2C+M+H">Matthew H. Samore</a>, 
<a href="/search/cs?searchtype=author&query=Sampath%2C+R">Rangarajan Sampath</a>, 
<a href="/search/cs?searchtype=author&query=Slayton%2C+R+B">Rachel B. Slayton</a>, 
<a href="/search/cs?searchtype=author&query=Swerdlow%2C+D+L">David L. Swerdlow</a>, 
<a href="/search/cs?searchtype=author&query=Truelove%2C+S">Shaun Truelove</a>, 
<a href="/search/cs?searchtype=author&query=Varma%2C+J+K">Jay K. Varma</a>, 
<a href="/search/cs?searchtype=author&query=Grad%2C+Y+H">Yonatan H. Grad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Physics and Society (physics.soc-ph); Populations and Evolution (q-bio.PE)

</div>
<p class="mathjax">The COVID-19 pandemic has highlighted the need to upgrade systems for
infectious disease surveillance and forecasting and modeling of the spread of
infection, both of which inform evidence-based public health guidance and
policies. Here, we discuss requirements for an effective surveillance system to
support decision making during a pandemic, drawing on the lessons of COVID-19
in the U.S., while looking to jurisdictions in the U.S. and beyond to learn
lessons about the value of specific data types. In this report, we define the
range of decisions for which surveillance data are required, the data elements
needed to inform these decisions and to calibrate inputs and outputs of
transmission-dynamic models, and the types of data needed to inform decisions
by state, territorial, local, and tribal health authorities. We define actions
needed to ensure that such data will be available and consider the contribution
of such efforts to improving health equity.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13725" title="Abstract">arXiv:2311.13725</a> [<a href="/pdf/2311.13725" title="Download PDF">pdf</a>, <a href="/format/2311.13725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Studying Artist Sentiments around AI-generated Artwork
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ali%2C+S">Safinah Ali</a>, 
<a href="/search/cs?searchtype=author&query=Breazeal%2C+C">Cynthia Breazeal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Art created using generated Artificial Intelligence has taken the world by
storm and generated excitement for many digital creators and technologists.
However, the reception and reaction from artists have been mixed. Concerns
about plagiarizing their artworks and styles for datasets and uncertainty
around the future of digital art sparked movements in artist communities
shunning the use of AI for generating art and protecting artists' rights.
Collaborating with these tools for novel creative use cases also sparked hope
from some creators. Artists are an integral stakeholder in the rapidly evolving
digital creativity industry and understanding their concerns and hopes inform
responsible development and use of creativity support tools. In this work, we
study artists' sentiments about AI-generated art. We interviewed 7 artists and
analyzed public posts from artists on social media platforms Reddit, Twitter
and Artstation. We report artists' main concerns and hopes around AI-generated
artwork, informing a way forward for inclusive development of these tools.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13728" title="Abstract">arXiv:2311.13728</a> [<a href="/pdf/2311.13728" title="Download PDF">pdf</a>, <a href="/format/2311.13728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VINCY: A Smart-contract based Data Integrity and Validation Tooling for  Automated Vehicle Incident Investigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Budel%2C+A">Andr&#xe9; Budel</a>, 
<a href="/search/cs?searchtype=author&query=Alhabib%2C+R">Reem Alhabib</a>, 
<a href="/search/cs?searchtype=author&query=Nicholson%2C+M">Mark Nicholson</a>, 
<a href="/search/cs?searchtype=author&query=Yadav%2C+P">Poonam Yadav</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Automated Driving Systems (ADSs) are being manufactured at an accelerated
rate, leading to improvements in traffic safety, reduced energy consumption,
pollution, and congestion. ADS relies on various data streams from onboard
sensors, external road infrastructure, and other vehicles to make driving
decisions. For effective traffic accident reconstruction, investigators must
produce, collect, store, and access real-time data. To ensure meaningful
investigation, the data used by investigators must be accurate and maintain its
integrity.
<br />In this paper, we propose a smart-contract based data integrity and
validation tool for automated vehicle incident investigation during road
trials, considering uncertainties in a real-world environment.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13729" title="Abstract">arXiv:2311.13729</a> [<a href="/pdf/2311.13729" title="Download PDF">pdf</a>, <a href="/format/2311.13729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparison of pipeline, sequence-to-sequence, and GPT models for  end-to-end relation extraction: experiments with the rare disease use-case
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Shashank Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+X">Xuguang Ai</a>, 
<a href="/search/cs?searchtype=author&query=Kavuluru%2C+R">Ramakanth Kavuluru</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The dataset and code for all our experiments are publicly available: <a href="https://github.com/shashank140195/Raredis">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">End-to-end relation extraction (E2ERE) is an important and realistic
application of natural language processing (NLP) in biomedicine. In this paper,
we aim to compare three prevailing paradigms for E2ERE using a complex dataset
focused on rare diseases involving discontinuous and nested entities. We use
the RareDis information extraction dataset to evaluate three competing
approaches (for E2ERE): NER $\rightarrow$ RE pipelines, joint sequence to
sequence models, and generative pre-trained transformer (GPT) models. We use
comparable state-of-the-art models and best practices for each of these
approaches and conduct error analyses to assess their failure modes. Our
findings reveal that pipeline models are still the best, while
sequence-to-sequence models are not far behind; GPT models with eight times as
many parameters are worse than even sequence-to-sequence models and lose to
pipeline models by over 10 F1 points. Partial matches and discontinuous
entities caused many NER errors contributing to lower overall E2E performances.
We also verify these findings on a second E2ERE dataset for chemical-protein
interactions. Although generative LM-based methods are more suitable for
zero-shot settings, when training data is available, our results show that it
is better to work with more conventional models trained and tailored for E2ERE.
More innovative methods are needed to marry the best of the both worlds from
smaller encoder-decoder pipeline models and the larger GPT models to improve
E2ERE. As of now, we see that well designed pipeline models offer substantial
performance gains at a lower cost and carbon footprint for E2ERE. Our
contribution is also the first to conduct E2ERE for the RareDis dataset.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13731" title="Abstract">arXiv:2311.13731</a> [<a href="/pdf/2311.13731" title="Download PDF">pdf</a>, <a href="/format/2311.13731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Blockchain, Artificial Intelligence, and Edge Computing for  Web 3.0
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jianjun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fan Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jinyuan Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Information Theory (cs.IT)

</div>
<p class="mathjax">Web 3.0, as the third generation of the World Wide Web, aims to solve
contemporary problems of trust, centralization, and data ownership. Driven by
the latest advances in cutting-edge technologies, Web 3.0 is moving towards a
more open, decentralized, intelligent, and interconnected network. However,
increasingly widespread data breaches have raised awareness of online privacy
and security of personal data. Additionally, since Web 3.0 is a sophisticated
and complex convergence, the technical details behind it are not as clear as
the characteristics it presents. In this survey, we conduct an in-depth
exploration of Web 3.0 from the perspectives of blockchain, artificial
intelligence, and edge computing. Specifically, we begin with summarizing the
evolution of the Internet and providing an overview of these three key
technological factors. Afterward, we provide a thorough analysis of each
technology separately, including its relevance to Web 3.0, key technology
components, and practical applications. We also propose decentralized storage
and computing solutions by exploring the integration of technologies. Finally,
we highlight the key challenges alongside potential research directions.
Through the combination and mutual complementation of multiple technologies,
Web 3.0 is expected to return more control and ownership of data and digital
assets back to users.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13732" title="Abstract">arXiv:2311.13732</a> [<a href="/pdf/2311.13732" title="Download PDF">pdf</a>, <a href="/format/2311.13732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recursive Rigid-Body Dynamics Algorithms for Systems with Kinematic  Loops
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chignoli%2C+M">Matthew Chignoli</a>, 
<a href="/search/cs?searchtype=author&query=Adrian%2C+N">Nicholas Adrian</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sangbae Kim</a>, 
<a href="/search/cs?searchtype=author&query=Wensing%2C+P+M">Patrick M. Wensing</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Transactions on Robotics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We propose a novel approach for generalizing the following rigid-body
dynamics algorithms: Recursive Newton-Euler Algorithm, Articulated-Body
Algorithm, and Extended-Force-Propagator Algorithm. The classic versions of
these recursive algorithms require systems to have an open chain structure.
Dealing with closed-chains has, conventionally, required different algorithms.
In this paper, we demonstrate that the classic recursive algorithms can be
modified to work for closed-chain mechanisms. The critical insight of our
generalized algorithms is the clustering of bodies involved in local loop
constraints. Clustering bodies enables loop constraints to be resolved locally,
i.e., only when that group of bodies is encountered during a forward or
backward pass. This local treatment avoids the need for large-scale matrix
factorization. We provide self-contained derivations of the algorithms using
familiar, physically meaningful concepts. Overall, our approach provides a
foundation for simulating robotic systems with traditionally
difficult-to-simulate designs, such as geared motors, differential drives, and
four-bar mechanisms. The performance of our library of algorithms is validated
numerically in C++ on various modern legged robots: the MIT Mini Cheetah, the
MIT Humanoid, the UIUC Tello Humanoid, and a modified version of the JVRC-1
Humanoid. Our algorithms are shown to outperform state-of-the-art algorithms
for computing constrained rigid-body dynamics.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13735" title="Abstract">arXiv:2311.13735</a> [<a href="/pdf/2311.13735" title="Download PDF">pdf</a>, <a href="/format/2311.13735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Surpassing GPT-4 Medical Coding with a Two-Stage Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhichao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Batra%2C+S+S">Sanjit Singh Batra</a>, 
<a href="/search/cs?searchtype=author&query=Stremmel%2C+J">Joel Stremmel</a>, 
<a href="/search/cs?searchtype=author&query=Halperin%2C+E">Eran Halperin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2023, December 10th, 2023, New Orleans, United States, 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent advances in large language models (LLMs) show potential for clinical
applications, such as clinical decision support and trial recommendations.
However, the GPT-4 LLM predicts an excessive number of ICD codes for medical
coding tasks, leading to high recall but low precision. To tackle this
challenge, we introduce LLM-codex, a two-stage approach to predict ICD codes
that first generates evidence proposals using an LLM and then employs an
LSTM-based verification stage. The LSTM learns from both the LLM's high recall
and human expert's high precision, using a custom loss function. Our model is
the only approach that simultaneously achieves state-of-the-art results in
medical coding accuracy, accuracy on rare codes, and sentence-level evidence
identification to support coding decisions without training on human-annotated
evidence according to experiments on the MIMIC dataset.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13738" title="Abstract">arXiv:2311.13738</a> [<a href="/pdf/2311.13738" title="Download PDF">pdf</a>, <a href="/format/2311.13738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Complexity of Computing KKT Solutions of Quadratic Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fearnley%2C+J">John Fearnley</a>, 
<a href="/search/cs?searchtype=author&query=Goldberg%2C+P+W">Paul W. Goldberg</a>, 
<a href="/search/cs?searchtype=author&query=Hollender%2C+A">Alexandros Hollender</a>, 
<a href="/search/cs?searchtype=author&query=Savani%2C+R">Rahul Savani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">It is well known that solving a (non-convex) quadratic program is NP-hard. We
show that the problem remains hard even if we are only looking for a
Karush-Kuhn-Tucker (KKT) point, instead of a global optimum. Namely, we prove
that computing a KKT point of a quadratic polynomial over the domain $[0,1]^n$
is complete for the class CLS = PPAD$\cap$PLS.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13739" title="Abstract">arXiv:2311.13739</a> [<a href="/pdf/2311.13739" title="Download PDF">pdf</a>, <a href="/format/2311.13739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OASIS: Offsetting Active Reconstruction Attacks in Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeter%2C+T+R">Tre&#x27; R. Jeter</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Truc Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Alharbi%2C+R">Raed Alharbi</a>, 
<a href="/search/cs?searchtype=author&query=Thai%2C+M+T">My T. Thai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Federated Learning (FL) has garnered significant attention for its potential
to protect user privacy while enhancing model training efficiency. However,
recent research has demonstrated that FL protocols can be easily compromised by
active reconstruction attacks executed by dishonest servers. These attacks
involve the malicious modification of global model parameters, allowing the
server to obtain a verbatim copy of users' private data by inverting their
gradient updates. Tackling this class of attack remains a crucial challenge due
to the strong threat model. In this paper, we propose OASIS, a defense
mechanism based on image augmentation that effectively counteracts active
reconstruction attacks while preserving model performance. We first uncover the
core principle of gradient inversion that enables these attacks and
theoretically identify the main conditions by which the defense can be robust
regardless of the attack strategies. We then construct OASIS with image
augmentation showing that it can undermine the attack principle. Comprehensive
evaluations demonstrate the efficacy of OASIS highlighting its feasibility as a
solution.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13744" title="Abstract">arXiv:2311.13744</a> [<a href="/pdf/2311.13744" title="Download PDF">pdf</a>, <a href="/ps/2311.13744" title="Download PostScript">ps</a>, <a href="/format/2311.13744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Security and Privacy Challenges in Deep Learning Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Golla%2C+G">Gopichandh Golla</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">These days, deep learning models have achieved great success in multiple
fields, from autonomous driving to medical diagnosis. These models have
expanded the abilities of artificial intelligence by offering great solutions
to complex problems that were very difficult to solve earlier. In spite of
their unseen success in various, it has been identified, through research
conducted, that deep learning models can be subjected to various attacks that
compromise model security and data privacy of the Deep Neural Network models.
Deep learning models can be subjected to various attacks at different stages of
their lifecycle. During the testing phase, attackers can exploit
vulnerabilities through different kinds of attacks such as Model Extraction
Attacks, Model Inversion attacks, and Adversarial attacks. Model Extraction
Attacks are aimed at reverse-engineering a trained deep learning model, with
the primary objective of revealing its architecture and parameters. Model
inversion attacks aim to compromise the privacy of the data used in the Deep
learning model. These attacks are done to compromise the confidentiality of the
model by going through the sensitive training data from the model's
predictions. By analyzing the model's responses, attackers aim to reconstruct
sensitive information. In this way, the model's data privacy is compromised.
Adversarial attacks, mainly employed on computer vision models, are made to
corrupt models into confidently making incorrect predictions through malicious
testing data. These attacks subtly alter the input data, making it look normal
but misleading deep learning models to make incorrect decisions. Such attacks
can happen during both the model's evaluation and training phases. Data
Poisoning Attacks add harmful data to the training set, disrupting the learning
process and reducing the reliability of the deep learning mode.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13745" title="Abstract">arXiv:2311.13745</a> [<a href="/pdf/2311.13745" title="Download PDF">pdf</a>, <a href="/format/2311.13745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample-Efficient Training for Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Shivam Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Parulekar%2C+A">Aditya Parulekar</a>, 
<a href="/search/cs?searchtype=author&query=Price%2C+E">Eric Price</a>, 
<a href="/search/cs?searchtype=author&query=Xun%2C+Z">Zhiyang Xun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Information Theory (cs.IT); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
<p class="mathjax">Score-based diffusion models have become the most popular approach to deep
generative modeling of images, largely due to their empirical performance and
reliability. Recently, a number of theoretical works \citep{chen2022,
Chen2022ImprovedAO, Chenetal23flowode, benton2023linear} have shown that
diffusion models can efficiently sample, assuming $L^2$-accurate score
estimates. The score-matching objective naturally approximates the true score
in $L^2$, but the sample complexity of existing bounds depends
\emph{polynomially} on the data radius and desired Wasserstein accuracy. By
contrast, the time complexity of sampling is only logarithmic in these
parameters. We show that estimating the score in $L^2$ \emph{requires} this
polynomial dependence, but that a number of samples that scales
polylogarithmically in the Wasserstein accuracy actually do suffice for
sampling. We show that with a polylogarithmic number of samples, the ERM of the
score-matching objective is $L^2$ accurate on all but a probability $\delta$
fraction of the true distribution, and that this weaker guarantee is sufficient
for efficient sampling.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13750" title="Abstract">arXiv:2311.13750</a> [<a href="/pdf/2311.13750" title="Download PDF">pdf</a>, <a href="/format/2311.13750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Transferable Multi-modal Perception Representation Learning for  Autonomy: NeRF-Supervised Masked AutoEncoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaohao Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">This work proposes a unified self-supervised pre-training framework for
transferable multi-modal perception representation learning via masked
multi-modal reconstruction in Neural Radiance Field (NeRF), namely
NeRF-Supervised Masked AutoEncoder (NS-MAE). Specifically, conditioned on
certain view directions and locations, multi-modal embeddings extracted from
corrupted multi-modal input signals, i.e., Lidar point clouds and images, are
rendered into projected multi-modal feature maps via neural rendering. Then,
original multi-modal signals serve as reconstruction targets for the rendered
multi-modal feature maps to enable self-supervised representation learning.
Extensive experiments show that the representation learned via NS-MAE shows
promising transferability for diverse multi-modal and single-modal (camera-only
and Lidar-only) perception models on diverse 3D perception downstream tasks (3D
object detection and BEV map segmentation) with diverse amounts of fine-tuning
labeled data. Moreover, we empirically find that NS-MAE enjoys the synergy of
both the mechanism of masked autoencoder and neural radiance field. Our code
shall be released upon acceptance.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13751" title="Abstract">arXiv:2311.13751</a> [<a href="/pdf/2311.13751" title="Download PDF">pdf</a>, <a href="/ps/2311.13751" title="Download PostScript">ps</a>, <a href="/format/2311.13751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Abaqus implementation of a large family of finite viscoelasticity models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lef%C3%A8vre%2C+V">Victor Lef&#xe8;vre</a>, 
<a href="/search/math?searchtype=author&query=Sozio%2C+F">Fabio Sozio</a>, 
<a href="/search/math?searchtype=author&query=Lopez-Pamies%2C+O">Oscar Lopez-Pamies</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Soft Condensed Matter (cond-mat.soft)

</div>
<p class="mathjax">In this paper, we introduce an Abaqus UMAT subroutine for a family of
constitutive models for the viscoelastic response of isotropic elastomers of
any compressibility -- including fully incompressible elastomers -- undergoing
finite deformations. The models can be chosen to account for a wide range of
non-Gaussian elasticities, as well as for a wide range of nonlinear
viscosities. From a mathematical point of view, the structure of the models is
such that the viscous dissipation is characterized by an internal variable
$\textbf{C}^v$, subject to the physically-based constraint
$\det\textbf{C}^v=1$, that is solution of a nonlinear first-order ODE in time.
This ODE is solved by means of an explicit Runge-Kutta scheme of high order
capable of preserving the constraint $\det\textbf{C}^v=1$ identically. The
accuracy and convergence of the code is demonstrated numerically by comparison
with an exact solution for several of the Abaqus built-in hybrid finite
elements, including the simplicial elements C3D4H and C3D10H and the hexahedral
elements C3D8H and C3D20H. The last part of this paper is devoted to showcasing
the capabilities of the code by deploying it to compute the homogenized
response of a bicontinuous rubber blend.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13752" title="Abstract">arXiv:2311.13752</a> [<a href="/pdf/2311.13752" title="Download PDF">pdf</a>, <a href="/format/2311.13752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D-MIR: A Benchmark and Empirical Study on 3D Medical Image Retrieval in  Radiology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abacha%2C+A+B">Asma Ben Abacha</a>, 
<a href="/search/cs?searchtype=author&query=Santamaria-Pang%2C+A">Alberto Santamaria-Pang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H+H">Ho Hin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Merkow%2C+J">Jameson Merkow</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Q">Qin Cai</a>, 
<a href="/search/cs?searchtype=author&query=Devarakonda%2C+S+T">Surya Teja Devarakonda</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+A">Abdullah Islam</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+J">Julia Gong</a>, 
<a href="/search/cs?searchtype=author&query=Lungren%2C+M+P">Matthew P. Lungren</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+T">Thomas Lin</a>, 
<a href="/search/cs?searchtype=author&query=Codella%2C+N+C">Noel C Codella</a>, 
<a href="/search/cs?searchtype=author&query=Tarapov%2C+I">Ivan Tarapov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The increasing use of medical imaging in healthcare settings presents a
significant challenge due to the increasing workload for radiologists, yet it
also offers opportunity for enhancing healthcare outcomes if effectively
leveraged. 3D image retrieval holds potential to reduce radiologist workloads
by enabling clinicians to efficiently search through diagnostically similar or
otherwise relevant cases, resulting in faster and more precise diagnoses.
However, the field of 3D medical image retrieval is still emerging, lacking
established evaluation benchmarks, comprehensive datasets, and thorough
studies. This paper attempts to bridge this gap by introducing a novel
benchmark for 3D Medical Image Retrieval (3D-MIR) that encompasses four
different anatomies imaged with computed tomography. Using this benchmark, we
explore a diverse set of search strategies that use aggregated 2D slices, 3D
volumes, and multi-modal embeddings from popular multi-modal foundation models
as queries. Quantitative and qualitative assessments of each approach are
provided alongside an in-depth discussion that offers insight for future
research. To promote the advancement of this field, our benchmark, dataset, and
code are made publicly available.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13755" title="Abstract">arXiv:2311.13755</a> [<a href="/pdf/2311.13755" title="Download PDF">pdf</a>, <a href="/format/2311.13755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer-based Named Entity Recognition in Construction Supply Chain  Risk Management in Australia
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shishehgarkhaneh%2C+M+B">Milad Baghalzadeh Shishehgarkhaneh</a>, 
<a href="/search/cs?searchtype=author&query=Moehler%2C+R+C">Robert C. Moehler</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yihai Fang</a>, 
<a href="/search/cs?searchtype=author&query=Hijazi%2C+A+A">Amer A. Hijazi</a>, 
<a href="/search/cs?searchtype=author&query=Aboutorab%2C+H">Hamed Aboutorab</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be acceptable
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The construction industry in Australia is characterized by its intricate
supply chains and vulnerability to myriad risks. As such, effective supply
chain risk management (SCRM) becomes imperative. This paper employs different
transformer models, and train for Named Entity Recognition (NER) in the context
of Australian construction SCRM. Utilizing NER, transformer models identify and
classify specific risk-associated entities in news articles, offering a
detailed insight into supply chain vulnerabilities. By analysing news articles
through different transformer models, we can extract relevant entities and
insights related to specific risk taxonomies local (milieu) to the Australian
construction landscape. This research emphasises the potential of NLP-driven
solutions, like transformer models, in revolutionising SCRM for construction in
geo-media specific contexts.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13761" title="Abstract">arXiv:2311.13761</a> [<a href="/pdf/2311.13761" title="Download PDF">pdf</a>, <a href="/format/2311.13761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Feasibility of Reasoning about the Internal States of Blackbox  IoT Devices Using Side-Channel Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yuwei Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Haojian Jin</a>, 
<a href="/search/cs?searchtype=author&query=Bharadia%2C+D">Dinesh Bharadia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Internet of Things (IoT) devices are typically designed to function in a
secure, closed environment, making it difficult for users to comprehend
devices' behaviors. This paper shows that a user can leverage side-channel
information to reason fine-grained internal states of black box IoT devices.
The key enablers for our design are a multi-model sensing technique that fuses
power consumption, network traffic, and radio emanations and an annotation
interface that helps users form mental models of a black box IoT system. We
built a prototype of our design and evaluated the prototype with open-source
IoT devices and black-box commercial devices. Our experiments show a false
positive rate of 1.44% for open-source IoT devices' state probing, and our
participants take an average of 19.8 minutes to reason the internal states of
black-box IoT devices.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13764" title="Abstract">arXiv:2311.13764</a> [<a href="/pdf/2311.13764" title="Download PDF">pdf</a>, <a href="/ps/2311.13764" title="Download PostScript">ps</a>, <a href="/format/2311.13764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Work-Efficient Parallel Derandomization I: Chernoff-like Concentrations  via Pairwise Independence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghaffari%2C+M">Mohsen Ghaffari</a>, 
<a href="/search/cs?searchtype=author&query=Grunau%2C+C">Christoph Grunau</a>, 
<a href="/search/cs?searchtype=author&query=Rozho%C5%88%2C+V">V&#xe1;clav Rozho&#x148;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We present a novel technique for work-efficient parallel derandomization, for
algorithms that rely on the concentration of measure bounds such as Chernoff,
Hoeffding, and Bernstein inequalities. Our method increases the algorithm's
computational work and depth by only polylogarithmic factors. Before our work,
the only known method to obtain parallel derandomization with such strong
concentrations was by the results of [Motwani, Naor, and Naor FOCS'89; Berger
and Rompel FOCS'89], which perform a binary search in a $k$-wise independent
space for $k=poly(\log n)$. However, that method blows up the computational
work by a high $poly(n)$ factor and does not yield work-efficient parallel
algorithms. Their method was an extension of the approach of [Luby FOCS'88],
which gave a work-efficient derandomization but was limited to algorithms
analyzed with only pairwise independence. Pushing the method from pairwise to
the higher $k$-wise analysis resulted in the $poly(n)$ factor computational
work blow-up. Our work can be viewed as an alternative extension from the
pairwise case, which yields the desired strong concentrations while retaining
work efficiency up to logarithmic factors.
<br />Our approach works by casting the problem of determining the random variables
as an iterative process with $poly(\log n)$ iterations, where different
iterations have independent randomness. This is done so that for the desired
concentrations, we need only pairwise independence inside each iteration. In
particular, we model each binary random variable as a result of a gradual
random walk, and our method shows that the desired Chernoff-like concentrations
about the endpoints of these walks can be boiled down to some pairwise analysis
on the steps of these random walks in each iteration (while having independence
across iterations).
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13766" title="Abstract">arXiv:2311.13766</a> [<a href="/pdf/2311.13766" title="Download PDF">pdf</a>, <a href="/format/2311.13766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Framework for Fair Spectral Clustering With Effective Graph  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">We consider the problem of spectral clustering under group fairness
constraints, where samples from each sensitive group are approximately
proportionally represented in each cluster. Traditional fair spectral
clustering (FSC) methods consist of two consecutive stages, i.e., performing
fair spectral embedding on a given graph and conducting $k$means to obtain
discrete cluster labels. However, in practice, the graph is usually unknown,
and we need to construct the underlying graph from potentially noisy data, the
quality of which inevitably affects subsequent fair clustering performance.
Furthermore, performing FSC through separate steps breaks the connections among
these steps, leading to suboptimal results. To this end, we first theoretically
analyze the effect of the constructed graph on FSC. Motivated by the analysis,
we propose a novel graph construction method with a node-adaptive graph filter
to learn graphs from noisy data. Then, all independent stages of conventional
FSC are integrated into a single objective function, forming an end-to-end
framework that inputs raw data and outputs discrete cluster labels. An
algorithm is developed to jointly and alternately update the variables in each
stage. Finally, we conduct extensive experiments on synthetic, benchmark, and
real data, which show that our model is superior to state-of-the-art fair
clustering methods.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13770" title="Abstract">arXiv:2311.13770</a> [<a href="/pdf/2311.13770" title="Download PDF">pdf</a>, <a href="/format/2311.13770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Archiving Body Movements: Collective Generation of Chinese Calligraphy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+A+L">Aven Le Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jiayi Ye</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianchen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">As a communication channel, body movements have been widely explored in
behavioral studies and kinesics. Performing and visual arts share the same
interests but focus on documenting and representing human body movements, such
as for dance notation and visual work creation. This paper investigates body
movements in oriental calligraphy and how to apply calligraphy principles to
stimulate and archive body movements. Through an artwork (Wushu), the authors
experiment with an interactive and generative approach to engage the audience's
bodily participation and archive the body movements as a compendium of
generated calligraphy. The audience assumes the role of both writers and
readers; creating ("writing") and appreciating ("reading") the generated
calligraphy becomes a cyclical process within this infinite "Book," which can
motivate further attention and discussions concerning Chinese characters and
calligraphy.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13771" title="Abstract">arXiv:2311.13771</a> [<a href="/pdf/2311.13771" title="Download PDF">pdf</a>, <a href="/ps/2311.13771" title="Download PostScript">ps</a>, <a href="/format/2311.13771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Work-Efficient Parallel Derandomization II: Optimal Concentrations via  Bootstrapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghaffari%2C+M">Mohsen Ghaffari</a>, 
<a href="/search/cs?searchtype=author&query=Grunau%2C+C">Christoph Grunau</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We present an efficient parallel derandomization method for randomized
algorithms that rely on concentrations such as the Chernoff bound. This settles
a classic problem in parallel derandomization, which dates back to the 1980s.
Consider the \textit{set balancing} problem where $m$ sets of size at most $s$
are given in a ground set of size $n$, and we should partition the ground set
into two parts such that each set is split evenly up to a small additive
(discrepancy) bound. A random partition achieves a discrepancy of $O(\sqrt{s
\log m})$ in each set, by Chernoff bound. We give a deterministic parallel
algorithm that matches this bound, using near-linear work and polylogarithmic
depth. The previous results were weaker in discrepancy and/or work bounds:
Motwani, Naor, and Naor [FOCS'89] and Berger and Rompel [FOCS'89] achieve
discrepancy $s^{\varepsilon} \cdot O(\sqrt{s \log m})$ with work
$\tilde{O}(m+n+\sum_{i=1}^{m} |S_i|) \cdot m^{\Theta(1/\varepsilon)}$ and
polylogarithmic depth; the discrepancy was optimized to $O(\sqrt{s \log m})$ in
later work, e.g. by Harris [Algorithmica'19], but the work bound remained high
at $\tilde{O}(m^4n^3)$. Ghaffari, Grunau, and Rozhon [FOCS'23] achieve
discrepancy $s/poly(\log(nm)) + O(\sqrt{s \log m})$ with near-linear work and
polylogarithmic-depth. Notice that this discrepancy is barely sublinear with
respect to the trivial bound of $s$. Our method relies on a novel bootstrapping
idea that uses crude partitioning algorithms as a subroutine. In particular, we
solve the problem recursively, by using the crude partition in each iteration
to split the variables into many smaller parts, and then we find a constraint
for the variables in each part such that we reduce the overall number of
variables in the problem. The scheme relies on an interesting application of
the multiplicative weights update method to control the variance losses in each
iteration.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13774" title="Abstract">arXiv:2311.13774</a> [<a href="/pdf/2311.13774" title="Download PDF">pdf</a>, <a href="/format/2311.13774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Hierarchical Polynomials with Three-Layer Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Nichani%2C+E">Eshaan Nichani</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+D">Jason D. Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 57 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We study the problem of learning hierarchical polynomials over the standard
Gaussian distribution with three-layer neural networks. We specifically
consider target functions of the form $h = g \circ p$ where $p : \mathbb{R}^d
\rightarrow \mathbb{R}$ is a degree $k$ polynomial and $g: \mathbb{R}
\rightarrow \mathbb{R}$ is a degree $q$ polynomial. This function class
generalizes the single-index model, which corresponds to $k=1$, and is a
natural class of functions possessing an underlying hierarchical structure. Our
main result shows that for a large subclass of degree $k$ polynomials $p$, a
three-layer neural network trained via layerwise gradient descent on the square
loss learns the target $h$ up to vanishing test error in
$\widetilde{\mathcal{O}}(d^k)$ samples and polynomial time. This is a strict
improvement over kernel methods, which require $\widetilde \Theta(d^{kq})$
samples, as well as existing guarantees for two-layer networks, which require
the target function to be low-rank. Our result also generalizes prior works on
three-layer neural networks, which were restricted to the case of $p$ being a
quadratic. When $p$ is indeed a quadratic, we achieve the
information-theoretically optimal sample complexity
$\widetilde{\mathcal{O}}(d^2)$, which is an improvement over prior
work~\citep{nichani2023provable} requiring a sample size of
$\widetilde\Theta(d^4)$. Our proof proceeds by showing that during the initial
stage of training the network performs feature learning to recover the feature
$p$ with $\widetilde{\mathcal{O}}(d^k)$ samples. This work demonstrates the
ability of three-layer neural networks to learn complex features and as a
result, learn a broad class of hierarchical functions.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13777" title="Abstract">arXiv:2311.13777</a> [<a href="/pdf/2311.13777" title="Download PDF">pdf</a>, <a href="/format/2311.13777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GS-Pose: Category-Level Object Pose Estimation via Geometric and  Semantic Correspondence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pengyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ikeda%2C+T">Takuya Ikeda</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+R">Robert Lee</a>, 
<a href="/search/cs?searchtype=author&query=Nishiwaki%2C+K">Koichi Nishiwaki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Category-level pose estimation is a challenging task with many potential
applications in computer vision and robotics. Recently, deep-learning-based
approaches have made great progress, but are typically hindered by the need for
large datasets of either pose-labelled real images or carefully tuned
photorealistic simulators. This can be avoided by using only geometry inputs
such as depth images to reduce the domain-gap but these approaches suffer from
a lack of semantic information, which can be vital in the pose estimation
problem. To resolve this conflict, we propose to utilize both geometric and
semantic features obtained from a pre-trained foundation model.Our approach
projects 2D features from this foundation model into 3D for a single object
model per category, and then performs matching against this for new single view
observations of unseen object instances with a trained matching network. This
requires significantly less data to train than prior methods since the semantic
features are robust to object texture and appearance. We demonstrate this with
a rich evaluation, showing improved performance over prior methods with a
fraction of the data required.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13781" title="Abstract">arXiv:2311.13781</a> [<a href="/pdf/2311.13781" title="Download PDF">pdf</a>, <a href="/format/2311.13781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Compositional Graph Convolutional Network for Efficient  Composite Human Motion Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wanying Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+F">Fanyang Meng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Songtao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mengyuan Liu</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 31st ACM International Conference on
  Multimedia, October 2023, Pages 2856-2864
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With potential applications in fields including intelligent surveillance and
human-robot interaction, the human motion prediction task has become a hot
research topic and also has achieved high success, especially using the recent
Graph Convolutional Network (GCN). Current human motion prediction task usually
focuses on predicting human motions for atomic actions. Observing that atomic
actions can happen at the same time and thus formulating the composite actions,
we propose the composite human motion prediction task. To handle this task, we
first present a Composite Action Generation (CAG) module to generate synthetic
composite actions for training, thus avoiding the laborious work of collecting
composite action samples. Moreover, we alleviate the effect of composite
actions on demand for a more complicated model by presenting a Dynamic
Compositional Graph Convolutional Network (DC-GCN). Extensive experiments on
the Human3.6M dataset and our newly collected CHAMP dataset consistently verify
the efficiency of our DC-GCN method, which achieves state-of-the-art motion
prediction accuracies and meanwhile needs few extra computational costs than
traditional GCN-based human motion methods.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13782" title="Abstract">arXiv:2311.13782</a> [<a href="/pdf/2311.13782" title="Download PDF">pdf</a>, <a href="/format/2311.13782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable AI Generative Content for Vehicular Network Semantic  Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+H">Hao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhu Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Perceiving vehicles in a driver's blind spot is vital for safe driving. The
detection of potentially dangerous vehicles in these blind spots can benefit
from vehicular network semantic communication technology. However, efficient
semantic communication involves a trade-off between accuracy and delay,
especially in bandwidth-limited situations. This paper unveils a scalable
Artificial Intelligence Generated Content (AIGC) system that leverages an
encoder-decoder architecture. This system converts images into textual
representations and reconstructs them into quality-acceptable images,
optimizing transmission for vehicular network semantic communication. Moreover,
when bandwidth allows, auxiliary information is integrated. The encoder-decoder
aims to maintain semantic equivalence with the original images across various
tasks. Then the proposed approach employs reinforcement learning to enhance the
reliability of the generated contents. Experimental results suggest that the
proposed method surpasses the baseline in perceiving vehicles in blind spots
and effectively compresses communication data. While this method is
specifically designed for driving scenarios, this encoder-decoder architecture
also holds potential for wide use across various semantic communication
scenarios.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13784" title="Abstract">arXiv:2311.13784</a> [<a href="/pdf/2311.13784" title="Download PDF">pdf</a>, <a href="/format/2311.13784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DaG LLM ver 1.0: Pioneering Instruction-Tuned Language Modeling for  Korean NLP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jang%2C+D">Dongjun Jang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sangah Lee</a>, 
<a href="/search/cs?searchtype=author&query=Byun%2C+S">Sungjoo Byun</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jinwoong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+J">Jean Seo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minseok Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Soyeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+C">Chaeyoung Oh</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jaeyoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jo%2C+H">Hyemi Jo</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+H">Hyopil Shin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper presents the DaG LLM (David and Goliath Large Language Model), a
language model specialized for Korean and fine-tuned through Instruction Tuning
across 41 tasks within 13 distinct categories.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13785" title="Abstract">arXiv:2311.13785</a> [<a href="/pdf/2311.13785" title="Download PDF">pdf</a>, <a href="/format/2311.13785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning Assisted Distributed Energy Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Du%2C+Y">Yuhan Du</a>, 
<a href="/search/eess?searchtype=author&query=Mendes%2C+N">Nuno Mendes</a>, 
<a href="/search/eess?searchtype=author&query=Rasouli%2C+S">Simin Rasouli</a>, 
<a href="/search/eess?searchtype=author&query=Mohammadi%2C+J">Javad Mohammadi</a>, 
<a href="/search/eess?searchtype=author&query=Moura%2C+P">Pedro Moura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 14 figures, submitted for journal IET Renewable Power Generation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The increased penetration of distributed energy resources and the adoption of
sensing and control technologies are driving the transition from our current
centralized electric grid to a distributed system controlled by multiple
entities (agents). The Transactive Energy Community (TEC) serves as an
established example of this transition. Distributed energy management
approaches can effectively address the scalability, resilience, and privacy
requirements of the evolving grid. In this context, the accuracy of agents'
estimations becomes crucial for the performance of distributed and multi-agent
decision-making paradigms. This paper specifically focuses on integrating
Federated Learning (FL) with the multi-agent energy management procedure. FL is
utilized to forecast agents' local energy generation and demand, aiming to
accelerate the convergence of the distributed decision-making process. To
enhance energy aggregation in TECs, we propose an FL-assisted distributed
Consensus + Innovations approach. The results demonstrate that employing FL
significantly reduces errors in predicting net power demand. The improved
forecast accuracy, in turn, introduces less error in the distributed
optimization process, thereby enhancing its convergence behavior.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13793" title="Abstract">arXiv:2311.13793</a> [<a href="/pdf/2311.13793" title="Download PDF">pdf</a>, <a href="/format/2311.13793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evidential Active Recognition: Intelligent and Prudent Open-World  Embodied Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lei Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+M">Mingfu Liang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+G">Gang Hua</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Ying Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Active recognition enables robots to intelligently explore novel
observations, thereby acquiring more information while circumventing undesired
viewing conditions. Recent approaches favor learning policies from simulated or
collected data, wherein appropriate actions are more frequently selected when
the recognition is accurate. However, most recognition modules are developed
under the closed-world assumption, which makes them ill-equipped to handle
unexpected inputs, such as the absence of the target object in the current
observation. To address this issue, we propose treating active recognition as a
sequential evidence-gathering process, providing by-step uncertainty
quantification and reliable prediction under the evidence combination theory.
Additionally, the reward function developed in this paper effectively
characterizes the merit of actions when operating in open-world environments.
To evaluate the performance, we collect a dataset from an indoor simulator,
encompassing various recognition challenges such as distance, occlusion levels,
and visibility. Through a series of experiments on recognition and robustness
analysis, we demonstrate the necessity of introducing uncertainties to active
recognition and the superior performance of the proposed method.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13798" title="Abstract">arXiv:2311.13798</a> [<a href="/pdf/2311.13798" title="Download PDF">pdf</a>, <a href="/format/2311.13798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient $k$-Clique Listing: An Edge-Oriented Branching Strategy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kaixin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kaiqiang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+C">Cheng Long</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by SIGMOD 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">$k$-clique listing is a vital graph mining operator with diverse applications
in various networks. The state-of-the-art algorithms all adopt a
branch-and-bound (BB) framework with a vertex-oriented branching strategy
(called VBBkC), which forms a sub-branch by expanding a partial $k$-clique with
a vertex. These algorithms have the time complexity of $O(k m
(\delta/2)^{k-2})$, where $m$ is the number of edges in the graph and $\delta$
is the degeneracy of the graph. In this paper, we propose a BB framework with a
new edge-oriented branching (called EBBkC), which forms a sub-branch by
expanding a partial $k$-clique with two vertices that connect each other (which
correspond to an edge). We explore various edge orderings for EBBkC such that
it achieves a time complexity of $O(\delta m + k m (\tau/2)^{k-2})$, where
$\tau$ is an integer related to the maximum truss number of the graph and we
have $\tau &lt; \delta$. The time complexity of EBBkC is better than that of VBBkC
algorithms for $k&gt;3$ since both $O(\delta m)$ and $O(k m (\tau/2)^{k-2})$ are
bounded by $O(k m (\delta/2)^{k-2})$. Furthermore, we develop specialized
algorithms for sub-branches on dense graphs so that we can early-terminate them
and apply the specialized algorithms. We conduct extensive experiments on 19
real graphs, and the results show that our newly developed EBBkC-based
algorithms with the early termination technique consistently and largely
outperform the state-of-the-art (VBBkC-based) algorithms.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13800" title="Abstract">arXiv:2311.13800</a> [<a href="/pdf/2311.13800" title="Download PDF">pdf</a>, <a href="/ps/2311.13800" title="Download PostScript">ps</a>, <a href="/format/2311.13800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Intrusion Detection In Internet Of Vehicles Through Federated  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sebastian%2C+A">Abhishek Sebastian</a>, 
<a href="/search/cs?searchtype=author&query=R%2C+P">Pragna R</a>, 
<a href="/search/cs?searchtype=author&query=G%2C+S">Sudhakaran G</a>, 
<a href="/search/cs?searchtype=author&query=N%2C+R+P">Renjith P N</a>, 
<a href="/search/cs?searchtype=author&query=H%2C+L+K">Leela Karthikeyan H</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Federated learning is a technique of decentralized machine learning. that
allows multiple parties to collaborate and learn a shared model without sharing
their raw data. Our paper proposes a federated learning framework for intrusion
detection in Internet of Vehicles (IOVs) using the CIC-IDS 2017 dataset. The
proposed framework employs SMOTE for handling class imbalance, outlier
detection for identifying and removing abnormal observations, and
hyperparameter tuning to optimize the model's performance. The authors
evaluated the proposed framework using various performance metrics and
demonstrated its effectiveness in detecting intrusions with other datasets
(KDD-Cup 99 and UNSW- NB-15) and conventional classifiers. Furthermore, the
proposed framework can protect sensitive data while achieving high intrusion
detection performance.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13806" title="Abstract">arXiv:2311.13806</a> [<a href="/pdf/2311.13806" title="Download PDF">pdf</a>, <a href="/format/2311.13806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdaTyper: Adaptive Semantic Column Type Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hulsebos%2C+M">Madelon Hulsebos</a>, 
<a href="/search/cs?searchtype=author&query=Groth%2C+P">Paul Groth</a>, 
<a href="/search/cs?searchtype=author&query=Demiralp%2C+%C3%87">&#xc7;a&#x11f;atay Demiralp</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to VLDB'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Understanding the semantics of relational tables is instrumental for
automation in data exploration and preparation systems. A key source for
understanding a table is the semantics of its columns. With the rise of deep
learning, learned table representations are now available, which can be applied
for semantic type detection and achieve good performance on benchmarks.
Nevertheless, we observe a gap between this performance and its applicability
in practice. In this paper, we propose AdaTyper to address one of the most
critical deployment challenges: adaptation. AdaTyper uses weak-supervision to
adapt a hybrid type predictor towards new semantic types and shifted data
distributions at inference time, using minimal human feedback. The hybrid type
predictor of AdaTyper combines rule-based methods and a light machine learning
model for semantic column type detection. We evaluate the adaptation
performance of AdaTyper on real-world database tables hand-annotated with
semantic column types through crowdsourcing and find that the f1-score improves
for new and existing types. AdaTyper approaches an average precision of 0.6
after only seeing 5 examples, significantly outperforming existing adaptation
methods based on human-provided regular expressions or dictionaries.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13809" title="Abstract">arXiv:2311.13809</a> [<a href="/pdf/2311.13809" title="Download PDF">pdf</a>, <a href="/format/2311.13809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Responsive Hydrogel-based Modular Microrobots for Multi-functional  Micromanipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+L">Liyuan Tan</a>, 
<a href="/search/cs?searchtype=author&query=Cappelleri%2C+D+J">David J. Cappelleri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Microrobots show great potential in biomedical applications such as drug
delivery and cell manipulations. However, current microrobots are mostly
fabricated as a single entity and type and the tasks they can perform are
limited. In this paper, modular microrobots, with an overall size of 120 $\mu$m
$\times$ 200 $\mu$m, are proposed with responsive mating components, made from
stimuli-responsive hydrogels, and application specific end-effectors for
microassembly tasks. The modular microrobots are fabricated based on
photolithography and two-photon polymerization together or separately. Two
types of modular microrobots are created based on the location of the
responsive mating component. The first type of modular microrobot has a mating
component that can shrink upon stimulation while the second type has a double
bilayer structure that can realize an open and close motion. The exchange of
end-effectors with an identical actuation base is demonstrated for both types
of microrobots. Finally, different manipulation tasks are performed with
different types of end-effectors.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13811" title="Abstract">arXiv:2311.13811</a> [<a href="/pdf/2311.13811" title="Download PDF">pdf</a>, <a href="/ps/2311.13811" title="Download PostScript">ps</a>, <a href="/format/2311.13811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Education distillation:getting student models to learn in shcools
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+L">Ling Feng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Danyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tianhao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+X">Xuliang Duan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Knowledge distillation is one of the methods for model compression, and
existing knowledge distillation techniques focus on how to improve the
distillation algorithm so as to enhance the distillation efficdiency. This
paper introduces dynamic incremental learning into knowledge distillation and
proposes a distillation strategy for education distillation. Specifically, it
is proposed to look at fragmented student models divided from the full student
model as low models. As the grade level rises, fragmented student models deepen
in conjunction with designed teaching reference layers, while learning and
distilling from more teacher models. By moving from lower to higher grades,
fragmented student models were gradually integrated into a complete target
student model, and the performance of the student models gradually improved
from lower to senior grades of the stage. Education distillation strategies
combined with distillation algorithms outperform the results of single
distillation algorithms on the public dataset CIFAR100,Caltech256, Food-101
dataset.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13814" title="Abstract">arXiv:2311.13814</a> [<a href="/pdf/2311.13814" title="Download PDF">pdf</a>, <a href="/format/2311.13814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Physical Human-Robot Interaction through Variable Impedance Control  based on ISO/TS 15066
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghanbarzadeh%2C+A">Armin Ghanbarzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Najafi%2C+E">Esmaeil Najafi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The successful implementation of Physical Human-Robot Interaction in
industrial environments depends on ensuring safe collaboration between human
operators and robotic devices. This necessitates the adoption of measures that
guarantee the safety of human operators in close proximity to robots, without
constraining the speed and motion of the robotic systems. This paper proposes a
novel variable impedance-based controller for cobots that ensures safe
collaboration by adhering to the ISO/TS 15066 safety standard, namely power and
force limiting mode, while achieving higher operational speeds. The
effectiveness of the proposed controller has been compared with conventional
methods and implemented on two different robotic platforms. The results
demonstrate the designed controller achieves higher speeds, while maintaining
compliance with safety standards. The proposed variable impedance holds
significant potential for enabling efficient and safe collaboration between
humans and robots in industrial settings.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13816" title="Abstract">arXiv:2311.13816</a> [<a href="/pdf/2311.13816" title="Download PDF">pdf</a>, <a href="/format/2311.13816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fairness-Aware Domain Generalization under Covariate and Dependence  Shifts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+K">Kai Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xintao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoliang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+L">Latifur Khan</a>, 
<a href="/search/cs?searchtype=author&query=Grant%2C+C">Christan Grant</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Feng Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">Achieving the generalization of an invariant classifier from source domains
to shifted target domains while simultaneously considering model fairness is a
substantial and complex challenge in machine learning. Existing domain
generalization research typically attributes domain shifts to concept shift,
which relates to alterations in class labels, and covariate shift, which
pertains to variations in data styles. In this paper, by introducing another
form of distribution shift, known as dependence shift, which involves
variations in fair dependence patterns across domains, we propose a novel
domain generalization approach that addresses domain shifts by considering both
covariate and dependence shifts. We assert the existence of an underlying
transformation model can transform data from one domain to another. By
generating data in synthetic domains through the model, a fairness-aware
invariant classifier is learned that enforces both model accuracy and fairness
in unseen domains. Extensive empirical studies on four benchmark datasets
demonstrate that our approach surpasses state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13817" title="Abstract">arXiv:2311.13817</a> [<a href="/pdf/2311.13817" title="Download PDF">pdf</a>, <a href="/format/2311.13817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Molecular Identification and Peak Assignment: Leveraging Multi-Level  Multimodal Alignment on NMR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhengyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+P">Pengyu Hong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Chemical Physics (physics.chem-ph); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Nuclear magnetic resonance (NMR) spectroscopy plays an essential role across
various scientific disciplines, providing valuable insights into molecular
dynamics and interactions. Despite the promise of AI-enhanced NMR prediction
models, challenges persist in the interpretation of spectra for tasks such as
molecular retrieval, isomer recognition, and peak assignment. In response, this
paper introduces Multi-Level Multimodal Alignment with Knowledge-Guided
Instance-Wise Discrimination (K-M3AID) to establish meaningful correspondences
between two heterogeneous modalities: molecular graphs (structures) and NMR
spectra. In particular, K-M3AID employs a dual-coordinated contrastive learning
architecture, and incorporates a graph-level alignment module, a node-level
alignment module, and a communication channel. Notably, the framework
introduces knowledge-guided instance-wise discrimination into contrastive
learning within the node-level alignment module, significantly enhancing
accuracy in cross-modal alignment. Additionally, K-M3AID showcases its
capability of meta-learning by demonstrating that skills acquired during
node-level alignment positively impact graph-level alignment. Empirical
validation underscores K-M3AID's effectiveness in addressing multiple zero-shot
tasks, offering a promising solution to bridge the gap between structural
information and spectral data in complex NMR scenarios.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13821" title="Abstract">arXiv:2311.13821</a> [<a href="/pdf/2311.13821" title="Download PDF">pdf</a>, <a href="/format/2311.13821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HypUC: Hyperfine Uncertainty Calibration with Gradient-boosted  Corrections for Reliable Regression on Imbalanced Electrocardiograms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Upadhyay%2C+U">Uddeshya Upadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Bade%2C+S">Sairam Bade</a>, 
<a href="/search/cs?searchtype=author&query=Puranik%2C+A">Arjun Puranik</a>, 
<a href="/search/cs?searchtype=author&query=Asfahan%2C+S">Shahir Asfahan</a>, 
<a href="/search/cs?searchtype=author&query=Babu%2C+M">Melwin Babu</a>, 
<a href="/search/cs?searchtype=author&query=Lopez-Jimenez%2C+F">Francisco Lopez-Jimenez</a>, 
<a href="/search/cs?searchtype=author&query=Asirvatham%2C+S+J">Samuel J. Asirvatham</a>, 
<a href="/search/cs?searchtype=author&query=Prasad%2C+A">Ashim Prasad</a>, 
<a href="/search/cs?searchtype=author&query=Rajasekharan%2C+A">Ajit Rajasekharan</a>, 
<a href="/search/cs?searchtype=author&query=Awasthi%2C+S">Samir Awasthi</a>, 
<a href="/search/cs?searchtype=author&query=Barve%2C+R">Rakesh Barve</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at TMLR
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Transactions on Machine Learning Research (TMLR), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Applications (stat.AP)

</div>
<p class="mathjax">The automated analysis of medical time series, such as the electrocardiogram
(ECG), electroencephalogram (EEG), pulse oximetry, etc, has the potential to
serve as a valuable tool for diagnostic decisions, allowing for remote
monitoring of patients and more efficient use of expensive and time-consuming
medical procedures. Deep neural networks (DNNs) have been demonstrated to
process such signals effectively. However, previous research has primarily
focused on classifying medical time series rather than attempting to regress
the continuous-valued physiological parameters central to diagnosis. One
significant challenge in this regard is the imbalanced nature of the dataset,
as a low prevalence of abnormal conditions can lead to heavily skewed data that
results in inaccurate predictions and a lack of certainty in such predictions
when deployed. To address these challenges, we propose HypUC, a framework for
imbalanced probabilistic regression in medical time series, making several
contributions. (i) We introduce a simple kernel density-based technique to
tackle the imbalanced regression problem with medical time series. (ii)
Moreover, we employ a probabilistic regression framework that allows
uncertainty estimation for the predicted continuous values. (iii) We also
present a new approach to calibrate the predicted uncertainty further. (iv)
Finally, we demonstrate a technique to use calibrated uncertainty estimates to
improve the predicted continuous value and show the efficacy of the calibrated
uncertainty estimates to flag unreliable predictions. HypUC is evaluated on a
large, diverse, real-world dataset of ECGs collected from millions of patients,
outperforming several conventional baselines on various diagnostic tasks,
suggesting a potential use-case for the reliable clinical deployment of deep
learning models.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13824" title="Abstract">arXiv:2311.13824</a> [<a href="/pdf/2311.13824" title="Download PDF">pdf</a>, <a href="/format/2311.13824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constraint-Guided Online Data Selection for Scalable Data-Driven Safety  Filters in Uncertain Robotic Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+J+J">Jason J. Choi</a>, 
<a href="/search/cs?searchtype=author&query=Casta%C3%B1eda%2C+F">Fernando Casta&#xf1;eda</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+W">Wonsuhk Jung</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bike Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tomlin%2C+C+J">Claire J. Tomlin</a>, 
<a href="/search/cs?searchtype=author&query=Sreenath%2C+K">Koushil Sreenath</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first three authors contributed equally to the work. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">As the use of autonomous robotic systems expands in tasks that are complex
and challenging to model, the demand for robust data-driven control methods
that can certify safety and stability in uncertain conditions is increasing.
However, the practical implementation of these methods often faces scalability
issues due to the growing amount of data points with system complexity, and a
significant reliance on high-quality training data. In response to these
challenges, this study presents a scalable data-driven controller that
efficiently identifies and infers from the most informative data points for
implementing data-driven safety filters. Our approach is grounded in the
integration of a model-based certificate function-based method and Gaussian
Process (GP) regression, reinforced by a novel online data selection algorithm
that reduces time complexity from quadratic to linear relative to dataset size.
Empirical evidence, gathered from successful real-world cart-pole swing-up
experiments and simulated locomotion of a five-link bipedal robot, demonstrates
the efficacy of our approach. Our findings reveal that our efficient online
data selection algorithm, which strategically selects key data points, enhances
the practicality and efficiency of data-driven certifying filters in complex
robotic systems, significantly mitigating scalability concerns inherent in
nonparametric learning-based control methods.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13831" title="Abstract">arXiv:2311.13831</a> [<a href="/pdf/2311.13831" title="Download PDF">pdf</a>, <a href="/format/2311.13831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Posterior Distillation Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koo%2C+J">Juil Koo</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+C">Chanho Park</a>, 
<a href="/search/cs?searchtype=author&query=Sung%2C+M">Minhyuk Sung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://posterior-distillation-sampling.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce Posterior Distillation Sampling (PDS), a novel optimization
method for parametric image editing based on diffusion models. Existing
optimization-based methods, which leverage the powerful 2D prior of diffusion
models to handle various parametric images, have mainly focused on generation.
Unlike generation, editing requires a balance between conforming to the target
attribute and preserving the identity of the source content. Recent 2D image
editing methods have achieved this balance by leveraging the stochastic latent
encoded in the generative process of diffusion models. To extend the editing
capabilities of diffusion models shown in pixel space to parameter space, we
reformulate the 2D image editing method into an optimization form named PDS.
PDS matches the stochastic latents of the source and the target, enabling the
sampling of targets in diverse parameter spaces that align with a desired
attribute while maintaining the source's identity. We demonstrate that this
optimization resembles running a generative process with the target attribute,
but aligning this process with the trajectory of the source's generative
process. Extensive editing results in Neural Radiance Fields and Scalable
Vector Graphics representations demonstrate that PDS is capable of sampling
targets to fulfill the aforementioned balance across various parameter spaces.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13832" title="Abstract">arXiv:2311.13832</a> [<a href="/pdf/2311.13832" title="Download PDF">pdf</a>, <a href="/format/2311.13832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Operating Envelopes Embedded Peer-to-Peer-to-Grid Energy Trading
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jiang%2C+Z">Zhisen Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+Y">Ye Guo</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+H">Hongbin Sun</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jianxiao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">A novel decentralized peer-to-peer-to-grid (P2P2G) trading mechanism
considering distribution network integrity is proposed. In order to direct
prosumers' peer-to-peer (P2P) trading behavior to be grid-friendly, the
proposed method incorporates Dynamic Operating Envelopes (DOEs) into the
existing P2P2G trading. Moreover, DOEs are determined through negotiations
between the distribution system operator (DSO) and prosumers alongside the
process of P2P trading, avoiding compromising prosumers' privacy and network
parameters leakage. To reduce communication costs during P2P trading, a variant
of the alternating direction method of multipliers (ADMM), i.e.,
communication-censored ADMM (COCA) is used to solve the P2P2G trading problem.
Finally, the DOE price is shown to be comprised of several economically
interpretable components. Simulations validate the effectiveness of the
proposed mechanism.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13833" title="Abstract">arXiv:2311.13833</a> [<a href="/pdf/2311.13833" title="Download PDF">pdf</a>, <a href="/format/2311.13833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lego: Learning to Disentangle and Invert Concepts Beyond Object  Appearance in Text-to-Image Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Motamed%2C+S">Saman Motamed</a>, 
<a href="/search/cs?searchtype=author&query=Paudel%2C+D+P">Danda Pani Paudel</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Diffusion models have revolutionized generative content creation and
text-to-image (T2I) diffusion models in particular have increased the creative
freedom of users by allowing scene synthesis using natural language. T2I models
excel at synthesizing concepts such as nouns, appearances, and styles. To
enable customized content creation based on a few example images of a concept,
methods such as Textual Inversion and DreamBooth invert the desired concept and
enable synthesizing it in new scenes. However, inverting more general concepts
that go beyond object appearance and style (adjectives and verbs) through
natural language, remains a challenge. Two key characteristics of these
concepts contribute to the limitations of current inversion methods. 1)
Adjectives and verbs are entangled with nouns (subject) and can hinder
appearance-based inversion methods, where the subject appearance leaks into the
concept embedding and 2) describing such concepts often extends beyond single
word embeddings (being frozen in ice, walking on a tightrope, etc.) that
current methods do not handle.
<br />In this study, we introduce Lego, a textual inversion method designed to
invert subject entangled concepts from a few example images. Lego disentangles
concepts from their associated subjects using a simple yet effective Subject
Separation step and employs a Context Loss that guides the inversion of
single/multi-embedding concepts. In a thorough user study, Lego-generated
concepts were preferred over 70% of the time when compared to the baseline.
Additionally, visual question answering using a large language model suggested
Lego-generated concepts are better aligned with the text description of the
concept.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13834" title="Abstract">arXiv:2311.13834</a> [<a href="/pdf/2311.13834" title="Download PDF">pdf</a>, <a href="/ps/2311.13834" title="Download PostScript">ps</a>, <a href="/format/2311.13834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asymptotically Tight Bayesian Cram&#xe9;r-Rao Bound
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aharon%2C+O">Ori Aharon</a>, 
<a href="/search/cs?searchtype=author&query=Tabrikian%2C+J">Joseph Tabrikian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Performance bounds for parameter estimation play a crucial role in
statistical signal processing theory and applications. Two widely recognized
bounds are the Cram\'{e}r-Rao bound (CRB) in the non-Bayesian framework, and
the Bayesian CRB (BCRB) in the Bayesian framework. However, unlike the CRB, the
BCRB is asymptotically unattainable in general, and its equality condition is
restrictive. This paper introduces an extension of the
Bobrovsky--Mayer-Wolf--Zakai class of bounds, also known as the weighted BCRB
(WBCRB). The WBCRB is optimized by tuning the weighting function in the scalar
case. Based on this result, we propose an asymptotically tight version of the
bound called AT-BCRB. We prove that the AT-BCRB is asymptotically attained by
the maximum {\it a-posteriori} probability (MAP) estimator. Furthermore, we
extend the WBCRB and the AT-BCRB to the case of vector parameters. The proposed
bounds are evaluated in several fundamental signal processing examples, such as
variance estimation of white Gaussian process, direction-of-arrival estimation,
and mean estimation of Gaussian process with unknown variance and prior
statistical information. It is shown that unlike the BCRB, the proposed bounds
are asymptotically attainable and coincide with the expected CRB (ECRB). The
ECRB, which imposes uniformly unbiasedness, cannot serve as a valid lower bound
in the Bayesian framework, while the proposed bounds are valid for any
estimator.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13841" title="Abstract">arXiv:2311.13841</a> [<a href="/pdf/2311.13841" title="Download PDF">pdf</a>, <a href="/format/2311.13841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial defense based on distribution transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiahao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+D">Diqun Yan</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+L">Li Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The presence of adversarial examples poses a significant threat to deep
learning models and their applications. Existing defense methods provide
certain resilience against adversarial examples, but often suffer from
decreased accuracy and generalization performance, making it challenging to
achieve a trade-off between robustness and generalization. To address this, our
paper interprets the adversarial example problem from the perspective of sample
distribution and proposes a defense method based on distribution shift,
leveraging the distribution transfer capability of a diffusion model for
adversarial defense. The core idea is to exploit the discrepancy between normal
and adversarial sample distributions to achieve adversarial defense using a
pretrained diffusion model. Specifically, an adversarial sample undergoes a
forward diffusion process, moving away from the source distribution, followed
by a reverse process guided by the protected model (victim model) output to map
it back to the normal distribution. Experimental evaluations on CIFAR10 and
ImageNet30 datasets are conducted, comparing with adversarial training and
input preprocessing methods. For infinite-norm attacks with 8/255 perturbation,
accuracy rates of 78.1% and 83.5% are achieved, respectively. For 2-norm
attacks with 128/255 perturbation, accuracy rates are 74.3% and 82.5%.
Additional experiments considering perturbation amplitude, diffusion
iterations, and adaptive attacks also validate the effectiveness of the
proposed method. Results demonstrate that even when the attacker has knowledge
of the defense, the proposed distribution-based method effectively withstands
adversarial examples. It fills the gaps of traditional approaches, restoring
high-quality original samples and showcasing superior performance in model
robustness and generalization.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13843" title="Abstract">arXiv:2311.13843</a> [<a href="/pdf/2311.13843" title="Download PDF">pdf</a>, <a href="/format/2311.13843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact Combinatorial Optimization with Temporo-Attentional Graph Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seyfi%2C+M">Mehdi Seyfi</a>, 
<a href="/search/cs?searchtype=author&query=Banitalebi-Dehkordi%2C+A">Amin Banitalebi-Dehkordi</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zirui Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ECML PKDD 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ECML PKDD 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Mathematical Software (cs.MS)

</div>
<p class="mathjax">Combinatorial optimization finds an optimal solution within a discrete set of
variables and constraints. The field has seen tremendous progress both in
research and industry. With the success of deep learning in the past decade, a
recent trend in combinatorial optimization has been to improve state-of-the-art
combinatorial optimization solvers by replacing key heuristic components with
machine learning (ML) models. In this paper, we investigate two essential
aspects of machine learning algorithms for combinatorial optimization: temporal
characteristics and attention. We argue that for the task of variable selection
in the branch-and-bound (B&amp;B) algorithm, incorporating the temporal information
as well as the bipartite graph attention improves the solver's performance. We
support our claims with intuitions and numerical results over several standard
datasets used in the literature and competitions. Code is available at:
https://developer.huaweicloud.com/develop/aigallery/notebook/detail?id=047c6cf2-8463-40d7-b92f-7b2ca998e935
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13845" title="Abstract">arXiv:2311.13845</a> [<a href="/pdf/2311.13845" title="Download PDF">pdf</a>, <a href="/format/2311.13845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Touring sampling with pushforward maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cabannes%2C+V">Vivien Cabannes</a>, 
<a href="/search/cs?searchtype=author&query=Arnal%2C+C">Charles Arnal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">The number of sampling methods could be daunting for a practitioner looking
to cast powerful machine learning methods to their specific problem. This paper
takes a theoretical stance to review and organize many sampling approaches in
the ``generative modeling'' setting, where one wants to generate new data that
are similar to some training examples. By revealing links between existing
methods, it might prove useful to overcome some of the current challenges in
sampling with diffusion models, such as long inference time due to diffusion
simulation, or the lack of diversity in generated samples.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13846" title="Abstract">arXiv:2311.13846</a> [<a href="/pdf/2311.13846" title="Download PDF">pdf</a>, <a href="/format/2311.13846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Progressive Learning with Visual Prompt Tuning for Variable-Rate Image  Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+S">Shiyu Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yimin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bin Chen</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+B">Baoyi An</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+T">Tao Dai</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Shu-Tao Xia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">In this paper, we propose a progressive learning paradigm for
transformer-based variable-rate image compression. Our approach covers a wide
range of compression rates with the assistance of the Layer-adaptive Prompt
Module (LPM). Inspired by visual prompt tuning, we use LPM to extract prompts
for input images and hidden features at the encoder side and decoder side,
respectively, which are fed as additional information into the Swin Transformer
layer of a pre-trained transformer-based image compression model to affect the
allocation of attention region and the bits, which in turn changes the target
compression ratio of the model. To ensure the network is more lightweight, we
involves the integration of prompt networks with less convolutional layers.
Exhaustive experiments show that compared to methods based on multiple models,
which are optimized separately for different target rates, the proposed method
arrives at the same performance with 80% savings in parameter storage and 90%
savings in datasets. Meanwhile, our model outperforms all current variable
bitrate image methods in terms of rate-distortion performance and approaches
the state-of-the-art fixed bitrate image compression methods trained from
scratch.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13847" title="Abstract">arXiv:2311.13847</a> [<a href="/pdf/2311.13847" title="Download PDF">pdf</a>, <a href="/format/2311.13847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perceptual Image Compression with Cooperative Cross-Modal Side  Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+S">Shiyu Qin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yujun Huang</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+B">Baoyi An</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+T">Tao Dai</a>, 
<a href="/search/cs?searchtype=author&query=Via%2C+S">Shu-Tao Via</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Theory (cs.IT); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">The explosion of data has resulted in more and more associated text being
transmitted along with images. Inspired by from distributed source coding, many
works utilize image side information to enhance image compression. However,
existing methods generally do not consider using text as side information to
enhance perceptual compression of images, even though the benefits of
multimodal synergy have been widely demonstrated in research. This begs the
following question: How can we effectively transfer text-level semantic
dependencies to help image compression, which is only available to the decoder?
In this work, we propose a novel deep image compression method with text-guided
side information to achieve a better rate-perception-distortion tradeoff.
Specifically, we employ the CLIP text encoder and an effective Semantic-Spatial
Aware block to fuse the text and image features. This is done by predicting a
semantic mask to guide the learned text-adaptive affine transformation at the
pixel level. Furthermore, we design a text-conditional generative adversarial
networks to improve the perceptual quality of reconstructed images. Extensive
experiments involving four datasets and ten image quality assessment metrics
demonstrate that the proposed approach achieves superior results in terms of
rate-perception trade-off and semantic distortion.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13848" title="Abstract">arXiv:2311.13848</a> [<a href="/pdf/2311.13848" title="Download PDF">pdf</a>, <a href="/format/2311.13848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grammatical Error Correction via Mixed-Grained Weighted Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiahao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Quan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chiwei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Z">Zhendong Mao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongdong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The task of Grammatical Error Correction (GEC) aims to automatically correct
grammatical errors in natural texts. Almost all previous works treat annotated
training data equally, but inherent discrepancies in data are neglected. In
this paper, the inherent discrepancies are manifested in two aspects, namely,
accuracy of data annotation and diversity of potential annotations. To this
end, we propose MainGEC, which designs token-level and sentence-level training
weights based on inherent discrepancies in accuracy and potential diversity of
data annotation, respectively, and then conducts mixed-grained weighted
training to improve the training effect for GEC. Empirical evaluation shows
that whether in the Seq2Seq or Seq2Edit manner, MainGEC achieves consistent and
significant performance improvements on two benchmark datasets, demonstrating
the effectiveness and superiority of the mixed-grained weighted training.
Further ablation experiments verify the effectiveness of designed weights of
both granularities in MainGEC.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13852" title="Abstract">arXiv:2311.13852</a> [<a href="/pdf/2311.13852" title="Download PDF">pdf</a>, <a href="/format/2311.13852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Cross Attention Approach to Diagnostic Explainability using Clinical  Practice Guidelines for Depression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dalal%2C+S">Sumit Dalal</a>, 
<a href="/search/cs?searchtype=author&query=Tilwani%2C+D">Deepa Tilwani</a>, 
<a href="/search/cs?searchtype=author&query=Gaur%2C+M">Manas Gaur</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+S">Sarika Jain</a>, 
<a href="/search/cs?searchtype=author&query=Shalin%2C+V">Valerie Shalin</a>, 
<a href="/search/cs?searchtype=author&query=Seth%2C+A">Amit Seth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The lack of explainability using relevant clinical knowledge hinders the
adoption of Artificial Intelligence-powered analysis of unstructured clinical
dialogue. A wealth of relevant, untapped Mental Health (MH) data is available
in online communities, providing the opportunity to address the explainability
problem with substantial potential impact as a screening tool for both online
and offline applications. We develop a method to enhance attention in popular
transformer models and generate clinician-understandable explanations for
classification by incorporating external clinical knowledge. Inspired by how
clinicians rely on their expertise when interacting with patients, we leverage
relevant clinical knowledge to model patient inputs, providing meaningful
explanations for classification. This will save manual review time and engender
trust. We develop such a system in the context of MH using clinical practice
guidelines (CPG) for diagnosing depression, a mental health disorder of global
concern. We propose an application-specific language model called ProcesS
knowledge-infused cross ATtention (PSAT), which incorporates CPGs when
computing attention. Through rigorous evaluation on three expert-curated
datasets related to depression, we demonstrate application-relevant
explainability of PSAT. PSAT also surpasses the performance of nine baseline
models and can provide explanations where other baselines fall short. We
transform a CPG resource focused on depression, such as the Patient Health
Questionnaire (e.g. PHQ-9) and related questions, into a machine-readable
ontology using SNOMED-CT. With this resource, PSAT enhances the ability of
models like GPT-3.5 to generate application-relevant explanations.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13857" title="Abstract">arXiv:2311.13857</a> [<a href="/pdf/2311.13857" title="Download PDF">pdf</a>, <a href="/ps/2311.13857" title="Download PostScript">ps</a>, <a href="/format/2311.13857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Challenges of Large Language Models for Mental Health Counseling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chung%2C+N+C">Neo Christopher Chung</a>, 
<a href="/search/cs?searchtype=author&query=Dyer%2C+G">George Dyer</a>, 
<a href="/search/cs?searchtype=author&query=Brocki%2C+L">Lennart Brocki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">The global mental health crisis is looming with a rapid increase in mental
disorders, limited resources, and the social stigma of seeking treatment. As
the field of artificial intelligence (AI) has witnessed significant
advancements in recent years, large language models (LLMs) capable of
understanding and generating human-like text may be used in supporting or
providing psychological counseling. However, the application of LLMs in the
mental health domain raises concerns regarding the accuracy, effectiveness, and
reliability of the information provided. This paper investigates the major
challenges associated with the development of LLMs for psychological
counseling, including model hallucination, interpretability, bias, privacy, and
clinical effectiveness. We explore potential solutions to these challenges that
are practical and applicable to the current paradigm of AI. From our experience
in developing and deploying LLMs for mental health, AI holds a great promise
for improving mental health care, if we can carefully navigate and overcome
pitfalls of LLMs.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13859" title="Abstract">arXiv:2311.13859</a> [<a href="/pdf/2311.13859" title="Download PDF">pdf</a>, <a href="/format/2311.13859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A TETRA-based System for Remote-Health Monitoring of First Responders:  Peak AoI Assessment in Direct and Trunked Mode
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farag%2C+H">Hossam Farag</a>, 
<a href="/search/cs?searchtype=author&query=Vujic%2C+A">Aleksandar Vujic</a>, 
<a href="/search/cs?searchtype=author&query=Kostic%2C+M">Milos Kostic</a>, 
<a href="/search/cs?searchtype=author&query=Bijelic%2C+G">Goran Bijelic</a>, 
<a href="/search/cs?searchtype=author&query=Stefanovic%2C+C">Cedomir Stefanovic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">In this paper, we study peak age of information (PAoI) performance of a novel
IoT solution for remote health-monitoring of first responders over TErrestrial
Trunked RAdio (TETRA) links. The solution features a set of sensors embedded in
a smart garment that periodically record and send physiological parameters of
first responders to a remote agent. The received data is analyzed by the remote
agent, which feeds back notifications and warnings to the first responders in
the form of electrotactile stimuli. The communication in the system is
performed over the TETRA Short Data Service (SDS), which is the default option
for the development of third-party applications and which has rather limited
capabilities. The choice of the PAoI as the parameter of interest is motivated
by its suitable to measure data freshness in IoT applications with periodic
monitoring. We derive closed-form expressions of PAoI for different
packet-management schemes allowed by the TETRA standard, and verify the
analytical results through extensive simulations under varying message
generation rates. Our results provide important insights on the expected PAoI
performance, which can be used for the system design guidelines. To the best of
our knowledge, this is the first work that analyzes AoI performance of TETRA
networks.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13861" title="Abstract">arXiv:2311.13861</a> [<a href="/pdf/2311.13861" title="Download PDF">pdf</a>, <a href="/format/2311.13861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Deep Reinforcement Learning Approach for Improving Age of Information  in Mission-Critical IoT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farag%2C+H">Hossam Farag</a>, 
<a href="/search/cs?searchtype=author&query=Gidlund%2C+M">Mikael Gidlund</a>, 
<a href="/search/cs?searchtype=author&query=Stefanovic%2C+C">Cedomir Stefanovic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The emerging mission-critical Internet of Things (IoT) play a vital role in
remote healthcare, haptic interaction, and industrial automation, where timely
delivery of status updates is crucial. The Age of Information (AoI) is an
effective metric to capture and evaluate information freshness at the
destination. A system design based solely on the optimization of the average
AoI might not be adequate to capture the requirements of mission-critical
applications, since averaging eliminates the effects of extreme events. In this
paper, we introduce a Deep Reinforcement Learning (DRL)-based algorithm to
improve AoI in mission-critical IoT applications. The objective is to minimize
an AoI-based metric consisting of the weighted sum of the average AoI and the
probability of exceeding an AoI threshold. We utilize the actor-critic method
to train the algorithm to achieve optimized scheduling policy to solve the
formulated problem. The performance of our proposed method is evaluated in a
simulated setup and the results show a significant improvement in terms of the
average AoI and the AoI violation probability compared to the related-work.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13862" title="Abstract">arXiv:2311.13862</a> [<a href="/pdf/2311.13862" title="Download PDF">pdf</a>, <a href="/ps/2311.13862" title="Download PostScript">ps</a>, <a href="/format/2311.13862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A reduced basis warm-start iterative solver for the parameterized  systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hou%2C+S">Shijin Hou</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+Y">Yanlai Chen</a>, 
<a href="/search/math?searchtype=author&query=Xia%2C+Y">Yinhua Xia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The reduced basis methods (RBMs) are widely use in fast solution of the
parametrized parametrized linear systems. In some problems lacking good
order-reduction condition, only the RBMs are not competent to give a
high-precision solution with an affordable computational cost of the offline
stage. To develop a high-precision solution and balance the offline and online
cost, we explore a reasonable and effective framework for accelerating the
iterative methods that is based on the RBMs. Firstly, the highly efficient
reduced basis (RB) solver is used as the generation tool of accurate initial
values. This data-driven initialization method could provide a warm start for
the iterative methods. Secondly, we analyze the further acceleration of the
RBMs as a preconditioner. For the purpose of high-precision solution, the
RBM-preconditioner not only fail to accelerate the convergence but also need to
pay more cost for the overuse of the RBMs. Two numerical test on 3D
steady-state diffusion equations for two- and six-dimensional parameter space
are presented to demonstrate the capability and efficiency of the
RBM-initialized pure high-fidelity iterative methods.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13864" title="Abstract">arXiv:2311.13864</a> [<a href="/pdf/2311.13864" title="Download PDF">pdf</a>, <a href="/format/2311.13864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Which Matters Most in Making Fund Investment Decisions? A  Multi-granularity Graph Disentangled Learning Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gan%2C+C">Chunjing Gan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Binbin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Bo Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tianyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yingru Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+W">Wenliang Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiqiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chuan Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by SIGIR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this paper, we highlight that both conformity and risk preference matter
in making fund investment decisions beyond personal interest and seek to
jointly characterize these aspects in a disentangled manner. Consequently, we
develop a novel M ulti-granularity Graph Disentangled Learning framework named
MGDL to effectively perform intelligent matching of fund investment products.
Benefiting from the well-established fund graph and the attention module,
multi-granularity user representations are derived from historical behaviors to
separately express personal interest, conformity and risk preference in a
fine-grained way. To attain stronger disentangled representations with specific
semantics, MGDL explicitly involve two self-supervised signals, i.e., fund type
based contrasts and fund popularity. Extensive experiments in offline and
online environments verify the effectiveness of MGDL.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13865" title="Abstract">arXiv:2311.13865</a> [<a href="/pdf/2311.13865" title="Download PDF">pdf</a>, <a href="/format/2311.13865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language-guided Few-shot Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qiang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Expanded version for a pending ICASSP2024 submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Few-shot learning is a promising way for reducing the label cost in new
categories adaptation with the guidance of a small, well labeled support set.
But for few-shot semantic segmentation, the pixel-level annotations of support
images are still expensive. In this paper, we propose an innovative solution to
tackle the challenge of few-shot semantic segmentation using only language
information, i.e.image-level text labels. Our approach involves a
vision-language-driven mask distillation scheme, which contains a
vision-language pretraining (VLP) model and a mask refiner, to generate high
quality pseudo-semantic masks from text prompts. We additionally introduce a
distributed prototype supervision method and complementary correlation matching
module to guide the model in digging precise semantic relations among support
and query images. The experiments on two benchmark datasets demonstrate that
our method establishes a new baseline for language-guided few-shot semantic
segmentation and achieves competitive results to recent vision-guided methods.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13866" title="Abstract">arXiv:2311.13866</a> [<a href="/pdf/2311.13866" title="Download PDF">pdf</a>, <a href="/format/2311.13866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Robot Fault Detection and Diagnosis Using Generative Models:  A Modified SFDD Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mitrevski%2C+A">Alex Mitrevski</a>, 
<a href="/search/cs?searchtype=author&query=Pl%C3%B6ger%2C+P+G">Paul G. Pl&#xf6;ger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the 30th International Workshop on Principles of Diagnosis (DX), 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents a modification of the data-driven sensor-based fault
detection and diagnosis (SFDD) algorithm for online robot monitoring. Our
version of the algorithm uses a collection of generative models, in particular
restricted Boltzmann machines, each of which represents the distribution of
sliding window correlations between a pair of correlated measurements. We use
such models in a residual generation scheme, where high residuals generate
conflict sets that are then used in a subsequent diagnosis step. As a proof of
concept, the framework is evaluated on a mobile logistics robot for the problem
of recognising disconnected wheels, such that the evaluation demonstrates the
feasibility of the framework (on the faulty data set, the models obtained 88.6%
precision and 75.6% recall rates), but also shows that the monitoring results
are influenced by the choice of distribution model and the model parameters as
a whole.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13868" title="Abstract">arXiv:2311.13868</a> [<a href="/pdf/2311.13868" title="Download PDF">pdf</a>, <a href="/format/2311.13868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> To Transmit or Not to Transmit: Optimal Sensor Schedule for Remote State  Estimation of Discrete-Event Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yingying Liu</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+J">Jin Hu</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+Y">Yongxia Yang</a>, 
<a href="/search/eess?searchtype=author&query=Duan%2C+W">Wei Duan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures. This paper was presented at ACC2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper considers the problem of optimal sensor schedules for remote state
estimation of discrete-event systems. In this setting, the sensors observe
information from the plant and transmit the observable information to the
receiver or estimator selectively. A transmission mechanism decides whether the
observable information is transmitted or not, according to an information
transmission policy, such that the receiver has sufficient information to
satisfy the purpose of decision-making. To construct such a transmission
mechanism, we first construct a non-deterministic dynamic observer that
contains all feasible information transmission policies. Then, we show that the
information updating rule of the dynamic observer indeed yields the state
estimate from the receiver's point of view. Finally, we propose an approach to
extract a specific information transmission policy, realized by a finite-state
automaton, from the dynamic observer while satisfying some desired observation
properties. To reduce transmission-related costs, we also require that the
sensors transmit events as few as possible. A running example is provided to
illustrate the proposed procedures.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13870" title="Abstract">arXiv:2311.13870</a> [<a href="/pdf/2311.13870" title="Download PDF">pdf</a>, <a href="/format/2311.13870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> L(M)V-IQL: Multiple Intention Inverse Reinforcement Learning for Animal  Behavior Characterization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=De+La+Crompe%2C+B">Brice De La Crompe</a>, 
<a href="/search/cs?searchtype=author&query=Kalweit%2C+G">Gabriel Kalweit</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+A">Artur Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Kalweit%2C+M">Maria Kalweit</a>, 
<a href="/search/cs?searchtype=author&query=Diester%2C+I">Ilka Diester</a>, 
<a href="/search/cs?searchtype=author&query=Boedecker%2C+J">Joschka Boedecker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">In advancing the understanding of decision-making processes, mathematical
models, particularly Inverse Reinforcement Learning (IRL), have proven
instrumental in reconstructing animal's multiple intentions amidst complex
behaviors. Given the recent development of a continuous-time multi-intention
IRL framework, there has been persistent inquiry into inferring discrete
time-varying reward functions with multiple intention IRL approaches. To tackle
the challenge, we introduce the Latent (Markov) Variable Inverse Q-learning
(L(M)V-IQL) algorithms, a novel IRL framework tailored for accommodating
discrete intrinsic rewards. Leveraging an Expectation-Maximization approach, we
cluster observed trajectories into distinct intentions and independently solve
the IRL problem for each. Demonstrating the efficacy of L(M)V-IQL through
simulated experiments and its application to different real mouse behavior
datasets, our approach surpasses current benchmarks in animal behavior
prediction, producing interpretable reward functions. This advancement holds
promise for neuroscience and psychology, contributing to a deeper understanding
of animal decision-making and uncovering underlying brain mechanisms.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13871" title="Abstract">arXiv:2311.13871</a> [<a href="/pdf/2311.13871" title="Download PDF">pdf</a>, <a href="/format/2311.13871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Legal Requirements Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abualhaija%2C+S">Sallam Abualhaija</a>, 
<a href="/search/cs?searchtype=author&query=Ceci%2C+M">Marcello Ceci</a>, 
<a href="/search/cs?searchtype=author&query=Briand%2C+L">Lionel Briand</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Modern software has been an integral part of everyday activities in many
disciplines and application contexts. Introducing intelligent automation by
leveraging artificial intelligence (AI) led to break-throughs in many fields.
The effectiveness of AI can be attributed to several factors, among which is
the increasing availability of data. Regulations such as the general data
protection regulation (GDPR) in the European Union (EU) are introduced to
ensure the protection of personal data. Software systems that collect, process,
or share personal data are subject to compliance with such regulations.
Developing compliant software depends heavily on addressing legal requirements
stipulated in applicable regulations, a central activity in the requirements
engineering (RE) phase of the software development process. RE is concerned
with specifying and maintaining requirements of a system-to-be, including legal
requirements. Legal agreements which describe the policies organizations
implement for processing personal data can provide an additional source to
regulations for eliciting legal requirements. In this chapter, we explore a
variety of methods for analyzing legal requirements and exemplify them on GDPR.
Specifically, we describe possible alternatives for creating machine-analyzable
representations from regulations, survey the existing automated means for
enabling compliance verification against regulations, and further reflect on
the current challenges of legal requirements analysis.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13875" title="Abstract">arXiv:2311.13875</a> [<a href="/pdf/2311.13875" title="Download PDF">pdf</a>, <a href="/ps/2311.13875" title="Download PostScript">ps</a>, <a href="/format/2311.13875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Max-Min SINR Analysis of STAR-RIS Assisted Massive MIMO Systems with  Hardware Impairments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Papazafeiropoulos%2C+A">Anastasios Papazafeiropoulos</a>, 
<a href="/search/cs?searchtype=author&query=Kourtessis%2C+P">Pandelis Kourtessis</a>, 
<a href="/search/cs?searchtype=author&query=Chatzinotas%2C+S">Symeon Chatzinotas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted in IEEE TWC
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Reconfigurable intelligent surface (RIS) has emerged as a cost-effective
solution to improve wireless communication performance through just passive
reflection. Recently, the concept of simultaneously transmitting and reflecting
RIS (STAR-RIS) has appeared but the study of minimum
signal-to-interference-plus-noise ratio (SINR) and the impact of hardware
impairments (HWIs) remain open. In addition to previous works on STAR-RIS, we
consider a massive multiple-input multiple-output (mMIMO) base station (BS)
serving multiple user equipments (UEs) at both sides of the RIS. Specifically,
in this work, focusing on the downlink of a single cell, we derive the minimum
SINR obtained by the optimal linear precoder (OLP) with HWIs in closed form.
The OLP maximises the minimum SINR subject to a given power constraint for any
given passive beamforming matrix (PBM). Next, we obtain deterministic
equivalents (DEs) for the OLP and the minimum SINR, which are then used to
optimise the PBM. Notably, based on the DEs and statistical channel state
information (CSI), we optimise simultaneously the amplitude and phase shift by
using a projected gradient ascent algorithm (PGAM) for both energy splitting
(ES) and mode switching (MS) STAR-RIS operation protocols with reduced
feedback, \textcolor{black}{which is quite crucial for STAR-RIS systems that
include the double number or variables compared to reflecting only RIS.}
Simulations verify the analytical results, shed light on the impact of HWIs,
and demonstrate the better performance of STAR-RIS compared to conventional
RIS.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13877" title="Abstract">arXiv:2311.13877</a> [<a href="/pdf/2311.13877" title="Download PDF">pdf</a>, <a href="/format/2311.13877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Locally Optimal Descent for Dynamic Stepsize Scheduling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yehudai%2C+G">Gilad Yehudai</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+A">Alon Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Daniely%2C+A">Amit Daniely</a>, 
<a href="/search/cs?searchtype=author&query=Drori%2C+Y">Yoel Drori</a>, 
<a href="/search/cs?searchtype=author&query=Koren%2C+T">Tomer Koren</a>, 
<a href="/search/cs?searchtype=author&query=Schain%2C+M">Mariano Schain</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">We introduce a novel dynamic learning-rate scheduling scheme grounded in
theory with the goal of simplifying the manual and time-consuming tuning of
schedules in practice. Our approach is based on estimating the locally-optimal
stepsize, guaranteeing maximal descent in the direction of the stochastic
gradient of the current step. We first establish theoretical convergence bounds
for our method within the context of smooth non-convex stochastic optimization,
matching state-of-the-art bounds while only assuming knowledge of the
smoothness parameter. We then present a practical implementation of our
algorithm and conduct systematic experiments across diverse datasets and
optimization algorithms, comparing our scheme with existing state-of-the-art
learning-rate schedulers. Our findings indicate that our method needs minimal
tuning when compared to existing approaches, removing the need for auxiliary
manual schedules and warm-up phases and achieving comparable performance with
drastically reduced parameter tuning.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13878" title="Abstract">arXiv:2311.13878</a> [<a href="/pdf/2311.13878" title="Download PDF">pdf</a>, <a href="/format/2311.13878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimizing Factual Inconsistency and Hallucination in Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=I%2C+M">Muneeswaran I</a>, 
<a href="/search/cs?searchtype=author&query=Saxena%2C+S">Shreya Saxena</a>, 
<a href="/search/cs?searchtype=author&query=Prasad%2C+S">Siva Prasad</a>, 
<a href="/search/cs?searchtype=author&query=Prakash%2C+M+V+S">M V Sai Prakash</a>, 
<a href="/search/cs?searchtype=author&query=Shankar%2C+A">Advaith Shankar</a>, 
<a href="/search/cs?searchtype=author&query=V%2C+V">Varun V</a>, 
<a href="/search/cs?searchtype=author&query=Vaddina%2C+V">Vishal Vaddina</a>, 
<a href="/search/cs?searchtype=author&query=Gopalakrishnan%2C+S">Saisubramaniam Gopalakrishnan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models (LLMs) are widely used in critical fields such as
healthcare, education, and finance due to their remarkable proficiency in
various language-related tasks. However, LLMs are prone to generating factually
incorrect responses or "hallucinations," which can lead to a loss of
credibility and trust among users. To address this issue, we propose a
multi-stage framework that generates the rationale first, verifies and refines
incorrect ones, and uses them as supporting references to generate the answer.
The generated rationale enhances the transparency of the answer and our
framework provides insights into how the model arrived at this answer, by using
this rationale and the references to the context. In this paper, we demonstrate
its effectiveness in improving the quality of responses to drug-related
inquiries in the life sciences industry. Our framework improves traditional
Retrieval Augmented Generation (RAG) by enabling OpenAI GPT-3.5-turbo to be
14-25% more faithful and 16-22% more accurate on two datasets. Furthermore,
fine-tuning samples based on our framework improves the accuracy of smaller
open-access LLMs by 33-42% and competes with RAG on commercial models.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13880" title="Abstract">arXiv:2311.13880</a> [<a href="/pdf/2311.13880" title="Download PDF">pdf</a>, <a href="/format/2311.13880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PointPCA+: Extending PointPCA objective quality assessment metric
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xuemei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Alexiou%2C+E">Evangelos Alexiou</a>, 
<a href="/search/cs?searchtype=author&query=Viola%2C+I">Irene Viola</a>, 
<a href="/search/cs?searchtype=author&query=Cesar%2C+P">Pablo Cesar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICIP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">A computationally-simplified and descriptor-richer Point Cloud Quality
Assessment (PCQA) metric, namely PointPCA+, is proposed in this paper, which is
an extension of PointPCA. PointPCA proposed a set of perceptually-relevant
descriptors based on PCA decomposition that were applied to both the geometry
and texture data of point clouds for full reference PCQA. PointPCA+ employs PCA
only on the geometry data while enriching existing geometry and texture
descriptors, that are computed more efficiently. Similarly to PointPCA, a total
quality score is obtained through a learning-based fusion of individual
predictions from geometry and texture descriptors that capture local shape and
appearance properties, respectively. Before feature fusion, a feature selection
module is introduced to choose the most effective features from a proposed
super-set. Experimental results show that PointPCA+ achieves high predictive
performance against subjective ground truth scores obtained from publicly
available datasets. The code is available at
\url{https://github.com/cwi-dis/pointpca_suite/}.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13881" title="Abstract">arXiv:2311.13881</a> [<a href="/pdf/2311.13881" title="Download PDF">pdf</a>, <a href="/format/2311.13881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multi-solution Study on GDPR AI-enabled Completeness Checking of DPAs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azeem%2C+M+I">Muhammad Ilyas Azeem</a>, 
<a href="/search/cs?searchtype=author&query=Abualhaija%2C+S">Sallam Abualhaija</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Specifying legal requirements for software systems to ensure their compliance
with the applicable regulations is a major concern to requirements engineering
(RE). Personal data which is collected by an organization is often shared with
other organizations to perform certain processing activities. In such cases,
the General Data Protection Regulation (GDPR) requires issuing a data
processing agreement (DPA) which regulates the processing and further ensures
that personal data remains protected. Violating GDPR can lead to huge fines
reaching to billions of Euros. Software systems involving personal data
processing must adhere to the legal obligations stipulated in GDPR and outlined
in DPAs. Requirements engineers can elicit from DPAs legal requirements for
regulating the data processing activities in software systems. Checking the
completeness of a DPA according to the GDPR provisions is therefore an
essential prerequisite to ensure that the elicited requirements are complete.
Analyzing DPAs entirely manually is time consuming and requires adequate legal
expertise. In this paper, we propose an automation strategy to address the
completeness checking of DPAs against GDPR. Specifically, we pursue ten
alternative solutions which are enabled by different technologies, namely
traditional machine learning, deep learning, language modeling, and few-shot
learning. The goal of our work is to empirically examine how these different
technologies fare in the legal domain. We computed F2 score on a set of 30 real
DPAs. Our evaluation shows that best-performing solutions yield F2 score of
86.7% and 89.7% are based on pre-trained BERT and RoBERTa language models. Our
analysis further shows that other alternative solutions based on deep learning
(e.g., BiLSTM) and few-shot learning (e.g., SetFit) can achieve comparable
accuracy, yet are more efficient to develop.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13883" title="Abstract">arXiv:2311.13883</a> [<a href="/pdf/2311.13883" title="Download PDF">pdf</a>, <a href="/format/2311.13883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Optimal Transport via Projections on Subspaces for Machine  Learning Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bonet%2C+C">Cl&#xe9;ment Bonet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD Thesis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Optimal Transport has received much attention in Machine Learning as it
allows to compare probability distributions by exploiting the geometry of the
underlying space. However, in its original formulation, solving this problem
suffers from a significant computational burden. Thus, a meaningful line of
work consists at proposing alternatives to reduce this burden while still
enjoying its properties. In this thesis, we focus on alternatives which use
projections on subspaces. The main such alternative is the Sliced-Wasserstein
distance, which we first propose to extend to Riemannian manifolds in order to
use it in Machine Learning applications for which using such spaces has been
shown to be beneficial in the recent years. We also study sliced distances
between positive measures in the so-called unbalanced OT problem. Back to the
original Euclidean Sliced-Wasserstein distance between probability measures, we
study the dynamic of gradient flows when endowing the space with this distance
in place of the usual Wasserstein distance. Then, we investigate the use of the
Busemann function, a generalization of the inner product in metric spaces, in
the space of probability measures. Finally, we extend the subspace detour
approach to incomparable spaces using the Gromov-Wasserstein distance.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13884" title="Abstract">arXiv:2311.13884</a> [<a href="/pdf/2311.13884" title="Download PDF">pdf</a>, <a href="/format/2311.13884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controlling Large Language Model-based Agents for Large-Scale  Decision-Making: An Actor-Critic Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+H">Hangyu Mao</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+J">Jingqing Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Ying Wen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dapeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziyue Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lijuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+G">Guoliang Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The significant advancements in large language models (LLMs) have presented
novel opportunities for tackling planning and decision-making within
multi-agent systems. However, as the number of agents increases, the issues of
hallucination in LLMs and coordination in multi-agent systems (MAS) have become
increasingly pronounced. Additionally, the efficient utilization of tokens
becomes a critical consideration when employing LLMs to facilitate the
interactions of large numbers of agents. In this paper, we present a novel
framework aimed at enhancing coordination and decision-making capabilities of
LLMs within large-scale multi-agent environments. Our approach draws
inspiration from the actor-critic framework employed in multi-agent
reinforcement learning, and we develop a modular and token-efficient solution
that effectively addresses challenges presented by LLMs and MAS. Through
evaluations conducted in experiments involving system resource allocation and
robot grid transportation, we demonstrate the considerable advantages afforded
by our proposed approach.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13885" title="Abstract">arXiv:2311.13885</a> [<a href="/pdf/2311.13885" title="Download PDF">pdf</a>, <a href="/format/2311.13885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Physics Informed Neural Operators Self Improve?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Majumdar%2C+R">Ritam Majumdar</a>, 
<a href="/search/cs?searchtype=author&query=Varhade%2C+A">Amey Varhade</a>, 
<a href="/search/cs?searchtype=author&query=Karande%2C+S">Shirish Karande</a>, 
<a href="/search/cs?searchtype=author&query=Vig%2C+L">Lovekesh Vig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted as a Spotlight talk at Symbiosis of Deep Learning and Differential Equations, Neural Information Processing Systems 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Analysis of PDEs (math.AP)

</div>
<p class="mathjax">Self-training techniques have shown remarkable value across many deep
learning models and tasks. However, such techniques remain largely unexplored
when considered in the context of learning fast solvers for systems of partial
differential equations (Eg: Neural Operators). In this work, we explore the use
of self-training for Fourier Neural Operators (FNO). Neural Operators emerged
as a data driven technique, however, data from experiments or traditional
solvers is not always readily available. Physics Informed Neural Operators
(PINO) overcome this constraint by utilizing a physics loss for the training,
however the accuracy of PINO trained without data does not match the
performance obtained by training with data. In this work we show that
self-training can be used to close this gap in performance. We examine
canonical examples, namely the 1D-Burgers and 2D-Darcy PDEs, to showcase the
efficacy of self-training. Specifically, FNOs, when trained exclusively with
physics loss through self-training, approach 1.07x for Burgers and 1.02x for
Darcy, compared to FNOs trained with both data and physics loss. Furthermore,
we discover that pseudo-labels can be used for self-training without
necessarily training to convergence in each iteration. A consequence of this is
that we are able to discover self-training schedules that improve upon the
baseline performance of PINO in terms of accuracy as well as time.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13887" title="Abstract">arXiv:2311.13887</a> [<a href="/pdf/2311.13887" title="Download PDF">pdf</a>, <a href="/format/2311.13887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Learning for Topological Classification of Transportation  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sabzekar%2C+S">Sina Sabzekar</a>, 
<a href="/search/cs?searchtype=author&query=Malakshah%2C+M+R+V">Mohammad Reza Valipour Malakshah</a>, 
<a href="/search/cs?searchtype=author&query=Amini%2C+Z">Zahra Amini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">With increasing urbanization, transportation plays an increasingly critical
role in city development. The number of studies on modeling, optimization,
simulation, and data analysis of transportation systems is on the rise. Many of
these studies utilize transportation test networks to represent real-world
transportation systems in urban areas, examining the efficacy of their proposed
approaches. Each of these networks exhibits unique characteristics in their
topology, making their applications distinct for various study objectives.
Despite their widespread use in research, there is a lack of comprehensive
study addressing the classification of these networks based on their
topological characteristics. This study aims to fill this gap by employing
unsupervised learning methods, particularly clustering. We present a
comprehensive framework for evaluating various topological network
characteristics. Additionally, we employ two dimensionality reduction
techniques, namely Principal Component Analysis (PCA) and Isometric Feature
Mapping (ISOMAP), to reduce overlaps of highly correlated features and enhance
the interpretability of the subsequent classification results. We then utilize
two clustering algorithms, K-means and HDBSCAN, to classify 14 transportation
networks. The PCA method, followed by the K-means clustering approach,
outperforms other alternatives with a Silhouette score of $0.510$, enabling the
classification of transportation networks into five clusters. We also provide a
detailed discussion on the resulting classification.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13888" title="Abstract">arXiv:2311.13888</a> [<a href="/pdf/2311.13888" title="Download PDF">pdf</a>, <a href="/format/2311.13888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-order upwind summation-by-parts methods for nonlinear conservation  laws
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ranocha%2C+H">Hendrik Ranocha</a>, 
<a href="/search/math?searchtype=author&query=Winters%2C+A+R">Andrew R. Winters</a>, 
<a href="/search/math?searchtype=author&query=Schlottke-Lakemper%2C+M">Michael Schlottke-Lakemper</a>, 
<a href="/search/math?searchtype=author&query=%C3%96ffner%2C+P">Philipp &#xd6;ffner</a>, 
<a href="/search/math?searchtype=author&query=Glaubitz%2C+J">Jan Glaubitz</a>, 
<a href="/search/math?searchtype=author&query=Gassner%2C+G+J">Gregor J. Gassner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">High-order methods for conservation laws can be very efficient, in particular
on modern hardware. However, it can be challenging to guarantee their stability
and robustness, especially for under-resolved flows. A typical approach is to
combine a well-working baseline scheme with additional techniques to ensure
invariant domain preservation. To obtain good results without too much
dissipation, it is important to develop suitable baseline methods. In this
article, we study upwind summation-by-parts operators, which have been used
mostly for linear problems so far. These operators come with some built-in
dissipation everywhere, not only at element interfaces as typical in
discontinuous Galerkin methods. At the same time, this dissipation does not
introduce additional parameters. We discuss the relation of high-order upwind
summation-by-parts methods to flux vector splitting schemes and investigate
their local linear/energy stability. Finally, we present some numerical
examples for shock-free flows of the compressible Euler equations.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13889" title="Abstract">arXiv:2311.13889</a> [<a href="/pdf/2311.13889" title="Download PDF">pdf</a>, <a href="/format/2311.13889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SIMBa: System Identification Methods leveraging Backpropagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Di+Natale%2C+L">Loris Di Natale</a>, 
<a href="/search/eess?searchtype=author&query=Zakwan%2C+M">Muhammad Zakwan</a>, 
<a href="/search/eess?searchtype=author&query=Heer%2C+P">Philipp Heer</a>, 
<a href="/search/eess?searchtype=author&query=Trecate%2C+G+F">Giancarlo Ferrari Trecate</a>, 
<a href="/search/eess?searchtype=author&query=Jones%2C+C+N">Colin N. Jones</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> First two authors contributed equally. Submitted to IEEE TCST
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This manuscript details the SIMBa toolbox (System Identification Methods
leveraging Backpropagation), which uses well-established Machine Learning tools
for discrete-time linear multi-step-ahead state-space System Identification
(SI). Backed up by novel linear-matrix-inequality-based free parametrizations
of Schur matrices to guarantee the stability of the identified model by design,
SIMBa allows for seamless integration of prior system knowledge. In particular,
it can simultaneously enforce desired system properties - such as sparsity
patterns - and stability on the model, solving an open SI problem.
<br />We extensively investigate SIMBa's behavior when identifying diverse systems
with various properties from both simulated and real-world data. Overall, we
find it consistently outperforms traditional stable subspace identification
methods, and sometimes significantly, even while enforcing desired model
properties. These results hint at the potential of SIMBa to pave the way for
generic structured nonlinear SI. The toolbox is open-sourced on
https://github.com/Cemempamoi/simba.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13890" title="Abstract">arXiv:2311.13890</a> [<a href="/pdf/2311.13890" title="Download PDF">pdf</a>, <a href="/format/2311.13890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical bounds on the Crouzeix ratio for a class of matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Michel%2C+C">Crouzeix Michel</a> (IRMAR), 
<a href="/search/math?searchtype=author&query=Anne%2C+G">Greenbaum Anne</a>, 
<a href="/search/math?searchtype=author&query=Kenan%2C+L">Li Kenan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We provide numerical bounds on the Crouzeix ratiofor KLS matrices $A$ which
have a line segment on the boundary of the numerical range. The Crouzeix ratio
is the supremum over all polynomials $p$ of the spectral norm of $p(A)$
dividedby the maximum absolute value of $p$ on the numerical range of $A$.Our
bounds confirm the conjecture that this ratiois less than or equal to $2$. We
also give a precise description of these numerical ranges.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13892" title="Abstract">arXiv:2311.13892</a> [<a href="/pdf/2311.13892" title="Download PDF">pdf</a>, <a href="/format/2311.13892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> General Phrase Debiaser: Debiasing Masked Language Models at a  Multi-Token Level
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Bingkang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaodan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+D">Dehan Kong</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yulei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zongzhen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+H">Honglei Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Longtao Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The social biases and unwelcome stereotypes revealed by pretrained language
models are becoming obstacles to their application. Compared to numerous
debiasing methods targeting word level, there has been relatively less
attention on biases present at phrase level, limiting the performance of
debiasing in discipline domains. In this paper, we propose an automatic
multi-token debiasing pipeline called \textbf{General Phrase Debiaser}, which
is capable of mitigating phrase-level biases in masked language models.
Specifically, our method consists of a \textit{phrase filter stage} that
generates stereotypical phrases from Wikipedia pages as well as a \textit{model
debias stage} that can debias models at the multi-token level to tackle bias
challenges on phrases. The latter searches for prompts that trigger model's
bias, and then uses them for debiasing. State-of-the-art results on standard
datasets and metrics show that our approach can significantly reduce gender
biases on both career and multiple disciplines, across models with varying
parameter sizes.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13893" title="Abstract">arXiv:2311.13893</a> [<a href="/pdf/2311.13893" title="Download PDF">pdf</a>, <a href="/ps/2311.13893" title="Download PostScript">ps</a>, <a href="/format/2311.13893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beamforming Design for Hybrid IRS-aided AF Relay Wireless Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuehui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yifan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+F">Feng Shu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2301.02858">arXiv:2301.02858</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, a hybrid IRS-aided amplify-and-forward (AF) relay wireless
network is put forward, where the hybrid IRS is made up of passive and active
elements. For maximum signal-to-noise ratio (SNR), a low-complexity method
based on successive convex approximation and fractional programming (LC-SCA-FP)
is proposed to jointly optimize the beamforming matrix at AF relay and the
reflecting coefficient matrices at IRS. Simulation results verify that the rate
achieved by the proposed LC-SCA-FP method surpass those of the benchmark
schemes, namely the passive IRS-aided AF relay and only AF relay network.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13894" title="Abstract">arXiv:2311.13894</a> [<a href="/pdf/2311.13894" title="Download PDF">pdf</a>, <a href="/ps/2311.13894" title="Download PostScript">ps</a>, <a href="/format/2311.13894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A first step towards an ecosystem meta-model for humancentered design in  case of disabled users
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kolski%2C+C">Christophe Kolski</a> (LAMIH), 
<a href="/search/cs?searchtype=author&query=Vigouroux%2C+N">Nadine Vigouroux</a> (IRIT-ELIPSE, CNRS, GREYC), 
<a href="/search/cs?searchtype=author&query=Guerrier%2C+Y">Yohan Guerrier</a> (LAMIH), 
<a href="/search/cs?searchtype=author&query=Vella%2C+F">Fr&#xe9;d&#xe9;ric Vella</a> (IRIT-ELIPSE, CNRS), 
<a href="/search/cs?searchtype=author&query=Guffroy%2C+M">Marine Guffroy</a> (CREN)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Disab2023 Engineering Interactive Computing Systems for People
  with Disabilities, Jun 2023, Swansea, United Kingdom
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">The involvement of the ecosystem or social environment of the disabled user
is considered as very useful and even essential for the human-centered design
of assistive technologies. In the era of model-based approaches, the modeling
of the ecosystem is therefore to be considered. The first version of a
metamodel of ecosystem is proposed. It is illustrated through a first case
study. It concerns a project aiming at a communication aid for people with
cerebral palsy. A conclusion and research perspectives end this paper.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13895" title="Abstract">arXiv:2311.13895</a> [<a href="/pdf/2311.13895" title="Download PDF">pdf</a>, <a href="/format/2311.13895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Query by Activity Video in the Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+T">Tao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Thong%2C+W">William Thong</a>, 
<a href="/search/cs?searchtype=author&query=Mettes%2C+P">Pascal Mettes</a>, 
<a href="/search/cs?searchtype=author&query=Snoek%2C+C+G+M">Cees G.M. Snoek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> An extended version of ICIP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper focuses on activity retrieval from a video query in an imbalanced
scenario. In current query-by-activity-video literature, a common assumption is
that all activities have sufficient labelled examples when learning an
embedding. This assumption does however practically not hold, as only a portion
of activities have many examples, while other activities are only described by
few examples. In this paper, we propose a visual-semantic embedding network
that explicitly deals with the imbalanced scenario for activity retrieval. Our
network contains two novel modules. The visual alignment module performs a
global alignment between the input video and fixed-sized visual bank
representations for all activities. The semantic module performs an alignment
between the input video and fixed-sized semantic activity representations. By
matching videos with both visual and semantic activity representations that are
of equal size over all activities, we no longer ignore infrequent activities
during retrieval. Experiments on a new imbalanced activity retrieval benchmark
show the effectiveness of our approach for all types of activities.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13898" title="Abstract">arXiv:2311.13898</a> [<a href="/pdf/2311.13898" title="Download PDF">pdf</a>, <a href="/ps/2311.13898" title="Download PostScript">ps</a>, <a href="/format/2311.13898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HandiMathKey-Device
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vella%2C+F">Fr&#xe9;d&#xe9;ric Vella</a> (IRIT-ELIPSE, CNRS), 
<a href="/search/cs?searchtype=author&query=Dubus%2C+N">Nathalie Dubus</a>, 
<a href="/search/cs?searchtype=author&query=Grolleau%2C+E">Eloise Grolleau</a>, 
<a href="/search/cs?searchtype=author&query=Deleau%2C+M">Marjorie Deleau</a>, 
<a href="/search/cs?searchtype=author&query=Malet%2C+C">C&#xe9;cile Malet</a> (ASEI), 
<a href="/search/cs?searchtype=author&query=Gallard%2C+C">Christine Gallard</a> (ASEI), 
<a href="/search/cs?searchtype=author&query=Ades%2C+V">V&#xe9;ronique Ades</a> (ASEI), 
<a href="/search/cs?searchtype=author&query=Vigouroux%2C+N">Nadine Vigouroux</a> (IRIT-ELIPSE, CNRS)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Universal Access in Human-Computer Interaction. HCII 2023, Jul 2023, Copenhagen (Virtual), Denmark
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Typing mathematics is sometimes difficult with text editor functions for
students with motor impairment and other associated impairments (visual,
cognitive). Based on the HandiMathKey software keyboard, a user-centred design
method involving the ecosytem of disabled students was applied to design the
HMK-D physical keyboard for mathematical input. We opted for the Stream Deck
device because of its multimedia features and its appeal to young students to
the HMK-D. Preliminary tests with 8 students (5 in secondary school and 3 in
high school) shows that HMK-D is highly accepted, accessible and fun for
mathematical input by students with impairments. A longitudinal study of the
usability and acceptability of HMK-D is planned for the 2023-2024 school year.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13902" title="Abstract">arXiv:2311.13902</a> [<a href="/pdf/2311.13902" title="Download PDF">pdf</a>, <a href="/format/2311.13902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Application of Reduced Basis Methods to Core Computation in APOLLO3
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Taumhas%2C+Y+C">Yonah Conjungo Taumhas</a> (SERMA), 
<a href="/search/math?searchtype=author&query=Dusson%2C+G">Genevi&#xe8;ve Dusson</a> (LMB), 
<a href="/search/math?searchtype=author&query=Ehrlacher%2C+V">Virginie Ehrlacher</a> (CERMICS, MATHERIALS), 
<a href="/search/math?searchtype=author&query=Leli%C3%A8vre%2C+T">Tony Leli&#xe8;vre</a> (CERMICS, MATHERIALS), 
<a href="/search/math?searchtype=author&query=Madiot%2C+F">Fran&#xe7;ois Madiot</a> (SERMA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In the aim of reducing the computational cost of the resolution of
parameter-dependent eigenvalue problems, a model order reduction (MOR)
procedure is proposed. We focus on the case of non-self-adjoint generalized
eigenvalue problems, such as the stationary multigroup neutron diffusion
equations. The method lies in an approximation of the manifold of solutions
using a Proper Orthogonal Decomposition approach. The numerical method is
composed of two stages. In the offline stage, we build a reduced space which
approximates the manifold. In the online stage, for any given new set of
parameters, we solve a reduced problem on the reduced space within a much
smaller computational time than the required time to solve the high-fidelity
problem. This method is applied to core computations in the APOLLO3 code.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13905" title="Abstract">arXiv:2311.13905</a> [<a href="/pdf/2311.13905" title="Download PDF">pdf</a>, <a href="/format/2311.13905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A DRL solution to help reduce the cost in waiting time of securing a  traffic light for cyclists
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Magnana%2C+L">Lucas Magnana</a> (AGORA), 
<a href="/search/cs?searchtype=author&query=Rivano%2C+H">Herv&#xe9; Rivano</a> (AGORA), 
<a href="/search/cs?searchtype=author&query=Chiabaut%2C+N">Nicolas Chiabaut</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Cyclists prefer to use infrastructure that separates them from motorized
traffic. Using a traffic light to segregate car and bike flows, with the
addition of bike-specific green phases, is a lightweight and cheap solution
that can be deployed dynamically to assess the opportunity of a heavier
infrastructure such as a separate bike lane. To compensate for the increased
waiting time induced by these new phases, we introduce in this paper a deep
reinforcement learning solution that adapts the green phase cycle of a traffic
light to the traffic. Vehicle counter data are used to compare the DRL approach
with the actuated traffic light control algorithm over whole days. Results show
that DRL achieves better minimization of vehicle waiting time at almost all
hours. Our DRL approach is also robust to moderate changes in bike traffic. The
code of this paper is available at
https://github.com/LucasMagnana/A-DRL-solution-to-help-reduce-the-cost-in-waiting-time-of-securing-a-traffic-light-for-cyclists.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13909" title="Abstract">arXiv:2311.13909</a> [<a href="/pdf/2311.13909" title="Download PDF">pdf</a>, <a href="/format/2311.13909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Order Integration on regular triangulated manifolds reaches  Super-Algebraic Approximation Rates through Cubical Re-parameterizations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zavalani%2C+G">Gentian Zavalani</a>, 
<a href="/search/math?searchtype=author&query=Sander%2C+O">Oliver Sander</a>, 
<a href="/search/math?searchtype=author&query=Hecht%2C+M">Michael Hecht</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We present a novel methodology for deriving high-order quadrature rules
(HOSQ) designed for the integration of scalar functions over regular embedded
manifolds. To construct the rules, we introduce square-squeezing--a
homeomorphic multilinear hypercube-simplex transformation--reparametrizing an
initial flat triangulation of the manifold to a hypercube mesh. By employing
square-squeezing, we approximate the integrand and the volume element for each
hypercube domain of the reparameterized mesh through interpolation in
Chebyshev-Lobatto grids. This strategy circumvents the Runge phenomenon,
replacing the initial integral with a closed-form expression that can be
precisely computed by high-order quadratures. We prove novel bounds of the
integration error in terms of the $r^\text{th}$-order total variation of the
integrand and the surface parameterization, predicting high algebraic
approximation rates that scale solely with the interpolation degree and not, as
is common, with the average simplex size. For smooth integrals whose total
variation is constantly bounded with increasing $r$, the estimates prove the
integration error to decrease even exponentially, while mesh refinements are
limited to achieve algebraic rates. The resulting approximation power is
demonstrated in several numerical experiments, particularly showcasing
$p$-refinements to overcome the limitations of $h$-refinements for highly
varying smooth integrals.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13910" title="Abstract">arXiv:2311.13910</a> [<a href="/pdf/2311.13910" title="Download PDF">pdf</a>, <a href="/format/2311.13910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dialogue Quality and Emotion Annotations for Customer Support  Conversations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mendon%C3%A7a%2C+J">John Mendon&#xe7;a</a>, 
<a href="/search/cs?searchtype=author&query=Pereira%2C+P">Patr&#xed;cia Pereira</a>, 
<a href="/search/cs?searchtype=author&query=Menezes%2C+M">Miguel Menezes</a>, 
<a href="/search/cs?searchtype=author&query=Cabarr%C3%A3o%2C+V">Vera Cabarr&#xe3;o</a>, 
<a href="/search/cs?searchtype=author&query=Farinha%2C+A+C">Ana C. Farinha</a>, 
<a href="/search/cs?searchtype=author&query=Moniz%2C+H">Helena Moniz</a>, 
<a href="/search/cs?searchtype=author&query=Carvalho%2C+J+P">Jo&#xe3;o Paulo Carvalho</a>, 
<a href="/search/cs?searchtype=author&query=Lavie%2C+A">Alon Lavie</a>, 
<a href="/search/cs?searchtype=author&query=Trancoso%2C+I">Isabel Trancoso</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at GEM (EMNLP Workshop)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Task-oriented conversational datasets often lack topic variability and
linguistic diversity. However, with the advent of Large Language Models (LLMs)
pretrained on extensive, multilingual and diverse text data, these limitations
seem overcome. Nevertheless, their generalisability to different languages and
domains in dialogue applications remains uncertain without benchmarking
datasets. This paper presents a holistic annotation approach for emotion and
conversational quality in the context of bilingual customer support
conversations. By performing annotations that take into consideration the
complete instances that compose a conversation, one can form a broader
perspective of the dialogue as a whole. Furthermore, it provides a unique and
valuable resource for the development of text classification models. To this
end, we present benchmarks for Emotion Recognition and Dialogue Quality
Estimation and show that further research is needed to leverage these models in
a production setting.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13914" title="Abstract">arXiv:2311.13914</a> [<a href="/pdf/2311.13914" title="Download PDF">pdf</a>, <a href="/format/2311.13914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A comparison of Algebraic Multigrid Bidomain solvers on hybrid CPU-GPU  architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Centofanti%2C+E">Edoardo Centofanti</a>, 
<a href="/search/math?searchtype=author&query=Scacchi%2C+S">Simone Scacchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The numerical simulation of cardiac electrophysiology is a highly challenging
problem in scientific computing. The Bidomain system is the most complete
mathematical model of cardiac bioelectrical activity. It consists of an
elliptic and a parabolic partial differential equation (PDE), of
reaction-diffusion type, describing the spread of electrical excitation in the
cardiac tissue. The two PDEs are coupled with a stiff system of ordinary
differential equations (ODEs), representing ionic currents through the cardiac
membrane. Developing efficient and scalable preconditioners for the linear
systems arising from the discretization of such computationally challenging
model is crucial in order to reduce the computational costs required by the
numerical simulations of cardiac electrophysiology. In this work, focusing on
the Bidomain system as a model problem, we have benchmarked two popular
implementations of the Algebraic Multigrid (AMG) preconditioner embedded in the
PETSc library and we have studied the performance on the calibration of
specific parameters. We have conducted our analysis on modern HPC
architectures, performing scalability tests on multi-core and multi-GPUs
setttings. The results have shown that, for our problem, although scalability
is verified on CPUs, GPUs are the optimal choice, since they yield the best
performance in terms of solution time.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13921" title="Abstract">arXiv:2311.13921</a> [<a href="/pdf/2311.13921" title="Download PDF">pdf</a>, <a href="/format/2311.13921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Some Like It Small: Czech Semantic Embedding Models for Industry  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bedn%C3%A1%C5%99%2C+J">Ji&#x159;&#xed; Bedn&#xe1;&#x159;</a>, 
<a href="/search/cs?searchtype=author&query=N%C3%A1plava%2C+J">Jakub N&#xe1;plava</a>, 
<a href="/search/cs?searchtype=author&query=Baran%C4%8D%C3%ADkov%C3%A1%2C+P">Petra Baran&#x10d;&#xed;kov&#xe1;</a>, 
<a href="/search/cs?searchtype=author&query=Lisick%C3%BD%2C+O">Ond&#x159;ej Lisick&#xfd;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the Thirty-Sixth Annual Conference on Innovative Applications of Artificial Intelligence (IAAI-24). IAAI Innovative Application Award. 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">This article focuses on the development and evaluation of Small-sized Czech
sentence embedding models. Small models are important components for real-time
industry applications in resource-constrained environments. Given the limited
availability of labeled Czech data, alternative approaches, including
pre-training, knowledge distillation, and unsupervised contrastive fine-tuning,
are investigated. Comprehensive intrinsic and extrinsic analyses are conducted,
showcasing the competitive performance of our models compared to significantly
larger counterparts, with approximately 8 times smaller size and 5 times faster
speed than conventional Base-sized models. To promote cooperation and
reproducibility, both the models and the evaluation pipeline are made publicly
accessible. Ultimately, this article presents practical applications of the
developed sentence embedding models in Seznam.cz, the Czech search engine.
These models have effectively replaced previous counterparts, enhancing the
overall search experience for instance, in organic search, featured snippets,
and image search. This transition has yielded improved performance.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13927" title="Abstract">arXiv:2311.13927</a> [<a href="/pdf/2311.13927" title="Download PDF">pdf</a>, <a href="/ps/2311.13927" title="Download PostScript">ps</a>, <a href="/format/2311.13927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integration demand response aggregator and wind power aggregators with  generation units and energy storages in wholesale electricity markets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Nourollahi%2C+R">Ramin Nourollahi</a>, 
<a href="/search/eess?searchtype=author&query=Esmaeilzadeh%2C+R">Rasoul Esmaeilzadeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The integration of various energy resources with wind farms, results in
improved market-aware management of wind generation variations. Consequently,
the proposed method minimizes the negative impact associated with wind
generation deviations on the electricity market and energy systems. This paper
integrates the multiple energy resources of a smart grid with wind producers to
form a virtual power plant (VRP). One of the primary issues of integrating
electricity markets in multi-electricity markets such as the Day-Ahead (DHM),
intraday (INT), and real-time market (RLT) is the participation of a VRP. The
proposed VRP was formed by the integration of the on-site generation (ONG),
energy storage system (ENS), wind power aggregator (WPG), and demand response
(DRE) contracts. Furthermore, The DRE includes detailed contracts with
shiftable loads and load curtailment load aggregators. An effective method to
manage the uncertainty of a VRP in order to attain optimal strategy and
offering is provided in this article. The p-robust method is the proposed
solution to measure the regret of VRP in the offering strategys formation. In
the modeled scenario-based program, the p-robust approach is used for
controlling the relative regret of a VRP in a multi-market operation under
uncertainty. The obtained results demonstrate that a 6.81% reduction in
estimated profit can result in a 45.75% reduction in relative regret of VRP.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13928" title="Abstract">arXiv:2311.13928</a> [<a href="/pdf/2311.13928" title="Download PDF">pdf</a>, <a href="/format/2311.13928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameter Exchange for Robust Dynamic Domain Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Luojun Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zhifeng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhishu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yuanlong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weijie Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM MM 2023. Source code: <a href="https://github.com/MetaVisionLab/PE">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Agnostic domain shift is the main reason of model degradation on the unknown
target domains, which brings an urgent need to develop Domain Generalization
(DG). Recent advances at DG use dynamic networks to achieve training-free
adaptation on the unknown target domains, termed Dynamic Domain Generalization
(DDG), which compensates for the lack of self-adaptability in static models
with fixed weights. The parameters of dynamic networks can be decoupled into a
static and a dynamic component, which are designed to learn domain-invariant
and domain-specific features, respectively. Based on the existing arts, in this
work, we try to push the limits of DDG by disentangling the static and dynamic
components more thoroughly from an optimization perspective. Our main
consideration is that we can enable the static component to learn
domain-invariant features more comprehensively by augmenting the
domain-specific information. As a result, the more comprehensive
domain-invariant features learned by the static component can then enforce the
dynamic component to focus more on learning adaptive domain-specific features.
To this end, we propose a simple yet effective Parameter Exchange (PE) method
to perturb the combination between the static and dynamic components. We
optimize the model using the gradients from both the perturbed and
non-perturbed feed-forward jointly to implicitly achieve the aforementioned
disentanglement. In this way, the two components can be optimized in a
mutually-beneficial manner, which can resist the agnostic domain shifts and
improve the self-adaptability on the unknown target domain. Extensive
experiments show that PE can be easily plugged into existing dynamic networks
to improve their generalization ability without bells and whistles.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13929" title="Abstract">arXiv:2311.13929</a> [<a href="/pdf/2311.13929" title="Download PDF">pdf</a>, <a href="/format/2311.13929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MetaFBP: Learning to Learn High-Order Predictor for Personalized Facial  Beauty Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Luojun Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zhifeng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Jia-Li Yin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qipeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yuanlong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weijie Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM MM 2023. Source code: <a href="https://github.com/MetaVisionLab/MetaFBP">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Predicting individual aesthetic preferences holds significant practical
applications and academic implications for human society. However, existing
studies mainly focus on learning and predicting the commonality of facial
attractiveness, with little attention given to Personalized Facial Beauty
Prediction (PFBP). PFBP aims to develop a machine that can adapt to individual
aesthetic preferences with only a few images rated by each user. In this paper,
we formulate this task from a meta-learning perspective that each user
corresponds to a meta-task. To address such PFBP task, we draw inspiration from
the human aesthetic mechanism that visual aesthetics in society follows a
Gaussian distribution, which motivates us to disentangle user preferences into
a commonality and an individuality part. To this end, we propose a novel
MetaFBP framework, in which we devise a universal feature extractor to capture
the aesthetic commonality and then optimize to adapt the aesthetic
individuality by shifting the decision boundary of the predictor via a
meta-learning mechanism. Unlike conventional meta-learning methods that may
struggle with slow adaptation or overfitting to tiny support sets, we propose a
novel approach that optimizes a high-order predictor for fast adaptation. In
order to validate the performance of the proposed method, we build several PFBP
benchmarks by using existing facial beauty prediction datasets rated by
numerous users. Extensive experiments on these benchmarks demonstrate the
effectiveness of the proposed MetaFBP method.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13930" title="Abstract">arXiv:2311.13930</a> [<a href="/pdf/2311.13930" title="Download PDF">pdf</a>, <a href="/format/2311.13930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Periodically Exchange Teacher-Student for Source-Free Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qipeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Luojun Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zhifeng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhifeng Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Source-free object detection (SFOD) aims to adapt the source detector to
unlabeled target domain data in the absence of source domain data. Most SFOD
methods follow the same self-training paradigm using mean-teacher (MT)
framework where the student model is guided by only one single teacher model.
However, such paradigm can easily fall into a training instability problem that
when the teacher model collapses uncontrollably due to the domain shift, the
student model also suffers drastic performance degradation. To address this
issue, we propose the Periodically Exchange Teacher-Student (PETS) method, a
simple yet novel approach that introduces a multiple-teacher framework
consisting of a static teacher, a dynamic teacher, and a student model. During
the training phase, we periodically exchange the weights between the static
teacher and the student model. Then, we update the dynamic teacher using the
moving average of the student model that has already been exchanged by the
static teacher. In this way, the dynamic teacher can integrate knowledge from
past periods, effectively reducing error accumulation and enabling a more
stable training process within the MT-based framework. Further, we develop a
consensus mechanism to merge the predictions of two teacher models to provide
higher-quality pseudo labels for student model. Extensive experiments on
multiple SFOD benchmarks show that the proposed method achieves
state-of-the-art performance compared with other related methods, demonstrating
the effectiveness and superiority of our method on SFOD task.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13934" title="Abstract">arXiv:2311.13934</a> [<a href="/pdf/2311.13934" title="Download PDF">pdf</a>, <a href="/format/2311.13934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robustness-Reinforced Knowledge Distillation with Correlation Distance  and Network Pruning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seonghak Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ham%2C+G">Gyeongdo Ham</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+Y">Yucheol Cho</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Daeshik Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The improvement in the performance of efficient and lightweight models (i.e.,
the student model) is achieved through knowledge distillation (KD), which
involves transferring knowledge from more complex models (i.e., the teacher
model). However, most existing KD techniques rely on Kullback-Leibler (KL)
divergence, which has certain limitations. First, if the teacher distribution
has high entropy, the KL divergence's mode-averaging nature hinders the
transfer of sufficient target information. Second, when the teacher
distribution has low entropy, the KL divergence tends to excessively focus on
specific modes, which fails to convey an abundant amount of valuable knowledge
to the student. Consequently, when dealing with datasets that contain numerous
confounding or challenging samples, student models may struggle to acquire
sufficient knowledge, resulting in subpar performance. Furthermore, in previous
KD approaches, we observed that data augmentation, a technique aimed at
enhancing a model's generalization, can have an adverse impact. Therefore, we
propose a Robustness-Reinforced Knowledge Distillation (R2KD) that leverages
correlation distance and network pruning. This approach enables KD to
effectively incorporate data augmentation for performance improvement.
Extensive experiments on various datasets, including CIFAR-100, FGVR,
TinyImagenet, and ImageNet, demonstrate our method's superiority over current
state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13936" title="Abstract">arXiv:2311.13936</a> [<a href="/pdf/2311.13936" title="Download PDF">pdf</a>, <a href="/ps/2311.13936" title="Download PostScript">ps</a>, <a href="/format/2311.13936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Process-Commutative Distributed Objects: From Cryptocurrencies to  Byzantine-Fault-Tolerant CRDTs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Frey%2C+D">Davide Frey</a>, 
<a href="/search/cs?searchtype=author&query=Guillou%2C+L">Lucie Guillou</a>, 
<a href="/search/cs?searchtype=author&query=Raynal%2C+M">Michel Raynal</a>, 
<a href="/search/cs?searchtype=author&query=Ta%C3%AFani%2C+F">Fran&#xe7;ois Ta&#xef;ani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A preliminary version of this work appeared at the 2021 International Conference on Parallel Computing Technologies (PaCT 2021)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">This paper explores the territory that lies between best-effort
Byzantine-Fault-Tolerant Conflict-free Replicated Data Types (BFT CRDTs) and
totally ordered distributed ledgers. It formally characterizes a novel class of
distributed objects that only requires a First In First Out (FIFO) order on the
object operations from each process (taken individually). The formalization
relies on Mazurkiewicz traces to define legal sequences of operations and
ensure a combination of Strong Eventual Consistency (SEC) and Pipleline
Consistency (PC). The paper presents a generic algorithm that implements this
novel class of distributed objects in both crash- and Byzantine setting.
Finally, the proposed approach is illustrated with four instances of this class
of objects, namely money transfer, Petri nets, multi-sets, and concurrent work
stealing dequeues.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13937" title="Abstract">arXiv:2311.13937</a> [<a href="/pdf/2311.13937" title="Download PDF">pdf</a>, <a href="/format/2311.13937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Methods for Cross-lingual Text Style Transfer: The Case of  Text Detoxification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dementieva%2C+D">Daryna Dementieva</a>, 
<a href="/search/cs?searchtype=author&query=Moskovskiy%2C+D">Daniil Moskovskiy</a>, 
<a href="/search/cs?searchtype=author&query=Dale%2C+D">David Dale</a>, 
<a href="/search/cs?searchtype=author&query=Panchenko%2C+A">Alexander Panchenko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AACL 2023, main conference, long paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Text detoxification is the task of transferring the style of text from toxic
to neutral. While here are approaches yielding promising results in monolingual
setup, e.g., (Dale et al., 2021; Hallinan et al., 2022), cross-lingual transfer
for this task remains a challenging open problem (Moskovskiy et al., 2022). In
this work, we present a large-scale study of strategies for cross-lingual text
detoxification -- given a parallel detoxification corpus for one language; the
goal is to transfer detoxification ability to another language for which we do
not have such a corpus. Moreover, we are the first to explore a new task where
text translation and detoxification are performed simultaneously, providing
several strong baselines for this task. Finally, we introduce new automatic
detoxification evaluation metrics with higher correlations with human judgments
than previous benchmarks. We assess the most promising approaches also with
manual markup, determining the answer for the best strategy to transfer the
knowledge of text detoxification between languages.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13939" title="Abstract">arXiv:2311.13939</a> [<a href="/pdf/2311.13939" title="Download PDF">pdf</a>, <a href="/format/2311.13939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 5G Edge Vision: Wearable Assistive Technology for People with Blindness  and Low Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Azzino%2C+T">Tommy Azzino</a>, 
<a href="/search/eess?searchtype=author&query=Mezzavilla%2C+M">Marco Mezzavilla</a>, 
<a href="/search/eess?searchtype=author&query=Rangan%2C+S">Sundeep Rangan</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Rizzo%2C+J">John-Ross Rizzo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures, 2 tables, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In an increasingly visual world, people with blindness and low vision (pBLV)
face substantial challenges in navigating their surroundings and interpreting
visual information. From our previous work, VIS4ION is a smart wearable that
helps pBLV in their day-to-day challenges. It enables multiple artificial
intelligence (AI)-based microservices such as visual scene processing,
navigation, and vision-language inference. These microservices require powerful
computational resources and, in some cases, stringent inference times, hence
the need to offload computation to edge servers. This paper introduces a novel
video streaming platform that improves the capabilities of VIS4ION by providing
real-time support of the microservices at the network edge. When video is
offloaded wirelessly to the edge, the time-varying nature of the wireless
network requires the use of adaptation strategies for a seamless video service.
We demonstrate the performance of an adaptive real-time video streaming
platform through experimentation with an open-source 5G deployment based on
open air interface (OAI). The experiments demonstrate the ability to provide
the microservices robustly in time-varying network loads.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13946" title="Abstract">arXiv:2311.13946</a> [<a href="/pdf/2311.13946" title="Download PDF">pdf</a>, <a href="/format/2311.13946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly-Supervised Video Moment Retrieval via Regularized Two-Branch  Proposal Networks with Erasing Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhou Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhijie Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
<p class="mathjax">Video moment retrieval is to identify the target moment according to the
given sentence in an untrimmed video. Due to temporal boundary annotations of
the video are extremely time-consuming to acquire, modeling in the
weakly-supervised setting is increasingly focused, where we only have access to
the video-sentence pairs during training. Most existing weakly-supervised
methods adopt a MIL-based framework to develop inter-sample confrontment, but
neglect the intra-sample confrontment between moments with similar semantics.
Therefore, these methods fail to distinguish the correct moment from plausible
negative moments. Further, the previous attention models in cross-modal
interaction tend to focus on a few dominant words exorbitantly, ignoring the
comprehensive video-sentence correspondence. In this paper, we propose a novel
Regularized Two-Branch Proposal Network with Erasing Mechanism to consider the
inter-sample and intra-sample confrontments simultaneously. Concretely, we
first devise a language-aware visual filter to generate both enhanced and
suppressed video streams. Then, we design the sharable two-branch proposal
module to generate positive and plausible negative proposals from the enhanced
and suppressed branch respectively, contributing to sufficient confrontment.
Besides, we introduce an attention-guided dynamic erasing mechanism in enhanced
branch to discover the complementary video-sentence relation. Moreover, we
apply two types of proposal regularization to stabilize the training process
and improve model performance. The extensive experiments on ActivityCaption,
Charades-STA and DiDeMo datasets show the effectiveness of our method.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13947" title="Abstract">arXiv:2311.13947</a> [<a href="/pdf/2311.13947" title="Download PDF">pdf</a>, <a href="/ps/2311.13947" title="Download PostScript">ps</a>, <a href="/format/2311.13947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Ratio Compression for Machine-Generated Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiujing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zhitao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shiyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+L">Lingkai Meng</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chuan Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+W">Wei Jia</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yue Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Qinhui Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenjie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xuemin Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Machine-generated data is rapidly growing and poses challenges for
data-intensive systems, especially as the growth of data outpaces the growth of
storage space. To cope with the storage issue, compression plays a critical
role in storage engines, particularly for data-intensive applications, where
high compression ratios and efficient random access are essential. However,
existing compression techniques tend to focus on general-purpose and data block
approaches, but overlook the inherent structure of machine-generated data and
hence result in low-compression ratios or limited lookup efficiency. To address
these limitations, we introduce the Pattern-Based Compression (PBC) algorithm,
which specifically targets patterns in machine-generated data to achieve
Pareto-optimality in most cases. Unlike traditional data block-based methods,
PBC compresses data on a per-record basis, facilitating rapid random access.
Our experimental evaluation demonstrates that PBC, on average, achieves a
compression ratio twice as high as state-of-the-art techniques while
maintaining competitive compression and decompression speeds.We also integrate
PBC to a production database system and achieve improvement on both comparison
ratio and throughput.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13949" title="Abstract">arXiv:2311.13949</a> [<a href="/pdf/2311.13949" title="Download PDF">pdf</a>, <a href="/format/2311.13949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Power Flow in Highly Renewable Power System Based on Attention  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chen Li</a>, 
<a href="/search/cs?searchtype=author&query=Kies%2C+A">Alexander Kies</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kai Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Schlott%2C+M">Markus Schlott</a>, 
<a href="/search/cs?searchtype=author&query=Sayed%2C+O+E">Omar El Sayed</a>, 
<a href="/search/cs?searchtype=author&query=Bilousova%2C+M">Mariia Bilousova</a>, 
<a href="/search/cs?searchtype=author&query=Stoecker%2C+H">Horst Stoecker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Elsevier
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The Optimal Power Flow (OPF) problem is pivotal for power system operations,
guiding generator output and power distribution to meet demand at minimized
costs, while adhering to physical and engineering constraints. The integration
of renewable energy sources, like wind and solar, however, poses challenges due
to their inherent variability. This variability, driven largely by changing
weather conditions, demands frequent recalibrations of power settings, thus
necessitating recurrent OPF resolutions. This task is daunting using
traditional numerical methods, particularly for extensive power systems. In
this work, we present a cutting-edge, physics-informed machine learning
methodology, trained using imitation learning and historical European weather
datasets. Our approach directly correlates electricity demand and weather
patterns with power dispatch and generation, circumventing the iterative
requirements of traditional OPF solvers. This offers a more expedient solution
apt for real-time applications. Rigorous evaluations on aggregated European
power systems validate our method's superiority over existing data-driven
techniques in OPF solving. By presenting a quick, robust, and efficient
solution, this research sets a new standard in real-time OPF resolution, paving
the way for more resilient power systems in the era of renewable energy.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13950" title="Abstract">arXiv:2311.13950</a> [<a href="/pdf/2311.13950" title="Download PDF">pdf</a>, <a href="/format/2311.13950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Object Location Prediction in Real-time using LSTM Neural Network and  Polynomial Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stojkovi%C4%87%2C+P">Petar Stojkovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Tadi%C4%87%2C+P">Predrag Tadi&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">This paper details the design and implementation of a system for predicting
and interpolating object location coordinates. Our solution is based on
processing inertial measurements and global positioning system data through a
Long Short-Term Memory (LSTM) neural network and polynomial regression. LSTM is
a type of recurrent neural network (RNN) particularly suited for processing
data sequences and avoiding the long-term dependency problem. We employed data
from real-world vehicles and the global positioning system (GPS) sensors. A
critical pre-processing step was developed to address varying sensor
frequencies and inconsistent GPS time steps and dropouts. The LSTM-based
system's performance was compared with the Kalman Filter. The system was tuned
to work in real-time with low latency and high precision. We tested our system
on roads under various driving conditions, including acceleration, turns,
deceleration, and straight paths. We tested our proposed solution's accuracy
and inference time and showed that it could perform in real-time. Our
LSTM-based system yielded an average error of 0.11 meters with an inference
time of 2 ms. This represents a 76\% reduction in error compared to the
traditional Kalman filter method, which has an average error of 0.46 meters
with a similar inference time to the LSTM-based system.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13951" title="Abstract">arXiv:2311.13951</a> [<a href="/pdf/2311.13951" title="Download PDF">pdf</a>, <a href="/format/2311.13951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MLLM-Bench, Evaluating Multi-modal LLMs using GPT-4V
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ge%2C+W">Wentao Ge</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shunian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guiming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junying Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhihong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Shuo Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chenghao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Ziyue Lin</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Wenya Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xidong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+A">Anningzhe Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianquan Li</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+X">Xiang Wan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Benyou Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In the pursuit of Artificial General Intelligence (AGI), the integration of
vision in language models has marked a significant milestone. The advent of
vision-language models (MLLMs) like GPT-4V have expanded AI applications,
aligning with the multi-modal capabilities of the human brain. However,
evaluating the efficacy of MLLMs poses a substantial challenge due to the
subjective nature of tasks that lack definitive answers. Existing automatic
evaluation methodologies on multi-modal large language models rely on objective
queries that have standard answers, inadequately addressing the nuances of
creative and associative multi-modal tasks. To address this, we introduce
MLLM-Bench, an innovative benchmark inspired by Vicuna, spanning a diverse
array of scenarios, including Perception, Understanding, Applying, Analyzing,
Evaluating, and Creation along with the ethical consideration. MLLM-Bench is
designed to reflect user experience more accurately and provide a more holistic
assessment of model performance. Comparative evaluations indicate a significant
performance gap between existing open-source models and GPT-4V. We posit that
MLLM-Bench will catalyze progress in the open-source community towards
developing user-centric vision-language models that meet a broad spectrum of
real-world applications. See online leaderboard in
\url{https://mllm-bench.llmzoo.com}.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13953" title="Abstract">arXiv:2311.13953</a> [<a href="/pdf/2311.13953" title="Download PDF">pdf</a>, <a href="/format/2311.13953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Uniform Clusters on Hypersphere for Deep Graph-level Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+M">Mengling Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chaochao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weiming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+X">Xinting Liao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiaolin Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Graph clustering has been popularly studied in recent years. However, most
existing graph clustering methods focus on node-level clustering, i.e.,
grouping nodes in a single graph into clusters. In contrast, graph-level
clustering, i.e., grouping multiple graphs into clusters, remains largely
unexplored. Graph-level clustering is critical in a variety of real-world
applications, such as, properties prediction of molecules and community
analysis in social networks. However, graph-level clustering is challenging due
to the insufficient discriminability of graph-level representations, and the
insufficient discriminability makes deep clustering be more likely to obtain
degenerate solutions (cluster collapse). To address the issue, we propose a
novel deep graph-level clustering method called Uniform Deep Graph Clustering
(UDGC). UDGC assigns instances evenly to different clusters and then scatters
those clusters on unit hypersphere, leading to a more uniform cluster-level
distribution and a slighter cluster collapse. Specifically, we first propose
Augmentation-Consensus Optimal Transport (ACOT) for generating uniformly
distributed and reliable pseudo labels for partitioning clusters. Then we adopt
contrastive learning to scatter those clusters. Besides, we propose Center
Alignment Optimal Transport (CAOT) for guiding the model to learn better
parameters, which further promotes the cluster performance. Our empirical study
on eight well-known datasets demonstrates that UDGC significantly outperforms
the state-of-the-art models.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13954" title="Abstract">arXiv:2311.13954</a> [<a href="/pdf/2311.13954" title="Download PDF">pdf</a>, <a href="/format/2311.13954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Electric Network Frequency Optical Sensing Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moysiadis%2C+C">Christos Moysiadis</a>, 
<a href="/search/cs?searchtype=author&query=Karantaidis%2C+G">Georgios Karantaidis</a>, 
<a href="/search/cs?searchtype=author&query=Kotropoulos%2C+C">Constantine Kotropoulos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Electric Network Frequency (ENF) acts as a fingerprint in multimedia
forensics applications. In indoor environments, ENF variations affect the
intensity of light sources connected to power mains. Accordingly, the light
intensity variations captured by sensing devices can be exploited to estimate
the ENF. A first optical sensing device based on a photodiode is developed for
capturing ENF variations in indoor lighting environments. In addition, a device
that captures the ENF directly from power mains is implemented. This device
serves as a ground truth ENF collector. Video recordings captured by a camera
are also employed to estimate the ENF. The camera serves as a second optical
sensor. The factors affecting the ENF estimation are thoroughly studied. The
maximum correlation coefficient between the ENF estimated by the two optical
sensors and that estimated directly from power mains is used to measure the
estimation accuracy. The paper's major contribution is in the disclosure of
extensive experimental evidence on ENF estimation in scenes ranging from static
ones capturing a white wall to non-static ones, including human activity.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13957" title="Abstract">arXiv:2311.13957</a> [<a href="/pdf/2311.13957" title="Download PDF">pdf</a>, <a href="/format/2311.13957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Trigger Word Insertion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yueqi Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziqiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+P">Pengfei Xia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bin Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">With the boom in the natural language processing (NLP) field these years,
backdoor attacks pose immense threats against deep neural network models.
However, previous works hardly consider the effect of the poisoning rate. In
this paper, our main objective is to reduce the number of poisoned samples
while still achieving a satisfactory Attack Success Rate (ASR) in text backdoor
attacks. To accomplish this, we propose an efficient trigger word insertion
strategy in terms of trigger word optimization and poisoned sample selection.
Extensive experiments on different datasets and models demonstrate that our
proposed method can significantly improve attack effectiveness in text
classification tasks. Remarkably, our approach achieves an ASR of over 90% with
only 10 poisoned samples in the dirty-label setting and requires merely 1.5% of
the training data in the clean-label setting.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13959" title="Abstract">arXiv:2311.13959</a> [<a href="/pdf/2311.13959" title="Download PDF">pdf</a>, <a href="/format/2311.13959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RankFeat\&amp;RankWeight: Rank-1 Feature/Weight Removal for  Out-of-distribution Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yue Song</a>, 
<a href="/search/cs?searchtype=author&query=Sebe%2C+N">Nicu Sebe</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to T-PAMI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The task of out-of-distribution (OOD) detection is crucial for deploying
machine learning models in real-world settings. In this paper, we observe that
the singular value distributions of the in-distribution (ID) and OOD features
are quite different: the OOD feature matrix tends to have a larger dominant
singular value than the ID feature, and the class predictions of OOD samples
are largely determined by it. This observation motivates us to propose
\texttt{RankFeat}, a simple yet effective \emph{post hoc} approach for OOD
detection by removing the rank-1 matrix composed of the largest singular value
and the associated singular vectors from the high-level feature.
\texttt{RankFeat} achieves \emph{state-of-the-art} performance and reduces the
average false positive rate (FPR95) by 17.90\% compared with the previous best
method. The success of \texttt{RankFeat} motivates us to investigate whether a
similar phenomenon would exist in the parameter matrices of neural networks. We
thus propose \texttt{RankWeight} which removes the rank-1 weight from the
parameter matrices of a single deep layer. Our \texttt{RankWeight}is also
\emph{post hoc} and only requires computing the rank-1 matrix once. As a
standalone approach, \texttt{RankWeight} has very competitive performance
against other methods across various backbones. Moreover, \texttt{RankWeight}
enjoys flexible compatibility with a wide range of OOD detection methods. The
combination of \texttt{RankWeight} and \texttt{RankFeat} refreshes the new
\emph{state-of-the-art} performance, achieving the FPR95 as low as 16.13\% on
the ImageNet-1k benchmark. Extensive ablation studies and comprehensive
theoretical analyses are presented to support the empirical results.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13960" title="Abstract">arXiv:2311.13960</a> [<a href="/pdf/2311.13960" title="Download PDF">pdf</a>, <a href="/ps/2311.13960" title="Download PostScript">ps</a>, <a href="/format/2311.13960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human Machine Co-Creation. A Complementary Cognitive Approach to  Creative Character Design Process Using GANs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lataifeh%2C+M">Mohammad Lataifeh</a>, 
<a href="/search/cs?searchtype=author&query=Carrascoa%2C+X+A">Xavier A Carrascoa</a>, 
<a href="/search/cs?searchtype=author&query=Elnagara%2C+A+M">Ashraf M Elnagara</a>, 
<a href="/search/cs?searchtype=author&query=Ahmeda%2C+N">Naveed Ahmeda</a>, 
<a href="/search/cs?searchtype=author&query=Junejo%2C+I">Imran Junejo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Recent advances in Generative Adversarial Networks GANs applications continue
to attract the attention of researchers in different fields. In such a
framework, two neural networks compete adversely to generate new visual
contents indistinguishable from the original dataset. The objective of this
research is to create a complementary codesign process between humans and
machines to augment character designers abilities in visualizing and creating
new characters for multimedia projects such as games and animation. Driven by
design cognitive scaffolding, the proposed approach aims to inform the process
of perceiving, knowing, and making. The machine generated concepts are used as
a launching platform for character designers to conceptualize new characters. A
labelled dataset of 22,000 characters was developed for this work and deployed
using different GANs to evaluate the most suited for the context, followed by
mixed methods evaluation for the machine output and human derivations. The
discussed results substantiate the value of the proposed cocreation framework
and elucidate how the generated concepts are used as cognitive substances that
interact with designers competencies in a versatile manner to influence the
creative processes of conceptualizing novel characters.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13967" title="Abstract">arXiv:2311.13967</a> [<a href="/pdf/2311.13967" title="Download PDF">pdf</a>, <a href="/format/2311.13967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unconstrained learning of networked nonlinear systems via free  parametrization of stable interconnected operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Massai%2C+L">Leonardo Massai</a>, 
<a href="/search/eess?searchtype=author&query=Saccani%2C+D">Danilo Saccani</a>, 
<a href="/search/eess?searchtype=author&query=Furieri%2C+L">Luca Furieri</a>, 
<a href="/search/eess?searchtype=author&query=Ferrari-Trecate%2C+G">Giancarlo Ferrari-Trecate</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper characterizes a new parametrization of nonlinear networked
incrementally $L_2$-bounded operators in discrete time. The distinctive novelty
is that our parametrization is \emph{free} -- that is, a sparse large-scale
operator with bounded incremental $L_2$ gain is obtained for any choice of the
real values of our parameters. This property allows one to freely search over
optimal parameters via unconstrained gradient descent, enabling direct
applications in large-scale optimal control and system identification. Further,
we can embed prior knowledge about the interconnection topology and stability
properties of the system directly into the large-scale distributed operator we
design. Our approach is extremely general in that it can seamlessly encapsulate
and interconnect state-of-the-art Neural Network (NN) parametrizations of
stable dynamical systems. To demonstrate the effectiveness of this approach, we
provide a simulation example showcasing the identification of a networked
nonlinear system. The results underscore the superiority of our free
parametrizations over standard NN-based identification methods where a prior
over the system topology and local stability properties are not enforced.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13973" title="Abstract">arXiv:2311.13973</a> [<a href="/pdf/2311.13973" title="Download PDF">pdf</a>, <a href="/format/2311.13973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Facilitating Human-Robot Collaboration through Natural Vocal  Conversations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferrari%2C+D">Davide Ferrari</a>, 
<a href="/search/cs?searchtype=author&query=Alberi%2C+F">Filippo Alberi</a>, 
<a href="/search/cs?searchtype=author&query=Secchi%2C+C">Cristian Secchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IRIM 3D 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In the rapidly evolving landscape of human-robot collaboration, effective
communication between humans and robots is crucial for complex task execution.
Traditional request-response systems often lack naturalness and may hinder
efficiency. In this study, we propose a novel approach that employs human-like
conversational interactions for vocal communication between human operators and
robots. The framework emphasizes the establishment of a natural and interactive
dialogue, enabling human operators to engage in vocal conversations with
robots. Through a comparative experiment, we demonstrate the efficacy of our
approach in enhancing task performance and collaboration efficiency. The
robot's ability to engage in meaningful vocal conversations enables it to seek
clarification, provide status updates, and ask for assistance when required,
leading to improved coordination and a smoother workflow. The results indicate
that the adoption of human-like conversational interactions positively
influences the human-robot collaborative dynamic. Human operators find it
easier to convey complex instructions and preferences, fostering a more
productive and satisfying collaboration experience.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13975" title="Abstract">arXiv:2311.13975</a> [<a href="/pdf/2311.13975" title="Download PDF">pdf</a>, <a href="/format/2311.13975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Scale Bridging Parametrizations with Metrics: Dispersive  Transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Coltman%2C+E">Edward Coltman</a>, 
<a href="/search/math?searchtype=author&query=Schneider%2C+M">Martin Schneider</a>, 
<a href="/search/math?searchtype=author&query=Helmig%2C+R">Rainer Helmig</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">In this work, the development of a framework for the multi-scale data-driven
parametrization of averaged-scale models is outlined and applied to dispersive
transport. Dispersive transport is a common phenomena included in transport
models at the averaged scale, describing the velocity and geometry dependent
mixing seen at the pore scale. Optimal parameters for the development of
dispersion tensors can be extracted from pore-scale simulations in the form of
an averaged velocity and characteristic length scales. In this work, the
determination of these parameters is outlined and tested first on simple and
later on complex random pore geometries. These parametrizations are then used
to develop a data-driven model extracting optimal parameters from pore
geometries. In order to better understand the relationships between these
parameters and pore geometries, we introduce a series of metrics based on
interfacial geometry, volume ratios, and connectivity. These metrics are then
compared against the parametrizations, and used to develop a metrics based
data-driven model.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13976" title="Abstract">arXiv:2311.13976</a> [<a href="/pdf/2311.13976" title="Download PDF">pdf</a>, <a href="/format/2311.13976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low Latency Instance Segmentation by Continuous Clustering for Rotating  LiDAR Sensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reich%2C+A">Andreas Reich</a>, 
<a href="/search/cs?searchtype=author&query=Wuensche%2C+H">Hans-Joachim Wuensche</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accompanying Video: <a href="https://www.youtube.com/watch?v=DZKuAQBngNE">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Low-latency instance segmentation of LiDAR point clouds is crucial in
real-world applications because it serves as an initial and frequently-used
building block in a robot's perception pipeline, where every task adds further
delay. Particularly in dynamic environments, this total delay can result in
significant positional offsets of dynamic objects, as seen in highway
scenarios. To address this issue, we employ continuous clustering of obstacle
points in order to obtain an instance-segmented point cloud. Unlike most
existing approaches, which use a full revolution of the LiDAR sensor, we
process the data stream in a continuous and seamless fashion. More
specifically, each column of a range image is processed as soon it is
available. Obstacle points are clustered to existing instances in real-time and
it is checked at a high-frequency which instances are completed and are ready
to be published. An additional advantage is that no problematic discontinuities
between the points of the start and the end of a scan are observed. In this
work we describe the two-layered data structure and the corresponding algorithm
for continuous clustering, which is able to cluster the incoming data in real
time. We explain the importance of a large perceptive field of view.
Furthermore, we describe and evaluate important architectural design choices,
which could be relevant to design an architecture for deep learning based
low-latency instance segmentation. We are publishing the source code at
https://github.com/UniBwTAS/continuous_clustering.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13978" title="Abstract">arXiv:2311.13978</a> [<a href="/pdf/2311.13978" title="Download PDF">pdf</a>, <a href="/format/2311.13978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MedISure: Towards Assuring Machine Learning-based Medical Image  Classifiers using Mixup Boundary Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Byfield%2C+A">Adam Byfield</a>, 
<a href="/search/cs?searchtype=author&query=Poulett%2C+W">William Poulett</a>, 
<a href="/search/cs?searchtype=author&query=Wallace%2C+B">Ben Wallace</a>, 
<a href="/search/cs?searchtype=author&query=Jose%2C+A">Anusha Jose</a>, 
<a href="/search/cs?searchtype=author&query=Tyagi%2C+S">Shatakshi Tyagi</a>, 
<a href="/search/cs?searchtype=author&query=Shembekar%2C+S">Smita Shembekar</a>, 
<a href="/search/cs?searchtype=author&query=Qayyum%2C+A">Adnan Qayyum</a>, 
<a href="/search/cs?searchtype=author&query=Qadir%2C+J">Junaid Qadir</a>, 
<a href="/search/cs?searchtype=author&query=Bilal%2C+M">Muhammad Bilal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Machine learning (ML) models are becoming integral in healthcare
technologies, presenting a critical need for formal assurance to validate their
safety, fairness, robustness, and trustworthiness. These models are inherently
prone to errors, potentially posing serious risks to patient health and could
even cause irreparable harm. Traditional software assurance techniques rely on
fixed code and do not directly apply to ML models since these algorithms are
adaptable and learn from curated datasets through a training process. However,
adapting established principles, such as boundary testing using synthetic test
data can effectively bridge this gap. To this end, we present a novel technique
called Mix-Up Boundary Analysis (MUBA) that facilitates evaluating image
classifiers in terms of prediction fairness. We evaluated MUBA for two
important medical imaging tasks -- brain tumour classification and breast
cancer classification -- and achieved promising results. This research aims to
showcase the importance of adapting traditional assurance principles for
assessing ML models to enhance the safety and reliability of healthcare
technologies. To facilitate future research, we plan to publicly release our
code for MUBA.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13980" title="Abstract">arXiv:2311.13980</a> [<a href="/pdf/2311.13980" title="Download PDF">pdf</a>, <a href="/ps/2311.13980" title="Download PostScript">ps</a>, <a href="/format/2311.13980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Permutation-Representation Number of Bipartite Graphs using  Neighborhood Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mozhui%2C+K">Khyodeno Mozhui</a>, 
<a href="/search/cs?searchtype=author&query=Krishna%2C+K+V">K. V. Krishna</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">The problems of determining the permutation-representation number (prn) and
the representation number of bipartite graphs are open in the literature.
Moreover, the decision problem corresponding to the determination of the prn of
a bipartite graph is NP-complete. However, these numbers were established for
certain subclasses of bipartite graphs, e.g., for crown graphs. Further, it was
conjectured that the crown graphs have the highest representation number among
the bipartite graphs. In this work, first, we reconcile the relation between
the prn of a comparability graph and the dimension of its induced poset and
review the upper bounds on the prn of bipartite graphs. Then, we study the prn
of bipartite graphs using the notion called neighborhood graphs. This approach
substantiates the aforesaid conjecture and gives us theoretical evidence. In
this connection, we devise a polynomial-time procedure to construct a word that
represents a given bipartite graph permutationally. Accordingly, we provide a
better upper bound for the prn of bipartite graphs. Further, we construct a
class of bipartite graphs, viz., extended crown graphs, defined over posets and
investigate its prn using the neighborhood graphs.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13982" title="Abstract">arXiv:2311.13982</a> [<a href="/pdf/2311.13982" title="Download PDF">pdf</a>, <a href="/format/2311.13982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Tree-of-thought Reasoning for Answering  Knowledge-intensive Complex Questions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+S">Shulin Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiajie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jiaxin Shi</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+X">Xin Lv</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Z">Zijun Yao</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qi Tian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Juanzi Li</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+L">Lei Hou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) are capable of answering knowledge-intensive
complex questions with chain-of-thought (CoT) reasoning. However, they tend to
generate factually incorrect reasoning steps when the required knowledge is not
available or up-to-date in models' parameters. Recent works turn to retrieving
external knowledge to augment CoT reasoning. Despite being promising, these
chain-based methods suffer from: 1) Negative retrieval. Unnecessary or
incorrect retrieval may mislead the reasoning; 2) Limited sight. Lacking the
ability to look backward or forward, a local error in one step will propagate
along the chain.
<br />In this paper, we propose a novel approach: Probabilistic Tree-of-thought
Reasoning (ProbTree). First, LLMs translate a complex question into a query
tree, in which each non-root node denotes a sub-question of its parent node.
Then, probabilistic reasoning is conducted over the tree, by solving questions
from leaf to root considering the confidence of both question decomposing and
answering. During reasoning, for leaf nodes, LLMs choose a more confident
answer from Closed-book QA that employs parametric knowledge and Open-book QA
that employs retrieved external knowledge, thus eliminating the negative
retrieval problem. For non-leaf nodes, with the hierarchical structure, LLMs
have broader sights and are able to globally reason with the information from
child nodes, thus recovering from local errors. The experiments on three
Complex QA datasets under the open-domain setting show that our approach
outperforms SOTA methods significantly, demonstrating the effect of
probabilistic tree-of-thought reasoning.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13983" title="Abstract">arXiv:2311.13983</a> [<a href="/pdf/2311.13983" title="Download PDF">pdf</a>, <a href="/format/2311.13983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Dynamic Selection and Pricing of Out-of-Home Deliveries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akkerman%2C+F">Fabian Akkerman</a>, 
<a href="/search/cs?searchtype=author&query=Dieter%2C+P">Peter Dieter</a>, 
<a href="/search/cs?searchtype=author&query=Mes%2C+M">Martijn Mes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Home delivery failures, traffic congestion, and relatively large handling
times have a negative impact on the profitability of last-mile logistics. These
external factors contribute to up to $28\%$ of the overall costs and $25\%$ of
emissions for the home delivery supply chain. A potential solution, showing
annual growth rates up to $36\%$, is the delivery to parcel lockers or parcel
shops, denoted by out-of-home (OOH) delivery. In the academic literature,
models of customer behavior with respect to OOH delivery were so far limited to
deterministic settings, contrasting with the stochastic nature of actual
customer choices. We model the sequential decision-making problem of which OOH
location to offer against what incentive for each incoming customer, taking
into account future customer arrivals and choices. We propose Dynamic Selection
and Pricing of OOH (DSPO), an algorithmic pipeline that uses a novel
spatial-temporal state encoding as input to a convolutional neural network. We
demonstrate the performance of our method by benchmarking it against three
state-of-the-art approaches. Our extensive numerical study, guided by
real-world data, reveals that DSPO can save $20.8\%$ in costs compared to a
situation without OOH locations, $8.1\%$ compared to a static selection and
pricing policy, and $4.6\%$ compared to a state-of-the-art demand management
benchmark. We provide comprehensive insights into the complex interplay between
OOH delivery dynamics and customer behavior influenced by pricing strategies.
The implications of our findings suggest practitioners to adopt dynamic
selection and pricing policies as OOH delivery gains a larger market share.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13986" title="Abstract">arXiv:2311.13986</a> [<a href="/pdf/2311.13986" title="Download PDF">pdf</a>, <a href="/format/2311.13986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FViT-Grasp: Grasping Objects With Using Fast Vision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yenicesu%2C+A+S">Arda Sarp Yenicesu</a>, 
<a href="/search/cs?searchtype=author&query=Cicek%2C+B">Berk Cicek</a>, 
<a href="/search/cs?searchtype=author&query=Oguz%2C+O+S">Ozgur S.Oguz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This study addresses the challenge of manipulation, a prominent issue in
robotics. We have devised a novel methodology for swiftly and precisely
identifying the optimal grasp point for a robot to manipulate an object. Our
approach leverages a Fast Vision Transformer (FViT), a type of neural network
designed for processing visual data and predicting the most suitable grasp
location. Demonstrating state-of-the-art performance in terms of speed while
maintaining a high level of accuracy, our method holds promise for potential
deployment in real-time robotic grasping applications. We believe that this
study provides a baseline for future research in vision-based robotic grasp
applications. Its high speed and accuracy bring researchers closer to real-life
applications.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13988" title="Abstract">arXiv:2311.13988</a> [<a href="/pdf/2311.13988" title="Download PDF">pdf</a>, <a href="/format/2311.13988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Docking Multirotors in Close Proximity using Learnt Downwash Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shankar%2C+A">Ajay Shankar</a>, 
<a href="/search/cs?searchtype=author&query=Woo%2C+H">Heedo Woo</a>, 
<a href="/search/cs?searchtype=author&query=Prorok%2C+A">Amanda Prorok</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at International Symposium on Experimental Robotics (ISER) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">Unmodeled aerodynamic disturbances pose a key challenge for multirotor flight
when multiple vehicles are in close proximity to each other. However, certain
missions \textit{require} two multirotors to approach each other within 1-2
body-lengths of each other and hold formation -- we consider one such practical
instance: vertically docking two multirotors in the air. In this
leader-follower setting, the follower experiences significant downwash
interference from the leader in its final docking stages. To compensate for
this, we employ a learnt downwash model online within an optimal feedback
controller to accurately track a docking maneuver and then hold formation.
Through real-world flights with different maneuvers, we demonstrate that this
compensation is crucial for reducing the large vertical separation otherwise
required by conventional/naive approaches. Our evaluations show a tracking
error of less than 0.06m for the follower (a 3-4x reduction) when approaching
vertically within two body-lengths of the leader. Finally, we deploy the
complete system to effect a successful physical docking between two airborne
multirotors in a single smooth planned trajectory.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13989" title="Abstract">arXiv:2311.13989</a> [<a href="/pdf/2311.13989" title="Download PDF">pdf</a>, <a href="/ps/2311.13989" title="Download PostScript">ps</a>, <a href="/format/2311.13989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An optimal first-order Taylor-like formula with a minimized remainder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chaskalovic%2C+J">Jo&#xeb;l Chaskalovic</a>, 
<a href="/search/math?searchtype=author&query=Assous%2C+F">Franck Assous</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we derive an optimal first-order Taylor-like formula. In a
seminal paper [14], we introduced a new first-order Taylor-like formula that
yields a reduced remainder compared to the classical Taylor's formula. Here, we
relax the assumption of equally spaced points in our formula. Instead, we
consider a sequence of unknown points and a sequence of unknown weights. Then,
we solve an optimization problem to determine the best distribution of points
and weights that ensures that the remainder is as minimal as possible.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13993" title="Abstract">arXiv:2311.13993</a> [<a href="/pdf/2311.13993" title="Download PDF">pdf</a>, <a href="/format/2311.13993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EIGEN: Expert-Informed Joint Learning Aggregation for High-Fidelity  Information Extraction from Document Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Abhishek Singh</a>, 
<a href="/search/cs?searchtype=author&query=Subramanian%2C+V">Venkatapathy Subramanian</a>, 
<a href="/search/cs?searchtype=author&query=Maheshwari%2C+A">Ayush Maheshwari</a>, 
<a href="/search/cs?searchtype=author&query=Narayan%2C+P">Pradeep Narayan</a>, 
<a href="/search/cs?searchtype=author&query=Shetty%2C+D+P">Devi Prasad Shetty</a>, 
<a href="/search/cs?searchtype=author&query=Ramakrishnan%2C+G">Ganesh Ramakrishnan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings of ML for Health Conference, 2023 (co-located with Neurips)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Information Extraction (IE) from document images is challenging due to the
high variability of layout formats. Deep models such as LayoutLM and BROS have
been proposed to address this problem and have shown promising results.
However, they still require a large amount of field-level annotations for
training these models. Other approaches using rule-based methods have also been
proposed based on the understanding of the layout and semantics of a form such
as geometric position, or type of the fields, etc. In this work, we propose a
novel approach, EIGEN (Expert-Informed Joint Learning aGgrEatioN), which
combines rule-based methods with deep learning models using data programming
approaches to circumvent the requirement of annotation of large amounts of
training data. Specifically, EIGEN consolidates weak labels induced from
multiple heuristics through generative models and use them along with a small
number of annotated labels to jointly train a deep model. In our framework, we
propose the use of labeling functions that include incorporating contextual
information thus capturing the visual and language context of a word for
accurate categorization. We empirically show that our EIGEN framework can
significantly improve the performance of state-of-the-art deep models with the
availability of very few labeled data instances. The source code is available
at
https://github.com/ayushayush591/EIGEN-High-Fidelity-Extraction-Document-Images.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13994" title="Abstract">arXiv:2311.13994</a> [<a href="/pdf/2311.13994" title="Download PDF">pdf</a>, <a href="/format/2311.13994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Efficient Distributed Nash Equilibrium Seeking with Compressed and  Event-triggered Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+X">Xiaomeng Chen</a>, 
<a href="/search/eess?searchtype=author&query=Huo%2C+W">Wei Huo</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Y">Yuchi Wu</a>, 
<a href="/search/eess?searchtype=author&query=Dey%2C+S">Subhrakanti Dey</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+L">Ling Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Distributed Nash equilibrium (NE) seeking problems for networked games have
been widely investigated in recent years. Despite the increasing attention,
communication expenditure is becoming a major bottleneck for scaling up
distributed approaches within limited communication bandwidth between agents.
To reduce communication cost, an efficient distributed NE seeking (ETC-DNES)
algorithm is proposed to obtain an NE for games over directed graphs, where the
communication efficiency is improved by event-triggered exchanges of compressed
information among neighbors. ETC-DNES saves communication costs in both
transmitted bits and rounds of communication. Furthermore, our method only
requires the row-stochastic property of the adjacency graph, unlike previous
approaches that hinged on double-stochastic communication matrices. We provide
convergence guarantees for ETC-DNES on games with restricted strongly monotone
mappings, testifying that such a communication method is efficient without
sacrificing the accuracy of the algorithm. The algorithm and analysis are
extended to a compressed algorithm with stochastic event-triggered mechanism
(SETC-DNES). In SETC-DNES, we introduce a random variable in the triggering
condition to further enhance algorithm efficiency. We demonstrate that
SETC-DNES guarantees linear convergence to the optimal NE while achieving even
greater reductions in communication costs compared to ETC-DNES. Finally,
numerical simulations illustrate the effectiveness of the proposed algorithms.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13995" title="Abstract">arXiv:2311.13995</a> [<a href="/pdf/2311.13995" title="Download PDF">pdf</a>, <a href="/ps/2311.13995" title="Download PostScript">ps</a>, <a href="/format/2311.13995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explicit Refinement Types
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghalayini%2C+J+E">Jad Elkhaleq Ghalayini</a>, 
<a href="/search/cs?searchtype=author&query=Krishnaswami%2C+N">Neel Krishnaswami</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, published at ICFP 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the ACM on Programming Languages, 2023, Volume 7,
  Issue ICFP, Article Number 195, pages 187-214
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">We present {\lambda}ert, a type theory supporting refinement types with
explicit proofs. Instead of solving refinement constraints with an SMT solver
like DML and Liquid Haskell, our system requires and permits programmers to
embed proofs of properties within the program text, letting us support a rich
logic of properties including quantifiers and induction. We show that the type
system is sound by showing that every refined program erases to a simply-typed
program, and by means of a denotational semantics, we show that every erased
program has all of the properties demanded by its refined type. All of our
proofs are formalised in Lean 4.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13997" title="Abstract">arXiv:2311.13997</a> [<a href="/pdf/2311.13997" title="Download PDF">pdf</a>, <a href="/format/2311.13997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GRJointNET: Synergistic Completion and Part Segmentation on 3D  Incomplete Point Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gurses%2C+Y">Yigit Gurses</a>, 
<a href="/search/cs?searchtype=author&query=Taspinar%2C+M">Melisa Taspinar</a>, 
<a href="/search/cs?searchtype=author&query=Yurt%2C+M">Mahmut Yurt</a>, 
<a href="/search/cs?searchtype=author&query=Ozer%2C+S">Sedat Ozer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Segmentation of three-dimensional (3D) point clouds is an important task for
autonomous systems. However, success of segmentation algorithms depends greatly
on the quality of the underlying point clouds (resolution, completeness etc.).
In particular, incomplete point clouds might reduce a downstream model's
performance. GRNet is proposed as a novel and recent deep learning solution to
complete point clouds, but it is not capable of part segmentation. On the other
hand, our proposed solution, GRJointNet, is an architecture that can perform
joint completion and segmentation on point clouds as a successor of GRNet.
Features extracted for the two tasks are also utilized by each other to
increase the overall performance. We evaluated our proposed network on the
ShapeNet-Part dataset and compared its performance to GRNet. Our results
demonstrate GRJointNet can outperform GRNet on point completion. It should also
be noted that GRNet is not capable of segmentation while GRJointNet is. This
study1, therefore, holds a promise to enhance practicality and utility of point
clouds in 3D vision for autonomous systems.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14003" title="Abstract">arXiv:2311.14003</a> [<a href="/pdf/2311.14003" title="Download PDF">pdf</a>, <a href="/format/2311.14003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Direct Preference-Based Evolutionary Multi-Objective Optimization with  Dueling Bandit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tian Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Ke Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Optimization problems find widespread use in both single-objective and
multi-objective scenarios. In practical applications, users aspire for
solutions that converge to the region of interest (ROI) along the Pareto front
(PF). While the conventional approach involves approximating a fitness function
or an objective function to reflect user preferences, this paper explores an
alternative avenue. Specifically, we aim to discover a method that sidesteps
the need for calculating the fitness function, relying solely on human
feedback. Our proposed approach entails conducting direct preference learning
facilitated by an active dueling bandit algorithm. The experimental phase is
structured into three sessions. Firstly, we assess the performance of our
active dueling bandit algorithm. Secondly, we implement our proposed method
within the context of Multi-objective Evolutionary Algorithms (MOEAs). Finally,
we deploy our method in a practical problem, specifically in protein structure
prediction (PSP). This research presents a novel interactive preference-based
MOEA framework that not only addresses the limitations of traditional
techniques but also unveils new possibilities for optimization problems.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14005" title="Abstract">arXiv:2311.14005</a> [<a href="/pdf/2311.14005" title="Download PDF">pdf</a>, <a href="/format/2311.14005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Side-Channel Attacks Break the Black-Box Property of Embedded  Artificial Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Coqueret%2C+B">Benoit Coqueret</a>, 
<a href="/search/cs?searchtype=author&query=Carbone%2C+M">Mathieu Carbone</a>, 
<a href="/search/cs?searchtype=author&query=Sentieys%2C+O">Olivier Sentieys</a>, 
<a href="/search/cs?searchtype=author&query=Zaid%2C+G">Gabriel Zaid</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> AISec'23: Proceedings of the 16th ACM Workshop on Artificial
  Intelligence and Security. November 2023. Pages 127-138
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Artificial intelligence, and specifically deep neural networks (DNNs), has
rapidly emerged in the past decade as the standard for several tasks from
specific advertising to object detection. The performance offered has led DNN
algorithms to become a part of critical embedded systems, requiring both
efficiency and reliability. In particular, DNNs are subject to malicious
examples designed in a way to fool the network while being undetectable to the
human observer: the adversarial examples. While previous studies propose
frameworks to implement such attacks in black box settings, those often rely on
the hypothesis that the attacker has access to the logits of the neural
network, breaking the assumption of the traditional black box. In this paper,
we investigate a real black box scenario where the attacker has no access to
the logits. In particular, we propose an architecture-agnostic attack which
solve this constraint by extracting the logits. Our method combines hardware
and software attacks, by performing a side-channel attack that exploits
electromagnetic leakages to extract the logits for a given input, allowing an
attacker to estimate the gradients and produce state-of-the-art adversarial
examples to fool the targeted neural network. Through this example of
adversarial attack, we demonstrate the effectiveness of logits extraction using
side-channel as a first step for more general attack frameworks requiring
either the logits or the confidence scores.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14006" title="Abstract">arXiv:2311.14006</a> [<a href="/pdf/2311.14006" title="Download PDF">pdf</a>, <a href="/format/2311.14006" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-resolution Population Maps Derived from Sentinel-1 and Sentinel-2
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Metzger%2C+N">Nando Metzger</a>, 
<a href="/search/cs?searchtype=author&query=Daudt%2C+R+C">Rodrigo Caye Daudt</a>, 
<a href="/search/cs?searchtype=author&query=Tuia%2C+D">Devis Tuia</a>, 
<a href="/search/cs?searchtype=author&query=Schindler%2C+K">Konrad Schindler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 10 tables, 7 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Detailed population maps play an important role in diverse fields ranging
from humanitarian action to urban planning. Generating such maps in a timely
and scalable manner presents a challenge, especially in data-scarce regions. To
address it we have developed POPCORN, a population mapping method whose only
inputs are free, globally available satellite images from Sentinel-1 and
Sentinel-2; and a small number of aggregate population counts over coarse
census districts for calibration. Despite the minimal data requirements our
approach surpasses the mapping accuracy of existing schemes, including several
that rely on building footprints derived from high-resolution imagery. E.g., we
were able to produce population maps for Rwanda with 100m GSD based on less
than 400 regional census counts. In Kigali, those maps reach an $R^2$ score of
66% w.r.t. a ground truth reference map, with an average error of only $\pm$10
inhabitants/ha. Conveniently, POPCORN retrieves explicit maps of built-up areas
and of local building occupancy rates, making the mapping process interpretable
and offering additional insights, for instance about the distribution of
built-up, but unpopulated areas, e.g., industrial warehouses. Moreover, we find
that, once trained, the model can be applied repeatedly to track population
changes; and that it can be transferred to geographically similar regions,
e.g., from Uganda to Rwanda). With our work we aim to democratize access to
up-to-date and high-resolution population maps, recognizing that some regions
faced with particularly strong population dynamics may lack the resources for
costly micro-census campaigns.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14007" title="Abstract">arXiv:2311.14007</a> [<a href="/pdf/2311.14007" title="Download PDF">pdf</a>, <a href="/format/2311.14007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extending JSON CRDT with Move Operations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Da%2C+L">Liangrun Da</a>, 
<a href="/search/cs?searchtype=author&query=Kleppmann%2C+M">Martin Kleppmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Conflict-Free Replicated Data Types (CRDTs) for JSON allow users to
concurrently update a JSON document without introducing any conflicts and
automatically merge the updates into a consistent state. However, moving a
subtree in a map or reordering elements in a list for a JSON CRDT is considered
challenging as an algorithm that is not carefully designed may introduce
unexpected results such as duplicates or cycles. In this paper, we show how to
extend Automerge, a CRDT library, by incorporating move operations and
evaluating the performance of our algorithm.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14012" title="Abstract">arXiv:2311.14012</a> [<a href="/pdf/2311.14012" title="Download PDF">pdf</a>, <a href="/format/2311.14012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shadow: A Novel Loss Function for Efficient Training in Siamese Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+A+E">Alif Elham Khan</a>, 
<a href="/search/cs?searchtype=author&query=Hasan%2C+M+J">Mohammad Junayed Hasan</a>, 
<a href="/search/cs?searchtype=author&query=Anjum%2C+H">Humayra Anjum</a>, 
<a href="/search/cs?searchtype=author&query=Mohammed%2C+N">Nabeel Mohammed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite significant recent advances in similarity detection tasks, existing
approaches pose substantial challenges under memory constraints. One of the
primary reasons for this is the use of computationally expensive metric
learning loss functions such as Triplet Loss in Siamese networks. In this
paper, we present a novel loss function called Shadow Loss that compresses the
dimensions of an embedding space during loss calculation without loss of
performance. The distance between the projections of the embeddings is learned
from inputs on a compact projection space where distances directly correspond
to a measure of class similarity. Projecting on a lower-dimension projection
space, our loss function converges faster, and the resulting classified image
clusters have higher inter-class and smaller intra-class distances. Shadow Loss
not only reduces embedding dimensions favoring memory constraint devices but
also consistently performs better than the state-of-the-art Triplet Margin Loss
by an accuracy of 5\%-10\% across diverse datasets. The proposed loss function
is also model agnostic, upholding its performance across several tested models.
Its effectiveness and robustness across balanced, imbalanced, medical, and
non-medical image datasets suggests that it is not specific to a particular
model or dataset but demonstrates superior performance consistently while using
less memory and computation.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14014" title="Abstract">arXiv:2311.14014</a> [<a href="/pdf/2311.14014" title="Download PDF">pdf</a>, <a href="/format/2311.14014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Hyperparameter Landscapes of Machine Learning Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Mingyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Ke Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Despite the recent success in a plethora of hyperparameter optimization (HPO)
methods for machine learning (ML) models, the intricate interplay between model
hyperparameters (HPs) and predictive losses (a.k.a fitness), which is a key
prerequisite for understanding HPO, remain notably underexplored in our
community. This results in limited explainability in the HPO process, rendering
a lack of human trust and difficulties in pinpointing algorithm bottlenecks. In
this paper, we aim to shed light on this black box by conducting large-scale
fitness landscape analysis (FLA) on 1,500 HP loss landscapes of 6 ML models
with more than 11 model configurations, across 67 datasets and different levels
of fidelities. We reveal the first unified, comprehensive portrait of their
topographies in terms of smoothness, neutrality and modality. We also show that
such properties are highly transferable across datasets and fidelities,
providing fundamental evidence for the success of multi-fidelity and transfer
learning methods. These findings are made possible by developing a dedicated
FLA framework that incorporates a combination of visual and quantitative
measures. We further demonstrate the potential of this framework by analyzing
the NAS-Bench-101 landscape, and we believe it is able to faciliate fundamental
understanding of a broader range of AutoML tasks.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14019" title="Abstract">arXiv:2311.14019</a> [<a href="/pdf/2311.14019" title="Download PDF">pdf</a>, <a href="/format/2311.14019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An efficient mixed finite element method for nonlinear magnetostatics  and quasistatics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Egger%2C+H">Herbert Egger</a>, 
<a href="/search/math?searchtype=author&query=Engertsberger%2C+F">Felix Engertsberger</a>, 
<a href="/search/math?searchtype=author&query=Radu%2C+B">Bogdan Radu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We consider systems of nonlinear magnetostatics and quasistatics that
typically arise in the modeling and simulation of electric machines. The
nonlinear problems, eventually obtained after time discretization, are usually
solved by employing a vector potential formulation. In the relevant
two-dimensional setting, a discretization can be obtained by H1-conforming
finite elements. We here consider an alternative formulation based on the
H-field which leads to a nonlinear saddlepoint problem. After commenting on the
unique solvability, we study the numerical approximation by H(curl)-conforming
finite elements and present the main convergence results. A particular focus is
put on the efficient solution of the linearized systems arising in every step
of the nonlinear Newton solver. Via hybridization, the linearized saddlepoint
systems can be transformed into linear elliptic problems, which can be solved
with similar computational complexity as those arising in the vector or scalar
potential formulation. In summary, we can thus claim that the mixed finite
element approach based on the $H$-field can be considered a competitive
alternative to the standard vector or scalar potential formulations for the
solution of problems in nonlinear magneto-quasistatics.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14023" title="Abstract">arXiv:2311.14023</a> [<a href="/pdf/2311.14023" title="Download PDF">pdf</a>, <a href="/ps/2311.14023" title="Download PostScript">ps</a>, <a href="/format/2311.14023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithm-agnostic low-rank approximation of operator monotone matrix  functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Persson%2C+D">David Persson</a>, 
<a href="/search/math?searchtype=author&query=Meyer%2C+R+A">Raphael A. Meyer</a>, 
<a href="/search/math?searchtype=author&query=Musco%2C+C">Christopher Musco</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Low-rank approximation of a matrix function, $f(A)$, is an important task in
computational mathematics. Most methods require direct access to $f(A)$, which
is often considerably more expensive than accessing $A$. Persson and Kressner
(SIMAX 2023) avoid this issue for symmetric positive semidefinite matrices by
proposing funNystr\"om, which first constructs a Nystr\"om approximation to $A$
using subspace iteration, and then uses the approximation to directly obtain a
low-rank approximation for $f(A)$. They prove that the method yields a
near-optimal approximation whenever $f$ is a continuous operator monotone
function with $f(0) = 0$.
<br />We significantly generalize the results of Persson and Kressner beyond
subspace iteration. We show that if $\widehat{A}$ is a near-optimal low-rank
Nystr\"om approximation to $A$ then $f(\widehat{A})$ is a near-optimal low-rank
approximation to $f(A)$, independently of how $\widehat{A}$ is computed.
Further, we show sufficient conditions for a basis $Q$ to produce a
near-optimal Nystr\"om approximation $\widehat{A} = AQ(Q^T AQ)^{\dagger} Q^T
A$. We use these results to establish that many common low-rank approximation
methods produce near-optimal Nystr\"om approximations to $A$ and therefore to
$f(A)$.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14024" title="Abstract">arXiv:2311.14024</a> [<a href="/pdf/2311.14024" title="Download PDF">pdf</a>, <a href="/format/2311.14024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Creating and Benchmarking a Synthetic Dataset for Cloud Optical  Thickness Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pirinen%2C+A">Aleksis Pirinen</a>, 
<a href="/search/cs?searchtype=author&query=Abid%2C+N">Nosheen Abid</a>, 
<a href="/search/cs?searchtype=author&query=Paszkowsky%2C+N+A">Nuria Agues Paszkowsky</a>, 
<a href="/search/cs?searchtype=author&query=Timoudas%2C+T+O">Thomas Ohlson Timoudas</a>, 
<a href="/search/cs?searchtype=author&query=Scheirer%2C+R">Ronald Scheirer</a>, 
<a href="/search/cs?searchtype=author&query=Ceccobello%2C+C">Chiara Ceccobello</a>, 
<a href="/search/cs?searchtype=author&query=Kov%C3%A1cs%2C+G">Gy&#xf6;rgy Kov&#xe1;cs</a>, 
<a href="/search/cs?searchtype=author&query=Persson%2C+A">Anders Persson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code, data and models available at <a href="https://github.com/aleksispi/ml-cloud-opt-thick">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Cloud formations often obscure optical satellite-based monitoring of the
Earth's surface, thus limiting Earth observation (EO) activities such as land
cover mapping, ocean color analysis, and cropland monitoring. The integration
of machine learning (ML) methods within the remote sensing domain has
significantly improved performance on a wide range of EO tasks, including cloud
detection and filtering, but there is still much room for improvement. A key
bottleneck is that ML methods typically depend on large amounts of annotated
data for training, which is often difficult to come by in EO contexts. This is
especially true for the task of cloud optical thickness (COT) estimation. A
reliable estimation of COT enables more fine-grained and application-dependent
control compared to using pre-specified cloud categories, as is commonly done
in practice. To alleviate the COT data scarcity problem, in this work we
propose a novel synthetic dataset for COT estimation, where top-of-atmosphere
radiances have been simulated for 12 of the spectral bands of the
Multi-Spectral Instrument (MSI) sensor onboard Sentinel-2 platforms. These data
points have been simulated under consideration of different cloud types, COTs,
and ground surface and atmospheric profiles. Extensive experimentation of
training several ML models to predict COT from the measured reflectivity of the
spectral bands demonstrates the usefulness of our proposed dataset.
Generalization to real data is also demonstrated on two satellite image
datasets -- one that is publicly available, and one which we have collected and
annotated. The synthetic data, the newly collected real dataset, code and
models have been made publicly available at
https://github.com/aleksispi/ml-cloud-opt-thick.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14028" title="Abstract">arXiv:2311.14028</a> [<a href="/pdf/2311.14028" title="Download PDF">pdf</a>, <a href="/format/2311.14028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Learning of Diffusion Models with Generative Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Masip%2C+S">Sergi Masip</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+P">Pau Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Tuytelaars%2C+T">Tinne Tuytelaars</a>, 
<a href="/search/cs?searchtype=author&query=van+de+Ven%2C+G+M">Gido M. van de Ven</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Diffusion models are powerful generative models that achieve state-of-the-art
performance in tasks such as image synthesis. However, training them demands
substantial amounts of data and computational resources. Continual learning
would allow for incrementally learning new tasks and accumulating knowledge,
thus reusing already trained models would be possible. One potentially suitable
approach is generative replay, where a copy of a generative model trained on
previous tasks produces synthetic data that are interleaved with data from the
current task. However, standard generative replay applied to diffusion models
results in a catastrophic loss in denoising capabilities. In this paper, we
propose generative distillation, an approach that distils the entire reverse
process of a diffusion model. We demonstrate that our approach significantly
improves the continual learning performance of generative replay with only a
moderate increase in the computational costs.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14029" title="Abstract">arXiv:2311.14029</a> [<a href="/pdf/2311.14029" title="Download PDF">pdf</a>, <a href="/format/2311.14029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Vulnerability of CLIP to Image Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Cangxiong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Namboodiri%2C+V+P">Vinay P. Namboodiri</a>, 
<a href="/search/cs?searchtype=author&query=Padget%2C+J">Julian Padget</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> R0-FoMo: Workshop on Robustness of Few-shot and Zero-shot Learning in Foundation Models at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">CLIP is a widely used foundational vision-language model that is used for
zero-shot image recognition and other image-text alignment tasks. We
demonstrate that CLIP is vulnerable to change in image quality under
compression. This surprising result is further analysed using an attribution
method-Integrated Gradients. Using this attribution method, we are able to
better understand both quantitatively and qualitatively exactly the nature in
which the compression affects the zero-shot recognition accuracy of this model.
We evaluate this extensively on CIFAR-10 and STL-10. Our work provides the
basis to understand this vulnerability of CLIP and can help us develop more
effective methods to improve the robustness of CLIP and other vision-language
models.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14030" title="Abstract">arXiv:2311.14030</a> [<a href="/pdf/2311.14030" title="Download PDF">pdf</a>, <a href="/format/2311.14030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PrivateLoRA For Efficient Privacy Preserving LLM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xiaodong Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guannan Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">End users face a choice between privacy and efficiency in current Large
Language Model (LLM) service paradigms. In cloud-based paradigms, users are
forced to compromise data locality for generation quality and processing speed.
Conversely, edge device paradigms maintain data locality but fail to deliver
satisfactory performance. In this work, we propose a novel LLM service paradigm
that distributes privacy-sensitive computation on edge devices and shared
computation in the cloud. Only activations are transmitted between the central
cloud and edge devices to ensure data locality. Our core innovation,
PrivateLoRA, addresses the challenging communication overhead by exploiting the
low rank of residual activations, achieving over 95% communication reduction.
Consequently, PrivateLoRA effectively maintains data locality and is extremely
resource efficient. Under standard 5G networks, PrivateLoRA achieves throughput
over 300% of device-only solutions for 7B models and over 80% of an A100 GPU
for 33B models. PrivateLoRA also provides tuning performance comparable to LoRA
for advanced personalization. Our approach democratizes access to
state-of-the-art generative AI for edge devices, paving the way for more
tailored LLM experiences for the general public. To our knowledge, our proposed
framework is the first efficient and privacy-preserving LLM solution in the
literature.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14031" title="Abstract">arXiv:2311.14031</a> [<a href="/pdf/2311.14031" title="Download PDF">pdf</a>, <a href="/format/2311.14031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bias and Multiscale Correction Methods for Variational State Estimation  Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Galarce%2C+F">Felipe Galarce</a>, 
<a href="/search/math?searchtype=author&query=Mura%2C+J">Joaquin Mura</a>, 
<a href="/search/math?searchtype=author&query=Caiazzo%2C+A">Alfonso Caiazzo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The integration of experimental data into mathematical and computational
models is crucial for enhancing their predictive power in real-world scenarios.
However, the performance of data assimilation algorithms can be significantly
degraded when measurements are corrupted by biased noise, altering the signal
magnitude, or when the system dynamics lack smoothness, such as in the presence
of fast oscillations or discontinuities. This paper focuses on variational
state estimation using the so-called Parameterized Background Data Weak method,
which relies on a parameterized background by a set of constraints, enabling
state estimation by solving a minimization problem on a reduced-order
background model, subject to constraints imposed by the input measurements. To
address biased noise in observations, a modified formulation is proposed,
incorporating a correction mechanism to handle rapid oscillations by treating
them as slow-decaying modes based on a two-scale splitting of the classical
reconstruction algorithm. The effectiveness of the proposed algorithms is
demonstrated through various examples, including discontinuous signals and
simulated Doppler ultrasound data.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14033" title="Abstract">arXiv:2311.14033</a> [<a href="/pdf/2311.14033" title="Download PDF">pdf</a>, <a href="/format/2311.14033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multivariate Scenario Generation of Day-Ahead Electricity Prices using  Normalizing Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hilger%2C+H">Hannes Hilger</a>, 
<a href="/search/cs?searchtype=author&query=Witthaut%2C+D">Dirk Witthaut</a>, 
<a href="/search/cs?searchtype=author&query=Dahmen%2C+M">Manuel Dahmen</a>, 
<a href="/search/cs?searchtype=author&query=Gorjao%2C+L+R">Leonardo Rydin Gorjao</a>, 
<a href="/search/cs?searchtype=author&query=Trebbien%2C+J">Julius Trebbien</a>, 
<a href="/search/cs?searchtype=author&query=Cramer%2C+E">Eike Cramer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Trading on electricity markets requires accurate information about the
realization of electricity prices and the uncertainty attached to the
predictions. We present a probabilistic forecasting approach for day-ahead
electricity prices using the fully data-driven deep generative model called
normalizing flows. Our modeling approach generates full-day scenarios of
day-ahead electricity prices based on conditional features such as residual
load forecasts. Furthermore, we propose extended feature sets of prior
realizations and a periodic retraining scheme that allows the normalizing flow
to adapt to the changing conditions of modern electricity markets. In
particular, we investigate the impact of the energy crisis ensuing from the
Russian invasion of Ukraine. Our results highlight that the normalizing flow
generates high-quality scenarios that reproduce the true price distribution and
yield highly accurate forecasts. Additionally, our analysis highlights how our
improvements towards adaptations in changing regimes allow the normalizing flow
to adapt to changing market conditions and enables continued sampling of
high-quality day-ahead price scenarios.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14037" title="Abstract">arXiv:2311.14037</a> [<a href="/pdf/2311.14037" title="Download PDF">pdf</a>, <a href="/format/2311.14037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdapterFL: Adaptive Heterogeneous Federated Learning for  Resource-constrained Mobile Computing Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruixuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+M">Ming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Z">Zeke Xia</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+J">Jun Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pengyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yihao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mingsong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Federated Learning (FL) enables collaborative learning of large-scale
distributed clients without data sharing. However, due to the disparity of
computing resources among massive mobile computing devices, the performance of
traditional homogeneous model-based Federated Learning (FL) is seriously
limited. On the one hand, to achieve model training in all the diverse clients,
mobile computing systems can only use small low-performance models for
collaborative learning. On the other hand, devices with high computing
resources cannot train a high-performance large model with their insufficient
raw data. To address the resource-constrained problem in mobile computing
systems, we present a novel heterogeneous FL approach named AdapterFL, which
uses a model reassemble strategy to facilitate collaborative training of
massive heterogeneous mobile devices adaptively. Specifically, we select
multiple candidate heterogeneous models based on the computing performance of
massive mobile devices and then divide each heterogeneous model into two
partitions. By reassembling the partitions, we can generate models with varied
sizes that are combined by the partial parameters of the large model with the
partial parameters of the small model. Using these reassembled models for FL
training, we can train the partial parameters of the large model using
low-performance devices. In this way, we can alleviate performance degradation
in large models due to resource constraints. The experimental results show that
AdapterFL can achieve up to 12\% accuracy improvement compared to the
state-of-the-art heterogeneous federated learning methods in
resource-constrained scenarios.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14045" title="Abstract">arXiv:2311.14045</a> [<a href="/pdf/2311.14045" title="Download PDF">pdf</a>, <a href="/format/2311.14045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics Informed Neural Network Framework for Unsteady Discretized  Reduced Order System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Halder%2C+R">Rahul Halder</a>, 
<a href="/search/math?searchtype=author&query=Stabile%2C+G">Giovanni Stabile</a>, 
<a href="/search/math?searchtype=author&query=Rozza%2C+G">Gianluigi Rozza</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">This work addresses the development of a physics-informed neural network
(PINN) with a loss term derived from a discretized time-dependent reduced-order
system. In this work, first, the governing equations are discretized using a
finite difference scheme (whereas, any other discretization technique can be
adopted), then projected on a reduced or latent space using the Proper
Orthogonal Decomposition (POD)-Galerkin approach and next, the residual arising
from discretized reduced order equation is considered as an additional loss
penalty term alongside the data-driven loss term using different variants of
deep learning method such as Artificial neural network (ANN), Long Short-Term
Memory based neural network (LSTM). The LSTM neural network has been proven to
be very effective for time-dependent problems in a purely data-driven
environment. The current work demonstrates the LSTM network's potential over
ANN networks in physics-informed neural networks (PINN) as well. The potential
of using discretized governing equations instead of continuous form lies in the
flexibility of input to the PINN. Different sizes of data ranging from small,
medium to big datasets are used to assess the potential of
discretized-physics-informed neural networks when there is very sparse or no
data available. The proposed methods are applied to a pitch-plunge airfoil
motion governed by rigid-body dynamics and a one-dimensional viscous Burgers'
equation. The current work also demonstrates the prediction capability of
various discretized-physics-informed neural networks outside the domain where
the data is available or governing equation-based residuals are minimized.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14050" title="Abstract">arXiv:2311.14050</a> [<a href="/pdf/2311.14050" title="Download PDF">pdf</a>, <a href="/format/2311.14050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Step size control for explicit relaxation Runge-Kutta methods preserving  invariants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bleecke%2C+S">Sebastian Bleecke</a>, 
<a href="/search/math?searchtype=author&query=Ranocha%2C+H">Hendrik Ranocha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Many time-dependent differential equations are equipped with invariants.
Preserving such invariants under discretization can be important, e.g., to
improve the qualitative and quantitative properties of numerical solutions.
Recently, relaxation methods have been proposed as small modifications of
standard time integration schemes guaranteeing the correct evolution of
functionals of the solution. Here, we investigate how to combine these
relaxation techniques with efficient step size control mechanisms based on
local error estimates for explicit Runge-Kutta methods. We demonstrate our
results in several numerical experiments including ordinary and partial
differential equations.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14053" title="Abstract">arXiv:2311.14053</a> [<a href="/pdf/2311.14053" title="Download PDF">pdf</a>, <a href="/format/2311.14053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coevolution of Neural Architectures and Features for Stock Market  Forecasting: A Multi-objective Decision Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hafiz%2C+F">Faizal Hafiz</a>, 
<a href="/search/cs?searchtype=author&query=Broekaert%2C+J">Jan Broekaert</a>, 
<a href="/search/cs?searchtype=author&query=La+Torre%2C+D">Davide La Torre</a>, 
<a href="/search/cs?searchtype=author&query=Swain%2C+A">Akshya Swain</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Decision Support Systems, 114015 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">In a multi objective setting, a portfolio manager's highly consequential
decisions can benefit from assessing alternative forecasting models of stock
index movement. The present investigation proposes a new approach to identify a
set of nondominated neural network models for further selection by the decision
maker. A new coevolution approach is proposed to simultaneously select the
features and topology of neural networks (collectively referred to as neural
architecture), where the features are viewed from a topological perspective as
input neurons. Further, the coevolution is posed as a multicriteria problem to
evolve sparse and efficacious neural architectures. The well known dominance
and decomposition based multiobjective evolutionary algorithms are augmented
with a nongeometric crossover operator to diversify and balance the search for
neural architectures across conflicting criteria. Moreover, the coevolution is
augmented to accommodate the data based implications of distinct market
behaviors prior to and during the ongoing COVID 19 pandemic. A detailed
comparative evaluation is carried out with the conventional sequential approach
of feature selection followed by neural topology design, as well as a
scalarized coevolution approach. The results on the NASDAQ index in pre and
peri COVID time windows convincingly demonstrate that the proposed coevolution
approach can evolve a set of nondominated neural forecasting models with better
generalization capabilities.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14056" title="Abstract">arXiv:2311.14056</a> [<a href="/pdf/2311.14056" title="Download PDF">pdf</a>, <a href="/format/2311.14056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DPSUR: Accelerating Differentially Private Stochastic Gradient Descent  Using Selective Update and Release
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Q">Qingqing Ye</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Haibo Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhili Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lulu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kuncan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xun%2C+R">Ran Xun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by VLDB 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Machine learning models are known to memorize private data to reduce their
training loss, which can be inadvertently exploited by privacy attacks such as
model inversion and membership inference. To protect against these attacks,
differential privacy (DP) has become the de facto standard for
privacy-preserving machine learning, particularly those popular training
algorithms using stochastic gradient descent, such as DPSGD. Nonetheless, DPSGD
still suffers from severe utility loss due to its slow convergence. This is
partially caused by the random sampling, which brings bias and variance to the
gradient, and partially by the Gaussian noise, which leads to fluctuation of
gradient updates.
<br />Our key idea to address these issues is to apply selective updates to the
model training, while discarding those useless or even harmful updates.
Motivated by this, this paper proposes DPSUR, a Differentially Private training
framework based on Selective Updates and Release, where the gradient from each
iteration is evaluated based on a validation test, and only those updates
leading to convergence are applied to the model. As such, DPSUR ensures the
training in the right direction and thus can achieve faster convergence than
DPSGD. The main challenges lie in two aspects -- privacy concerns arising from
gradient evaluation, and gradient selection strategy for model update. To
address the challenges, DPSUR introduces a clipping strategy for update
randomization and a threshold mechanism for gradient selection. Experiments
conducted on MNIST, FMNIST, CIFAR-10, and IMDB datasets show that DPSUR
significantly outperforms previous works in terms of convergence speed and
model utility.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14057" title="Abstract">arXiv:2311.14057</a> [<a href="/pdf/2311.14057" title="Download PDF">pdf</a>, <a href="/format/2311.14057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing the Impact of Noise on Quantum Neural Networks: An  Experimental Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Escudero%2C+E+B+T">Erik B. Terres Escudero</a>, 
<a href="/search/cs?searchtype=author&query=Alamo%2C+D+A">Danel Arias Alamo</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez%2C+O+M">Oier Mentxaka G&#xf3;mez</a>, 
<a href="/search/cs?searchtype=author&query=Bringas%2C+P+G">Pablo Garc&#xed;a Bringas</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Hybrid Artificial Intelligent Systems. HAIS 2023. Lecture Notes in
  Computer Science(), vol 14001. Springer, Cham
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">In the race towards quantum computing, the potential benefits of quantum
neural networks (QNNs) have become increasingly apparent. However, Noisy
Intermediate-Scale Quantum (NISQ) processors are prone to errors, which poses a
significant challenge for the execution of complex algorithms or quantum
machine learning. To ensure the quality and security of QNNs, it is crucial to
explore the impact of noise on their performance. This paper provides a
comprehensive analysis of the impact of noise on QNNs, examining the Mottonen
state preparation algorithm under various noise models and studying the
degradation of quantum states as they pass through multiple layers of QNNs.
Additionally, the paper evaluates the effect of noise on the performance of
pre-trained QNNs and highlights the challenges posed by noise models in quantum
computing. The findings of this study have significant implications for the
development of quantum software, emphasizing the importance of prioritizing
stability and noise-correction measures when developing QNNs to ensure reliable
and trustworthy results. This paper contributes to the growing body of
literature on quantum computing and quantum machine learning, providing new
insights into the impact of noise on QNNs and paving the way towards the
development of more robust and efficient quantum algorithms.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14058" title="Abstract">arXiv:2311.14058</a> [<a href="/pdf/2311.14058" title="Download PDF">pdf</a>, <a href="/format/2311.14058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identification for Tree-shaped Structural Causal Models in Polynomial  Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Aaryan Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Bl%C3%A4ser%2C+M">Markus Bl&#xe4;ser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Linear structural causal models (SCMs) are used to express and analyse the
relationships between random variables. Direct causal effects are represented
as directed edges and confounding factors as bidirected edges. Identifying the
causal parameters from correlations between the nodes is an open problem in
artificial intelligence. In this paper, we study SCMs whose directed component
forms a tree. Van der Zander et al. (AISTATS'22, PLMR 151, pp. 6770--6792,
2022) give a PSPACE-algorithm for the identification problem in this case,
which is a significant improvement over the general Gr\"obner basis approach,
which has doubly-exponential time complexity in the number of structural
parameters. In this work, we present a randomized polynomial-time algorithm,
which solves the identification problem for tree-shaped SCMs. For every
structural parameter, our algorithms decides whether it is generically
identifiable, generically 2-identifiable, or generically unidentifiable. (No
other cases can occur.) In the first two cases, it provides one or two
fractional affine square root terms of polynomials (FASTPs) for the
corresponding parameter, respectively.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14061" title="Abstract">arXiv:2311.14061</a> [<a href="/pdf/2311.14061" title="Download PDF">pdf</a>, <a href="/format/2311.14061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Explainable Strategy Templates using NLP Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bagga%2C+P">Pallavi Bagga</a>, 
<a href="/search/cs?searchtype=author&query=Stathis%2C+K">Kostas Stathis</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Workshop Workshop on Explainable AI in Finance, November 27, 2023,
  ACM, New York, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This paper bridges the gap between mathematical heuristic strategies learned
from Deep Reinforcement Learning (DRL) in automated agent negotiation, and
comprehensible, natural language explanations. Our aim is to make these
strategies more accessible to non-experts. By leveraging traditional Natural
Language Processing (NLP) techniques and Large Language Models (LLMs) equipped
with Transformers, we outline how parts of DRL strategies composed of parts
within strategy templates can be transformed into user-friendly, human-like
English narratives. To achieve this, we present a top-level algorithm that
involves parsing mathematical expressions of strategy templates, semantically
interpreting variables and structures, generating rule-based primary
explanations, and utilizing a Generative Pre-trained Transformer (GPT) model to
refine and contextualize these explanations. Subsequent customization for
varied audiences and meticulous validation processes in an example illustrate
the applicability and potential of this approach.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14062" title="Abstract">arXiv:2311.14062</a> [<a href="/pdf/2311.14062" title="Download PDF">pdf</a>, <a href="/format/2311.14062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hardware Resilience Properties of Text-Guided Image Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wasim%2C+S+T">Syed Talal Wasim</a>, 
<a href="/search/cs?searchtype=author&query=Saboka%2C+K+H">Kabila Haile Saboka</a>, 
<a href="/search/cs?searchtype=author&query=Mahmoud%2C+A">Abdulrahman Mahmoud</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S">Salman Khan</a>, 
<a href="/search/cs?searchtype=author&query=Brooks%2C+D">David Brooks</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+G">Gu-Yeon Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents a novel method to enhance the reliability of image
classification models during deployment in the face of transient hardware
errors. By utilizing enriched text embeddings derived from GPT-3 with question
prompts per class and CLIP pretrained text encoder, we investigate their impact
as an initialization for the classification layer. Our approach achieves a
remarkable $5.5\times$ average increase in hardware reliability (and up to 14x)
across various architectures in the most critical layer, with minimal accuracy
drop (0.3% on average) compared to baseline PyTorch models. Furthermore, our
method seamlessly integrates with any image classification backbone, showcases
results across various network architectures, decreases parameter and FLOPs
overhead, and follows a consistent training recipe. This research offers a
practical and efficient solution to bolster the robustness of image
classification models against hardware failures, with potential implications
for future studies in this domain. Our code and models are released at
https://github.com/TalalWasim/TextGuidedResilience.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14063" title="Abstract">arXiv:2311.14063</a> [<a href="/pdf/2311.14063" title="Download PDF">pdf</a>, <a href="/format/2311.14063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do VSR Models Generalize Beyond LRS3?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Djilali%2C+Y+A+D">Yasser Abdelaziz Dahou Djilali</a>, 
<a href="/search/cs?searchtype=author&query=Narayan%2C+S">Sanath Narayan</a>, 
<a href="/search/cs?searchtype=author&query=Bihan%2C+E+L">Eustache Le Bihan</a>, 
<a href="/search/cs?searchtype=author&query=Boussaid%2C+H">Haithem Boussaid</a>, 
<a href="/search/cs?searchtype=author&query=Almazrouei%2C+E">Ebtessam Almazrouei</a>, 
<a href="/search/cs?searchtype=author&query=Debbah%2C+M">Merouane Debbah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">The Lip Reading Sentences-3 (LRS3) benchmark has primarily been the focus of
intense research in visual speech recognition (VSR) during the last few years.
As a result, there is an increased risk of overfitting to its excessively used
test set, which is only one hour duration. To alleviate this issue, we build a
new VSR test set named WildVSR, by closely following the LRS3 dataset creation
processes. We then evaluate and analyse the extent to which the current VSR
models generalize to the new test data. We evaluate a broad range of publicly
available VSR models and find significant drops in performance on our test set,
compared to their corresponding LRS3 results. Our results suggest that the
increase in word error rates is caused by the models inability to generalize to
slightly harder and in the wild lip sequences than those found in the LRS3 test
set. Our new test benchmark is made public in order to enable future research
towards more robust VSR models.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14064" title="Abstract">arXiv:2311.14064</a> [<a href="/pdf/2311.14064" title="Download PDF">pdf</a>, <a href="/format/2311.14064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HGCLIP: Exploring Vision-Language Models with Graph Representations for  Hierarchical Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+P">Peng Xia</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xingtong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+M">Ming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Ju%2C+L">Lie Ju</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhiyong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+P">Peibo Duan</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Z">Zongyuan Ge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Object categories are typically organized into a multi-granularity taxonomic
hierarchy. When classifying categories at different hierarchy levels,
traditional uni-modal approaches focus primarily on image features, revealing
limitations in complex scenarios. Recent studies integrating Vision-Language
Models (VLMs) with class hierarchies have shown promise, yet they fall short of
fully exploiting the hierarchical relationships. These efforts are constrained
by their inability to perform effectively across varied granularity of
categories. To tackle this issue, we propose a novel framework (HGCLIP) that
effectively combines CLIP with a deeper exploitation of the Hierarchical class
structure via Graph representation learning. We explore constructing the class
hierarchy into a graph, with its nodes representing the textual or image
features of each category. After passing through a graph encoder, the textual
features incorporate hierarchical structure information, while the image
features emphasize class-aware features derived from prototypes through the
attention mechanism. Our approach demonstrates significant improvements on both
generic and fine-grained visual recognition benchmarks. Our codes are fully
available at https://github.com/richard-peng-xia/HGCLIP.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14067" title="Abstract">arXiv:2311.14067</a> [<a href="/pdf/2311.14067" title="Download PDF">pdf</a>, <a href="/format/2311.14067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Task-Oriented Dialogues with Chitchat: a Comparative Study  Based on Lexical Diversity and Divergence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stricker%2C+A">Armand Stricker</a>, 
<a href="/search/cs?searchtype=author&query=Paroubek%2C+P">Patrick Paroubek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ASRU 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">As a recent development, task-oriented dialogues (TODs) have been enriched
with chitchat in an effort to make dialogues more diverse and engaging. This
enhancement is particularly valuable as TODs are often confined to narrow
domains, making the mitigation of repetitive and predictable responses a
significant challenge. This paper presents a comparative analysis of three
chitchat enhancements, aiming to identify the most effective approach in terms
of diversity. Additionally, we quantify the divergence between the added
chitchat, the original task-oriented language, and chitchat typically found in
chitchat datasets, highlighting the top 20 divergent keywords for each
comparison. Our findings drive a discussion on future enhancements for
augmenting TODs, emphasizing the importance of grounding dialogues beyond the
task to achieve more diverse and natural exchanges.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14073" title="Abstract">arXiv:2311.14073</a> [<a href="/pdf/2311.14073" title="Download PDF">pdf</a>, <a href="/format/2311.14073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Saliency From Fixations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Djilali%2C+Y+A+D">Yasser Abdelaziz Dahou Djilali</a>, 
<a href="/search/cs?searchtype=author&query=McGuiness%2C+K">Kevin McGuiness</a>, 
<a href="/search/cs?searchtype=author&query=O%27Connor%2C+N">Noel O&#x27;Connor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present a novel approach for saliency prediction in images, leveraging
parallel decoding in transformers to learn saliency solely from fixation maps.
Models typically rely on continuous saliency maps, to overcome the difficulty
of optimizing for the discrete fixation map. We attempt to replicate the
experimental setup that generates saliency datasets. Our approach treats
saliency prediction as a direct set prediction problem, via a global loss that
enforces unique fixations prediction through bipartite matching and a
transformer encoder-decoder architecture. By utilizing a fixed set of learned
fixation queries, the cross-attention reasons over the image features to
directly output the fixation points, distinguishing it from other modern
saliency predictors. Our approach, named Saliency TRansformer (SalTR), achieves
metric scores on par with state-of-the-art approaches on the Salicon and MIT300
benchmarks.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14076" title="Abstract">arXiv:2311.14076</a> [<a href="/pdf/2311.14076" title="Download PDF">pdf</a>, <a href="/format/2311.14076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Searching for Snippets of Open-Domain Dialogue in Task-Oriented Dialogue  Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stricker%2C+A">Armand Stricker</a>, 
<a href="/search/cs?searchtype=author&query=Paroubek%2C+P">Patrick Paroubek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Most existing dialogue corpora and models have been designed to fit into 2
predominant categories : task-oriented dialogues portray functional goals, such
as making a restaurant reservation or booking a plane ticket, while
chit-chat/open-domain dialogues focus on holding a socially engaging talk with
a user. However, humans tend to seamlessly switch between modes and even use
chitchat to enhance task-oriented conversations. To bridge this gap, new
datasets have recently been created, blending both communication modes into
conversation examples. The approaches used tend to rely on adding chit-chat
snippets to pre-existing, human-generated task-oriented datasets. Given the
tendencies observed in humans, we wonder however if the latter do not
\textit{already} hold chit-chat sequences. By using topic modeling and
searching for topics which are most similar to a set of keywords related to
social talk, we explore the training sets of Schema-Guided Dialogues and
MultiWOZ. Our study shows that sequences related to social talk are indeed
naturally present, motivating further research on ways chitchat is combined
into task-oriented dialogues.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14077" title="Abstract">arXiv:2311.14077</a> [<a href="/pdf/2311.14077" title="Download PDF">pdf</a>, <a href="/format/2311.14077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RetroDiff: Retrosynthesis as Multi-stage Distribution Interpolation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yuxuan Song</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Minkai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Weiying Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Retrosynthesis poses a fundamental challenge in biopharmaceuticals, aiming to
aid chemists in finding appropriate reactant molecules and synthetic pathways
given determined product molecules. With the reactant and product represented
as 2D graphs, retrosynthesis constitutes a conditional graph-to-graph
generative task. Inspired by the recent advancements in discrete diffusion
models for graph generation, we introduce Retrosynthesis Diffusion (RetroDiff),
a novel diffusion-based method designed to address this problem. However,
integrating a diffusion-based graph-to-graph framework while retaining
essential chemical reaction template information presents a notable challenge.
Our key innovation is to develop a multi-stage diffusion process. In this
method, we decompose the retrosynthesis procedure to first sample external
groups from the dummy distribution given products and then generate the
external bonds to connect the products and generated groups. Interestingly,
such a generation process is exactly the reverse of the widely adapted
semi-template retrosynthesis procedure, i.e. from reaction center
identification to synthon completion, which significantly reduces the error
accumulation. Experimental results on the benchmark have demonstrated the
superiority of our method over all other semi-template methods.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14078" title="Abstract">arXiv:2311.14078</a> [<a href="/pdf/2311.14078" title="Download PDF">pdf</a>, <a href="/ps/2311.14078" title="Download PostScript">ps</a>, <a href="/format/2311.14078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine learning-based decentralized TDMA for VLC IoT networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Makvandi%2C+A">Armin Makvandi</a>, 
<a href="/search/cs?searchtype=author&query=Kavian%2C+Y+S">Yousef Seifi Kavian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to Elsevier for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, a machine learning-based decentralized time division multiple
access (TDMA) algorithm for visible light communication (VLC) Internet of
Things (IoT) networks is proposed. The proposed algorithm is based on
Q-learning, a reinforcement learning algorithm. This paper considers a
decentralized condition in which there is no coordinator node for sending
synchronization frames and assigning transmission time slots to other nodes.
The proposed algorithm uses a decentralized manner for synchronization, and
each node uses the Q-learning algorithm to find the optimal transmission time
slot for sending data without collisions. The proposed algorithm is implemented
on a VLC hardware system, which had been designed and implemented in our
laboratory. Average reward, convergence time, goodput, average delay, and data
packet size are evaluated parameters. The results show that the proposed
algorithm converges quickly and provides collision-free decentralized TDMA for
the network. The proposed algorithm is compared with carrier-sense multiple
access with collision avoidance (CSMA/CA) algorithm as a potential selection
for decentralized VLC IoT networks. The results show that the proposed
algorithm provides up to 61% more goodput and up to 49% less average delay than
CSMA/CA.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14079" title="Abstract">arXiv:2311.14079</a> [<a href="/pdf/2311.14079" title="Download PDF">pdf</a>, <a href="/format/2311.14079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empirical Comparison between Cross-Validation and Mutation-Validation in  Model Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jinyang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Hamdan%2C+S">Sami Hamdan</a>, 
<a href="/search/cs?searchtype=author&query=Sasse%2C+L">Leonard Sasse</a>, 
<a href="/search/cs?searchtype=author&query=Morrison%2C+A">Abigail Morrison</a>, 
<a href="/search/cs?searchtype=author&query=Patil%2C+K+R">Kaustubh R. Patil</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Mutation validation (MV) is a recently proposed approach for model selection,
garnering significant interest due to its unique characteristics and potential
benefits compared to the widely used cross-validation (CV) method. In this
study, we empirically compared MV and $k$-fold CV using benchmark and
real-world datasets. By employing Bayesian tests, we compared generalization
estimates yielding three posterior probabilities: practical equivalence, CV
superiority, and MV superiority. We also evaluated the differences in the
capacity of the selected models and computational efficiency. We found that
both MV and CV select models with practically equivalent generalization
performance across various machine learning algorithms and the majority of
benchmark datasets. MV exhibited advantages in terms of selecting simpler
models and lower computational costs. However, in some cases MV selected overly
simplistic models leading to underfitting and showed instability in
hyperparameter selection. These limitations of MV became more evident in the
evaluation of a real-world neuroscientific task of predicting sex at birth
using brain functional connectivity.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14081" title="Abstract">arXiv:2311.14081</a> [<a href="/pdf/2311.14081" title="Download PDF">pdf</a>, <a href="/format/2311.14081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> You Only Explain Once
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kelly%2C+D+A">David A. Kelly</a>, 
<a href="/search/cs?searchtype=author&query=Chockler%2C+H">Hana Chockler</a>, 
<a href="/search/cs?searchtype=author&query=Kroening%2C+D">Daniel Kroening</a>, 
<a href="/search/cs?searchtype=author&query=Blake%2C+N">Nathan Blake</a>, 
<a href="/search/cs?searchtype=author&query=Ramaswamy%2C+A">Aditi Ramaswamy</a>, 
<a href="/search/cs?searchtype=author&query=Navaratnarajah%2C+M">Melane Navaratnarajah</a>, 
<a href="/search/cs?searchtype=author&query=Shivakumar%2C+A">Aaditya Shivakumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we propose a new black-box explainability algorithm and tool,
YO-ReX, for efficient explanation of the outputs of object detectors. The new
algorithm computes explanations for all objects detected in the image
simultaneously. Hence, compared to the baseline, the new algorithm reduces the
number of queries by a factor of 10X for the case of ten detected objects. The
speedup increases further with with the number of objects. Our experimental
results demonstrate that YO-ReX can explain the outputs of YOLO with a
negligible overhead over the running time of YOLO. We also demonstrate similar
results for explaining SSD and Faster R-CNN. The speedup is achieved by
avoiding backtracking by combining aggressive pruning with a causal analysis.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14082" title="Abstract">arXiv:2311.14082</a> [<a href="/pdf/2311.14082" title="Download PDF">pdf</a>, <a href="/format/2311.14082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometric Covering using Random Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goncalves%2C+F">Felipe Goncalves</a>, 
<a href="/search/cs?searchtype=author&query=Keren%2C+D">Daniel Keren</a>, 
<a href="/search/cs?searchtype=author&query=Shahar%2C+A">Amit Shahar</a>, 
<a href="/search/cs?searchtype=author&query=Yehuda%2C+G">Gal Yehuda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">A set of vectors $S \subseteq \mathbb{R}^d$ is
$(k_1,\varepsilon)$-clusterable if there are $k_1$ balls of radius
$\varepsilon$ that cover $S$. A set of vectors $S \subseteq \mathbb{R}^d$ is
$(k_2,\delta)$-far from being clusterable if there are at least $k_2$ vectors
in $S$, with all pairwise distances at least $\delta$. We propose a
probabilistic algorithm to distinguish between these two cases. Our algorithm
reaches a decision by only looking at the extreme values of a scalar valued
hash function, defined by a random field, on $S$; hence, it is especially
suitable in distributed and online settings. An important feature of our method
is that the algorithm is oblivious to the number of vectors: in the online
setting, for example, the algorithm stores only a constant number of scalars,
which is independent of the stream length.
<br />We introduce random field hash functions, which are a key ingredient in our
paradigm. Random field hash functions generalize locality-sensitive hashing
(LSH). In addition to the LSH requirement that ``nearby vectors are hashed to
similar values", our hash function also guarantees that the ``hash values are
(nearly) independent random variables for distant vectors". We formulate
necessary conditions for the kernels which define the random fields applied to
our problem, as well as a measure of kernel optimality, for which we provide a
bound. Then, we propose a method to construct kernels which approximate the
optimal one.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14084" title="Abstract">arXiv:2311.14084</a> [<a href="/pdf/2311.14084" title="Download PDF">pdf</a>, <a href="/format/2311.14084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-Generated Images Introduce Invisible Relevance Bias to Text-Image  Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shicheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+D">Danyang Hou</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+L">Liang Pang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jingcheng Deng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Huawei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xueqi Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">With the advancement of generation models, AI-generated content (AIGC) is
becoming more realistic, flooding the Internet. A recent study suggests that
this phenomenon has elevated the issue of source bias in text retrieval for web
searches. Specifically, neural retrieval models tend to rank generated texts
higher than human-written texts. In this paper, we extend the study of this
bias to cross-modal retrieval. Firstly, we successfully construct a suitable
benchmark to explore the existence of the bias. Subsequent extensive
experiments on this benchmark reveal that AI-generated images introduce an
invisible relevance bias to text-image retrieval models. Specifically, our
experiments show that text-image retrieval models tend to rank the AI-generated
images higher than the real images, even though the AI-generated images do not
exhibit more visually relevant features to the query than real images. This
invisible relevance bias is prevalent across retrieval models with varying
training data and architectures. Furthermore, our subsequent exploration
reveals that the inclusion of AI-generated images in the training data of the
retrieval models exacerbates the invisible relevance bias. The above phenomenon
triggers a vicious cycle, which makes the invisible relevance bias become more
and more serious. To elucidate the potential causes of invisible relevance and
address the aforementioned issues, we introduce an effective training method
aimed at alleviating the invisible relevance bias. Subsequently, we apply our
proposed debiasing method to retroactively identify the causes of invisible
relevance, revealing that the AI-generated images induce the image encoder to
embed additional information into their representation. This information
exhibits a certain consistency across generated images with different semantics
and can make the retriever estimate a higher relevance score.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14087" title="Abstract">arXiv:2311.14087</a> [<a href="/pdf/2311.14087" title="Download PDF">pdf</a>, <a href="/ps/2311.14087" title="Download PostScript">ps</a>, <a href="/format/2311.14087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Question Answering in Natural Language: the Special Case of Temporal  Expressions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stricker%2C+A">Armand Stricker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Student Research Workshop associated with RANLP-2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Although general question answering has been well explored in recent years,
temporal question answering is a task which has not received as much focus. Our
work aims to leverage a popular approach used for general question answering,
answer extraction, in order to find answers to temporal questions within a
paragraph. To train our model, we propose a new dataset, inspired by SQuAD,
specifically tailored to provide rich temporal information. We chose to adapt
the corpus WikiWars, which contains several documents on history's greatest
conflicts. Our evaluation shows that a deep learning model trained to perform
pattern matching, often used in general question answering, can be adapted to
temporal question answering, if we accept to ask questions whose answers must
be directly present within a text.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14090" title="Abstract">arXiv:2311.14090</a> [<a href="/pdf/2311.14090" title="Download PDF">pdf</a>, <a href="/format/2311.14090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Class Uncertainty: A Measure to Mitigate Class Imbalance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baltaci%2C+Z+S">Z. S. Baltaci</a>, 
<a href="/search/cs?searchtype=author&query=Oksuz%2C+K">K. Oksuz</a>, 
<a href="/search/cs?searchtype=author&query=Kuzucu%2C+S">S. Kuzucu</a>, 
<a href="/search/cs?searchtype=author&query=Tezoren%2C+K">K. Tezoren</a>, 
<a href="/search/cs?searchtype=author&query=Konar%2C+B+K">B. K. Konar</a>, 
<a href="/search/cs?searchtype=author&query=Ozkan%2C+A">A. Ozkan</a>, 
<a href="/search/cs?searchtype=author&query=Akbas%2C+E">E. Akbas</a>, 
<a href="/search/cs?searchtype=author&query=Kalkan%2C+S">S. Kalkan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Class-wise characteristics of training examples affect the performance of
deep classifiers. A well-studied example is when the number of training
examples of classes follows a long-tailed distribution, a situation that is
likely to yield sub-optimal performance for under-represented classes. This
class imbalance problem is conventionally addressed by approaches relying on
the class-wise cardinality of training examples, such as data resampling. In
this paper, we demonstrate that considering solely the cardinality of classes
does not cover all issues causing class imbalance. To measure class imbalance,
we propose "Class Uncertainty" as the average predictive uncertainty of the
training examples, and we show that this novel measure captures the differences
across classes better than cardinality. We also curate SVCI-20 as a novel
dataset in which the classes have equal number of training examples but they
differ in terms of their hardness; thereby causing a type of class imbalance
which cannot be addressed by the approaches relying on cardinality. We
incorporate our "Class Uncertainty" measure into a diverse set of ten class
imbalance mitigation methods to demonstrate its effectiveness on long-tailed
datasets as well as on our SVCI-20. Code and datasets will be made available.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14091" title="Abstract">arXiv:2311.14091</a> [<a href="/pdf/2311.14091" title="Download PDF">pdf</a>, <a href="/format/2311.14091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PortfolioMentor: Multimodal Generative AI Companion for Learning and  Crafting Interactive Digital Art Portfolios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Long%2C+T">Tao Long</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Weirui Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages, 1 figure, work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Multimedia (cs.MM)

</div>
<p class="mathjax">Digital art portfolios serve as impactful mediums for artists to convey their
visions, weaving together visuals, audio, interactions, and narratives.
However, without technical backgrounds, design students often find it
challenging to translate creative ideas into tangible codes and designs, given
the lack of tailored resources for the non-technical, academic support in art
schools, and a comprehensive guiding tool throughout the mentally demanding
process. Recognizing the role of companionship in code learning and leveraging
generative AI models' capabilities in supporting creative tasks, we present
PortfolioMentor, a coding companion chatbot for IDEs. This tool guides and
collaborates with students through proactive suggestions and responsible Q&amp;As
for learning, inspiration, and support. In detail, the system starts with the
understanding of the task and artist's visions, follows the co-creation of
visual illustrations, audio or music suggestions and files, click-scroll
effects for interactions, and creative vision conceptualization, and finally
synthesizes these facets into a polished interactive digital portfolio.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14094" title="Abstract">arXiv:2311.14094</a> [<a href="/pdf/2311.14094" title="Download PDF">pdf</a>, <a href="/format/2311.14094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Decision Aggregation with Second-order Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yuqi Pan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhaohua Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+Y">Yuqing Kong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We consider a decision aggregation problem with two experts who each make a
binary recommendation after observing a private signal about an unknown binary
world state. An agent, who does not know the joint information structure
between signals and states, sees the experts' recommendations and aims to match
the action with the true state. Under the scenario, we study whether
supplemented additionally with second-order information (each expert's forecast
on the other's recommendation) could enable a better aggregation.
<br />We adopt a minimax regret framework to evaluate the aggregator's performance,
by comparing it to an omniscient benchmark that knows the joint information
structure. With general information structures, we show that second-order
information provides no benefit. No aggregator can improve over a trivial
aggregator, which always follows the first expert's recommendation. However,
positive results emerge when we assume experts' signals are conditionally
independent given the world state. When the aggregator is deterministic, we
present a robust aggregator that leverages second-order information, which can
significantly outperform counterparts without it. Second, when two experts are
homogeneous, by adding a non-degenerate assumption on the signals, we
demonstrate that random aggregators using second-order information can surpass
optimal ones without it. In the remaining settings, the second-order
information is not beneficial. We also extend the above results to the setting
when the aggregator's utility function is more general.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14095" title="Abstract">arXiv:2311.14095</a> [<a href="/pdf/2311.14095" title="Download PDF">pdf</a>, <a href="/format/2311.14095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video Anomaly Detection using GAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sethi%2C+A">Anikeit Sethi</a>, 
<a href="/search/cs?searchtype=author&query=Saini%2C+K">Krishanu Saini</a>, 
<a href="/search/cs?searchtype=author&query=Mididoddi%2C+S+M">Sai Mounika Mididoddi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Accounting for the increased concern for public safety, automatic abnormal
event detection and recognition in a surveillance scene is crucial. It is a
current open study subject because of its intricacy and utility. The
identification of aberrant events automatically, it's a difficult undertaking
because everyone's idea of abnormality is different. A typical occurrence in
one circumstance could be seen as aberrant in another. Automatic anomaly
identification becomes particularly challenging in the surveillance footage
with a large crowd due to congestion and high occlusion. With the use of
machine learning techniques, this thesis study aims to offer the solution for
this use case so that human resources won't be required to keep an eye out for
any unusual activity in the surveillance system records. We have developed a
novel generative adversarial network (GAN) based anomaly detection model. This
model is trained such that it learns together about constructing a high
dimensional picture space and determining the latent space from the video's
context. The generator uses a residual Autoencoder architecture made up of a
multi-stage channel attention-based decoder and a two-stream, deep
convolutional encoder that can realise both spatial and temporal data. We have
also offered a technique for refining the GAN model that reduces training time
while also generalising the model by utilising transfer learning between
datasets. Using a variety of assessment measures, we compare our model to the
current state-of-the-art techniques on four benchmark datasets. The empirical
findings indicate that, in comparison to existing techniques, our network
performs favourably on all datasets.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14096" title="Abstract">arXiv:2311.14096</a> [<a href="/pdf/2311.14096" title="Download PDF">pdf</a>, <a href="/ps/2311.14096" title="Download PostScript">ps</a>, <a href="/format/2311.14096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Auditing and Mitigating Cultural Bias in LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+Y">Yan Tao</a>, 
<a href="/search/cs?searchtype=author&query=Viberg%2C+O">Olga Viberg</a>, 
<a href="/search/cs?searchtype=author&query=Baker%2C+R+S">Ryan S. Baker</a>, 
<a href="/search/cs?searchtype=author&query=Kizilcec%2C+R+F">Rene F. Kizilcec</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Culture fundamentally shapes people's reasoning, behavior, and communication.
Generative artificial intelligence (AI) technologies may cause a shift towards
a dominant culture. As people increasingly use AI to expedite and even automate
various professional and personal tasks, cultural values embedded in AI models
may bias authentic expression. We audit large language models for cultural
bias, comparing their responses to nationally representative survey data, and
evaluate country-specific prompting as a mitigation strategy. We find that
GPT-4, 3.5 and 3 exhibit cultural values resembling English-speaking and
Protestant European countries. Our mitigation strategy reduces cultural bias in
recent models but not for all countries/territories. To avoid cultural bias in
generative AI, especially in high-stakes contexts, we suggest using culture
matching and ongoing cultural audits.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14097" title="Abstract">arXiv:2311.14097</a> [<a href="/pdf/2311.14097" title="Download PDF">pdf</a>, <a href="/format/2311.14097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ACT: Adversarial Consistency Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kong%2C+F">Fei Kong</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+J">Jinhao Duan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Renjing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Hengtao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaofeng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xiaoshuang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kaidi Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Though diffusion models excel in image generation, their step-by-step
denoising leads to slow generation speeds. Consistency training addresses this
issue with single-step sampling but often produces lower-quality generations
and requires high training costs. In this paper, we show that optimizing
consistency training loss minimizes the Wasserstein distance between target and
generated distributions. As timestep increases, the upper bound accumulates
previous consistency training losses. Therefore, larger batch sizes are needed
to reduce both current and accumulated losses. We propose Adversarial
Consistency Training (ACT), which directly minimizes the Jensen-Shannon (JS)
divergence between distributions at each timestep using a discriminator.
Theoretically, ACT enhances generation quality, and convergence. By
incorporating a discriminator into the consistency training framework, our
method achieves improved FID scores on CIFAR10 and ImageNet 64$\times$64,
retains zero-shot image inpainting capabilities, and uses less than $1/6$ of
the original batch size and fewer than $1/2$ of the model parameters and
training steps compared to the baseline method, this leads to a substantial
reduction in resource consumption.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14098" title="Abstract">arXiv:2311.14098</a> [<a href="/pdf/2311.14098" title="Download PDF">pdf</a>, <a href="/format/2311.14098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lead-acid battery lifetime extension in solar home systems under  different operating conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Perriment%2C+R">Rebecca Perriment</a>, 
<a href="/search/eess?searchtype=author&query=Kumtepeli%2C+V">Volkan Kumtepeli</a>, 
<a href="/search/eess?searchtype=author&query=McCulloch%2C+M">Malcolm McCulloch</a>, 
<a href="/search/eess?searchtype=author&query=Howey%2C+D">David Howey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Solar home systems (SHS) provide low-cost electricity access for rural
off-grid communities. Batteries are a crucial part of the system, however they
are often the first point of failure due to shorter lifetimes. Using field
data, this work models the degradation of lead-acid batteries for different SHS
use-cases, finding the dominant ageing mechanisms in each case. Corrosion is
the dominant ageing mechanisms in all cases apart from the highest use case.
This is caused by extended time at high state of charge (SOC) and hence high
voltage. A new voltage control scheme is proposed for one of the use cases
dominated by corrosion, whereby the number of days between full recharges
varies depending on the degradation mechanisms the battery experiences.
Simulating the new voltage control scheme yields a 25% increase in battery
lifetime whilst ensuring no loss of load to the user.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14100" title="Abstract">arXiv:2311.14100</a> [<a href="/pdf/2311.14100" title="Download PDF">pdf</a>, <a href="/format/2311.14100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MonoNav: MAV Navigation via Monocular Depth Estimation and  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Simon%2C+N">Nathaniel Simon</a>, 
<a href="/search/cs?searchtype=author&query=Majumdar%2C+A">Anirudha Majumdar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Symposium on Experimental Robotics (ISER) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">A major challenge in deploying the smallest of Micro Aerial Vehicle (MAV)
platforms (&lt; 100 g) is their inability to carry sensors that provide
high-resolution metric depth information (e.g., LiDAR or stereo cameras).
Current systems rely on end-to-end learning or heuristic approaches that
directly map images to control inputs, and struggle to fly fast in unknown
environments. In this work, we ask the following question: using only a
monocular camera, optical odometry, and offboard computation, can we create
metrically accurate maps to leverage the powerful path planning and navigation
approaches employed by larger state-of-the-art robotic systems to achieve
robust autonomy in unknown environments? We present MonoNav: a fast 3D
reconstruction and navigation stack for MAVs that leverages recent advances in
depth prediction neural networks to enable metrically accurate 3D scene
reconstruction from a stream of monocular images and poses. MonoNav uses
off-the-shelf pre-trained monocular depth estimation and fusion techniques to
construct a map, then searches over motion primitives to plan a collision-free
trajectory to the goal. In extensive hardware experiments, we demonstrate how
MonoNav enables the Crazyflie (a 37 g MAV) to navigate fast (0.5 m/s) in
cluttered indoor environments. We evaluate MonoNav against a state-of-the-art
end-to-end approach, and find that the collision rate in navigation is
significantly reduced (by a factor of 4). This increased safety comes at the
cost of conservatism in terms of a 22% reduction in goal completion.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14101" title="Abstract">arXiv:2311.14101</a> [<a href="/pdf/2311.14101" title="Download PDF">pdf</a>, <a href="/format/2311.14101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Subnetwork Ensembles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Whitaker%2C+T">Tim Whitaker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 116 Pages, 21 figures, Accepted PhD Dissertation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Neural network ensembles have been effectively used to improve generalization
by combining the predictions of multiple independently trained models. However,
the growing scale and complexity of deep neural networks have led to these
methods becoming prohibitively expensive and time consuming to implement.
Low-cost ensemble methods have become increasingly important as they can
alleviate the need to train multiple models from scratch while retaining the
generalization benefits that traditional ensemble learning methods afford. This
dissertation introduces and formalizes a low-cost framework for constructing
Subnetwork Ensembles, where a collection of child networks are formed by
sampling, perturbing, and optimizing subnetworks from a trained parent model.
We explore several distinct methodologies for generating child networks and we
evaluate their efficacy through a variety of ablation studies and established
benchmarks. Our findings reveal that this approach can greatly improve training
efficiency, parametric utilization, and generalization performance while
minimizing computational cost. Subnetwork Ensembles offer a compelling
framework for exploring how we can build better systems by leveraging the
unrealized potential of deep neural networks.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14108" title="Abstract">arXiv:2311.14108</a> [<a href="/pdf/2311.14108" title="Download PDF">pdf</a>, <a href="/format/2311.14108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MINTY: Rule-based Models that Minimize the Need for Imputing Features  with Missing Values
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stempfle%2C+L">Lena Stempfle</a>, 
<a href="/search/cs?searchtype=author&query=Johansson%2C+F+D">Fredrik D. Johansson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Rule models are often preferred in prediction tasks with tabular inputs as
they can be easily interpreted using natural language and provide predictive
performance on par with more complex models. However, most rule models'
predictions are undefined or ambiguous when some inputs are missing, forcing
users to rely on statistical imputation models or heuristics like zero
imputation, undermining the interpretability of the models. In this work, we
propose fitting concise yet precise rule models that learn to avoid relying on
features with missing values and, therefore, limit their reliance on imputation
at test time. We develop MINTY, a method that learns rules in the form of
disjunctions between variables that act as replacements for each other when one
or more is missing. This results in a sparse linear rule model, regularized to
have small dependence on features with missing values, that allows a trade-off
between goodness of fit, interpretability, and robustness to missing values at
test time. We demonstrate the value of MINTY in experiments using synthetic and
real-world data sets and find its predictive performance comparable or
favorable to baselines, with smaller reliance on features with missing values.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14109" title="Abstract">arXiv:2311.14109</a> [<a href="/pdf/2311.14109" title="Download PDF">pdf</a>, <a href="/format/2311.14109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting the Power of Small Multimodal Reasoning Models to Match Larger  Models with Self-Consistency Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Cheng Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jingxuan Wei</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhangyang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Linzhuang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Siyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xihong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S+Z">Stan Z. Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Multimodal reasoning is a challenging task that requires models to reason
across multiple modalities to answer questions. Existing approaches have made
progress by incorporating language and visual modalities into a two-stage
reasoning framework, separating rationale generation from answer inference.
However, these approaches often fall short due to the inadequate quality of the
generated rationales. In this work, we delve into the importance of rationales
in model reasoning. We observe that when rationales are completely accurate,
the model's accuracy significantly improves, highlighting the need for
high-quality rationale generation. Motivated by this, we propose MC-CoT, a
self-consistency training strategy that generates multiple rationales and
answers, subsequently selecting the most accurate through a voting process.
This approach not only enhances the quality of generated rationales but also
leads to more accurate and robust answers. Through extensive experiments, we
demonstrate that our approach significantly improves model performance across
various benchmarks. Remarkably, we show that even smaller base models, when
equipped with our proposed approach, can achieve results comparable to those of
larger models, illustrating the potential of our approach in harnessing the
power of rationales for improved multimodal reasoning. The code is available at
https://github.com/chengtan9907/mc-cot.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14110" title="Abstract">arXiv:2311.14110</a> [<a href="/pdf/2311.14110" title="Download PDF">pdf</a>, <a href="/format/2311.14110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When is Off-Policy Evaluation Useful? A Data-Centric Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+A+J">Alex J. Chan</a>, 
<a href="/search/cs?searchtype=author&query=Seedat%2C+N">Nabeel Seedat</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%BCy%C3%BCk%2C+A">Alihan H&#xfc;y&#xfc;k</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Schaar%2C+M">Mihaela van der Schaar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Off-Policy Evaluation, Data-Centric AI, Data-Centric Reinforcement Learning, Reinforcement Learning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Evaluating the value of a hypothetical target policy with only a logged
dataset is important but challenging. On the one hand, it brings opportunities
for safe policy improvement under high-stakes scenarios like clinical
guidelines. On the other hand, such opportunities raise a need for precise
off-policy evaluation (OPE). While previous work on OPE focused on improving
the algorithm in value estimation, in this work, we emphasize the importance of
the offline dataset, hence putting forward a data-centric framework for
evaluating OPE problems. We propose DataCOPE, a data-centric framework for
evaluating OPE, that answers the questions of whether and to what extent we can
evaluate a target policy given a dataset. DataCOPE (1) forecasts the overall
performance of OPE algorithms without access to the environment, which is
especially useful before real-world deployment where evaluating OPE is
impossible; (2) identifies the sub-group in the dataset where OPE can be
inaccurate; (3) permits evaluations of datasets or data-collection strategies
for OPE problems. Our empirical analysis of DataCOPE in the logged contextual
bandit settings using healthcare datasets confirms its ability to evaluate both
machine-learning and human expert policies like clinical guidelines.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14114" title="Abstract">arXiv:2311.14114</a> [<a href="/pdf/2311.14114" title="Download PDF">pdf</a>, <a href="/format/2311.14114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SySMOL: A Hardware-software Co-design Framework for Ultra-Low and  Fine-Grained Mixed-Precision Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Cyrus Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Richard%2C+V">Vaughn Richard</a>, 
<a href="/search/cs?searchtype=author&query=Savarese%2C+P">Pedro Savarese</a>, 
<a href="/search/cs?searchtype=author&query=Hassman%2C+Z">Zachary Hassman</a>, 
<a href="/search/cs?searchtype=author&query=Maire%2C+M">Michael Maire</a>, 
<a href="/search/cs?searchtype=author&query=DiBrino%2C+M">Michael DiBrino</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanjing Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Machine Learning (cs.LG); Performance (cs.PF)

</div>
<p class="mathjax">Recent advancements in quantization and mixed-precision techniques offer
significant promise for improving the run-time and energy efficiency of neural
networks. In this work, we further showed that neural networks, wherein
individual parameters or activations can take on different precisions ranging
between 1 and 4 bits, can achieve accuracies comparable to or exceeding the
full-precision counterparts. However, the deployment of such networks poses
numerous challenges, stemming from the necessity to manage and control the
compute/communication/storage requirements associated with these extremely
fine-grained mixed precisions for each piece of data. There is a lack of
existing efficient hardware and system-level support tailored to these unique
and challenging requirements. Our research introduces the first novel holistic
hardware-software co-design approach for these networks, which enables a
continuous feedback loop between hardware design, training, and inference to
facilitate systematic design exploration. As a proof-of-concept, we illustrate
this co-design approach by designing new, configurable CPU SIMD architectures
tailored for these networks, tightly integrating the architecture with new
system-aware training and inference techniques. We perform systematic design
space exploration using this framework to analyze various tradeoffs. The design
for mixed-precision networks that achieves optimized tradeoffs corresponds to
an architecture that supports 1, 2, and 4-bit fixed-point operations with four
configurable precision patterns, when coupled with system-aware training and
inference optimization -- networks trained for this design achieve accuracies
that closely match full-precision accuracies, while compressing and improving
run-time efficiency of the neural networks drastically by 10-20x, compared to
full-precision networks.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14115" title="Abstract">arXiv:2311.14115</a> [<a href="/pdf/2311.14115" title="Download PDF">pdf</a>, <a href="/format/2311.14115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A density estimation perspective on learning from pairwise human  preferences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dumoulin%2C+V">Vincent Dumoulin</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+D+D">Daniel D. Johnson</a>, 
<a href="/search/cs?searchtype=author&query=Castro%2C+P+S">Pablo Samuel Castro</a>, 
<a href="/search/cs?searchtype=author&query=Larochelle%2C+H">Hugo Larochelle</a>, 
<a href="/search/cs?searchtype=author&query=Dauphin%2C+Y">Yann Dauphin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Learning from human feedback (LHF) -- and in particular learning from
pairwise preferences -- has recently become a crucial ingredient in training
large language models (LLMs), and has been the subject of much research. Most
recent works frame it as a reinforcement learning problem, where a reward
function is learned from pairwise preference data and the LLM is treated as a
policy which is adapted to maximize the rewards, often under additional
regularization constraints. We propose an alternative interpretation which
centers on the generative process for pairwise preferences and treats LHF as a
density estimation problem. We provide theoretical and empirical results
showing that for a family of generative processes defined via preference
behavior distribution equations, training a reward function on pairwise
preferences effectively models an annotator's implicit preference distribution.
Finally, we discuss and present findings on "annotator misspecification" --
failure cases where wrong modeling assumptions are made about annotator
behavior, resulting in poorly-adapted models -- suggesting that approaches that
learn from pairwise human preferences could have trouble learning from a
population of annotators with diverse viewpoints.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14116" title="Abstract">arXiv:2311.14116</a> [<a href="/pdf/2311.14116" title="Download PDF">pdf</a>, <a href="/format/2311.14116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Coded Gradient Aggregation Based on Layered MDS Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krishnan%2C+M+N">M. Nikhil Krishnan</a>, 
<a href="/search/cs?searchtype=author&query=Thomas%2C+A">Anoop Thomas</a>, 
<a href="/search/cs?searchtype=author&query=Sasidharan%2C+B">Birenjith Sasidharan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at 2023 IEEE International Symposium on Information Theory (ISIT)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">The growing privacy concerns and the communication costs associated with
transmitting raw data have resulted in techniques like federated learning,
where the machine learning models are trained at the edge nodes, and the
parameter updates are shared with a central server. Because communications from
the edge nodes are often unreliable, a hierarchical setup involving
intermediate helper nodes is considered. The communication links between the
edges and the helper nodes are error-prone and are modeled as
straggling/failing links. To overcome the issue of link failures, coding
techniques are proposed. The edge nodes communicate encoded versions of the
model updates to the helper nodes, which pass them on to the master after
suitable aggregation. The primary work in this area uses repetition codes and
Maximum Distance Separable (MDS) codes at the edge nodes to arrive at the
Aligned Repetition Coding (ARC) and Aligned MDS Coding (AMC) schemes,
respectively. We propose using vector codes, specifically a family of layered
MDS codes parameterized by a variable $\nu$, at the edge nodes. For the
proposed family of codes, suitable aggregation strategies at the helper nodes
are also developed. At the extreme values of $\nu$, our scheme matches the
communication costs incurred by the ARC and AMC schemes, resulting in a
graceful transition between these schemes.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14118" title="Abstract">arXiv:2311.14118</a> [<a href="/pdf/2311.14118" title="Download PDF">pdf</a>, <a href="/format/2311.14118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On The Impact of Replacing Private Cars with Autonomous Shuttles: An  Agent-Based Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bogdoll%2C+D">Daniel Bogdoll</a>, 
<a href="/search/cs?searchtype=author&query=Karsch%2C+L">Louis Karsch</a>, 
<a href="/search/cs?searchtype=author&query=Amritzer%2C+J">Jennifer Amritzer</a>, 
<a href="/search/cs?searchtype=author&query=Z%C3%B6llner%2C+J+M">J. Marius Z&#xf6;llner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Daniel Bogdoll nd Louis Karsch contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The European Green Deal aims to achieve climate neutrality by 2050, requiring
the transportation industry to improve emission efficiency as it accounts for
20% of global CO2 emissions. This study uses an agent-based simulation to
analyze the sustainability impacts of shared autonomous shuttles. We forecast
travel demands for 2050 and simulate regulatory interventions in the form of
replacing private cars with a fleet of shared autonomous shuttles in specific
areas. We derive driving-related emissions, energy consumption, and
non-driving-related emissions to calculate life-cycle emissions. We observe
reduced life-cycle emissions from 0.4% to 9.6% and reduced energy consumption
from 1.5% to 12.2%.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14120" title="Abstract">arXiv:2311.14120</a> [<a href="/pdf/2311.14120" title="Download PDF">pdf</a>, <a href="/format/2311.14120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weight fluctuations in (deep) linear neural networks and a derivation of  the inverse-variance flatness relation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gross%2C+M">Markus Gross</a>, 
<a href="/search/cs?searchtype=author&query=Raulf%2C+A+P">Arne P. Raulf</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%A4th%2C+C">Christoph R&#xe4;th</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Statistical Mechanics (cond-mat.stat-mech)

</div>
<p class="mathjax">We investigate the stationary (late-time) training regime of single- and
two-layer linear neural networks within the continuum limit of stochastic
gradient descent (SGD) for synthetic Gaussian data. In the case of a
single-layer network in the weakly oversampled regime, the spectrum of the
noise covariance matrix deviates notably from the Hessian, which can be
attributed to the broken detailed balance of SGD dynamics. The weight
fluctuations are in this case generally anisotropic, but experience an
isotropic loss. For a two-layer network, we obtain the stochastic dynamics of
the weights in each layer and analyze the associated stationary covariances. We
identify the inter-layer coupling as a new source of anisotropy for the weight
fluctuations. In contrast to the single-layer case, the weight fluctuations
experience an anisotropic loss, the flatness of which is inversely related to
the fluctuation variance. We thereby provide an analytical derivation of the
recently observed inverse variance-flatness relation in a deep linear network
model.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14125" title="Abstract">arXiv:2311.14125</a> [<a href="/pdf/2311.14125" title="Download PDF">pdf</a>, <a href="/format/2311.14125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable AI Safety via Doubly-Efficient Debate
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brown-Cohen%2C+J">Jonah Brown-Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Irving%2C+G">Geoffrey Irving</a>, 
<a href="/search/cs?searchtype=author&query=Piliouras%2C+G">Georgios Piliouras</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The emergence of pre-trained AI systems with powerful capabilities across a
diverse and ever-increasing set of complex domains has raised a critical
challenge for AI safety as tasks can become too complicated for humans to judge
directly. Irving et al. [2018] proposed a debate method in this direction with
the goal of pitting the power of such AI models against each other until the
problem of identifying (mis)-alignment is broken down into a manageable
subtask. While the promise of this approach is clear, the original framework
was based on the assumption that the honest strategy is able to simulate
deterministic AI systems for an exponential number of steps, limiting its
applicability. In this paper, we show how to address these challenges by
designing a new set of debate protocols where the honest strategy can always
succeed using a simulation of a polynomial number of steps, whilst being able
to verify the alignment of stochastic AI systems, even when the dishonest
strategy is allowed to use exponentially many simulation steps.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14126" title="Abstract">arXiv:2311.14126</a> [<a href="/pdf/2311.14126" title="Download PDF">pdf</a>, <a href="/ps/2311.14126" title="Download PostScript">ps</a>, <a href="/format/2311.14126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Auditing Large Language Models: Improving Text-based Stereotype  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zekun%2C+W">Wu Zekun</a>, 
<a href="/search/cs?searchtype=author&query=Bulathwela%2C+S">Sahan Bulathwela</a>, 
<a href="/search/cs?searchtype=author&query=Koshiyama%2C+A+S">Adriano Soares Koshiyama</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 NeurIPS SoLaR Workshop Accepted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models (LLM) have made significant advances in the recent past
becoming more mainstream in Artificial Intelligence (AI) enabled human-facing
applications. However, LLMs often generate stereotypical output inherited from
historical data, amplifying societal biases and raising ethical concerns. This
work introduces i) the Multi-Grain Stereotype Dataset, which includes 52,751
instances of gender, race, profession and religion stereotypic text and ii) a
novel stereotype classifier for English text. We design several experiments to
rigorously test the proposed model trained on the novel dataset. Our
experiments show that training the model in a multi-class setting can
outperform the one-vs-all binary counterpart. Consistent feature importance
signals from different eXplainable AI tools demonstrate that the new model
exploits relevant text features. We utilise the newly created model to assess
the stereotypic behaviour of the popular GPT family of models and observe the
reduction of bias over time. In summary, our work establishes a robust and
practical framework for auditing and evaluating the stereotypic bias in LLM.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14127" title="Abstract">arXiv:2311.14127</a> [<a href="/pdf/2311.14127" title="Download PDF">pdf</a>, <a href="/format/2311.14127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Byzantine Robustness and Partial Participation Can Be Achieved  Simultaneously: Just Clip Gradient Differences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malinovsky%2C+G">Grigory Malinovsky</a>, 
<a href="/search/cs?searchtype=author&query=Richt%C3%A1rik%2C+P">Peter Richt&#xe1;rik</a>, 
<a href="/search/cs?searchtype=author&query=Horv%C3%A1th%2C+S">Samuel Horv&#xe1;th</a>, 
<a href="/search/cs?searchtype=author&query=Gorbunov%2C+E">Eduard Gorbunov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 50 pages; 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Optimization and Control (math.OC)

</div>
<p class="mathjax">Distributed learning has emerged as a leading paradigm for training large
machine learning models. However, in real-world scenarios, participants may be
unreliable or malicious, posing a significant challenge to the integrity and
accuracy of the trained models. Byzantine fault tolerance mechanisms have been
proposed to address these issues, but they often assume full participation from
all clients, which is not always practical due to the unavailability of some
clients or communication constraints. In our work, we propose the first
distributed method with client sampling and provable tolerance to Byzantine
workers. The key idea behind the developed method is the use of gradient
clipping to control stochastic gradient differences in recursive variance
reduction. This allows us to bound the potential harm caused by Byzantine
workers, even during iterations when all sampled clients are Byzantine.
Furthermore, we incorporate communication compression into the method to
enhance communication efficiency. Under quite general assumptions, we prove
convergence rates for the proposed method that match the existing
state-of-the-art (SOTA) theoretical results.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14131" title="Abstract">arXiv:2311.14131</a> [<a href="/pdf/2311.14131" title="Download PDF">pdf</a>, <a href="/format/2311.14131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exactly conservative physics-informed neural networks and deep operator  networks for dynamical systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cardoso-Bihlo%2C+E">Elsa Cardoso-Bihlo</a>, 
<a href="/search/cs?searchtype=author&query=Bihlo%2C+A">Alex Bihlo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures, 1 algorithm
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">We introduce a method for training exactly conservative physics-informed
neural networks and physics-informed deep operator networks for dynamical
systems. The method employs a projection-based technique that maps a candidate
solution learned by the neural network solver for any given dynamical system
possessing at least one first integral onto an invariant manifold. We
illustrate that exactly conservative physics-informed neural network solvers
and physics-informed deep operator networks for dynamical systems vastly
outperform their non-conservative counterparts for several real-world problems
from the mathematical sciences.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14134" title="Abstract">arXiv:2311.14134</a> [<a href="/pdf/2311.14134" title="Download PDF">pdf</a>, <a href="/format/2311.14134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimizing Corners in Colored Rectilinear Grids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Depian%2C+T">Thomas Depian</a>, 
<a href="/search/cs?searchtype=author&query=Dobler%2C+A">Alexander Dobler</a>, 
<a href="/search/cs?searchtype=author&query=Kern%2C+C">Christoph Kern</a>, 
<a href="/search/cs?searchtype=author&query=Wulms%2C+J">Jules Wulms</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in the Proceedings of the 18th International Conference and Workshops on Algorithms and Computation (WALCOM 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">Given a rectilinear grid $G$, in which cells are either assigned a single
color, out of $k$ possible colors, or remain white, can we color white grid
cells of $G$ to minimize the total number of corners of the resulting colored
rectilinear polygons in $G$? We show how this problem relates to hypergraph
visualization, prove that it is NP-hard even for $k=2$, and present an exact
dynamic programming algorithm. Together with a set of simple kernelization
rules, this leads to an FPT-algorithm in the number of colored cells of the
input. We additionally provide an XP-algorithm in the solution size, and a
polynomial $\mathcal{O}(OPT)$-approximation algorithm.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14136" title="Abstract">arXiv:2311.14136</a> [<a href="/pdf/2311.14136" title="Download PDF">pdf</a>, <a href="/format/2311.14136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Blockchain Solution for Collaborative Machine Learning over IoT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beis-Penedo%2C+C">Carlos Beis-Penedo</a>, 
<a href="/search/cs?searchtype=author&query=Troncoso-Pastoriza%2C+F">Francisco Troncoso-Pastoriza</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz-Redondo%2C+R+P">Rebeca P. D&#xed;az-Redondo</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez-Vilas%2C+A">Ana Fern&#xe1;ndez-Vilas</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez-Veiga%2C+M">Manuel Fern&#xe1;ndez-Veiga</a>, 
<a href="/search/cs?searchtype=author&query=Soto%2C+M+G">Mart&#xed;n Gonz&#xe1;lez Soto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">The rapid growth of Internet of Things (IoT) devices and applications has led
to an increased demand for advanced analytics and machine learning techniques
capable of handling the challenges associated with data privacy, security, and
scalability. Federated learning (FL) and blockchain technologies have emerged
as promising approaches to address these challenges by enabling decentralized,
secure, and privacy-preserving model training on distributed data sources. In
this paper, we present a novel IoT solution that combines the incremental
learning vector quantization algorithm (XuILVQ) with Ethereum blockchain
technology to facilitate secure and efficient data sharing, model training, and
prototype storage in a distributed environment. Our proposed architecture
addresses the shortcomings of existing blockchain-based FL solutions by
reducing computational and communication overheads while maintaining data
privacy and security. We assess the performance of our system through a series
of experiments, showcasing its potential to enhance the accuracy and efficiency
of machine learning tasks in IoT settings.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14137" title="Abstract">arXiv:2311.14137</a> [<a href="/pdf/2311.14137" title="Download PDF">pdf</a>, <a href="/format/2311.14137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy-Preserving Algorithmic Recourse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pentyala%2C+S">Sikha Pentyala</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+S">Shubham Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Kariyappa%2C+S">Sanjay Kariyappa</a>, 
<a href="/search/cs?searchtype=author&query=Lecue%2C+F">Freddy Lecue</a>, 
<a href="/search/cs?searchtype=author&query=Magazzeni%2C+D">Daniele Magazzeni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at 3rd International Workshop on Explainable AI in Finance, ICAIF 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">When individuals are subject to adverse outcomes from machine learning
models, providing a recourse path to help achieve a positive outcome is
desirable. Recent work has shown that counterfactual explanations - which can
be used as a means of single-step recourse - are vulnerable to privacy issues,
putting an individuals' privacy at risk. Providing a sequential multi-step path
for recourse can amplify this risk. Furthermore, simply adding noise to
recourse paths found from existing methods can impact the realism and
actionability of the path for an end-user. In this work, we address privacy
issues when generating realistic recourse paths based on instance-based
counterfactual explanations, and provide PrivRecourse: an end-to-end privacy
preserving pipeline that can provide realistic recourse paths. PrivRecourse
uses differentially private (DP) clustering to represent non-overlapping
subsets of the private dataset. These DP cluster centers are then used to
generate recourse paths by forming a graph with cluster centers as the nodes,
so that we can generate realistic - feasible and actionable - recourse paths.
We empirically evaluate our approach on finance datasets and compare it to
simply adding noise to data instances, and to using DP synthetic data, to
generate the graph. We observe that PrivRecourse can provide paths that are
private and realistic.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14139" title="Abstract">arXiv:2311.14139</a> [<a href="/pdf/2311.14139" title="Download PDF">pdf</a>, <a href="/ps/2311.14139" title="Download PostScript">ps</a>, <a href="/format/2311.14139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning For An Explainable Cost Prediction of Medical Insurance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Orji%2C+U">Ugochukwu Orji</a>, 
<a href="/search/cs?searchtype=author&query=Ukwandu%2C+E">Elochukwu Ukwandu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages, 16 figures and 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Predictive modeling in healthcare continues to be an active actuarial
research topic as more insurance companies aim to maximize the potential of
Machine Learning approaches to increase their productivity and efficiency. In
this paper, the authors deployed three regression-based ensemble ML models that
combine variations of decision trees through Extreme Gradient Boosting,
Gradient-boosting Machine, and Random Forest) methods in predicting medical
insurance costs. Explainable Artificial Intelligence methods SHapley Additive
exPlanations and Individual Conditional Expectation plots were deployed to
discover and explain the key determinant factors that influence medical
insurance premium prices in the dataset. The dataset used comprised 986 records
and is publicly available in the KAGGLE repository. The models were evaluated
using four performance evaluation metrics, including R-squared, Mean Absolute
Error, Root Mean Squared Error, and Mean Absolute Percentage Error. The results
show that all models produced impressive outcomes; however, the XGBoost model
achieved a better overall performance although it also expanded more
computational resources, while the RF model recorded a lesser prediction error
and consumed far fewer computing resources than the XGBoost model. Furthermore,
we compared the outcome of both XAi methods in identifying the key determinant
features that influenced the PremiumPrices for each model and whereas both XAi
methods produced similar outcomes, we found that the ICE plots showed in more
detail the interactions between each variable than the SHAP analysis which
seemed to be more high-level. It is the aim of the authors that the
contributions of this study will help policymakers, insurers, and potential
medical insurance buyers in their decision-making process for selecting the
right policies that meet their specific needs.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14145" title="Abstract">arXiv:2311.14145</a> [<a href="/pdf/2311.14145" title="Download PDF">pdf</a>, <a href="/format/2311.14145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Agent Motion Planning with B&#xe9;zier Curve Optimization under  Kinodynamic Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Jingtian Yan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiaoyang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Multi-Agent Motion Planning (MAMP) is a problem that seeks collision-free
dynamically-feasible trajectories for multiple moving agents in a known
environment while minimizing their travel time. MAMP is closely related to the
well-studied Multi-Agent Path-Finding (MAPF) problem. Recently, MAPF methods
have achieved great success in finding collision-free paths for a substantial
number of agents. However, those methods often overlook the kinodynamic
constraints of the agents, assuming instantaneous movement, which limits their
practicality and realism. In this paper, we present a three-level MAPF-based
planner called PSB to address the challenges posed by MAMP. PSB fully considers
the kinodynamic capability of the agents and produces solutions with smooth
speed profiles that can be directly executed by the controller. Empirically, we
evaluate PSB within the domains of traffic intersection coordination for
autonomous vehicles and obstacle-rich grid map navigation for mobile robots.
PSB shows up to 49.79% improvements in solution cost compared to existing
methods.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14146" title="Abstract">arXiv:2311.14146</a> [<a href="/pdf/2311.14146" title="Download PDF">pdf</a>, <a href="/format/2311.14146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Class Balanced Dynamic Acquisition for Domain Adaptive Semantic  Segmentation using Active Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schachtsiek%2C+M">Marc Schachtsiek</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+S">Simone Rossi</a>, 
<a href="/search/cs?searchtype=author&query=Hannagan%2C+T">Thomas Hannagan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Workshop on Adaptive Experimental Design and Active Learning in the Real World
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Domain adaptive active learning is leading the charge in label-efficient
training of neural networks. For semantic segmentation, state-of-the-art models
jointly use two criteria of uncertainty and diversity to select training
labels, combined with a pixel-wise acquisition strategy. However, we show that
such methods currently suffer from a class imbalance issue which degrades their
performance for larger active learning budgets. We then introduce Class
Balanced Dynamic Acquisition (CBDA), a novel active learning method that
mitigates this issue, especially in high-budget regimes. The more balanced
labels increase minority class performance, which in turn allows the model to
outperform the previous baseline by 0.6, 1.7, and 2.4 mIoU for budgets of 5%,
10%, and 20%, respectively. Additionally, the focus on minority classes leads
to improvements of the minimum class performance of 0.5, 2.9, and 4.6 IoU
respectively. The top-performing model even exceeds the fully supervised
baseline, showing that a more balanced label than the entire ground truth can
be beneficial.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14153" title="Abstract">arXiv:2311.14153</a> [<a href="/pdf/2311.14153" title="Download PDF">pdf</a>, <a href="/format/2311.14153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tube-NeRF: Efficient Imitation Learning of Visuomotor Policies from MPC  using Tube-Guided Data Augmentation and NeRFs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tagliabue%2C+A">Andrea Tagliabue</a>, 
<a href="/search/cs?searchtype=author&query=How%2C+J+P">Jonathan P. How</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Video: <a href="https://youtu.be/_W5z33ZK1m4.">this https URL</a> Evolved paper from our previous work: <a href="/abs/2210.10127">arXiv:2210.10127</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Imitation learning (IL) can train computationally-efficient sensorimotor
policies from a resource-intensive Model Predictive Controller (MPC), but it
often requires many samples, leading to long training times or limited
robustness. To address these issues, we combine IL with a variant of robust MPC
that accounts for process and sensing uncertainties, and we design a data
augmentation (DA) strategy that enables efficient learning of vision-based
policies. The proposed DA method, named Tube-NeRF, leverages Neural Radiance
Fields (NeRFs) to generate novel synthetic images, and uses properties of the
robust MPC (the tube) to select relevant views and to efficiently compute the
corresponding actions. We tailor our approach to the task of localization and
trajectory tracking on a multirotor, by learning a visuomotor policy that
generates control actions using images from the onboard camera as only source
of horizontal position. Our evaluations numerically demonstrate learning of a
robust visuomotor policy with an 80-fold increase in demonstration efficiency
and a 50% reduction in training time over current IL methods. Additionally, our
policies successfully transfer to a real multirotor, achieving accurate
localization and low tracking errors despite large disturbances, with an
onboard inference time of only 1.5 ms.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14155" title="Abstract">arXiv:2311.14155</a> [<a href="/pdf/2311.14155" title="Download PDF">pdf</a>, <a href="/format/2311.14155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GigaPose: Fast and Robust Novel Object Pose Estimation via One  Correspondence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V+N">Van Nguyen Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Groueix%2C+T">Thibault Groueix</a>, 
<a href="/search/cs?searchtype=author&query=Salzmann%2C+M">Mathieu Salzmann</a>, 
<a href="/search/cs?searchtype=author&query=Lepetit%2C+V">Vincent Lepetit</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present GigaPose, a fast, robust, and accurate method for CAD-based novel
object pose estimation in RGB images. GigaPose first leverages discriminative
templates, rendered images of the CAD models, to recover the out-of-plane
rotation and then uses patch correspondences to estimate the four remaining
parameters. Our approach samples templates in only a two-degrees-of-freedom
space instead of the usual three and matches the input image to the templates
using fast nearest neighbor search in feature space, results in a speedup
factor of 38x compared to the state of the art. Moreover, GigaPose is
significantly more robust to segmentation errors. Our extensive evaluation on
the seven core datasets of the BOP challenge demonstrates that it achieves
state-of-the-art accuracy and can be seamlessly integrated with a refinement
method. Additionally, we show the potential of GigaPose with 3D models
predicted by recent work on 3D reconstruction from a single image, relaxing the
need for CAD models and making 6D pose object estimation much more convenient.
Our source code and trained models are publicly available at
https://github.com/nv-nguyen/gigaPose
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14156" title="Abstract">arXiv:2311.14156</a> [<a href="/pdf/2311.14156" title="Download PDF">pdf</a>, <a href="/format/2311.14156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variational Annealing on Graphs for Combinatorial Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sanokowski%2C+S">Sebastian Sanokowski</a>, 
<a href="/search/cs?searchtype=author&query=Berghammer%2C+W">Wilhelm Berghammer</a>, 
<a href="/search/cs?searchtype=author&query=Hochreiter%2C+S">Sepp Hochreiter</a>, 
<a href="/search/cs?searchtype=author&query=Lehner%2C+S">Sebastian Lehner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Discrete Mathematics (cs.DM); Machine Learning (stat.ML)

</div>
<p class="mathjax">Several recent unsupervised learning methods use probabilistic approaches to
solve combinatorial optimization (CO) problems based on the assumption of
statistically independent solution variables. We demonstrate that this
assumption imposes performance limitations in particular on difficult problem
instances. Our results corroborate that an autoregressive approach which
captures statistical dependencies among solution variables yields superior
performance on many popular CO problems. We introduce subgraph tokenization in
which the configuration of a set of solution variables is represented by a
single token. This tokenization technique alleviates the drawback of the long
sequential sampling procedure which is inherent to autoregressive methods
without sacrificing expressivity. Importantly, we theoretically motivate an
annealed entropy regularization and show empirically that it is essential for
efficient and stable learning.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14169" title="Abstract">arXiv:2311.14169</a> [<a href="/pdf/2311.14169" title="Download PDF">pdf</a>, <a href="/format/2311.14169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating GPT-4&#x27;s Vision Capabilities on Brazilian University Admission  Exams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pires%2C+R">Ramon Pires</a>, 
<a href="/search/cs?searchtype=author&query=Almeida%2C+T+S">Thales Sales Almeida</a>, 
<a href="/search/cs?searchtype=author&query=Abonizio%2C+H">Hugo Abonizio</a>, 
<a href="/search/cs?searchtype=author&query=Nogueira%2C+R">Rodrigo Nogueira</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2303.17003">arXiv:2303.17003</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advancements in language models have showcased human-comparable
performance in academic entrance exams. However, existing studies often
overlook questions that require the integration of visual comprehension, thus
compromising the full spectrum and complexity inherent in real-world scenarios.
To address this gap, we present a comprehensive framework to evaluate language
models on entrance exams, which incorporates both textual and visual elements.
We evaluate the two most recent editions of Exame Nacional do Ensino M\'edio
(ENEM), the main standardized entrance examination adopted by Brazilian
universities. Our study not only reaffirms the capabilities of GPT-4 as the
state of the art for handling complex multidisciplinary questions, but also
pioneers in offering a realistic assessment of multimodal language models on
Portuguese examinations. One of the highlights is that text captions
transcribing visual content outperform the direct use of images, suggesting
that the vision model has room for improvement. Yet, despite improvements
afforded by images or captions, mathematical questions remain a challenge for
these state-of-the-art models. The code and data used on experiments are
available at https://github.com/piresramon/gpt-4-enem.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14171" title="Abstract">arXiv:2311.14171</a> [<a href="/pdf/2311.14171" title="Download PDF">pdf</a>, <a href="/ps/2311.14171" title="Download PostScript">ps</a>, <a href="/format/2311.14171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenMP behavior in low resource and high stress mobile environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaijun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>

</div>
<p class="mathjax">This paper investigates the use of OpenMP for parallel post processing in
obejct detection on personal Android devices, where resources like
computational power, memory, and battery are limited. Specifically, it explores
various configurations of thread count, CPU affinity, and chunk size on a Redmi
Note 10 Pro with an ARM Cortex A76 CPU. The study finds that using four threads
offers a maximum post processing speedup of 2.3x but increases overall
inference time by 2.7x. A balanced configuration of two threads achieves a 1.8x
speedup in post processing and a 2% improvement in overall program performance.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14175" title="Abstract">arXiv:2311.14175</a> [<a href="/pdf/2311.14175" title="Download PDF">pdf</a>, <a href="/format/2311.14175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Appearance-based gaze estimation enhanced with synthetic images using  deep neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Herashchenko%2C+D">Dmytro Herashchenko</a>, 
<a href="/search/cs?searchtype=author&query=Farka%C5%A1%2C+I">Igor Farka&#x161;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 10 figures, accepted to 2023 IEEE Symposium Series on Computational Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Human eye gaze estimation is an important cognitive ingredient for successful
human-robot interaction, enabling the robot to read and predict human behavior.
We approach this problem using artificial neural networks and build a modular
system estimating gaze from separately cropped eyes, taking advantage of
existing well-functioning components for face detection (RetinaFace) and head
pose estimation (6DRepNet). Our proposed method does not require any special
hardware or infrared filters but uses a standard notebook-builtin RGB camera,
as often approached with appearance-based methods. Using the MetaHuman tool, we
also generated a large synthetic dataset of more than 57,000 human faces and
made it publicly available. The inclusion of this dataset (with eye gaze and
head pose information) on top of the standard Columbia Gaze dataset into
training the model led to better accuracy with a mean average error below two
degrees in eye pitch and yaw directions, which compares favourably to related
methods. We also verified the feasibility of our model by its preliminary
testing in real-world setting using the builtin 4K camera in NICO semi-humanoid
robot's eye.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14177" title="Abstract">arXiv:2311.14177</a> [<a href="/pdf/2311.14177" title="Download PDF">pdf</a>, <a href="/format/2311.14177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TCuPGAN: A novel framework developed for optimizing human-machine  interactions in citizen science
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sankar%2C+R">Ramanakumar Sankar</a>, 
<a href="/search/cs?searchtype=author&query=Mantha%2C+K">Kameswara Mantha</a>, 
<a href="/search/cs?searchtype=author&query=Fortson%2C+L">Lucy Fortson</a>, 
<a href="/search/cs?searchtype=author&query=Spiers%2C+H">Helen Spiers</a>, 
<a href="/search/cs?searchtype=author&query=Pengo%2C+T">Thomas Pengo</a>, 
<a href="/search/cs?searchtype=author&query=Mashek%2C+D">Douglas Mashek</a>, 
<a href="/search/cs?searchtype=author&query=Mo%2C+M">Myat Mo</a>, 
<a href="/search/cs?searchtype=author&query=Sanders%2C+M">Mark Sanders</a>, 
<a href="/search/cs?searchtype=author&query=Christensen%2C+T">Trace Christensen</a>, 
<a href="/search/cs?searchtype=author&query=Salisbury%2C+J">Jeffrey Salisbury</a>, 
<a href="/search/cs?searchtype=author&query=Trouille%2C+L">Laura Trouille</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 1 figure, accepted for publication at HLDM '23 (ECML PKDD 2023 workshop)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">In the era of big data in scientific research, there is a necessity to
leverage techniques which reduce human effort in labeling and categorizing
large datasets by involving sophisticated machine tools. To combat this
problem, we present a novel, general purpose model for 3D segmentation that
leverages patch-wise adversariality and Long Short-Term Memory to encode
sequential information. Using this model alongside citizen science projects
which use 3D datasets (image cubes) on the Zooniverse platforms, we propose an
iterative human-machine optimization framework where only a fraction of the 2D
slices from these cubes are seen by the volunteers. We leverage the patch-wise
discriminator in our model to provide an estimate of which slices within these
image cubes have poorly generalized feature representations, and
correspondingly poor machine performance. These images with corresponding
machine proposals would be presented to volunteers on Zooniverse for
correction, leading to a drastic reduction in the volunteer effort on citizen
science projects. We trained our model on ~2300 liver tissue 3D electron
micrographs. Lipid droplets were segmented within these images through human
annotation via the `Etch A Cell - Fat Checker' citizen science project, hosted
on the Zooniverse platform. In this work, we demonstrate this framework and the
selection methodology which resulted in a measured reduction in volunteer
effort by more than 60%. We envision this type of joint human-machine
partnership will be of great use on future Zooniverse projects.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14182" title="Abstract">arXiv:2311.14182</a> [<a href="/pdf/2311.14182" title="Download PDF">pdf</a>, <a href="/format/2311.14182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient-based bilevel optimization for multi-penalty Ridge regression  through matrix differential calculus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maroni%2C+G">Gabriele Maroni</a>, 
<a href="/search/cs?searchtype=author&query=Cannelli%2C+L">Loris Cannelli</a>, 
<a href="/search/cs?searchtype=author&query=Piga%2C+D">Dario Piga</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Common regularization algorithms for linear regression, such as LASSO and
Ridge regression, rely on a regularization hyperparameter that balances the
tradeoff between minimizing the fitting error and the norm of the learned model
coefficients. As this hyperparameter is scalar, it can be easily selected via
random or grid search optimizing a cross-validation criterion. However, using a
scalar hyperparameter limits the algorithm's flexibility and potential for
better generalization. In this paper, we address the problem of linear
regression with l2-regularization, where a different regularization
hyperparameter is associated with each input variable. We optimize these
hyperparameters using a gradient-based approach, wherein the gradient of a
cross-validation criterion with respect to the regularization hyperparameters
is computed analytically through matrix differential calculus. Additionally, we
introduce two strategies tailored for sparse model learning problems aiming at
reducing the risk of overfitting to the validation data. Numerical examples
demonstrate that our multi-hyperparameter regularization approach outperforms
LASSO, Ridge, and Elastic Net regression. Moreover, the analytical computation
of the gradient proves to be more efficient in terms of computational time
compared to automatic differentiation, especially when handling a large number
of input variables. Application to the identification of over-parameterized
Linear Parameter-Varying models is also presented.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14186" title="Abstract">arXiv:2311.14186</a> [<a href="/pdf/2311.14186" title="Download PDF">pdf</a>, <a href="/ps/2311.14186" title="Download PostScript">ps</a>, <a href="/format/2311.14186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anyone Can Code: Algorithmic Thinking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arya%2C+A">Ali Arya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">As the second book in the Anyone Can Code series, Algorithmic Thinking
focuses on the logic behind computer programming and software design. With a
data-centred approach, it starts with simple algorithms that work on simple
data items and advances to more complex ones covering data structures and
classes. Examples are given in C/C++ and Python and use both plain text and
graphics applications to illustrate the concepts in different languages and
forms. With the advances in artificial intelligence and automated code
generators, it is essential to learn about the logic of what a code needs to
do, not just how to write the code. Anyone Can Code: Algorithmic Thinking is
suitable for anyone who aims to improve their programming skills and go beyond
the simple craft of programming, stepping into the world of algorithm design.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14189" title="Abstract">arXiv:2311.14189</a> [<a href="/pdf/2311.14189" title="Download PDF">pdf</a>, <a href="/format/2311.14189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HACD: Hand-Aware Conditional Diffusion for Monocular Hand-Held Object  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+B">Bowen Fu</a>, 
<a href="/search/cs?searchtype=author&query=Di%2C+Y">Yan Di</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenyangguang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Gu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Ziqin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Leng%2C+Z">Zhiying Leng</a>, 
<a href="/search/cs?searchtype=author&query=Manhardt%2C+F">Fabian Manhardt</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+X">Xiangyang Ji</a>, 
<a href="/search/cs?searchtype=author&query=Tombari%2C+F">Federico Tombari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Reconstructing hand-held objects from a single RGB image without known 3D
object templates, category prior, or depth information is a vital yet
challenging problem in computer vision. In contrast to prior works that utilize
deterministic modeling paradigms, which make it hard to account for the
uncertainties introduced by hand- and self-occlusion, we employ a probabilistic
point cloud denoising diffusion model to tackle the above challenge. In this
work, we present Hand-Aware Conditional Diffusion for monocular hand-held
object reconstruction (HACD), modeling the hand-object interaction in two
aspects. First, we introduce hand-aware conditioning to model hand-object
interaction from both semantic and geometric perspectives. Specifically, a
unified hand-object semantic embedding compensates for the 2D local feature
deficiency induced by hand occlusion, and a hand articulation embedding further
encodes the relationship between object vertices and hand joints. Second, we
propose a hand-constrained centroid fixing scheme, which utilizes hand vertices
priors to restrict the centroid deviation of partially denoised point cloud
during diffusion and reverse process. Removing the centroid bias interference
allows the diffusion models to focus on the reconstruction of shape, thus
enhancing the stability and precision of local feature projection. Experiments
on the synthetic ObMan dataset and two real-world datasets, HO3D and MOW,
demonstrate our approach surpasses all existing methods by a large margin.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14195" title="Abstract">arXiv:2311.14195</a> [<a href="/pdf/2311.14195" title="Download PDF">pdf</a>, <a href="/ps/2311.14195" title="Download PostScript">ps</a>, <a href="/format/2311.14195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Touch Analysis: An Empirical Evaluation of Machine Learning  Classification Algorithms on Touch Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Montgomery%2C+M">Melodee Montgomery</a>, 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+P">Prosenjit Chatterjee</a>, 
<a href="/search/cs?searchtype=author&query=Jenkins%2C+J">John Jenkins</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+K">Kaushik Roy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Our research aims at classifying individuals based on their unique
interactions on touchscreen-based smartphones. In this research, we use
Touch-Analytics datasets, which include 41 subjects and 30 different behavioral
features. Furthermore, we derived new features from the raw data to improve the
overall authentication performance. Previous research has already been done on
the Touch-Analytics datasets with the state-of-the-art classifiers, including
Support Vector Machine (SVM) and k-nearest neighbor (kNN), and achieved equal
error rates (EERs) between 0% to 4%. Here, we propose a novel Deep Neural Net
(DNN) architecture to classify the individuals correctly. The proposed DNN
architecture has three dense layers and uses many-to-many mapping techniques.
When we combine the new features with the existing ones, SVM and kNN achieved
the classification accuracy of 94.7% and 94.6%, respectively. This research
explored seven other classifiers and out of them, the decision tree and our
proposed DNN classifiers resulted in the highest accuracy of 100%. The others
included: Logistic Regression (LR), Linear Discriminant Analysis (LDA),
Gaussian Naive Bayes (NB), Neural Network, and VGGNet with the following
accuracy scores of 94.7%, 95.9%, 31.9%, 88.8%, and 96.1%, respectively.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14199" title="Abstract">arXiv:2311.14199</a> [<a href="/pdf/2311.14199" title="Download PDF">pdf</a>, <a href="/format/2311.14199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Systematic Review of Deep Learning-based Research on Radiology Report  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuanhe Tian</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yan Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Radiology report generation (RRG) aims to automatically generate free-text
descriptions from clinical radiographs, e.g., chest X-Ray images. RRG plays an
essential role in promoting clinical automation and presents significant help
to provide practical assistance for inexperienced doctors and alleviate
radiologists' workloads. Therefore, consider these meaningful potentials,
research on RRG is experiencing explosive growth in the past half-decade,
especially with the rapid development of deep learning approaches. Existing
studies perform RRG from the perspective of enhancing different modalities,
provide insights on optimizing the report generation process with elaborated
features from both visual and textual information, and further facilitate RRG
with the cross-modal interactions among them. In this paper, we present a
comprehensive review of deep learning-based RRG from various perspectives.
Specifically, we firstly cover pivotal RRG approaches based on the
task-specific features of radiographs, reports, and the cross-modal relations
between them, and then illustrate the benchmark datasets conventionally used
for this task with evaluation metrics, subsequently analyze the performance of
different approaches and finally offer our summary on the challenges and the
trends in future directions. Overall, the goal of this paper is to serve as a
tool for understanding existing literature and inspiring potential valuable
research in the field of RRG.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14200" title="Abstract">arXiv:2311.14200</a> [<a href="/pdf/2311.14200" title="Download PDF">pdf</a>, <a href="/format/2311.14200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prebunking Design as a Defense Mechanism Against Misinformation  Propagation on Social Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bayiz%2C+Y+E">Yigit Ege Bayiz</a>, 
<a href="/search/cs?searchtype=author&query=Topcu%2C+U">Ufuk Topcu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures, Submitted to PERCOM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The growing reliance on social media for news consumption necessitates
effective countermeasures to mitigate the rapid spread of misinformation.
Prebunking, a proactive method that arms users with accurate information before
they come across false content, has garnered support from journalism and
psychology experts. We formalize the problem of optimal prebunking as
optimizing the timing of delivering accurate information, ensuring users
encounter it before receiving misinformation while minimizing the disruption to
user experience. Utilizing a susceptible-infected epidemiological process to
model the propagation of misinformation, we frame optimal prebunking as a
policy synthesis problem with safety constraints. We then propose a policy that
approximates the optimal solution to a relaxed problem. The experiments show
that this policy cuts the user experience cost of repeated information delivery
in half, compared to delivering accurate information immediately after
identifying a misinformation propagation.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14201" title="Abstract">arXiv:2311.14201</a> [<a href="/pdf/2311.14201" title="Download PDF">pdf</a>, <a href="/format/2311.14201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the convergence of adaptive approximations for stochastic  differential equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Foster%2C+J">James Foster</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Probability (math.PR)

</div>
<p class="mathjax">In this paper, we study numerical approximations for stochastic differential
equations (SDEs) that use adaptive step sizes. In particular, we consider a
general setting where decisions to reduce step sizes are allowed to depend on
the future trajectory of the underlying Brownian motion. Since these adaptive
step sizes may not be previsible, the standard mean squared error analysis
cannot be directly applied to show that the numerical method converges to the
solution of the SDE. Building upon the pioneering work of Gaines and Lyons, we
shall instead use rough path theory to establish convergence for a wide class
of adaptive numerical methods on general Stratonovich SDEs (with sufficiently
smooth vector fields). To the author's knowledge, this is the first error
analysis applicable to standard solvers, such as the Milstein and Heun methods,
with non-previsible step sizes. In our analysis, we require the sequence of
adaptive step sizes to be nested and the SDE solver to have unbiased "L\'evy
area" terms in its Taylor expansion. We conjecture that for adaptive SDE
solvers more generally, convergence is still possible provided the method does
not introduce "L\'evy area bias". We present a simple example where the step
size control can skip over previously considered times, resulting in the
numerical method converging to an incorrect limit (i.e. not the Stratonovich
SDE). Finally, we conclude with a numerical experiment demonstrating a newly
introduced adaptive scheme and showing the potential improvements in accuracy
when step sizes are allowed to be non-previsible.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14203" title="Abstract">arXiv:2311.14203</a> [<a href="/pdf/2311.14203" title="Download PDF">pdf</a>, <a href="/ps/2311.14203" title="Download PostScript">ps</a>, <a href="/format/2311.14203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Risk Modeling for Infrastructure Projects Using Artificial  Intelligence Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Erfani%2C+A">Abdolmajid Erfani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Managing project risk is a key part of the successful implementation of any
large project and is widely recognized as a best practice for public agencies
to deliver infrastructures. The conventional method of identifying and
evaluating project risks involves getting input from subject matter experts at
risk workshops in the early phases of a project. As a project moves through its
life cycle, these identified risks and their assessments evolve. Some risks are
realized to become issues, some are mitigated, and some are retired as no
longer important. Despite the value provided by conventional expert-based
approaches, several challenges remain due to the time-consuming and expensive
processes involved. Moreover, limited is known about how risks evolve from
ex-ante to ex-post over time. How well does the project team identify and
evaluate risks in the initial phase compared to what happens during project
execution? Using historical data and artificial intelligence techniques, this
study addressed these limitations by introducing a data-driven framework to
identify risks automatically and to examine the quality of early risk registers
and risk assessments. Risk registers from more than 70 U.S. major
transportation projects form the input dataset.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14206" title="Abstract">arXiv:2311.14206</a> [<a href="/pdf/2311.14206" title="Download PDF">pdf</a>, <a href="/format/2311.14206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GMRES with randomized sketching and deflated restarting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Burke%2C+L">Liam Burke</a>, 
<a href="/search/math?searchtype=author&query=G%C3%BCttel%2C+S">Stefan G&#xfc;ttel</a>, 
<a href="/search/math?searchtype=author&query=Soodhalter%2C+K+M">Kirk M. Soodhalter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 Pages; 9 Figures; 4 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We present a new Krylov subspace recycling method for solving a linear system
of equations, or a sequence of slowly changing linear systems. Our new method,
named GMRES-SDR, combines randomized sketching and deflated restarting in a way
that avoids orthogononalizing a full Krylov basis. We provide new theory which
characterizes sketched GMRES with and without augmentation as a projection
method using a semi-inner product. We present results of numerical experiments
demonstrating the effectiveness of GMRES-SDR over competitor methods such as
GMRES-DR and GCRO-DR.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14208" title="Abstract">arXiv:2311.14208</a> [<a href="/pdf/2311.14208" title="Download PDF">pdf</a>, <a href="/format/2311.14208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ECRF: Entropy-Constrained Neural Radiance Fields Compression with  Frequency Domain Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Soonbin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+F">Fangwen Shu</a>, 
<a href="/search/cs?searchtype=author&query=Sanchez%2C+Y">Yago Sanchez</a>, 
<a href="/search/cs?searchtype=author&query=Schierl%2C+T">Thomas Schierl</a>, 
<a href="/search/cs?searchtype=author&query=Hellge%2C+C">Cornelius Hellge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Explicit feature-grid based NeRF models have shown promising results in terms
of rendering quality and significant speed-up in training. However, these
methods often require a significant amount of data to represent a single scene
or object. In this work, we present a compression model that aims to minimize
the entropy in the frequency domain in order to effectively reduce the data
size. First, we propose using the discrete cosine transform (DCT) on the
tensorial radiance fields to compress the feature-grid. This feature-grid is
transformed into coefficients, which are then quantized and entropy encoded,
following a similar approach to the traditional video coding pipeline.
Furthermore, to achieve a higher level of sparsity, we propose using an entropy
parameterization technique for the frequency domain, specifically for DCT
coefficients of the feature-grid. Since the transformed coefficients are
optimized during the training phase, the proposed model does not require any
fine-tuning or additional information. Our model only requires a lightweight
compression pipeline for encoding and decoding, making it easier to apply
volumetric radiance field methods for real-world applications. Experimental
results demonstrate that our proposed frequency domain entropy model can
achieve superior compression performance across various datasets. The source
code will be made publicly available.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14213" title="Abstract">arXiv:2311.14213</a> [<a href="/pdf/2311.14213" title="Download PDF">pdf</a>, <a href="/format/2311.14213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Solve Inverse Problems for Perceptual Sound Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+H">Han Han</a>, 
<a href="/search/cs?searchtype=author&query=Lostanlen%2C+V">Vincent Lostanlen</a>, 
<a href="/search/cs?searchtype=author&query=Lagrange%2C+M">Mathieu Lagrange</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Perceptual sound matching (PSM) aims to find the input parameters to a
synthesizer so as to best imitate an audio target. Deep learning for PSM
optimizes a neural network to analyze and reconstruct prerecorded samples. In
this context, our article addresses the problem of designing a suitable loss
function when the training set is generated by a differentiable synthesizer.
Our main contribution is perceptual-neural-physical loss (PNP), which aims at
addressing a tradeoff between perceptual relevance and computational
efficiency. The key idea behind PNP is to linearize the effect of synthesis
parameters upon auditory features in the vicinity of each training sample. The
linearization procedure is massively paralellizable, can be precomputed, and
offers a 100-fold speedup during gradient descent compared to differentiable
digital signal processing (DDSP). We demonstrate PNP on two datasets of
nonstationary sounds: an AM/FM arpeggiator and a physical model of rectangular
membranes. We show that PNP is able to accelerate DDSP with joint
time-frequency scattering transform (JTFS) as auditory feature, while
preserving its perceptual fidelity. Additionally, we evaluate the impact of
other design choices in PSM: parameter rescaling, pretraining, auditory
representation, and gradient clipping. We report state-of-the-art results on
both datasets and find that PNP-accelerated JTFS has greater influence on PSM
performance than any other design choice.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14214" title="Abstract">arXiv:2311.14214</a> [<a href="/pdf/2311.14214" title="Download PDF">pdf</a>, <a href="/format/2311.14214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extending Variability-Aware Model Selection with Bias Detection in  Machine Learning Projects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tavares%2C+C">Cristina Tavares</a>, 
<a href="/search/cs?searchtype=author&query=Nascimento%2C+N">Nathalia Nascimento</a>, 
<a href="/search/cs?searchtype=author&query=Alencar%2C+P">Paulo Alencar</a>, 
<a href="/search/cs?searchtype=author&query=Cowan%2C+D">Donald Cowan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE BigData 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Data science projects often involve various machine learning (ML) methods
that depend on data, code, and models. One of the key activities in these
projects is the selection of a model or algorithm that is appropriate for the
data analysis at hand. ML model selection depends on several factors, which
include data-related attributes such as sample size, functional requirements
such as the prediction algorithm type, and non-functional requirements such as
performance and bias. However, the factors that influence such selection are
often not well understood and explicitly represented. This paper describes
ongoing work on extending an adaptive variability-aware model selection method
with bias detection in ML projects. The method involves: (i) modeling the
variability of the factors that affect model selection using feature models
based on heuristics proposed in the literature; (ii) instantiating our
variability model with added features related to bias (e.g., bias-related
metrics); and (iii) conducting experiments that illustrate the method in a
specific case study to illustrate our approach based on a heart failure
prediction project. The proposed approach aims to advance the state of the art
by making explicit factors that influence model selection, particularly those
related to bias, as well as their interactions. The provided representations
can transform model selection in ML projects into a non ad hoc, adaptive, and
explainable process.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14215" title="Abstract">arXiv:2311.14215</a> [<a href="/pdf/2311.14215" title="Download PDF">pdf</a>, <a href="/format/2311.14215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Refinement calculus of quantum programs with projective assertions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yuan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Li Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yingte Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">Refinement calculus provides a structured framework for the progressive and
modular development of programs, ensuring their correctness throughout the
refinement process. This paper introduces a refinement calculus tailored for
quantum programs. To this end, we first study the partial correctness of
nondeterministic programs within a quantum while language featuring
prescription statements. Orthogonal projectors, which are equivalent to
subspaces of the state Hilbert space, are taken as assertions for quantum
states. In addition to the denotational semantics where a nondeterministic
program is associated with a set of trace-nonincreasing super-operators, we
also present their semantics in transforming a postcondition to the weakest
liberal postconditions and, conversely, transforming a precondition to the
strongest postconditions. Subsequently, refinement rules are introduced based
on these dual semantics, offering a systematic approach to the incremental
development of quantum programs applicable in various contexts. To illustrate
the practical application of the refinement calculus, we examine examples such
as the implementation of a $Z$-rotation gate, the repetition code, and the
quantum-to-quantum Bernoulli factory. Furthermore, we present Quire, a
Python-based interactive prototype tool that provides practical support to
programmers engaged in the stepwise development of correct quantum programs.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14218" title="Abstract">arXiv:2311.14218</a> [<a href="/pdf/2311.14218" title="Download PDF">pdf</a>, <a href="/format/2311.14218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Benchmark and Model for Challenging Image Manipulation Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenfei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+M">Ming-Ching Chang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, 3 tabels
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The ability to detect manipulation in multimedia data is vital in digital
forensics. Existing Image Manipulation Detection (IMD) methods are mainly based
on detecting anomalous features arisen from image editing or double compression
artifacts. All existing IMD techniques encounter challenges when it comes to
detecting small tampered regions from a large image. Moreover,
compression-based IMD approaches face difficulties in cases of double
compression of identical quality factors. To investigate the State-of-The-Art
(SoTA) IMD methods in those challenging conditions, we introduce a new
Challenging Image Manipulation Detection (CIMD) benchmark dataset, which
consists of two subsets, for evaluating editing-based and compression-based IMD
methods, respectively. The dataset images were manually taken and tampered with
high-quality annotations. In addition, we propose a new two-branch network
model based on HRNet that can better detect both the image-editing and
compression artifacts in those challenging conditions. Extensive experiments on
the CIMD benchmark show that our model significantly outperforms SoTA IMD
methods on CIMD.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14222" title="Abstract">arXiv:2311.14222</a> [<a href="/pdf/2311.14222" title="Download PDF">pdf</a>, <a href="/format/2311.14222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Risk Bounds of Accelerated SGD for Overparameterized Linear Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yihe Deng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jingfeng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Dongruo Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Q">Quanquan Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 85 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">Accelerated stochastic gradient descent (ASGD) is a workhorse in deep
learning and often achieves better generalization performance than SGD.
However, existing optimization theory can only explain the faster convergence
of ASGD, but cannot explain its better generalization. In this paper, we study
the generalization of ASGD for overparameterized linear regression, which is
possibly the simplest setting of learning with overparameterization. We
establish an instance-dependent excess risk bound for ASGD within each
eigen-subspace of the data covariance matrix. Our analysis shows that (i) ASGD
outperforms SGD in the subspace of small eigenvalues, exhibiting a faster rate
of exponential decay for bias error, while in the subspace of large
eigenvalues, its bias error decays slower than SGD; and (ii) the variance error
of ASGD is always larger than that of SGD. Our result suggests that ASGD can
outperform SGD when the difference between the initialization and the true
weight vector is mostly confined to the subspace of small eigenvalues.
Additionally, when our analysis is specialized to linear regression in the
strongly convex setting, it yields a tighter bound for bias error than the
best-known result.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14223" title="Abstract">arXiv:2311.14223</a> [<a href="/pdf/2311.14223" title="Download PDF">pdf</a>, <a href="/format/2311.14223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information Velocity of Cascaded Gaussian Channels with Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Domanovitz%2C+E">Elad Domanovitz</a>, 
<a href="/search/cs?searchtype=author&query=Khina%2C+A">Anatoly Khina</a>, 
<a href="/search/cs?searchtype=author&query=Philosof%2C+T">Tal Philosof</a>, 
<a href="/search/cs?searchtype=author&query=Kochman%2C+Y">Yuval Kochman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">We consider a line network of nodes, connected by additive white Gaussian
noise channels, equipped with local feedback. We study the velocity at which
information spreads over this network. For transmission of a data packet, we
give an explicit positive lower bound on the velocity, for any packet size.
Furthermore, we consider streaming, that is, transmission of data packets
generated at a given average arrival rate. We show that a positive velocity
exists as long as the arrival rate is below the individual Gaussian channel
capacity, and provide an explicit lower bound. Our analysis involves applying
pulse-amplitude modulation to the data (successively in the streaming case),
and using linear mean-squared error estimation at the network nodes. Due to the
analog linear nature of the scheme, the results extend to any additive noise.
For general noise, we derive exponential error-probability bounds. Moreover,
for (sub-)Gaussian noise we show a doubly-exponential behavior, which reduces
to the celebrated Schalkwijk-Kailath scheme when considering a single node.
Viewing the constellation as an "analog source", we also provide bounds on the
exponential decay of the mean-squared error of source transmission over the
network.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14225" title="Abstract">arXiv:2311.14225</a> [<a href="/pdf/2311.14225" title="Download PDF">pdf</a>, <a href="/ps/2311.14225" title="Download PostScript">ps</a>, <a href="/format/2311.14225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Agent-Based Discrete Event Simulation of Teleoperated Driving in  Freight Transport Operations: The Fleet Sizing Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Madadi%2C+B">Bahman Madadi</a>, 
<a href="/search/cs?searchtype=author&query=Nadi%2C+A">Ali Nadi</a>, 
<a href="/search/cs?searchtype=author&query=de+Almeida+Correia%2C+G+H">Gon&#xe7;alo Homem de Almeida Correia</a>, 
<a href="/search/cs?searchtype=author&query=Verduijn%2C+T">Thierry Verduijn</a>, 
<a href="/search/cs?searchtype=author&query=Tavasszy%2C+L">L&#xf3;r&#xe1;nt Tavasszy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">Teleoperated or remote-controlled driving complements automated driving and
acts as transitional technology toward full automation. An economic advantage
of teleoperated driving in logistics operations lies in managing fleets with
fewer teleoperators compared to vehicles with in-vehicle drivers. This
alleviates growing truck driver shortage problems in the logistics industry and
saves costs. However, a trade-off exists between the teleoperator-to-vehicle
ratio and the service level of teleoperation. This study designs a simulation
framework to explore this trade-off generating multiple performance indicators
as proxies for teleoperation service level. By applying the framework, we
identify factors influencing the trade-off and optimal teleoperator-to-vehicle
ratios under different scenarios. Our case study on road freight tours in The
Netherlands reveals that for any operational setting, a
teleoperation-to-vehicle ratio below one can manage all freight truck tours
without delay, while one represents the current situation. The minimum
teleoperator-to-vehicle ratio for zero-delay operations is never above 0.6,
implying a minimum of 40% teleoperation labor cost saving. For operations where
a small delay is allowed, teleoperator-to-vehicle ratios as low as 0.4 are
shown to be feasible, which indicates potential savings of up to 60%. This
confirms great promise for a positive business case for the teleoperated
driving as a service.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14226" title="Abstract">arXiv:2311.14226</a> [<a href="/pdf/2311.14226" title="Download PDF">pdf</a>, <a href="/format/2311.14226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncovering Gender Stereotypes in Video Game Character Designs: A  Multi-Modal Analysis of Honor of Kings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bingqing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K+Z">Kyrie Zhixuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+D">Danlei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jaihyun Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3rd International Conference on Natural Language Processing for Digital Humanities (NLP4DH)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">In this paper, we conduct a comprehensive analysis of gender stereotypes in
the character design of Honor of Kings, a popular multiplayer online battle
arena (MOBA) game in China. We probe gender stereotypes through the lens of
role assignments, visual designs, spoken lines, and background stories,
combining qualitative analysis and text mining based on the moral foundation
theory. Male heroes are commonly designed as masculine fighters with power and
female heroes as feminine "ornaments" with ideal looks. We contribute with a
culture-aware and multi-modal understanding of gender stereotypes in games,
leveraging text-, visual-, and role-based evidence.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14228" title="Abstract">arXiv:2311.14228</a> [<a href="/pdf/2311.14228" title="Download PDF">pdf</a>, <a href="/format/2311.14228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Formulations to select assets for constructing sparse index tracking  portfolios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sakurai%2C+Y">Yutaka Sakurai</a>, 
<a href="/search/cs?searchtype=author&query=Wakabayashi%2C+D">Daiki Wakabayashi</a>, 
<a href="/search/cs?searchtype=author&query=Ishizaki%2C+F">Fumio Ishizaki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">In this paper, we study asset selection methods to construct a sparse index
tracking portfolio. For its advantage over full replication portfolio, the
concept of sparse index tracking portfolio has significant attention in the
field of finance and investment management. We propose useful formulations to
select assets for sparse index tracking portfolio. Our formulations are
described as combinatorial optimization problems, and they can yield various
asset selection methods, including some existing methods, by adjusting the
values of parameters. As a result, the proposed formulations can provide a
well-balanced asset selection to create successful sparse index tracking
portfolios. We also provide numerical examples to compare the tracking
performance of resulting sparse index tracking portfolios.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14236" title="Abstract">arXiv:2311.14236</a> [<a href="/pdf/2311.14236" title="Download PDF">pdf</a>, <a href="/ps/2311.14236" title="Download PostScript">ps</a>, <a href="/format/2311.14236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximum Cardinality $f$-Matching in Time $O(n^{2/3}m)$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gabow%2C+H">Harold Gabow</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We present an algorithm that finds a maximum cardinality $f$-matching of a
simple graph in time $O(n^{2/3} m)$. Here $f:V\to \mathbb{N}$ is a given
function, and an $f$-matching is a subgraph wherein each vertex $v\in V$ has
degree $\le f(v)$. This result generalizes a string of algorithms,
concentrating on simple bipartite graphs. The bipartite case is based on the
notion of level graph, introduced by Dinic for network flow. For general graphs
the ``level'' of a vertex is unclear: A given vertex can occur on many
different levels in augmenting trails. In fact there does not seem to be a
unique level graph, our notion of level graph depends on the trails being
analyzed. Our analysis presents new properties of blossoms of shortest
augmenting trails.
<br />Our algorithm, unmodified, is also efficient on multigraphs, achieving time
$O(\min \{\sqrt {f(V)}, n\}\,m)$, for $f(V)=\sum_vf(v)$.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14237" title="Abstract">arXiv:2311.14237</a> [<a href="/pdf/2311.14237" title="Download PDF">pdf</a>, <a href="/format/2311.14237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pseudo-label Correction for Instance-dependent Noise Using  Teacher-student Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+E">Eugene Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The high capacity of deep learning models to learn complex patterns poses a
significant challenge when confronted with label noise. The inability to
differentiate clean and noisy labels ultimately results in poor generalization.
We approach this problem by reassigning the label for each image using a new
teacher-student based framework termed P-LC (pseudo-label correction).
Traditional teacher-student networks are composed of teacher and student
classifiers for knowledge distillation. In our novel approach, we reconfigure
the teacher network into a triple encoder, leveraging the triplet loss to
establish a pseudo-label correction system. As the student generates pseudo
labels for a set of given images, the teacher learns to choose between the
initially assigned labels and the pseudo labels. Experiments on MNIST,
Fashion-MNIST, and SVHN demonstrate P-LC's superior performance over existing
state-of-the-art methods across all noise levels, most notably in high noise.
In addition, we introduce a noise level estimation to help assess model
performance and inform the need for additional data cleaning procedures.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14239" title="Abstract">arXiv:2311.14239</a> [<a href="/pdf/2311.14239" title="Download PDF">pdf</a>, <a href="/format/2311.14239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Allpass impulse response modelling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Flax%2C+M+R">Matt R. Flax</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)

</div>
<p class="mathjax">This document defines a method for FIR system modelling which is very trivial
as it only depends on phase introduction and removal (allpass filters). As
magnitude is not altered, the processing is numerically stable. It is limited
to phase alteration which maintains the time domain magnitude to force a system
within its linear limits.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14241" title="Abstract">arXiv:2311.14241</a> [<a href="/pdf/2311.14241" title="Download PDF">pdf</a>, <a href="/format/2311.14241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How We Manage an Army of Teaching Assistants: Experience Report on  Scaling a CS1 Course
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akhmetov%2C+I">Ildar Akhmetov</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+S">Sadaf Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Ayuno%2C+K">Kezziah Ayuno</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">A considerable increase in enrollment numbers poses major challenges in
course management, such as fragmented information sharing, inefficient
meetings, and poor understanding of course activities among a large team of
teaching assistants. To address these challenges, we restructured the course,
drawing inspiration from successful management and educational practices. We
developed an organized, three-tier structure for teams, each led by an
experienced Lead TA. We also formed five functional teams, each focusing on a
specific area of responsibility: communication, content, "lost student"
support, plagiarism, and scheduling. In addition, we updated our recruitment
method for undergraduate TAs, following a model similar to the one used in the
software industry, while also deciding to mentor Lead TAs in place of
traditional training. Our experiences, lessons learned, and future plans for
enhancement have been detailed in this experience report. We emphasize the
value of using management techniques in dealing with large-scale course
handling and invite cooperation to improve the implementation of these
strategies, inviting other institutions to consider and adapt this approach,
tailoring it to their specific needs.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14242" title="Abstract">arXiv:2311.14242</a> [<a href="/pdf/2311.14242" title="Download PDF">pdf</a>, <a href="/format/2311.14242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RSB-Pose: Robust Short-Baseline Binocular 3D Human Pose Estimation with  Occlusion Handling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+X">Xiaoyue Wan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+Y">Yiming Bao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xu Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures, currently under review at IEEE Transactions on Image Processing journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the domain of 3D Human Pose Estimation, which finds widespread daily
applications, the requirement for convenient acquisition equipment continues to
grow. To satisfy this demand, we set our sights on a short-baseline binocular
setting that offers both portability and a geometric measurement property that
radically mitigates depth ambiguity. However, as the binocular baseline
shortens, two serious challenges emerge: first, the robustness of 3D
reconstruction against 2D errors deteriorates; and second, occlusion reoccurs
due to the limited visual differences between two views. To address the first
challenge, we propose the Stereo Co-Keypoints Estimation module to improve the
view consistency of 2D keypoints and enhance the 3D robustness. In this module,
the disparity is utilized to represent the correspondence of binocular 2D
points and the Stereo Volume Feature is introduced to contain binocular
features across different disparities. Through the regression of SVF, two-view
2D keypoints are simultaneously estimated in a collaborative way which
restricts their view consistency. Furthermore, to deal with occlusions, a
Pre-trained Pose Transformer module is introduced. Through this module, 3D
poses are refined by perceiving pose coherence, a representation of joint
correlations. This perception is injected by the Pose Transformer network and
learned through a pre-training task that recovers iterative masked joints.
Comprehensive experiments carried out on H36M and MHAD datasets, complemented
by visualizations, validate the effectiveness of our approach in the
short-baseline binocular 3D Human Pose Estimation and occlusion handling.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14246" title="Abstract">arXiv:2311.14246</a> [<a href="/pdf/2311.14246" title="Download PDF">pdf</a>, <a href="/format/2311.14246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constant-Time Wasmtime, for Real This Time: End-to-End Verified  Zero-Overhead Constant-Time Programming for the Web and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+G">Garrett Gu</a>, 
<a href="/search/cs?searchtype=author&query=Shacham%2C+H">Hovav Shacham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">We claim that existing techniques and tools for generating and verifying
constant-time code are incomplete, since they rely on assumptions that compiler
optimization passes do not break constant-timeness or that certain operations
execute in constant time on the hardware. We present the first end-to-end
constant-time-aware compilation process that preserves constant-time semantics
at every step from a high-level language down to microarchitectural guarantees,
provided by the forthcoming ARM PSTATE.DIT feature. First, we present a new
compiler-verifier suite based on the JIT-style runtime Wasmtime, modified to
compile ct-wasm, a preexisting type-safe constant-time extension of
WebAssembly, into ARM machine code while maintaining the constant-time property
throughout all optimization passes. The resulting machine code is then fed into
an automated verifier that requires no human intervention and uses static
dataflow analysis in Ghidra to check the constant-timeness of the output. Our
verifier leverages characteristics unique to ct-wasm-generated code in order to
speed up verification while preserving both soundness and wide applicability.
We also consider the resistance of our compilation and verification against
speculative timing leakages such as Spectre. Finally, in order to expose
ct-Wasmtime at a high level, we present a port of FaCT, a preexisting
constant-time-aware DSL, to target ct-wasm.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14247" title="Abstract">arXiv:2311.14247</a> [<a href="/pdf/2311.14247" title="Download PDF">pdf</a>, <a href="/format/2311.14247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distribution Testing with a Confused Collector
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pinto%2C+R+F">Renato Ferreira Pinto Jr.</a>, 
<a href="/search/cs?searchtype=author&query=Harms%2C+N">Nathaniel Harms</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 64 pages. Full version of paper to appear at ITCS 2024. arXiv admin note: text overlap with <a href="/abs/2304.01374">arXiv:2304.01374</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We are interested in testing properties of distributions with systematically
mislabeled samples. Our goal is to make decisions about unknown probability
distributions, using a sample that has been collected by a confused collector,
such as a machine-learning classifier that has not learned to distinguish all
elements of the domain. The confused collector holds an unknown clustering of
the domain and an input distribution $\mu$, and provides two oracles: a sample
oracle which produces a sample from $\mu$ that has been labeled according to
the clustering; and a label-query oracle which returns the label of a query
point $x$ according to the clustering.
<br />Our first set of results shows that identity, uniformity, and equivalence of
distributions can be tested efficiently, under the earth-mover distance, with
remarkably weak conditions on the confused collector, even when the unknown
clustering is adversarial. This requires defining a variant of the distribution
testing task (inspired by the recent testable learning framework of Rubinfeld &amp;
Vasilyan), where the algorithm should test a joint property of the distribution
and its clustering. As an example, we get efficient testers when the
distribution tester is allowed to reject if it detects that the confused
collector clustering is "far" from being a decision tree.
<br />The second set of results shows that we can sometimes do significantly better
when the clustering is random instead of adversarial. For certain
one-dimensional random clusterings, we show that uniformity can be tested under
the TV distance using $\widetilde O\left(\frac{\sqrt n}{\rho^{3/2}
\epsilon^2}\right)$ samples and zero queries, where $\rho \in (0,1]$ controls
the "resolution" of the clustering. We improve this to $O\left(\frac{\sqrt
n}{\rho \epsilon^2}\right)$ when queries are allowed.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14249" title="Abstract">arXiv:2311.14249</a> [<a href="/pdf/2311.14249" title="Download PDF">pdf</a>, <a href="/format/2311.14249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Local Search for Nonlinear Real Arithmetic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhonghan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+B">Bohua Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bohan Li</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+S">Shaowei Cai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full version of VMCAI'2024 publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>

</div>
<p class="mathjax">Local search has recently been applied to SMT problems over various
arithmetic theories. Among these, nonlinear real arithmetic poses special
challenges due to its uncountable solution space and potential need to solve
higher-degree polynomials. As a consequence, existing work on local search only
considered fragments of the theory. In this work, we analyze the difficulties
and propose ways to address them, resulting in an efficient search algorithm
that covers the full theory of nonlinear real arithmetic. In particular, we
present two algorithmic improvements: incremental computation of variable
scores and temporary relaxation of equality constraints. We also discuss choice
of candidate moves and a look-ahead mechanism in case when no critical moves
are available. The resulting implementation is competitive on satisfiable
problem instances against complete methods such as MCSAT in existing SMT
solvers.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14251" title="Abstract">arXiv:2311.14251</a> [<a href="/pdf/2311.14251" title="Download PDF">pdf</a>, <a href="/ps/2311.14251" title="Download PostScript">ps</a>, <a href="/format/2311.14251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal 1-bit Error Exponent for 2-hop Relaying with Binary-Input  Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ling%2C+Y+H">Yan Hao Ling</a>, 
<a href="/search/cs?searchtype=author&query=Scarlett%2C+J">Jonathan Scarlett</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this paper, we study the problem of relaying a single bit over a tandem of
binary-input channels, with the goal of attaining the highest possible error
exponent in the exponentially decaying error probability. Our previous work
gave an exact characterization of the best possible error exponent in various
special cases, including when the two channels are identical, but the general
case was left as an open problem. We resolve this open problem by deriving a
new converse bound that matches our existing achievability bound.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14255" title="Abstract">arXiv:2311.14255</a> [<a href="/pdf/2311.14255" title="Download PDF">pdf</a>, <a href="/format/2311.14255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Out-of-Distribution Generalized Dynamic Graph Neural Network with  Disentangled Intervention and Invariance Promotion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zeyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenwu Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Dynamic graph neural networks (DyGNNs) have demonstrated powerful predictive
abilities by exploiting graph structural and temporal dynamics. However, the
existing DyGNNs fail to handle distribution shifts, which naturally exist in
dynamic graphs, mainly because the patterns exploited by DyGNNs may be variant
with respect to labels under distribution shifts. In this paper, we propose
Disentangled Intervention-based Dynamic graph Attention networks with
Invariance Promotion (I-DIDA) to handle spatio-temporal distribution shifts in
dynamic graphs by discovering and utilizing invariant patterns, i.e.,
structures and features whose predictive abilities are stable across
distribution shifts. Specifically, we first propose a disentangled
spatio-temporal attention network to capture the variant and invariant
patterns. By utilizing the disentangled patterns, we design a spatio-temporal
intervention mechanism to create multiple interventional distributions and an
environment inference module to infer the latent spatio-temporal environments,
and minimize the variance of predictions among these intervened distributions
and environments, so that our model can make predictions based on invariant
patterns with stable predictive abilities under distribution shifts. Extensive
experiments demonstrate the superiority of our method over state-of-the-art
baselines under distribution shifts. Our work is the first study of
spatio-temporal distribution shifts in dynamic graphs, to the best of our
knowledge.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14262" title="Abstract">arXiv:2311.14262</a> [<a href="/pdf/2311.14262" title="Download PDF">pdf</a>, <a href="/format/2311.14262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZeroPS: High-quality Cross-modal Knowledge Transfer for Zero-Shot 3D  Part Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+Y">Yuheng Xue</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+N">Nenglun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wenyun Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures; references added
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, many 2D pretrained foundational models have demonstrated impressive
zero-shot prediction capabilities. In this work, we design a novel pipeline for
zero-shot 3D part segmentation, called ZeroPS. It high-quality transfers
knowledge from 2D pretrained foundational models to 3D point clouds. The main
idea of our approach is to explore the natural relationship between multi-view
correspondences and the prompt mechanism of foundational models and build
bridges on it. Our pipeline consists of two components: 1) a self-extension
component that extends 2D groups from a single viewpoint to spatial
global-level 3D groups; 2) a multi-modal labeling component that introduces a
two-dimensional checking mechanism to vote each 2D predicted bounding box to
the best matching 3D part, and a Class Non-highest Vote Penalty function to
refine the Vote Matrix. Additionally, a merging algorithm is included to merge
part-level 3D groups. Extensive evaluation of three zero-shot segmentation
tasks on PartnetE datasets, achieving state-of-the-art results with significant
improvements (+19.6%, +5.2% and +4.9%, respectively) over existing methods. Our
proposed approach does not need any training, fine-tuning or learnable
parameters. It is hardly affected by domain shift. The code will be released.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14265" title="Abstract">arXiv:2311.14265</a> [<a href="/pdf/2311.14265" title="Download PDF">pdf</a>, <a href="/format/2311.14265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bursting Spikes: Efficient and High-performance SNNs for Event-based  Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuetong Fang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jiahang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Renjing Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Advancing event-driven vision through spiking neural networks (SNNs) is
crucial to empowering high-speed and efficient perception. While directly
converting the pre-trained artificial neural networks (ANNs) - by replacing the
non-linear activation with spiking neurons - can provide SNNs with good
performance, the resultant SNNs typically demand long timesteps and high energy
consumption to achieve their optimal performance. To address this challenge, we
introduce the burst-spike mechanism inspired by the biological nervous system,
allowing multiple spikes per timestep to reduce conversion errors and produce
low-latency SNNs. To further bolster this enhancement, we leverage the Pareto
Frontier-driven algorithm to reallocate burst-firing patterns. Moreover, to
reduce energy consumption during the conversion process, we propose a
sensitivity-driven spike compression technique, which automatically locates the
optimal threshold ratio according to layer-specific sensitivity. Extensive
experiments demonstrate our approach outperforms state-of-the-art SNN methods,
showcasing superior performance and reduced energy usage across classification
and object detection. Our code will be available at
https://github.com/bic-L/burst-ann2snn.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14270" title="Abstract">arXiv:2311.14270</a> [<a href="/pdf/2311.14270" title="Download PDF">pdf</a>, <a href="/format/2311.14270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Open-world Reinforcement Learning via Knowledge Distillation  and Autonomous Rule Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nikonova%2C+E">Ekaterina Nikonova</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+C">Cheng Xue</a>, 
<a href="/search/cs?searchtype=author&query=Renz%2C+J">Jochen Renz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Deep reinforcement learning suffers from catastrophic forgetting and sample
inefficiency making it less applicable to the ever-changing real world.
However, the ability to use previously learned knowledge is essential for AI
agents to quickly adapt to novelties. Often, certain spatial information
observed by the agent in the previous interactions can be leveraged to infer
task-specific rules. Inferred rules can then help the agent to avoid
potentially dangerous situations in the previously unseen states and guide the
learning process increasing agent's novelty adaptation speed. In this work, we
propose a general framework that is applicable to deep reinforcement learning
agents. Our framework provides the agent with an autonomous way to discover the
task-specific rules in the novel environments and self-supervise it's learning.
We provide a rule-driven deep Q-learning agent (RDQ) as one possible
implementation of that framework. We show that RDQ successfully extracts
task-specific rules as it interacts with the world and uses them to drastically
increase its learning efficiency. In our experiments, we show that the RDQ
agent is significantly more resilient to the novelties than the baseline
agents, and is able to detect and adapt to novel situations faster.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14271" title="Abstract">arXiv:2311.14271</a> [<a href="/pdf/2311.14271" title="Download PDF">pdf</a>, <a href="/ps/2311.14271" title="Download PostScript">ps</a>, <a href="/format/2311.14271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segmentation-Based Parametric Painting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Guevara%2C+M+L">Manuel Ladron de Guevara</a>, 
<a href="/search/cs?searchtype=author&query=Fisher%2C+M">Matthew Fisher</a>, 
<a href="/search/cs?searchtype=author&query=Hertzmann%2C+A">Aaron Hertzmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce a novel image-to-painting method that facilitates the creation
of large-scale, high-fidelity paintings with human-like quality and stylistic
variation. To process large images and gain control over the painting process,
we introduce a segmentation-based painting process and a dynamic attention map
approach inspired by human painting strategies, allowing optimization of brush
strokes to proceed in batches over different image regions, thereby capturing
both large-scale structure and fine details, while also allowing stylistic
control over detail. Our optimized batch processing and patch-based loss
framework enable efficient handling of large canvases, ensuring our painted
outputs are both aesthetically compelling and functionally superior as compared
to previous methods, as confirmed by rigorous evaluations. Code available at:
https://github.com/manuelladron/semantic\_based\_painting.git
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14272" title="Abstract">arXiv:2311.14272</a> [<a href="/pdf/2311.14272" title="Download PDF">pdf</a>, <a href="/format/2311.14272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CRISP: Hybrid Structured Sparsity for Class-aware Model Pruning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+S">Shivam Aggarwal</a>, 
<a href="/search/cs?searchtype=author&query=Binici%2C+K">Kuluhan Binici</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+T">Tulika Mitra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, accepted in Design, Automation &amp; Test in Europe Conference &amp; Exhibition (DATE) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Hardware Architecture (cs.AR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Machine learning pipelines for classification tasks often train a universal
model to achieve accuracy across a broad range of classes. However, a typical
user encounters only a limited selection of classes regularly. This disparity
provides an opportunity to enhance computational efficiency by tailoring models
to focus on user-specific classes. Existing works rely on unstructured pruning,
which introduces randomly distributed non-zero values in the model, making it
unsuitable for hardware acceleration. Alternatively, some approaches employ
structured pruning, such as channel pruning, but these tend to provide only
minimal compression and may lead to reduced model accuracy. In this work, we
propose CRISP, a novel pruning framework leveraging a hybrid structured
sparsity pattern that combines both fine-grained N:M structured sparsity and
coarse-grained block sparsity. Our pruning strategy is guided by a
gradient-based class-aware saliency score, allowing us to retain weights
crucial for user-specific classes. CRISP achieves high accuracy with minimal
memory consumption for popular models like ResNet-50, VGG-16, and MobileNetV2
on ImageNet and CIFAR-100 datasets. Moreover, CRISP delivers up to 14$\times$
reduction in latency and energy consumption compared to existing pruning
methods while maintaining comparable accuracy. Our code is available at
https://github.com/shivmgg/CRISP/.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14275" title="Abstract">arXiv:2311.14275</a> [<a href="/pdf/2311.14275" title="Download PDF">pdf</a>, <a href="/format/2311.14275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cooperative Dual Attention for Audio-Visual Speech Enhancement with  Facial Cues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Feixiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+S">Shiguang Shan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xilin Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to BMVC 2023 15 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In this work, we focus on leveraging facial cues beyond the lip region for
robust Audio-Visual Speech Enhancement (AVSE). The facial region, encompassing
the lip region, reflects additional speech-related attributes such as gender,
skin color, nationality, etc., which contribute to the effectiveness of AVSE.
However, static and dynamic speech-unrelated attributes also exist, causing
appearance changes during speech. To address these challenges, we propose a
Dual Attention Cooperative Framework, DualAVSE, to ignore speech-unrelated
information, capture speech-related information with facial cues, and
dynamically integrate it with the audio signal for AVSE. Specifically, we
introduce a spatial attention-based visual encoder to capture and enhance
visual speech information beyond the lip region, incorporating global facial
context and automatically ignoring speech-unrelated information for robust
visual feature extraction. Additionally, a dynamic visual feature fusion
strategy is introduced by integrating a temporal-dimensional self-attention
module, enabling the model to robustly handle facial variations. The acoustic
noise in the speaking process is variable, impacting audio quality. Therefore,
a dynamic fusion strategy for both audio and visual features is introduced to
address this issue. By integrating cooperative dual attention in the visual
encoder and audio-visual fusion strategy, our model effectively extracts
beneficial speech information from both audio and visual cues for AVSE.
Thorough analysis and comparison on different datasets, including normal and
challenging cases with unreliable or absent visual information, consistently
show our model outperforming existing methods across multiple metrics.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14276" title="Abstract">arXiv:2311.14276</a> [<a href="/pdf/2311.14276" title="Download PDF">pdf</a>, <a href="/format/2311.14276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Racing With ROS 2 A Navigation System for an Autonomous Formula Student  Race Car
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bradford%2C+A">Alastair Bradford</a>, 
<a href="/search/cs?searchtype=author&query=van+Breda%2C+G">Grant van Breda</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+T">Tobias Fischer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Australasian Conference on Robotics and Automation (ACRA 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The advent of autonomous vehicle technologies has significantly impacted
various sectors, including motorsport, where Formula Student and Formula:
Society of Automotive Engineers introduced autonomous racing classes. These
offer new challenges to aspiring engineers, including the team at QUT
Motorsport, but also raise the entry barrier due to the complexity of
high-speed navigation and control. This paper presents an open-source solution
using the Robot Operating System 2, specifically its open-source navigation
stack, to address these challenges in autonomous Formula Student race cars. We
compare off-the-shelf navigation libraries that this stack comprises of against
traditional custom-made programs developed by QUT Motorsport to evaluate their
applicability in autonomous racing scenarios and integrate them onto an
autonomous race car. Our contributions include quantitative and qualitative
comparisons of these packages against traditional navigation solutions, aiming
to lower the entry barrier for autonomous racing. This paper also serves as a
comprehensive tutorial for teams participating in similar racing disciplines
and other autonomous mobile robot applications.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14281" title="Abstract">arXiv:2311.14281</a> [<a href="/pdf/2311.14281" title="Download PDF">pdf</a>, <a href="/ps/2311.14281" title="Download PostScript">ps</a>, <a href="/format/2311.14281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-modal Instance Refinement for Cross-domain Action Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qing%2C+Y">Yuan Qing</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+N">Naixing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+S">Shaohua Wan</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+L">Lixin Duan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by PRCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Unsupervised cross-domain action recognition aims at adapting the model
trained on an existing labeled source domain to a new unlabeled target domain.
Most existing methods solve the task by directly aligning the feature
distributions of source and target domains. However, this would cause negative
transfer during domain adaptation due to some negative training samples in both
domains. In the source domain, some training samples are of low-relevance to
target domain due to the difference in viewpoints, action styles, etc. In the
target domain, there are some ambiguous training samples that can be easily
classified as another type of action under the case of source domain. The
problem of negative transfer has been explored in cross-domain object
detection, while it remains under-explored in cross-domain action recognition.
Therefore, we propose a Multi-modal Instance Refinement (MMIR) method to
alleviate the negative transfer based on reinforcement learning. Specifically,
a reinforcement learning agent is trained in both domains for every modality to
refine the training data by selecting out negative samples from each domain.
Our method finally outperforms several other state-of-the-art baselines in
cross-domain action recognition on the benchmark EPIC-Kitchens dataset, which
demonstrates the advantage of MMIR in reducing negative transfer.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14282" title="Abstract">arXiv:2311.14282</a> [<a href="/pdf/2311.14282" title="Download PDF">pdf</a>, <a href="/format/2311.14282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Super-Resolution with Text Prompt Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yulun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jinjin Gu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Linghe Kong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guihai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaokang Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is available at <a href="https://github.com/zhengchen1999/PromptSR">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image super-resolution (SR) methods typically model degradation to improve
reconstruction accuracy in complex and unknown degradation scenarios. However,
extracting degradation information from low-resolution images is challenging,
which limits the model performance. To boost image SR performance, one feasible
approach is to introduce additional priors. Inspired by advancements in
multi-modal methods and text prompt image processing, we introduce text prompts
to image SR to provide degradation priors. Specifically, we first design a
text-image generation pipeline to integrate text into SR dataset through the
text degradation representation and degradation model. The text representation
applies a discretization manner based on the binning method to describe the
degradation abstractly. This representation method can also maintain the
flexibility of language. Meanwhile, we propose the PromptSR to realize the text
prompt SR. The PromptSR employs the diffusion model and the pre-trained
language model (e.g., T5 and CLIP). We train the model on the generated
text-image dataset. Extensive experiments indicate that introducing text
prompts into image SR, yields excellent results on both synthetic and
real-world images. Code: https://github.com/zhengchen1999/PromptSR.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14284" title="Abstract">arXiv:2311.14284</a> [<a href="/pdf/2311.14284" title="Download PDF">pdf</a>, <a href="/format/2311.14284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Paragraph-to-Image Generation with Information-Enriched Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Weijia Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuang Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yefei He</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chunhua Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Lele Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yan Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+T">Tingting Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Di Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhongyuan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The project website is at: <a href="https://weijiawu.github.io/ParaDiffusionPage/.">this https URL</a> Code: <a href="https://github.com/weijiawu/ParaDiffusion">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-to-image (T2I) models have recently experienced rapid development,
achieving astonishing performance in terms of fidelity and textual alignment
capabilities. However, given a long paragraph (up to 512 words), these
generation models still struggle to achieve strong alignment and are unable to
generate images depicting complex scenes. In this paper, we introduce an
information-enriched diffusion model for paragraph-to-image generation task,
termed ParaDiffusion, which delves into the transference of the extensive
semantic comprehension capabilities of large language models to the task of
image generation. At its core is using a large language model (e.g., Llama V2)
to encode long-form text, followed by fine-tuning with LORA to alignthe
text-image feature spaces in the generation task. To facilitate the training of
long-text semantic alignment, we also curated a high-quality paragraph-image
pair dataset, namely ParaImage. This dataset contains a small amount of
high-quality, meticulously annotated data, and a large-scale synthetic dataset
with long text descriptions being generated using a vision-language model.
Experiments demonstrate that ParaDiffusion outperforms state-of-the-art models
(SD XL, DeepFloyd IF) on ViLG-300 and ParaPrompts, achieving up to 15% and 45%
human voting rate improvements for visual appeal and text faithfulness,
respectively. The code and dataset will be released to foster community
research on long-text alignment.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14288" title="Abstract">arXiv:2311.14288</a> [<a href="/pdf/2311.14288" title="Download PDF">pdf</a>, <a href="/format/2311.14288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fair Influence Maximization in Social Networks: A Community-Based  Evolutionary Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+K">Kaicong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xinxiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Haipeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+R">Renzhi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Influence Maximization (IM) has been extensively studied in network science,
which attempts to find a subset of users to maximize the influence spread. A
new variant of IM, Fair Influence Maximization (FIM), which primarily enhances
the fair propagation of information, attracts increasing attention in academic.
However, existing algorithms for FIM suffer from a trade-off between fairness
and running time. Since it is a tough task to ensure that users are fairly
influenced in terms of sensitive attributes, such as race or gender, while
maintaining a high influence spread. To tackle this problem, in this paper, we
propose an effective and efficient Community-based Evolutionary Algorithm for
FIM (named CEA-FIM). In CEA-FIM, a community-based node selection strategy is
proposed to identify potential nodes, which not only considers the size of the
community but also the attributes of the nodes in the community. Subsequently,
we design an evolutionary algorithm based on the proposed node selection
strategy to hasten the search for the optimal solution, including the novel
initialization, crossover and mutation strategies. We validate the proposed
algorithm CEA-FIM by performing experiments on real-world and synthetic
networks. The experimental results show that the proposed CEA-FIM achieves a
better balance between effectiveness and efficiency, compared to the
state-of-the-art baseline algorithms.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14289" title="Abstract">arXiv:2311.14289</a> [<a href="/pdf/2311.14289" title="Download PDF">pdf</a>, <a href="/format/2311.14289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Four-set Hypergraphlets for Characterization of Directed Hypergraphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moon%2C+H">Heechan Moon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyunju Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sunwoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+K">Kijung Shin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">A directed hypergraph, which consists of nodes and hyperarcs, is a
higher-order data structure that naturally models directional group
interactions (e.g., chemical reactions of molecules). Although there have been
extensive studies on local structures of (directed) graphs in the real world,
those of directed hypergraphs remain unexplored. In this work, we focus on
measurements, findings, and applications related to local structures of
directed hypergraphs, and they together contribute to a systematic
understanding of various real-world systems interconnected by directed group
interactions. Our first contribution is to define 91 directed hypergraphlets
(DHGs), which disjointly categorize directed connections and overlaps among
four node sets that compose two incident hyperarcs. Our second contribution is
to develop exact and approximate algorithms for counting the occurrences of
each DHG. Our last contribution is to characterize 11 real-world directed
hypergraphs and individual hyperarcs in them using the occurrences of DHGs,
which reveals clear domain-based local structural patterns. Our experiments
demonstrate that our DHG-based characterization gives up to 12% and 33% better
performances on hypergraph clustering and hyperarc prediction, respectively,
than baseline characterization methods. Moreover, we show that CODA-A, which is
our proposed approximate algorithm, is up to 32X faster than its competitors
with similar characterization quality.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14294" title="Abstract">arXiv:2311.14294</a> [<a href="/pdf/2311.14294" title="Download PDF">pdf</a>, <a href="/format/2311.14294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decouple Content and Motion for Conditional Image-to-Video Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Cuifeng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+Y">Yulu Gan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiongwei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Lele Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinzhi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The goal of conditional image-to-video (cI2V) generation is to create a
believable new video by beginning with the condition, i.e., one image and
text.The previous cI2V generation methods conventionally perform in RGB pixel
space, with limitations in modeling motion consistency and visual continuity.
Additionally, the efficiency of generating videos in pixel space is quite
low.In this paper, we propose a novel approach to address these challenges by
disentangling the target RGB pixels into two distinct components: spatial
content and temporal motions. Specifically, we predict temporal motions which
include motion vector and residual based on a 3D-UNet diffusion model. By
explicitly modeling temporal motions and warping them to the starting image, we
improve the temporal consistency of generated videos. This results in a
reduction of spatial redundancy, emphasizing temporal details. Our proposed
method achieves performance improvements by disentangling content and motion,
all without introducing new structural complexities to the model. Extensive
experiments on various datasets confirm our approach's superior performance
over the majority of state-of-the-art methods in both effectiveness and
efficiency.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14295" title="Abstract">arXiv:2311.14295</a> [<a href="/pdf/2311.14295" title="Download PDF">pdf</a>, <a href="/ps/2311.14295" title="Download PostScript">ps</a>, <a href="/format/2311.14295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Active RIS in NOMA Networks with Hardware Impairments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+X">Xinwei Yue</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Meiqi Song</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+C">Chongjun Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tian Li</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+T">Tianwei Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Active reconfigurable intelligent surface (ARIS) is a promising way to
compensate for multiplicative fading attenuation by amplifying and reflecting
event signals to selected users. This paper investigates the performance of
ARIS assisted non-orthogonal multiple access (NOMA) networks over cascaded
Nakagami-m fading channels. The effects of hardware impairments (HIS) and
reflection coefficients on ARIS-NOMA networks with imperfect successive
interference cancellation (ipSIC) and perfect successive interference
cancellation (pSIC) are considered. More specifically, we develop new precise
and asymptotic expressions of outage probability and ergodic data rate with
ipSIC/pSIC for ARIS-NOMA-HIS networks. According to the approximated analyses,
the diversity orders and multiplexing gains for couple of non-orthogonal users
are attained in detail. Additionally, the energy efficiency of ARIS-NOMA-HIS
networks is surveyed in delay-limited and delay-tolerant transmission schemes.
The simulation findings are presented to demonstrate that: i) The outage
behaviors and ergodic data rates of ARIS-NOMA-HIS networks precede that of ARIS
aided orthogonal multiple access (OMA) and passive reconfigurable intelligent
surface (PRIS) aided OMA; ii) As the reflection coefficient of ARIS increases,
ARIS-NOMA-HIS networks have the ability to provide the strengthened outage
performance; and iii) ARIS-NOMA-HIS networks are more energy efficient than
ARIS/PRIS-OMA networks and conventional cooperative schemes.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14301" title="Abstract">arXiv:2311.14301</a> [<a href="/pdf/2311.14301" title="Download PDF">pdf</a>, <a href="/format/2311.14301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GeoViT: A Versatile Vision Transformer Architecture for Geospatial Image  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khirwar%2C+M">Madhav Khirwar</a>, 
<a href="/search/cs?searchtype=author&query=Narang%2C+A">Ankur Narang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended Abstract, Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Greenhouse gases are pivotal drivers of climate change, necessitating precise
quantification and source identification to foster mitigation strategies. We
introduce GeoViT, a compact vision transformer model adept in processing
satellite imagery for multimodal segmentation, classification, and regression
tasks targeting CO2 and NO2 emissions. Leveraging GeoViT, we attain superior
accuracy in estimating power generation rates, fuel type, plume coverage for
CO2, and high-resolution NO2 concentration mapping, surpassing previous
state-of-the-art models while significantly reducing model size. GeoViT
demonstrates the efficacy of vision transformer architectures in harnessing
satellite-derived data for enhanced GHG emission insights, proving instrumental
in advancing climate change monitoring and emission regulation efforts
globally.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14304" title="Abstract">arXiv:2311.14304</a> [<a href="/pdf/2311.14304" title="Download PDF">pdf</a>, <a href="/format/2311.14304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdaMedGraph: Adaboosting Graph Neural Networks for Personalized Medicine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lian%2C+J">Jie Lian</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xufang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+C">Caihua Shan</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+D">Dongqi Han</a>, 
<a href="/search/cs?searchtype=author&query=Vardhanabhuti%2C+V">Varut Vardhanabhuti</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongsheng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2023, December 10th, 2023, New Orleans, United States, 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Precision medicine tailored to individual patients has gained significant
attention in recent times. Machine learning techniques are now employed to
process personalized data from various sources, including images, genetics, and
assessments. These techniques have demonstrated good outcomes in many clinical
prediction tasks. Notably, the approach of constructing graphs by linking
similar patients and then applying graph neural networks (GNNs) stands out,
because related information from analogous patients are aggregated and
considered for prediction. However, selecting the appropriate edge feature to
define patient similarity and construct the graph is challenging, given that
each patient is depicted by high-dimensional features from diverse sources.
Previous studies rely on human expertise to select the edge feature, which is
neither scalable nor efficient in pinpointing crucial edge features for complex
diseases. In this paper, we propose a novel algorithm named \ours, which can
automatically select important features to construct multiple patient
similarity graphs, and train GNNs based on these graphs as weak learners in
adaptive boosting. \ours{} is evaluated on two real-world medical scenarios and
shows superiors performance.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14305" title="Abstract">arXiv:2311.14305</a> [<a href="/pdf/2311.14305" title="Download PDF">pdf</a>, <a href="/format/2311.14305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Epochs in AI Supervision: Design and Implementation of an Autonomous  Radiology AI Monitoring System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Venugopal%2C+V+K">Vasantha Kumar Venugopal</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Abhishek Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Takhar%2C+R">Rohit Takhar</a>, 
<a href="/search/cs?searchtype=author&query=Mahajan%2C+V">Vidur Mahajan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">With the increasingly widespread adoption of AI in healthcare, maintaining
the accuracy and reliability of AI models in clinical practice has become
crucial. In this context, we introduce novel methods for monitoring the
performance of radiology AI classification models in practice, addressing the
challenges of obtaining real-time ground truth for performance monitoring. We
propose two metrics - predictive divergence and temporal stability - to be used
for preemptive alerts of AI performance changes. Predictive divergence,
measured using Kullback-Leibler and Jensen-Shannon divergences, evaluates model
accuracy by comparing predictions with those of two supplementary models.
Temporal stability is assessed through a comparison of current predictions
against historical moving averages, identifying potential model decay or data
drift. This approach was retrospectively validated using chest X-ray data from
a single-center imaging clinic, demonstrating its effectiveness in maintaining
AI model reliability. By providing continuous, real-time insights into model
performance, our system ensures the safe and effective use of AI in clinical
decision-making, paving the way for more robust AI integration in healthcare
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14307" title="Abstract">arXiv:2311.14307</a> [<a href="/pdf/2311.14307" title="Download PDF">pdf</a>, <a href="/format/2311.14307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cosine Similarity Knowledge Distillation for Individual Class  Information Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ham%2C+G">Gyeongdo Ham</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seonghak Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Suin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jae-Hyeok Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Daeshik Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Previous logits-based Knowledge Distillation (KD) have utilized predictions
about multiple categories within each sample (i.e., class predictions) and have
employed Kullback-Leibler (KL) divergence to reduce the discrepancy between the
student and teacher predictions. Despite the proliferation of KD techniques,
the student model continues to fall short of achieving a similar level as
teachers. In response, we introduce a novel and effective KD method capable of
achieving results on par with or superior to the teacher models performance. We
utilize teacher and student predictions about multiple samples for each
category (i.e., batch predictions) and apply cosine similarity, a commonly used
technique in Natural Language Processing (NLP) for measuring the resemblance
between text embeddings. This metric's inherent scale-invariance property,
which relies solely on vector direction and not magnitude, allows the student
to dynamically learn from the teacher's knowledge, rather than being bound by a
fixed distribution of the teacher's knowledge. Furthermore, we propose a method
called cosine similarity weighted temperature (CSWT) to improve the
performance. CSWT reduces the temperature scaling in KD when the cosine
similarity between the student and teacher models is high, and conversely, it
increases the temperature scaling when the cosine similarity is low. This
adjustment optimizes the transfer of information from the teacher to the
student model. Extensive experimental results show that our proposed method
serves as a viable alternative to existing methods. We anticipate that this
approach will offer valuable insights for future research on model compression.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14308" title="Abstract">arXiv:2311.14308</a> [<a href="/pdf/2311.14308" title="Download PDF">pdf</a>, <a href="/format/2311.14308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distance-Only Task Orchestration Algorithm for Energy Efficiency in  Satellite-Based Mist Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Babaghayou%2C+M">Messaoud Babaghayou</a>, 
<a href="/search/cs?searchtype=author&query=Chaib%2C+N">Noureddine Chaib</a>, 
<a href="/search/cs?searchtype=author&query=Maglaras%2C+L">Leandros Maglaras</a>, 
<a href="/search/cs?searchtype=author&query=Yigit%2C+Y">Yagmur Yigit</a>, 
<a href="/search/cs?searchtype=author&query=Ferrag%2C+M+A">Mohamed Amine Ferrag</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">This paper addresses the challenge of efficiently offloading heavy computing
tasks from ground mobile devices to the satellite-based mist computing
environment. With ground-based edge and cloud servers often being inaccessible,
the exploitation of satellite mist computing becomes imperative. Existing
offloading algorithms have shown limitations in adapting to the unique
characteristics of heavy computing tasks. Thus, we propose a heavy computing
task offloading algorithm that prioritizes satellite proximity. This approach
not only reduces energy consumption during telecommunications but also ensures
tasks are executed within the specified timing constraints, which are typically
non-time-critical. Our proposed algorithm outperforms other offloading schemes
in terms of satellites energy consumption, average end-to-end delay, and tasks
success rates. Although it exhibits a higher average VM CPU usage, this
increase does not pose critical challenges. This distance-based approach offers
a promising solution to enhance energy efficiency in satellite-based mist
computing, making it well-suited for heavy computing tasks demands.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14310" title="Abstract">arXiv:2311.14310</a> [<a href="/pdf/2311.14310" title="Download PDF">pdf</a>, <a href="/format/2311.14310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stable Cluster Discrimination for Deep Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+Q">Qi Qian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by ICCV'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep clustering can optimize representations of instances (i.e.,
representation learning) and explore the inherent data distribution (i.e.,
clustering) simultaneously, which demonstrates a superior performance over
conventional clustering methods with given features. However, the coupled
objective implies a trivial solution that all instances collapse to the uniform
features. To tackle the challenge, a two-stage training strategy is developed
for decoupling, where it introduces an additional pre-training stage for
representation learning and then fine-tunes the obtained model for clustering.
Meanwhile, one-stage methods are developed mainly for representation learning
rather than clustering, where various constraints for cluster assignments are
designed to avoid collapsing explicitly. Despite the success of these methods,
an appropriate learning objective tailored for deep clustering has not been
investigated sufficiently. In this work, we first show that the prevalent
discrimination task in supervised learning is unstable for one-stage clustering
due to the lack of ground-truth labels and positive instances for certain
clusters in each mini-batch. To mitigate the issue, a novel stable cluster
discrimination (SeCu) task is proposed and a new hardness-aware clustering
criterion can be obtained accordingly. Moreover, a global entropy constraint
for cluster assignments is studied with efficient optimization. Extensive
experiments are conducted on benchmark data sets and ImageNet. SeCu achieves
state-of-the-art performance on all of them, which demonstrates the
effectiveness of one-stage deep clustering. Code is available at
\url{https://github.com/idstcv/SeCu}.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14311" title="Abstract">arXiv:2311.14311</a> [<a href="/pdf/2311.14311" title="Download PDF">pdf</a>, <a href="/format/2311.14311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RelJoin: Relative-cost-based Selection of Distributed Join Methods for  Query Plan Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+F">F. Liang</a>, 
<a href="/search/cs?searchtype=author&query=Lau%2C+F+C+M">F.C.M. Lau</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+H">H. Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Y. Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B">B. Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">C. Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">X. Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Selecting appropriate distributed join methods for logical join operations in
a query plan is crucial for the performance of data-intensive scalable
computing (DISC). Different network communication patterns in the data exchange
phase generate varying network communication workloads and significantly affect
the distributed join performance. However, most cost-based query optimizers
focus on the local computing cost and do not precisely model the network
communication cost. We propose a cost model for various distributed join
methods to optimize join queries in DISC platforms. Our method precisely
measures the network and local computing workloads in different execution
phases, using information on the size and cardinality statistics of datasets
and cluster join parallelism. Our cost model reveals the importance of the
relative size of the joining datasets. We implement an efficient distributed
join selection strategy, known as RelJoin in SparkSQL, which is an
industry-prevalent distributed data processing framework. RelJoin uses runtime
adaptive statistics for accurate cost estimation and selects optimal
distributed join methods for logical joins to optimize the physical query plan.
The evaluation results on the TPC-DS benchmark show that RelJoin performs best
in 62 of the 97 queries and can reduce the average query time by 21% compared
with other strategies.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14312" title="Abstract">arXiv:2311.14312</a> [<a href="/pdf/2311.14312" title="Download PDF">pdf</a>, <a href="/format/2311.14312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Adaptive Fast-Multipole-Accelerated Hybrid Boundary Integral Equation  Method for Accurate Diffusion Curves
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bang%2C+S">Seungbae Bang</a>, 
<a href="/search/math?searchtype=author&query=Serkh%2C+K">Kirill Serkh</a>, 
<a href="/search/math?searchtype=author&query=Stein%2C+O">Oded Stein</a>, 
<a href="/search/math?searchtype=author&query=Jacobson%2C+A">Alec Jacobson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 22 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">In theory, diffusion curves promise complex color gradations for
infinite-resolution vector graphics. In practice, existing realizations suffer
from poor scaling, discretization artifacts, or insufficient support for rich
boundary conditions. Previous applications of the boundary element method to
diffusion curves have relied on polygonal approximations, which either forfeit
the high-order smoothness of B\'ezier curves, or, when the polygonal
approximation is extremely detailed, result in large and costly systems of
equations that must be solved. In this paper, we utilize the boundary integral
equation method to accurately and efficiently solve the underlying partial
differential equation. Given a desired resolution and viewport, we then
interpolate this solution and use the boundary element method to render it. We
couple this hybrid approach with the fast multipole method on a non-uniform
quadtree for efficient computation. Furthermore, we introduce an adaptive
strategy to enable truly scalable infinite-resolution diffusion curves.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14315" title="Abstract">arXiv:2311.14315</a> [<a href="/pdf/2311.14315" title="Download PDF">pdf</a>, <a href="/format/2311.14315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Domain Misinformation Detection via Multi-modal Feature Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenya Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Rocha%2C+A">Anderson Rocha</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoliang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by TIFS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Social media misinformation harms individuals and societies and is
potentialized by fast-growing multi-modal content (i.e., texts and images),
which accounts for higher "credibility" than text-only news pieces. Although
existing supervised misinformation detection methods have obtained acceptable
performances in key setups, they may require large amounts of labeled data from
various events, which can be time-consuming and tedious. In turn, directly
training a model by leveraging a publicly available dataset may fail to
generalize due to domain shifts between the training data (a.k.a. source
domains) and the data from target domains. Most prior work on domain shift
focuses on a single modality (e.g., text modality) and ignores the scenario
where sufficient unlabeled target domain data may not be readily available in
an early stage. The lack of data often happens due to the dynamic propagation
trend (i.e., the number of posts related to fake news increases slowly before
catching the public attention). We propose a novel robust domain and
cross-modal approach (\textbf{RDCM}) for multi-modal misinformation detection.
It reduces the domain shift by aligning the joint distribution of textual and
visual modalities through an inter-domain alignment module and bridges the
semantic gap between both modalities through a cross-modality alignment module.
We also propose a framework that simultaneously considers application scenarios
of domain generalization (in which the target domain data is unavailable) and
domain adaptation (in which unlabeled target domain data is available).
Evaluation results on two public multi-modal misinformation detection datasets
(Pheme and Twitter Datasets) evince the superiority of the proposed model. The
formal implementation of this paper can be found in this link:
https://github.com/less-and-less-bugs/RDCM
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14317" title="Abstract">arXiv:2311.14317</a> [<a href="/pdf/2311.14317" title="Download PDF">pdf</a>, <a href="/format/2311.14317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical methods and regularity properties for viscosity solutions of  nonlocal in space and time diffusion equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=del+Teso%2C+F">F&#xe9;lix del Teso</a>, 
<a href="/search/math?searchtype=author&query=P%C5%82ociniczak%2C+%C5%81">&#x141;ukasz P&#x142;ociniczak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">We consider a general family of nonlocal in space and time diffusion
equations with space-time dependent diffusivity and prove convergence of finite
difference schemes in the context of viscosity solutions under very mild
conditions. The proofs, based on regularity properties and compactness
arguments on the numerical solution, allow to inherit a number of interesting
results for the limit equation. More precisely, assuming H\"older regularity
only on the initial condition, we prove convergence of the scheme, space-time
H\"older regularity of the solution depending on the fractional orders of the
operators, as well as specific blow up rates of the first time derivative.
Finally, using the obtained regularity results, we are able to prove orders of
convergence of the scheme in some cases. These results are consistent with
previous studies. The schemes' performance is further numerically verified
using both constructed exact solutions and realistic examples. Our experiments
show that multithreaded implementation yields an efficient method to solve
nonlocal equations numerically.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14323" title="Abstract">arXiv:2311.14323</a> [<a href="/pdf/2311.14323" title="Download PDF">pdf</a>, <a href="/format/2311.14323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Binarized 3D Whole-body Human Mesh Recovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiteng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yulun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jing Lin</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+H">Haotong Qin</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jinjin Gu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Linghe Kong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaokang Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The code will be available at <a href="https://github.com/ZHITENGLI/BiDRN">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D whole-body human mesh recovery aims to reconstruct the 3D human body,
face, and hands from a single image. Although powerful deep learning models
have achieved accurate estimation in this task, they require enormous memory
and computational resources. Consequently, these methods can hardly be deployed
on resource-limited edge devices. In this work, we propose a Binarized Dual
Residual Network (BiDRN), a novel quantization method to estimate the 3D human
body, face, and hands parameters efficiently. Specifically, we design a basic
unit Binarized Dual Residual Block (BiDRB) composed of Local Convolution
Residual (LCR) and Block Residual (BR), which can preserve full-precision
information as much as possible. For LCR, we generalize it to four kinds of
convolutional modules so that full-precision information can be propagated even
between mismatched dimensions. We also binarize the face and hands
box-prediction network as Binaried BoxNet, which can further reduce the model
redundancy. Comprehensive quantitative and qualitative experiments demonstrate
the effectiveness of BiDRN, which has a significant improvement over
state-of-the-art binarization algorithms. Moreover, our proposed BiDRN achieves
comparable performance with full-precision method Hand4Whole while using just
22.1% parameters and 14.8% operations. We will release all the code and
pretrained models.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14324" title="Abstract">arXiv:2311.14324</a> [<a href="/pdf/2311.14324" title="Download PDF">pdf</a>, <a href="/format/2311.14324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models as Topological Structure Enhancers for  Text-Attributed Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shengyin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yuxiang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chen Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuecang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">The latest advancements in large language models (LLMs) have revolutionized
the field of natural language processing (NLP). Inspired by the success of LLMs
in NLP tasks, some recent work has begun investigating the potential of
applying LLMs in graph learning tasks. However, most of the existing work
focuses on utilizing LLMs as powerful node feature augmenters, leaving
employing LLMs to enhance graph topological structures an understudied problem.
In this work, we explore how to leverage the information retrieval and text
generation capabilities of LLMs to refine/enhance the topological structure of
text-attributed graphs (TAGs) under the node classification setting. First, we
propose using LLMs to help remove unreliable edges and add reliable ones in the
TAG. Specifically, we first let the LLM output the semantic similarity between
node attributes through delicate prompt designs, and then perform edge deletion
and edge addition based on the similarity. Second, we propose using
pseudo-labels generated by the LLM to improve graph topology, that is, we
introduce the pseudo-label propagation as a regularization to guide the graph
neural network (GNN) in learning proper edge weights. Finally, we incorporate
the two aforementioned LLM-based methods for graph topological refinement into
the process of GNN training, and perform extensive experiments on four
real-world datasets. The experimental results demonstrate the effectiveness of
LLM-based graph topology refinement (achieving a 0.15%--2.47% performance gain
on public benchmarks).
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14327" title="Abstract">arXiv:2311.14327</a> [<a href="/pdf/2311.14327" title="Download PDF">pdf</a>, <a href="/format/2311.14327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> C-ITS Environment Modeling and Attack Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jaewoong Choi</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M+G">Min Geun Song</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hyosun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Sagong%2C+C">Chaeyeon Sagong</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Sangbeom Park</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaesung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+J">Jeongdo Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H+K">Huy Kang Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in Korean Language, 14 Figures, 15 Pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">As technology advances, cities are evolving into smart cities, with the
ability to process large amounts of data and the increasing complexity and
diversification of various elements within urban areas. Among the core systems
of a smart city is the Cooperative-Intelligent Transport Systems (C-ITS). C-ITS
is a system where vehicles provide real-time information to drivers about
surrounding traffic conditions, sudden stops, falling objects, and other
accident risks through roadside base stations. It consists of road
infrastructure, C-ITS centers, and vehicle terminals. However, as smart cities
integrate many elements through networks and electronic control, they are
susceptible to cybersecurity issues. In the case of cybersecurity problems in
C-ITS, there is a significant risk of safety issues arising. This technical
document aims to model the C-ITS environment and the services it provides, with
the purpose of identifying the attack surface where security incidents could
occur in a smart city environment. Subsequently, based on the identified attack
surface, the document aims to construct attack scenarios and their respective
stages. The document provides a description of the concept of C-ITS, followed
by the description of the C-ITS environment model, service model, and attack
scenario model defined by us.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14328" title="Abstract">arXiv:2311.14328</a> [<a href="/pdf/2311.14328" title="Download PDF">pdf</a>, <a href="/format/2311.14328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Offline Skill Generalization via Task and Motion Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Watanabe%2C+S">Shin Watanabe</a>, 
<a href="/search/cs?searchtype=author&query=Horn%2C+G">Geir Horn</a>, 
<a href="/search/cs?searchtype=author&query=T%C3%B8rresen%2C+J">Jim T&#xf8;rresen</a>, 
<a href="/search/cs?searchtype=author&query=Ellefsen%2C+K+O">Kai Olav Ellefsen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents a novel approach to generalizing robot manipulation
skills by combining a sampling-based task-and-motion planner with an offline
reinforcement learning algorithm. Starting with a small library of scripted
primitive skills (e.g. Push) and object-centric symbolic predicates (e.g.
On(block, plate)), the planner autonomously generates a demonstration dataset
of manipulation skills in the context of a long-horizon task. An offline
reinforcement learning algorithm then extracts a policy from the dataset
without further interactions with the environment and replaces the scripted
skill in the existing library. Refining the skill library improves the
robustness of the planner, which in turn facilitates data collection for more
complex manipulation skills. We validate our approach in simulation, on a
block-pushing task. We show that the proposed method requires less training
data than conventional reinforcement learning methods. Furthermore, interaction
with the environment is collision-free because of the use of planner
demonstrations, making the approach more amenable to persistent robot learning
in the real world.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14329" title="Abstract">arXiv:2311.14329</a> [<a href="/pdf/2311.14329" title="Download PDF">pdf</a>, <a href="/format/2311.14329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enabling Feedback-Free MIMO Transmission for FD-RAN: A Data-driven  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingbo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiacheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zongxi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Haibo Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">To enhance flexibility and facilitate resource cooperation, a novel
fully-decoupled radio access network (FD-RAN) architecture is proposed for 6G.
However, the decoupling of uplink (UL) and downlink (DL) in FD-RAN makes the
existing feedback mechanism ineffective. To this end, we propose an end-to-end
data-driven MIMO solution without the conventional channel feedback procedure.
Data-driven MIMO can alleviate the drawbacks of feedback including overheads
and delay, and can provide customized precoding design for different BSs based
on their historical channel data. It essentially learns a mapping from
geolocation to MIMO transmission parameters. We first present a codebook-based
approach, which selects transmission parameters from the statistics of discrete
channel state information (CSI) values and utilizes integer interpolation for
spatial inference. We further present a non-codebook-based approach, which 1)
derives the optimal precoder from the singular value decomposition (SVD) of the
channel; 2) utilizes variational autoencoder (VAE) to select the representative
precoder from the latent Gaussian representations; and 3) exploits Gaussian
process regression (GPR) to predict unknown precoders in the space domain.
Extensive simulations are performed on a link-level 5G simulator using
realistic ray-tracing channel data. The results demonstrate the effectiveness
of data-driven MIMO, showcasing its potential for application in FD-RAN and 6G.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14332" title="Abstract">arXiv:2311.14332</a> [<a href="/pdf/2311.14332" title="Download PDF">pdf</a>, <a href="/format/2311.14332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GATGPT: A Pre-trained Large Language Model with Graph Attention Network  for Spatiotemporal Imputation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yakun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xianzhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Guandong Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">The analysis of spatiotemporal data is increasingly utilized across diverse
domains, including transportation, healthcare, and meteorology. In real-world
settings, such data often contain missing elements due to issues like sensor
malfunctions and data transmission errors. The objective of spatiotemporal
imputation is to estimate these missing values by understanding the inherent
spatial and temporal relationships in the observed multivariate time series.
Traditionally, spatiotemporal imputation has relied on specific, intricate
architectures designed for this purpose, which suffer from limited
applicability and high computational complexity. In contrast, our approach
integrates pre-trained large language models (LLMs) into spatiotemporal
imputation, introducing a groundbreaking framework, GATGPT. This framework
merges a graph attention mechanism with LLMs. We maintain most of the LLM
parameters unchanged to leverage existing knowledge for learning temporal
patterns, while fine-tuning the upper layers tailored to various applications.
The graph attention component enhances the LLM's ability to understand spatial
relationships. Through tests on three distinct real-world datasets, our
innovative approach demonstrates comparable results to established deep
learning benchmarks.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14333" title="Abstract">arXiv:2311.14333</a> [<a href="/pdf/2311.14333" title="Download PDF">pdf</a>, <a href="/format/2311.14333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cycle Invariant Positional Encoding for Graph Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zuoyu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+T">Tengfei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Liangcai Gao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zhi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yusu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as oral presentation in the Learning on Graphs Conference (LoG 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Cycles are fundamental elements in graph-structured data and have
demonstrated their effectiveness in enhancing graph learning models. To encode
such information into a graph learning framework, prior works often extract a
summary quantity, ranging from the number of cycles to the more sophisticated
persistence diagram summaries. However, more detailed information, such as
which edges are encoded in a cycle, has not yet been used in graph neural
networks. In this paper, we make one step towards addressing this gap, and
propose a structure encoding module, called CycleNet, that encodes cycle
information via edge structure encoding in a permutation invariant manner. To
efficiently encode the space of all cycles, we start with a cycle basis (i.e.,
a minimal set of cycles generating the cycle space) which we compute via the
kernel of the 1-dimensional Hodge Laplacian of the input graph. To guarantee
the encoding is invariant w.r.t. the choice of cycle basis, we encode the cycle
information via the orthogonal projector of the cycle basis, which is inspired
by BasisNet proposed by Lim et al. We also develop a more efficient variant
which however requires that the input graph has a unique shortest cycle basis.
To demonstrate the effectiveness of the proposed module, we provide some
theoretical understandings of its expressive power. Moreover, we show via a
range of experiments that networks enhanced by our CycleNet module perform
better in various benchmarks compared to several existing SOTA models.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14334" title="Abstract">arXiv:2311.14334</a> [<a href="/pdf/2311.14334" title="Download PDF">pdf</a>, <a href="/format/2311.14334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximizing Discrimination Capability of Knowledge Distillation with  Energy-based Score
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seonghak Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ham%2C+G">Gyeongdo Ham</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Suin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+D">Donggon Jang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Daeshik Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 4 figures. This work has been submitted to the Elsevier for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">To apply the latest computer vision techniques that require a large
computational cost in real industrial applications, knowledge distillation
methods (KDs) are essential. Existing logit-based KDs apply the constant
temperature scaling to all samples in dataset, limiting the utilization of
knowledge inherent in each sample individually. In our approach, we classify
the dataset into two categories (i.e., low energy and high energy samples)
based on their energy score. Through experiments, we have confirmed that low
energy samples exhibit high confidence scores, indicating certain predictions,
while high energy samples yield low confidence scores, meaning uncertain
predictions. To distill optimal knowledge by adjusting non-target class
predictions, we apply a higher temperature to low energy samples to create
smoother distributions and a lower temperature to high energy samples to
achieve sharper distributions. When compared to previous logit-based and
feature-based methods, our energy-based KD (Energy KD) achieves better
performance on various datasets. Especially, Energy KD shows significant
improvements on CIFAR-100-LT and ImageNet datasets, which contain many
challenging samples. Furthermore, we propose high energy-based data
augmentation (HE-DA) for further improving the performance. We demonstrate that
meaningful performance improvement could be achieved by augmenting only 20-50%
of dataset, suggesting that it can be employed on resource-limited devices. To
the best of our knowledge, this paper represents the first attempt to make use
of energy scores in KD and DA, and we believe it will greatly contribute to
future research.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14335" title="Abstract">arXiv:2311.14335</a> [<a href="/pdf/2311.14335" title="Download PDF">pdf</a>, <a href="/format/2311.14335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative Analysis of Transformers for Modeling Tabular Data: A  Casestudy using Industry Scale Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+U">Usneek Singh</a>, 
<a href="/search/cs?searchtype=author&query=Arora%2C+P">Piyush Arora</a>, 
<a href="/search/cs?searchtype=author&query=Ganesan%2C+S">Shamika Ganesan</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+M">Mohit Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+S">Siddhant Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+S+R">Salil R. Joshi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at 7th Joint International Conference on Data Science &amp; Management of Data (11th ACMIKDD CODS and 29th COMAD)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We perform a comparative analysis of transformer-based models designed for
modeling tabular data, specifically on an industry-scale dataset. While earlier
studies demonstrated promising outcomes on smaller public or synthetic
datasets, the effectiveness did not extend to larger industry-scale datasets.
The challenges identified include handling high-dimensional data, the necessity
for efficient pre-processing of categorical and numerical features, and
addressing substantial computational requirements.
<br />To overcome the identified challenges, the study conducts an extensive
examination of various transformer-based models using both synthetic datasets
and the default prediction Kaggle dataset (2022) from American Express. The
paper presents crucial insights into optimal data pre-processing, compares
pre-training and direct supervised learning methods, discusses strategies for
managing categorical and numerical features, and highlights trade-offs between
computational resources and performance. Focusing on temporal financial data
modeling, the research aims to facilitate the systematic development and
deployment of transformer-based models in real-world scenarios, emphasizing
scalability.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14337" title="Abstract">arXiv:2311.14337</a> [<a href="/pdf/2311.14337" title="Download PDF">pdf</a>, <a href="/format/2311.14337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TVT: Training-Free Vision Transformer Search on Tiny Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zimian Wei</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+H">Hengyue Pan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lujun Li</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+P">Peijie Dong</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zhiliang Tian</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+X">Xin Niu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongsheng Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Training-free Vision Transformer (ViT) architecture search is presented to
search for a better ViT with zero-cost proxies. While ViTs achieve significant
distillation gains from CNN teacher models on small datasets, the current
zero-cost proxies in ViTs do not generalize well to the distillation training
paradigm according to our experimental observations. In this paper, for the
first time, we investigate how to search in a training-free manner with the
help of teacher models and devise an effective Training-free ViT (TVT) search
framework. Firstly, we observe that the similarity of attention maps between
ViT and ConvNet teachers affects distill accuracy notably. Thus, we present a
teacher-aware metric conditioned on the feature attention relations between
teacher and student. Additionally, TVT employs the L2-Norm of the student's
weights as the student-capability metric to improve ranking consistency.
Finally, TVT searches for the best ViT for distilling with ConvNet teachers via
our teacher-aware metric and student-capability metric, resulting in impressive
gains in efficiency and effectiveness. Extensive experiments on various tiny
datasets and search spaces show that our TVT outperforms state-of-the-art
training-free search methods. The code will be released.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14339" title="Abstract">arXiv:2311.14339</a> [<a href="/pdf/2311.14339" title="Download PDF">pdf</a>, <a href="/format/2311.14339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Concept-based Interpretability of Skin Lesion Diagnosis using  Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patr%C3%ADcio%2C+C">Cristiano Patr&#xed;cio</a>, 
<a href="/search/cs?searchtype=author&query=Teixeira%2C+L+F">Lu&#xed;s F. Teixeira</a>, 
<a href="/search/cs?searchtype=author&query=Neves%2C+J+C">Jo&#xe3;o C. Neves</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Concept-based models naturally lend themselves to the development of
inherently interpretable skin lesion diagnosis, as medical experts make
decisions based on a set of visual patterns of the lesion. Nevertheless, the
development of these models depends on the existence of concept-annotated
datasets, whose availability is scarce due to the specialized knowledge and
expertise required in the annotation process. In this work, we show that
vision-language models can be used to alleviate the dependence on a large
number of concept-annotated samples. In particular, we propose an embedding
learning strategy to adapt CLIP to the downstream task of skin lesion
classification using concept-based descriptions as textual embeddings. Our
experiments reveal that vision-language models not only attain better accuracy
when using concepts as textual embeddings, but also require a smaller number of
concept-annotated samples to attain comparable performance to approaches
specifically devised for automatic concept generation.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14342" title="Abstract">arXiv:2311.14342</a> [<a href="/pdf/2311.14342" title="Download PDF">pdf</a>, <a href="/format/2311.14342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-based Attack Graph Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Sangbeom Park</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaesung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+J">Jeongdo Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M+G">Min Geun Song</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hyosun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jaewoong Choi</a>, 
<a href="/search/cs?searchtype=author&query=Sagong%2C+C">Chaeyeon Sagong</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H+K">Huy Kang Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in Korean Language, 8 Figures, 14 Pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">With the advancement of IoT technology, many electronic devices are
interconnected through networks, communicating with each other and performing
specific roles. However, as numerous devices join networks, the threat of
cyberattacks also escalates. Preventing and detecting cyber threats are
crucial, and one method of preventing such threats involves using attack
graphs. Attack graphs are widely used to assess security threats within
networks. However, a drawback emerges as the network scales, as generating
attack graphs becomes time-consuming. To overcome this limitation, artificial
intelligence models can be employed. By utilizing AI models, attack graphs can
be created within a short period, approximating optimal outcomes. AI models
designed for attack graph generation consist of encoders and decoders, trained
using reinforcement learning algorithms. After training the AI models, we
confirmed the model's learning effectiveness by observing changes in loss and
reward values. Additionally, we compared attack graphs generated by the AI
model with those created through conventional methods.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14343" title="Abstract">arXiv:2311.14343</a> [<a href="/pdf/2311.14343" title="Download PDF">pdf</a>, <a href="/format/2311.14343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Highly Detailed and Temporal Consistent Video Stylization via  Synchronized Multi-Frame Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+M">Minshan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hanyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chengze Li</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+T">Tien-Tsin Wong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-guided video-to-video stylization transforms the visual appearance of a
source video to a different appearance guided on textual prompts. Existing
text-guided image diffusion models can be extended for stylized video
synthesis. However, they struggle to generate videos with both highly detailed
appearance and temporal consistency. In this paper, we propose a synchronized
multi-frame diffusion framework to maintain both the visual details and the
temporal consistency. Frames are denoised in a synchronous fashion, and more
importantly, information of different frames is shared since the beginning of
the denoising process. Such information sharing ensures that a consensus, in
terms of the overall structure and color distribution, among frames can be
reached in the early stage of the denoising process before it is too late. The
optical flow from the original video serves as the connection, and hence the
venue for information sharing, among frames. We demonstrate the effectiveness
of our method in generating high-quality and diverse results in extensive
experiments. Our method shows superior qualitative and quantitative results
compared to state-of-the-art video editing methods.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14347" title="Abstract">arXiv:2311.14347</a> [<a href="/pdf/2311.14347" title="Download PDF">pdf</a>, <a href="/format/2311.14347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Typed compositional quantum computation with lenses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garrigue%2C+J">Jacques Garrigue</a>, 
<a href="/search/cs?searchtype=author&query=Saikawa%2C+T">Takafumi Saikawa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">We propose a type-theoretic framework for describing and proving properties
of quantum computations, in particular those presented as quantum circuits. Our
proposal is based on an observation that, in the polymorphic type system of
Coq, currying on quantum states allows us to apply quantum gates directly
inside a complex circuit. By introducing a discrete notion of lens to control
this currying, we are further able to separate the combinatorics of the circuit
structure from the computational content of gates. We apply our development to
define quantum circuits recursively from the bottom up, and prove their
correctness compositionally.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14349" title="Abstract">arXiv:2311.14349</a> [<a href="/pdf/2311.14349" title="Download PDF">pdf</a>, <a href="/format/2311.14349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DEUS: Distributed Electronic Patient File Update System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neumann%2C+C+P">Christoph P. Neumann</a>, 
<a href="/search/cs?searchtype=author&query=Rampp%2C+F">Florian Rampp</a>, 
<a href="/search/cs?searchtype=author&query=Lenz%2C+R">Richard Lenz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> University of Erlangen, Dept. of Computer Science, Technical Reports, CS-2012-02, March 2012
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Inadequate availability of patient information is a major cause for medical
errors and affects costs in healthcare. Traditional approaches to information
integration in healthcare do not solve the problem. Applying a
document-oriented paradigm to systems integration enables inter-institutional
information exchange in healthcare. The goal of the proposed architecture is to
provide information exchange between strict autonomous healthcare institutions,
bridging the gap between primary and secondary care. In a long-term healthcare
data distribution scenario, the patient has to maintain sovereignty over any
personal health information. Thus, the traditional publish-subscribe
architecture is extended by a phase of human mediation within the data flow.
DEUS essentially decouples the roles of information author and information
publisher into distinct actors, resulting in a triangular data flow. The
interaction scenario will be motivated. The significance of human mediation
will be discussed. DEUS provides a carefully distinguished actor and role model
for mediated pub-sub. The data flow between the participants is factored into
distinct phases of information interchange. The artefact model is decomposed
into role-dependent constituent parts. Both a domain specific (healthcare)
terminology and a generic terminology is provided. From a technical
perspective, the system design is presented. The sublayer for network transfer
will be highlighted as well as the subsystem for human-machine interaction.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14353" title="Abstract">arXiv:2311.14353</a> [<a href="/pdf/2311.14353" title="Download PDF">pdf</a>, <a href="/format/2311.14353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Average Token Delay: A Duration-aware Latency Metric for Simultaneous  Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kano%2C+Y">Yasumasa Kano</a>, 
<a href="/search/cs?searchtype=author&query=Sudoh%2C+K">Katsuhito Sudoh</a>, 
<a href="/search/cs?searchtype=author&query=Nakamura%2C+S">Satoshi Nakamura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of the paper (doi: 10.21437/Interspeech.2023-933) which appeared in INTERSPEECH 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Simultaneous translation is a task in which the translation begins before the
end of an input speech segment. Its evaluation should be conducted based on
latency in addition to quality, and for users, the smallest possible amount of
latency is preferable. Most existing metrics measure latency based on the start
timings of partial translations and ignore their duration. This means such
metrics do not penalize the latency caused by long translation output, which
delays the comprehension of users and subsequent translations. In this work, we
propose a novel latency evaluation metric for simultaneous translation called
\emph{Average Token Delay} (ATD) that focuses on the duration of partial
translations. We demonstrate its effectiveness through analyses simulating
user-side latency based on Ear-Voice Span (EVS). In our experiment, ATD had the
highest correlation with EVS among baseline latency metrics under most
conditions.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14354" title="Abstract">arXiv:2311.14354</a> [<a href="/pdf/2311.14354" title="Download PDF">pdf</a>, <a href="/format/2311.14354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modularity-based selection of the number of slices in temporal network  clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seiron%2C+P">Patrik Seiron</a>, 
<a href="/search/cs?searchtype=author&query=Lindegren%2C+A">Axel Lindegren</a>, 
<a href="/search/cs?searchtype=author&query=Magnani%2C+M">Matteo Magnani</a>, 
<a href="/search/cs?searchtype=author&query=Rohner%2C+C">Christian Rohner</a>, 
<a href="/search/cs?searchtype=author&query=Murata%2C+T">Tsuyoshi Murata</a>, 
<a href="/search/cs?searchtype=author&query=Holme%2C+P">Petter Holme</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Temporal Network Theory (2nd ed.), Petter Holme and Jari Saramaki,
  eds., (Springer, Cham, 2023), pp. 435-447
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">A popular way to cluster a temporal network is to transform it into a
sequence of networks, also called slices, where each slice corresponds to a
time interval and contains the vertices and edges existing in that interval. A
reason to perform this transformation is that after a network has been sliced,
existing algorithms designed to find clusters in multilayer networks can be
used. However, to use this approach, we need to know how many slices to
generate. This chapter discusses how to select the number of slices when
generalized modularity is used to identify the clusters.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14361" title="Abstract">arXiv:2311.14361</a> [<a href="/pdf/2311.14361" title="Download PDF">pdf</a>, <a href="/format/2311.14361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deciphering and integrating invariants for neural operator learning with  various physical mechanisms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+Q">Qi Meng</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhi-Ming Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Neural operators have been explored as surrogate models for simulating
physical systems to overcome the limitations of traditional partial
differential equation (PDE) solvers. However, most existing operator learning
methods assume that the data originate from a single physical mechanism,
limiting their applicability and performance in more realistic scenarios. To
this end, we propose Physical Invariant Attention Neural Operator (PIANO) to
decipher and integrate the physical invariants (PI) for operator learning from
the PDE series with various physical mechanisms. PIANO employs self-supervised
learning to extract physical knowledge and attention mechanisms to integrate
them into dynamic convolutional layers. Compared to existing techniques, PIANO
can reduce the relative error by 13.6\%-82.2\% on PDE forecasting tasks across
varying coefficients, forces, or boundary conditions. Additionally, varied
downstream tasks reveal that the PI embeddings deciphered by PIANO align well
with the underlying invariants in the PDE systems, verifying the physical
significance of PIANO. The source code will be publicly available at:
https://github.com/optray/PIANO.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14363" title="Abstract">arXiv:2311.14363</a> [<a href="/pdf/2311.14363" title="Download PDF">pdf</a>, <a href="/format/2311.14363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High order unfitted finite element discretizations for explicit boundary  representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Martorell%2C+P+A">Pere A. Martorell</a>, 
<a href="/search/cs?searchtype=author&query=Badia%2C+S">Santiago Badia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">When modeling scientific and industrial problems, geometries are typically
modeled by explicit boundary representations obtained from computer-aided
design software. Unfitted (also known as embedded or immersed) finite element
methods offer a significant advantage in dealing with complex geometries,
eliminating the need for generating unstructured body-fitted meshes. However,
current unfitted finite elements on nonlinear geometries are restricted to
implicit (possibly high-order) level set geometries. In this work, we introduce
a novel automatic computational pipeline to approximate solutions of partial
differential equations on domains defined by explicit nonlinear boundary
representations. For the geometrical discretization, we propose a novel
algorithm to generate quadratures for the bulk and surface integration on
nonlinear polytopes required to compute all the terms in unfitted finite
element methods. The algorithm relies on a nonlinear triangulation of the
boundary, a kd-tree refinement of the surface cells that simplify the nonlinear
intersections of surface and background cells to simple cases that are
diffeomorphically equivalent to linear intersections, robust polynomial
root-finding algorithms and surface parameterization techniques. We prove the
correctness of the proposed algorithm. We have successfully applied this
algorithm to simulate partial differential equations with unfitted finite
elements on nonlinear domains described by computer-aided design models,
demonstrating the robustness of the geometric algorithm and showing high-order
accuracy of the overall method.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14366" title="Abstract">arXiv:2311.14366</a> [<a href="/pdf/2311.14366" title="Download PDF">pdf</a>, <a href="/format/2311.14366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low regularity full error estimates for the cubic nonlinear  Schr&#xf6;dinger equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ji%2C+L">Lun Ji</a>, 
<a href="/search/math?searchtype=author&query=Ostermann%2C+A">Alexander Ostermann</a>, 
<a href="/search/math?searchtype=author&query=Rousset%2C+F">Fr&#xe9;d&#xe9;ric Rousset</a>, 
<a href="/search/math?searchtype=author&query=Schratz%2C+K">Katharina Schratz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2301.10639">arXiv:2301.10639</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">For the numerical solution of the cubic nonlinear Schr\"{o}dinger equation
with periodic boundary conditions, a pseudospectral method in space combined
with a filtered Lie splitting scheme in time is considered. This scheme is
shown to converge even for initial data with very low regularity. In
particular, for data in $H^s(\mathbb T^2)$, where $s&gt;0$, convergence of order
$\mathcal O(\tau^{s/2}+N^{-s})$ is proved in $L^2$. Here $\tau$ denotes the
time step size and $N$ the number of Fourier modes considered. The proof of
this result is carried out in an abstract framework of discrete Bourgain
spaces, the final convergence result, however, is given in $L^2$. The stated
convergence behavior is illustrated by several numerical examples.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14371" title="Abstract">arXiv:2311.14371</a> [<a href="/pdf/2311.14371" title="Download PDF">pdf</a>, <a href="/format/2311.14371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Transformed Learning for a Circular, Secure, and Tiny AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Weisi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Schyler Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bin Li</a>, 
<a href="/search/cs?searchtype=author&query=Blakeman%2C+S">Sam Blakeman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep Learning (DL) is penetrating into a diverse range of mass mobility,
smart living, and industrial applications, rapidly transforming the way we live
and work. DL is at the heart of many AI implementations. A key set of
challenges is to produce AI modules that are: (1) "circular" - can solve new
tasks without forgetting how to solve previous ones, (2) "secure" - have
immunity to adversarial data attacks, and (3) "tiny" - implementable in low
power low cost embedded hardware. Clearly it is difficult to achieve all three
aspects on a single horizontal layer of platforms, as the techniques require
transformed deep representations that incur different computation and
communication requirements. Here we set out the vision to achieve transformed
DL representations across a 5G and Beyond networked architecture. We first
detail the cross-sectoral motivations for each challenge area, before
demonstrating recent advances in DL research that can achieve circular, secure,
and tiny AI (CST-AI). Recognising the conflicting demand of each transformed
deep representation, we federate their deep learning transformations and
functionalities across the network to achieve connected run-time capabilities.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14373" title="Abstract">arXiv:2311.14373</a> [<a href="/pdf/2311.14373" title="Download PDF">pdf</a>, <a href="/format/2311.14373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Local To Global Optimality in Concurrent Parity Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bordais%2C+B">Benjamin Bordais</a>, 
<a href="/search/cs?searchtype=author&query=Bouyer%2C+P">Patricia Bouyer</a>, 
<a href="/search/cs?searchtype=author&query=Roux%2C+S+L">St&#xe9;phane Le Roux</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We study two-player games on finite graphs. Turn-based games have many nice
properties, but concurrent games are harder to tame: e.g. turn-based stochastic
parity games have positional optimal strategies, whereas even basic concurrent
reachability games may fail to have optimal strategies. We study concurrent
stochastic parity games, and identify a local structural condition that, when
satisfied at each state, guarantees existence of positional optimal strategies
for both players.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14375" title="Abstract">arXiv:2311.14375</a> [<a href="/pdf/2311.14375" title="Download PDF">pdf</a>, <a href="/ps/2311.14375" title="Download PostScript">ps</a>, <a href="/format/2311.14375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the radial discretization of finite element spaces in the scaled  boundary finite element method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Daneshyar%2C+A">Alireza Daneshyar</a>, 
<a href="/search/math?searchtype=author&query=Kollmannsberger%2C+S">Stefan Kollmannsberger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The scaled boundary finite element method is known for its capability in
reproducing highly-detailed solution fields. This, however, is only attainable
in those cases where analytical solutions exist. Many others invoke the use of
numerical methods that only provide the response of boundaries. Hence, no
information on the inner-subdomain solution fields can be recovered. As a
remedy, we propose a new solution scheme by which the interior fields of
subdomains can be recovered.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14378" title="Abstract">arXiv:2311.14378</a> [<a href="/pdf/2311.14378" title="Download PDF">pdf</a>, <a href="/ps/2311.14378" title="Download PostScript">ps</a>, <a href="/format/2311.14378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ethical implications of ChatGPT in higher education: A scoping review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Ming Li</a>, 
<a href="/search/cs?searchtype=author&query=Enkhtur%2C+A">Ariunaa Enkhtur</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+F">Fei Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Yamamoto%2C+B+A">Beverley Anne Yamamoto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">This scoping review explores the ethical challenges of using ChatGPT in
education, focusing particularly on issues related to higher education. By
reviewing recent academic articles written in English, Chinese, and Japanese,
we aimed to provide a comprehensive overview of relevant research while
identifying gaps for future considerations. Drawing on Arksey and O'Malley's
(2005) five-stage scoping review framework, we identified research questions,
search terms, and conducted article search from four databases in the target
three languages. Each article was reviewed by at least two researchers
identifying the main ethical issues of utilizing AI in education, particularly
higher education. Our analysis of ethical issues followed the framework
developed by DeepMind (Weiginger et al., 2021) to identify six main areas of
ethical concern in Language Models. The majority of papers were concerned with
misinformation harms (n=25) and/or human-computer interaction related harms
(n=24). Given the rapid deployment of Generative Artificial Intelligence (GAI),
it is imperative for educators to conduct more empirical studies to develop
sound ethical policies for the use of GAI.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14379" title="Abstract">arXiv:2311.14379</a> [<a href="/pdf/2311.14379" title="Download PDF">pdf</a>, <a href="/ps/2311.14379" title="Download PostScript">ps</a>, <a href="/format/2311.14379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robot Learning in the Era of Foundation Models: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xuan Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiahang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhipeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yanmin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yong Qi</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Q">Qian Cheng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+B">Bin He</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Shuo Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The proliferation of Large Language Models (LLMs) has s fueled a shift in
robot learning from automation towards general embodied Artificial Intelligence
(AI). Adopting foundation models together with traditional learning methods to
robot learning has increasingly gained recent interest research community and
showed potential for real-life application. However, there are few literatures
comprehensively reviewing the relatively new technologies combined with
robotics. The purpose of this review is to systematically assess the
state-of-the-art foundation model techniques in the robot learning and to
identify future potential areas. Specifically, we first summarized the
technical evolution of robot learning and identified the necessary preliminary
preparations for foundation models including the simulators, datasets,
foundation model framework. In addition, we focused on the following four
mainstream areas of robot learning including manipulation, navigation,
planning, and reasoning and demonstrated how the foundation model techniques
can be adopted in the above scenarios. Furthermore, critical issues which are
neglected in the current literatures including robot hardware and software
decoupling, dynamic data, generalization performance with the presence of
human, etc. were discussed. This review highlights the state-of-the-art
progress of foundation models in robot learning and future research should
focus on multimodal interaction especially dynamics data, exclusive foundation
models for robots, and AI alignment, etc.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14381" title="Abstract">arXiv:2311.14381</a> [<a href="/pdf/2311.14381" title="Download PDF">pdf</a>, <a href="/ps/2311.14381" title="Download PostScript">ps</a>, <a href="/format/2311.14381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Potential Societal Biases of ChatGPT in Higher Education: A Scoping  Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Ming Li</a>, 
<a href="/search/cs?searchtype=author&query=Enkhtur%2C+A">Ariunaa Enkhtur</a>, 
<a href="/search/cs?searchtype=author&query=Yamamoto%2C+B+A">Beverley Anne Yamamoto</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+F">Fei Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">ChatGPT and other Generative Artificial Intelligence (GAI) models tend to
inherit and even amplify prevailing societal biases as they are trained on
large amounts of existing data. Given the increasing usage of ChatGPT and other
GAI by students, faculty members, and staff in higher education institutions
(HEIs), there is an urgent need to examine the ethical issues involved such as
its potential biases. In this scoping review, we clarify the ways in which
biases related to GAI in higher education settings have been discussed in
recent academic publications and identify what type of potential biases are
commonly reported in this body of literature. We searched for academic articles
written in English, Chinese, and Japanese across four main databases concerned
with GAI usage in higher education and bias. Our findings show that while there
is an awareness of potential biases around large language models (LLMs) and
GAI, the majority of articles touch on ``bias'' at a relatively superficial
level. Few identify what types of bias may occur under what circumstances.
Neither do they discuss the possible implications for the higher education,
staff, faculty members, or students. There is a notable lack of empirical work
at this point, and we call for higher education researchers and AI experts to
conduct more research in this area.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14386" title="Abstract">arXiv:2311.14386</a> [<a href="/pdf/2311.14386" title="Download PDF">pdf</a>, <a href="/format/2311.14386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collective Memory, Consensus, and Learning explained by Network  Connectivity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bruggeman%2C+J">Jeroen Bruggeman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Humans cluster in social groups where they discuss their shared past,
problems, and potential solutions, learn collectively when they repeat
activities, synchronize when they sing or dance together, and bond through
social cohesion. By representing a group network by a Laplacian matrix, the
outcomes of these activities, as well as group's cohesion, can be predicted by
its second smallest eigenvalue, called algebraic connectivity. It predicts well
when processes converge towards a consensus or focal activity, but it cannot
predict divergence, such as division of labor or polarization.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14387" title="Abstract">arXiv:2311.14387</a> [<a href="/pdf/2311.14387" title="Download PDF">pdf</a>, <a href="/format/2311.14387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Achieving Margin Maximization Exponentially Fast via Progressive Norm  Rescaling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mingze Wang</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+Z">Zeping Min</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lei Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">In this work, we investigate the margin-maximization bias exhibited by
gradient-based algorithms in classifying linearly separable data. We present an
in-depth analysis of the specific properties of the velocity field associated
with (normalized) gradients, focusing on their role in margin maximization.
Inspired by this analysis, we propose a novel algorithm called Progressive
Rescaling Gradient Descent (PRGD) and show that PRGD can maximize the margin at
an {\em exponential rate}. This stands in stark contrast to all existing
algorithms, which maximize the margin at a slow {\em polynomial rate}.
Specifically, we identify mild conditions on data distribution under which
existing algorithms such as gradient descent (GD) and normalized gradient
descent (NGD) {\em provably fail} in maximizing the margin efficiently. To
validate our theoretical findings, we present both synthetic and real-world
experiments. Notably, PRGD also shows promise in enhancing the generalization
performance when applied to linearly non-separable datasets and deep neural
networks.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14388" title="Abstract">arXiv:2311.14388</a> [<a href="/pdf/2311.14388" title="Download PDF">pdf</a>, <a href="/format/2311.14388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Parameterized Generative Adversarial Network Using Cyclic Projection  for Explainable Medical Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+X">Xiangyu Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yue Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaohong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+C">ChanTong Lam</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+T">Tong Tong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Q">Qinquan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+W">Wei Ke</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+T">Tao Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Although current data augmentation methods are successful to alleviate the
data insufficiency, conventional augmentation are primarily intra-domain while
advanced generative adversarial networks (GANs) generate images remaining
uncertain, particularly in small-scale datasets. In this paper, we propose a
parameterized GAN (ParaGAN) that effectively controls the changes of synthetic
samples among domains and highlights the attention regions for downstream
classification. Specifically, ParaGAN incorporates projection distance
parameters in cyclic projection and projects the source images to the decision
boundary to obtain the class-difference maps. Our experiments show that ParaGAN
can consistently outperform the existing augmentation methods with explainable
classification on two small-scale medical datasets.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14390" title="Abstract">arXiv:2311.14390</a> [<a href="/pdf/2311.14390" title="Download PDF">pdf</a>, <a href="/format/2311.14390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Directly Attention Loss Adjusted Prioritized Experience Replay
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuoying Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huiping Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaoxu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Prioritized Experience Replay (PER) enables the model to learn more about
relatively important samples by artificially changing their accessed
frequencies. However, this non-uniform sampling method shifts the state-action
distribution that is originally used to estimate Q-value functions, which
brings about the estimation deviation. In this article, an novel off policy
reinforcement learning training framework called Directly Attention Loss
Adjusted Prioritized Experience Replay (DALAP) is proposed, which can directly
quantify the changed extent of the shifted distribution through Parallel
Self-Attention network, so as to accurately compensate the error. In addition,
a Priority-Encouragement mechanism is designed simultaneously to optimize the
sample screening criterion, and further improve the training efficiency. In
order to verify the effectiveness and generality of DALAP, we integrate it with
the value-function based, the policy-gradient based and multi-agent
reinforcement learning algorithm, respectively. The multiple groups of
comparative experiments show that DALAP has the significant advantages of both
improving the convergence rate and reducing the training variance.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14391" title="Abstract">arXiv:2311.14391</a> [<a href="/pdf/2311.14391" title="Download PDF">pdf</a>, <a href="/format/2311.14391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &#xda;FAL CorPipe at CRAC 2023: Larger Context Improves Multilingual  Coreference Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Straka%2C+M">Milan Straka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CRAC 2023 (the Sixth Workshop on Computational Models of Reference, Anaphora and Coreference)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We present CorPipe, the winning entry to the CRAC 2023 Shared Task on
Multilingual Coreference Resolution. Our system is an improved version of our
earlier multilingual coreference pipeline, and it surpasses other participants
by a large margin of 4.5 percent points. CorPipe first performs mention
detection, followed by coreference linking via an antecedent-maximization
approach on the retrieved spans. Both tasks are trained jointly on all
available corpora using a shared pretrained language model. Our main
improvements comprise inputs larger than 512 subwords and changing the mention
decoding to support ensembling. The source code is available at
https://github.com/ufal/crac2023-corpipe.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14395" title="Abstract">arXiv:2311.14395</a> [<a href="/pdf/2311.14395" title="Download PDF">pdf</a>, <a href="/format/2311.14395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-scale Semantic Correlation Mining for Visible-Infrared Person  Re-Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+K">Ke Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+X">Xuecheng Hua</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+J">Juanjuan Tu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuanquan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shitong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The main challenge in the Visible-Infrared Person Re-Identification (VI-ReID)
task lies in how to extract discriminative features from different modalities
for matching purposes. While the existing well works primarily focus on
minimizing the modal discrepancies, the modality information can not thoroughly
be leveraged. To solve this problem, a Multi-scale Semantic Correlation Mining
network (MSCMNet) is proposed to comprehensively exploit semantic features at
multiple scales and simultaneously reduce modality information loss as small as
possible in feature extraction. The proposed network contains three novel
components. Firstly, after taking into account the effective utilization of
modality information, the Multi-scale Information Correlation Mining Block
(MIMB) is designed to explore semantic correlations across multiple scales.
Secondly, in order to enrich the semantic information that MIMB can utilize, a
quadruple-stream feature extractor (QFE) with non-shared parameters is
specifically designed to extract information from different dimensions of the
dataset. Finally, the Quadruple Center Triplet Loss (QCT) is further proposed
to address the information discrepancy in the comprehensive features. Extensive
experiments on the SYSU-MM01, RegDB, and LLCM datasets demonstrate that the
proposed MSCMNet achieves the greatest accuracy.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14400" title="Abstract">arXiv:2311.14400</a> [<a href="/pdf/2311.14400" title="Download PDF">pdf</a>, <a href="/format/2311.14400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Higher-order iterative decoupling for poroelasticity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Altmann%2C+R">Robert Altmann</a>, 
<a href="/search/math?searchtype=author&query=Mujahid%2C+A">Abdullah Mujahid</a>, 
<a href="/search/math?searchtype=author&query=Unger%2C+B">Benjamin Unger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">For the iterative decoupling of elliptic-parabolic problems such as
poroelasticity, we introduce time discretization schemes up to order $5$ based
on the backward differentiation formulae. Its analysis combines techniques
known from fixed-point iterations with the convergence analysis of the temporal
discretization. As the main result, we show that the convergence depends on the
interplay between the time step size and the parameters for the contraction of
the iterative scheme. Moreover, this connection is quantified explicitly, which
allows for balancing the single error components. Several numerical experiments
illustrate and validate the theoretical results, including a three-dimensional
example from biomechanics.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14401" title="Abstract">arXiv:2311.14401</a> [<a href="/pdf/2311.14401" title="Download PDF">pdf</a>, <a href="/format/2311.14401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prototype of deployment of Federated Learning with IoT devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Santaclara%2C+P+G">Pablo Garc&#xed;a Santaclara</a>, 
<a href="/search/cs?searchtype=author&query=Vilas%2C+A+F">Ana Fern&#xe1;ndez Vilas</a>, 
<a href="/search/cs?searchtype=author&query=Redondo%2C+R+P+D">Rebeca P. D&#xed;az Redondo</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 19th ACM International Symposium on Performance
  Evaluation of Wireless Ad Hoc, Sensor, Ubiquitous Networks. October 2022.
  Pages 9-16
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">In the age of technology, data is an increasingly important resource. This
importance is growing in the field of Artificial Intelligence (AI), where sub
fields such as Machine Learning (ML) need more and more data to achieve better
results. Internet of Things (IoT) is the connection of sensors and smart
objects to collect and exchange data, in addition to achieving many other
tasks. A huge amount of the resource desired, data, is stored in mobile
devices, sensors and other Internet of Things (IoT) devices, but remains there
due to data protection restrictions. At the same time these devices do not have
enough data or computational capacity to train good models. Moreover,
transmitting, storing and processing all this data on a centralised server is
problematic. Federated Learning (FL) provides an innovative solution that
allows devices to learn in a collaborative way. More importantly, it
accomplishes this without violating data protection laws. FL is currently
growing, and there are several solutions that implement it. This article
presents a prototype of a FL solution where the IoT devices used were raspberry
pi boards. The results compare the performance of a solution of this type with
those obtained in traditional approaches. In addition, the FL solution
performance was tested in a hostile environment. A convolutional neural network
(CNN) and a image data set were used. The results show the feasibility and
usability of these techniques, although in many cases they do not reach the
performance of traditional approaches.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14402" title="Abstract">arXiv:2311.14402</a> [<a href="/pdf/2311.14402" title="Download PDF">pdf</a>, <a href="/format/2311.14402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TEA: Test-time Energy Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yige Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Bingbing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+L">Liang Hou</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+F">Fei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Huawei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xueqi Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 10 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Test-time adaptation (TTA) aims to improve model generalizability when test
data diverges from training distribution, offering the distinct advantage of
not requiring access to training data and processes, especially valuable in the
context of large pre-trained models. However, current TTA methods fail to
address the fundamental issue: covariate shift, i.e., the decreased
generalizability can be attributed to the model's reliance on the marginal
distribution of the training data, which may impair model calibration and
introduce confirmation bias. To address this, we propose a novel energy-based
perspective, enhancing the model's perception of target data distributions
without requiring access to training data or processes. Building on this
perspective, we introduce $\textbf{T}$est-time $\textbf{E}$nergy
$\textbf{A}$daptation ($\textbf{TEA}$), which transforms the trained classifier
into an energy-based model and aligns the model's distribution with the test
data's, enhancing its ability to perceive test distributions and thus improving
overall generalizability. Extensive experiments across multiple tasks,
benchmarks and architectures demonstrate TEA's superior generalization
performance against state-of-the-art methods. Further in-depth analyses reveal
that TEA can equip the model with a comprehensive perception of test
distribution, ultimately paving the way toward improved generalization and
calibration.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14404" title="Abstract">arXiv:2311.14404</a> [<a href="/pdf/2311.14404" title="Download PDF">pdf</a>, <a href="/format/2311.14404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BHGNN-RT: Network embedding for directed heterogeneous graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiyang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Komaki%2C+F">Fumiyasu Komaki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Networks are one of the most valuable data structures for modeling problems
in the real world. However, the most recent node embedding strategies have
focused on undirected graphs, with limited attention to directed graphs,
especially directed heterogeneous graphs. In this study, we first investigated
the network properties of directed heterogeneous graphs. Based on network
analysis, we proposed an embedding method, a bidirectional heterogeneous graph
neural network with random teleport (BHGNN-RT), for directed heterogeneous
graphs, that leverages bidirectional message-passing process and network
heterogeneity. With the optimization of teleport proportion, BHGNN-RT is
beneficial to overcome the over-smoothing problem. Extensive experiments on
various datasets were conducted to verify the efficacy and efficiency of
BHGNN-RT. Furthermore, we investigated the effects of message components, model
layer, and teleport proportion on model performance. The performance comparison
with all other baselines illustrates that BHGNN-RT achieves state-of-the-art
performance, outperforming the benchmark methods in both node classification
and unsupervised clustering tasks.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14405" title="Abstract">arXiv:2311.14405</a> [<a href="/pdf/2311.14405" title="Download PDF">pdf</a>, <a href="/format/2311.14405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OneFormer3D: One Transformer for Unified Point Cloud Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kolodiazhnyi%2C+M">Maxim Kolodiazhnyi</a>, 
<a href="/search/cs?searchtype=author&query=Vorontsova%2C+A">Anna Vorontsova</a>, 
<a href="/search/cs?searchtype=author&query=Konushin%2C+A">Anton Konushin</a>, 
<a href="/search/cs?searchtype=author&query=Rukhovich%2C+D">Danila Rukhovich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Semantic, instance, and panoptic segmentation of 3D point clouds have been
addressed using task-specific models of distinct design. Thereby, the
similarity of all segmentation tasks and the implicit relationship between them
have not been utilized effectively. This paper presents a unified, simple, and
effective model addressing all these tasks jointly. The model, named
OneFormer3D, performs instance and semantic segmentation consistently, using a
group of learnable kernels, where each kernel is responsible for generating a
mask for either an instance or a semantic category. These kernels are trained
with a transformer-based decoder with unified instance and semantic queries
passed as an input. Such a design enables training a model end-to-end in a
single run, so that it achieves top performance on all three segmentation tasks
simultaneously. Specifically, our OneFormer3D ranks 1st and sets a new
state-of-the-art (+2.1 mAP50) in the ScanNet test leaderboard. We also
demonstrate the state-of-the-art results in semantic, instance, and panoptic
segmentation of ScanNet (+21 PQ), ScanNet200 (+3.8 mAP50), and S3DIS (+0.8
mIoU) datasets.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14407" title="Abstract">arXiv:2311.14407</a> [<a href="/pdf/2311.14407" title="Download PDF">pdf</a>, <a href="/format/2311.14407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLamol: A Dynamic Multi-Conditional Generative Transformer for De Novo  Molecular Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dobberstein%2C+N">Niklas Dobberstein</a>, 
<a href="/search/cs?searchtype=author&query=Maass%2C+A">Astrid Maass</a>, 
<a href="/search/cs?searchtype=author&query=Hamaekers%2C+J">Jan Hamaekers</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Chemical Physics (physics.chem-ph)

</div>
<p class="mathjax">Generative models have demonstrated substantial promise in Natural Language
Processing (NLP) and have found application in designing molecules, as seen in
General Pretrained Transformer (GPT) models. In our efforts to develop such a
tool for exploring the organic chemical space in search of potentially
electro-active compounds, we present "LLamol", a single novel generative
transformer model based on the LLama 2 architecture, which was trained on a 13M
superset of organic compounds drawn from diverse public sources. To allow for a
maximum flexibility in usage and robustness in view of potentially incomplete
data, we introduce "Stochastic Context Learning" as a new training procedure.
We demonstrate that the resulting model adeptly handles single- and
multi-conditional organic molecule generation with up to four conditions, yet
more are possible. The model generates valid molecular structures in SMILES
notation while flexibly incorporating three numerical and/or one token sequence
into the generative process, just as requested. The generated compounds are
very satisfactory in all scenarios tested. In detail, we showcase the model's
capability to utilize token sequences for conditioning, either individually or
in combination with numerical properties, making LLamol a potent tool for de
novo molecule design, easily expandable with new properties.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14410" title="Abstract">arXiv:2311.14410</a> [<a href="/pdf/2311.14410" title="Download PDF">pdf</a>, <a href="/format/2311.14410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling The Factors of Aesthetic Preferences with Explainable AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soydaner%2C+D">Derya Soydaner</a>, 
<a href="/search/cs?searchtype=author&query=Wagemans%2C+J">Johan Wagemans</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The allure of aesthetic appeal in images captivates our senses, yet the
underlying intricacies of aesthetic preferences remain elusive. In this study,
we pioneer a novel perspective by utilizing machine learning models that focus
on aesthetic attributes known to influence preferences. Through a data mining
approach, our models process these attributes as inputs to predict the
aesthetic scores of images. Moreover, to delve deeper and obtain interpretable
explanations regarding the factors driving aesthetic preferences, we utilize
the popular Explainable AI (XAI) technique known as SHapley Additive
exPlanations (SHAP). Our methodology involves employing various machine
learning models, including Random Forest, XGBoost, Support Vector Regression,
and Multilayer Perceptron, to compare their performances in accurately
predicting aesthetic scores, and consistently observing results in conjunction
with SHAP. We conduct experiments on three image aesthetic benchmarks,
providing insights into the roles of attributes and their interactions.
Ultimately, our study aims to shed light on the complex nature of aesthetic
preferences in images through machine learning and provides a deeper
understanding of the attributes that influence aesthetic judgements.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14411" title="Abstract">arXiv:2311.14411</a> [<a href="/pdf/2311.14411" title="Download PDF">pdf</a>, <a href="/format/2311.14411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Receding Horizon Optimization with PPUM: An Approach for Autonomous  Robot Path Planning in Uncertain Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ge%2C+Z">Zijian Ge</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jingjing Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Coombes%2C+M">Matthew Coombes</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Liang Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The ability to understand spatial-temporal patterns for crowds of people is
crucial for achieving long-term autonomy of mobile robots deployed in human
environments. However, traditional historical data-driven memory models are
inadequate for handling anomalies, resulting in poor reasoning by robot in
estimating the crowd spatial distribution. In this article, a Receding Horizon
Optimization (RHO) formulation is proposed that incorporates a
Probability-related Partially Updated Memory (PPUM) for robot path planning in
crowded environments with uncertainties. The PPUM acts as a memory layer that
combines real-time sensor observations with historical knowledge using a
weighted evidence fusion theory to improve robot's adaptivity to the dynamic
environments. RHO then utilizes the PPUM as a informed knowledge to generate a
path that minimizes the likelihood of encountering dense crowds while reducing
the cost of local motion planning. The proposed approach provides an innovative
solution to the problem of robot's long-term safe interaction with human in
uncertain crowded environments. In simulation, the results demonstrate the
superior performance of our approach compared to benchmark methods in terms of
crowd distribution estimation accuracy, adaptability to anomalies and path
planning efficiency.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14412" title="Abstract">arXiv:2311.14412</a> [<a href="/pdf/2311.14412" title="Download PDF">pdf</a>, <a href="/ps/2311.14412" title="Download PostScript">ps</a>, <a href="/format/2311.14412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparison of PDF Projection with Normalizing Flows and SurVAE
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baggenstoss%2C+P+M">Paul M. Baggenstoss</a>, 
<a href="/search/cs?searchtype=author&query=Govaers%2C+F">Felix Govaers</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
<p class="mathjax">Normalizing flows (NF) recently gained attention as a way to construct
generative networks with exact likelihood calculation out of composable layers.
However, NF is restricted to dimension-preserving transformations. Surjection
VAE (SurVAE) has been proposed to extend NF to dimension-altering
transformations. Such networks are desirable because they are expressive and
can be precisely trained. We show that the approaches are a re-invention of PDF
projection, which appeared over twenty years earlier and is much further
developed.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14421" title="Abstract">arXiv:2311.14421</a> [<a href="/pdf/2311.14421" title="Download PDF">pdf</a>, <a href="/format/2311.14421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximation of Convex Envelope Using Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Borkar%2C+V+S">Vivek S. Borkar</a>, 
<a href="/search/eess?searchtype=author&query=Akarsh%2C+A">Adit Akarsh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Oberman gave a stochastic control formulation of the problem of estimating
the convex envelope of a non-convex function. Based on this, we develop a
reinforcement learning scheme to approximate the convex envelope, using a
variant of Q-learning for controlled optimal stopping. It shows very promising
results on a standard library of test problems.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14422" title="Abstract">arXiv:2311.14422</a> [<a href="/pdf/2311.14422" title="Download PDF">pdf</a>, <a href="/ps/2311.14422" title="Download PostScript">ps</a>, <a href="/format/2311.14422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigation on the Impact of Heat Waves on Distribution System  Failures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mazza%2C+A">Andrea Mazza</a>, 
<a href="/search/eess?searchtype=author&query=Chicco%2C+G">Gianfranco Chicco</a>, 
<a href="/search/eess?searchtype=author&query=Borges%2C+C+L+T">Carmen L.T. Borges</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper discusses some aspects referring to the characterization and
modelling of the resilience of distribution systems in the presence of heat
waves. The aim is to identify the specific features that can lead to more
detailed modelling of the impact of heat waves on the failures that happen in
distribution systems. In particular, with heat waves there are differences
between the cumulative distribution function of the time to failure in
practical cases and in the theoretical reference used for reliability analysis.
These differences may be considered to refine the resilience models due to heat
waves. Examples taken from real cases are illustrated and commented.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14426" title="Abstract">arXiv:2311.14426</a> [<a href="/pdf/2311.14426" title="Download PDF">pdf</a>, <a href="/format/2311.14426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human-Machine Cooperative Multimodal Learning Method for Cross-subject  Olfactory Preference Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+X">Xiuxin Xia</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuchen Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuchao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Men%2C+H">Hong Men</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Odor sensory evaluation has a broad application in food, clothing, cosmetics,
and other fields. Traditional artificial sensory evaluation has poor
repeatability, and the machine olfaction represented by the electronic nose
(E-nose) is difficult to reflect human feelings. Olfactory electroencephalogram
(EEG) contains odor and individual features associated with human olfactory
preference, which has unique advantages in odor sensory evaluation. However,
the difficulty of cross-subject olfactory EEG recognition greatly limits its
application. It is worth noting that E-nose and olfactory EEG are more
advantageous in representing odor information and individual emotions,
respectively. In this paper, an E-nose and olfactory EEG multimodal learning
method is proposed for cross-subject olfactory preference recognition. Firstly,
the olfactory EEG and E-nose multimodal data acquisition and preprocessing
paradigms are established. Secondly, a complementary multimodal data mining
strategy is proposed to effectively mine the common features of multimodal data
representing odor information and the individual features in olfactory EEG
representing individual emotional information. Finally, the cross-subject
olfactory preference recognition is achieved in 24 subjects by fusing the
extracted common and individual features, and the recognition effect is
superior to the state-of-the-art recognition methods. Furthermore, the
advantages of the proposed method in cross-subject olfactory preference
recognition indicate its potential for practical odor evaluation applications.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14431" title="Abstract">arXiv:2311.14431</a> [<a href="/pdf/2311.14431" title="Download PDF">pdf</a>, <a href="/format/2311.14431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What you need to know about a learning robot: Identifying the enabling  architecture of complex systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beierling%2C+H">Helen Beierling</a>, 
<a href="/search/cs?searchtype=author&query=Richter%2C+P">Phillip Richter</a>, 
<a href="/search/cs?searchtype=author&query=Brandt%2C+M">Mara Brandt</a>, 
<a href="/search/cs?searchtype=author&query=Terfloth%2C+L">Lutz Terfloth</a>, 
<a href="/search/cs?searchtype=author&query=Schulte%2C+C">Carsten Schulte</a>, 
<a href="/search/cs?searchtype=author&query=Wersing%2C+H">Heiko Wersing</a>, 
<a href="/search/cs?searchtype=author&query=Vollmer%2C+A">Anna-Lisa Vollmer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in Cognitive Systems Research
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Nowadays, we are dealing more and more with robots and AI in everyday life.
However, their behavior is not always apparent to most lay users, especially in
error situations. As a result, there can be misconceptions about the behavior
of the technologies in use. This, in turn, can lead to misuse and rejection by
users. Explanation, for example, through transparency, can address these
misconceptions. However, it would be confusing and overwhelming for users if
the entire software or hardware was explained. Therefore, this paper looks at
the 'enabling' architecture. It describes those aspects of a robotic system
that might need to be explained to enable someone to use the technology
effectively. Furthermore, this paper is concerned with the 'explanandum', which
is the corresponding misunderstanding or missing concepts of the enabling
architecture that needs to be clarified. We have thus developed and present an
approach for determining this 'enabling' architecture and the resulting
'explanandum' of complex technologies.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14435" title="Abstract">arXiv:2311.14435</a> [<a href="/pdf/2311.14435" title="Download PDF">pdf</a>, <a href="/format/2311.14435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GCPV: Guided Concept Projection Vectors for the Explainable Inspection  of CNN Feature Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mikriukov%2C+G">Georgii Mikriukov</a>, 
<a href="/search/cs?searchtype=author&query=Schwalbe%2C+G">Gesina Schwalbe</a>, 
<a href="/search/cs?searchtype=author&query=Hellert%2C+C">Christian Hellert</a>, 
<a href="/search/cs?searchtype=author&query=Bade%2C+K">Korinna Bade</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">For debugging and verification of computer vision convolutional deep neural
networks (CNNs) human inspection of the learned latent representations is
imperative. Therefore, state-of-the-art eXplainable Artificial Intelligence
(XAI) methods globally associate given natural language semantic concepts with
representing vectors or regions in the CNN latent space supporting manual
inspection. Yet, this approach comes with two major disadvantages: They are
locally inaccurate when reconstructing a concept label and discard information
about the distribution of concept instance representations. The latter, though,
is of particular interest for debugging, like finding and understanding
outliers, learned notions of sub-concepts, and concept confusion. Furthermore,
current single-layer approaches neglect that information about a concept may be
spread over the CNN depth. To overcome these shortcomings, we introduce the
local-to-global Guided Concept Projection Vectors (GCPV) approach: It (1)
generates local concept vectors that each precisely reconstruct a concept
segmentation label, and then (2) generalizes these to global concept and even
sub-concept vectors by means of hiearchical clustering. Our experiments on
object detectors demonstrate improved performance compared to the
state-of-the-art, the benefit of multi-layer concept vectors, and robustness
against low-quality concept segmentation labels. Finally, we demonstrate that
GCPVs can be applied to find root causes for confusion of concepts like bus and
truck, and reveal interesting concept-level outliers. Thus, GCPVs pose a
promising step towards interpretable model debugging and informed data
improvement.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14443" title="Abstract">arXiv:2311.14443</a> [<a href="/pdf/2311.14443" title="Download PDF">pdf</a>, <a href="/ps/2311.14443" title="Download PostScript">ps</a>, <a href="/format/2311.14443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Petit programming language and compiler
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barbosa%2C+R">Raul Barbosa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Petit is an educational programming language for learning compilers. Students
embark on the journey of learning compilers through a series of six tutorials,
progressing from topics like lexical analysis and syntactic analysis to
semantic analysis and code generation. The initial tutorials in this series
cover the practical applications of the lex and yacc tools, while the
concluding tutorial focuses on generating LLVM intermediate representation.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14450" title="Abstract">arXiv:2311.14450</a> [<a href="/pdf/2311.14450" title="Download PDF">pdf</a>, <a href="/format/2311.14450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segment (Almost) Nothing: Prompt-Agnostic Adversarial Attacks on  Segmentation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Croce%2C+F">Francesco Croce</a>, 
<a href="/search/cs?searchtype=author&query=Hein%2C+M">Matthias Hein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">General purpose segmentation models are able to generate (semantic)
segmentation masks from a variety of prompts, including visual (points, boxed,
etc.) and textual (object names) ones. In particular, input images are
pre-processed by an image encoder to obtain embedding vectors which are later
used for mask predictions. Existing adversarial attacks target the end-to-end
tasks, i.e. aim at altering the segmentation mask predicted for a specific
image-prompt pair. However, this requires running an individual attack for each
new prompt for the same image. We propose instead to generate prompt-agnostic
adversarial attacks by maximizing the $\ell_2$-distance, in the latent space,
between the embedding of the original and perturbed images. Since the encoding
process only depends on the image, distorted image representations will cause
perturbations in the segmentation masks for a variety of prompts. We show that
even imperceptible $\ell_\infty$-bounded perturbations of radius
$\epsilon=1/255$ are often sufficient to drastically modify the masks predicted
with point, box and text prompts by recently proposed foundation models for
segmentation. Moreover, we explore the possibility of creating universal, i.e.
non image-specific, attacks which can be readily applied to any input without
further computational cost.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14452" title="Abstract">arXiv:2311.14452</a> [<a href="/pdf/2311.14452" title="Download PDF">pdf</a>, <a href="/ps/2311.14452" title="Download PostScript">ps</a>, <a href="/format/2311.14452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Refinement Proofs in Rust Using Ghost Locks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C3%ADl%C3%BD%2C+A">Aurel B&#xed;l&#xfd;</a> (1), 
<a href="/search/cs?searchtype=author&query=Pereira%2C+J+C">Jo&#xe3;o C. Pereira</a> (1), 
<a href="/search/cs?searchtype=author&query=Sch%C3%A4r%2C+J">Jan Sch&#xe4;r</a> (1), 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+P">Peter M&#xfc;ller</a> (1) ((1) ETH Zurich)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 3 figures, submitted to PLDI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Refinement transforms an abstract system model into a concrete, executable
program, such that properties established for the abstract model carry over to
the concrete implementation. Refinement has been used successfully in the
development of substantial verified systems. Nevertheless, existing refinement
techniques have limitations that impede their practical usefulness. Some
techniques generate executable code automatically, which generally leads to
implementations with sub-optimal performance. Others employ bottom-up program
verification to reason about efficient implementations, but impose strict
requirements on the structure of the code, the structure of the refinement
proofs, as well as the employed verification logic and tools.
<br />In this paper, we present a novel refinement technique that removes these
limitations. It supports a wide range of program structures, data
representations, and proof structures. Our approach supports reasoning about
both safety and liveness properties. We implement our approach in a
state-of-the-art verifier for the Rust language, which itself offers a strong
foundation for memory safety. We demonstrate the practicality of our approach
on a number of substantial case studies.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14454" title="Abstract">arXiv:2311.14454</a> [<a href="/pdf/2311.14454" title="Download PDF">pdf</a>, <a href="/format/2311.14454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Robotic Experimenters help improve HRI Experiments? An Experimental  Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suissa%2C+D+R">Dan R. Suissa</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Shikhar Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Edan%2C+Y">Yael Edan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">To evaluate the design and skills of a robot or an algorithm for robotics,
human-robot interaction user studies need to be performed. Classically, these
studies are conducted by human experimenters, requiring considerable effort,
and introducing variability and potential human error. In this paper, we
investigate the use of robots in support of HRI experiments. Robots can perform
repeated tasks accurately, thereby reducing human effort and improving validity
through reduction of error and variability between participants. To assess the
potential for robot led HRI experiments, we ran an HRI experiment with two
participant groups, one led by a human experimenter and another led mostly by a
robot experimenter.We show that the replacement of several repetitive
experiment tasks through robots is not only possible but beneficial: Trials
performed by the robot experimenter had fewer errors and were more fluent.
There was no statistically significant difference in participants' perception
w.r.t. cognitive load, comfortability, enjoyment, safety, trust and
understandability between both groups. To the best of our knowledge, this is
the first comparison between robot-led and human-led HRI experiments. It
suggests that using robot experimenters can be beneficial and should be
considered.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14455" title="Abstract">arXiv:2311.14455</a> [<a href="/pdf/2311.14455" title="Download PDF">pdf</a>, <a href="/format/2311.14455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Jailbreak Backdoors from Poisoned Human Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rando%2C+J">Javier Rando</a>, 
<a href="/search/cs?searchtype=author&query=Tram%C3%A8r%2C+F">Florian Tram&#xe8;r</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Reinforcement Learning from Human Feedback (RLHF) is used to align large
language models to produce helpful and harmless responses. Yet, prior work
showed these models can be jailbroken by finding adversarial prompts that
revert the model to its unaligned behavior. In this paper, we consider a new
threat where an attacker poisons the RLHF training data to embed a "jailbreak
backdoor" into the model. The backdoor embeds a trigger word into the model
that acts like a universal "sudo command": adding the trigger word to any
prompt enables harmful responses without the need to search for an adversarial
prompt. Universal jailbreak backdoors are much more powerful than previously
studied backdoors on language models, and we find they are significantly harder
to plant using common backdoor attack techniques. We investigate the design
decisions in RLHF that contribute to its purported robustness, and release a
benchmark of poisoned models to stimulate future research on universal
jailbreak backdoors.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14457" title="Abstract">arXiv:2311.14457</a> [<a href="/pdf/2311.14457" title="Download PDF">pdf</a>, <a href="/ps/2311.14457" title="Download PostScript">ps</a>, <a href="/format/2311.14457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to ensure a safe control strategy? Towards a SRL for urban transit  autonomous operation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zicong Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages,11 figures,5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Deep reinforcement learning has gradually shown its latent decision-making
ability in urban rail transit autonomous operation. However, since
reinforcement learning can not neither guarantee safety during learning nor
execution, this is still one of the major obstacles to the practical
application of reinforcement learning. Given this drawback, reinforcement
learning applied in the safety-critical autonomous operation domain remains
challenging without generating a safe control command sequence that avoids
overspeed operations. Therefore, a SSA-DRL framework is proposed in this paper
for safe intelligent control of urban rail transit autonomous operation trains.
The proposed framework is combined with linear temporal logic, reinforcement
learning and Monte Carlo tree search and consists of four mainly module: a
post-posed shielding, a searching tree module, a DRL framework and an
additional actor. Furthermore, the output of the framework can meet speed
constraint, schedule constraint and optimize the operation process. Finally,
the proposed SSA-DRL framework for decision-making in urban rail transit
autonomous operation is evaluated in sixteen different sections, and its
effectiveness is demonstrated through an ablation experiment and comparison
with the scheduled operation plan.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14459" title="Abstract">arXiv:2311.14459</a> [<a href="/pdf/2311.14459" title="Download PDF">pdf</a>, <a href="/format/2311.14459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IDD-AW: A Benchmark for Safe and Robust Segmentation of Drive Scenes in  Unstructured Traffic and Adverse Weather
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shaik%2C+F+A">Furqan Ahmed Shaik</a>, 
<a href="/search/cs?searchtype=author&query=Malreddy%2C+A">Abhishek Malreddy</a>, 
<a href="/search/cs?searchtype=author&query=Billa%2C+N+R">Nikhil Reddy Billa</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhary%2C+K">Kunal Chaudhary</a>, 
<a href="/search/cs?searchtype=author&query=Manchanda%2C+S">Sunny Manchanda</a>, 
<a href="/search/cs?searchtype=author&query=Varma%2C+G">Girish Varma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages excluding references. Accepted in WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Large-scale deployment of fully autonomous vehicles requires a very high
degree of robustness to unstructured traffic, and weather conditions, and
should prevent unsafe mispredictions. While there are several datasets and
benchmarks focusing on segmentation for drive scenes, they are not specifically
focused on safety and robustness issues. We introduce the IDD-AW dataset, which
provides 5000 pairs of high-quality images with pixel-level annotations,
captured under rain, fog, low light, and snow in unstructured driving
conditions. As compared to other adverse weather datasets, we provide i.) more
annotated images, ii.) paired Near-Infrared (NIR) image for each frame, iii.)
larger label set with a 4-level label hierarchy to capture unstructured traffic
conditions. We benchmark state-of-the-art models for semantic segmentation in
IDD-AW. We also propose a new metric called ''Safe mean Intersection over Union
(Safe mIoU)'' for hierarchical datasets which penalizes dangerous
mispredictions that are not captured in the traditional definition of mean
Intersection over Union (mIoU). The results show that IDD-AW is one of the most
challenging datasets to date for these tasks. The dataset and code will be
available here: <a href="http://iddaw.github.io.">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14461" title="Abstract">arXiv:2311.14461</a> [<a href="/pdf/2311.14461" title="Download PDF">pdf</a>, <a href="/ps/2311.14461" title="Download PostScript">ps</a>, <a href="/format/2311.14461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safety Assessment of Vehicle Characteristics Variations in Autonomous  Driving Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+Q">Qi Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tiexin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Arcaini%2C+P">Paolo Arcaini</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+T">Tao Yue</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+S">Shaukat Ali</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Autonomous driving systems (ADSs) must be sufficiently tested to ensure their
safety. Though various ADS testing methods have shown promising results, they
are limited to a fixed set of vehicle characteristics settings (VCSs). The
impact of variations in vehicle characteristics (e.g., mass, tire friction) on
the safety of ADSs has not been sufficiently and systematically studied.Such
variations are often due to wear and tear, production errors, etc., which may
lead to unexpected driving behaviours of ADSs. To this end, in this paper, we
propose a method, named SAFEVAR, to systematically find minimum variations to
the original vehicle characteristics setting, which affect the safety of the
ADS deployed on the vehicle. To evaluate the effectiveness of SAFEVAR, we
employed two ADSs and conducted experiments with two driving simulators.
Results show that SAFEVAR, equipped with NSGA-II, generates more critical VCSs
that put the vehicle into unsafe situations, as compared with two baseline
algorithms: Random Search and a mutation-based fuzzer. We also identified
critical vehicle characteristics and reported to which extent varying their
settings put the ADS vehicles in unsafe situations.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14464" title="Abstract">arXiv:2311.14464</a> [<a href="/pdf/2311.14464" title="Download PDF">pdf</a>, <a href="/format/2311.14464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finite Volume Features, Global Geometry Representations, and Residual  Training for Deep Learning-based CFD Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jessica%2C+L+S+E">Loh Sher En Jessica</a>, 
<a href="/search/cs?searchtype=author&query=Arafat%2C+N+A">Naheed Anjum Arafat</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+W+X">Wei Xian Lim</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+W+L">Wai Lee Chan</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+A+W+K">Adams Wai Kin Kong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE); Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">Computational fluid dynamics (CFD) simulation is an irreplaceable modelling
step in many engineering designs, but it is often computationally expensive.
Some graph neural network (GNN)-based CFD methods have been proposed. However,
the current methods inherit the weakness of traditional numerical simulators,
as well as ignore the cell characteristics in the mesh used in the finite
volume method, a common method in practical CFD applications. Specifically, the
input nodes in these GNN methods have very limited information about any object
immersed in the simulation domain and its surrounding environment. Also, the
cell characteristics of the mesh such as cell volume, face surface area, and
face centroid are not included in the message-passing operations in the GNN
methods. To address these weaknesses, this work proposes two novel geometric
representations: Shortest Vector (SV) and Directional Integrated Distance
(DID). Extracted from the mesh, the SV and DID provide global geometry
perspective to each input node, thus removing the need to collect this
information through message-passing. This work also introduces the use of
Finite Volume Features (FVF) in the graph convolutions as node and edge
attributes, enabling its message-passing operations to adjust to different
nodes. Finally, this work is the first to demonstrate how residual training,
with the availability of low-resolution data, can be adopted to improve the
flow field prediction accuracy. Experimental results on two datasets with five
different state-of-the-art GNN methods for CFD indicate that SV, DID, FVF and
residual training can effectively reduce the predictive error of current
GNN-based methods by as much as 41%.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14465" title="Abstract">arXiv:2311.14465</a> [<a href="/pdf/2311.14465" title="Download PDF">pdf</a>, <a href="/format/2311.14465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DP-NMT: Scalable Differentially-Private Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Igamberdiev%2C+T">Timour Igamberdiev</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+D+N+L">Doan Nam Long Vu</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%BCnnecke%2C+F">Felix K&#xfc;nnecke</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhuo Yu</a>, 
<a href="/search/cs?searchtype=author&query=Holmer%2C+J">Jannik Holmer</a>, 
<a href="/search/cs?searchtype=author&query=Habernal%2C+I">Ivan Habernal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Neural machine translation (NMT) is a widely popular text generation task,
yet there is a considerable research gap in the development of
privacy-preserving NMT models, despite significant data privacy concerns for
NMT systems. Differentially private stochastic gradient descent (DP-SGD) is a
popular method for training machine learning models with concrete privacy
guarantees; however, the implementation specifics of training a model with
DP-SGD are not always clarified in existing models, with differing software
libraries used and code bases not always being public, leading to
reproducibility issues. To tackle this, we introduce DP-NMT, an open-source
framework for carrying out research on privacy-preserving NMT with DP-SGD,
bringing together numerous models, datasets, and evaluation metrics in one
systematic software package. Our goal is to provide a platform for researchers
to advance the development of privacy-preserving NMT systems, keeping the
specific details of the DP-SGD algorithm transparent and intuitive to
implement. We run a set of experiments on datasets from both general and
privacy-related domains to demonstrate our framework in use. We make our
framework publicly available and welcome feedback from the community.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14467" title="Abstract">arXiv:2311.14467</a> [<a href="/pdf/2311.14467" title="Download PDF">pdf</a>, <a href="/format/2311.14467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards an Efficient Simulation Approach for Transmission Systems with  ICT Infrastructures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sabot%2C+F">Fr&#xe9;d&#xe9;ric Sabot</a>, 
<a href="/search/eess?searchtype=author&query=Labeau%2C+P">Pierre-Etienne Labeau</a>, 
<a href="/search/eess?searchtype=author&query=Dricot%2C+J">Jean-Michel Dricot</a>, 
<a href="/search/eess?searchtype=author&query=Henneaux%2C+P">Pierre Henneaux</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">With the transition towards a smart grid, Information and Communications
Technology (ICT) infrastructures play a growing role in the operation of
transmission systems. Cyber-physical systems are usually studied using
co-simulation. The latter allows to leverage existing simulators and models for
both power systems and communication networks. A major drawback of
co-simulation is however the computation time. Indeed, simulators have to be
frequently paused in order to stay synchronised and to exchange information.
This is especially true for large systems for which lots of interactions
between the two domains occur. We thus propose a self-consistent simulation
approach as an alternative to co-simulation. We compare the two approaches on
the IEEE 39-bus test system equipped with an all-PMU state estimator. We show
that our approach can reach the same accuracy as co-simulation, while using
drastically less computer resources.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14468" title="Abstract">arXiv:2311.14468</a> [<a href="/pdf/2311.14468" title="Download PDF">pdf</a>, <a href="/format/2311.14468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Gradient Estimation via Adaptive Sampling and Importance  Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sala%C3%BCn%2C+C">Corentin Sala&#xfc;n</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xingchang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Georgiev%2C+I">Iliyan Georgiev</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+N+J">Niloy J. Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+G">Gurprit Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Machine learning problems rely heavily on stochastic gradient descent (SGD)
for optimization. The effectiveness of SGD is contingent upon accurately
estimating gradients from a mini-batch of data samples. Instead of the commonly
used uniform sampling, adaptive or importance sampling reduces noise in
gradient estimation by forming mini-batches that prioritize crucial data
points. Previous research has suggested that data points should be selected
with probabilities proportional to their gradient norm. Nevertheless, existing
algorithms have struggled to efficiently integrate importance sampling into
machine learning frameworks. In this work, we make two contributions. First, we
present an algorithm that can incorporate existing importance functions into
our framework. Second, we propose a simplified importance function that relies
solely on the loss gradient of the output layer. By leveraging our proposed
gradient estimation techniques, we observe improved convergence in
classification and regression tasks with minimal computational overhead. We
validate the effectiveness of our adaptive and importance-sampling approach on
image and point-cloud datasets.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14469" title="Abstract">arXiv:2311.14469</a> [<a href="/pdf/2311.14469" title="Download PDF">pdf</a>, <a href="/format/2311.14469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fault Detection in Telecom Networks using Bi-level Federated Graph  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bourgerie%2C+R">R. Bourgerie</a>, 
<a href="/search/cs?searchtype=author&query=Zanouda%2C+T">T. Zanouda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted as part of the The 2nd International Workshop on Federated Learning with Graph Data, colocated at EEE ICDM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">5G and Beyond Networks become increasingly complex and heterogeneous, with
diversified and high requirements from a wide variety of emerging applications.
The complexity and diversity of Telecom networks place an increasing strain on
maintenance and operation efforts. Moreover, the strict security and privacy
requirements present a challenge for mobile operators to leverage network data.
To detect network faults, and mitigate future failures, prior work focused on
leveraging traditional ML/DL methods to locate anomalies in networks. The
current approaches, although powerful, do not consider the intertwined nature
of embedded and software-intensive Radio Access Network systems. In this paper,
we propose a Bi-level Federated Graph Neural Network anomaly detection and
diagnosis model that is able to detect anomalies in Telecom networks in a
privacy-preserving manner, while minimizing communication costs. Our method
revolves around conceptualizing Telecom data as a bi-level temporal Graph
Neural Networks. The first graph captures the interactions between different
RAN nodes that are exposed to different deployment scenarios in the network,
while each individual Radio Access Network node is further elaborated into its
software (SW) execution graph. Additionally, we use Federated Learning to
address privacy and security limitations. Furthermore, we study the performance
of anomaly detection model under three settings: (1) Centralized (2) Federated
Learning and (3) Personalized Federated Learning using real-world data from an
operational network. Our comprehensive experiments showed that Personalized
Federated Temporal Graph Neural Networks method outperforms the most commonly
used techniques for Anomaly Detection.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14471" title="Abstract">arXiv:2311.14471</a> [<a href="/pdf/2311.14471" title="Download PDF">pdf</a>, <a href="/format/2311.14471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MRxaI: Black-Box Explainability for Image Classifiers in a Medical  Setting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blake%2C+N">Nathan Blake</a>, 
<a href="/search/cs?searchtype=author&query=Chockler%2C+H">Hana Chockler</a>, 
<a href="/search/cs?searchtype=author&query=Kelly%2C+D+A">David A. Kelly</a>, 
<a href="/search/cs?searchtype=author&query=Pena%2C+S+C">Santiago Calderon Pena</a>, 
<a href="/search/cs?searchtype=author&query=Chanchal%2C+A">Akchunya Chanchal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Existing tools for explaining the output of image classifiers can be divided
into white-box, which rely on access to the model internals, and black-box,
agnostic to the model. As the usage of AI in the medical domain grows, so too
does the usage of explainability tools. Existing work on medical image
explanations focuses on white-box tools, such as gradcam. However, there are
clear advantages to switching to a black-box tool, including the ability to use
it with any classifier and the wide selection of black-box tools available. On
standard images, black-box tools are as precise as white-box. In this paper we
compare the performance of several black-box methods against gradcam on a brain
cancer MRI dataset. We demonstrate that most black-box tools are not suitable
for explaining medical image classifications and present a detailed analysis of
the reasons for their shortcomings. We also show that one black-box tool, a
causal explainability-based rex, performs as well as \gradcam.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14477" title="Abstract">arXiv:2311.14477</a> [<a href="/pdf/2311.14477" title="Download PDF">pdf</a>, <a href="/format/2311.14477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simulation Limitations of Affine Cellular Automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hudcov%C3%A1%2C+B">Barbora Hudcov&#xe1;</a>, 
<a href="/search/cs?searchtype=author&query=Kr%C3%A1sensk%C3%BD%2C+J">Jakub Kr&#xe1;sensk&#xfd;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
<p class="mathjax">Cellular automata are a famous model of computation, yet it is still a
challenging task to assess the computational capacity of a given automaton;
especially when it comes to showing negative results. In this paper, we focus
on studying this problem via the notion of CA relative simulation. We say that
automaton A is simulated by B if each space-time diagram of A can be, after
suitable transformations, reproduced by B.
<br />We study affine automata - i.e., automata whose local rules are affine
mappings of vector spaces. This broad class contains the well-studied cases of
additive automata. The main result of this paper shows that (almost) every
automaton affine over a finite field F_p can only simulate affine automata over
F_p. We discuss how this general result implies, and widely surpasses,
limitations of additive automata previously proved in the literature.
<br />We provide a formalization of the simulation notions into algebraic language
and discuss how this opens a new path to showing negative results about the
computational power of cellular automata using deeper algebraic theorems.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14479" title="Abstract">arXiv:2311.14479</a> [<a href="/pdf/2311.14479" title="Download PDF">pdf</a>, <a href="/format/2311.14479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controlled Text Generation via Language Model Arithmetic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dekoninck%2C+J">Jasper Dekoninck</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+M">Marc Fischer</a>, 
<a href="/search/cs?searchtype=author&query=Beurer-Kellner%2C+L">Luca Beurer-Kellner</a>, 
<a href="/search/cs?searchtype=author&query=Vechev%2C+M">Martin Vechev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">As Large Language Models (LLMs) are deployed more widely, customization with
respect to vocabulary, style and character becomes more important. In this work
we introduce model arithmetic, a novel inference framework for composing and
biasing LLMs without the need for model (re)training or highly specific
datasets. In addition, the framework allows for more precise control of
generated text than direct prompting and prior controlled text generation (CTG)
techniques. Using model arithmetic, we can express prior CTG techniques as
simple formulas and naturally extend them to new and more effective
formulations. Further, we show that speculative sampling, a technique for
efficient LLM sampling, extends to our setting. This enables highly efficient
text generation with multiple composed models with only marginal overhead over
a single model. Our empirical evaluation demonstrates that model arithmetic
allows fine-grained control of generated text while outperforming
state-of-the-art on the task of toxicity reduction.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14480" title="Abstract">arXiv:2311.14480</a> [<a href="/pdf/2311.14480" title="Download PDF">pdf</a>, <a href="/format/2311.14480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evolutionary game theory: the mathematics of evolution and collective  behaviours
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
The <a href="/search/cs?searchtype=author&query=Han%2C+A">Anh Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2205.07369">arXiv:2205.07369</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Mathematical Physics (math-ph); Dynamical Systems (math.DS); Adaptation and Self-Organizing Systems (nlin.AO)

</div>
<p class="mathjax">This brief discusses evolutionary game theory as a powerful and unified
mathematical tool to study evolution of collective behaviours. It summarises
some of my recent research directions using evolutionary game theory methods,
which include i) the analysis of statistical properties of the number of
(stable) equilibria in a random evolutionary game, and ii) the modelling of
safety behaviours' evolution and the risk posed by advanced Artificial
Intelligence technologies in a technology development race. Finally, it
includes an outlook and some suggestions for future researchers.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14485" title="Abstract">arXiv:2311.14485</a> [<a href="/pdf/2311.14485" title="Download PDF">pdf</a>, <a href="/format/2311.14485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Interpretable Classification of Leukocytes based on Deep  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=R%C3%B6hrl%2C+S">Stefan R&#xf6;hrl</a>, 
<a href="/search/cs?searchtype=author&query=Groll%2C+J">Johannes Groll</a>, 
<a href="/search/cs?searchtype=author&query=Lengl%2C+M">Manuel Lengl</a>, 
<a href="/search/cs?searchtype=author&query=Schumann%2C+S">Simon Schumann</a>, 
<a href="/search/cs?searchtype=author&query=Klenk%2C+C">Christian Klenk</a>, 
<a href="/search/cs?searchtype=author&query=Heim%2C+D">Dominik Heim</a>, 
<a href="/search/cs?searchtype=author&query=Knopp%2C+M">Martin Knopp</a>, 
<a href="/search/cs?searchtype=author&query=Hayden%2C+O">Oliver Hayden</a>, 
<a href="/search/cs?searchtype=author&query=Diepold%2C+K">Klaus Diepold</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the 3rd Workshop on Interpretable Machine Learning in Healthcare (IMLH) @ ICML 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Label-free approaches are attractive in cytological imaging due to their
flexibility and cost efficiency. They are supported by machine learning
methods, which, despite the lack of labeling and the associated lower contrast,
can classify cells with high accuracy where the human observer has little
chance to discriminate cells. In order to better integrate these workflows into
the clinical decision making process, this work investigates the calibration of
confidence estimation for the automated classification of leukocytes. In
addition, different visual explanation approaches are compared, which should
bring machine decision making closer to professional healthcare applications.
Furthermore, we were able to identify general detection patterns in neural
networks and demonstrate the utility of the presented approaches in different
scenarios of blood cell analysis.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14490" title="Abstract">arXiv:2311.14490</a> [<a href="/pdf/2311.14490" title="Download PDF">pdf</a>, <a href="/format/2311.14490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Overview Of The 2023 Icassp Sp Clarity Challenge: Speech Enhancement For  Hearing Aids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cox%2C+T+J">Trevor J. Cox</a>, 
<a href="/search/cs?searchtype=author&query=Barker%2C+J">Jon Barker</a>, 
<a href="/search/cs?searchtype=author&query=Bailey%2C+W">Will Bailey</a>, 
<a href="/search/cs?searchtype=author&query=Graetzer%2C+S">Simone Graetzer</a>, 
<a href="/search/cs?searchtype=author&query=Akeroyd%2C+M+A">Michael A. Akeroyd</a>, 
<a href="/search/cs?searchtype=author&query=Culling%2C+J+F">John F. Culling</a>, 
<a href="/search/cs?searchtype=author&query=Naylor%2C+G">Graham Naylor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICASSP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This paper reports on the design and outcomes of the ICASSP SP Clarity
Challenge: Speech Enhancement for Hearing Aids. The scenario was a listener
attending to a target speaker in a noisy, domestic environment. There were
multiple interferers and head rotation by the listener. The challenge extended
the second Clarity Enhancement Challenge (CEC2) by fixing the amplification
stage of the hearing aid; evaluating with a combined metric for speech
intelligibility and quality; and providing two evaluation sets, one based on
simulation and the other on real-room measurements. Five teams improved on the
baseline system for the simulated evaluation set, but the performance on the
measured evaluation set was much poorer. Investigations are on-going to
determine the exact cause of the mismatch between the simulated and measured
data sets. The presence of transducer noise in the measurements, lower order
Ambisonics harming the ability for systems to exploit binaural cues and the
differences between real and simulated room impulse responses are suggested
causes
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14494" title="Abstract">arXiv:2311.14494</a> [<a href="/pdf/2311.14494" title="Download PDF">pdf</a>, <a href="/format/2311.14494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MVControl: Adding Conditional Control to Multi-view Diffusion for  Controllable Text-to-3D Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lingzhe Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Peidong Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce MVControl, a novel neural network architecture that enhances
existing pre-trained multi-view 2D diffusion models by incorporating additional
input conditions, e.g. edge maps. Our approach enables the generation of
controllable multi-view images and view-consistent 3D content. To achieve
controllable multi-view image generation, we leverage MVDream as our base
model, and train a new neural network module as additional plugin for
end-to-end task-specific condition learning. To precisely control the shapes
and views of generated images, we innovatively propose a new conditioning
mechanism that predicts an embedding encapsulating the input spatial and view
conditions, which is then injected to the network globally. Once MVControl is
trained, score-distillation (SDS) loss based optimization can be performed to
generate 3D content, in which process we propose to use a hybrid diffusion
prior. The hybrid prior relies on a pre-trained Stable-Diffusion network and
our trained MVControl for additional guidance. Extensive experiments
demonstrate that our method achieves robust generalization and enables the
controllable generation of high-quality 3D content.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14495" title="Abstract">arXiv:2311.14495</a> [<a href="/pdf/2311.14495" title="Download PDF">pdf</a>, <a href="/format/2311.14495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StableSSM: Alleviating the Curse of Memory in State-space Models through  Stable Reparameterization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shida Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qianxiao Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Dynamical Systems (math.DS)

</div>
<p class="mathjax">In this paper, we investigate the long-term memory learning capabilities of
state-space models (SSMs) from the perspective of parameterization. We prove
that state-space models without any reparameterization exhibit a memory
limitation similar to that of traditional RNNs: the target relationships that
can be stably approximated by state-space models must have an exponential
decaying memory. Our analysis identifies this "curse of memory" as a result of
the recurrent weights converging to a stability boundary, suggesting that a
reparameterization technique can be effective. To this end, we introduce a
class of reparameterization techniques for SSMs that effectively lift its
memory limitations. Besides improving approximation capabilities, we further
illustrate that a principled choice of reparameterization scheme can also
enhance optimization stability. We validate our findings using synthetic
datasets and language models.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14496" title="Abstract">arXiv:2311.14496</a> [<a href="/pdf/2311.14496" title="Download PDF">pdf</a>, <a href="/format/2311.14496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RTPS Attack Dataset Description
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+D+Y">Dong Young Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D+S">Dong Sung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y+C">Yu Chan Song</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+G+M">Gang Min Kim</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M+G">Min Geun Song</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+J+D">Jeong Do Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H+K">Huy Kang Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This manuscript is written in Korean. You can download our dataset in our lab: <a href="https://ocslab.hksecurity.net/Datasets">this https URL</a> We welcome your comments or feedback. Contact INFO: DongYoung Kim (klgh1256@korea.ac.kr), HuyKang Kim (cenda@korea.ac.kr)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">This paper explains all about our RTPS datasets. We collect attack and normal
packet data by injecting attack data in an Unmanned Ground Vehicle (UGV) which
is normal state. To collect this dataset, We assembled a test bed consisting of
UGV, controller, PC, and router. We conducted two types of Attacks "Command
Injection" and "ARP Spoofing" on the testbed. The data collection time is 180,
300, 600, and 1200, the scenario has 30 each on collection time. 240 total. We
expect this dataset will contribute to the development of technologies such as
anomaly detection to address security threat issues in ROS2 networks and UGVs.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14499" title="Abstract">arXiv:2311.14499</a> [<a href="/pdf/2311.14499" title="Download PDF">pdf</a>, <a href="/ps/2311.14499" title="Download PostScript">ps</a>, <a href="/format/2311.14499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comment on &quot;Improved RSA Technique with Efficient Data Integrity  Verification for Outsourcing Database in Cloud&quot;
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+C+D">Chebrolu Deepak Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Biswas%2C+L+K">Lilly Kumari Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Mookherji%2C+S">Srijanee Mookherji</a>, 
<a href="/search/cs?searchtype=author&query=Kurmala%2C+G+R+N">Gowri Raghavendra Narayan Kurmala</a>, 
<a href="/search/cs?searchtype=author&query=Odelu%2C+V">Vanga Odelu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">In 2022, Neela and Kavitha proposed an improved RSA encryption algorithm
(IREA) for cloud environment. In this paper, we review and comment on the
correctness of the IREA technique. We prove that the private key generation in
the proposed IREA is mathematical incorrect. That is, decryption of the cipher
generated by the public key is not possible with the private key. Further, we
discuss the possible modifications in IREA to make it correct decryption.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14501" title="Abstract">arXiv:2311.14501</a> [<a href="/pdf/2311.14501" title="Download PDF">pdf</a>, <a href="/ps/2311.14501" title="Download PostScript">ps</a>, <a href="/format/2311.14501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Malware Analysis on AI Technique
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Amjani Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+D+K">Dr. Karan Singh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">In today's world, we are performing our maximum work through the Internet,
i.e., online payment, data transfer, etc., per day. More than thousands of
users are connecting. So, it's essential to provide security to the user. It is
necessary to detect and prevent malicious object from gaining persistence and
causing destruction within the organization. Therefore, Malware analysis is
needed in order to secure the system. This necessitates the use of effective
and efficient approaches for detecting OS malware. Due to the cheap cost of
technology, artificial intelligence has also become less difficult to implement
in projects to analyse malware. The categorization and analysis of malware on
OS using various AI-based analysis techniques are covered in detail in this
paper.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14505" title="Abstract">arXiv:2311.14505</a> [<a href="/pdf/2311.14505" title="Download PDF">pdf</a>, <a href="/format/2311.14505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysing the Impact of Removing Infrequent Words on Topic Quality in  LDA Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bystrov%2C+V">Victor Bystrov</a>, 
<a href="/search/cs?searchtype=author&query=Naboka-Krell%2C+V">Viktoriia Naboka-Krell</a>, 
<a href="/search/cs?searchtype=author&query=Staszewska-Bystrova%2C+A">Anna Staszewska-Bystrova</a>, 
<a href="/search/cs?searchtype=author&query=Winker%2C+P">Peter Winker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">An initial procedure in text-as-data applications is text preprocessing. One
of the typical steps, which can substantially facilitate computations, consists
in removing infrequent words believed to provide limited information about the
corpus. Despite popularity of vocabulary pruning, not many guidelines on how to
implement it are available in the literature. The aim of the paper is to fill
this gap by examining the effects of removing infrequent words for the quality
of topics estimated using Latent Dirichlet Allocation. The analysis is based on
Monte Carlo experiments taking into account different criteria for infrequent
terms removal and various evaluation metrics. The results indicate that pruning
is beneficial and that the share of vocabulary which might be eliminated can be
quite considerable.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14506" title="Abstract">arXiv:2311.14506</a> [<a href="/pdf/2311.14506" title="Download PDF">pdf</a>, <a href="/format/2311.14506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Class Anomaly Detection based on Regularized Discriminative  Coupled hypersphere-based Feature Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rafiei%2C+M">Mehdi Rafiei</a>, 
<a href="/search/cs?searchtype=author&query=Iosifidis%2C+A">Alexandros Iosifidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 6 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In anomaly detection, identification of anomalies across diverse product
categories is a complex task. This paper introduces a new model by including
class discriminative properties obtained by a modified Regularized
Discriminative Variational Auto-Encoder (RD-VAE) in the feature extraction
process of Coupled-hypersphere-based Feature Adaptation (CFA). By doing so, the
proposed Regularized Discriminative Coupled-hypersphere-based Feature
Adaptation (RD-CFA), forms a solution for multi-class anomaly detection. By
using the discriminative power of RD-VAE to capture intricate class
distributions, combined with CFA's robust anomaly detection capability, the
proposed method excels in discerning anomalies across various classes.
Extensive evaluations on multi-class anomaly detection and localization using
the MVTec AD and BeanTech AD datasets showcase the effectiveness of RD-CFA
compared to eight leading contemporary methods.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14508" title="Abstract">arXiv:2311.14508</a> [<a href="/pdf/2311.14508" title="Download PDF">pdf</a>, <a href="/format/2311.14508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Filasofia: A Framework for Streamlined Development of Real-Time Surgical  Simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Poliakov%2C+V">Vladimir Poliakov</a>, 
<a href="/search/cs?searchtype=author&query=Tsetserukou%2C+D">Dzmitry Tsetserukou</a>, 
<a href="/search/cs?searchtype=author&query=Poorten%2C+E+V">Emmanuel Vander Poorten</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures, The 21st International Conference on Advanced Robotics (ICAR 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Virtual reality simulation has become a popular approach for training and
assessing medical students. It offers diverse scenarios, realistic visuals, and
quantitative performance metrics for objective evaluation. However, creating
these simulations can be time-consuming and complex, even for experienced
users. The SOFA framework is an open-source solution that efficiently simulates
finite element (FE) models in real-time. Yet, some users find it challenging to
navigate the software due to the numerous components required for a basic
simulation and their variability. Additionally, SOFA has limited visual
rendering capabilities, leading developers to integrate other software for
high-quality visuals. To address these issues, we developed Filasofia, a
dedicated framework that simplifies development, provides modern visualization,
and allows fine-tuning using SOFA objects. Our experiments demonstrate that
Filasofia outperforms conventional SOFA simulations, even with real-time
subdivision. Our design approach aims to streamline development while offering
flexibility for fine-tuning. Future work will focus on further simplification
of the development process for users.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14509" title="Abstract">arXiv:2311.14509</a> [<a href="/pdf/2311.14509" title="Download PDF">pdf</a>, <a href="/ps/2311.14509" title="Download PostScript">ps</a>, <a href="/format/2311.14509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FAMAC: A Federated Assisted Modified Actor-Critic Framework for Secured  Energy Saving in 5G and Beyond Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Abubakar%2C+A+I">Attai Ibrahim Abubakar</a>, 
<a href="/search/eess?searchtype=author&query=Mollel%2C+M+S">Michael S. Mollel</a>, 
<a href="/search/eess?searchtype=author&query=Ramzan%2C+N">Naeem Ramzan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 24 figures, 4 tables, To be submitted to Transactions in Vehicular Technology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The constant surge in the traffic demand on cellular networks has led to
continuous expansion in network capacity in order to accommodate existing and
new service demands. This has given rise to ultra-dense base station deployment
in 5G and beyond networks which leads to increased energy consumption in the
network. Hence, these ultra-dense base station deployments must be operated in
a way that the energy consumption of the network can be adapted to the
spatio-temporal traffic demands on the network in order to minimize the overall
energy consumption of the network. To achieve this goal, we leverage two
artificial intelligence algorithms, federated learning and actor-critic
algorithm, to develop a proactive and intelligent base station switching
framework that can learn the operating policy of the small base station in an
ultra-dense heterogeneous network (UDHN) that would result in maximum energy
saving in the network while respecting the quality of service (QoS)
constraints. The performance evaluation reveals that the proposed framework can
achieve an energy saving that is about 77% more than that of the
state-of-the-art solutions while respecting the QoS constraints of the network.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14510" title="Abstract">arXiv:2311.14510</a> [<a href="/pdf/2311.14510" title="Download PDF">pdf</a>, <a href="/format/2311.14510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Westermo test system performance data set
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Strandberg%2C+P+E">Per Erik Strandberg</a>, 
<a href="/search/cs?searchtype=author&query=Marklund%2C+Y">Yosh Marklund</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">There is a growing body of knowledge in the computer science, software
engineering, software testing and software test automation disciplines.
However, a challenge for researchers is to evaluate their research findings,
ideas and tools due to lack of realistic data. This paper presents the Westermo
test system performance data set. More than twenty performance metrics such as
CPU and memory usage sampled twice per minute for a month on nineteen test
systems driving nightly testing of cyber-physical systems has been anonymized
and released. The industrial motivation is to spur work on anomaly detection in
seasonal data such that one may increase trust in nightly testing. One could
ask: If the test system is in an abnormal state - can we trust the test
results? How could one automate the detection of abnormal states? The data set
has previously been used by students and in hackathons. By releasing it we hope
to simplify experiments on anomaly detection based on rules, thresholds,
statistics, machine learning or artificial intelligence, perhaps while
incorporating seasonality. We also hope that the data set could lead to
findings in sustainable software engineering.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14514" title="Abstract">arXiv:2311.14514</a> [<a href="/pdf/2311.14514" title="Download PDF">pdf</a>, <a href="/format/2311.14514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FRAD: Front-Running Attacks Detection on Ethereum using Ternary  Classification Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Pin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guojun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peiqiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+W">Wanyi Gu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Houji Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuelei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jinyao Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the evolution of blockchain technology, the issue of transaction
security, particularly on platforms like Ethereum, has become increasingly
critical. Front-running attacks, a unique form of security threat, pose
significant challenges to the integrity of blockchain transactions. In these
attack scenarios, malicious actors monitor other users' transaction activities,
then strategically submit their own transactions with higher fees. This ensures
their transactions are executed before the monitored transactions are included
in the block. The primary objective of this paper is to delve into a
comprehensive classification of transactions associated with front-running
attacks, which aims to equip developers with specific strategies to counter
each type of attack. To achieve this, we introduce a novel detection method
named FRAD (Front-Running Attacks Detection on Ethereum using Ternary
Classification Model). This method is specifically tailored for transactions
within decentralized applications (DApps) on Ethereum, enabling accurate
classification of front-running attacks involving transaction displacement,
insertion, and suppression. Our experimental validation reveals that the
Multilayer Perceptron (MLP) classifier offers the best performance in detecting
front-running attacks, achieving an impressive accuracy rate of 84.59% and
F1-score of 84.60%.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14515" title="Abstract">arXiv:2311.14515</a> [<a href="/pdf/2311.14515" title="Download PDF">pdf</a>, <a href="/format/2311.14515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On RIS-Aided SIMO Gaussian Channels: Towards A Single-RF MIMO  Transceiver Architecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ru-Han Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jing Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yonggang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A Shortened version is submitted to IEEE journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, for a single-input multiple-output (SIMO) system aided by a
passive reconfigurable intelligent surface (RIS), the joint transmission
accomplished by the single transmit antenna and the RIS with multiple
controllable reflective elements is considered. Relying on a general capacity
upper bound derived by a maximum-trace argument, we respectively characterize
the capacity of such \rev{a} channel in the low-SNR or the rank-one regimes, in
which the optimal configuration of the RIS is proved to be beamforming with
carefully-chosen phase shifts. To exploit the potential of modulating extra
information on the RIS, based on the QR decomposition, successive interference
cancellation, and a strategy named \textit{partially beamforming and partially
information-carrying}, we propose a novel transceiver architecture with only a
single RF front end at the transmitter, by which the considered channel can be
regarded as a concatenation of a vector Gaussian channel and several
phase-modulated channels. Especially, we investigate a class of vector Gaussian
channels with a hypersphere input support constraint, and not only generalize
the existing result to arbitrary-dimensional real spaces but also present its
high-order capacity asymptotics, by which both capacities of
hypersphere-constrained channels and achievable rates of the proposed
transceiver with two different signaling schemes can be well-approximated.
Information-theoretic analyses show that the transceiver architecture designed
for the SIMO channel has a boosted multiplexing gain, rather than one for the
conventionally-used optimized beamforming scheme.Numerical results verify our
derived asymptotics and show notable superiority of the proposed transceiver.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14516" title="Abstract">arXiv:2311.14516</a> [<a href="/pdf/2311.14516" title="Download PDF">pdf</a>, <a href="/format/2311.14516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Morphing Graph Drawings in the Presence of Point Obstacles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Firman%2C+O">Oksana Firman</a>, 
<a href="/search/cs?searchtype=author&query=Hegemann%2C+T">Tim Hegemann</a>, 
<a href="/search/cs?searchtype=author&query=Klemz%2C+B">Boris Klemz</a>, 
<a href="/search/cs?searchtype=author&query=Klesen%2C+F">Felix Klesen</a>, 
<a href="/search/cs?searchtype=author&query=Sieper%2C+M+D">Marie Diana Sieper</a>, 
<a href="/search/cs?searchtype=author&query=Wolff%2C+A">Alexander Wolff</a>, 
<a href="/search/cs?searchtype=author&query=Zink%2C+J">Johannes Zink</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in Proc. SOFSEM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">A crossing-free morph is a continuous deformation between two graph drawings
that preserves straight-line pairwise noncrossing edges. Motivated by
applications in 3D morphing problems, we initiate the study of morphing graph
drawings in the plane in the presence of stationary point obstacles, which need
to be avoided throughout the deformation. As our main result, we prove that it
is NP-hard to decide whether such an obstacle-avoiding 2D morph between two
given drawings of the same graph exists. This is in sharp contrast to the
classical case without obstacles, where there is an efficiently verifiable
(necessary and sufficient) criterion for the existence of a morph.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14517" title="Abstract">arXiv:2311.14517</a> [<a href="/pdf/2311.14517" title="Download PDF">pdf</a>, <a href="/format/2311.14517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> tinyCLAP: Distilling Constrastive Language-Audio Pretrained Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paissan%2C+F">Francesco Paissan</a>, 
<a href="/search/cs?searchtype=author&query=Farella%2C+E">Elisabetta Farella</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Contrastive Language-Audio Pretraining (CLAP) became of crucial importance in
the field of audio and speech processing. Its employment ranges from sound
event detection to text-to-audio generation. However, one of the main
limitations is the considerable amount of data required in the training process
and the overall computational complexity during inference. This paper
investigates how we can reduce the complexity of contrastive language-audio
pre-trained models, yielding an efficient model that we call tinyCLAP. We
derive an unimodal distillation loss from first principles and explore how the
dimensionality of the shared, multimodal latent space can be reduced via
pruning. TinyCLAP uses only 6% of the original Microsoft CLAP parameters with a
minimal reduction (less than 5%) in zero-shot classification performance across
the three sound event detection datasets on which it was tested
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14519" title="Abstract">arXiv:2311.14519</a> [<a href="/pdf/2311.14519" title="Download PDF">pdf</a>, <a href="/format/2311.14519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Large Language Models for Log Analysis, Security, and  Interpretation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karlsen%2C+E">Egil Karlsen</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zincir-Heywood%2C+N">Nur Zincir-Heywood</a>, 
<a href="/search/cs?searchtype=author&query=Heywood%2C+M">Malcolm Heywood</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Large Language Models (LLM) continue to demonstrate their utility in a
variety of emergent capabilities in different fields. An area that could
benefit from effective language understanding in cybersecurity is the analysis
of log files. This work explores LLMs with different architectures (BERT,
RoBERTa, DistilRoBERTa, GPT-2, and GPT-Neo) that are benchmarked for their
capacity to better analyze application and system log files for security.
Specifically, 60 fine-tuned language models for log analysis are deployed and
benchmarked. The resulting models demonstrate that they can be used to perform
log analysis effectively with fine-tuning being particularly important for
appropriate domain adaptation to specific log types. The best-performing
fine-tuned sequence classification model (DistilRoBERTa) outperforms the
current state-of-the-art; with an average F1-Score of 0.998 across six datasets
from both web application and system log sources. To achieve this, we propose
and implement a new experimentation pipeline (LLM4Sec) which leverages LLMs for
log analysis experimentation, evaluation, and analysis.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14521" title="Abstract">arXiv:2311.14521</a> [<a href="/pdf/2311.14521" title="Download PDF">pdf</a>, <a href="/format/2311.14521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GaussianEditor: Swift and Controllable 3D Editing with Gaussian  Splatting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiwen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zilong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Feng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaofeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yikai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zhongang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huaping Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Guosheng Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://buaacyw.github.io/gaussian-editor/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D editing plays a crucial role in many areas such as gaming and virtual
reality. Traditional 3D editing methods, which rely on representations like
meshes and point clouds, often fall short in realistically depicting complex
scenes. On the other hand, methods based on implicit 3D representations, like
Neural Radiance Field (NeRF), render complex scenes effectively but suffer from
slow processing speeds and limited control over specific scene areas. In
response to these challenges, our paper presents GaussianEditor, an innovative
and efficient 3D editing algorithm based on Gaussian Splatting (GS), a novel 3D
representation. GaussianEditor enhances precision and control in editing
through our proposed Gaussian semantic tracing, which traces the editing target
throughout the training process. Additionally, we propose Hierarchical Gaussian
splatting (HGS) to achieve stabilized and fine results under stochastic
generative guidance from 2D diffusion models. We also develop editing
strategies for efficient object removal and integration, a challenging task for
existing methods. Our comprehensive experiments demonstrate GaussianEditor's
superior control, efficacy, and rapid performance, marking a significant
advancement in 3D editing. Project Page:
https://buaacyw.github.io/gaussian-editor/
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14523" title="Abstract">arXiv:2311.14523</a> [<a href="/pdf/2311.14523" title="Download PDF">pdf</a>, <a href="/format/2311.14523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of a Non-Coherent Ultra-Wideband Transceiver for Micropower  Sensor Nodes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Imfeld%2C+J">Jonah Imfeld</a>, 
<a href="/search/eess?searchtype=author&query=Cortesi%2C+S">Silvano Cortesi</a>, 
<a href="/search/eess?searchtype=author&query=Mayer%2C+P">Philipp Mayer</a>, 
<a href="/search/eess?searchtype=author&query=Magno%2C+M">Michele Magno</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article has been accepted for publication in the Proceedings of the 2023 IEEE SENSORS conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Spatial and contextual awareness has the potential to revolutionize sensor
nodes, enabling spatially augmented data collection and location-based
services. With its high bandwidth, superior energy efficiency, and precise
time-of-flight measurements, ultra-wideband (UWB) technology emerges as an
ideal solution for such devices.
<br />This paper presents an evaluation and comparison of a non-coherent UWB
transceiver within the context of highly energy-constrained wireless sensing
nodes and pervasive Internet of Things (IoT) devices. Experimental results
highlight the unique properties of UWB transceivers, showcasing efficient data
transfer ranging from 2 kbit/s to 7.2 Mbit/s while reaching an energy
consumption of 0.29 nJ/bit and 1.39 nJ/bit for transmitting and receiving,
respectively. Notably, a ranging accuracy of up to +/-25 cm can be achieved.
Moreover, the peak power consumption of the UWB transceiver is with 6.7 mW in
TX and 23 mW in RX significantly lower than that of other commercial UWB
transceivers.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14526" title="Abstract">arXiv:2311.14526</a> [<a href="/pdf/2311.14526" title="Download PDF">pdf</a>, <a href="/format/2311.14526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pitfalls of Projection: A study of Newton-type solvers for incremental  potentials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Longva%2C+A">Andreas Longva</a> (1), 
<a href="/search/cs?searchtype=author&query=L%C3%B6schner%2C+F">Fabian L&#xf6;schner</a> (1), 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez-Fern%C3%A1ndez%2C+J+A">Jos&#xe9; Antonio Fern&#xe1;ndez-Fern&#xe1;ndez</a> (1), 
<a href="/search/cs?searchtype=author&query=Larionov%2C+E">Egor Larionov</a> (Meta Reality Labs), 
<a href="/search/cs?searchtype=author&query=Ascher%2C+U+M">Uri M. Ascher</a> (University of British Columbia), 
<a href="/search/cs?searchtype=author&query=Bender%2C+J">Jan Bender</a> (1) ((1) RWTH Aachen University)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 18 figures, under peer view at time of submission. Supplemental video in ancillary files
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">Nonlinear systems arising from time integrators like Backward Euler can
sometimes be reformulated as optimization problems, known as incremental
potentials. We show through a comprehensive experimental analysis that the
widely used Projected Newton method, which relies on unconditional semidefinite
projection of Hessian contributions, typically exhibits a reduced convergence
rate compared to classical Newton's method. We demonstrate how factors like
resolution, element order, projection method, material model and boundary
handling impact convergence of Projected Newton and Newton.
<br />Drawing on these findings, we propose the hybrid method Project-on-Demand
Newton, which projects only conditionally, and show that it enjoys both the
robustness of Projected Newton and convergence rate of Newton. We additionally
introduce Kinetic Newton, a regularization-based method that takes advantage of
the structure of incremental potentials and avoids projection altogether. We
compare the four solvers on hyperelasticity and contact problems.
<br />We also present a nuanced discussion of convergence criteria, and propose a
new acceleration-based criterion that avoids problems associated with existing
residual norm criteria and is easier to interpret. We finally address a
fundamental limitation of the Armijo backtracking line search that occasionally
blocks convergence, especially for stiff problems. We propose a novel
parameter-free, robust line search technique to eliminate this issue.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14530" title="Abstract">arXiv:2311.14530</a> [<a href="/pdf/2311.14530" title="Download PDF">pdf</a>, <a href="/ps/2311.14530" title="Download PostScript">ps</a>, <a href="/format/2311.14530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Translation for Ge&#x27;ez Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wassie%2C+A+K">Aman Kassahun Wassie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Machine translation (MT) for low-resource languages such as Ge'ez, an ancient
language that is no longer spoken in daily life, faces challenges such as
out-of-vocabulary words, domain mismatches, and lack of sufficient labeled
training data. In this work, we explore various methods to improve Ge'ez MT,
including transfer-learning from related languages, optimizing shared
vocabulary and token segmentation approaches, finetuning large pre-trained
models, and using large language models (LLMs) for few-shot translation with
fuzzy matches. We develop a multilingual neural machine translation (MNMT)
model based on languages relatedness, which brings an average performance
improvement of about 4 BLEU compared to standard bilingual models. We also
attempt to finetune the NLLB-200 model, one of the most advanced translation
models available today, but find that it performs poorly with only 4k training
samples for Ge'ez. Furthermore, we experiment with using GPT-3.5, a
state-of-the-art LLM, for few-shot translation with fuzzy matches, which
leverages embedding similarity-based retrieval to find context examples from a
parallel corpus. We observe that GPT-3.5 achieves a remarkable BLEU score of
9.2 with no initial knowledge of Ge'ez, but still lower than the MNMT baseline
of 15.2. Our work provides insights into the potential and limitations of
different approaches for low-resource and ancient language MT.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14532" title="Abstract">arXiv:2311.14532</a> [<a href="/pdf/2311.14532" title="Download PDF">pdf</a>, <a href="/format/2311.14532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digital Twin-Native AI-Driven Service Architecture for Industrial  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duran%2C+K">Kubra Duran</a>, 
<a href="/search/cs?searchtype=author&query=Broadbent%2C+M">Matthew Broadbent</a>, 
<a href="/search/cs?searchtype=author&query=Yurdakul%2C+G">Gokhan Yurdakul</a>, 
<a href="/search/cs?searchtype=author&query=Canberk%2C+B">Berk Canberk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The dramatic increase in the connectivity demand results in an excessive
amount of Internet of Things (IoT) sensors. To meet the management needs of
these large-scale networks, such as accurate monitoring and learning
capabilities, Digital Twin (DT) is the key enabler. However, current attempts
regarding DT implementations remain insufficient due to the perpetual
connectivity requirements of IoT networks. Furthermore, the sensor data
streaming in IoT networks cause higher processing time than traditional
methods. In addition to these, the current intelligent mechanisms cannot
perform well due to the spatiotemporal changes in the implemented IoT network
scenario. To handle these challenges, we propose a DT-native AI-driven service
architecture in support of the concept of IoT networks. Within the proposed
DT-native architecture, we implement a TCP-based data flow pipeline and a
Reinforcement Learning (RL)-based learner model. We apply the proposed
architecture to one of the broad concepts of IoT networks, the Internet of
Vehicles (IoV). We measure the efficiency of our proposed architecture and note
~30% processing time-saving thanks to the TCP-based data flow pipeline.
Moreover, we test the performance of the learner model by applying several
learning rate combinations for actor and critic networks and highlight the most
successive model.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14533" title="Abstract">arXiv:2311.14533</a> [<a href="/pdf/2311.14533" title="Download PDF">pdf</a>, <a href="/format/2311.14533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing Feature Engineering and End-to-End Deep Learning for Autism  Spectrum Disorder Assessment based on Fullbody-Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Altozano%2C+A">Alberto Altozano</a>, 
<a href="/search/cs?searchtype=author&query=Minissi%2C+M+E">Maria Eleonora Minissi</a>, 
<a href="/search/cs?searchtype=author&query=Alca%C3%B1iz%2C+M">Mariano Alca&#xf1;iz</a>, 
<a href="/search/cs?searchtype=author&query=Mar%C3%ADn-Morales%2C+J">Javier Mar&#xed;n-Morales</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Autism Spectrum Disorder (ASD) is characterized by challenges in social
communication and restricted patterns, with motor abnormalities gaining
traction for early detection. However, kinematic analysis in ASD is limited,
often lacking robust validation and relying on hand-crafted features for single
tasks, leading to inconsistencies across studies. Thus, end-to-end models have
become promising methods to overcome the need for feature engineering. Our aim
is to assess both approaches across various kinematic tasks to measure the
efficacy of commonly used features in ASD assessment, while comparing them to
end-to-end models. Specifically, we developed a virtual reality environment
with multiple motor tasks and trained models using both classification
approaches. We prioritized a reliable validation framework with repeated
cross-validation. Our comparative analysis revealed that hand-crafted features
outperformed our deep learning approach in specific tasks, achieving a
state-of-the-art area under the curve (AUC) of 0.90$\pm$0.06. Conversely,
end-to-end models provided more consistent results with less variability across
all VR tasks, demonstrating domain generalization and reliability, with a
maximum task AUC of 0.89$\pm$0.06. These findings show that end-to-end models
enable less variable and context-independent ASD assessments without requiring
domain knowledge or task specificity. However, they also recognize the
effectiveness of hand-crafted features in specific task scenarios.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14534" title="Abstract">arXiv:2311.14534</a> [<a href="/pdf/2311.14534" title="Download PDF">pdf</a>, <a href="/format/2311.14534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding Foundation Models for Time Series Classification with a PreText  Task
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ismail-Fawaz%2C+A">Ali Ismail-Fawaz</a>, 
<a href="/search/cs?searchtype=author&query=Devanne%2C+M">Maxime Devanne</a>, 
<a href="/search/cs?searchtype=author&query=Berretti%2C+S">Stefano Berretti</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+J">Jonathan Weber</a>, 
<a href="/search/cs?searchtype=author&query=Forestier%2C+G">Germain Forestier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Over the past decade, Time Series Classification (TSC) has gained an
increasing attention. While various methods were explored, deep learning -
particularly through Convolutional Neural Networks (CNNs)-stands out as an
effective approach. However, due to the limited availability of training data,
defining a foundation model for TSC that overcomes the overfitting problem is
still a challenging task. The UCR archive, encompassing a wide spectrum of
datasets ranging from motion recognition to ECG-based heart disease detection,
serves as a prime example for exploring this issue in diverse TSC scenarios. In
this paper, we address the overfitting challenge by introducing pre-trained
domain foundation models. A key aspect of our methodology is a novel pretext
task that spans multiple datasets. This task is designed to identify the
originating dataset of each time series sample, with the goal of creating
flexible convolution filters that can be applied across different datasets. The
research process consists of two phases: a pre-training phase where the model
acquires general features through the pretext task, and a subsequent
fine-tuning phase for specific dataset classifications. Our extensive
experiments on the UCR archive demonstrate that this pre-training strategy
significantly outperforms the conventional training approach without
pre-training. This strategy effectively reduces overfitting in small datasets
and provides an efficient route for adapting these models to new datasets, thus
advancing the capabilities of deep learning in TSC.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14539" title="Abstract">arXiv:2311.14539</a> [<a href="/pdf/2311.14539" title="Download PDF">pdf</a>, <a href="/ps/2311.14539" title="Download PostScript">ps</a>, <a href="/format/2311.14539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CMed-GPT: Prompt Tuning for Entity-Aware Chinese Medical Dialogue  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+Z">Zhijie Qu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Juan Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zerui Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianqiang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Medical dialogue generation relies on natural language generation techniques
to enable online medical consultations. Recently, the widespread adoption of
large-scale models in the field of natural language processing has facilitated
rapid advancements in this technology. Existing medical dialogue models are
mostly based on BERT and pre-trained on English corpora, but there is a lack of
high-performing models on the task of Chinese medical dialogue generation. To
solve the above problem, this paper proposes CMed-GPT, which is the GPT
pre-training language model based on Chinese medical domain text. The model is
available in two versions, namely, base and large, with corresponding
perplexity values of 8.64 and 8.01. Additionally, we incorporate lexical and
entity embeddings into the dialogue text in a uniform manner to meet the
requirements of downstream dialogue generation tasks. By applying both
fine-tuning and p-tuning to CMed-GPT, we lowered the PPL from 8.44 to 7.35.
This study not only confirms the exceptional performance of the CMed-GPT model
in generating Chinese biomedical text but also highlights the advantages of
p-tuning over traditional fine-tuning with prefix prompts. Furthermore, we
validate the significance of incorporating external information in medical
dialogue generation, which enhances the quality of dialogue generation.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14540" title="Abstract">arXiv:2311.14540</a> [<a href="/pdf/2311.14540" title="Download PDF">pdf</a>, <a href="/format/2311.14540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RDF Stream Taxonomy: Systematizing RDF Stream Types in Research and  Practice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sowinski%2C+P">Piotr Sowinski</a>, 
<a href="/search/cs?searchtype=author&query=Szmeja%2C+P">Pawel Szmeja</a>, 
<a href="/search/cs?searchtype=author&query=Ganzha%2C+M">Maria Ganzha</a>, 
<a href="/search/cs?searchtype=author&query=Paprzycki%2C+M">Marcin Paprzycki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Over the years, RDF streaming was explored in research and practice from many
angles, resulting in a wide range of RDF stream definitions. This variety
presents a major challenge in discussing and integrating streaming solutions,
due to the lack of a common language. This work attempts to address this
critical research gap, by systematizing RDF stream types present in the
literature in a novel taxonomy. The proposed RDF Stream Taxonomy (RDF-STaX) is
embodied in an OWL 2 DL ontology that follows the FAIR principles, making it
readily applicable in practice. Extensive documentation and additional
resources are provided, to foster the adoption of the ontology. Two realized
use cases are presented, demonstrating the usefulness of the resource in
discussing research works and annotating streaming datasets. Another result of
this contribution is the novel nanopublications dataset, which serves as a
collaborative, living state-of-the-art review of RDF streaming. The aim of
RDF-STaX is to address a real need of the community for a better way to
systematize and describe RDF streams. The resource is designed to help drive
innovation in RDF streaming, by fostering scientific discussion, cooperation,
and tool interoperability.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14542" title="Abstract">arXiv:2311.14542</a> [<a href="/pdf/2311.14542" title="Download PDF">pdf</a>, <a href="/format/2311.14542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ToddlerDiffusion: Flash Interpretable Controllable Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bakr%2C+E+M">Eslam Mohamed Bakr</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Liangbing Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+V+T">Vincent Tao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Cord%2C+M">Matthieu Cord</a>, 
<a href="/search/cs?searchtype=author&query=Perez%2C+P">Patrick Perez</a>, 
<a href="/search/cs?searchtype=author&query=Elhoseiny%2C+M">Mohamed Elhoseiny</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diffusion-based generative models excel in perceptually impressive synthesis
but face challenges in interpretability. This paper introduces
ToddlerDiffusion, an interpretable 2D diffusion image-synthesis framework
inspired by the human generation system. Unlike traditional diffusion models
with opaque denoising steps, our approach decomposes the generation process
into simpler, interpretable stages; generating contours, a palette, and a
detailed colored image. This not only enhances overall performance but also
enables robust editing and interaction capabilities. Each stage is meticulously
formulated for efficiency and accuracy, surpassing Stable-Diffusion (LDM).
Extensive experiments on datasets like LSUN-Churches and COCO validate our
approach, consistently outperforming existing methods. ToddlerDiffusion
achieves notable efficiency, matching LDM performance on LSUN-Churches while
operating three times faster with a 3.76 times smaller architecture. Our source
code is provided in the supplementary material and will be publicly accessible.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14543" title="Abstract">arXiv:2311.14543</a> [<a href="/pdf/2311.14543" title="Download PDF">pdf</a>, <a href="/format/2311.14543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Efficient Alignment of Large Language Models with Human Feedback  Through Natural Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+D">Di Jin</a>, 
<a href="/search/cs?searchtype=author&query=Mehri%2C+S">Shikib Mehri</a>, 
<a href="/search/cs?searchtype=author&query=Hazarika%2C+D">Devamanyu Hazarika</a>, 
<a href="/search/cs?searchtype=author&query=Padmakumar%2C+A">Aishwarya Padmakumar</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sungjin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Namazifar%2C+M">Mahdi Namazifar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Workshop on Instruction Tuning and Instruction Following at NeurIPS 2023, Submitted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Learning from human feedback is a prominent technique to align the output of
large language models (LLMs) with human expectations. Reinforcement learning
from human feedback (RLHF) leverages human preference signals that are in the
form of ranking of response pairs to perform this alignment. However, human
preference on LLM outputs can come in much richer forms including natural
language, which may provide detailed feedback on strengths and weaknesses of a
given response. In this work we investigate data efficiency of modeling human
feedback that is in natural language. Specifically, we fine-tune an open-source
LLM, e.g., Falcon-40B-Instruct, on a relatively small amount (1000 records or
even less) of human feedback in natural language in the form of critiques and
revisions of responses. We show that this model is able to improve the quality
of responses from even some of the strongest LLMs such as ChatGPT, BARD, and
Vicuna, through critique and revision of those responses. For instance, through
one iteration of revision of ChatGPT responses, the revised responses have
56.6% win rate over the original ones, and this win rate can be further
improved to 65.9% after applying the revision for five iterations.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14544" title="Abstract">arXiv:2311.14544</a> [<a href="/pdf/2311.14544" title="Download PDF">pdf</a>, <a href="/format/2311.14544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inferring Latent Class Statistics from Text for Robust Visual Few-Shot  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bendou%2C+Y">Yassir Bendou</a>, 
<a href="/search/cs?searchtype=author&query=Gripon%2C+V">Vincent Gripon</a>, 
<a href="/search/cs?searchtype=author&query=Pasdeloup%2C+B">Bastien Pasdeloup</a>, 
<a href="/search/cs?searchtype=author&query=Lioi%2C+G">Giulia Lioi</a>, 
<a href="/search/cs?searchtype=author&query=Mauch%2C+L">Lukas Mauch</a>, 
<a href="/search/cs?searchtype=author&query=Cardinaux%2C+F">Fabien Cardinaux</a>, 
<a href="/search/cs?searchtype=author&query=Hacene%2C+G+B">Ghouthi Boukli Hacene</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> R0-FoMo: Workshop on Robustness of Few-shot and Zero-shot Learning in Foundation Models at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the realm of few-shot learning, foundation models like CLIP have proven
effective but exhibit limitations in cross-domain robustness especially in
few-shot settings. Recent works add text as an extra modality to enhance the
performance of these models. Most of these approaches treat text as an
auxiliary modality without fully exploring its potential to elucidate the
underlying class visual features distribution. In this paper, we present a
novel approach that leverages text-derived statistics to predict the mean and
covariance of the visual feature distribution for each class. This predictive
framework enriches the latent space, yielding more robust and generalizable
few-shot learning models. We demonstrate the efficacy of incorporating both
mean and covariance statistics in improving few-shot classification performance
across various datasets. Our method shows that we can use text to predict the
mean and covariance of the distribution offering promising improvements in
few-shot learning scenarios.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14552" title="Abstract">arXiv:2311.14552</a> [<a href="/pdf/2311.14552" title="Download PDF">pdf</a>, <a href="/format/2311.14552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Griffon: Spelling out All Object Locations at Any Granularity with Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Y">Yufei Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yousong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhiyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+M">Ming Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinqiao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report. The codes and dataset will be released soon
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Replicating the innate human ability to detect all objects based on free-form
texts at any granularity remains a formidable challenge for Vision-Language
models. Current Large Vision Language Models (LVLMs) are predominantly
constrained to grounding a single, pre-existing object, relying solely on data
from Referring Expression Comprehension tasks. The limitation leads to a
compromise in model design, necessitating the introduction of visual expert
models or the integration of customized head structures. Beyond these
constraints, our research delves into the untapped potential of LVLMs and
uncover their inherent capability for basic object perception, allowing them to
accurately identify and locate objects of interest. Building on this insight,
we introduce a novel language-prompted localization dataset designed to fully
unleash the capabilities of LVLMs in integrating fine-grained object perception
with precise location awareness. More importantly, we present
$\textbf{Griffon}$, a purely LVLM-based baseline, which does not require the
introduction of any special tokens, expert models, or additional detection
modules. It simply maintains a consistent structure with popular LVLMs by
unifying data formats across various localization-related scenarios and is
trained end-to-end through a well-designed pipeline. Comprehensive experiments
demonstrate that $\textbf{Griffon}$ not only achieves state-of-the-art
performance on the fine-grained RefCOCO series but also approaches the
capabilities of the expert model Faster RCNN on the detection benchmark MSCOCO.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14553" title="Abstract">arXiv:2311.14553</a> [<a href="/pdf/2311.14553" title="Download PDF">pdf</a>, <a href="/format/2311.14553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Cross-Phase Effects of Reactive Power Intervention on  Distribution Voltage Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dalal%2C+D">Dhaval Dalal</a>, 
<a href="/search/eess?searchtype=author&query=Pal%2C+A">Anamitra Pal</a>, 
<a href="/search/eess?searchtype=author&query=Ayyanar%2C+R">Raja Ayyanar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 5 figures, PES-GM submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Increasing photovoltaic (PV) penetration in the distribution system can often
lead to voltage violations. Mitigation of these violations requires reactive
power intervention from PV inverters. However, the unbalanced nature of the
distribution system leads to mixed effects on the voltages of nearby nodes for
each inverter injecting or absorbing reactive power. In particular, reactive
power absorption to reduce over-voltage in one phase can exacerbate
over-voltage in a different phase. In this paper, the factors impacting the
incremental and decremental voltage effects of reactive power intervention are
analyzed in detail. The result of these effects on the distribution system
performance is presented to highlight their significance and the need to factor
them in for any coordinated voltage control algorithm.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14554" title="Abstract">arXiv:2311.14554</a> [<a href="/pdf/2311.14554" title="Download PDF">pdf</a>, <a href="/format/2311.14554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep learning based reduced order modeling of Darcy flow systems with  local mass conservation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Boon%2C+W+M">Wietse M. Boon</a>, 
<a href="/search/math?searchtype=author&query=Franco%2C+N+R">Nicola R. Franco</a>, 
<a href="/search/math?searchtype=author&query=Fumagalli%2C+A">Alessio Fumagalli</a>, 
<a href="/search/math?searchtype=author&query=Zunino%2C+P">Paolo Zunino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We propose a new reduced order modeling strategy for tackling parametrized
Partial Differential Equations (PDEs) with linear constraints, in particular
Darcy flow systems in which the constraint is given by mass conservation. Our
approach employs classical neural network architectures and supervised
learning, but it is constructed in such a way that the resulting Reduced Order
Model (ROM) is guaranteed to satisfy the linear constraints exactly. The
procedure is based on a splitting of the PDE solution into a particular
solution satisfying the constraint and a homogenous solution. The homogeneous
solution is approximated by mapping a suitable potential function, generated by
a neural network model, onto the kernel of the constraint operator; for the
particular solution, instead, we propose an efficient spanning tree algorithm.
Starting from this paradigm, we present three approaches that follow this
methodology, obtained by exploring different choices of the potential spaces:
from empirical ones, derived via Proper Orthogonal Decomposition (POD), to more
abstract ones based on differential complexes. All proposed approaches combine
computational efficiency with rigorous mathematical interpretation, thus
guaranteeing the explainability of the model outputs. To demonstrate the
efficacy of the proposed strategies and to emphasize their advantages over
vanilla black-box approaches, we present a series of numerical experiments on
fluid flows in porous media, ranging from mixed-dimensional problems to
nonlinear systems. This research lays the foundation for further exploration
and development in the realm of model order reduction, potentially unlocking
new capabilities and solutions in computational geosciences and beyond.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14563" title="Abstract">arXiv:2311.14563</a> [<a href="/pdf/2311.14563" title="Download PDF">pdf</a>, <a href="/ps/2311.14563" title="Download PostScript">ps</a>, <a href="/format/2311.14563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Electric Vehicles coordination for grid balancing using multi-objective  Harris Hawks Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pop%2C+C+B">Cristina Bianca Pop</a>, 
<a href="/search/cs?searchtype=author&query=Cioara%2C+T">Tudor Cioara</a>, 
<a href="/search/cs?searchtype=author&query=Chifu%2C+V">Viorica Chifu</a>, 
<a href="/search/cs?searchtype=author&query=Anghel%2C+I">Ionut Anghel</a>, 
<a href="/search/cs?searchtype=author&query=Bellesini%2C+F">Francesco Bellesini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Elsevier journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Neural and Evolutionary Computing (cs.NE); Systems and Control (eess.SY)

</div>
<p class="mathjax">The rise of renewables coincides with the shift towards Electrical Vehicles
(EVs) posing technical and operational challenges for the energy balance of the
local grid. Nowadays, the energy grid cannot deal with a spike in EVs usage
leading to a need for more coordinated and grid aware EVs charging and
discharging strategies. However, coordinating power flow from multiple EVs into
the grid requires sophisticated algorithms and load-balancing strategies as the
complexity increases with more control variables and EVs, necessitating large
optimization and decision search spaces. In this paper, we propose an EVs fleet
coordination model for the day ahead aiming to ensure a reliable energy supply
and maintain a stable local grid, by utilizing EVs to store surplus energy and
discharge it during periods of energy deficit. The optimization problem is
addressed using Harris Hawks Optimization (HHO) considering criteria related to
energy grid balancing, time usage preference, and the location of EV drivers.
The EVs schedules, associated with the position of individuals from the
population, are adjusted through exploration and exploitation operations, and
their technical and operational feasibility is ensured, while the rabbit
individual is updated with a non-dominated EV schedule selected per iteration
using a roulette wheel algorithm. The solution is evaluated within the
framework of an e-mobility service in Terni city. The results indicate that
coordinated charging and discharging of EVs not only meet balancing service
requirements but also align with user preferences with minimal deviations.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14566" title="Abstract">arXiv:2311.14566</a> [<a href="/pdf/2311.14566" title="Download PDF">pdf</a>, <a href="/format/2311.14566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-tap Resistive Sensing and FEM Modeling enables Shape and Force  Estimation in Soft Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+S">Sizhe Tian</a>, 
<a href="/search/cs?searchtype=author&query=Cangan%2C+B+G">Barnabas Gavin Cangan</a>, 
<a href="/search/cs?searchtype=author&query=Navarro%2C+S+E">Stefan Escaida Navarro</a>, 
<a href="/search/cs?searchtype=author&query=Beger%2C+A">Artem Beger</a>, 
<a href="/search/cs?searchtype=author&query=Duriez%2C+C">Christian Duriez</a>, 
<a href="/search/cs?searchtype=author&query=Katzschmann%2C+R+K">Robert K. Katzschmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures, to be published in Robotics and Automation Letters (RA-L)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We address the challenge of reliable and accurate proprioception in soft
robots, specifically those with tight packaging constraints and relying only on
internally embedded sensors. While various sensing approaches with single
sensors have been tried, often with a constant curvature assumption, we look
into sensing local deformations at multiple locations of the sensor. In our
approach, we multi-tap an off-the-shelf resistive sensor by creating multiple
electrical connections onto the resistive layer of the sensor and we insert the
sensor into a soft body. This modification allows us to measure changes in
resistance at multiple segments throughout the length of the sensor, providing
improved resolution of local deformations in the soft body. These measurements
inform a model based on a finite element method (FEM) that estimates the shape
of the soft body and the magnitude of an external force acting at a known
arbitrary location. Our model-based approach estimates soft body deformation
with approximately 3% average relative error while taking into account internal
fluidic actuation. Our estimate of external force disturbance has an 11%
relative error within a range of 0 to 5 N. The combined sensing and modeling
approach can be integrated, for instance, into soft manipulation platforms to
enable features such as identifying the shape and material properties of an
object being grasped. Such manipulators can benefit from the inherent softness
and compliance while being fully proprioceptive, relying only on embedded
sensing and not on external systems such as motion capture. Such proprioception
is essential for the deployment of soft robots in real-world scenarios.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14570" title="Abstract">arXiv:2311.14570</a> [<a href="/pdf/2311.14570" title="Download PDF">pdf</a>, <a href="/ps/2311.14570" title="Download PostScript">ps</a>, <a href="/format/2311.14570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RAISE -- Radiology AI Safety, an End-to-end lifecycle approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cardoso%2C+M+J">M. Jorge Cardoso</a>, 
<a href="/search/cs?searchtype=author&query=Moosbauer%2C+J">Julia Moosbauer</a>, 
<a href="/search/cs?searchtype=author&query=Cook%2C+T+S">Tessa S. Cook</a>, 
<a href="/search/cs?searchtype=author&query=Erdal%2C+B+S">B. Selnur Erdal</a>, 
<a href="/search/cs?searchtype=author&query=Genereaux%2C+B">Brad Genereaux</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+V">Vikash Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Landman%2C+B+A">Bennett A. Landman</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+T">Tiarna Lee</a>, 
<a href="/search/cs?searchtype=author&query=Nachev%2C+P">Parashkev Nachev</a>, 
<a href="/search/cs?searchtype=author&query=Somasundaram%2C+E">Elanchezhian Somasundaram</a>, 
<a href="/search/cs?searchtype=author&query=Summers%2C+R+M">Ronald M. Summers</a>, 
<a href="/search/cs?searchtype=author&query=Younis%2C+K">Khaled Younis</a>, 
<a href="/search/cs?searchtype=author&query=Ourselin%2C+S">Sebastien Ourselin</a>, 
<a href="/search/cs?searchtype=author&query=Pfister%2C+F+M">Franz MJ Pfister</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Medical Physics (physics.med-ph)

</div>
<p class="mathjax">The integration of AI into radiology introduces opportunities for improved
clinical care provision and efficiency but it demands a meticulous approach to
mitigate potential risks as with any other new technology. Beginning with
rigorous pre-deployment evaluation and validation, the focus should be on
ensuring models meet the highest standards of safety, effectiveness and
efficacy for their intended applications. Input and output guardrails
implemented during production usage act as an additional layer of protection,
identifying and addressing individual failures as they occur. Continuous
post-deployment monitoring allows for tracking population-level performance
(data drift), fairness, and value delivery over time. Scheduling reviews of
post-deployment model performance and educating radiologists about new
algorithmic-driven findings is critical for AI to be effective in clinical
practice. Recognizing that no single AI solution can provide absolute assurance
even when limited to its intended use, the synergistic application of quality
assurance at multiple levels - regulatory, clinical, technical, and ethical -
is emphasized. Collaborative efforts between stakeholders spanning healthcare
systems, industry, academia, and government are imperative to address the
multifaceted challenges involved. Trust in AI is an earned privilege,
contingent on a broad set of goals, among them transparently demonstrating that
the AI adheres to the same rigorous safety, effectiveness and efficacy
standards as other established medical technologies. By doing so, developers
can instil confidence among providers and patients alike, enabling the
responsible scaling of AI and the realization of its potential benefits. The
roadmap presented herein aims to expedite the achievement of deployable,
reliable, and safe AI in radiology.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14573" title="Abstract">arXiv:2311.14573</a> [<a href="/pdf/2311.14573" title="Download PDF">pdf</a>, <a href="/format/2311.14573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainties in Robust Planning and Control of Autonomous  Tractor-Trailer Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Westny%2C+T">Theodor Westny</a>, 
<a href="/search/eess?searchtype=author&query=Olofsson%2C+B">Bj&#xf6;rn Olofsson</a>, 
<a href="/search/eess?searchtype=author&query=Frisk%2C+E">Erik Frisk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">To study the effects of uncertainty in autonomous motion planning and
control, an 8-DOF model of a tractor-semitrailer is implemented and analyzed.
The implications of uncertainties in the model are then quantified and
presented using sensitivity analysis and closed-loop simulations. The analysis
reveals that the significance of various model parameters varies depending on
the specific scenario under investigation. By using sampling-based closed-loop
predictions, uncertainty bounds on state variable trajectories are determined.
Our findings suggest the potential for the inclusion of our method within a
robust predictive controller or as a driver-assistance system for rollover or
lane departure warnings.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14579" title="Abstract">arXiv:2311.14579</a> [<a href="/pdf/2311.14579" title="Download PDF">pdf</a>, <a href="/format/2311.14579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Counting Solutions to Conjunctive Queries: Structural and Hybrid  Tractability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hubie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Greco%2C+G">Gianluigi Greco</a>, 
<a href="/search/cs?searchtype=author&query=Mengel%2C+S">Stefan Mengel</a>, 
<a href="/search/cs?searchtype=author&query=Scarcello%2C+F">Francesco Scarcello</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Counting the number of answers to conjunctive queries is a fundamental
problem in databases that, under standard assumptions, does not have an
efficient solution. The issue is inherently #P-hard, extending even to classes
of acyclic instances.
<br />To address this, we pinpoint tractable classes by examining the structural
properties of instances and introducing the novel concept of #-hypertree
decomposition. We establish the feasibility of counting answers in polynomial
time for classes of queries featuring bounded #-hypertree width. Additionally,
employing novel techniques from the realm of fixed-parameter computational
complexity, we prove that, for bounded arity queries, the bounded #-hypertree
width property precisely delineates the frontier of tractability for the
counting problem. This result closes an important gap in our understanding of
the complexity of such a basic problem for conjunctive queries and,
equivalently, for constraint satisfaction problems (CSPs).
<br />Drawing upon #-hypertree decompositions, a ''hybrid'' decomposition method
emerges. This approach leverages both the structural characteristics of the
query and properties intrinsic to the input database, including keys or other
(weaker) degree constraints that limit the permissible combinations of values.
Intuitively, these features may introduce distinct structural properties that
elude identification through the ''worst-possible database'' perspective
inherent in purely structural methods.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14580" title="Abstract">arXiv:2311.14580</a> [<a href="/pdf/2311.14580" title="Download PDF">pdf</a>, <a href="/format/2311.14580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models as Automated Aligners for benchmarking  Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+Y">Yuanfeng Ji</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+C">Chongjian Ge</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+W">Weikai Kong</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+E">Enze Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengying Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhengguo Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the advancements in Large Language Models (LLMs), Vision-Language Models
(VLMs) have reached a new level of sophistication, showing notable competence
in executing intricate cognition and reasoning tasks. However, existing
evaluation benchmarks, primarily relying on rigid, hand-crafted datasets to
measure task-specific performance, face significant limitations in assessing
the alignment of these increasingly anthropomorphic models with human
intelligence. In this work, we address the limitations via Auto-Bench, which
delves into exploring LLMs as proficient aligners, measuring the alignment
between VLMs and human intelligence and value through automatic data curation
and assessment. Specifically, for data curation, Auto-Bench utilizes LLMs
(e.g., GPT-4) to automatically generate a vast set of question-answer-reasoning
triplets via prompting on visual symbolic representations (e.g., captions,
object locations, instance relationships, and etc.). The curated data closely
matches human intent, owing to the extensive world knowledge embedded in LLMs.
Through this pipeline, a total of 28.5K human-verified and 3,504K unfiltered
question-answer-reasoning triplets have been curated, covering 4 primary
abilities and 16 sub-abilities. We subsequently engage LLMs like GPT-3.5 to
serve as judges, implementing the quantitative and qualitative automated
assessments to facilitate a comprehensive evaluation of VLMs. Our validation
results reveal that LLMs are proficient in both evaluation data curation and
model assessment, achieving an average agreement rate of 85%. We envision
Auto-Bench as a flexible, scalable, and comprehensive benchmark for evaluating
the evolving sophisticated VLMs.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14581" title="Abstract">arXiv:2311.14581</a> [<a href="/pdf/2311.14581" title="Download PDF">pdf</a>, <a href="/format/2311.14581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Example-Based Explanations of Random Forest Predictions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bostr%C3%B6m%2C+H">Henrik Bostr&#xf6;m</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to 22nd International Symposium on Intelligent Data Analysis, IDA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">A random forest prediction can be computed by the scalar product of the
labels of the training examples and a set of weights that are determined by the
leafs of the forest into which the test object falls; each prediction can hence
be explained exactly by the set of training examples for which the weights are
non-zero. The number of examples used in such explanations is shown to vary
with the dimensionality of the training set and hyperparameters of the random
forest algorithm. This means that the number of examples involved in each
prediction can to some extent be controlled by varying these parameters.
However, for settings that lead to a required predictive performance, the
number of examples involved in each prediction may be unreasonably large,
preventing the user to grasp the explanations. In order to provide more useful
explanations, a modified prediction procedure is proposed, which includes only
the top-weighted examples. An investigation on regression and classification
tasks shows that the number of examples used in each explanation can be
substantially reduced while maintaining, or even improving, predictive
performance compared to the standard prediction procedure.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14583" title="Abstract">arXiv:2311.14583</a> [<a href="/pdf/2311.14583" title="Download PDF">pdf</a>, <a href="/ps/2311.14583" title="Download PostScript">ps</a>, <a href="/format/2311.14583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPT Struct Me: Probing GPT Models on Narrative Entity Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sousa%2C+H">Hugo Sousa</a>, 
<a href="/search/cs?searchtype=author&query=Guimar%C3%A3es%2C+N">Nuno Guimar&#xe3;es</a>, 
<a href="/search/cs?searchtype=author&query=Jorge%2C+A">Al&#xed;pio Jorge</a>, 
<a href="/search/cs?searchtype=author&query=Campos%2C+R">Ricardo Campos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">The importance of systems that can extract structured information from
textual data becomes increasingly pronounced given the ever-increasing volume
of text produced on a daily basis. Having a system that can effectively extract
such information in an interoperable manner would be an asset for several
domains, be it finance, health, or legal. Recent developments in natural
language processing led to the production of powerful language models that can,
to some degree, mimic human intelligence. Such effectiveness raises a pertinent
question: Can these models be leveraged for the extraction of structured
information? In this work, we address this question by evaluating the
capabilities of two state-of-the-art language models -- GPT-3 and GPT-3.5,
commonly known as ChatGPT -- in the extraction of narrative entities, namely
events, participants, and temporal expressions. This study is conducted on the
Text2Story Lusa dataset, a collection of 119 Portuguese news articles whose
annotation framework includes a set of entity structures along with several
tags and attribute values. We first select the best prompt template through an
ablation study over prompt components that provide varying degrees of
information on a subset of documents of the dataset. Subsequently, we use the
best templates to evaluate the effectiveness of the models on the remaining
documents. The results obtained indicate that GPT models are competitive with
out-of-the-box baseline systems, presenting an all-in-one alternative for
practitioners with limited resources. By studying the strengths and limitations
of these models in the context of information extraction, we offer insights
that can guide future improvements and avenues to explore in this field.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14593" title="Abstract">arXiv:2311.14593</a> [<a href="/pdf/2311.14593" title="Download PDF">pdf</a>, <a href="/ps/2311.14593" title="Download PostScript">ps</a>, <a href="/format/2311.14593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visualizing Plasma Physics Simulations in Immersive Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Trindade%2C+N+V">Nuno Verdelho Trindade</a>, 
<a href="/search/cs?searchtype=author&query=Amaro%2C+O">Oscar Amaro</a>, 
<a href="/search/cs?searchtype=author&query=Bras%2C+D">David Bras</a>, 
<a href="/search/cs?searchtype=author&query=Goncalves%2C+D">Daniel Goncalves</a>, 
<a href="/search/cs?searchtype=author&query=Pereira%2C+J+M">Jo&#xe3;o Madeiras Pereira</a>, 
<a href="/search/cs?searchtype=author&query=Ferreira%2C+A">Alfredo Ferreira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">Plasma physics simulations create complex datasets for which researchers need
state-of-the-art visualization tools to gain insights. These datasets are 3D in
nature but are commonly depicted and analyzed using 2D idioms displayed on 2D
screens. These offer limited understandability in a domain where spatial
awareness is key. Virtual reality (VR) can be used as an alternative to
conventional means for analyzing such datasets. VR has been known to improve
depth and spatial relationship perception, which are fundamental for obtaining
insights into 3D plasma morphology. Likewise, VR can potentially increase user
engagement by offering more immersive and enjoyable experiences. Methods This
study presents PlasmaVR, a proof-of-concept VR tool for visualizing datasets
resulting from plasma physics simulations. It enables immersive
multidimensional data visualization of particles, scalar, and vector fields and
uses a more natural interface. The study includes user evaluation with domain
experts where PlasmaVR was employed to assess the possible benefits of
immersive environments in plasma physics visualization. The experimental group
comprised five plasma physics researchers who were asked to perform tasks
designed to represent their typical analysis workflow. To assess the
suitability of the prototype for the different types of tasks, a set of
objective metrics, such as completion time and number of errors, were measured.
The prototype's usability was also evaluated using a standard System Usability
Survey questionnaire.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14594" title="Abstract">arXiv:2311.14594</a> [<a href="/pdf/2311.14594" title="Download PDF">pdf</a>, <a href="/format/2311.14594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MABFuzz: Multi-Armed Bandit Algorithms for Fuzzing Processors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gohil%2C+V">Vasudev Gohil</a>, 
<a href="/search/cs?searchtype=author&query=Kande%2C+R">Rahul Kande</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sadeghi%2C+A">Ahmad-Reza Sadeghi</a>, 
<a href="/search/cs?searchtype=author&query=Rajendran%2C+J">Jeyavijayan Rajendran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published at Design, Automation and Test in Europe Conference, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">As the complexities of processors keep increasing, the task of effectively
verifying their integrity and security becomes ever more daunting. The
intricate web of instructions, microarchitectural features, and
interdependencies woven into modern processors pose a formidable challenge for
even the most diligent verification and security engineers. To tackle this
growing concern, recently, researchers have developed fuzzing techniques
explicitly tailored for hardware processors. However, a prevailing issue with
these hardware fuzzers is their heavy reliance on static strategies to make
decisions in their algorithms. To address this problem, we develop a novel
dynamic and adaptive decision-making framework, MABFuzz, that uses multi-armed
bandit (MAB) algorithms to fuzz processors. MABFuzz is agnostic to, and hence,
applicable to, any existing hardware fuzzer. In the process of designing
MABFuzz, we encounter challenges related to the compatibility of MAB algorithms
with fuzzers and maximizing their efficacy for fuzzing. We overcome these
challenges by modifying the fuzzing process and tailoring MAB algorithms to
accommodate special requirements for hardware fuzzing.
<br />We integrate three widely used MAB algorithms in a state-of-the-art hardware
fuzzer and evaluate them on three popular RISC-V-based processors. Experimental
results demonstrate the ability of MABFuzz to cover a broader spectrum of
processors' intricate landscapes and doing so with remarkable efficiency. In
particular, MABFuzz achieves up to 308x speedup in detecting vulnerabilities
and up to 5x speedup in achieving coverage compared to a state-of-the-art
technique.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14595" title="Abstract">arXiv:2311.14595</a> [<a href="/pdf/2311.14595" title="Download PDF">pdf</a>, <a href="/format/2311.14595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey and Analysis of Evolutionary Operators for Permutations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cicirello%2C+V+A">Vincent A. Cicirello</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Proceedings of the 15th International Joint Conference on
  Computational Intelligence (2023), pages 288-299
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">There are many combinatorial optimization problems whose solutions are best
represented by permutations. The classic traveling salesperson seeks an optimal
ordering over a set of cities. Scheduling problems often seek optimal orderings
of tasks or activities. Although some evolutionary approaches to such problems
utilize the bit strings of a genetic algorithm, it is more common to directly
represent solutions with permutations. Evolving permutations directly requires
specialized evolutionary operators. Over the years, many crossover and mutation
operators have been developed for solving permutation problems with
evolutionary algorithms. In this paper, we survey the breadth of evolutionary
operators for permutations. We implemented all of these in Chips-n-Salsa, an
open source Java library for evolutionary computation. Finally, we empirically
analyze the crossover operators on artificial fitness landscapes isolating
different permutation features.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14598" title="Abstract">arXiv:2311.14598</a> [<a href="/pdf/2311.14598" title="Download PDF">pdf</a>, <a href="/format/2311.14598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Target-driven splitting SPH optimization of thermal conductivity  distribution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiangyu Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages and 14 figures and 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Efficiently enhancing heat conduction through optimized distribution of a
limited quantity of high thermal conductivity material is paramount in cooling
electronic devices and numerous other applications. This paper introduces a
target-driven all-at-once approach for PDE-constrained optimization and derives
a splitting smoothed particle hydrodynamics (SPH) method for optimizing the
distribution of thermal conductivity in heat conduction problems. In this
method, the optimization iteration of the system is split into several easily
addressed steps. A targeting step is employed to progressively enforce the
direct target, which potentially leads to increased PDE residuals. Then, these
residuals are recovered through an evolution step of the design variable. After
this, a PDE solution step is carried out to further decrease the PDE residuals,
and the system is ready for the next iteration. Unlike the simulation-based
approaches, the present method does not rely on the adjoint state equation and
converged state variable field in each iteration, and the optimization process
is significantly simplified and accelerated. With the utilization of an
implicit SPH splitting operator and a general numerical regularization
formulation, the information propagation is further accelerated and the
numerical stability is greatly enhanced. Typical examples of heat conduction
optimization demonstrate that the current method yields optimal results
comparable to previous methods and exhibits considerable computational
efficiency. Moreover, the optimal results feature more moderate extreme values,
which offers distinct advantages for the easier selection of appropriate
material with high thermal conductivity.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14600" title="Abstract">arXiv:2311.14600</a> [<a href="/pdf/2311.14600" title="Download PDF">pdf</a>, <a href="/format/2311.14600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Peer-to-Peer Data Distribution Layer for Efficient and  Collaborative Resource Optimization of Distributed Dataflow Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scheinert%2C+D">Dominik Scheinert</a>, 
<a href="/search/cs?searchtype=author&query=Becker%2C+S">Soeren Becker</a>, 
<a href="/search/cs?searchtype=author&query=Will%2C+J">Jonathan Will</a>, 
<a href="/search/cs?searchtype=author&query=Englaender%2C+L">Luis Englaender</a>, 
<a href="/search/cs?searchtype=author&query=Thamsen%2C+L">Lauritz Thamsen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF)

</div>
<p class="mathjax">Performance modeling can help to improve the resource efficiency of clusters
and distributed dataflow applications, yet the available modeling data is often
limited. Collaborative approaches to performance modeling, characterized by the
sharing of performance data or models, have been shown to improve resource
efficiency, but there has been little focus on actual data sharing strategies
and implementation in production environments. This missing building block
holds back the realization of proposed collaborative solutions.
<br />In this paper, we envision, design, and evaluate a peer-to-peer performance
data sharing approach for collaborative performance modeling of distributed
dataflow applications. Our proposed data distribution layer enables access to
performance data in a decentralized manner, thereby facilitating collaborative
modeling approaches and allowing for improved prediction capabilities and hence
increased resource efficiency. In our evaluation, we assess our approach with
regard to deployment, data replication, and data validation, through
experiments with a prototype implementation and simulation, demonstrating
feasibility and allowing discussion of potential limitations and next steps.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14601" title="Abstract">arXiv:2311.14601</a> [<a href="/pdf/2311.14601" title="Download PDF">pdf</a>, <a href="/format/2311.14601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Metalearned Neural Circuit for Nonparametric Bayesian Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Snell%2C+J+C">Jake C. Snell</a>, 
<a href="/search/cs?searchtype=author&query=Bencomo%2C+G">Gianluca Bencomo</a>, 
<a href="/search/cs?searchtype=author&query=Griffiths%2C+T+L">Thomas L. Griffiths</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 3 figures. Code available at <a href="https://github.com/jakesnell/neural-circuits">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)

</div>
<p class="mathjax">Most applications of machine learning to classification assume a closed set
of balanced classes. This is at odds with the real world, where class
occurrence statistics often follow a long-tailed power-law distribution and it
is unlikely that all classes are seen in a single sample. Nonparametric
Bayesian models naturally capture this phenomenon, but have significant
practical barriers to widespread adoption, namely implementation complexity and
computational inefficiency. To address this, we present a method for extracting
the inductive bias from a nonparametric Bayesian model and transferring it to
an artificial neural network. By simulating data with a nonparametric Bayesian
prior, we can metalearn a sequence model that performs inference over an
unlimited set of classes. After training, this "neural circuit" has distilled
the corresponding inductive bias and can successfully perform sequential
inference over an open set of classes. Our experimental results show that the
metalearned neural circuit achieves comparable or better performance than
particle filter-based methods for inference in these models while being faster
and simpler to use than methods that explicitly incorporate Bayesian
nonparametric inference.
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14603" title="Abstract">arXiv:2311.14603</a> [<a href="/pdf/2311.14603" title="Download PDF">pdf</a>, <a href="/format/2311.14603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Animate124: Animating One Image to 4D Dynamic Scene
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yuyang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zhiwen Yan</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+E">Enze Xie</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+L">Lanqing Hong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenguo Li</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+G+H">Gim Hee Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://animate124.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce Animate124 (Animate-one-image-to-4D), the first work to animate
a single in-the-wild image into 3D video through textual motion descriptions,
an underexplored problem with significant applications. Our 4D generation
leverages an advanced 4D grid dynamic Neural Radiance Field (NeRF) model,
optimized in three distinct stages using multiple diffusion priors. Initially,
a static model is optimized using the reference image, guided by 2D and 3D
diffusion priors, which serves as the initialization for the dynamic NeRF.
Subsequently, a video diffusion model is employed to learn the motion specific
to the subject. However, the object in the 3D videos tends to drift away from
the reference image over time. This drift is mainly due to the misalignment
between the text prompt and the reference image in the video diffusion model.
In the final stage, a personalized diffusion prior is therefore utilized to
address the semantic drift. As the pioneering image-text-to-4D generation
framework, our method demonstrates significant advancements over existing
baselines, evidenced by comprehensive quantitative and qualitative assessments.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14604" title="Abstract">arXiv:2311.14604</a> [<a href="/pdf/2311.14604" title="Download PDF">pdf</a>, <a href="/format/2311.14604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evolution of Neural Architectures for Financial Forecasting: A Note on  Data Incompatibility during Crisis Periods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hafiz%2C+F">Faizal Hafiz</a>, 
<a href="/search/cs?searchtype=author&query=Broekaert%2C+J">Jan Broekaert</a>, 
<a href="/search/cs?searchtype=author&query=Swain%2C+A">Akshya Swain</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">This note focuses on the optimization of neural architectures for stock index
movement forecasting following a major market disruption or crisis. Given that
such crises may introduce a shift in market dynamics, this study aims to
investigate whether the training data from market dynamics prior to the crisis
are compatible with the data during the crisis period. To this end, two
distinct learning environments are designed to evaluate and reconcile the
effects of possibly different market dynamics. These environments differ
principally based on the role assigned to the pre-crisis data. In both
environments, a set of non-dominated architectures are identified to satisfy
the multi-criteria co-evolution problem, which simultaneously addresses the
selection issues related to features and hidden layer topology. To test the
hypothesis of pre-crisis data incompatibility, the day-ahead movement
prediction of the NASDAQ index is considered during two recent and major market
disruptions; the 2008 financial crisis and the COVID-19 pandemic. The results
of a detailed comparative evaluation convincingly support the incompatibility
hypothesis and highlight the need to select re-training windows carefully.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14613" title="Abstract">arXiv:2311.14613</a> [<a href="/pdf/2311.14613" title="Download PDF">pdf</a>, <a href="/format/2311.14613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Routing and Spectrum Allocation in Broadband Degenerate EPR-Pair  Distribution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bali%2C+R">Rohan Bali</a>, 
<a href="/search/cs?searchtype=author&query=Tittelbaugh%2C+A">Ashley Tittelbaugh</a>, 
<a href="/search/cs?searchtype=author&query=Jenkins%2C+S+L">Shelbi L. Jenkins</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+A">Anuj Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Horgan%2C+J">Jerry Horgan</a>, 
<a href="/search/cs?searchtype=author&query=Ruffini%2C+M">Marco Ruffini</a>, 
<a href="/search/cs?searchtype=author&query=Kilper%2C+D">Daniel Kilper</a>, 
<a href="/search/cs?searchtype=author&query=Bash%2C+B+A">Boulat A. Bash</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">We investigate resource allocation for quantum entanglement distribution over
an optical network. We characterize and model a network architecture that
employs a single quasideterministic time-frequency heralded EPR-pair source,
and develop a routing scheme for distributing entangled photon pairs over such
a network. We focus on fairness in entanglement distribution, and compare both
the performance of various spectrum allocation schemes as well as their Jain
index.
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14615" title="Abstract">arXiv:2311.14615</a> [<a href="/pdf/2311.14615" title="Download PDF">pdf</a>, <a href="/format/2311.14615" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Industrial Perspective on Multi-Agent Decision Making for  Interoperable Robot Navigation following the VDA5050 Standard
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+Duijkeren%2C+N">Niels van Duijkeren</a>, 
<a href="/search/cs?searchtype=author&query=Palmieri%2C+L">Luigi Palmieri</a>, 
<a href="/search/cs?searchtype=author&query=Lange%2C+R">Ralph Lange</a>, 
<a href="/search/cs?searchtype=author&query=Kleiner%2C+A">Alexander Kleiner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 2 figures, presented in the Decision Making in Multi-Agent Systems Workshop at IROS2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper provides a perspective on the literature and current challenges in
Multi-Agent Systems for interoperable robot navigation in industry. The focus
is on the multi-agent decision stack for Autonomous Mobile Robots operating in
mixed environments with humans, manually driven vehicles, and legacy Automated
Guided Vehicles. We provide typical characteristics of such Multi-Agent Systems
observed today and how these are expected to change on the short term due to
the new standard VDA5050 and the interoperability framework OpenRMF. We present
recent changes in fleet management standards and the role of open middleware
frameworks like ROS2 reaching industrial-grade quality. Approaches to increase
the robustness and performance of multi-robot navigation systems for
transportation are discussed, and research opportunities are derived.
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14616" title="Abstract">arXiv:2311.14616</a> [<a href="/pdf/2311.14616" title="Download PDF">pdf</a>, <a href="/format/2311.14616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using MultiPrecisonArrays.jl: Iterative Refinement in Julia
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kelley%2C+C+T">C. T. Kelley</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">MultiPrecisionArrays.jl is a Julia package. This package provides data
structures and solvers for several variants of iterative refinement. It will
become much more useful when half precision (aka Float16) is fully supported in
LAPACK/BLAS. For now, its only general-purpose application is classical
iterative refinement with double precision equations and single precision
factorizations.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14617" title="Abstract">arXiv:2311.14617</a> [<a href="/pdf/2311.14617" title="Download PDF">pdf</a>, <a href="/format/2311.14617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Style Transfer for Computer Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ioannou%2C+E">Eleftherios Ioannou</a>, 
<a href="/search/cs?searchtype=author&query=Maddock%2C+S">Steve Maddock</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural Style Transfer (NST) research has been applied to images, videos, 3D
meshes and radiance fields, but its application to 3D computer games remains
relatively unexplored. Whilst image and video NST systems can be used as a
post-processing effect for a computer game, this results in undesired artefacts
and diminished post-processing effects. Here, we present an approach for
injecting depth-aware NST as part of the 3D rendering pipeline. Qualitative and
quantitative experiments are used to validate our in-game stylisation
framework. We demonstrate temporally consistent results of artistically
stylised game scenes, outperforming state-of-the-art image and video NST
methods.
</p>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14619" title="Abstract">arXiv:2311.14619</a> [<a href="/pdf/2311.14619" title="Download PDF">pdf</a>, <a href="/format/2311.14619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eliciting Honest Information From Authors Using Sequential Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yichi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Schoenebeck%2C+G">Grant Schoenebeck</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+W">Weijie Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">In the setting of conference peer review, the conference aims to accept
high-quality papers and reject low-quality papers based on noisy review scores.
A recent work proposes the isotonic mechanism, which can elicit the ranking of
paper qualities from an author with multiple submissions to help improve the
conference's decisions. However, the isotonic mechanism relies on the
assumption that the author's utility is both an increasing and a convex
function with respect to the review score, which is often violated in peer
review settings (e.g.~when authors aim to maximize the number of accepted
papers). In this paper, we propose a sequential review mechanism that can
truthfully elicit the ranking information from authors while only assuming the
agent's utility is increasing with respect to the true quality of her accepted
papers. The key idea is to review the papers of an author in a sequence based
on the provided ranking and conditioning the review of the next paper on the
review scores of the previous papers. Advantages of the sequential review
mechanism include 1) eliciting truthful ranking information in a more realistic
setting than prior work; 2) improving the quality of accepted papers, reducing
the reviewing workload and increasing the average quality of papers being
reviewed; 3) incentivizing authors to write fewer papers of higher quality.
</p>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14621" title="Abstract">arXiv:2311.14621</a> [<a href="/pdf/2311.14621" title="Download PDF">pdf</a>, <a href="/format/2311.14621" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Received Signal and Channel Parameter Estimation in Molecular  Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baydas%2C+O+T">O. Tansel Baydas</a>, 
<a href="/search/cs?searchtype=author&query=Akan%2C+O+B">Ozgur B. Akan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Molecular communication (MC) is a paradigm that employs molecules as
information transmitters, hence, requiring unconventional transceivers and
detection techniques for the Internet of Bio-Nano Things (IoBNT). In this
study, we provide a novel MC model that incorporates a spherical transmitter
and receiver with partial absorption. This model offers a more realistic
representation than receiver architectures in literature, e.g. passive or
entirely absorbing configurations. An optimization-based technique utilizing
particle swarm optimization (PSO) is employed to accurately estimate the
cumulative number of molecules received. This technique yields nearly constant
correction parameters and demonstrates a significant improvement of 5 times in
terms of root mean square error (RMSE). The estimated channel model provides an
approximate analytical impulse response; hence, it is used for estimating
channel parameters such as distance, diffusion coefficient, or a combination of
both. We apply iterative maximum likelihood estimation (MLE) for the parameter
estimation, which gives consistent errors compared to the estimated Cramer-Rao
Lower Bound (CLRB).
</p>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14625" title="Abstract">arXiv:2311.14625</a> [<a href="/pdf/2311.14625" title="Download PDF">pdf</a>, <a href="/format/2311.14625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ARIA: On the interaction between Architectures, Aggregation methods and  Initializations in federated visual classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Siomos%2C+V">Vasilis Siomos</a>, 
<a href="/search/cs?searchtype=author&query=Naval-Marimont%2C+S">Sergio Naval-Marimont</a>, 
<a href="/search/cs?searchtype=author&query=Passerat-Palmbach%2C+J">Jonathan Passerat-Palmbach</a>, 
<a href="/search/cs?searchtype=author&query=Tarroni%2C+G">Giacomo Tarroni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review at the 21st IEEE International Symposium on Biomedical Imaging
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated Learning (FL) is a collaborative training paradigm that allows for
privacy-preserving learning of cross-institutional models by eliminating the
exchange of sensitive data and instead relying on the exchange of model
parameters between the clients and a server. Despite individual studies on how
client models are aggregated, and, more recently, on the benefits of ImageNet
pre-training, there is a lack of understanding of the effect the architecture
chosen for the federation has, and of how the aforementioned elements
interconnect. To this end, we conduct the first joint
ARchitecture-Initialization-Aggregation study and benchmark ARIAs across a
range of medical image classification tasks. We find that, contrary to current
practices, ARIA elements have to be chosen together to achieve the best
possible performance. Our results also shed light on good choices for each
element depending on the task, the effect of normalisation layers, and the
utility of SSL pre-training, pointing to potential directions for designing
FL-specific architectures and training pipelines.
</p>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14631" title="Abstract">arXiv:2311.14631</a> [<a href="/pdf/2311.14631" title="Download PDF">pdf</a>, <a href="/format/2311.14631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CatVersion: Concatenating Embeddings for Diffusion-Based Text-to-Image  Personalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Ruoyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Mingrui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+S">Shiyin Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Nannan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xinbo Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose CatVersion, an inversion-based method that learns the personalized
concept through a handful of examples. Subsequently, users can utilize text
prompts to generate images that embody the personalized concept, thereby
achieving text-to-image personalization. In contrast to existing approaches
that emphasize word embedding learning or parameter fine-tuning for the
diffusion model, which potentially causes concept dilution or overfitting, our
method concatenates embeddings on the feature-dense space of the text encoder
in the diffusion model to learn the gap between the personalized concept and
its base class, aiming to maximize the preservation of prior knowledge in
diffusion models while restoring the personalized concepts. To this end, we
first dissect the text encoder's integration in the image generation process to
identify the feature-dense space of the encoder. Afterward, we concatenate
embeddings on the Keys and Values in this space to learn the gap between the
personalized concept and its base class. In this way, the concatenated
embeddings ultimately manifest as a residual on the original attention output.
To more accurately and unbiasedly quantify the results of personalized image
generation, we improve the CLIP image alignment score based on masks.
Qualitatively and quantitatively, CatVersion helps to restore personalization
concepts more faithfully and enables more robust editing.
</p>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14632" title="Abstract">arXiv:2311.14632</a> [<a href="/pdf/2311.14632" title="Download PDF">pdf</a>, <a href="/format/2311.14632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially Private SGD Without Clipping Bias: An Error-Feedback  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bu%2C+Z">Zhiqi Bu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z+S">Zhiwei Steven Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+M">Mingyi Hong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Differentially Private Stochastic Gradient Descent with gradient clipping
(DPSGD-GC) is a powerful tool for training deep learning models using sensitive
data, providing both a solid theoretical privacy guarantee and high efficiency.
However, using DPSGD-GC to ensure Differential Privacy (DP) comes at the cost
of model performance degradation due to DP noise injection and gradient
clipping. Existing research has extensively analyzed the theoretical
convergence of DPSGD-GC, and has shown that it only converges when using large
clipping thresholds that are dependent on problem-specific parameters.
Unfortunately, these parameters are often unknown in practice, making it hard
to choose the optimal clipping threshold. Therefore, in practice, DPSGD-GC
suffers from degraded performance due to the {\it constant} bias introduced by
the clipping.
<br />In our work, we propose a new error-feedback (EF) DP algorithm as an
alternative to DPSGD-GC, which not only offers a diminishing utility bound
without inducing a constant clipping bias, but more importantly, it allows for
an arbitrary choice of clipping threshold that is independent of the problem.
We establish an algorithm-specific DP analysis for our proposed algorithm,
providing privacy guarantees based on R{\'e}nyi DP. Additionally, we
demonstrate that under mild conditions, our algorithm can achieve nearly the
same utility bound as DPSGD without gradient clipping. Our empirical results on
Cifar-10/100 and E2E datasets, show that the proposed algorithm achieves higher
accuracies than DPSGD while maintaining the same level of DP guarantee.
</p>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14633" title="Abstract">arXiv:2311.14633</a> [<a href="/pdf/2311.14633" title="Download PDF">pdf</a>, <a href="/format/2311.14633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One Strike, You&#x27;re Out: Detecting Markush Structures in Low  Signal-to-Noise Ratio Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jurriaans%2C+T">Thomas Jurriaans</a>, 
<a href="/search/cs?searchtype=author&query=Szarkowska%2C+K">Kinga Szarkowska</a>, 
<a href="/search/cs?searchtype=author&query=Nalisnick%2C+E">Eric Nalisnick</a>, 
<a href="/search/cs?searchtype=author&query=Schwoerer%2C+M">Markus Schwoerer</a>, 
<a href="/search/cs?searchtype=author&query=Thorne%2C+C">Camilo Thorne</a>, 
<a href="/search/cs?searchtype=author&query=Akhondi%2C+S">Saber Akhondi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 9 tables, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Modern research increasingly relies on automated methods to assist
researchers. An example of this is Optical Chemical Structure Recognition
(OCSR), which aids chemists in retrieving information about chemicals from
large amounts of documents. Markush structures are chemical structures that
cannot be parsed correctly by OCSR and cause errors. The focus of this research
was to propose and test a novel method for classifying Markush structures.
Within this method, a comparison was made between fixed-feature extraction and
end-to-end learning (CNN). The end-to-end method performed significantly better
than the fixed-feature method, achieving 0.928 (0.035 SD) Macro F1 compared to
the fixed-feature method's 0.701 (0.052 SD). Because of the nature of the
experiment, these figures are a lower bound and can be improved further. These
results suggest that Markush structures can be filtered out effectively and
accurately using the proposed method. When implemented into OCSR pipelines,
this method can improve their performance and use to other researchers.
</p>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14634" title="Abstract">arXiv:2311.14634</a> [<a href="/pdf/2311.14634" title="Download PDF">pdf</a>, <a href="/format/2311.14634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Bounds on the Local and Global Edge-length Ratio of Planar Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Di+Giacomo%2C+E">Emilio Di Giacomo</a>, 
<a href="/search/cs?searchtype=author&query=Didimo%2C+W">Walter Didimo</a>, 
<a href="/search/cs?searchtype=author&query=Liotta%2C+G">Giuseppe Liotta</a>, 
<a href="/search/cs?searchtype=author&query=Meijer%2C+H">Henk Meijer</a>, 
<a href="/search/cs?searchtype=author&query=Montecchiani%2C+F">Fabrizio Montecchiani</a>, 
<a href="/search/cs?searchtype=author&query=Wismath%2C+S">Stephen Wismath</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">The \emph{local edge-length ratio} of a planar straight-line drawing $\Gamma$
is the largest ratio between the lengths of any pair of edges of $\Gamma$ that
share a common vertex. The \emph{global edge-length ratio} of $\Gamma$ is the
largest ratio between the lengths of any pair of edges of $\Gamma$. The local
(global) edge-length ratio of a planar graph is the infimum over all local
(global) edge-length ratios of its planar straight-line drawings. We show that
there exist planar graphs with $n$ vertices whose local edge-length ratio is
$\Omega(\sqrt{n})$. We then show a technique to establish upper bounds on the
global (and hence local) edge-length ratio of planar graphs and~apply~it to
Halin graphs and to other families of graphs having outerplanarity two.
</p>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14635" title="Abstract">arXiv:2311.14635</a> [<a href="/pdf/2311.14635" title="Download PDF">pdf</a>, <a href="/ps/2311.14635" title="Download PostScript">ps</a>, <a href="/format/2311.14635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Detection and Counting of Windows using UAV Imagery based  Remote Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patel%2C+D">Dhruv Patel</a>, 
<a href="/search/cs?searchtype=author&query=Chepuri%2C+S">Shivani Chepuri</a>, 
<a href="/search/cs?searchtype=author&query=Thakur%2C+S">Sarvesh Thakur</a>, 
<a href="/search/cs?searchtype=author&query=Harikumar%2C+K">K. Harikumar</a>, 
<a href="/search/cs?searchtype=author&query=S.%2C+R+K">Ravi Kiran S.</a>, 
<a href="/search/cs?searchtype=author&query=Krishna%2C+K+M">K. Madhava Krishna</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Despite the technological advancements in the construction and surveying
sector, the inspection of salient features like windows in an
under-construction or existing building is predominantly a manual process.
Moreover, the number of windows present in a building is directly related to
the magnitude of deformation it suffers under earthquakes. In this research, a
method to accurately detect and count the number of windows of a building by
deploying an Unmanned Aerial Vehicle (UAV) based remote sensing system is
proposed. The proposed two-stage method automates the identification and
counting of windows by developing computer vision pipelines that utilize data
from UAV's onboard camera and other sensors. Quantitative and Qualitative
results show the effectiveness of our proposed approach in accurately detecting
and counting the windows compared to the existing method.
</p>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14641" title="Abstract">arXiv:2311.14641</a> [<a href="/pdf/2311.14641" title="Download PDF">pdf</a>, <a href="/format/2311.14641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neuromorphic Intermediate Representation: A Unified Instruction Set for  Interoperable Brain-Inspired Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pedersen%2C+J+E">Jens E. Pedersen</a>, 
<a href="/search/cs?searchtype=author&query=Abreu%2C+S">Steven Abreu</a>, 
<a href="/search/cs?searchtype=author&query=Jobst%2C+M">Matthias Jobst</a>, 
<a href="/search/cs?searchtype=author&query=Lenz%2C+G">Gregor Lenz</a>, 
<a href="/search/cs?searchtype=author&query=Fra%2C+V">Vittorio Fra</a>, 
<a href="/search/cs?searchtype=author&query=Bauer%2C+F+C">Felix C. Bauer</a>, 
<a href="/search/cs?searchtype=author&query=Muir%2C+D+R">Dylan R. Muir</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Peng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Vogginger%2C+B">Bernhard Vogginger</a>, 
<a href="/search/cs?searchtype=author&query=Heckel%2C+K">Kade Heckel</a>, 
<a href="/search/cs?searchtype=author&query=Urgese%2C+G">Gianvito Urgese</a>, 
<a href="/search/cs?searchtype=author&query=Shankar%2C+S">Sadasivan Shankar</a>, 
<a href="/search/cs?searchtype=author&query=Stewart%2C+T+C">Terrence C. Stewart</a>, 
<a href="/search/cs?searchtype=author&query=Eshraghian%2C+J+K">Jason K. Eshraghian</a>, 
<a href="/search/cs?searchtype=author&query=Sheik%2C+S">Sadique Sheik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NIR is available at <a href="https://github.com/neuromorphs/NIR">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Spiking neural networks and neuromorphic hardware platforms that emulate
neural dynamics are slowly gaining momentum and entering main-stream usage.
Despite a well-established mathematical foundation for neural dynamics, the
implementation details vary greatly across different platforms.
Correspondingly, there are a plethora of software and hardware implementations
with their own unique technology stacks. Consequently, neuromorphic systems
typically diverge from the expected computational model, which challenges the
reproducibility and reliability across platforms. Additionally, most
neuromorphic hardware is limited by its access via a single software frameworks
with a limited set of training procedures. Here, we establish a common
reference-frame for computations in neuromorphic systems, dubbed the
Neuromorphic Intermediate Representation (NIR). NIR defines a set of
computational primitives as idealized continuous-time hybrid systems that can
be composed into graphs and mapped to and from various neuromorphic technology
stacks. By abstracting away assumptions around discretization and hardware
constraints, NIR faithfully captures the fundamental computation, while
simultaneously exposing the exact differences between the evaluated
implementation and the idealized mathematical formalism. We reproduce three NIR
graphs across 7 neuromorphic simulators and 4 hardware platforms, demonstrating
support for an unprecedented number of neuromorphic systems. With NIR, we
decouple the evolution of neuromorphic hardware and software, ultimately
increasing the interoperability between platforms and improving accessibility
to neuromorphic technologies. We believe that NIR is an important step towards
the continued study of brain-inspired hardware and bottom-up approaches aimed
at an improved understanding of the computational underpinnings of nervous
systems.
</p>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14642" title="Abstract">arXiv:2311.14642</a> [<a href="/pdf/2311.14642" title="Download PDF">pdf</a>, <a href="/format/2311.14642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous football player tracking from discrete broadcast data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Penn%2C+M+J">Matthew J. Penn</a>, 
<a href="/search/cs?searchtype=author&query=Donnelly%2C+C+A">Christl A. Donnelly</a>, 
<a href="/search/cs?searchtype=author&query=Bhatt%2C+S">Samir Bhatt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Player tracking data remains out of reach for many professional football
teams as their video feeds are not sufficiently high quality for computer
vision technologies to be used. To help bridge this gap, we present a method
that can estimate continuous full-pitch tracking data from discrete data made
from broadcast footage. Such data could be collected by clubs or players at a
similar cost to event data, which is widely available down to semi-professional
level. We test our method using open-source tracking data, and include a
version that can be applied to a large set of over 200 games with such discrete
data.
</p>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14645" title="Abstract">arXiv:2311.14645</a> [<a href="/pdf/2311.14645" title="Download PDF">pdf</a>, <a href="/format/2311.14645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A General Framework for User-Guided Bayesian Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hvarfner%2C+C">Carl Hvarfner</a>, 
<a href="/search/cs?searchtype=author&query=Hutter%2C+F">Frank Hutter</a>, 
<a href="/search/cs?searchtype=author&query=Nardi%2C+L">Luigi Nardi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">The optimization of expensive-to-evaluate black-box functions is prevalent in
various scientific disciplines. Bayesian optimization is an automatic, general
and sample-efficient method to solve these problems with minimal knowledge of
the underlying function dynamics. However, the ability of Bayesian optimization
to incorporate prior knowledge or beliefs about the function at hand in order
to accelerate the optimization is limited, which reduces its appeal for
knowledgeable practitioners with tight budgets. To allow domain experts to
customize the optimization routine, we propose ColaBO, the first
Bayesian-principled framework for incorporating prior beliefs beyond the
typical kernel structure, such as the likely location of the optimizer or the
optimal value. The generality of ColaBO makes it applicable across different
Monte Carlo acquisition functions and types of user beliefs. We empirically
demonstrate ColaBO's ability to substantially accelerate optimization when the
prior information is accurate, and to retain approximately default performance
when it is misleading.
</p>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14646" title="Abstract">arXiv:2311.14646</a> [<a href="/pdf/2311.14646" title="Download PDF">pdf</a>, <a href="/format/2311.14646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> More is Better in Modern Machine Learning: when Infinite  Overparameterization is Optimal and Overfitting is Obligatory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Simon%2C+J+B">James B. Simon</a>, 
<a href="/search/cs?searchtype=author&query=Karkada%2C+D">Dhruva Karkada</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+N">Nikhil Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Belkin%2C+M">Mikhail Belkin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">In our era of enormous neural networks, empirical progress has been driven by
the philosophy that more is better. Recent deep learning practice has found
repeatedly that larger model size, more data, and more computation (resulting
in lower training loss) improves performance. In this paper, we give
theoretical backing to these empirical observations by showing that these three
properties hold in random feature (RF) regression, a class of models equivalent
to shallow networks with only the last layer trained.
<br />Concretely, we first show that the test risk of RF regression decreases
monotonically with both the number of features and the number of samples,
provided the ridge penalty is tuned optimally. In particular, this implies that
infinite width RF architectures are preferable to those of any finite width. We
then proceed to demonstrate that, for a large class of tasks characterized by
powerlaw eigenstructure, training to near-zero training loss is obligatory:
near-optimal performance can only be achieved when the training error is much
smaller than the test error. Grounding our theory in real-world data, we find
empirically that standard computer vision tasks with convolutional neural
tangent kernels clearly fall into this class. Taken together, our results tell
a simple, testable story of the benefits of overparameterization, overfitting,
and more data in random feature models.
</p>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14648" title="Abstract">arXiv:2311.14648</a> [<a href="/pdf/2311.14648" title="Download PDF">pdf</a>, <a href="/format/2311.14648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Calibrated Language Models Must Hallucinate
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kalai%2C+A+T">Adam Tauman Kalai</a>, 
<a href="/search/cs?searchtype=author&query=Vempala%2C+S+S">Santosh S. Vempala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent language models have a mysterious tendency to generate false but
plausible-sounding text. Such "hallucinations" are an obstacle to the usability
of language-based AI systems and can harm people who rely upon their outputs.
This work shows shows that there is an inherent statistical reason that
pretrained language models hallucinate certain types of facts, having nothing
to do with the transformer LM architecture or data quality. For "arbitrary"
facts whose veracity cannot be determined from the training data, we show that
hallucination is necessary for language models that satisfy a statistical
calibration condition appropriate for generative language models. Specifically,
if the maximum probability of any fact is bounded, we show that the probability
of generating a hallucination is close to the fraction of facts that occur
exactly once in the training data (a "Good-Turing" estimate), even assuming
ideal training data without errors.
<br />One conclusion is that models pretrained to be sufficiently good predictors
(i.e., calibrated) may require post-training to mitigate hallucinations on the
type of arbitrary facts that tend to appear once in the training set. However,
our analysis also suggests that there is no statistical reason that pretraining
will lead to hallucination on facts that tend to appear more than once in the
training data (like references to publications such as articles and books,
whose hallucinations have been particularly notable and problematic) or on
systematic facts (like arithmetic calculations). Therefore, different
architectures and learning algorithms may mitigate these latter types of
hallucinations.
</p>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14649" title="Abstract">arXiv:2311.14649</a> [<a href="/pdf/2311.14649" title="Download PDF">pdf</a>, <a href="/format/2311.14649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning in Deep Factor Graphs with Gaussian Belief Propagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nabarro%2C+S">Seth Nabarro</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Wilk%2C+M">Mark van der Wilk</a>, 
<a href="/search/cs?searchtype=author&query=Davison%2C+A+J">Andrew J Davison</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We propose an approach to do learning in Gaussian factor graphs. We treat all
relevant quantities (inputs, outputs, parameters, latents) as random variables
in a graphical model, and view both training and prediction as inference
problems with different observed nodes. Our experiments show that these
problems can be efficiently solved with belief propagation (BP), whose updates
are inherently local, presenting exciting opportunities for distributed and
asynchronous training. Our approach can be scaled to deep networks and provides
a natural means to do continual learning: use the BP-estimated parameter
marginals of the current task as parameter priors for the next. On a video
denoising task we demonstrate the benefit of learnable parameters over a
classical factor graph approach and we show encouraging performance of deep
factor graphs for continual image classification on MNIST.
</p>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14650" title="Abstract">arXiv:2311.14650</a> [<a href="/pdf/2311.14650" title="Download PDF">pdf</a>, <a href="/format/2311.14650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GVEL: Fast Graph Loading in Edgelist and Compressed Sparse Row (CSR)  formats
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sahu%2C+S">Subhajit Sahu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>

</div>
<p class="mathjax">Efficient IO techniques are crucial in high-performance graph processing
frameworks like Gunrock and Hornet, as fast graph loading is essential to
minimize processing time and reduce system/cloud usage charges. This research
study presents approaches for efficiently reading an Edgelist from a text file
and converting it to a Compressed Sparse Row (CSR) representation. On a server
with dual 16-core Intel Xeon Gold 6226R processors and MegaRAID SAS-3 storage,
our approach, which we term as GVEL, outperforms Hornet, Gunrock, and PIGO by
significant margins in CSR reading, exhibiting an average speedup of 78x, 112x,
and 1.8x, respectively. For Edgelist reading, GVEL is 2.6x faster than PIGO on
average, and achieves a Edgelist read rate of 1.9 billion edges/s. For every
doubling of threads, GVEL improves performance at an average rate of 1.9x and
1.7x for reading Edgelist and reading CSR respectively.
</p>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14651" title="Abstract">arXiv:2311.14651</a> [<a href="/pdf/2311.14651" title="Download PDF">pdf</a>, <a href="/format/2311.14651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> History Filtering in Imperfect Information Games: Algorithms and  Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Solinas%2C+C">Christopher Solinas</a>, 
<a href="/search/cs?searchtype=author&query=Rebstock%2C+D">Douglas Rebstock</a>, 
<a href="/search/cs?searchtype=author&query=Sturtevant%2C+N+R">Nathan R. Sturtevant</a>, 
<a href="/search/cs?searchtype=author&query=Buro%2C+M">Michael Buro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Historically applied exclusively to perfect information games, depth-limited
search with value functions has been key to recent advances in AI for imperfect
information games. Most prominent approaches with strong theoretical guarantees
require subgame decomposition - a process in which a subgame is computed from
public information and player beliefs. However, subgame decomposition can
itself require non-trivial computations, and its tractability depends on the
existence of efficient algorithms for either full enumeration or generation of
the histories that form the root of the subgame. Despite this, no formal
analysis of the tractability of such computations has been established in prior
work, and application domains have often consisted of games, such as poker, for
which enumeration is trivial on modern hardware. Applying these ideas to more
complex domains requires understanding their cost.
<br />In this work, we introduce and analyze the computational aspects and
tractability of filtering histories for subgame decomposition. We show that
constructing a single history from the root of the subgame is generally
intractable, and then provide a necessary and sufficient condition for
efficient enumeration. We also introduce a novel Markov Chain Monte Carlo-based
generation algorithm for trick-taking card games - a domain where enumeration
is often prohibitively expensive. Our experiments demonstrate its improved
scalability in the trick-taking card game Oh Hell. These contributions clarify
when and how depth-limited search via subgame decomposition can be an effective
tool for sequential decision-making in imperfect information settings.
</p>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14652" title="Abstract">arXiv:2311.14652</a> [<a href="/pdf/2311.14652" title="Download PDF">pdf</a>, <a href="/ps/2311.14652" title="Download PostScript">ps</a>, <a href="/format/2311.14652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One Pass Streaming Algorithm for Super Long Token Attention  Approximation in Sublinear Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Addanki%2C+R">Raghav Addanki</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhao Song</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chiwun Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Machine Learning (stat.ML)

</div>
<p class="mathjax">Deploying Large Language Models (LLMs) in streaming applications that involve
long contexts, particularly for extended dialogues and text analysis, is of
paramount importance but presents two significant challenges. Firstly, the
memory consumption is substantial during the decoding phase due to the caching
of Key and Value states (KV) of previous tokens. Secondly, attention
computation is time-consuming with a time complexity of $O(n^2)$ for the
generation of each token. In recent OpenAI DevDay (Nov 6, 2023), OpenAI
released a new model that is able to support a 128K-long document, in our
paper, we focus on the memory-efficient issue when context length $n$ is much
greater than 128K ($n \gg 2^d$). Considering a single-layer self-attention with
Query, Key, and Value matrices $Q, K, V \in \mathbb{R}^{n \times d}$, the
polynomial method approximates the attention output $T \in \mathbb{R}^{n \times
d}$. It accomplishes this by constructing $U_1, U_2 \in \mathbb{R}^{n \times
t}$ to expedite attention ${\sf Attn}(Q, K, V)$ computation within $n^{1+o(1)}$
time executions. Despite this, storing the Key and Value matrices $K, V \in
\mathbb{R}^{n \times d}$ still necessitates $O( n d)$ space, leading to
significant memory usage. In response to these challenges, we introduce a new
algorithm that only reads one pass of the data in streaming fashion. This
method employs sublinear space $o(n)$ to store three sketch matrices,
alleviating the need for exact $K, V$ storage. Notably, our algorithm exhibits
exceptional memory-efficient performance with super-long tokens. As the token
length $n$ increases, our error guarantee diminishes while the memory usage
remains nearly constant. This unique attribute underscores the potential of our
technique in efficiently handling LLMs in streaming applications.
</p>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14653" title="Abstract">arXiv:2311.14653</a> [<a href="/pdf/2311.14653" title="Download PDF">pdf</a>, <a href="/format/2311.14653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven Prior Learning for Bayesian Optimisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hellan%2C+S+P">Sigrid Passano Hellan</a>, 
<a href="/search/cs?searchtype=author&query=Lucas%2C+C+G">Christopher G. Lucas</a>, 
<a href="/search/cs?searchtype=author&query=Goddard%2C+N+H">Nigel H. Goddard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be presented at the NeurIPS 2023 Workshop on Adaptive Experimental Design and Active Learning in the Real World
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Transfer learning for Bayesian optimisation has generally assumed a strong
similarity between optimisation tasks, with at least a subset having similar
optimal inputs. This assumption can reduce computational costs, but it is
violated in a wide range of optimisation problems where transfer learning may
nonetheless be useful. We replace this assumption with a weaker one only
requiring the shape of the optimisation landscape to be similar, and analyse
the recent method Prior Learning for Bayesian Optimisation - PLeBO - in this
setting. By learning priors for the hyperparameters of the Gaussian process
surrogate model we can better approximate the underlying function, especially
for few function evaluations. We validate the learned priors and compare to a
breadth of transfer learning approaches, using synthetic data and a recent air
pollution optimisation problem as benchmarks. We show that PLeBO and prior
transfer find good inputs in fewer evaluations.
</p>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14656" title="Abstract">arXiv:2311.14656</a> [<a href="/pdf/2311.14656" title="Download PDF">pdf</a>, <a href="/format/2311.14656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Charting New Territories: Exploring the Geographic and Geospatial  Capabilities of Multimodal LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roberts%2C+J">Jonathan Roberts</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%BCddecke%2C+T">Timo L&#xfc;ddecke</a>, 
<a href="/search/cs?searchtype=author&query=Sheikh%2C+R">Rehan Sheikh</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Kai Han</a>, 
<a href="/search/cs?searchtype=author&query=Albanie%2C+S">Samuel Albanie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multimodal large language models (MLLMs) have shown remarkable capabilities
across a broad range of tasks but their knowledge and abilities in the
geographic and geospatial domains are yet to be explored, despite potential
wide-ranging benefits to navigation, environmental research, urban development,
and disaster response. We conduct a series of experiments exploring various
vision capabilities of MLLMs within these domains, particularly focusing on the
frontier model GPT-4V, and benchmark its performance against open-source
counterparts. Our methodology involves challenging these models with a
small-scale geographic benchmark consisting of a suite of visual tasks, testing
their abilities across a spectrum of complexity. The analysis uncovers not only
where such models excel, including instances where they outperform humans, but
also where they falter, providing a balanced view of their capabilities in the
geographic domain. To enable the comparison and evaluation of future models,
our benchmark will be publicly released.
</p>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14658" title="Abstract">arXiv:2311.14658</a> [<a href="/pdf/2311.14658" title="Download PDF">pdf</a>, <a href="/format/2311.14658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence Analysis for Learning Orthonormal Deep Linear Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhen Qin</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xuwei Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhihui Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Enforcing orthonormal or isometric property for the weight matrices has been
shown to enhance the training of deep neural networks by mitigating gradient
exploding/vanishing and increasing the robustness of the learned networks.
However, despite its practical performance, the theoretical analysis of
orthonormality in neural networks is still lacking; for example, how
orthonormality affects the convergence of the training process. In this letter,
we aim to bridge this gap by providing convergence analysis for training
orthonormal deep linear neural networks. Specifically, we show that Riemannian
gradient descent with an appropriate initialization converges at a linear rate
for training orthonormal deep linear neural networks with a class of loss
functions. Unlike existing works that enforce orthonormal weight matrices for
all the layers, our approach excludes this requirement for one layer, which is
crucial to establish the convergence guarantee. Our results shed light on how
increasing the number of hidden layers can impact the convergence speed.
Experimental results validate our theoretical analysis.
</p>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14665" title="Abstract">arXiv:2311.14665</a> [<a href="/pdf/2311.14665" title="Download PDF">pdf</a>, <a href="/format/2311.14665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Self-Supervised Features for Learning Unsupervised  Instance Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Engstler%2C+P">Paul Engstler</a>, 
<a href="/search/cs?searchtype=author&query=Melas-Kyriazi%2C+L">Luke Melas-Kyriazi</a>, 
<a href="/search/cs?searchtype=author&query=Rupprecht%2C+C">Christian Rupprecht</a>, 
<a href="/search/cs?searchtype=author&query=Laina%2C+I">Iro Laina</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Self-supervised learning (SSL) can be used to solve complex visual tasks
without human labels. Self-supervised representations encode useful semantic
information about images, and as a result, they have already been used for
tasks such as unsupervised semantic segmentation. In this paper, we investigate
self-supervised representations for instance segmentation without any manual
annotations. We find that the features of different SSL methods vary in their
level of instance-awareness. In particular, DINO features, which are known to
be excellent semantic descriptors, lack behind MAE features in their
sensitivity for separating instances.
</p>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14671" title="Abstract">arXiv:2311.14671</a> [<a href="/pdf/2311.14671" title="Download PDF">pdf</a>, <a href="/format/2311.14671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SEGIC: Unleashing the Emergent Correspondence for In-Context  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+L">Lingchen Meng</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+S">Shiyi Lan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hengduo Li</a>, 
<a href="/search/cs?searchtype=author&query=Alvarez%2C+J+M">Jose M. Alvarez</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zuxuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yu-Gang Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In-context segmentation aims at segmenting novel images using a few labeled
example images, termed as "in-context examples", exploring content similarities
between examples and the target. The resulting models can be generalized
seamlessly to novel segmentation tasks, significantly reducing the labeling and
training costs compared with conventional pipelines. However, in-context
segmentation is more challenging than classic ones due to its meta-learning
nature, requiring the model to learn segmentation rules conditioned on a few
samples, not just the segmentation. Unlike previous work with ad-hoc or
non-end-to-end designs, we propose SEGIC, an end-to-end segment-in-context
framework built upon a single vision foundation model (VFM). In particular,
SEGIC leverages the emergent correspondence within VFM to capture dense
relationships between target images and in-context samples. As such,
information from in-context samples is then extracted into three types of
instructions, i.e. geometric, visual, and meta instructions, serving as
explicit conditions for the final mask prediction. SEGIC is a straightforward
yet effective approach that yields state-of-the-art performance on one-shot
segmentation benchmarks. Notably, SEGIC can be easily generalized to diverse
tasks, including video object segmentation and open-vocabulary segmentation.
Code will be available at \url{https://github.com/MengLcool/SEGIC}.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Mon, 27 Nov 23</h3>
<dl>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/quant-ph/9712040" title="Abstract">arXiv:quant-ph/9712040</a> (cross-list from quant-ph) [<a href="/pdf/quant-ph/9712040" title="Download PDF">pdf</a>, <a href="/ps/quant-ph/9712040" title="Download PostScript">ps</a>, <a href="/format/quant-ph/9712040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing Local Invariants of Qubit Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Grassl%2C+M">Markus Grassl</a>, 
<a href="/search/quant-ph?searchtype=author&query=Roetteler%2C+M">Martin Roetteler</a>, 
<a href="/search/quant-ph?searchtype=author&query=Beth%2C+T">Thomas Beth</a> (Universitaet Karlsruhe)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, RevTeX, submitted to PRA; example added to demonstrate the application of the invariants
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Phys.Rev.A58:1833-1839,1998
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">We investigate means to describe the non-local properties of quantum systems
and to test if two quantum systems are locally equivalent. For this we consider
quantum systems that consist of several subsystems, especially multiple qubits.
We compute invariant polynomials, i. e., polynomial functions of the entries of
the density operator which are invariant under local unitary operations.
<br />As an example, we consider a system of two qubits. We compute the Molien
series for the corresponding representation which gives information about the
number of linearly independent invariants. Furthermore, we present a set of
polynomials which generate all invariants (at least) up to degree 23. Finally,
the use of invariants to check whether two density operators are locally
equivalent is demonstrated.
</p>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/quant-ph/9807064" title="Abstract">arXiv:quant-ph/9807064</a> (cross-list from quant-ph) [<a href="/pdf/quant-ph/9807064" title="Download PDF">pdf</a>, <a href="/ps/quant-ph/9807064" title="Download PostScript">ps</a>, <a href="/format/quant-ph/9807064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Quantum Fourier Transforms for a Class of Non-abelian Groups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Pueschel%2C+M">Markus Pueschel</a>, 
<a href="/search/quant-ph?searchtype=author&query=Roetteler%2C+M">Martin Roetteler</a>, 
<a href="/search/quant-ph?searchtype=author&query=Beth%2C+T">Thomas Beth</a> (Universitaet Karlsruhe)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, LaTeX2e
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings 13th International Symposium on Applied Algebra,
  Algebraic Algorithms and Error-Correcting Codes (AAECC'99), Honolulu, Hawaii,
  Springer LNCS, pp. 148-159, 1999
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">An algorithm is presented allowing the construction of fast Fourier
transforms for any solvable group on a classical computer. The special
structure of the recursion formula being the core of this algorithm makes it a
good starting point to obtain systematically fast Fourier transforms for
solvable groups on a quantum computer. The inherent structure of the Hilbert
space imposed by the qubit architecture suggests to consider groups of order
2^n first (where n is the number of qubits). As an example, fast quantum
Fourier transforms for all 4 classes of non-abelian 2-groups with cyclic normal
subgroup of index 2 are explicitly constructed in terms of quantum circuits.
The (quantum) complexity of the Fourier transform for these groups of size 2^n
is O(n^2) in all cases.
</p>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/quant-ph/9812070" title="Abstract">arXiv:quant-ph/9812070</a> (cross-list from quant-ph) [<a href="/pdf/quant-ph/9812070" title="Download PDF">pdf</a>, <a href="/ps/quant-ph/9812070" title="Download PostScript">ps</a>, <a href="/format/quant-ph/9812070" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polynomial-Time Solution to the Hidden Subgroup Problem for a Class of  non-abelian Groups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Roetteler%2C+M">Martin Roetteler</a>, 
<a href="/search/quant-ph?searchtype=author&query=Beth%2C+T">Thomas Beth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, LaTeX2e, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">We present a family of non-abelian groups for which the hidden subgroup
problem can be solved efficiently on a quantum computer.
</p>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/quant-ph/0010076" title="Abstract">arXiv:quant-ph/0010076</a> (cross-list from quant-ph) [<a href="/pdf/quant-ph/0010076" title="Download PDF">pdf</a>, <a href="/ps/quant-ph/0010076" title="Download PostScript">ps</a>, <a href="/format/quant-ph/0010076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Stabilizer Codes II: Clifford Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Klappenecker%2C+A">Andreas Klappenecker</a> (Texas A&amp;M University), 
<a href="/search/quant-ph?searchtype=author&query=Roetteler%2C+M">Martin Roetteler</a> (Universitaet Karlsruhe)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, LaTeX2e. Minor changes. Title changed by request of IEEE Trans. IT
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Information Theory, vol. 48, no. 8, pp.
  2396-2399, 2002
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Knill introduced a generalization of stabilizer codes, in this note called
Clifford codes. It remained unclear whether or not Clifford codes can be
superior to stabilizer codes. We show that Clifford codes are stabilizer codes
provided that the abstract error group has an abelian index group. In
particular, if the errors are modelled by tensor products of Pauli matrices,
then the associated Clifford codes are necessarily stabilizer codes.
</p>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/quant-ph/0010082" title="Abstract">arXiv:quant-ph/0010082</a> (cross-list from quant-ph) [<a href="/pdf/quant-ph/0010082" title="Download PDF">pdf</a>, <a href="/ps/quant-ph/0010082" title="Download PostScript">ps</a>, <a href="/format/quant-ph/0010082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Stabilizer Codes I: Nice Error Bases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Klappenecker%2C+A">Andreas Klappenecker</a> (Texas A&amp;M University), 
<a href="/search/quant-ph?searchtype=author&query=Roetteler%2C+M">Martin Roetteler</a> (Universitaet Karlsruhe)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, LaTeX2e. Minor changes. Title changed by request of IEEE Trans. IT
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Information Theory, vol. 48, no. 8, pp.
  2392-2395, 2002
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Nice error bases have been introduced by Knill as a generalization of the
Pauli basis. These bases are shown to be projective representations of finite
groups. We classify all nice error bases of small degree, and all nice error
bases with abelian index groups. We show that in general an index group of a
nice error basis is necessarily solvable.
</p>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/quant-ph/0109063" title="Abstract">arXiv:quant-ph/0109063</a> (cross-list from quant-ph) [<a href="/pdf/quant-ph/0109063" title="Download PDF">pdf</a>, <a href="/ps/quant-ph/0109063" title="Download PostScript">ps</a>, <a href="/format/quant-ph/0109063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Simulation of Hamiltonians Using a Finite Set of Control  Operations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Wocjan%2C+P">Pawel Wocjan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Roetteler%2C+M">Martin Roetteler</a>, 
<a href="/search/quant-ph?searchtype=author&query=Janzing%2C+D">Dominik Janzing</a>, 
<a href="/search/quant-ph?searchtype=author&query=Beth%2C+T">Thomas Beth</a> (Universitaet Karlsruhe)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, LaTeX2e
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Quantum Information &amp; Computation 2(2): 133-150, 2002
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Any quantum system with a non-trivial Hamiltonian is able to simulate any
other Hamiltonian evolution provided that a sufficiently large group of unitary
control operations is available. We show that there exist finite groups with
this property and present a sufficient condition in terms of group characters.
We give examples of such groups in dimension 2 and 3. Furthermore, we show that
it is possible to simulate an arbitrary bipartite interaction by a given one
using such groups acting locally on the subsystems.
</p>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/quant-ph/0109088" title="Abstract">arXiv:quant-ph/0109088</a> (cross-list from quant-ph) [<a href="/pdf/quant-ph/0109088" title="Download PDF">pdf</a>, <a href="/ps/quant-ph/0109088" title="Download PostScript">ps</a>, <a href="/format/quant-ph/0109088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simulating Hamiltonians in Quantum Networks: Efficient Schemes and  Complexity Bounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Wocjan%2C+P">Pawel Wocjan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Roetteler%2C+M">Martin Roetteler</a>, 
<a href="/search/quant-ph?searchtype=author&query=Janzing%2C+D">Dominik Janzing</a>, 
<a href="/search/quant-ph?searchtype=author&query=Beth%2C+T">Thomas Beth</a> (Universitaet Karlsruhe)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, LaTeX2e
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Phys. Rev. A 65, 042309 (2002)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">We address the problem of simulating pair-interaction Hamiltonians in n node
quantum networks where the subsystems have arbitrary, possibly different,
dimensions. We show that any pair-interaction can be used to simulate any other
by applying sequences of appropriate local control sequences. Efficient schemes
for decoupling and time reversal can be constructed from orthogonal arrays.
Conditions on time optimal simulation are formulated in terms of spectral
majorization of matrices characterizing the coupling parameters. Moreover, we
consider a specific system of n harmonic oscillators with bilinear interaction.
In this case, decoupling can efficiently be achieved using the combinatorial
concept of difference schemes. For this type of interactions we present optimal
schemes for inversion.
</p>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/quant-ph/0111038" title="Abstract">arXiv:quant-ph/0111038</a> (cross-list from quant-ph) [<a href="/pdf/quant-ph/0111038" title="Download PDF">pdf</a>, <a href="/ps/quant-ph/0111038" title="Download PostScript">ps</a>, <a href="/format/quant-ph/0111038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discrete Cosine Transforms on Quantum Computers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Klappenecker%2C+A">Andreas Klappenecker</a> (Texas A&amp;M University), 
<a href="/search/quant-ph?searchtype=author&query=Roetteler%2C+M">Martin Roetteler</a> (Universitaet Karlsruhe)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, LaTeX 2e, IEEE ISPA01, Pula, Croatia, 2001
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE R8-EURASIP Symposium on Image and Signal Processing and
  Analysis, pp. 464-468, Pula, Croatia, 2001
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">A classical computer does not allow to calculate a discrete cosine transform
on N points in less than linear time. This trivial lower bound is no longer
valid for a computer that takes advantage of quantum mechanical superposition,
entanglement, and interference principles. In fact, we show that it is possible
to realize the discrete cosine transforms and the discrete sine transforms of
size NxN and types I,II,III, and IV with as little as O(log^2 N) operations on
a quantum computer, whereas the known fast algorithms on a classical computer
need O(N log N) operations.
</p>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/quant-ph/0111039" title="Abstract">arXiv:quant-ph/0111039</a> (cross-list from quant-ph) [<a href="/pdf/quant-ph/0111039" title="Download PDF">pdf</a>, <a href="/ps/quant-ph/0111039" title="Download PostScript">ps</a>, <a href="/format/quant-ph/0111039" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Irresistible Efficiency of Signal Processing Methods in Quantum  Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Klappenecker%2C+A">Andreas Klappenecker</a> (Texas A&amp;M University), 
<a href="/search/quant-ph?searchtype=author&query=Roetteler%2C+M">Martin Roetteler</a> (Universitaet Karlsruhe)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, LaTeX 2e. Expanded version of <a href="/abs/quant-ph/0111038">quant-ph/0111038</a>. SPECLOG 2000, Tampere, Finland
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the First International Workshop on Spectral
  Techniques and Logic Design (SPECLOG 2000), pp. 483-497, 2000
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">We show that many well-known signal transforms allow highly efficient
realizations on a quantum computer. We explain some elementary quantum circuits
and review the construction of the Quantum Fourier Transform. We derive quantum
circuits for the Discrete Cosine and Sine Transforms, and for the Discrete
Hartley transform. We show that at most O(log^2 N) elementary quantum gates are
necessary to implement any of those transforms for input sequences of length N.
</p>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/quant-ph/0208130" title="Abstract">arXiv:quant-ph/0208130</a> (cross-list from quant-ph) [<a href="/pdf/quant-ph/0208130" title="Download PDF">pdf</a>, <a href="/ps/quant-ph/0208130" title="Download PostScript">ps</a>, <a href="/format/quant-ph/0208130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Engineering Functional Quantum Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Klappenecker%2C+A">Andreas Klappenecker</a> (Texas A&amp;M University), 
<a href="/search/quant-ph?searchtype=author&query=Roetteler%2C+M">Martin Roetteler</a> (Universitaet Karlsruhe)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 2 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Physical Review A, 67, 010302, 2003
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Suppose that a quantum circuit with K elementary gates is known for a unitary
matrix U, and assume that U^m is a scalar matrix for some positive integer m.
We show that a function of U can be realized on a quantum computer with at most
O(mK+m^2log m) elementary gates. The functions of U are realized by a generic
quantum circuit, which has a particularly simple structure. Among other
results, we obtain efficient circuits for the fractional Fourier transform.
</p>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/quant-ph/0211014" title="Abstract">arXiv:quant-ph/0211014</a> (cross-list from quant-ph) [<a href="/pdf/quant-ph/0211014" title="Download PDF">pdf</a>, <a href="/ps/quant-ph/0211014" title="Download PostScript">ps</a>, <a href="/format/quant-ph/0211014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Quantum Circuits for Non-Qubit Quantum Error-Correcting Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Grassl%2C+M">Markus Grassl</a> (1,2), 
<a href="/search/quant-ph?searchtype=author&query=Roetteler%2C+M">Martin Roetteler</a> (1), 
<a href="/search/quant-ph?searchtype=author&query=Beth%2C+T">Thomas Beth</a> (1),  (Universitaet Karlsruhe (1), The Mathematical Sciences Research Institute (2))
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, submitted to special issue of IJFCS
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Foundations of Computer Science (IJFCS),
  Vol. 14, No. 5 (2003), pp. 757-775
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">We present two methods for the construction of quantum circuits for quantum
error-correcting codes (QECC). The underlying quantum systems are tensor
products of subsystems (qudits) of equal dimension which is a prime power. For
a QECC encoding k qudits into n qudits, the resulting quantum circuit has
O(n(n-k)) gates. The running time of the classical algorithm to compute the
quantum circuit is O(n(n-k)^2).
</p>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/quant-ph/0301078" title="Abstract">arXiv:quant-ph/0301078</a> (cross-list from quant-ph) [<a href="/pdf/quant-ph/0301078" title="Download PDF">pdf</a>, <a href="/ps/quant-ph/0301078" title="Download PostScript">ps</a>, <a href="/format/quant-ph/0301078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Monomiality of Nice Error Bases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Klappenecker%2C+A">Andreas Klappenecker</a> (Texas A&amp;M University), 
<a href="/search/quant-ph?searchtype=author&query=Roetteler%2C+M">Martin Roetteler</a> (University of Waterloo)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Information Theory, vol. 51, no. 3, pp. 1084
  - 1089, 2005
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Unitary error bases generalize the Pauli matrices to higher dimensional
systems. Two basic constructions of unitary error bases are known: An algebraic
construction by Knill, which yields nice error bases, and a combinatorial
construction by Werner, which yields shift-and-multiply bases. An open problem
posed by Schlingemann and Werner (see
<a href="http://www.imaph.tu-bs.de/qi/problems/6.html">this http URL</a>) relates these two constructions
and asks whether each nice error basis is equivalent to a shift-and-multiply
basis. We solve this problem and show that the answer is negative. However, we
also show that it is always possible to find a fairly sparse representation of
a nice error basis.
</p>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/quant-ph/0303091" title="Abstract">arXiv:quant-ph/0303091</a> (cross-list from quant-ph) [<a href="/pdf/quant-ph/0303091" title="Download PDF">pdf</a>, <a href="/ps/quant-ph/0303091" title="Download PostScript">ps</a>, <a href="/format/quant-ph/0303091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comment on &quot;Probabilistic Quantum Memories&quot;
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Brun%2C+T">T.Brun</a>, 
<a href="/search/quant-ph?searchtype=author&query=Klauck%2C+H">H.Klauck</a>, 
<a href="/search/quant-ph?searchtype=author&query=Nayak%2C+A">A.Nayak</a>, 
<a href="/search/quant-ph?searchtype=author&query=Roetteler%2C+M">M.Roetteler</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zalka%2C+C">Ch.Zalka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> REVTeX4, 1 page, published version
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Phys. Rev. Lett. 91 209801 (2003)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">This is a comment on two wrong Phys. Rev. Letters papers by C.A.
Trugenberger. Trugenberger claimed that quantum registers could be used as
exponentially large "associative" memories. We show that his scheme is no
better than one where the quantum register is replaced with a classical one of
equal size.
<br />We also point out that the Holevo bound and more recent bounds on "quantum
random access codes" pretty much rule out powerful memories (for classical
information) based on quantum states.
</p>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/quant-ph/0309120" title="Abstract">arXiv:quant-ph/0309120</a> (cross-list from quant-ph) [<a href="/pdf/quant-ph/0309120" title="Download PDF">pdf</a>, <a href="/ps/quant-ph/0309120" title="Download PostScript">ps</a>, <a href="/format/quant-ph/0309120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constructions of Mutually Unbiased Bases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Klappenecker%2C+A">Andreas Klappenecker</a> (Texas A&amp;M University), 
<a href="/search/quant-ph?searchtype=author&query=Roetteler%2C+M">Martin Roetteler</a> (University of Waterloo)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages latex
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 7th International Conference on Finite Fields
  (Fq7), Toulouse, France, Springer LNCS, pp. 137-144, 2004
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Two orthonormal bases B and B' of a d-dimensional complex inner-product space
are called mutually unbiased if and only if |&lt;b|b'&gt;|^2=1/d holds for all b in B
and b' in B'. The size of any set containing (pairwise) mutually unbiased bases
of C^d cannot exceed d+1. If d is a power of a prime, then extremal sets
containing d+1 mutually unbiased bases are known to exist. We give a simplified
proof of this fact based on the estimation of exponential sums. We discuss
conjectures and open problems concerning the maximal number of mutually
unbiased bases for arbitrary dimensions.
</p>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/quant-ph/0309121" title="Abstract">arXiv:quant-ph/0309121</a> (cross-list from quant-ph) [<a href="/pdf/quant-ph/0309121" title="Download PDF">pdf</a>, <a href="/ps/quant-ph/0309121" title="Download PostScript">ps</a>, <a href="/format/quant-ph/0309121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Software Reusability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Klappenecker%2C+A">Andreas Klappenecker</a> (Texas A&amp;M University), 
<a href="/search/quant-ph?searchtype=author&query=Roetteler%2C+M">Martin Roetteler</a> (University of Waterloo)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages latex, 11 postscript figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal on Foundations of Computer Science, 14(5),
  pages 777-796, 2003
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">The design of efficient quantum circuits is an important issue in quantum
computing. It is in general a formidable task to find a highly optimized
quantum circuit for a given unitary matrix. We propose a quantum circuit design
method that has the following unique feature: It allows to construct efficient
quantum circuits in a systematic way by reusing and combining a set of highly
optimized quantum circuits. Specifically, the method realizes a quantum circuit
for a given unitary matrix by implementing a linear combination of representing
matrices of a group, which have known fast quantum circuits. We motivate and
illustrate this method by deriving extremely efficient quantum circuits for the
discrete Hartley transform and for the fractional Fourier transforms. The sound
mathematical basis of this design method allows to give meaningful and natural
interpretations of the resulting circuits. We demonstrate this aspect by giving
a natural interpretation of known teleportation circuits.
</p>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/quant-ph/0312164" title="Abstract">arXiv:quant-ph/0312164</a> (cross-list from quant-ph) [<a href="/pdf/quant-ph/0312164" title="Download PDF">pdf</a>, <a href="/ps/quant-ph/0312164" title="Download PostScript">ps</a>, <a href="/format/quant-ph/0312164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On optimal quantum codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Grassl%2C+M">Markus Grassl</a> (Universitaet Karlsruhe), , 
<a href="/search/quant-ph?searchtype=author&query=Beth%2C+T">Thomas Beth</a> (Universitaet Karlsruhe), 
<a href="/search/quant-ph?searchtype=author&query=Roetteler%2C+M">Martin Roetteler</a> (University of Waterloo)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in the International Journal of Quantum Information
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Quantum Information, Vol. 2, No. 1
  (2004), pp. 55-64
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">We present families of quantum error-correcting codes which are optimal in
the sense that the minimum distance is maximal. These maximum distance
separable (MDS) codes are defined over q-dimensional quantum systems, where q
is an arbitrary prime power. It is shown that codes with parameters
[[n,n-2d+2,d]]_q exist for all 3 &lt;= n &lt;= q and 1 &lt;= d &lt;= n/2+1. We also present
quantum MDS codes with parameters [[q^2,q^2-2d+2,d]]_q for 1 &lt;= d &lt;= q which
additionally give rise to shortened codes [[q^2-s,q^2-2d+2-s,d]]_q for some s.
</p>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/quant-ph/0312228" title="Abstract">arXiv:quant-ph/0312228</a> (cross-list from quant-ph) [<a href="/pdf/quant-ph/0312228" title="Download PDF">pdf</a>, <a href="/ps/quant-ph/0312228" title="Download PostScript">ps</a>, <a href="/format/quant-ph/0312228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Remarks on Clifford codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Klappenecker%2C+A">Andreas Klappenecker</a> (Texas A&amp;M University), 
<a href="/search/quant-ph?searchtype=author&query=Roetteler%2C+M">Martin Roetteler</a> (University of Waterloo)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages; submitted to Quantum Information and Computation
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings 2004 IEEE International Symposium on Information
  Theory (ISIT 2004), Chicago, USA, pp. 354, 2004
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Clifford codes are a class of quantum error control codes that form a natural
generalization of stabilizer codes. These codes were introduced in 1996 by
Knill, but only a single Clifford code was known, which is not already a
stabilizer code. We derive a necessary and sufficient condition that allows to
decide when a Clifford code is a stabilizer code, and compile a table of all
true Clifford codes for error groups of small order.
</p>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/quant-ph/0407054" title="Abstract">arXiv:quant-ph/0407054</a> (cross-list from quant-ph) [<a href="/pdf/quant-ph/0407054" title="Download PDF">pdf</a>, <a href="/ps/quant-ph/0407054" title="Download PostScript">ps</a>, <a href="/format/quant-ph/0407054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implementation of group-covariant POVMs by orthogonal measurements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Decker%2C+T">Thomas Decker</a>, 
<a href="/search/quant-ph?searchtype=author&query=Janzing%2C+D">Dominik Janzing</a>, 
<a href="/search/quant-ph?searchtype=author&query=Roetteler%2C+M">Martin Roetteler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> latex, 25 pages, 3 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Mathematical Physics, 46:012104, 2005
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">We consider group-covariant positive operator valued measures (POVMs) on a
finite dimensional quantum system. Following Neumark's theorem a POVM can be
implemented by an orthogonal measurement on a larger system. Accordingly, our
goal is to find an implementation of a given group-covariant POVM by a quantum
circuit using its symmetry. Based on representation theory of the symmetry
group we develop a general approach for the implementation of group-covariant
POVMs which consist of rank-one operators. The construction relies on a method
to decompose matrices that intertwine two representations of a finite group. We
give several examples for which the resulting quantum circuits are efficient.
In particular, we obtain efficient quantum circuits for a class of POVMs
generated by Weyl-Heisenberg groups. These circuits allow to implement an
approximative simultaneous measurement of the position and crystal momentum of
a particle moving on a cyclic chain.
</p>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/quant-ph/0408078" title="Abstract">arXiv:quant-ph/0408078</a> (cross-list from quant-ph) [<a href="/pdf/quant-ph/0408078" title="Download PDF">pdf</a>, <a href="/ps/quant-ph/0408078" title="Download PostScript">ps</a>, <a href="/format/quant-ph/0408078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Decoupling Schemes Based on Hamilton Cycles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Roetteler%2C+M">Martin Roetteler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 1 figure, uses revtex 4
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Mathematical Physics, 49:042106, 2008
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Decoupling the interactions in a spin network governed by a pair-interaction
Hamiltonian is a well-studied problem. Combinatorial schemes for decoupling and
for manipulating the couplings of Hamiltonians have been developed which use
selective pulses. In this paper we consider an additional requirement on these
pulse sequences: as few {\em different} control operations as possible should
be used. This requirement is motivated by the fact that optimizing each
individual selective pulse will be expensive, i. e., it is desirable to use as
few different selective pulses as possible. For an arbitrary $d$-dimensional
system we show that the ability to implement only two control operations is
sufficient to turn off the time evolution. In case of a bipartite system with
local control we show that four different control operations are sufficient.
Turning to networks consisting of several $d$-dimensional nodes which are
governed by a pair-interaction Hamiltonian, we show that decoupling can be
achieved if one is able to control a number of different control operations
which is logarithmic in the number of nodes.
</p>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/quant-ph/0409135" title="Abstract">arXiv:quant-ph/0409135</a> (cross-list from quant-ph) [<a href="/pdf/quant-ph/0409135" title="Download PDF">pdf</a>, <a href="/ps/quant-ph/0409135" title="Download PostScript">ps</a>, <a href="/format/quant-ph/0409135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Equivalence of Decoupling Schemes and Orthogonal Arrays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Roetteler%2C+M">Martin Roetteler</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wocjan%2C+P">Pawel Wocjan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, latex, 1 figure in text
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Information Theory 52(9): 4171-4181 (2006)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">We consider the problem of switching off unwanted interactions in a given
multi-partite Hamiltonian. This is known to be an important primitive in
quantum information processing and several schemes have been presented in the
literature to achieve this task. A method to construct decoupling schemes for
quantum systems of pairwise interacting qubits was introduced by M.
Stollsteimer and G. Mahler and is based on orthogonal arrays. Another approach
based on triples of Hadamard matrices that are closed under pointwise
multiplication was proposed by D. Leung. In this paper, we show that both
methods lead to the same class of decoupling schemes. Moreover, we establish a
characterization of orthogonal arrays by showing that they are equivalent to
decoupling schemes which allow a refinement into equidistant time-slots.
Furthermore, we show that decoupling schemes for networks of higher-dimensional
quantum systems with t-local Hamiltonians can be constructed from classical
error-correcting codes.
</p>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/quant-ph/0502031" title="Abstract">arXiv:quant-ph/0502031</a> (cross-list from quant-ph) [<a href="/pdf/quant-ph/0502031" title="Download PDF">pdf</a>, <a href="/ps/quant-ph/0502031" title="Download PostScript">ps</a>, <a href="/format/quant-ph/0502031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mutually Unbiased Bases are Complex Projective 2-Designs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Klappenecker%2C+A">Andreas Klappenecker</a> (Texas A&amp;M University), 
<a href="/search/quant-ph?searchtype=author&query=Roetteler%2C+M">Martin Roetteler</a> (NEC Laboratories America, Inc.)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages; minor corrections, two remarks on previous work added, submitted to 2005 IEEE International Symposium on Information Theory
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings 2005 IEEE International Symposium on Information
  Theory (ISIT 2005), Adelaide, Australia, pp. 1740-1744, 2005
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Mutually unbiased bases (MUBs) are a primitive used in quantum information
processing to capture the principle of complementarity. While constructions of
maximal sets of d+1 such bases are known for systems of prime power dimension
d, it is unknown whether this bound can be achieved for any non-prime power
dimension. In this paper we demonstrate that maximal sets of MUBs come with a
rich combinatorial structure by showing that they actually are the same objects
as the complex projective 2-designs with angle set {0,1/d}. We also give a new
and simple proof that symmetric informationally complete POVMs are complex
projective 2-designs with angle set {1/(d+1)}.
</p>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/quant-ph/0502101" title="Abstract">arXiv:quant-ph/0502101</a> (cross-list from quant-ph) [<a href="/pdf/quant-ph/0502101" title="Download PDF">pdf</a>, <a href="/ps/quant-ph/0502101" title="Download PostScript">ps</a>, <a href="/format/quant-ph/0502101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Thresholds for Linear Optics Quantum Computing with Photon Loss at the  Detectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Silva%2C+M">Marcus Silva</a>, 
<a href="/search/quant-ph?searchtype=author&query=Roetteler%2C+M">Martin Roetteler</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zalka%2C+C">Christof Zalka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Phys. Rev. A 72, 032307 (2005)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">We calculate the error threshold for the linear optics quantum computing
proposal by Knill, Laflamme and Milburn [Nature 409, pp. 46--52 (2001)] under
an error model where photon detectors have efficiency &lt;100% but all other
components -- such as single photon sources, beam splitters and phase shifters
-- are perfect and introduce no errors. We make use of the fact that the error
model induced by the lossy hardware is that of an erasure channel, i.e., the
error locations are always known. Using a method based on a Markov chain
description of the error correction procedure, our calculations show that, with
the 7 qubit CSS quantum code, the gate error threshold for fault tolerant
quantum computation is bounded below by a value between 1.78% and 11.5%
depending on the construction of the entangling gates.
</p>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/quant-ph/0502138" title="Abstract">arXiv:quant-ph/0502138</a> (cross-list from quant-ph) [<a href="/pdf/quant-ph/0502138" title="Download PDF">pdf</a>, <a href="/ps/quant-ph/0502138" title="Download PostScript">ps</a>, <a href="/format/quant-ph/0502138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Tales of the Mean King
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Klappenecker%2C+A">Andreas Klappenecker</a> (Texas A&amp;M University), 
<a href="/search/quant-ph?searchtype=author&query=Roetteler%2C+M">Martin Roetteler</a> (NEC Laboratories America, Inc.)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 1 figure, uses yfonts
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">The Mean King's problem asks to determine the outcome of a measurement that
is randomly selected from a set of complementary observables. We review this
problem and offer a combinatorial solution. More generally, we show that
whenever an affine resolvable design exists, then a state reconstruction
problem similar to the Mean King's problem can be defined and solved. As an
application of this general framework we consider a problem involving three
qubits in which the outcome of nine different measurements can be determined
without using ancillary qubits. The solution is based on a measurement derived
from Hadamard designs.
</p>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/quant-ph/0503114" title="Abstract">arXiv:quant-ph/0503114</a> (cross-list from quant-ph) [<a href="/pdf/quant-ph/0503114" title="Download PDF">pdf</a>, <a href="/ps/quant-ph/0503114" title="Download PostScript">ps</a>, <a href="/format/quant-ph/0503114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Power of Random Bases in Fourier Sampling: Hidden Subgroup  Problem in the Heisenberg Group
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Radhakrishnan%2C+J">Jaikumar Radhakrishnan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Roetteler%2C+M">Martin Roetteler</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sen%2C+P">Pranab Sen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, LaTeX
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings 32nd International Conference on Automata, Languages,
  and Programming (ICALP 2005), Lisbon, Portugal, Springer LNCS, pp. 1399-1411,
  2005
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">The hidden subgroup problem (HSP) provides a unified framework to study
problems of group-theoretical nature in quantum computing such as order finding
and the discrete logarithm problem. While it is known that Fourier sampling
provides an efficient solution in the abelian case, not much is known for
general non-abelian groups. Recently, some authors raised the question as to
whether post-processing the Fourier spectrum by measuring in a random
orthonormal basis helps for solving the HSP. Several negative results on the
shortcomings of this random strong method are known. In this paper however, we
show that the random strong method can be quite powerful under certain
conditions on the group G. We define a parameter r(G) for a group G and show
that O((\log |G| / r(G))^2) iterations of the random strong method give enough
classical information to identify a hidden subgroup in G. We illustrate the
power of the random strong method via a concrete example of the HSP over finite
Heisenberg groups. We show that r(G) = \Omega(1) for these groups; hence the
HSP can be solved using polynomially many random strong Fourier samplings
followed by a possibly exponential classical post-processing without further
queries. The quantum part of our algorithm consists of a polynomial computation
followed by measuring in a random orthonormal basis. This gives the first
example of a group where random representation bases do help in solving the HSP
and for which no explicit representation bases are known that solve the problem
with (\log G)^O(1) Fourier samplings. As an interesting by-product of our work,
we get an algorithm for solving the state identification problem for a set of
nearly orthogonal pure quantum states.
</p>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/quant-ph/0503239" title="Abstract">arXiv:quant-ph/0503239</a> (cross-list from quant-ph) [<a href="/pdf/quant-ph/0503239" title="Download PDF">pdf</a>, <a href="/ps/quant-ph/0503239" title="Download PostScript">ps</a>, <a href="/format/quant-ph/0503239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Approximately Symmetric Informationally Complete Positive  Operator-Valued Measures and Related Systems of Quantum States
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Klappenecker%2C+A">Andreas Klappenecker</a>, 
<a href="/search/quant-ph?searchtype=author&query=Roetteler%2C+M">Martin Roetteler</a>, 
<a href="/search/quant-ph?searchtype=author&query=Shparlinski%2C+I">Igor Shparlinski</a>, 
<a href="/search/quant-ph?searchtype=author&query=Winterhof%2C+A">Arne Winterhof</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, LaTeX
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Mathematical Physics, 46:082104, 2005
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">We address the problem of constructing positive operator-valued measures
(POVMs) in finite dimension $n$ consisting of $n^2$ operators of rank one which
have an inner product close to uniform. This is motivated by the related
question of constructing symmetric informationally complete POVMs (SIC-POVMs)
for which the inner products are perfectly uniform. However, SIC-POVMs are
notoriously hard to construct and despite some success of constructing them
numerically, there is no analytic construction known. We present two
constructions of approximate versions of SIC-POVMs, where a small deviation
from uniformity of the inner products is allowed. The first construction is
based on selecting vectors from a maximal collection of mutually unbiased bases
and works whenever the dimension of the system is a prime power. The second
construction is based on perturbing the matrix elements of a subset of mutually
unbiased bases.
<br />Moreover, we construct vector systems in $\C^n$ which are almost orthogonal
and which might turn out to be useful for quantum computation. Our
constructions are based on results of analytic number theory.
</p>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/quant-ph/0511148" title="Abstract">arXiv:quant-ph/0511148</a> (cross-list from quant-ph) [<a href="/pdf/quant-ph/0511148" title="Download PDF">pdf</a>, <a href="/ps/quant-ph/0511148" title="Download PostScript">ps</a>, <a href="/format/quant-ph/0511148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Limitations of Quantum Coset States for Graph Isomorphism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Hallgren%2C+S">Sean Hallgren</a>, 
<a href="/search/quant-ph?searchtype=author&query=Roetteler%2C+M">Martin Roetteler</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sen%2C+P">Pranab Sen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> J. ACM 57(6): 34 (2010)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">It has been known for some time that graph isomorphism reduces to the hidden
subgroup problem (HSP). What is more, most exponential speedups in quantum
computation are obtained by solving instances of the HSP. A common feature of
the resulting algorithms is the use of quantum coset states, which encode the
hidden subgroup. An open question has been how hard it is to use these states
to solve graph isomorphism. It was recently shown by Moore, Russell, and
Schulman that only an exponentially small amount of information is available
from one, or a pair of coset states. A potential source of power to exploit are
entangled quantum measurements that act jointly on many states at once. We show
that entangled quantum measurements on at least \Omega(n log n) coset states
are necessary to get useful information for the case of graph isomorphism,
matching an information theoretic upper bound. This may be viewed as a negative
result because highly entangled measurements seem hard to implement in general.
Our main theorem is very general and also rules out using joint measurements on
few coset states for some other groups, such as GL(n, F_{p^m}) and G^n where G
is finite and satisfies a suitable property.
</p>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1805.03682" title="Abstract">arXiv:1805.03682</a> (cross-list from math.OC) [<a href="/pdf/1805.03682" title="Download PDF">pdf</a>, <a href="/format/1805.03682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust-to-Dynamics Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ahmadi%2C+A+A">Amir Ali Ahmadi</a>, 
<a href="/search/math?searchtype=author&query=Gunluk%2C+O">Oktay Gunluk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Major revision
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Data Structures and Algorithms (cs.DS); Systems and Control (eess.SY); Dynamical Systems (math.DS)

</div>
<p class="mathjax">A robust-to-dynamics optimization (RDO) problem is an optimization problem
specified by two pieces of input: (i) a mathematical program (an objective
function $f:\mathbb{R}^n\rightarrow\mathbb{R}$ and a feasible set
$\Omega\subseteq\mathbb{R}^n$), and (ii) a dynamical system (a map
$g:\mathbb{R}^n\rightarrow\mathbb{R}^n$). Its goal is to minimize $f$ over the
set $\mathcal{S}\subseteq\Omega$ of initial conditions that forever remain in
$\Omega$ under $g$. The focus of this paper is on the case where the
mathematical program is a linear program and the dynamical system is either a
known linear map, or an uncertain linear map that can change over time. In both
cases, we study a converging sequence of polyhedral outer approximations and
(lifted) spectrahedral inner approximations to $\mathcal{S}$. Our inner
approximations are optimized with respect to the objective function $f$ and
their semidefinite characterization -- which has a semidefinite constraint of
fixed size -- is obtained by applying polar duality to convex sets that are
invariant under (multiple) linear maps. We characterize three barriers that can
stop convergence of the outer approximations from being finite. We prove that
once these barriers are removed, our inner and outer approximating procedures
find an optimal solution and a certificate of optimality for the RDO problem in
a finite number of steps. Moreover, in the case where the dynamics are linear,
we show that this phenomenon occurs in a number of steps that can be computed
in time polynomial in the bit size of the input data. Our analysis also leads
to a polynomial-time algorithm for RDO instances where the spectral radius of
the linear map is bounded above by any constant less than one. Finally, in our
concluding section, we propose a broader research agenda for studying
optimization problems with dynamical systems constraints, of which RDO is a
special case.
</p>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2007.14460" title="Abstract">arXiv:2007.14460</a> (cross-list from quant-ph) [<a href="/pdf/2007.14460" title="Download PDF">pdf</a>, <a href="/format/2007.14460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum computing enhanced computational catalysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=von+Burg%2C+V">Vera von Burg</a>, 
<a href="/search/quant-ph?searchtype=author&query=Low%2C+G+H">Guang Hao Low</a>, 
<a href="/search/quant-ph?searchtype=author&query=H%C3%A4ner%2C+T">Thomas H&#xe4;ner</a>, 
<a href="/search/quant-ph?searchtype=author&query=Steiger%2C+D+S">Damian S. Steiger</a>, 
<a href="/search/quant-ph?searchtype=author&query=Reiher%2C+M">Markus Reiher</a>, 
<a href="/search/quant-ph?searchtype=author&query=Roetteler%2C+M">Martin Roetteler</a>, 
<a href="/search/quant-ph?searchtype=author&query=Troyer%2C+M">Matthias Troyer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Main text: 19 pages, 6 figures. Supplement: 82 pages, 8 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Phys. Rev. Research 3, 033055 (2021)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET); Chemical Physics (physics.chem-ph)

</div>
<p class="mathjax">The quantum computation of electronic energies can break the curse of
dimensionality that plagues many-particle quantum mechanics. It is for this
reason that a universal quantum computer has the potential to fundamentally
change computational chemistry and materials science, areas in which strong
electron correlations present severe hurdles for traditional electronic
structure methods. Here, we present a state-of-the-art analysis of accurate
energy measurements on a quantum computer for computational catalysis, using
improved quantum algorithms with more than an order of magnitude improvement
over the best previous algorithms. As a prototypical example of local catalytic
chemical reactivity we consider the case of a ruthenium catalyst that can bind,
activate, and transform carbon dioxide to the high-value chemical methanol. We
aim at accurate resource estimates for the quantum computing steps required for
assessing the electronic energy of key intermediates and transition states of
its catalytic cycle. In particular, we present new quantum algorithms for
double-factorized representations of the four-index integrals that can
significantly reduce the computational cost over previous algorithms, and we
discuss the challenges of increasing active space sizes to accurately deal with
dynamical correlations. We address the requirements for future quantum hardware
in order to make a universal quantum computer a successful and reliable tool
for quantum computing enhanced computational materials science and chemistry,
and identify open questions for further research.
</p>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.04444" title="Abstract">arXiv:2208.04444</a> (cross-list from quant-ph) [<a href="/pdf/2208.04444" title="Download PDF">pdf</a>, <a href="/format/2208.04444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Periodic Plane-Wave Electronic Structure Calculations on Quantum  Computers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Song%2C+D">Duo Song</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bauman%2C+N+P">Nicholas P. Bauman</a>, 
<a href="/search/quant-ph?searchtype=author&query=Prawiroatmodjo%2C+G">Guen Prawiroatmodjo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Peng%2C+B">Bo Peng</a>, 
<a href="/search/quant-ph?searchtype=author&query=Granade%2C+C">Cassandra Granade</a>, 
<a href="/search/quant-ph?searchtype=author&query=Rosso%2C+K+M">Kevin M. Rosso</a>, 
<a href="/search/quant-ph?searchtype=author&query=Low%2C+G+H">Guang Hao Low</a>, 
<a href="/search/quant-ph?searchtype=author&query=Roetteler%2C+M">Martin Roetteler</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kowalski%2C+K">Karol Kowalski</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bylaska%2C+E+J">Eric J. Bylaska</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2009.00080">arXiv:2009.00080</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">A procedure for defining virtual spaces, and the periodic one-electron and
two-electron integrals, for plane-wave second quantized Hamiltonians has been
developed and demonstrated using full configuration interaction (FCI)
simulations and variational quantum eigensolver (VQE) circuits on Quantinuum's
ion trap quantum computers accessed through Microsoft's Azure Quantum service.
This work is an extension to periodic systems of a new class of algorithms in
which the virtual spaces were generated by optimizing orbitals from small
pairwise CI Hamiltonians, which we term as correlation optimized virtual
orbitals with the abbreviation COVOs. In this extension, the integration of the
first Brillouin zone is automatically incorporated into the two-electron
integrals. With these procedures we have been able to derive virtual spaces,
containing only a few orbitals, that were able to capture a significant amount
of correlation. The focus in this manuscript is on comparing the simulations of
small molecules calculated with plane-wave basis sets with large periodic unit
cells at the $\Gamma$-point, including images, to results for plane-wave basis
sets with aperiodic unit cells. The results for this approach were promising as
we were able to obtain good agreement between periodic and aperiodic results
for an LiH molecule. Simulations performed on the Quantinuum H1-1 quantum
computer were able to produce surprisingly good energies, reproducing the FCI
values for the 1 COVO Hamiltonian to within 11 milliHartree (6.9 kcal/mol),
when corrected for noise.
</p>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.03680" title="Abstract">arXiv:2210.03680</a> (cross-list from quant-ph) [<a href="/pdf/2210.03680" title="Download PDF">pdf</a>, <a href="/format/2210.03680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QParallel: Explicit Parallelism for Programming Quantum Computers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=H%C3%A4ner%2C+T">Thomas H&#xe4;ner</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kliuchnikov%2C+V">Vadym Kliuchnikov</a>, 
<a href="/search/quant-ph?searchtype=author&query=Roetteler%2C+M">Martin Roetteler</a>, 
<a href="/search/quant-ph?searchtype=author&query=Soeken%2C+M">Mathias Soeken</a>, 
<a href="/search/quant-ph?searchtype=author&query=Vaschillo%2C+A">Alexander Vaschillo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">We present a language extension for parallel quantum programming to (1)
remove ambiguities concerning parallelism in current quantum programming
languages and (2) facilitate space-time tradeoff investigations in quantum
computing. While the focus of similar libraries in the domain of classical
computing (OpenMP, OpenACC, etc.) is to divide a computation into multiple
threads, the main goal of QParallel is to keep the compiler and the runtime
system from introducing parallelism-inhibiting dependencies, e.g., through
reuse of qubits in automatic qubit management. We describe the syntax and
semantics of the proposed language extension, implement a prototype based on
Q#, and present several examples and use cases to illustrate its performance
benefits. Moreover, we introduce a tool that guides programmers in the
placement of parallel regions by identifying the subroutines that profit most
from parallelization, which is especially useful if the programmer's knowledge
of the source code is limited. Support for QParallel can be added to any
multithreading library and language extension, including OpenMP and OpenACC.
</p>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.01133" title="Abstract">arXiv:2211.01133</a> (cross-list from quant-ph) [<a href="/pdf/2211.01133" title="Download PDF">pdf</a>, <a href="/format/2211.01133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Space-time optimized table lookup
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=H%C3%A4ner%2C+T">Thomas H&#xe4;ner</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kliuchnikov%2C+V">Vadym Kliuchnikov</a>, 
<a href="/search/quant-ph?searchtype=author&query=Roetteler%2C+M">Martin Roetteler</a>, 
<a href="/search/quant-ph?searchtype=author&query=Soeken%2C+M">Mathias Soeken</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">We describe a space-time optimized circuit for the table lookup subroutine
from lattice-surgery surface code primitives respecting 2D grid connectivity.
Table lookup circuits are ubiquitous in quantum computing, allowing the
presented circuit to be used for applications ranging from cryptography to
quantum chemistry. Surface code is the leading approach to scalable
fault-tolerant quantum computing pursued by industry and academia. We abstract
away surface code implementation details by using a minimal set of operations
supported by the surface code via lattice-surgery. Our exposition is accessible
to a reader not familiar with surface codes and fault-tolerant quantum
computing.
</p>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06580" title="Abstract">arXiv:2307.06580</a> (cross-list from quant-ph) [<a href="/pdf/2307.06580" title="Download PDF">pdf</a>, <a href="/format/2307.06580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Simulation of Boson-Related Hamiltonians: Techniques, Effective  Hamiltonian Construction, and Error Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Peng%2C+B">Bo Peng</a>, 
<a href="/search/quant-ph?searchtype=author&query=Su%2C+Y">Yuan Su</a>, 
<a href="/search/quant-ph?searchtype=author&query=Claudino%2C+D">Daniel Claudino</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kowalski%2C+K">Karol Kowalski</a>, 
<a href="/search/quant-ph?searchtype=author&query=Low%2C+G+H">Guang Hao Low</a>, 
<a href="/search/quant-ph?searchtype=author&query=Roetteler%2C+M">Martin Roetteler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Elementary quantum mechanics proposes that a closed physical system
consistently evolves in a reversible manner. However, control and readout
necessitate the coupling of the quantum system to the external environment,
subjecting it to relaxation and decoherence. Consequently, system-environment
interactions are indispensable for simulating physically significant theories.
A broad spectrum of physical systems in condensed-matter and high-energy
physics, vibrational spectroscopy, and circuit and cavity QED necessitates the
incorporation of bosonic degrees of freedom, such as phonons, photons, and
gluons, into optimized fermion algorithms for near-future quantum simulations.
In particular, when a quantum system is surrounded by an external environment,
its basic physics can usually be simplified to a spin or fermionic system
interacting with bosonic modes. Nevertheless, troublesome factors such as the
magnitude of the bosonic degrees of freedom typically complicate the direct
quantum simulation of these interacting models, necessitating the consideration
of a comprehensive plan. This strategy should specifically include a suitable
fermion/boson-to-qubit mapping scheme to encode sufficiently large yet
manageable bosonic modes, and a method for truncating and/or downfolding the
Hamiltonian to the defined subspace for performing an approximate but highly
accurate simulation, guided by rigorous error analysis. In this paper, we aim
to provide such an exhaustive strategy. Specifically, we emphasize two aspects:
(1) the discussion of recently developed quantum algorithms for these
interacting models and the construction of effective Hamiltonians, and (2) a
detailed analysis regarding a tightened error bound for truncating the bosonic
modes for a class of fermion-boson interacting Hamiltonians.
</p>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13060" title="Abstract">arXiv:2311.13060</a> (cross-list from hep-ex) [<a href="/pdf/2311.13060" title="Download PDF">pdf</a>, <a href="/format/2311.13060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training Deep 3D Convolutional Neural Networks to Extract BSM Physics  Parameters Directly from HEP Data: a Proof-of-Concept Study Using Monte Carlo  Simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ex?searchtype=author&query=Dubey%2C+S">S. Dubey</a>, 
<a href="/search/hep-ex?searchtype=author&query=Browder%2C+T+E">T.E. Browder</a>, 
<a href="/search/hep-ex?searchtype=author&query=Kohani%2C+S">S.Kohani</a>, 
<a href="/search/hep-ex?searchtype=author&query=Mandal%2C+R">R. Mandal</a>, 
<a href="/search/hep-ex?searchtype=author&query=Sibidanov%2C+A">A. Sibidanov</a>, 
<a href="/search/hep-ex?searchtype=author&query=Sinha%2C+R">R. Sinha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Experiment (hep-ex)</span>; Machine Learning (cs.LG); High Energy Physics - Phenomenology (hep-ph)

</div>
<p class="mathjax">We report on a novel application of computer vision techniques to extract
beyond the Standard Model (BSM) parameters directly from high energy physics
(HEP) flavor data. We develop a method of transforming angular and kinematic
distributions into "quasi-images" that can be used to train a convolutional
neural network to perform regression tasks, similar to fitting. This contrasts
with the usual classification functions performed using ML/AI in HEP. As a
proof-of-concept, we train a 34-layer Residual Neural Network to regress on
these images and determine the Wilson Coefficient $C_{9}$ in MC (Monte Carlo)
simulations of $B \rightarrow K^{*}\mu^{+}\mu^{-}$ decays. The technique
described here can be generalized and may find applicability across various HEP
experiments and elsewhere.
</p>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13616" title="Abstract">arXiv:2311.13616</a> (cross-list from eess.IV) [<a href="/pdf/2311.13616" title="Download PDF">pdf</a>, <a href="/format/2311.13616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Video Quality Enhancement with Spatial-Temporal Look-up Tables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Qu%2C+Z">Zefan Qu</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+X">Xinyang Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+Y">Yifan Yang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+D">Dongsheng Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+C">Cairong Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Low latency rates are crucial for online video-based applications, such as
video conferencing and cloud gaming, which make improving video quality in
online scenarios increasingly important. However, existing quality enhancement
methods are limited by slow inference speed and the requirement for temporal
information contained in future frames, making it challenging to deploy them
directly in online tasks. In this paper, we propose a novel method, STLVQE,
specifically designed to address the rarely studied online video quality
enhancement (Online-VQE) problem. Our STLVQE designs a new VQE framework which
contains a Module-Agnostic Feature Extractor that greatly reduces the redundant
computations and redesign the propagation, alignment, and enhancement module of
the network. A Spatial-Temporal Look-up Tables (STL) is proposed, which
extracts spatial-temporal information in videos while saving substantial
inference time. To the best of our knowledge, we are the first to exploit the
LUT structure to extract temporal information in video tasks. Extensive
experiments on the MFQE 2.0 dataset demonstrate that our STLVQE achieves a
satisfactory performance-speed trade-off.
</p>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13626" title="Abstract">arXiv:2311.13626</a> (cross-list from eess.IV) [<a href="/pdf/2311.13626" title="Download PDF">pdf</a>, <a href="/format/2311.13626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-driven generative adversarial networks empower single-pixel  infrared hyperspectral imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+D">Dong-Yin Wang</a>, 
<a href="/search/eess?searchtype=author&query=Bie%2C+S">Shu-Hang Bie</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+X">Xi-Hao Chen</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+W">Wen-Kai Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Optics (physics.optics)

</div>
<p class="mathjax">A physics-driven generative adversarial network (GAN) was established here
for single-pixel hyperspectral imaging (HSI) in the infrared spectrum, to
eliminate the extensive data training work required by traditional data-driven
model. Within the GAN framework, the physical process of single-pixel imaging
(SPI) was integrated into the generator, and the actual and estimated
one-dimensional (1D) bucket signals were employed as constraints in the
objective function to update the network's parameters and optimize the
generator with the assistance of the discriminator. In comparison to
single-pixel infrared HSI methods based on compressed sensing and
physics-driven convolution neural networks, our physics-driven GAN-based
single-pixel infrared HSI can achieve higher imaging performance but with fewer
measurements. We believe that this physics-driven GAN will promote practical
applications of computational imaging, especially various SPI-based techniques.
</p>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13654" title="Abstract">arXiv:2311.13654</a> (cross-list from quant-ph) [<a href="/pdf/2311.13654" title="Download PDF">pdf</a>, <a href="/format/2311.13654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Quantum Computation via Superposed Orders of Single-Qubit  Gates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Simonov%2C+K">Kyrylo Simonov</a>, 
<a href="/search/quant-ph?searchtype=author&query=Caleffi%2C+M">Marcello Caleffi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Illiano%2C+J">Jessica Illiano</a>, 
<a href="/search/quant-ph?searchtype=author&query=Cacciapuoti%2C+A+S">Angela Sara Cacciapuoti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Superposed orders of quantum channels have already been proved - both
theoretically and experimentally - to enable unparalleled opportunities in the
quantum communication domain. As a matter of fact, superposition of orders can
be exploited within the quantum computing domain as well, by relaxing the
(traditional) assumption underlying quantum computation about applying gates in
a well-defined causal order. In this context, we address a fundamental question
arising with quantum computing: whether superposed orders of single-qubit gates
can enable universal quantum computation. As shown in this paper, the answer to
this key question is a definitive "yes". Indeed, we prove that any two-qubit
controlled quantum gate can be deterministically realized, including the
so-called Barenco gate that alone enables universal quantum computation.
</p>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13662" title="Abstract">arXiv:2311.13662</a> (cross-list from math.CO) [<a href="/pdf/2311.13662" title="Download PDF">pdf</a>, <a href="/format/2311.13662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zarankiewicz&#x27;s problem via $&#x3b5;$-t-nets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Keller%2C+C">Chaya Keller</a>, 
<a href="/search/math?searchtype=author&query=Smorodinsky%2C+S">Shakhar Smorodinsky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Geometry (cs.CG)

</div>
<p class="mathjax">The classical Zarankiewicz's problem asks for the maximum number of edges in
a bipartite graph on $n$ vertices which does not contain the complete bipartite
graph $K_{t,t}$. In one of the cornerstones of extremal graph theory,
K\H{o}v\'ari S\'os and Tur\'an proved an upper bound of $O(n^{2-\frac{1}{t}})$.
In a celebrated result, Fox et al. obtained an improved bound of
$O(n^{2-\frac{1}{d}})$ for graphs of VC-dimension $d$ (where $d&lt;t$). Basit,
Chernikov, Starchenko, Tao and Tran improved the bound for the case of
semilinear graphs. At SODA'23, Chan and Har-Peled further improved Basit et
al.'s bounds and presented (quasi-)linear upper bounds for several classes of
geometrically-defined incidence graphs, including a bound of $O(n \log \log n)$
for the incidence graph of points and pseudo-discs in the plane.
<br />In this paper we present a new approach to Zarankiewicz's problem, via
$\epsilon$-t-nets - a recently introduced generalization of the classical
notion of $\epsilon$-nets. We show that the existence of `small'-sized
$\epsilon$-t-nets implies upper bounds for Zarankiewicz's problem. Using the
new approach, we obtain a sharp bound of $O(n)$ for the intersection graph of
two families of pseudo-discs, thus both improving and generalizing the result
of Chan and Har-Peled from incidence graphs to intersection graphs. We also
obtain a short proof of the $O(n^{2-\frac{1}{d}})$ bound of Fox et al., and
show improved bounds for several other classes of geometric intersection
graphs, including a sharp $O(n\frac{\log n}{\log \log n})$ bound for the
intersection graph of two families of axis-parallel rectangles.
</p>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13679" title="Abstract">arXiv:2311.13679</a> (cross-list from quant-ph) [<a href="/pdf/2311.13679" title="Download PDF">pdf</a>, <a href="/ps/2311.13679" title="Download PostScript">ps</a>, <a href="/format/2311.13679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parity vs. $\mathsf{AC^0}$ with simple quantum preprocessing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Slote%2C+J">Joseph Slote</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages. To appear in ITCS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">A recent line of work has shown the unconditional advantage of constant-depth
quantum computation, or $\mathsf{QNC^0}$, over $\mathsf{NC^0}$,
$\mathsf{AC^0}$, and related models of classical computation. Problems
exhibiting this advantage include search and sampling tasks related to the
parity function, and it is natural to ask whether $\mathsf{QNC^0}$ can be used
to help compute parity itself. We study $\mathsf{AC^0\circ QNC^0}$ -- a hybrid
circuit model where $\mathsf{AC^0}$ operates on measurement outcomes of a
$\mathsf{QNC^0}$ circuit, and conjecture $\mathsf{AC^0\circ QNC^0}$ cannot even
achieve $\Omega(1)$ correlation with parity. As evidence for this conjecture,
we prove:
<br />$\bullet$ When the $\mathsf{QNC^0}$ circuit is ancilla-free, this model
achieves only negligible correlation with parity.
<br />$\bullet$ For the general (non-ancilla-free) case, we show via a connection
to nonlocal games that the conjecture holds for any class of postprocessing
functions that has approximate degree $o(n)$ and is closed under restrictions,
even when the $\mathsf{QNC^0}$ circuit is given arbitrary quantum advice. By
known results this confirms the conjecture for linear-size $\mathsf{AC^0}$
circuits.
<br />$\bullet$ Towards the a switching lemma for $\mathsf{AC^0\circ QNC^0}$, we
study the effect of quantum preprocessing on the decision tree complexity of
Boolean functions. We find that from this perspective, nonlocal channels are no
better than randomness: a Boolean function $f$ precomposed with an $n$-party
nonlocal channel is together equal to a randomized decision tree with
worst-case depth at most $\mathrm{DT}_\mathrm{depth}[f]$.
<br />Our results suggest that while $\mathsf{QNC^0}$ is surprisingly powerful for
search and sampling, that power is "locked away" in the global correlations of
its output, inaccessible to simple classical computation for solving decision
problems.
</p>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13688" title="Abstract">arXiv:2311.13688</a> (cross-list from eess.IV) [<a href="/pdf/2311.13688" title="Download PDF">pdf</a>, <a href="/format/2311.13688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masked Conditional Diffusion Models for Image Analysis with Application  to Radiographic Diagnosis of Infant Abuse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wu%2C+S">Shaoju Wu</a>, 
<a href="/search/eess?searchtype=author&query=Kurugol%2C+S">Sila Kurugol</a>, 
<a href="/search/eess?searchtype=author&query=Tsai%2C+A">Andy Tsai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by MICCAI DALI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">The classic metaphyseal lesion (CML) is a distinct injury that is highly
specific for infant abuse. It commonly occurs in the distal tibia. To aid
radiologists detect these subtle fractures, we need to develop a model that can
flag abnormal distal tibial radiographs (i.e. those with CMLs). Unfortunately,
the development of such a model requires a large and diverse training database,
which is often not available. To address this limitation, we propose a novel
generative model for data augmentation. Unlike previous models that fail to
generate data that span the diverse radiographic appearance of the distal
tibial CML, our proposed masked conditional diffusion model (MaC-DM) not only
generates realistic-appearing and wide-ranging synthetic images of the distal
tibial radiographs with and without CMLs, it also generates their associated
segmentation labels. To achieve these tasks, MaC-DM combines the weighted
segmentation masks of the tibias and the CML fracture sites as additional
conditions for classifier guidance. The augmented images from our model
improved the performances of ResNet-34 in classifying normal radiographs and
those with CMLs. Further, the augmented images and their associated
segmentation masks enhanced the performance of the U-Net in labeling areas of
the CMLs on distal tibial radiographs.
</p>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13691" title="Abstract">arXiv:2311.13691</a> (cross-list from physics.ao-ph) [<a href="/pdf/2311.13691" title="Download PDF">pdf</a>, <a href="/ps/2311.13691" title="Download PostScript">ps</a>, <a href="/format/2311.13691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Next-Generation Earth System Models: Towards Reliable Hybrid Models for  Weather and Climate Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Beucler%2C+T">Tom Beucler</a>, 
<a href="/search/physics?searchtype=author&query=Koch%2C+E">Erwan Koch</a>, 
<a href="/search/physics?searchtype=author&query=Kotlarski%2C+S">Sven Kotlarski</a>, 
<a href="/search/physics?searchtype=author&query=Leutwyler%2C+D">David Leutwyler</a>, 
<a href="/search/physics?searchtype=author&query=Michel%2C+A">Adrien Michel</a>, 
<a href="/search/physics?searchtype=author&query=Koh%2C+J">Jonathan Koh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, submitted as part of the Swiss Academy of Engineering Sciences' 2023 whitepaper on "Artificial Intelligence for Climate Change Mitigation"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Artificial Intelligence (cs.AI); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">We review how machine learning has transformed our ability to model the Earth
system, and how we expect recent breakthroughs to benefit end-users in
Switzerland in the near future.
</p>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13694" title="Abstract">arXiv:2311.13694</a> (cross-list from quant-ph) [<a href="/pdf/2311.13694" title="Download PDF">pdf</a>, <a href="/ps/2311.13694" title="Download PostScript">ps</a>, <a href="/format/2311.13694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Limit Distribution Theory for Quantum Divergences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Sreekumar%2C+S">Sreejith Sreekumar</a>, 
<a href="/search/quant-ph?searchtype=author&query=Berta%2C+M">Mario Berta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12+27 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT); Statistics Theory (math.ST)

</div>
<p class="mathjax">Estimation of quantum relative entropy and its R\'{e}nyi generalizations is a
fundamental statistical task in quantum information theory, physics, and
beyond. While several estimators of these divergences have been proposed in the
literature along with their computational complexities explored, a limit
distribution theory which characterizes the asymptotic fluctuations of the
estimation error is still premature. As our main contribution, we characterize
these asymptotic distributions in terms of Fr\'{e}chet derivatives of
elementary operator-valued functions. We achieve this by leveraging an operator
version of Taylor's theorem and identifying the regularity conditions needed.
As an application of our results, we consider an estimator of quantum relative
entropy based on generalized Pauli tomography of quantum states and show that
the resulting asymptotic distribution is a centered normal, with its variance
characterized in terms of the Pauli operators and states. We utilize the
knowledge of the aforementioned limit distribution to obtain asymptotic
performance guarantees for a multi-hypothesis testing problem.
</p>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13706" title="Abstract">arXiv:2311.13706</a> (cross-list from eess.IV) [<a href="/pdf/2311.13706" title="Download PDF">pdf</a>, <a href="/format/2311.13706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-view Hybrid Graph Convolutional Network for Volume-to-mesh  Reconstruction in Cardiovascular MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gaggion%2C+N">Nicol&#xe1;s Gaggion</a>, 
<a href="/search/eess?searchtype=author&query=Matheson%2C+B+A">Benjamin A. Matheson</a>, 
<a href="/search/eess?searchtype=author&query=Xia%2C+Y">Yan Xia</a>, 
<a href="/search/eess?searchtype=author&query=Bonazzola%2C+R">Rodrigo Bonazzola</a>, 
<a href="/search/eess?searchtype=author&query=Ravikumar%2C+N">Nishant Ravikumar</a>, 
<a href="/search/eess?searchtype=author&query=Taylor%2C+Z+A">Zeike A. Taylor</a>, 
<a href="/search/eess?searchtype=author&query=Milone%2C+D+H">Diego H. Milone</a>, 
<a href="/search/eess?searchtype=author&query=Frangi%2C+A+F">Alejandro F. Frangi</a>, 
<a href="/search/eess?searchtype=author&query=Ferrante%2C+E">Enzo Ferrante</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Cardiovascular magnetic resonance imaging is emerging as a crucial tool to
examine cardiac morphology and function. Essential to this endeavour are
anatomical 3D surface and volumetric meshes derived from CMR images, which
facilitate computational anatomy studies, biomarker discovery, and in-silico
simulations. However, conventional surface mesh generation methods, such as
active shape models and multi-atlas segmentation, are highly time-consuming and
require complex processing pipelines to generate simulation-ready 3D meshes. In
response, we introduce HybridVNet, a novel architecture for direct
image-to-mesh extraction seamlessly integrating standard convolutional neural
networks with graph convolutions, which we prove can efficiently handle surface
and volumetric meshes by encoding them as graph structures. To further enhance
accuracy, we propose a multiview HybridVNet architecture which processes both
long axis and short axis CMR, showing that it can increase the performance of
cardiac MR mesh generation. Our model combines traditional convolutional
networks with variational graph generative models, deep supervision and
mesh-specific regularisation. Experiments on a comprehensive dataset from the
UK Biobank confirm the potential of HybridVNet to significantly advance cardiac
imaging and computational cardiology by efficiently generating high-fidelity
and simulation ready meshes from CMR images.
</p>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13707" title="Abstract">arXiv:2311.13707</a> (cross-list from stat.AP) [<a href="/pdf/2311.13707" title="Download PDF">pdf</a>, <a href="/format/2311.13707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayes-xG: Player and Position Correction on Expected Goals (xG) using  Bayesian Hierarchical Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Scholtes%2C+A">Alexander Scholtes</a>, 
<a href="/search/stat?searchtype=author&query=Karaku%C5%9F%2C+O">Oktay Karaku&#x15f;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pgs, 15 Figures and 9 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applications (stat.AP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This study employs Bayesian methodologies to explore the influence of player
or positional factors in predicting the probability of a shot resulting in a
goal, measured by the expected goals (xG) metric. Utilising publicly available
data from StatsBomb, Bayesian hierarchical logistic regressions are
constructed, analysing approximately 10,000 shots from the English Premier
League to ascertain whether positional or player-level effects impact xG. The
findings reveal positional effects in a basic model that includes only distance
to goal and shot angle as predictors, highlighting that strikers and attacking
midfielders exhibit a higher likelihood of scoring. However, these effects
diminish when more informative predictors are introduced. Nevertheless, even
with additional predictors, player-level effects persist, indicating that
certain players possess notable positive or negative xG adjustments,
influencing their likelihood of scoring a given chance. The study extends its
analysis to data from Spain's La Liga and Germany's Bundesliga, yielding
comparable results. Additionally, the paper assesses the impact of prior
distribution choices on outcomes, concluding that the priors employed in the
models provide sound results but could be refined to enhance sampling
efficiency for constructing more complex and extensive models feasibly.
</p>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13710" title="Abstract">arXiv:2311.13710</a> (cross-list from eess.IV) [<a href="/pdf/2311.13710" title="Download PDF">pdf</a>, <a href="/format/2311.13710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Review of Artificial Intelligence Applications in Major  Retinal Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Raja%2C+H">Hina Raja</a>, 
<a href="/search/eess?searchtype=author&query=Hassan%2C+T">Taimur Hassan</a>, 
<a href="/search/eess?searchtype=author&query=Hassan%2C+B">Bilal Hassan</a>, 
<a href="/search/eess?searchtype=author&query=Akram%2C+M+U">Muhammad Usman Akram</a>, 
<a href="/search/eess?searchtype=author&query=Raja%2C+H">Hira Raja</a>, 
<a href="/search/eess?searchtype=author&query=Abd-alrazaq%2C+A+A">Alaa A Abd-alrazaq</a>, 
<a href="/search/eess?searchtype=author&query=Yousefi%2C+S">Siamak Yousefi</a>, 
<a href="/search/eess?searchtype=author&query=Werghi%2C+N">Naoufel Werghi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This paper provides a systematic survey of retinal diseases that cause visual
impairments or blindness, emphasizing the importance of early detection for
effective treatment. It covers both clinical and automated approaches for
detecting retinal disease, focusing on studies from the past decade. The survey
evaluates various algorithms for identifying structural abnormalities and
diagnosing retinal diseases, and it identifies future research directions based
on a critical analysis of existing literature. This comprehensive study, which
reviews both clinical and automated detection methods using different
modalities, appears to be unique in its scope. Additionally, the survey serves
as a helpful guide for researchers interested in digital retinopathy.
</p>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13719" title="Abstract">arXiv:2311.13719</a> (cross-list from eess.IV) [<a href="/pdf/2311.13719" title="Download PDF">pdf</a>, <a href="/ps/2311.13719" title="Download PostScript">ps</a>, <a href="/format/2311.13719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep learning-based instance segmentation for the precise automated  quantification of digital breast cancer immunohistochemistry images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Priego-Torresa%2C+B+M">Blanca Maria Priego-Torresa</a>, 
<a href="/search/eess?searchtype=author&query=Lobato-Delgado%2C+B">Barbara Lobato-Delgado</a>, 
<a href="/search/eess?searchtype=author&query=Atienza-Cuevas%2C+L">Lidia Atienza-Cuevas</a>, 
<a href="/search/eess?searchtype=author&query=Sanchez-Morillo%2C+D">Daniel Sanchez-Morillo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 12 figures, 7 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Expert Syst Appl 2022;193:116471
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The quantification of biomarkers on immunohistochemistry breast cancer images
is essential for defining appropriate therapy for breast cancer patients, as
well as for extracting relevant information on disease prognosis. This is an
arduous and time-consuming task that may introduce a bias in the results due to
intra- and inter-observer variability which could be alleviated by making use
of automatic quantification tools. However, this is not a simple processing
task given the heterogeneity of breast tumors that results in non-uniformly
distributed tumor cells exhibiting different staining colors and intensity,
size, shape, and texture, of the nucleus, cytoplasm and membrane. In this
research work, we demonstrate the feasibility of using a deep learning-based
instance segmentation architecture for the automatic quantification of both
nuclear and membrane biomarkers applied to IHC-stained slides. We have solved
the cumbersome task of training set generation with the design and
implementation of a web platform, which has served as a hub for communication
and feedback between researchers and pathologists as well as a system for the
validation of the automatic image processing models. Through this tool, we have
collected annotations over samples of HE, ER and Ki-67 (nuclear biomarkers) and
HER2 (membrane biomarker) IHC-stained images. Using the same deep learning
network architecture, we have trained two models, so-called nuclei- and
membrane-aware segmentation models, which, once successfully validated, have
revealed to be a promising method to segment nuclei instances in IHC-stained
images. The quantification method proposed in this work has been integrated
into the developed web platform and is currently being used as a
decision-support tool by pathologists.
</p>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13722" title="Abstract">arXiv:2311.13722</a> (cross-list from physics.chem-ph) [<a href="/pdf/2311.13722" title="Download PDF">pdf</a>, <a href="/format/2311.13722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning as a Method for Inversion of NMR Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Beckmann%2C+J+B+B">Julian B. B. Beckmann</a>, 
<a href="/search/physics?searchtype=author&query=Mantle%2C+M+D">Mick D. Mantle</a>, 
<a href="/search/physics?searchtype=author&query=Sederman%2C+A+J">Andrew J. Sederman</a>, 
<a href="/search/physics?searchtype=author&query=Gladden%2C+L+F">Lynn F. Gladden</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">The concept of deep learning is employed for the inversion of NMR signals and
it is shown that NMR signal inversion can be considered as an image-to-image
regression problem, which can be treated with a convolutional neural net. It is
further outlined, that inversion through deep learning provides a clear
efficiency and usability advantage compared to regularization techniques such
as Tikhonov and modified total generalized variation (MTGV), because no
hyperparemeter selection prior to reconstruction is necessary. The inversion
network is applied to simulated NMR signals and the results compared with
Tikhonov- and MTGV-regularization. The comparison shows that inversion via deep
learning is significantly faster than the latter regularization methods and
also outperforms both regularization techniques in nearly all instances.
</p>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13743" title="Abstract">arXiv:2311.13743</a> (cross-list from q-fin.CP) [<a href="/pdf/2311.13743" title="Download PDF">pdf</a>, <a href="/format/2311.13743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FinMe: A Performance-Enhanced Large Language Model Trading Agent with  Layered Memory and Character Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Yu%2C+Y">Yangyang Yu</a>, 
<a href="/search/q-fin?searchtype=author&query=Li%2C+H">Haohang Li</a>, 
<a href="/search/q-fin?searchtype=author&query=Chen%2C+Z">Zhi Chen</a>, 
<a href="/search/q-fin?searchtype=author&query=Jiang%2C+Y">Yuechen Jiang</a>, 
<a href="/search/q-fin?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/q-fin?searchtype=author&query=Zhang%2C+D">Denghui Zhang</a>, 
<a href="/search/q-fin?searchtype=author&query=Liu%2C+R">Rong Liu</a>, 
<a href="/search/q-fin?searchtype=author&query=Suchow%2C+J+W">Jordan W. Suchow</a>, 
<a href="/search/q-fin?searchtype=author&query=Khashanah%2C+K">Khaldoun Khashanah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Finance (q-fin.CP)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advancements in Large Language Models (LLMs) have exhibited notable
efficacy in question-answering (QA) tasks across diverse domains. Their prowess
in integrating extensive web knowledge has fueled interest in developing LLM
autonomous agents. While LLMs are efficient in decoding human instructions and
deriving solutions by holistically processing historical inputs, transitioning
to purpose-driven agents requires a supplementary rational architecture to
process multi-source information, establish reasoning chains, and prioritize
critical tasks. Addressing this, we introduce \textsc{FinMe}, a novel LLM-based
agent framework devised for financial decision-making, encompassing three core
modules: Profiling, to outline the agent's characteristics; Memory, with
layered processing, to aid the agent in assimilating realistic hierarchical
financial data; and Decision-making, to convert insights gained from memories
into investment decisions. Notably, \textsc{FinMe}'s memory module aligns
closely with the cognitive structure of human traders, offering robust
interpretability and real-time tuning. Its adjustable cognitive span allows for
the retention of critical information beyond human perceptual limits, thereby
enhancing trading outcomes. This framework enables the agent to self-evolve its
professional knowledge, react agilely to new investment cues, and continuously
refine trading decisions in the volatile financial environment. We first
compare \textsc{FinMe} with various algorithmic agents on a scalable real-world
financial dataset, underscoring its leading trading performance in stocks and
funds. We then fine-tuned the agent's perceptual spans to achieve a significant
trading performance. Collectively, \textsc{FinMe} presents a cutting-edge LLM
agent framework for automated trading, boosting cumulative investment returns.
</p>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13749" title="Abstract">arXiv:2311.13749</a> (cross-list from cond-mat.stat-mech) [<a href="/pdf/2311.13749" title="Download PDF">pdf</a>, <a href="/format/2311.13749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Principles of Emergent Organization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Rupe%2C+A+T">Adam T. Rupe</a>, 
<a href="/search/cond-mat?searchtype=author&query=Crutchfield%2C+J+P">James P. Crutchfield</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 51 pages, 7 figures; <a href="https://csc.ucdavis.edu/~cmg/compmech/pubs/tsfpoo.htm">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Mechanics (cond-mat.stat-mech)</span>; Machine Learning (cs.LG); Chaotic Dynamics (nlin.CD); Pattern Formation and Solitons (nlin.PS); Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
<p class="mathjax">After more than a century of concerted effort, physics still lacks basic
principles of spontaneous self-organization. To appreciate why, we first state
the problem, outline historical approaches, and survey the present state of the
physics of self-organization. This frames the particular challenges arising
from mathematical intractability and the resulting need for computational
approaches, as well as those arising from a chronic failure to define
structure. Then, an overview of two modern mathematical formulations of
organization -- intrinsic computation and evolution operators -- lays out a way
to overcome these challenges. Together, the vantage point they afford shows how
to account for the emergence of structured states via a statistical mechanics
of systems arbitrarily far from equilibrium. The result is a constructive path
forward to principles of organization that builds on mathematical
identification of structure.
</p>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13763" title="Abstract">arXiv:2311.13763</a> (cross-list from physics.plasm-ph) [<a href="/pdf/2311.13763" title="Download PDF">pdf</a>, <a href="/ps/2311.13763" title="Download PostScript">ps</a>, <a href="/format/2311.13763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extraction of n = 0 pick-up by locked mode detectors based on neural  networks in J-TEXT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Shen%2C+C">Chengshuo Shen</a>, 
<a href="/search/physics?searchtype=author&query=Li%2C+J">Jianchao Li</a>, 
<a href="/search/physics?searchtype=author&query=Ding%2C+Y">Yonghua Ding</a>, 
<a href="/search/physics?searchtype=author&query=Dong%2C+J">Jiaolong Dong</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+N">Nengchao Wang</a>, 
<a href="/search/physics?searchtype=author&query=Han%2C+D">Dongliang.Han</a>, 
<a href="/search/physics?searchtype=author&query=Mao%2C+F">Feiyue Mao</a>, 
<a href="/search/physics?searchtype=author&query=Li%2C+D">Da Li</a>, 
<a href="/search/physics?searchtype=author&query=Chen%2C+Z">Zhipeng Chen</a>, 
<a href="/search/physics?searchtype=author&query=Yang%2C+Z">Zhoujun Yang</a>, 
<a href="/search/physics?searchtype=author&query=Chen%2C+Z">Zhongyong Chen</a>, 
<a href="/search/physics?searchtype=author&query=Pan%2C+Y">Yuan Pan</a>, 
<a href="/search/physics?searchtype=author&query=J-Text+Team">J-Text Team</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7pages, 10figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Plasma Physics (physics.plasm-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Measurement of locked mode (LM) is important for the physical research of
Magnetohydrodynamic (MHD) instabilities and plasma disruption. The n = 0
pick-up need to be extracted and subtracted to calculate the amplitude and
phase of the LM. A new method to extract this pick-up has been developed by
predicting the n = 0 pick-up brn=0 by the LM detectors based on Neural Networks
(NNs) in J-TEXT. An approach called Power Multiple Time Scale (PMTS) has been
developed with outstanding regressing effect in multiple frequency ranges.
Three models have been progressed based on PMTS NNs. PMTS could fit the brn=0
on the LM detectors with little errors both in time domain and frequency
domain. The n&gt;0 pick-up brn&gt;0 generated by resonant magnetic perturbations
(RMPs) can be obtained after subtracting the extracted brn=0. This new method
uses only one LM instead of 4 LM detectors to extract brn=0. Therefore, the
distribution of the LM detectors can also be optimized based on this new
method.
</p>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13765" title="Abstract">arXiv:2311.13765</a> (cross-list from math.OC) [<a href="/pdf/2311.13765" title="Download PDF">pdf</a>, <a href="/format/2311.13765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Optimal and Fair Policies for Online Allocation of Scarce  Societal Resources from Data Collected in Deployment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tang%2C+B">Bill Tang</a>, 
<a href="/search/math?searchtype=author&query=Ko%C3%A7yi%C4%9Fit%2C+%C3%87">&#xc7;a&#x11f;&#x131;l Ko&#xe7;yi&#x11f;it</a>, 
<a href="/search/math?searchtype=author&query=Rice%2C+E">Eric Rice</a>, 
<a href="/search/math?searchtype=author&query=Vayanos%2C+P">Phebe Vayanos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 61 pages, 9 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">We study the problem of allocating scarce societal resources of different
types (e.g., permanent housing, deceased donor kidneys for transplantation,
ventilators) to heterogeneous allocatees on a waitlist (e.g., people
experiencing homelessness, individuals suffering from end-stage renal disease,
Covid-19 patients) based on their observed covariates. We leverage
administrative data collected in deployment to design an online policy that
maximizes expected outcomes while satisfying budget constraints, in the long
run. Our proposed policy waitlists each individual for the resource maximizing
the difference between their estimated mean treatment outcome and the estimated
resource dual-price or, roughly, the opportunity cost of using the resource.
Resources are then allocated as they arrive, in a first-come first-serve
fashion. We demonstrate that our data-driven policy almost surely
asymptotically achieves the expected outcome of the optimal out-of-sample
policy under mild technical assumptions. We extend our framework to incorporate
various fairness constraints. We evaluate the performance of our approach on
the problem of designing policies for allocating scarce housing resources to
people experiencing homelessness in Los Angeles based on data from the homeless
management information system. In particular, we show that using our policies
improves rates of exit from homelessness by 1.9% and that policies that are
fair in either allocation or outcomes by race come at a very low price of
fairness.
</p>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13779" title="Abstract">arXiv:2311.13779</a> (cross-list from eess.IV) [<a href="/pdf/2311.13779" title="Download PDF">pdf</a>, <a href="/format/2311.13779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detection and Identification Accuracy of PCA-Accelerated Real-Time  Processing of Hyperspectral Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Basener%2C+A">Abigail Basener</a>, 
<a href="/search/eess?searchtype=author&query=Herald%2C+M">Meagan Herald</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Real-time or near real-time hyperspectral detection and identification are
extremely useful and needed in many fields. These data sets can be quite large,
and the algorithms can require numerous computations that slow the process
down. A common way of speeding up the process is to use principal component
analysis (PCA) for dimension reduction. In the reduced dimensional space,
provided by a subset of the principal components, fewer computations are needed
to process the data resulting in a faster run time. In this paper, we propose a
way to further decrease the time required to use PCA by investigating how many
principal components may be omitted with minimal impact on the detection rate.
Using ACE to perform the detection, and then probability, and spectral fit for
identification, we find that the number of principal components can be reduced
by a substantial amount before seeing a noticeable change in detection rates.
</p>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13789" title="Abstract">arXiv:2311.13789</a> (cross-list from eess.SP) [<a href="/pdf/2311.13789" title="Download PDF">pdf</a>, <a href="/format/2311.13789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Distillation Based Semantic Communications For Multiple Users
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+C">Chenguang Liu</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Y">Yuxin Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yunfei Chen</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+S">Shuang-Hua Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Wireless Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep learning (DL) has shown great potential in revolutionizing the
traditional communications system. Many applications in communications have
adopted DL techniques due to their powerful representation ability. However,
the learning-based methods can be dependent on the training dataset and perform
worse on unseen interference due to limited model generalizability and
complexity. In this paper, we consider the semantic communication (SemCom)
system with multiple users, where there is a limited number of training samples
and unexpected interference. To improve the model generalization ability and
reduce the model size, we propose a knowledge distillation (KD) based system
where Transformer based encoder-decoder is implemented as the semantic
encoder-decoder and fully connected neural networks are implemented as the
channel encoder-decoder. Specifically, four types of knowledge transfer and
model compression are analyzed. Important system and model parameters are
considered, including the level of noise and interference, the number of
interfering users and the size of the encoder and decoder. Numerical results
demonstrate that KD significantly improves the robustness and the
generalization ability when applied to unexpected interference, and it reduces
the performance loss when compressing the model size.
</p>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13794" title="Abstract">arXiv:2311.13794</a> (cross-list from math.OC) [<a href="/pdf/2311.13794" title="Download PDF">pdf</a>, <a href="/ps/2311.13794" title="Download PostScript">ps</a>, <a href="/format/2311.13794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error estimation for the non-convex cosparse optimization problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+Z">Zisheng Liu</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+T">Ting Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">When the signal does not have a sparse structure but has sparsity under a
certain transformation domain, Nam et al. \cite{NS} introduced the cosparse
analysis model, which provides a dual perspective on the sparse representation
model. This paper mainly discusses the error estimation of non-convex
$\ell_p(0&lt;p&lt;1)$ relaxation cosparse optimization model with noise condition.
Compared with the existing literature, under the same conditions, the value
range of the $\Omega$-RIP constant $\delta_{7s}$ given in this paper is wider.
When $p=0.5$ and $\delta_{7s}=0.5$, the error constants $C_0$ and $C_1$ in this
paper are better than those corresponding results in the literature
\cite{Cand,LiSong1}. Moreover, when $0&lt;p&lt;1$, the error results of the
non-convex relaxation method are significantly smaller than those of the convex
relaxation method. The experimental results verify the correctness of the
theoretical analysis and illustrate that the $\ell_p(0&lt;p&lt;1)$ method can provide
robust reconstruction for cosparse optimization problems.
</p>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13810" title="Abstract">arXiv:2311.13810</a> (cross-list from quant-ph) [<a href="/pdf/2311.13810" title="Download PDF">pdf</a>, <a href="/format/2311.13810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging Classical and Quantum Machine Learning: Knowledge Transfer From  Classical to Quantum Neural Networks Using Knowledge Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Hasan%2C+M+J">Mohammad Junayed Hasan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Mahdy%2C+M+R+C">M.R.C.Mahdy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 7 figures and 17 equations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Very recently, studies have shown that quantum neural networks surpass
classical neural networks in tasks like image classification when a similar
number of learnable parameters are used. However, the development and
optimization of quantum models are currently hindered by issues such as qubit
instability and limited qubit availability, leading to error-prone systems with
weak performance. In contrast, classical models can exhibit high-performance
owing to substantial resource availability. As a result, more studies have been
focusing on hybrid classical-quantum integration. A line of research
particularly focuses on transfer learning through classical-quantum integration
or quantum-quantum approaches. Unlike previous studies, this paper introduces a
new method to transfer knowledge from classical to quantum neural networks
using knowledge distillation, effectively bridging the gap between classical
machine learning and emergent quantum computing techniques. We adapt classical
convolutional neural network (CNN) architectures like LeNet and AlexNet to
serve as teacher networks, facilitating the training of student quantum models
by sending supervisory signals during backpropagation through KL-divergence.
The approach yields significant performance improvements for the quantum models
by solely depending on classical CNNs, with quantum models achieving an average
accuracy improvement of 0.80% on the MNIST dataset and 5.40% on the more
complex Fashion MNIST dataset. Applying this technique eliminates the
cumbersome training of huge quantum models for transfer learning in
resource-constrained settings and enables re-using existing pre-trained
classical models to improve performance.Thus, this study paves the way for
future research in quantum machine learning (QML) by positioning knowledge
distillation as a core technique for advancing QML applications.
</p>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13812" title="Abstract">arXiv:2311.13812</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2311.13812" title="Download PDF">pdf</a>, <a href="/format/2311.13812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mechanical Characterization and Inverse Design of Stochastic Architected  Metamaterials Using Neural Operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Jin%2C+H">Hanxun Jin</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zhang%2C+E">Enrui Zhang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zhang%2C+B">Boyu Zhang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Krishnaswamy%2C+S">Sridhar Krishnaswamy</a>, 
<a href="/search/cond-mat?searchtype=author&query=Karniadakis%2C+G+E">George Em Karniadakis</a>, 
<a href="/search/cond-mat?searchtype=author&query=Espinosa%2C+H+D">Horacio D. Espinosa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Machine learning (ML) is emerging as a transformative tool for the design of
architected materials, offering properties that far surpass those achievable
through lab-based trial-and-error methods. However, a major challenge in
current inverse design strategies is their reliance on extensive computational
and/or experimental datasets, which becomes particularly problematic for
designing micro-scale stochastic architected materials that exhibit nonlinear
mechanical behaviors. Here, we introduce a new end-to-end scientific ML
framework, leveraging deep neural operators (DeepONet), to directly learn the
relationship between the complete microstructure and mechanical response of
architected metamaterials from sparse but high-quality in situ experimental
data. The approach facilitates the inverse design of structures tailored to
specific nonlinear mechanical behaviors. Results obtained from spinodal
microstructures, printed using two-photon lithography, reveal that the
prediction error for mechanical responses is within a range of 5 - 10%. Our
work underscores that by employing neural operators with advanced
micro-mechanics experimental techniques, the design of complex
micro-architected materials with desired properties becomes feasible, even in
scenarios constrained by data scarcity. Our work marks a significant
advancement in the field of materials-by-design, potentially heralding a new
era in the discovery and development of next-generation metamaterials with
unparalleled mechanical characteristics derived directly from experimental
insights.
</p>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13827" title="Abstract">arXiv:2311.13827</a> (cross-list from stat.ML) [<a href="/pdf/2311.13827" title="Download PDF">pdf</a>, <a href="/format/2311.13827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stability and L2-penalty in Model Averaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhu%2C+H">Hengkun Zhu</a>, 
<a href="/search/stat?searchtype=author&query=Zou%2C+G">Guohua Zou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 47 pages, 14 figures, 1 table. This article was submitted to Journal of Machine Learning Research in July 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Model averaging has received much attention in the past two decades, which
integrates available information by averaging over potential models. Although
various model averaging methods have been developed, there are few literatures
on the theoretical properties of model averaging from the perspective of
stability, and the majority of these methods constrain model weights to a
simplex. The aim of this paper is to introduce stability from statistical
learning theory into model averaging. Thus, we define the stability, asymptotic
empirical risk minimizer, generalization, and consistency of model averaging
and study the relationship among them. Our results indicate that stability can
ensure that model averaging has good generalization performance and consistency
under reasonable conditions, where consistency means model averaging estimator
can asymptotically minimize the mean squared prediction error. We also propose
a L2-penalty model averaging method without limiting model weights and prove
that it has stability and consistency. In order to reduce the impact of tuning
parameter selection, we use 10-fold cross-validation to select a candidate set
of tuning parameters and perform a weighted average of the estimators of model
weights based on estimation errors. The Monte Carlo simulation and an
illustrative application demonstrate the usefulness of the proposed method.
</p>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13876" title="Abstract">arXiv:2311.13876</a> (cross-list from q-bio.NC) [<a href="/pdf/2311.13876" title="Download PDF">pdf</a>, <a href="/format/2311.13876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EEG Connectivity Analysis Using Denoising Autoencoders for the Detection  of Dyslexia
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Martinez-Murcia%2C+F+J">Francisco Jesus Martinez-Murcia</a>, 
<a href="/search/q-bio?searchtype=author&query=Ortiz%2C+A">Andr&#xe9;s Ortiz</a>, 
<a href="/search/q-bio?searchtype=author&query=G%C3%B3rriz%2C+J+M">Juan Manuel G&#xf3;rriz</a>, 
<a href="/search/q-bio?searchtype=author&query=Ram%C3%ADrez%2C+J">Javier Ram&#xed;rez</a>, 
<a href="/search/q-bio?searchtype=author&query=Lopez-Perez%2C+P+J">Pedro Javier Lopez-Perez</a>, 
<a href="/search/q-bio?searchtype=author&query=L%C3%B3pez-Zamora%2C+M">Miguel L&#xf3;pez-Zamora</a>, 
<a href="/search/q-bio?searchtype=author&query=Luque%2C+J+L">Juan Luis Luque</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 6 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> INT J NEURAL SYST 30 (7), 2020, 2050037
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">The Temporal Sampling Framework (TSF) theorizes that the characteristic
phonological difficulties of dyslexia are caused by an atypical oscillatory
sampling at one or more temporal rates. The LEEDUCA study conducted a series of
Electroencephalography (EEG) experiments on children listening to amplitude
modulated (AM) noise with slow-rythmic prosodic (0.5-1 Hz), syllabic (4-8 Hz)
or the phoneme (12-40 Hz) rates, aimed at detecting differences in perception
of oscillatory sampling that could be associated with dyslexia. The purpose of
this work is to check whether these differences exist and how they are related
to children's performance in different language and cognitive tasks commonly
used to detect dyslexia. To this purpose, temporal and spectral inter-channel
EEG connectivity was estimated, and a denoising autoencoder (DAE) was trained
to learn a low-dimensional representation of the connectivity matrices. This
representation was studied via correlation and classification analysis, which
revealed ability in detecting dyslexic subjects with an accuracy higher than
0.8, and balanced accuracy around 0.7. Some features of the DAE representation
were significantly correlated ($p&lt;0.005$) with children's performance in
language and cognitive tasks of the phonological hypothesis category such as
phonological awareness and rapid symbolic naming, as well as reading efficiency
and reading comprehension. Finally, a deeper analysis of the adjacency matrix
revealed a reduced bilateral connection between electrodes of the temporal lobe
(roughly the primary auditory cortex) in DD subjects, as well as an increased
connectivity of the F7 electrode, placed roughly on Broca's area. These results
pave the way for a complementary assessment of dyslexia using more objective
methodologies such as EEG.
</p>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13896" title="Abstract">arXiv:2311.13896</a> (cross-list from math.AP) [<a href="/pdf/2311.13896" title="Download PDF">pdf</a>, <a href="/ps/2311.13896" title="Download PostScript">ps</a>, <a href="/format/2311.13896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computer-assisted proofs for the many steady states of a chemotaxis  model with local sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Breden%2C+M">Maxime Breden</a> (CMAP), 
<a href="/search/math?searchtype=author&query=Payan%2C+M">Maxime Payan</a> (CMAP)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Dynamical Systems (math.DS); Numerical Analysis (math.NA)

</div>
<p class="mathjax">We study the steady states of a system of cross-diffusion equations arising
from the modeling of chemotaxis with local sensing, where the motility is a
decreasing function of the concentration of the chemical. In order to capture
the many different equilibria that sometimes co-exist, we use computer-assisted
proofs: Given an approximate solution obtained numerically, we apply a
fixed-point argument in a small neighborhood of this approximate solution to
prove the existence of an exact solution nearby. This allows us to rigorously
study the steady states of this crossdiffusion system much more extensively
than what previously possible with purely pen-and-paper techniques. Our
computer-assisted argument makes use of Fourier series decomposition, which is
common in the literature, but usually restricted to systems with polynomial
nonlinearities. This is not the case for the model considered in this paper,
and we develop a new way of dealing with some nonpolynomial nonlinearities in
the context of computer-assisted proofs with Fourier series.
</p>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13906" title="Abstract">arXiv:2311.13906</a> (cross-list from eess.SP) [<a href="/pdf/2311.13906" title="Download PDF">pdf</a>, <a href="/format/2311.13906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Threat-Based Resource Allocation Strategy for Target Tracking in a  Cognitive Radar Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lee%2C+J">JiYe Lee</a>, 
<a href="/search/eess?searchtype=author&query=Park%2C+J+H">J.H Park</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Cognitive radar is developed to utilize the feedback of its operating
environment obtained from a beam to make resource allocation decisions by
solving optimization problems. Previous works focused on target tracking
accuracy by designing an evaluation metric for an optimization problem.
However, in a real combat situation, not only the tracking performance of the
target but also its operational perspective should be considered. In this
study, the usage of threats in the allocation of radar resource is proposed for
a cognitive radar framework. Resource allocation regarding radar dwell time is
considered to reflect the operational importance of target effects. The dwell
time allocation problem is solved using a Second-Order Cone Program (SOCP).
Numerical simulations are performed to verify the effectiveness of the proposed
framework.
</p>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13912" title="Abstract">arXiv:2311.13912</a> (cross-list from eess.IV) [<a href="/pdf/2311.13912" title="Download PDF">pdf</a>, <a href="/format/2311.13912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expanding the deep-learning model to diagnosis LVNC: Limitations and  trade-offs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bernab%C3%A9%2C+G">Gregorio Bernab&#xe9;</a>, 
<a href="/search/eess?searchtype=author&query=Gonz%C3%A1lez-F%C3%A9rez%2C+P">Pilar Gonz&#xe1;lez-F&#xe9;rez</a>, 
<a href="/search/eess?searchtype=author&query=Garc%C3%ADa%2C+J+M">Jos&#xe9; M. Garc&#xed;a</a>, 
<a href="/search/eess?searchtype=author&query=Casas%2C+G">Guillem Casas</a>, 
<a href="/search/eess?searchtype=author&query=Gonz%C3%A1lez-Carrillo%2C+J">Josefa Gonz&#xe1;lez-Carrillo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Hyper-trabeculation or non-compaction in the left ventricle of the myocardium
(LVNC) is a recently classified form of cardiomyopathy. Several methods have
been proposed to quantify the trabeculae accurately in the left ventricle, but
there is no general agreement in the medical community to use a particular
approach. In previous work, we proposed DL-LVTQ, a deep learning approach for
left ventricular trabecular quantification based on a U-Net CNN architecture.
DL-LVTQ was an automatic diagnosis tool developed from a dataset of patients
with the same cardiomyopathy (hypertrophic cardiomyopathy).
<br />In this work, we have extended and adapted DL-LVTQ to cope with patients with
different cardiomyopathies. The dataset consists of up 379 patients in three
groups with different particularities and cardiomyopathies. Patient images were
taken from different scanners and hospitals. We have modified and adapted the
U-Net convolutional neural network to account for the different particularities
of a heterogeneous group of patients with various unclassifiable or mixed and
inherited cardiomyopathies.
<br />The inclusion of new groups of patients has increased the accuracy,
specificity and kappa values while maintaining the sensitivity of the automatic
deep learning method proposed. Therefore, a better-prepared diagnosis tool is
ready for various cardiomyopathies with different characteristics.
Cardiologists have considered that 98.9% of the evaluated outputs are verified
clinically for diagnosis. Therefore, the high precision to segment the
different cardiac structures allows us to make a robust diagnostic system
objective and faster, decreasing human error and time spent.
</p>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13917" title="Abstract">arXiv:2311.13917</a> (cross-list from physics.soc-ph) [<a href="/pdf/2311.13917" title="Download PDF">pdf</a>, <a href="/ps/2311.13917" title="Download PostScript">ps</a>, <a href="/format/2311.13917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the impact of social stress on the adaptive dynamics of  COVID-19: Typing the behavior of na&#xef;ve populations faced with epidemics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Kastalskiy%2C+I">Innokentiy Kastalskiy</a>, 
<a href="/search/physics?searchtype=author&query=Zinovyev%2C+A">Andrei Zinovyev</a>, 
<a href="/search/physics?searchtype=author&query=Mirkes%2C+E">Evgeny Mirkes</a>, 
<a href="/search/physics?searchtype=author&query=Kazantsev%2C+V">Victor Kazantsev</a>, 
<a href="/search/physics?searchtype=author&query=Gorban%2C+A+N">Alexander N. Gorban</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 15 figures, 1 table, 1 appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In the context of natural disasters, human responses inevitably intertwine
with natural factors. The COVID-19 pandemic, as a significant stress factor,
has brought to light profound variations among different countries in terms of
their adaptive dynamics in addressing the spread of infection outbreaks across
different regions. This emphasizes the crucial role of cultural characteristics
in natural disaster analysis. The theoretical understanding of large-scale
epidemics primarily relies on mean-field kinetic models. However, conventional
SIR-like models failed to fully explain the observed phenomena at the onset of
the COVID-19 outbreak. These phenomena included the unexpected cessation of
exponential growth, the reaching of plateaus, and the occurrence of multi-wave
dynamics. In situations where an outbreak of a highly virulent and unfamiliar
infection arises, it becomes crucial to respond swiftly at a non-medical level
to mitigate the negative socio-economic impact. Here we present a theoretical
examination of the first wave of the epidemic based on a simple SIRSS model
(SIR with Social Stress). We conduct an analysis of the socio-cultural features
of na\"ive population behaviors across various countries worldwide. The unique
characteristics of each country/territory are encapsulated in only a few
constants within our model, derived from the fitted COVID-19 statistics. These
constants also reflect the societal response dynamics to the external stress
factor, underscoring the importance of studying the mutual behavior of humanity
and natural factors during global social disasters. Based on these distinctive
characteristics of specific regions, local authorities can optimize their
strategies to effectively combat epidemics until vaccines are developed.
</p>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13925" title="Abstract">arXiv:2311.13925</a> (cross-list from eess.IV) [<a href="/pdf/2311.13925" title="Download PDF">pdf</a>, <a href="/ps/2311.13925" title="Download PostScript">ps</a>, <a href="/format/2311.13925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Recovery or Decease of COVID-19 Patients with Clinical and  RT-PCR Using Machine Learning Classification Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dehghani%2C+M">Mohammad Dehghani</a>, 
<a href="/search/eess?searchtype=author&query=Yazdanparast%2C+Z">Zahra Yazdanparast</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">The COVID-19 pandemic has disrupted the global economy and people's daily
lives in unprecedented ways. To make appropriate decisions, it is necessary to
diagnose COVID-19 rapidly and accurately. Clinical decision making is
influenced by data collected from patients. With the aid of artificial
intelligence, COVID-19 has been diagnosed quickly by analyzing symptoms,
polymerase chain reaction (PCR), computed tomography scans, chest X-rays,
routine laboratory blood tests and even cough sounds. Furthermore, these data
can be used to predict a patient's morality, although there is a question about
which data makes the most accurate predictions. Therefore, this study consists
of two parts. Our first objective is to examine whether machine learning
algorithms can predict the outcome of COVID-19 cases (recovery or death), based
on the features present in the dataset. In the second part of the research, we
investigated the impact of clinical and RT-PCR on prediction of recovery and
decease to determine which one is more reliable. We defined four stages with
different feature sets and use six machine learning methods to build prediction
model. With an accuracy of 78.7%, random forest showed promising results for
predicting death and recovery of patients. Based on this, it appears that
recovery and decease of patients are predictable using machine learning. For
second objective, results indicate that clinical alone (without using RT-PCR),
trained with AdaBoost algorithm, is the most accurate with an accuracy of
82.1%. This study can provide guidance for medical professionals in the event
of a crisis or outbreak similar to COVID-19.
</p>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13958" title="Abstract">arXiv:2311.13958</a> (cross-list from stat.ML) [<a href="/pdf/2311.13958" title="Download PDF">pdf</a>, <a href="/format/2311.13958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Order Tensor Recovery with A Tensor $U_1$ Norm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zheng%2C+J">Jingjing Zheng</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+W">Wenzhe Wang</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+X">Xiaoqin Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Cao%2C+Y">Yankai Cao</a>, 
<a href="/search/stat?searchtype=author&query=Jiang%2C+X">Xianta Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recently, numerous tensor SVD (t-SVD)-based tensor recovery methods have
emerged, showing promise in processing visual data. However, these methods
often suffer from performance degradation when confronted with high-order
tensor data exhibiting non-smooth changes, commonly observed in real-world
scenarios but ignored by the traditional t-SVD-based methods. Our objective in
this study is to provide an effective tensor recovery technique for handling
non-smooth changes in tensor data and efficiently explore the correlations of
high-order tensor data across its various dimensions without introducing
numerous variables and weights. To this end, we introduce a new tensor
decomposition and a new tensor norm called the Tensor $U_1$ norm. We utilize
these novel techniques in solving the problem of high-order tensor completion
problem and provide theoretical guarantees for the exact recovery of the
resulting tensor completion models. An optimization algorithm is proposed to
solve the resulting tensor completion model iteratively by combining the
proximal algorithm with the Alternating Direction Method of Multipliers.
Theoretical analysis showed the convergence of the algorithm to the
Karush-Kuhn-Tucker (KKT) point of the optimization problem. Numerical
experiments demonstrated the effectiveness of the proposed method in high-order
tensor completion, especially for tensor data with non-smooth changes.
</p>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13963" title="Abstract">arXiv:2311.13963</a> (cross-list from eess.IV) [<a href="/pdf/2311.13963" title="Download PDF">pdf</a>, <a href="/ps/2311.13963" title="Download PostScript">ps</a>, <a href="/format/2311.13963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating the use of publicly available natural videos to learn  Dynamic MR image reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jaubert%2C+O">Olivier Jaubert</a>, 
<a href="/search/eess?searchtype=author&query=Pascale%2C+M">Michele Pascale</a>, 
<a href="/search/eess?searchtype=author&query=Montalt-Tordera%2C+J">Javier Montalt-Tordera</a>, 
<a href="/search/eess?searchtype=author&query=Akesson%2C+J">Julius Akesson</a>, 
<a href="/search/eess?searchtype=author&query=Virsinskaite%2C+R">Ruta Virsinskaite</a>, 
<a href="/search/eess?searchtype=author&query=Knight%2C+D">Daniel Knight</a>, 
<a href="/search/eess?searchtype=author&query=Arridge%2C+S">Simon Arridge</a>, 
<a href="/search/eess?searchtype=author&query=Steeden%2C+J">Jennifer Steeden</a>, 
<a href="/search/eess?searchtype=author&query=Muthurangu%2C+V">Vivek Muthurangu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Purpose: To develop and assess a deep learning (DL) pipeline to learn dynamic
MR image reconstruction from publicly available natural videos (Inter4K).
<br />Materials and Methods: Learning was performed for a range of DL architectures
(VarNet, 3D UNet, FastDVDNet) and corresponding sampling patterns (Cartesian,
radial, spiral) either from true multi-coil cardiac MR data (N=692) or from
pseudo-MR data simulated from Inter4K natural videos (N=692). Real-time
undersampled dynamic MR images were reconstructed using DL networks trained
with cardiac data and natural videos, and compressed sensing (CS). Differences
were assessed in simulations (N=104 datasets) in terms of MSE, PSNR, and SSIM
and prospectively for cardiac (short axis, four chambers, N=20) and speech
(N=10) data in terms of subjective image quality ranking, SNR and Edge
sharpness. Friedman Chi Square tests with post-hoc Nemenyi analysis were
performed to assess statistical significance.
<br />Results: For all simulation metrics, DL networks trained with cardiac data
outperformed DL networks trained with natural videos, which outperformed CS
(p&lt;0.05). However, in prospective experiments DL reconstructions using both
training datasets were ranked similarly (and higher than CS) and presented no
statistical differences in SNR and Edge Sharpness for most conditions.
Additionally, high SSIM was measured between the DL methods with cardiac data
and natural videos (SSIM&gt;0.85).
<br />Conclusion: The developed pipeline enabled learning dynamic MR reconstruction
from natural videos preserving DL reconstruction advantages such as high
quality fast and ultra-fast reconstructions while overcoming some limitations
(data scarcity or sharing). The natural video dataset, code and pre-trained
networks are made readily available on github.
<br />Key Words: real-time; dynamic MRI; deep learning; image reconstruction;
machine learning;
</p>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13964" title="Abstract">arXiv:2311.13964</a> (cross-list from eess.IV) [<a href="/pdf/2311.13964" title="Download PDF">pdf</a>, <a href="/format/2311.13964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Interactive Segmentation of Medical Images: A Systematic Review and  Taxonomy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Marinov%2C+Z">Zdravko Marinov</a>, 
<a href="/search/eess?searchtype=author&query=J%C3%A4ger%2C+P+F">Paul F. J&#xe4;ger</a>, 
<a href="/search/eess?searchtype=author&query=Egger%2C+J">Jan Egger</a>, 
<a href="/search/eess?searchtype=author&query=Kleesiek%2C+J">Jens Kleesiek</a>, 
<a href="/search/eess?searchtype=author&query=Stiefelhagen%2C+R">Rainer Stiefelhagen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 8 figures, 10 tables; Zdravko Marinov and Paul F. J\"ager and co-first authors; This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Interactive segmentation is a crucial research area in medical image analysis
aiming to boost the efficiency of costly annotations by incorporating human
feedback. This feedback takes the form of clicks, scribbles, or masks and
allows for iterative refinement of the model output so as to efficiently guide
the system towards the desired behavior. In recent years, deep learning-based
approaches have propelled results to a new level causing a rapid growth in the
field with 121 methods proposed in the medical imaging domain alone. In this
review, we provide a structured overview of this emerging field featuring a
comprehensive taxonomy, a systematic review of existing methods, and an
in-depth analysis of current practices. Based on these contributions, we
discuss the challenges and opportunities in the field. For instance, we find
that there is a severe lack of comparison across methods which needs to be
tackled by standardized baselines and benchmarks.
</p>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13987" title="Abstract">arXiv:2311.13987</a> (cross-list from eess.AS) [<a href="/pdf/2311.13987" title="Download PDF">pdf</a>, <a href="/format/2311.13987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jam-ALT: A Formatting-Aware Lyrics Transcription Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=C%C3%ADfka%2C+O">Ond&#x159;ej C&#xed;fka</a>, 
<a href="/search/eess?searchtype=author&query=Dimitriou%2C+C">Constantinos Dimitriou</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+C">Cheng-i Wang</a>, 
<a href="/search/eess?searchtype=author&query=Schreiber%2C+H">Hendrik Schreiber</a>, 
<a href="/search/eess?searchtype=author&query=Miner%2C+L">Luke Miner</a>, 
<a href="/search/eess?searchtype=author&query=St%C3%B6ter%2C+F">Fabian-Robert St&#xf6;ter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages (3 pages main content); website: <a href="https://audioshake.github.io/jam-alt/">this https URL</a>; data: <a href="https://huggingface.co/datasets/audioshake/jam-alt">this https URL</a>; code: <a href="https://github.com/audioshake/alt-eval/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">Current automatic lyrics transcription (ALT) benchmarks focus exclusively on
word content and ignore the finer nuances of written lyrics including
formatting and punctuation, which leads to a potential misalignment with the
creative products of musicians and songwriters as well as listeners'
experiences. For example, line breaks are important in conveying information
about rhythm, emotional emphasis, rhyme, and high-level structure. To address
this issue, we introduce Jam-ALT, a new lyrics transcription benchmark based on
the JamendoLyrics dataset. Our contribution is twofold. Firstly, a complete
revision of the transcripts, geared specifically towards ALT evaluation by
following a newly created annotation guide that unifies the music industry's
guidelines, covering aspects such as punctuation, line breaks, spelling,
background vocals, and non-word sounds. Secondly, a suite of evaluation metrics
designed, unlike the traditional word error rate, to capture such phenomena. We
hope that the proposed benchmark contributes to the ALT task, enabling more
precise and reliable assessments of transcription systems and enhancing the
user experience in lyrics applications such as subtitle renderings for live
captioning or karaoke.
</p>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14039" title="Abstract">arXiv:2311.14039</a> (cross-list from astro-ph.IM) [<a href="/pdf/2311.14039" title="Download PDF">pdf</a>, <a href="/format/2311.14039" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Timing relationships and resulting communications challenges in  relativistic travel
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Messerschmitt%2C+D">David Messerschmitt</a>, 
<a href="/search/astro-ph?searchtype=author&query=Morrison%2C+I">Ian Morrison</a>, 
<a href="/search/astro-ph?searchtype=author&query=Mozdzen%2C+T">Thomas Mozdzen</a>, 
<a href="/search/astro-ph?searchtype=author&query=Lubin%2C+P">Philip Lubin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Communications to and from a spacecraft undertaking launch-landing
interstellar travel at near light speed faces significant challenges.
Photon-based communication is significantly impacted by large photon
propagation delay and relativistic time dilation. The timing of communications
by photon transfer, as measured specifically by local clocks at origin and
destination and aboard spacecraft, is analyzed and illustrated for concrete
mission scenarios. These include a spacecraft experiencing indefinite constant
self-acceleration, and a launch-landing mission, in which a spacecraft
experiences constant acceleration for the first half of its cruise phase and a
like deceleration for the second half. The origin and destination are assumed
to be at rest within a common inertial frame with a wide range of fixed
distances separating them. Several typical communication modes are considered,
including one-way messaging, two-way message query with an expected response,
and the one-way streaming of long program material such as a podcast or video.
The local-clock relative timing experienced by the communicating entities
including clock images (relation of transmit and receive clocks in one-way
communication), the query-response latency (the elapsed time between a query
message and reception of a message in response), and the time warping of a
streaming program (nonlinear stretching or shrinking of the time axis) are
included. In particular, large query-response latency, except for a short
interval following launch or before landing, is a severe limit on remote
control and social interaction. When photons must travel in the same direction
as the spacecraft, communication blackouts strongly limit the periods of time
during which communication is possible, and restrict the opportunities for both
one-way and two-way communication.
</p>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14049" title="Abstract">arXiv:2311.14049</a> (cross-list from eess.IV) [<a href="/pdf/2311.14049" title="Download PDF">pdf</a>, <a href="/format/2311.14049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessment of Deep Learning Segmentation for Real-Time Free-Breathing  Cardiac Magnetic Resonance Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Schilling%2C+M">Martin Schilling</a>, 
<a href="/search/eess?searchtype=author&query=Unterberg-Buchwald%2C+C">Christina Unterberg-Buchwald</a>, 
<a href="/search/eess?searchtype=author&query=Lotz%2C+J">Joachim Lotz</a>, 
<a href="/search/eess?searchtype=author&query=Uecker%2C+M">Martin Uecker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> *These authors contributed equally to this work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In recent years, a variety of deep learning networks for cardiac MRI (CMR)
segmentation have been developed and analyzed. However, nearly all of them are
focused on cine CMR under breathold. In this work, accuracy of deep learning
methods is assessed for volumetric analysis (via segmentation) of the left
ventricle in real-time free-breathing CMR at rest and under exercise stress.
Data from healthy volunteers (n=15) for cine and real-time free-breathing CMR
were analyzed retrospectively. Segmentations of a commercial software (comDL)
and a freely available neural network (nnU-Net), were compared to a reference
created via the manual correction of comDL segmentation. Segmentation of left
ventricular endocardium (LV), left ventricular myocardium (MYO), and right
ventricle (RV) is evaluated for both end-systolic and end-diastolic phases and
analyzed with Dice's coefficient (DC). The volumetric analysis includes LV
end-diastolic volume (EDV), LV end-systolic volume (ESV), and LV ejection
fraction (EF). For cine CMR, nnU-Net and comDL achieve a DC above 0.95 for LV
and 0.9 for MYO, and RV. For real-time CMR, the accuracy of nnU-Net exceeds
that of comDL overall. For real-time CMR at rest, nnU-Net achieves a DC of 0.94
for LV, 0.89 for MYO, and 0.90 for RV; mean absolute differences between
nnU-Net and reference are 2.9mL for EDV, 3.5mL for ESV and 2.6% for EF. For
real-time CMR under exercise stress, nnU-Net achieves a DC of 0.92 for LV, 0.85
for MYO, and 0.83 for RV; mean absolute differences between nnU-Net and
reference are 11.4mL for EDV, 2.9mL for ESV and 3.6% for EF. Deep learning
methods designed or trained for cine CMR segmentation can perform well on
real-time CMR. For real-time free-breathing CMR at rest, the performance of
deep learning methods is comparable to inter-observer variability in cine CMR
and is usable or fully automatic segmentation.
</p>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14086" title="Abstract">arXiv:2311.14086</a> (cross-list from eess.IV) [<a href="/pdf/2311.14086" title="Download PDF">pdf</a>, <a href="/format/2311.14086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Brain MRI Screening Tool with Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Stoklasa%2C+R">Roman Stoklasa</a>, 
<a href="/search/eess?searchtype=author&query=Stathopoulos%2C+I">Ioannis Stathopoulos</a>, 
<a href="/search/eess?searchtype=author&query=Karavasilis%2C+E">Efstratios Karavasilis</a>, 
<a href="/search/eess?searchtype=author&query=Efstathopoulos%2C+E">Efstathios Efstathopoulos</a>, 
<a href="/search/eess?searchtype=author&query=Dost%C3%A1l%2C+M">Marek Dost&#xe1;l</a>, 
<a href="/search/eess?searchtype=author&query=Ke%C5%99kovsk%C3%BD%2C+M">Milo&#x161; Ke&#x159;kovsk&#xfd;</a>, 
<a href="/search/eess?searchtype=author&query=Kozubek%2C+M">Michal Kozubek</a>, 
<a href="/search/eess?searchtype=author&query=Serio%2C+L">Luigi Serio</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures. Submitted to ISBI 2024 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">In clinical practice, we often see significant delays between MRI scans and
the diagnosis made by radiologists, even for severe cases. In some cases, this
may be caused by the lack of additional information and clues, so even the
severe cases need to wait in the queue for diagnosis. This can be avoided if
there is an automatic software tool, which would supplement additional
information, alerting radiologists that the particular patient may be a severe
case.
<br />We are presenting an automatic brain MRI Screening Tool and we are
demonstrating its capabilities for detecting tumor-like pathologies. It is the
first version on the path toward a robust multi-pathology screening solution.
The tool supports Federated Learning, so multiple institutions may contribute
to the model without disclosing their private data.
</p>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14123" title="Abstract">arXiv:2311.14123</a> (cross-list from quant-ph) [<a href="/pdf/2311.14123" title="Download PDF">pdf</a>, <a href="/ps/2311.14123" title="Download PostScript">ps</a>, <a href="/format/2311.14123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exponential Quantum Space Advantage for Approximating Maximum Directed  Cut in the Streaming Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Kallaugher%2C+J">John Kallaugher</a>, 
<a href="/search/quant-ph?searchtype=author&query=Parekh%2C+O">Ojas Parekh</a>, 
<a href="/search/quant-ph?searchtype=author&query=Voronova%2C+N">Nadezhda Voronova</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">While the search for quantum advantage typically focuses on speedups in
execution time, quantum algorithms also offer the potential for advantage in
space complexity. Previous work has shown such advantages for data stream
problems, in which elements arrive and must be processed sequentially without
random access, but these have been restricted to specially-constructed problems
[Le Gall, SPAA `06] or polynomial advantage [Kallaugher, FOCS `21]. We show an
exponential quantum space advantage for the maximum directed cut problem. This
is the first known exponential quantum space advantage for any natural
streaming problem. This also constitutes the first unconditional exponential
quantum resource advantage for approximating a discrete optimization problem in
any setting.
<br />Our quantum streaming algorithm $0.4844$-approximates the value of the
largest directed cut in a graph stream with $n$ vertices using polylog$(n)$
space, while previous work by Chou, Golovnev, and Velusamy [FOCS '20] implies
that obtaining an approximation ratio better than $4/9 \approx 0.4444$ requires
$\Omega(\sqrt{n})$ space for any classical streaming algorithm. Our result is
based on a recent $\widetilde{\text{O}}(\sqrt{n})$ space classical streaming
approach by Saxena, Singer, Sudan, and Velusamy [FOCS '23], with an additional
improvement in the approximation ratio due to recent work by Singer [APPROX
'23].
</p>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14138" title="Abstract">arXiv:2311.14138</a> (cross-list from physics.comp-ph) [<a href="/pdf/2311.14138" title="Download PDF">pdf</a>, <a href="/ps/2311.14138" title="Download PostScript">ps</a>, <a href="/format/2311.14138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A symmetric Gauss-Seidel method for the steady-state Boltzmann equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Yin%2C+T">Tianai Yin</a>, 
<a href="/search/physics?searchtype=author&query=Cai%2C+Z">Zhenning Cai</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+Y">Yanli Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">We introduce numerical solvers for the steady-state Boltzmann equation based
on the symmetric Gauss-Seidel (SGS) method. Due to the quadratic collision
operator in the Boltzmann equation, the SGS method requires solving a nonlinear
system on each grid cell, and we consider two methods, namely Newton's method
and the fixed-point iteration, in our numerical tests. For small Knudsen
numbers, our method has an efficiency between the classical source iteration
and the modern generalized synthetic iterative scheme, and the complexity of
its implementation is closer to the source iteration. A variety of numerical
tests are carried out to demonstrate its performance, and it is concluded that
the proposed method is suitable for applications with moderate to large Knudsen
numbers.
</p>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14148" title="Abstract">arXiv:2311.14148</a> (cross-list from eess.IV) [<a href="/pdf/2311.14148" title="Download PDF">pdf</a>, <a href="/format/2311.14148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated 3D Tumor Segmentation using Temporal Cubic PatchGAN (TCuP-GAN)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mantha%2C+K+B">Kameswara Bharadwaj Mantha</a>, 
<a href="/search/eess?searchtype=author&query=Sankar%2C+R">Ramanakumar Sankar</a>, 
<a href="/search/eess?searchtype=author&query=Fortson%2C+L">Lucy Fortson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted as a short paper to the proceedings of the 2023 Brain Tumor Segmentation (BraTS) Challenge
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Development of robust general purpose 3D segmentation frameworks using the
latest deep learning techniques is one of the active topics in various
bio-medical domains. In this work, we introduce Temporal Cubic PatchGAN
(TCuP-GAN), a volume-to-volume translational model that marries the concepts of
a generative feature learning framework with Convolutional Long Short-Term
Memory Networks (LSTMs), for the task of 3D segmentation. We demonstrate the
capabilities of our TCuP-GAN on the data from four segmentation challenges
(Adult Glioma, Meningioma, Pediatric Tumors, and Sub-Saharan Africa subset)
featured within the 2023 Brain Tumor Segmentation (BraTS) Challenge and
quantify its performance using LesionWise Dice similarity and $95\%$ Hausdorff
Distance metrics. We demonstrate the successful learning of our framework to
predict robust multi-class segmentation masks across all the challenges. This
benchmarking work serves as a stepping stone for future efforts towards
applying TCuP-GAN on other multi-class tasks such as multi-organelle
segmentation in electron microscopy imaging.
</p>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14160" title="Abstract">arXiv:2311.14160</a> (cross-list from hep-ex) [<a href="/pdf/2311.14160" title="Download PDF">pdf</a>, <a href="/format/2311.14160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient and Robust Jet Tagging at the LHC with Knowledge Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ex?searchtype=author&query=Liu%2C+R">Ryan Liu</a>, 
<a href="/search/hep-ex?searchtype=author&query=Gandrakota%2C+A">Abhijith Gandrakota</a>, 
<a href="/search/hep-ex?searchtype=author&query=Ngadiuba%2C+J">Jennifer Ngadiuba</a>, 
<a href="/search/hep-ex?searchtype=author&query=Spiropulu%2C+M">Maria Spiropulu</a>, 
<a href="/search/hep-ex?searchtype=author&query=Vlimant%2C+J">Jean-Roch Vlimant</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures, accepted at the Machine Learning and the Physical Sciences Workshop, NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Experiment (hep-ex)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The challenging environment of real-time data processing systems at the Large
Hadron Collider (LHC) strictly limits the computational complexity of
algorithms that can be deployed. For deep learning models, this implies that
only models with low computational complexity that have weak inductive bias are
feasible. To address this issue, we utilize knowledge distillation to leverage
both the performance of large models and the reduced computational complexity
of small ones. In this paper, we present an implementation of knowledge
distillation, demonstrating an overall boost in the student models' performance
for the task of classifying jets at the LHC. Furthermore, by using a teacher
model with a strong inductive bias of Lorentz symmetry, we show that we can
induce the same inductive bias in the student model which leads to better
robustness against arbitrary Lorentz boost.
</p>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14164" title="Abstract">arXiv:2311.14164</a> (cross-list from quant-ph) [<a href="/pdf/2311.14164" title="Download PDF">pdf</a>, <a href="/format/2311.14164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Circuit Mapping: Leveraging the Full Spectrum of Computational  Capabilities of Neutral Atom Quantum Computers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Schmid%2C+L">Ludwig Schmid</a>, 
<a href="/search/quant-ph?searchtype=author&query=Park%2C+S">Sunghye Park</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kang%2C+S">Seokhyeong Kang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wille%2C+R">Robert Wille</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Quantum computing based on Neutral Atoms (NAs) provides a wide range of
computational capabilities, encompassing high-fidelity long-range interactions
with native multi-qubit gates, and the ability to shuttle arrays of qubits.
While previously these capabilities have been studied individually, we propose
the first approach of a fast hybrid compiler to perform circuit mapping and
routing based on both high-fidelity gate interactions and qubit shuttling. We
delve into the intricacies of the compilation process when combining multiple
capabilities and present effective solutions to address resulting challenges.
The final compilation strategy is then showcased across various hardware
settings, revealing its versatility, and highlighting potential fidelity
enhancements achieved through the strategic utilization of combined gate- and
shuttling-based routing. With the additional multi-qubit gate support for both
routing capabilities, the proposed approach is able to take advantage of the
full spectrum of computational capabilities offered by NAs.
</p>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14168" title="Abstract">arXiv:2311.14168</a> (cross-list from math.OC) [<a href="/pdf/2311.14168" title="Download PDF">pdf</a>, <a href="/format/2311.14168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Policy Learning for Linear Quadratic Regulator with Entropy  Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Guo%2C+X">Xin Guo</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+X">Xinyu Li</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+R">Renyuan Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper proposes and analyzes two new policy learning methods: regularized
policy gradient (RPG) and iterative policy optimization (IPO), for a class of
discounted linear-quadratic regulator (LQR) problems over an infinite time
horizon with entropy regularization. Assuming access to the exact policy
evaluation, both proposed approaches are proved to converge linearly in finding
optimal policies of the regularized LQR. Moreover, the IPO method can achieve a
super-linear convergence rate once it enters a local region around the optimal
policy. Finally, when the optimal policy from a well-understood environment in
an RL problem is appropriately transferred as the initial policy to an RL
problem with an unknown environment, the IPO method is shown to enable a
super-linear convergence rate if the latter is sufficiently close to the
former. The performances of these proposed algorithms are supported by
numerical examples.
</p>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14197" title="Abstract">arXiv:2311.14197</a> (cross-list from eess.IV) [<a href="/pdf/2311.14197" title="Download PDF">pdf</a>, <a href="/ps/2311.14197" title="Download PostScript">ps</a>, <a href="/format/2311.14197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing mTBI Diagnosis with Residual Triplet Convolutional Neural  Network Using 3D CT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ellethy%2C+H">Hanem Ellethy</a>, 
<a href="/search/eess?searchtype=author&query=Chandra%2C+S+S">Shekhar S. Chandra</a>, 
<a href="/search/eess?searchtype=author&query=Vegh%2C+V">Viktor Vegh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Mild Traumatic Brain Injury (mTBI) is a common and challenging condition to
diagnose accurately. Timely and precise diagnosis is essential for effective
treatment and improved patient outcomes. Traditional diagnostic methods for
mTBI often have limitations in terms of accuracy and sensitivity. In this
study, we introduce an innovative approach to enhance mTBI diagnosis using 3D
Computed Tomography (CT) images and a metric learning technique trained with
triplet loss. To address these challenges, we propose a Residual Triplet
Convolutional Neural Network (RTCNN) model to distinguish between mTBI cases
and healthy ones by embedding 3D CT scans into a feature space. The triplet
loss function maximizes the margin between similar and dissimilar image pairs,
optimizing feature representations. This facilitates better context placement
of individual cases, aids informed decision-making, and has the potential to
improve patient outcomes. Our RTCNN model shows promising performance in mTBI
diagnosis, achieving an average accuracy of 94.3%, a sensitivity of 94.1%, and
a specificity of 95.2%, as confirmed through a five-fold cross-validation.
Importantly, when compared to the conventional Residual Convolutional Neural
Network (RCNN) model, the RTCNN exhibits a significant improvement, showcasing
a remarkable 22.5% increase in specificity, a notable 16.2% boost in accuracy,
and an 11.3% enhancement in sensitivity. Moreover, RTCNN requires lower memory
resources, making it not only highly effective but also resource-efficient in
minimizing false positives while maximizing its diagnostic accuracy in
distinguishing normal CT scans from mTBI cases. The quantitative performance
metrics provided and utilization of occlusion sensitivity maps to visually
explain the model's decision-making process further enhance the
interpretability and transparency of our approach.
</p>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14202" title="Abstract">arXiv:2311.14202</a> (cross-list from math.OC) [<a href="/pdf/2311.14202" title="Download PDF">pdf</a>, <a href="/ps/2311.14202" title="Download PostScript">ps</a>, <a href="/format/2311.14202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eigenstructure perturbations for a class of Hamiltonian matrices and  solutions of related Riccati inequalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mehrmann%2C+V">Volker Mehrmann</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+H">Hongguo Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">The characterization of the solution set for a class of algebraic Riccati
inequalities is studied. This class arises in the passivity analysis of linear
time invariant control systems. Eigenvalue perturbation theory for the
Hamiltonian matrix associated with the Riccati inequality is used to analyze
the extremal points of the solution set.
</p>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14212" title="Abstract">arXiv:2311.14212</a> (cross-list from stat.ML) [<a href="/pdf/2311.14212" title="Download PDF">pdf</a>, <a href="/format/2311.14212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Annotation Sensitivity: Training Data Collection Methods Affect Model  Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Kern%2C+C">Christoph Kern</a>, 
<a href="/search/stat?searchtype=author&query=Eckman%2C+S">Stephanie Eckman</a>, 
<a href="/search/stat?searchtype=author&query=Beck%2C+J">Jacob Beck</a>, 
<a href="/search/stat?searchtype=author&query=Chew%2C+R">Rob Chew</a>, 
<a href="/search/stat?searchtype=author&query=Ma%2C+B">Bolei Ma</a>, 
<a href="/search/stat?searchtype=author&query=Kreuter%2C+F">Frauke Kreuter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">When training data are collected from human annotators, the design of the
annotation instrument, the instructions given to annotators, the
characteristics of the annotators, and their interactions can impact training
data. This study demonstrates that design choices made when creating an
annotation instrument also impact the models trained on the resulting
annotations.
<br />We introduce the term annotation sensitivity to refer to the impact of
annotation data collection methods on the annotations themselves and on
downstream model performance and predictions.
<br />We collect annotations of hate speech and offensive language in five
experimental conditions of an annotation instrument, randomly assigning
annotators to conditions. We then fine-tune BERT models on each of the five
resulting datasets and evaluate model performance on a holdout portion of each
condition. We find considerable differences between the conditions for 1) the
share of hate speech/offensive language annotations, 2) model performance, 3)
model predictions, and 4) model learning curves.
<br />Our results emphasize the crucial role played by the annotation instrument
which has received little attention in the machine learning literature. We call
for additional research into how and why the instrument impacts the annotations
to inform the development of best practices in instrument design.
</p>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14220" title="Abstract">arXiv:2311.14220</a> (cross-list from stat.ME) [<a href="/pdf/2311.14220" title="Download PDF">pdf</a>, <a href="/format/2311.14220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assumption-lean and Data-adaptive Post-Prediction Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Miao%2C+J">Jiacheng Miao</a>, 
<a href="/search/stat?searchtype=author&query=Miao%2C+X">Xinran Miao</a>, 
<a href="/search/stat?searchtype=author&query=Wu%2C+Y">Yixuan Wu</a>, 
<a href="/search/stat?searchtype=author&query=Zhao%2C+J">Jiwei Zhao</a>, 
<a href="/search/stat?searchtype=author&query=Lu%2C+Q">Qiongshi Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">A primary challenge facing modern scientific research is the limited
availability of gold-standard data which can be both costly and labor-intensive
to obtain. With the rapid development of machine learning (ML), scientists have
relied on ML algorithms to predict these gold-standard outcomes with easily
obtained covariates. However, these predicted outcomes are often used directly
in subsequent statistical analyses, ignoring imprecision and heterogeneity
introduced by the prediction procedure. This will likely result in false
positive findings and invalid scientific conclusions. In this work, we
introduce an assumption-lean and data-adaptive Post-Prediction Inference
(POP-Inf) procedure that allows valid and powerful inference based on
ML-predicted outcomes. Its "assumption-lean" property guarantees reliable
statistical inference without assumptions on the ML-prediction, for a wide
range of statistical quantities. Its "data-adaptive'" feature guarantees an
efficiency gain over existing post-prediction inference methods, regardless of
the accuracy of ML-prediction. We demonstrate the superiority and applicability
of our method through simulations and large-scale genomic data.
</p>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14227" title="Abstract">arXiv:2311.14227</a> (cross-list from eess.IV) [<a href="/pdf/2311.14227" title="Download PDF">pdf</a>, <a href="/format/2311.14227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust and Interpretable COVID-19 Diagnosis on Chest X-ray Images using  Adversarial Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yang%2C+K">Karina Yang</a>, 
<a href="/search/eess?searchtype=author&query=Bennett%2C+A">Alexis Bennett</a>, 
<a href="/search/eess?searchtype=author&query=Duncan%2C+D">Dominique Duncan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">The novel 2019 Coronavirus disease (COVID-19) global pandemic is a defining
health crisis. Recent efforts have been increasingly directed towards achieving
quick and accurate detection of COVID-19 across symptomatic patients to
mitigate the intensity and spread of the disease. Artificial intelligence (AI)
algorithms applied to chest X-ray (CXR) images have emerged as promising
diagnostic tools, and previous work has demonstrated impressive classification
performances. However, such methods have faced criticisms from physicians due
to their black-box reasoning process and unpredictable nature. In contrast to
professional radiologist diagnosis, AI systems often lack generalizability,
explainability, and robustness in the clinical decision making process. In our
work, we address these issues by first proposing an extensive baseline study,
training and evaluating 21 convolutional neural network (CNN) models on a
diverse set of 33,000+ CXR images to classify between healthy, COVID-19, and
non-COVID-19 pneumonia CXRs. Our resulting models achieved a 3-way
classification accuracy, recall, and precision of up to 97.03\%, 97.97\%, and
99.95\%, respectively. Next, we investigate the effectiveness of adversarial
training on model robustness and explainability via Gradient-weighted Class
Activation Mapping (Grad-CAM) heatmaps. We find that adversarially trained
models not only significantly outperform their standard counterparts on
classifying perturbed images, but also yield saliency maps that 1) better
specify clinically relevant features, 2) are robust against extraneous
artifacts, and 3) agree considerably more with expert radiologist findings.
</p>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14280" title="Abstract">arXiv:2311.14280</a> (cross-list from eess.IV) [<a href="/pdf/2311.14280" title="Download PDF">pdf</a>, <a href="/format/2311.14280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Diffusion Prior Enhanced Deep Unfolding for Spectral Image  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wu%2C+Z">Zongliang Wu</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+R">Ruiying Lu</a>, 
<a href="/search/eess?searchtype=author&query=Fu%2C+Y">Ying Fu</a>, 
<a href="/search/eess?searchtype=author&query=Yuan%2C+X">Xin Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Snapshot compressive spectral imaging reconstruction aims to reconstruct
three-dimensional spatial-spectral images from a single-shot two-dimensional
compressed measurement. Existing state-of-the-art methods are mostly based on
deep unfolding structures but have intrinsic performance bottlenecks: $i$) the
ill-posed problem of dealing with heavily degraded measurement, and $ii$) the
regression loss-based reconstruction models being prone to recover images with
few details. In this paper, we introduce a generative model, namely the latent
diffusion model (LDM), to generate degradation-free prior to enhance the
regression-based deep unfolding method. Furthermore, to overcome the large
computational cost challenge in LDM, we propose a lightweight model to generate
knowledge priors in deep unfolding denoiser, and integrate these priors to
guide the reconstruction process for compensating high-quality spectral signal
details. Numeric and visual comparisons on synthetic and real-world datasets
illustrate the superiority of our proposed method in both reconstruction
quality and computational efficiency. Code will be released.
</p>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14303" title="Abstract">arXiv:2311.14303</a> (cross-list from astro-ph.IM) [<a href="/pdf/2311.14303" title="Download PDF">pdf</a>, <a href="/format/2311.14303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RFI Detection with Spiking Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Pritchard%2C+N+J">Nicholas J. Pritchard</a>, 
<a href="/search/astro-ph?searchtype=author&query=Wicenec%2C+A">Andreas Wicenec</a>, 
<a href="/search/astro-ph?searchtype=author&query=Bennamoun%2C+M">Mohammed Bennamoun</a>, 
<a href="/search/astro-ph?searchtype=author&query=Dodson%2C+R">Richard Dodson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Radio Frequency Interference (RFI) detection and mitigation is critical for
enabling and maximising the scientific output of radio telescopes. The
emergence of machine learning methods capable of handling large datasets has
led to their application in radio astronomy, particularly in RFI detection.
Spiking Neural Networks (SNNs), inspired by biological systems, are well-suited
for processing spatio-temporal data. This study introduces the first
application of SNNs to an astronomical data-processing task, specifically RFI
detection. We adapt the nearest-latent-neighbours (NLN) algorithm and
auto-encoder architecture proposed by previous authors to SNN execution by
direct ANN2SNN conversion, enabling simplified downstream RFI detection by
sampling the naturally varying latent space from the internal spiking neurons.
We evaluate performance with the simulated HERA telescope and hand-labelled
LOFAR dataset that the original authors provided. We additionally evaluate
performance with a new MeerKAT-inspired simulation dataset. This dataset
focuses on satellite-based RFI, an increasingly important class of RFI and is,
therefore, an additional contribution. Our SNN approach remains competitive
with the original NLN algorithm and AOFlagger in AUROC, AUPRC and F1 scores for
the HERA dataset but exhibits difficulty in the LOFAR and MeerKAT datasets.
However, our method maintains this performance while completely removing the
compute and memory-intense latent sampling step found in NLN. This work
demonstrates the viability of SNNs as a promising avenue for
machine-learning-based RFI detection in radio telescopes by establishing a
minimal performance baseline on traditional and nascent satellite-based RFI
sources and is the first work to our knowledge to apply SNNs in astronomy.
</p>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14316" title="Abstract">arXiv:2311.14316</a> (cross-list from eess.SP) [<a href="/pdf/2311.14316" title="Download PDF">pdf</a>, <a href="/format/2311.14316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Windformer:Bi-Directional Long-Distance Spatio-Temporal Network For Wind  Speed Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xuewei Li</a>, 
<a href="/search/eess?searchtype=author&query=Shang%2C+Z">Zewen Shang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Z">Zhiqiang Liu</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+J">Jian Yu</a>, 
<a href="/search/eess?searchtype=author&query=Xiong%2C+W">Wei Xiong</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+M">Mei Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Wind speed prediction is critical to the management of wind power generation.
Due to the large range of wind speed fluctuations and wake effect, there may
also be strong correlations between long-distance wind turbines. This
difficult-to-extract feature has become a bottleneck for improving accuracy.
History and future time information includes the trend of airflow changes,
whether this dynamic information can be utilized will also affect the
prediction effect. In response to the above problems, this paper proposes
Windformer. First, Windformer divides the wind turbine cluster into multiple
non-overlapping windows and calculates correlations inside the windows, then
shifts the windows partially to provide connectivity between windows, and
finally fuses multi-channel features based on detailed and global information.
To dynamically model the change process of wind speed, this paper extracts time
series in both history and future directions simultaneously. Compared with
other current-advanced methods, the Mean Square Error (MSE) of Windformer is
reduced by 0.5\% to 15\% on two datasets from NERL.
</p>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14326" title="Abstract">arXiv:2311.14326</a> (cross-list from physics.soc-ph) [<a href="/pdf/2311.14326" title="Download PDF">pdf</a>, <a href="/format/2311.14326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal link prediction methods based on behavioral synchrony
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Duan%2C+Y">Yueran Duan</a>, 
<a href="/search/physics?searchtype=author&query=Guan%2C+Q">Qing Guan</a>, 
<a href="/search/physics?searchtype=author&query=Holme%2C+P">Petter Holme</a>, 
<a href="/search/physics?searchtype=author&query=Yang%2C+Y">Yacheng Yang</a>, 
<a href="/search/physics?searchtype=author&query=Guan%2C+W">Wei Guan</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Temporal Network Theory (2nd ed.), Petter Holme and Jari Saramaki,
  eds., (Springer, Cham, 2023), pp. 381-402
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Link prediction -- to identify potential missing or spurious links in
temporal network data -- has typically been based on local structures, ignoring
long-term temporal effects. In this chapter, we propose link-prediction methods
based on agents' behavioral synchrony. Since synchronous behavior signals
similarity and similar agents are known to have a tendency to connect in the
future, behavioral synchrony could function as a precursor of contacts and,
thus, as a basis for link prediction. We use four data sets of different sizes
to test the algorithm's accuracy. We compare the results with traditional link
prediction models involving both static and temporal networks. Among our
findings, we note that the proposed algorithm is superior to conventional
methods, with the average accuracy improved by approximately 2% - 5%. We
identify different evolution patterns of four network topologies -- a proximity
network, a communication network, transportation data, and a collaboration
network. We found that: (1) timescale similarity contributes more to the
evolution of the human contact network and the human communication network; (2)
such contribution is not observed through a transportation network whose
evolution pattern is more dependent on network structure than on the behavior
of regional agents; (3) both timescale similarity and local structural
similarity contribute to the collaboration network.
</p>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14344" title="Abstract">arXiv:2311.14344</a> (cross-list from quant-ph) [<a href="/pdf/2311.14344" title="Download PDF">pdf</a>, <a href="/format/2311.14344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Traveling Salesman Problem from a Tensor Networks Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Ali%2C+A+M">Alejandro Mata Ali</a>, 
<a href="/search/quant-ph?searchtype=author&query=Delgado%2C+I+P">I&#xf1;igo Perez Delgado</a>, 
<a href="/search/quant-ph?searchtype=author&query=de+Leceta%2C+A+M+F">Aitor Moreno Fdez. de Leceta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">We present a novel quantum-inspired algorithm for solving the Traveling
Salesman Problem (TSP) and some of its variations using tensor networks. This
approach consists on the simulated initialization of a quantum system with
superposition of all possible combinations, an imaginary time evolution, a
projection, and lastly a partial trace to search for solutions. We adapt it to
different generalizations of the TSP and apply it to the job reassignment
problem, a real productive industrial case.
</p>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14359" title="Abstract">arXiv:2311.14359</a> (cross-list from stat.ML) [<a href="/pdf/2311.14359" title="Download PDF">pdf</a>, <a href="/format/2311.14359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Thompson sampling for zero-inflated count outcomes with an application  to the Drink Less mobile health study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Liu%2C+X">Xueqing Liu</a>, 
<a href="/search/stat?searchtype=author&query=Deliu%2C+N">Nina Deliu</a>, 
<a href="/search/stat?searchtype=author&query=Chakraborty%2C+T">Tanujit Chakraborty</a>, 
<a href="/search/stat?searchtype=author&query=Bell%2C+L">Lauren Bell</a>, 
<a href="/search/stat?searchtype=author&query=Chakraborty%2C+B">Bibhas Chakraborty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Applications (stat.AP)

</div>
<p class="mathjax">Mobile health (mHealth) technologies aim to improve distal outcomes, such as
clinical conditions, by optimizing proximal outcomes through just-in-time
adaptive interventions. Contextual bandits provide a suitable framework for
customizing such interventions according to individual time-varying contexts,
intending to maximize cumulative proximal outcomes. However, unique challenges
such as modeling count outcomes within bandit frameworks have hindered the
widespread application of contextual bandits to mHealth studies. The current
work addresses this challenge by leveraging count data models into online
decision-making approaches. Specifically, we combine four common offline count
data models (Poisson, negative binomial, zero-inflated Poisson, and
zero-inflated negative binomial regressions) with Thompson sampling, a popular
contextual bandit algorithm. The proposed algorithms are motivated by and
evaluated on a real dataset from the Drink Less trial, where they are shown to
improve user engagement with the mHealth system. The proposed methods are
further evaluated on simulated data, achieving improvement in maximizing
cumulative proximal outcomes over existing algorithms. Theoretical results on
regret bounds are also derived. A user-friendly R package countts that
implements the proposed methods for assessing contextual bandit algorithms is
made publicly available at https://cran.r-project.org/web/packages/countts.
</p>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14364" title="Abstract">arXiv:2311.14364</a> (cross-list from math.AT) [<a href="/pdf/2311.14364" title="Download PDF">pdf</a>, <a href="/format/2311.14364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Depth Poset of a Filtered Lefschetz Complex
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Edelsbrunner%2C+H">Herbert Edelsbrunner</a>, 
<a href="/search/math?searchtype=author&query=Mrozek%2C+M">Marian Mrozek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Topology (math.AT)</span>; Computational Geometry (cs.CG); Dynamical Systems (math.DS)

</div>
<p class="mathjax">Taking a discrete approach to functions and dynamical systems, this paper
integrates the combinatorial gradients in Forman's discrete Morse theory with
persistent homology to forge a unified approach to function simplification. The
two crucial ingredients in this effort are the Lefschetz complex, which focuses
on the homology at the expense of the geometry of the cells, and the shallow
pairs, which are birth-death pairs that can double as vectors in discrete Morse
theory. The main new concept is the depth poset on the birth-death pairs, which
captures all simplifications achieved through canceling shallow pairs. One of
its linear extensions is the ordering by persistence.
</p>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14414" title="Abstract">arXiv:2311.14414</a> (cross-list from eess.IV) [<a href="/pdf/2311.14414" title="Download PDF">pdf</a>, <a href="/format/2311.14414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deformable multi-modal image registration for the correlation between  optical measurements and histology images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Feenstra%2C+L">Lianne Feenstra</a>, 
<a href="/search/eess?searchtype=author&query=Lambregts%2C+M">Maud Lambregts</a>, 
<a href="/search/eess?searchtype=author&query=Ruers%2C+T+J+M">Theo J.M Ruers</a>, 
<a href="/search/eess?searchtype=author&query=Dashtbozorg%2C+B">Behdad Dashtbozorg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The correlation of optical measurements with a correct pathology label is
often hampered by imprecise registration caused by deformations in histology
images. This study explores an automated multi-modal image registration
technique utilizing deep learning principles to align snapshot breast specimen
images with corresponding histology images. The input images, acquired through
different modalities, present challenges due to variations in intensities and
structural visibility, making linear assumptions inappropriate. An unsupervised
and supervised learning approach, based on the VoxelMorph model, was explored,
making use of a dataset with manually registered images used as ground truth.
Evaluation metrics, including Dice scores and mutual information, reveal that
the unsupervised model outperforms the supervised (and manual approach)
significantly, achieving superior image alignment. This automated registration
approach holds promise for improving the validation of optical technologies by
minimizing human errors and inconsistencies associated with manual
registration.
</p>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14427" title="Abstract">arXiv:2311.14427</a> (cross-list from math.AT) [<a href="/pdf/2311.14427" title="Download PDF">pdf</a>, <a href="/format/2311.14427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disentangling the Spectral Properties of the Hodge Laplacian: Not All  Small Eigenvalues Are Equal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Grande%2C+V+P">Vincent P. Grande</a>, 
<a href="/search/math?searchtype=author&query=Schaub%2C+M+T">Michael T. Schaub</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures, comments welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Topology (math.AT)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The rich spectral information of the graph Laplacian has been instrumental in
graph theory, machine learning, and graph signal processing for applications
such as graph classification, clustering, or eigenmode analysis. Recently, the
Hodge Laplacian has come into focus as a generalisation of the ordinary
Laplacian for higher-order graph models such as simplicial and cellular
complexes. Akin to the traditional analysis of graph Laplacians, many authors
analyse the smallest eigenvalues of the Hodge Laplacian, which are connected to
important topological properties such as homology. However, small eigenvalues
of the Hodge Laplacian can carry different information depending on whether
they are related to curl or gradient eigenmodes, and thus may not be
comparable. We therefore introduce the notion of persistent eigenvector
similarity and provide a method to track individual harmonic, curl, and
gradient eigenvectors/-values through the so-called persistence filtration,
leveraging the full information contained in the Hodge-Laplacian spectrum
across all possible scales of a point cloud. Finally, we use our insights (a)
to introduce a novel form of topological spectral clustering and (b) to
classify edges and higher-order simplices based on their relationship to the
smallest harmonic, curl, and gradient eigenvectors.
</p>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14448" title="Abstract">arXiv:2311.14448</a> (cross-list from eess.IV) [<a href="/pdf/2311.14448" title="Download PDF">pdf</a>, <a href="/format/2311.14448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning for Automatic Strain Quantification in Arrhythmogenic  Right Ventricular Cardiomyopathy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Alvarez-Florez%2C+L">Laura Alvarez-Florez</a>, 
<a href="/search/eess?searchtype=author&query=Sander%2C+J">J&#xf6;rg Sander</a>, 
<a href="/search/eess?searchtype=author&query=Bourfiss%2C+M">Mimount Bourfiss</a>, 
<a href="/search/eess?searchtype=author&query=Tjong%2C+F+V+Y">Fleur V. Y. Tjong</a>, 
<a href="/search/eess?searchtype=author&query=Velthuis%2C+B+K">Birgitta K. Velthuis</a>, 
<a href="/search/eess?searchtype=author&query=I%C5%A1gum%2C+I">Ivana I&#x161;gum</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Statistical Atlases and Computational Modeling of the Heart (STACOM) workshop accepted paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Quantification of cardiac motion with cine Cardiac Magnetic Resonance Imaging
(CMRI) is an integral part of arrhythmogenic right ventricular cardiomyopathy
(ARVC) diagnosis. Yet, the expert evaluation of motion abnormalities with CMRI
is a challenging task. To automatically assess cardiac motion, we register
CMRIs from different time points of the cardiac cycle using Implicit Neural
Representations (INRs) and perform a biomechanically informed regularization
inspired by the myocardial incompressibility assumption. To enhance the
registration performance, our method first rectifies the inter-slice
misalignment inherent to CMRI by performing a rigid registration guided by the
long-axis views, and then increases the through-plane resolution using an
unsupervised deep learning super-resolution approach. Finally, we propose to
synergically combine information from short-axis and 4-chamber long-axis views,
along with an initialization to incorporate information from multiple cardiac
time points. Thereafter, to quantify cardiac motion, we calculate global and
segmental strain over a cardiac cycle and compute the peak strain. The
evaluation of the method is performed on a dataset of cine CMRI scans from 47
ARVC patients and 67 controls. Our results show that inter-slice alignment and
generation of super-resolved volumes combined with joint analysis of the two
cardiac views, notably improves registration performance. Furthermore, the
proposed initialization yields more physiologically plausible registrations.
The significant differences in the peak strain, discerned between the ARVC
patients and healthy controls suggest that automated motion quantification
methods may assist in diagnosis and provide further understanding of
disease-specific alterations of cardiac motion.
</p>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14462" title="Abstract">arXiv:2311.14462</a> (cross-list from eess.IV) [<a href="/pdf/2311.14462" title="Download PDF">pdf</a>, <a href="/format/2311.14462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CT-xCOV: a CT-scan based Explainable Framework for COVid-19 diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Elbouknify%2C+I">Ismail Elbouknify</a>, 
<a href="/search/eess?searchtype=author&query=Bouhoute%2C+A">Afaf Bouhoute</a>, 
<a href="/search/eess?searchtype=author&query=Fardousse%2C+K">Khalid Fardousse</a>, 
<a href="/search/eess?searchtype=author&query=Berrada%2C+I">Ismail Berrada</a>, 
<a href="/search/eess?searchtype=author&query=Badri%2C+A">Abdelmajid Badri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In this work, CT-xCOV, an explainable framework for COVID-19 diagnosis using
Deep Learning (DL) on CT-scans is developed. CT-xCOV adopts an end-to-end
approach from lung segmentation to COVID-19 detection and explanations of the
detection model's prediction. For lung segmentation, we used the well-known
U-Net model. For COVID-19 detection, we compared three different CNN
architectures: a standard CNN, ResNet50, and DenseNet121. After the detection,
visual and textual explanations are provided. For visual explanations, we
applied three different XAI techniques, namely, Grad-Cam, Integrated Gradient
(IG), and LIME. Textual explanations are added by computing the percentage of
infection by lungs. To assess the performance of the used XAI techniques, we
propose a ground-truth-based evaluation method, measuring the similarity
between the visualization outputs and the ground-truth infections. The
performed experiments show that the applied DL models achieved good results.
The U-Net segmentation model achieved a high Dice coefficient (98%). The
performance of our proposed classification model (standard CNN) was validated
using 5-fold cross-validation (acc of 98.40% and f1-score 98.23%). Lastly, the
results of the comparison of XAI techniques show that Grad-Cam gives the best
explanations compared to LIME and IG, by achieving a Dice coefficient of 55%,
on COVID-19 positive scans, compared to 29% and 24% obtained by IG and LIME
respectively. The code and the dataset used in this paper are available in the
GitHub repository [1].
</p>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14473" title="Abstract">arXiv:2311.14473</a> (cross-list from eess.IV) [<a href="/pdf/2311.14473" title="Download PDF">pdf</a>, <a href="/format/2311.14473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Diffusion: Mutual Consistency-Driven Diffusion Model for PET-MRI  Co-Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xie%2C+T">Taofeng Xie</a>, 
<a href="/search/eess?searchtype=author&query=Cui%2C+Z">Zhuo-Xu Cui</a>, 
<a href="/search/eess?searchtype=author&query=Luo%2C+C">Chen Luo</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Huayu Wang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+C">Congcong Liu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yuanzhi Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xuemei Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+Y">Yanjie Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Jin%2C+Q">Qiyu Jin</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+G">Guoqing Chen</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Y">Yihang Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Liang%2C+D">Dong Liang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Haifeng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Positron Emission Tomography and Magnetic Resonance Imaging (PET-MRI) systems
can obtain functional and anatomical scans. PET suffers from a low
signal-to-noise ratio. Meanwhile, the k-space data acquisition process in MRI
is time-consuming. The study aims to accelerate MRI and enhance PET image
quality. Conventional approaches involve the separate reconstruction of each
modality within PET-MRI systems. However, there exists complementary
information among multi-modal images. The complementary information can
contribute to image reconstruction. In this study, we propose a novel PET-MRI
joint reconstruction model employing a mutual consistency-driven diffusion
mode, namely MC-Diffusion. MC-Diffusion learns the joint probability
distribution of PET and MRI for utilizing complementary information. We
conducted a series of contrast experiments about LPLS, Joint ISAT-net and
MC-Diffusion by the ADNI dataset. The results underscore the qualitative and
quantitative improvements achieved by MC-Diffusion, surpassing the
state-of-the-art method.
</p>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14482" title="Abstract">arXiv:2311.14482</a> (cross-list from eess.IV) [<a href="/pdf/2311.14482" title="Download PDF">pdf</a>, <a href="/format/2311.14482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sliding Window FastEdit: A Framework for Lesion Annotation in Whole-body  PET Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hadlich%2C+M">Matthias Hadlich</a>, 
<a href="/search/eess?searchtype=author&query=Marinov%2C+Z">Zdravko Marinov</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+M">Moon Kim</a>, 
<a href="/search/eess?searchtype=author&query=Nasca%2C+E">Enrico Nasca</a>, 
<a href="/search/eess?searchtype=author&query=Kleesiek%2C+J">Jens Kleesiek</a>, 
<a href="/search/eess?searchtype=author&query=Stiefelhagen%2C+R">Rainer Stiefelhagen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Deep learning has revolutionized the accurate segmentation of diseases in
medical imaging. However, achieving such results requires training with
numerous manual voxel annotations. This requirement presents a challenge for
whole-body Positron Emission Tomography (PET) imaging, where lesions are
scattered throughout the body. To tackle this problem, we introduce SW-FastEdit
- an interactive segmentation framework that accelerates the labeling by
utilizing only a few user clicks instead of voxelwise annotations. While prior
interactive models crop or resize PET volumes due to memory constraints, we use
the complete volume with our sliding window-based interactive scheme. Our model
outperforms existing non-sliding window interactive models on the AutoPET
dataset and generalizes to the previously unseen HECKTOR dataset. A user study
revealed that annotators achieve high-quality predictions with only 10 click
iterations and a low perceived NASA-TLX workload. Our framework is implemented
using MONAI Label and is available:
https://github.com/matt3o/AutoPET2-Submission/
</p>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14483" title="Abstract">arXiv:2311.14483</a> (cross-list from eess.AS) [<a href="/pdf/2311.14483" title="Download PDF">pdf</a>, <a href="/format/2311.14483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SER_AMPEL: A multi-source dataset for SER of Italian older adults
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Grossi%2C+A">Alessandra Grossi</a>, 
<a href="/search/eess?searchtype=author&query=Gasparini%2C+F">Francesca Gasparini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 1 Figure, 7 Tables, submitted to ForItAAL 2023 (12{\deg} Forum Italiano Ambient Assisted Living)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Sound (cs.SD)

</div>
<p class="mathjax">In this paper, SER_AMPEL, a multi-source dataset for speech emotion
recognition (SER) is presented. The peculiarity of the dataset is that it is
collected with the aim of providing a reference for speech emotion recognition
in case of Italian older adults. The dataset is collected following different
protocols, in particular considering acted conversations, extracted from movies
and TV series, and recording natural conversations where the emotions are
elicited by proper questions. The evidence of the need for such a dataset
emerges from the analysis of the state of the art. Preliminary considerations
on the critical issues of SER are reported analyzing the classification results
on a subset of the proposed dataset.
</p>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14520" title="Abstract">arXiv:2311.14520</a> (cross-list from math.PR) [<a href="/pdf/2311.14520" title="Download PDF">pdf</a>, <a href="/format/2311.14520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shifted Composition I: Harnack and Reverse Transport Inequalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Altschuler%2C+J+M">Jason M. Altschuler</a>, 
<a href="/search/math?searchtype=author&query=Chewi%2C+S">Sinho Chewi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Information Theory (cs.IT); Analysis of PDEs (math.AP); Functional Analysis (math.FA)

</div>
<p class="mathjax">We formulate a new information-theoretic principle--the shifted composition
rule--which bounds the divergence (e.g., Kullback-Leibler or R\'enyi) between
the laws of two stochastic processes via the introduction of auxiliary shifts.
In this paper, we apply this principle to prove reverse transport inequalities
for diffusions which, by duality, imply F.-Y. Wang's celebrated dimension-free
Harnack inequalities. Our approach bridges continuous-time coupling methods
from geometric analysis with the discrete-time shifted divergence technique
from differential privacy and sampling. It also naturally gives rise to (1) an
alternative continuous-time coupling method based on optimal transport, which
bypasses Girsanov transformations, (2) functional inequalities for
discrete-time processes, and (3) a family of "reverse" Harnack inequalities.
</p>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14549" title="Abstract">arXiv:2311.14549</a> (cross-list from stat.ML) [<a href="/pdf/2311.14549" title="Download PDF">pdf</a>, <a href="/format/2311.14549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FRUITS: Feature Extraction Using Iterated Sums for Time Series  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Diehl%2C+J">Joscha Diehl</a>, 
<a href="/search/stat?searchtype=author&query=Krieg%2C+R">Richard Krieg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce a pipeline for time series classification that extracts features
based on the iterated-sums signature (ISS) and then applies a linear
classifier. These features are intrinsically nonlinear, capture chronological
information, and, under certain settings, are invariant to time-warping. We are
competitive with state-of-the-art methods on the UCR archive, both in terms of
accuracy and speed. We make our code available at
\url{https://github.com/irkri/fruits}.
</p>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14577" title="Abstract">arXiv:2311.14577</a> (cross-list from q-fin.GN) [<a href="/pdf/2311.14577" title="Download PDF">pdf</a>, <a href="/ps/2311.14577" title="Download PostScript">ps</a>, <a href="/format/2311.14577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Failure of P2P Lending Platforms through Machine Learning:  The Case in China
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Yeh%2C+J">Jen-Yin Yeh</a>, 
<a href="/search/q-fin?searchtype=author&query=Chiu%2C+H">Hsin-Yu Chiu</a>, 
<a href="/search/q-fin?searchtype=author&query=Huang%2C+J">Jhih-Huei Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Finance (q-fin.GN)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This study employs machine learning models to predict the failure of
Peer-to-Peer (P2P) lending platforms, specifically in China. By employing the
filter method and wrapper method with forward selection and backward
elimination, we establish a rigorous and practical procedure that ensures the
robustness and importance of variables in predicting platform failures. The
research identifies a set of robust variables that consistently appear in the
feature subsets across different selection methods and models, suggesting their
reliability and relevance in predicting platform failures. The study highlights
that reducing the number of variables in the feature subset leads to an
increase in the false acceptance rate while the performance metrics remain
stable, with an AUC value of approximately 0.96 and an F1 score of around 0.88.
The findings of this research provide significant practical implications for
regulatory authorities and investors operating in the Chinese P2P lending
industry.
</p>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14609" title="Abstract">arXiv:2311.14609</a> (cross-list from stat.ML) [<a href="/pdf/2311.14609" title="Download PDF">pdf</a>, <a href="/ps/2311.14609" title="Download PostScript">ps</a>, <a href="/format/2311.14609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of the expected $L_2$ error of an over-parametrized deep neural  network estimate learned by gradient descent without regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Drews%2C+S">Selina Drews</a>, 
<a href="/search/stat?searchtype=author&query=Kohler%2C+M">Michael Kohler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent results show that estimates defined by over-parametrized deep neural
networks learned by applying gradient descent to a regularized empirical $L_2$
risk are universally consistent and achieve good rates of convergence. In this
paper, we show that the regularization term is not necessary to obtain similar
results. In the case of a suitably chosen initialization of the network, a
suitable number of gradient descent steps, and a suitable step size we show
that an estimate without a regularization term is universally consistent for
bounded predictor variables. Additionally, we show that if the regression
function is H\"older smooth with H\"older exponent $1/2 \leq p \leq 1$, the
$L_2$ error converges to zero with a convergence rate of approximately
$n^{-1/(1+d)}$. Furthermore, in case of an interaction model, where the
regression function consists of a sum of H\"older smooth functions with $d^*$
components, a rate of convergence is derived which does not depend on the input
dimension $d$.
</p>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14639" title="Abstract">arXiv:2311.14639</a> (cross-list from eess.IV) [<a href="/pdf/2311.14639" title="Download PDF">pdf</a>, <a href="/format/2311.14639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised high-throughput segmentation of cells and cell nuclei in  quantitative phase images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sistermanns%2C+J">Julia Sistermanns</a>, 
<a href="/search/eess?searchtype=author&query=Emken%2C+E">Ellen Emken</a>, 
<a href="/search/eess?searchtype=author&query=Weirich%2C+G">Gregor Weirich</a>, 
<a href="/search/eess?searchtype=author&query=Hayden%2C+O">Oliver Hayden</a>, 
<a href="/search/eess?searchtype=author&query=Utschick%2C+W">Wolfgang Utschick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Cell Behavior (q-bio.CB); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">In the effort to aid cytologic diagnostics by establishing automatic single
cell screening using high throughput digital holographic microscopy for
clinical studies thousands of images and millions of cells are captured. The
bottleneck lies in an automatic, fast, and unsupervised segmentation technique
that does not limit the types of cells which might occur. We propose an
unsupervised multistage method that segments correctly without confusing noise
or reflections with cells and without missing cells that also includes the
detection of relevant inner structures, especially the cell nucleus in the
unstained cell. In an effort to make the information reasonable and
interpretable for cytopathologists, we also introduce new cytoplasmic and
nuclear features of potential help for cytologic diagnoses which exploit the
quantitative phase information inherent to the measurement scheme. We show that
the segmentation provides consistently good results over many experiments on
patient samples in a reasonable per cell analysis time.
</p>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14654" title="Abstract">arXiv:2311.14654</a> (cross-list from hep-ph) [<a href="/pdf/2311.14654" title="Download PDF">pdf</a>, <a href="/format/2311.14654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JetLOV: Enhancing Jet Tree Tagging through Neural Network Learning of  Optimal LundNet Variables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ph?searchtype=author&query=Diaz%2C+M+A">Mauricio A. Diaz</a>, 
<a href="/search/hep-ph?searchtype=author&query=Cerro%2C+G">Giorgio Cerro</a>, 
<a href="/search/hep-ph?searchtype=author&query=Chaplais%2C+J">Jacan Chaplais</a>, 
<a href="/search/hep-ph?searchtype=author&query=Dasmahapatra%2C+S">Srinandan Dasmahapatra</a>, 
<a href="/search/hep-ph?searchtype=author&query=Moretti%2C+S">Stefano Moretti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the NeurIPS 2023 workshop: Machine Learning and the Physical Sciences
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Phenomenology (hep-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Machine learning has played a pivotal role in advancing physics, with deep
learning notably contributing to solving complex classification problems such
as jet tagging in the field of jet physics. In this experiment, we aim to
harness the full potential of neural networks while acknowledging that, at
times, we may lose sight of the underlying physics governing these models.
Nevertheless, we demonstrate that we can achieve remarkable results obscuring
physics knowledge and relying completely on the model's outcome. We introduce
JetLOV, a composite comprising two models: a straightforward multilayer
perceptron (MLP) and the well-established LundNet. Our study reveals that we
can attain comparable jet tagging performance without relying on the
pre-computed LundNet variables. Instead, we allow the network to autonomously
learn an entirely new set of variables, devoid of a priori knowledge of the
underlying physics. These findings hold promise, particularly in addressing the
issue of model dependence, which can be mitigated through generalization and
training on diverse data sets.
</p>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14670" title="Abstract">arXiv:2311.14670</a> (cross-list from physics.comp-ph) [<a href="/pdf/2311.14670" title="Download PDF">pdf</a>, <a href="/format/2311.14670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable and accelerated spherical harmonic and Wigner transforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Price%2C+M+A">Matthew A. Price</a>, 
<a href="/search/physics?searchtype=author&query=McEwen%2C+J+D">Jason D. McEwen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 7 figures, code available at <a href="https://github.com/astro-informatics/s2fft">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG)

</div>
<p class="mathjax">Many areas of science and engineering encounter data defined on spherical
manifolds. Modelling and analysis of spherical data often necessitates
spherical harmonic transforms, at high degrees, and increasingly requires
efficient computation of gradients for machine learning or other differentiable
programming tasks. We develop novel algorithmic structures for accelerated and
differentiable computation of generalised Fourier transforms on the sphere
$\mathbb{S}^2$ and rotation group $\text{SO}(3)$, i.e. spherical harmonic and
Wigner transforms, respectively. We present a recursive algorithm for the
calculation of Wigner $d$-functions that is both stable to high harmonic
degrees and extremely parallelisable. By tightly coupling this with separable
spherical transforms, we obtain algorithms that exhibit an extremely
parallelisable structure that is well-suited for the high throughput computing
of modern hardware accelerators (e.g. GPUs). We also develop a hybrid automatic
and manual differentiation approach so that gradients can be computed
efficiently. Our algorithms are implemented within the JAX differentiable
programming framework in the S2FFT software code. Numerous samplings of the
sphere are supported, including equiangular and HEALPix sampling. Computational
errors are at the order of machine precision for spherical samplings that admit
a sampling theorem. When benchmarked against alternative C codes we observe up
to a 400-fold acceleration. Furthermore, when distributing over multiple GPUs
we achieve very close to optimal linear scaling with increasing number of GPUs
due to the highly parallelised and balanced nature of our algorithms. Provided
access to sufficiently many GPUs our transforms thus exhibit an unprecedented
effective linear time complexity.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Mon, 27 Nov 23</h3>
<dl>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1805.03682" title="Abstract">arXiv:1805.03682</a> (replaced) [<a href="/pdf/1805.03682" title="Download PDF">pdf</a>, <a href="/format/1805.03682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust-to-Dynamics Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ahmadi%2C+A+A">Amir Ali Ahmadi</a>, 
<a href="/search/math?searchtype=author&query=Gunluk%2C+O">Oktay Gunluk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Major revision
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Data Structures and Algorithms (cs.DS); Systems and Control (eess.SY); Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1902.08767" title="Abstract">arXiv:1902.08767</a> (replaced) [<a href="/pdf/1902.08767" title="Download PDF">pdf</a>, <a href="/format/1902.08767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VoroCrust: Voronoi Meshing Without Clipping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdelkader%2C+A">Ahmed Abdelkader</a>, 
<a href="/search/cs?searchtype=author&query=Bajaj%2C+C+L">Chandrajit L. Bajaj</a>, 
<a href="/search/cs?searchtype=author&query=Ebeida%2C+M+S">Mohamed S. Ebeida</a>, 
<a href="/search/cs?searchtype=author&query=Mahmoud%2C+A+H">Ahmed H. Mahmoud</a>, 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+S+A">Scott A. Mitchell</a>, 
<a href="/search/cs?searchtype=author&query=Owens%2C+J+D">John D. Owens</a>, 
<a href="/search/cs?searchtype=author&query=Rushdi%2C+A+A">Ahmad A. Rushdi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages (including appendix), 18 figures. Version without compressed images available on <a href="https://www.sandia.gov/app/uploads/sites/217/2023/09/VoroCrust.pdf.">this https URL</a> Supplemental materials available on <a href="https://www.sandia.gov/app/uploads/sites/217/2023/09/VoroCrust_supplemental_materials.pdf">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM Transaction on Graphics, Vol. 39, No. 3, Article No. 23 (May
  2020)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computational Geometry (cs.CG)

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1908.09094" title="Abstract">arXiv:1908.09094</a> (replaced) [<a href="/pdf/1908.09094" title="Download PDF">pdf</a>, <a href="/format/1908.09094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal $&#x3b4;$-Correct Best-Arm Selection for Heavy-Tailed  Distributions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+S">Shubhada Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Juneja%2C+S">Sandeep Juneja</a>, 
<a href="/search/cs?searchtype=author&query=Glynn%2C+P">Peter Glynn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated version of work that appeared in ALT 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Probability (math.PR); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2008.09751" title="Abstract">arXiv:2008.09751</a> (replaced) [<a href="/pdf/2008.09751" title="Download PDF">pdf</a>, <a href="/ps/2008.09751" title="Download PostScript">ps</a>, <a href="/format/2008.09751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Tuning Control based on Modified Equivalent-Dynamic-Linearization  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+F">Feilong Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.01208" title="Abstract">arXiv:2103.01208</a> (replaced) [<a href="/pdf/2103.01208" title="Download PDF">pdf</a>, <a href="/format/2103.01208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mind the box: $l_1$-APGD for sparse adversarial attacks on image  classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Croce%2C+F">Francesco Croce</a>, 
<a href="/search/cs?searchtype=author&query=Hein%2C+M">Matthias Hein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In ICML 2021. Fixed typos in Eq. (3) and Eq. (4)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.13192" title="Abstract">arXiv:2103.13192</a> (replaced) [<a href="/pdf/2103.13192" title="Download PDF">pdf</a>, <a href="/format/2103.13192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Preference Learning Based on Sequential Bayesian Optimization with  Pairwise Comparison
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ignatenko%2C+T">Tanya Ignatenko</a>, 
<a href="/search/cs?searchtype=author&query=Kondrashov%2C+K">Kirill Kondrashov</a>, 
<a href="/search/cs?searchtype=author&query=Cox%2C+M">Marco Cox</a>, 
<a href="/search/cs?searchtype=author&query=de+Vries%2C+B">Bert de Vries</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preference learning, Bayesian inference, Intelligent agents; 29 pages, 5 figures (15 with subfigures)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.00542" title="Abstract">arXiv:2109.00542</a> (replaced) [<a href="/pdf/2109.00542" title="Download PDF">pdf</a>, <a href="/format/2109.00542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shared Certificates for Neural Network Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fischer%2C+M">Marc Fischer</a>, 
<a href="/search/cs?searchtype=author&query=Sprecher%2C+C">Christian Sprecher</a>, 
<a href="/search/cs?searchtype=author&query=Dimitrov%2C+D+I">Dimitar I. Dimitrov</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+G">Gagandeep Singh</a>, 
<a href="/search/cs?searchtype=author&query=Vechev%2C+M">Martin Vechev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of our CAV'22 paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.02271" title="Abstract">arXiv:2110.02271</a> (replaced) [<a href="/pdf/2110.02271" title="Download PDF">pdf</a>, <a href="/format/2110.02271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Networked Time Series Prediction with Incomplete Data via Generative  Adversarial Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yichen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Bo Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Haiming Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengtian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+F">Feng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jianqiang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+T">Tao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinbing Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.12616" title="Abstract">arXiv:2110.12616</a> (replaced) [<a href="/pdf/2110.12616" title="Download PDF">pdf</a>, <a href="/format/2110.12616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On query complexity measures and their relations for symmetric functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Mittal%2C+R">Rajat Mittal</a>, 
<a href="/search/quant-ph?searchtype=author&query=Nair%2C+S+S">Sanjay S Nair</a>, 
<a href="/search/quant-ph?searchtype=author&query=Patro%2C+S">Sunayana Patro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.07628" title="Abstract">arXiv:2112.07628</a> (replaced) [<a href="/pdf/2112.07628" title="Download PDF">pdf</a>, <a href="/ps/2112.07628" title="Download PostScript">ps</a>, <a href="/format/2112.07628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training Multi-Layer Over-Parametrized Neural Network in Subquadratic  Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhao Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lichen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruizhe Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ITCS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.00292" title="Abstract">arXiv:2201.00292</a> (replaced) [<a href="/pdf/2201.00292" title="Download PDF">pdf</a>, <a href="/format/2201.00292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fair Data Representation for Machine Learning at the Pareto Frontier
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Xu%2C+S">Shizhou Xu</a>, 
<a href="/search/stat?searchtype=author&query=Strohmer%2C+T">Thomas Strohmer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 63 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.11954" title="Abstract">arXiv:2202.11954</a> (replaced) [<a href="/pdf/2202.11954" title="Download PDF">pdf</a>, <a href="/format/2202.11954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> XAutoML: A Visual Analytics Tool for Understanding and Validating  Automated Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Z%C3%B6ller%2C+M">Marc-Andr&#xe9; Z&#xf6;ller</a>, 
<a href="/search/cs?searchtype=author&query=Titov%2C+W">Waldemar Titov</a>, 
<a href="/search/cs?searchtype=author&query=Schlegel%2C+T">Thomas Schlegel</a>, 
<a href="/search/cs?searchtype=author&query=Huber%2C+M+F">Marco F. Huber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Revised version accepted at ACM TiiS Special Issue on Human-centered Explainable AI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.02205" title="Abstract">arXiv:2203.02205</a> (replaced) [<a href="/pdf/2203.02205" title="Download PDF">pdf</a>, <a href="/format/2203.02205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Object (mis)Detection from a Safety and Reliability  Perspective: Discussion and Measures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ceccarelli%2C+A">Andrea Ceccarelli</a>, 
<a href="/search/cs?searchtype=author&query=Montecchi%2C+L">Leonardo Montecchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> journal version, open access
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> in IEEE Access, vol. 11, pp. 44952-44963, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.04838" title="Abstract">arXiv:2203.04838</a> (replaced) [<a href="/pdf/2203.04838" title="Download PDF">pdf</a>, <a href="/format/2203.04838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CMX: Cross-Modal Fusion for RGB-X Semantic Segmentation with  Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huayao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kailun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xinxin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruiping Liu</a>, 
<a href="/search/cs?searchtype=author&query=Stiefelhagen%2C+R">Rainer Stiefelhagen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE Transactions on Intelligent Transportation Systems (T-ITS). The source code of CMX is publicly available at <a href="https://github.com/huaaaliu/RGBX_Semantic_Segmentation">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.04159" title="Abstract">arXiv:2204.04159</a> (replaced) [<a href="/pdf/2204.04159" title="Download PDF">pdf</a>, <a href="/format/2204.04159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gravitational-wave matched filtering on a quantum computer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Veske%2C+D">Do&#x11f;a Veske</a>, 
<a href="/search/quant-ph?searchtype=author&query=T%C3%BCys%C3%BCz%2C+C">Cenk T&#xfc;ys&#xfc;z</a>, 
<a href="/search/quant-ph?searchtype=author&query=Amico%2C+M">Mirko Amico</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bronn%2C+N+T">Nicholas T. Bronn</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lanes%2C+O+T">Olivia T. Lanes</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bartos%2C+I">Imre Bartos</a>, 
<a href="/search/quant-ph?searchtype=author&query=M%C3%A1rka%2C+Z">Zsuzsa M&#xe1;rka</a>, 
<a href="/search/quant-ph?searchtype=author&query=Will%2C+S">Sebastian Will</a>, 
<a href="/search/quant-ph?searchtype=author&query=M%C3%A1rka%2C+S">Szabolcs M&#xe1;rka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5+5 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Computational Complexity (cs.CC); Emerging Technologies (cs.ET); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.07485" title="Abstract">arXiv:2204.07485</a> (replaced) [<a href="/pdf/2204.07485" title="Download PDF">pdf</a>, <a href="/format/2204.07485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Use K-means for Big Data Clustering?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mussabayev%2C+R">Rustam Mussabayev</a>, 
<a href="/search/cs?searchtype=author&query=Mladenovic%2C+N">Nenad Mladenovic</a>, 
<a href="/search/cs?searchtype=author&query=Jarboui%2C+B">Bassem Jarboui</a>, 
<a href="/search/cs?searchtype=author&query=Mussabayev%2C+R">Ravil Mussabayev</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Pattern Recognition, Volume 137, 2023, 109269, ISSN 0031-3203
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.10581" title="Abstract">arXiv:2204.10581</a> (replaced) [<a href="/pdf/2204.10581" title="Download PDF">pdf</a>, <a href="/format/2204.10581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fused Audio Instance and Representation for Respiratory Disease  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Truong%2C+T">Tuan Truong</a>, 
<a href="/search/cs?searchtype=author&query=Lenga%2C+M">Matthias Lenga</a>, 
<a href="/search/cs?searchtype=author&query=Serrurier%2C+A">Antoine Serrurier</a>, 
<a href="/search/cs?searchtype=author&query=Mohammadi%2C+S">Sadegh Mohammadi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.11291" title="Abstract">arXiv:2204.11291</a> (replaced) [<a href="/pdf/2204.11291" title="Download PDF">pdf</a>, <a href="/format/2204.11291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Scale Time-Series Representation Learning via Simultaneous Low and  High Frequency Feature Bootstrapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gorade%2C+V">Vandan Gorade</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Azad Singh</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+D">Deepak Mishra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.11952" title="Abstract">arXiv:2205.11952</a> (replaced) [<a href="/pdf/2205.11952" title="Download PDF">pdf</a>, <a href="/format/2205.11952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D helical CT Reconstruction with a Memory Efficient Learned Primal-Dual  Architecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rudzusika%2C+J">Jevgenija Rudzusika</a>, 
<a href="/search/eess?searchtype=author&query=Baji%C4%87%2C+B">Buda Baji&#x107;</a>, 
<a href="/search/eess?searchtype=author&query=Koehler%2C+T">Thomas Koehler</a>, 
<a href="/search/eess?searchtype=author&query=%C3%96ktem%2C+O">Ozan &#xd6;ktem</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.14415" title="Abstract">arXiv:2205.14415</a> (replaced) [<a href="/pdf/2205.14415" title="Download PDF">pdf</a>, <a href="/format/2205.14415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-stationary Transformers: Exploring the Stationarity in Time Series  Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haixu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianmin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+M">Mingsheng Long</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.11161" title="Abstract">arXiv:2206.11161</a> (replaced) [<a href="/pdf/2206.11161" title="Download PDF">pdf</a>, <a href="/format/2206.11161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sharing pattern submodels for prediction with missing values
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stempfle%2C+L">Lena Stempfle</a>, 
<a href="/search/cs?searchtype=author&query=Panahi%2C+A">Ashkan Panahi</a>, 
<a href="/search/cs?searchtype=author&query=Johansson%2C+F+D">Fredrik D. Johansson</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> AAAI Conference on Artificial Intelligence. 37, 8 (Jun. 2023),
  9882-9890
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.01072" title="Abstract">arXiv:2207.01072</a> (replaced) [<a href="/pdf/2207.01072" title="Download PDF">pdf</a>, <a href="/format/2207.01072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Sub-Cluster-Aware Network for Few-Shot Skin Disease  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=LI%2C+S">Shuhan LI</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaomeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaowei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+K">Kwang-Ting Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by TNNLS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.11209" title="Abstract">arXiv:2207.11209</a> (replaced) [<a href="/pdf/2207.11209" title="Download PDF">pdf</a>, <a href="/format/2207.11209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Divide and Conquer: 3D Point Cloud Instance Segmentation With Point-Wise  Binarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Weiguang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yuyao Yan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chaolong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jianan Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kaizhu Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.12291" title="Abstract">arXiv:2207.12291</a> (replaced) [<a href="/pdf/2207.12291" title="Download PDF">pdf</a>, <a href="/format/2207.12291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the convergence and sampling of randomized primal-dual algorithms and  their application to parallel MRI reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gutierrez%2C+E+B">Eric B Gutierrez</a>, 
<a href="/search/math?searchtype=author&query=Delplancke%2C+C">Claire Delplancke</a>, 
<a href="/search/math?searchtype=author&query=Ehrhardt%2C+M+J">Matthias J Ehrhardt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.01974" title="Abstract">arXiv:2209.01974</a> (replaced) [<a href="/pdf/2209.01974" title="Download PDF">pdf</a>, <a href="/format/2209.01974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Orthogonal layers of parallelism in large-scale eigenvalue computations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alvermann%2C+A">Andreas Alvermann</a>, 
<a href="/search/cs?searchtype=author&query=Hager%2C+G">Georg Hager</a>, 
<a href="/search/cs?searchtype=author&query=Fehske%2C+H">Holger Fehske</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Final version, almost as published. 32 pages, 12 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM Trans. Parallel Comput. 10, 16 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.02892" title="Abstract">arXiv:2209.02892</a> (replaced) [<a href="/pdf/2209.02892" title="Download PDF">pdf</a>, <a href="/format/2209.02892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Systematical Evaluation for Next-Basket Recommendation Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+Z">Zhufeng Shao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shoujin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Wenpeng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xueping Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.03048" title="Abstract">arXiv:2209.03048</a> (replaced) [<a href="/pdf/2209.03048" title="Download PDF">pdf</a>, <a href="/format/2209.03048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Multimodal Variational Autoencoders: CdSprites+ Dataset and  Toolkit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sejnova%2C+G">Gabriela Sejnova</a>, 
<a href="/search/cs?searchtype=author&query=Vavrecka%2C+M">Michal Vavrecka</a>, 
<a href="/search/cs?searchtype=author&query=Stepanova%2C+K">Karla Stepanova</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.05703" title="Abstract">arXiv:2209.05703</a> (replaced) [<a href="/pdf/2209.05703" title="Download PDF">pdf</a>, <a href="/format/2209.05703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Independent Learning in Mean-Field Games: Satisficing Paths and  Convergence to Subjective Equilibria
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yongacoglu%2C+B">Bora Yongacoglu</a>, 
<a href="/search/cs?searchtype=author&query=Arslan%2C+G">G&#xfc;rdal Arslan</a>, 
<a href="/search/cs?searchtype=author&query=Y%C3%BCksel%2C+S">Serdar Y&#xfc;ksel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.05954" title="Abstract">arXiv:2209.05954</a> (replaced) [<a href="/pdf/2209.05954" title="Download PDF">pdf</a>, <a href="/format/2209.05954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatically Score Tissue Images Like a Pathologist by Transfer  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+I">Iris Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.07278" title="Abstract">arXiv:2209.07278</a> (replaced) [<a href="/pdf/2209.07278" title="Download PDF">pdf</a>, <a href="/format/2209.07278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &#xda;FAL CorPipe at CRAC 2022: Effectivity of Multilingual Models for  Coreference Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Straka%2C+M">Milan Straka</a>, 
<a href="/search/cs?searchtype=author&query=Strakov%C3%A1%2C+J">Jana Strakov&#xe1;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CRAC 2022 (Fifth Workshop on Computational Models of Reference, Anaphora and Coreference)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.09154" title="Abstract">arXiv:2209.09154</a> (replaced) [<a href="/pdf/2209.09154" title="Download PDF">pdf</a>, <a href="/format/2209.09154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Constrained Neural Network for Design and Feature-Based  Optimization of Weave Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Feng%2C+H">Haotian Feng</a>, 
<a href="/search/physics?searchtype=author&query=Subramaniyan%2C+S+P">Sabarinathan P Subramaniyan</a>, 
<a href="/search/physics?searchtype=author&query=Tewani%2C+H">Hridyesh Tewani</a>, 
<a href="/search/physics?searchtype=author&query=Prabhakar%2C+P">Pavana Prabhakar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applied Physics (physics.app-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.13099" title="Abstract">arXiv:2209.13099</a> (replaced) [<a href="/pdf/2209.13099" title="Download PDF">pdf</a>, <a href="/format/2209.13099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Mechanism Design for Blockchain Transaction Fee Allocation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Simchi-Levi%2C+D">David Simchi-Levi</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zishuo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuan Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 59 pages, CESC 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.03488" title="Abstract">arXiv:2210.03488</a> (replaced) [<a href="/pdf/2210.03488" title="Download PDF">pdf</a>, <a href="/format/2210.03488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AlphaFold Distillation for Protein Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Melnyk%2C+I">Igor Melnyk</a>, 
<a href="/search/q-bio?searchtype=author&query=Lozano%2C+A">Aurelie Lozano</a>, 
<a href="/search/q-bio?searchtype=author&query=Das%2C+P">Payel Das</a>, 
<a href="/search/q-bio?searchtype=author&query=Chenthamarakshan%2C+V">Vijil Chenthamarakshan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.13552" title="Abstract">arXiv:2210.13552</a> (replaced) [<a href="/pdf/2210.13552" title="Download PDF">pdf</a>, <a href="/format/2210.13552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perceptual Image Enhancement for Smartphone Real-Time Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Conde%2C+M+V">Marcos V. Conde</a>, 
<a href="/search/cs?searchtype=author&query=Vasluianu%2C+F">Florin Vasluianu</a>, 
<a href="/search/cs?searchtype=author&query=Vazquez-Corral%2C+J">Javier Vazquez-Corral</a>, 
<a href="/search/cs?searchtype=author&query=Timofte%2C+R">Radu Timofte</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE/CVF WACV 2023 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.17543" title="Abstract">arXiv:2210.17543</a> (replaced) [<a href="/pdf/2210.17543" title="Download PDF">pdf</a>, <a href="/format/2210.17543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High order splitting methods for SDEs satisfying a commutativity  condition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Foster%2C+J">James Foster</a>, 
<a href="/search/math?searchtype=author&query=Reis%2C+G+d">Goncalo dos Reis</a>, 
<a href="/search/math?searchtype=author&query=Strange%2C+C">Calum Strange</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.00539" title="Abstract">arXiv:2211.00539</a> (replaced) [<a href="/pdf/2211.00539" title="Download PDF">pdf</a>, <a href="/format/2211.00539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dungeons and Data: A Large-Scale NetHack Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hambro%2C+E">Eric Hambro</a>, 
<a href="/search/cs?searchtype=author&query=Raileanu%2C+R">Roberta Raileanu</a>, 
<a href="/search/cs?searchtype=author&query=Rothermel%2C+D">Danielle Rothermel</a>, 
<a href="/search/cs?searchtype=author&query=Mella%2C+V">Vegard Mella</a>, 
<a href="/search/cs?searchtype=author&query=Rockt%C3%A4schel%2C+T">Tim Rockt&#xe4;schel</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%BCttler%2C+H">Heinrich K&#xfc;ttler</a>, 
<a href="/search/cs?searchtype=author&query=Murray%2C+N">Naila Murray</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, published in the Proceedings of the 36th Conference on Neural Information Processing Systems (NeurIPS 2022) Track on Datasets and Benchmarks. New links to hosting location. Revised results, same conclusions
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.03157" title="Abstract">arXiv:2211.03157</a> (replaced) [<a href="/pdf/2211.03157" title="Download PDF">pdf</a>, <a href="/ps/2211.03157" title="Download PostScript">ps</a>, <a href="/format/2211.03157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Examining the Differential Risk from High-level Artificial Intelligence  and the Question of Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kilian%2C+K+A">Kyle A. Kilian</a>, 
<a href="/search/cs?searchtype=author&query=Ventura%2C+C+J">Christopher J. Ventura</a>, 
<a href="/search/cs?searchtype=author&query=Bailey%2C+M+M">Mark M. Bailey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.04927" title="Abstract">arXiv:2211.04927</a> (replaced) [<a href="/pdf/2211.04927" title="Download PDF">pdf</a>, <a href="/format/2211.04927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepDC: Deep Distance Correlation as a Perceptual Image Quality  Evaluator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hanwei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Baoliang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lingyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Weisi Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.09894" title="Abstract">arXiv:2211.09894</a> (replaced) [<a href="/pdf/2211.09894" title="Download PDF">pdf</a>, <a href="/format/2211.09894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Supervised Feature Compression based on Counterfactual Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Piccialli%2C+V">Veronica Piccialli</a>, 
<a href="/search/cs?searchtype=author&query=Morales%2C+D+R">Dolores Romero Morales</a>, 
<a href="/search/cs?searchtype=author&query=Salvatore%2C+C">Cecilia Salvatore</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 45figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.10198" title="Abstract">arXiv:2211.10198</a> (replaced) [<a href="/pdf/2211.10198" title="Download PDF">pdf</a>, <a href="/format/2211.10198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Promoting Social Behaviour in Reducing Peak Electricity Consumption  Using Multi-Agent Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brooks%2C+N+A">Nathan A. Brooks</a>, 
<a href="/search/cs?searchtype=author&query=Powers%2C+S+T">Simon T. Powers</a>, 
<a href="/search/cs?searchtype=author&query=Borg%2C+J+M">James M. Borg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2006.14526">arXiv:2006.14526</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.11744" title="Abstract">arXiv:2211.11744</a> (replaced) [<a href="/pdf/2211.11744" title="Download PDF">pdf</a>, <a href="/format/2211.11744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Dexterity: In-Hand Reorientation of Novel and Complex Object  Shapes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tippur%2C+M">Megha Tippur</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Siyang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+V">Vikash Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Adelson%2C+E">Edward Adelson</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+P">Pulkit Agrawal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Science Robotics: <a href="https://www.science.org/doi/10.1126/scirobotics.adc9244">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Science Robotics, 8(84): eadc9244, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.12792" title="Abstract">arXiv:2211.12792</a> (replaced) [<a href="/pdf/2211.12792" title="Download PDF">pdf</a>, <a href="/format/2211.12792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MECCH: Metapath Context Convolution-based Heterogeneous Graph Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xinyu Fu</a>, 
<a href="/search/cs?searchtype=author&query=King%2C+I">Irwin King</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures, 7 tables; published in Neural Networks; code available at <a href="https://github.com/cynricfu/MECCH">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Neural Networks 170 (2024) 266-275
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.00509" title="Abstract">arXiv:2212.00509</a> (replaced) [<a href="/pdf/2212.00509" title="Download PDF">pdf</a>, <a href="/ps/2212.00509" title="Download PostScript">ps</a>, <a href="/format/2212.00509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CultureBERT: Measuring Corporate Culture With Transformer-Based Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koch%2C+S">Sebastian Koch</a>, 
<a href="/search/cs?searchtype=author&query=Pasch%2C+S">Stefan Pasch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01668" title="Abstract">arXiv:2212.01668</a> (replaced) [<a href="/pdf/2212.01668" title="Download PDF">pdf</a>, <a href="/format/2212.01668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Gap in the Subrank of Tensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Christandl%2C+M">Matthias Christandl</a>, 
<a href="/search/math?searchtype=author&query=Gesmundo%2C+F">Fulvio Gesmundo</a>, 
<a href="/search/math?searchtype=author&query=Zuiddam%2C+J">Jeroen Zuiddam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages. Final version
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> SIAM J. Applied Alg. Geom., 7 (4), 742-767, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Geometry (math.AG)</span>; Computational Complexity (cs.CC); Combinatorics (math.CO); Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.05911" title="Abstract">arXiv:2212.05911</a> (replaced) [<a href="/pdf/2212.05911" title="Download PDF">pdf</a>, <a href="/format/2212.05911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Self-Training for Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vandeghen%2C+R">Renaud Vandeghen</a>, 
<a href="/search/cs?searchtype=author&query=Louppe%2C+G">Gilles Louppe</a>, 
<a href="/search/cs?searchtype=author&query=Van+Droogenbroeck%2C+M">Marc Van Droogenbroeck</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures, 5 tables, 1 page of supplementary material
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.13766" title="Abstract">arXiv:2212.13766</a> (replaced) [<a href="/e-print/2212.13766" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OVO: One-shot Vision Transformer Search with Online distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zimian Wei</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+H">Hengyue Pan</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+X">Xin Niu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongsheng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The work is not implemented
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.00876" title="Abstract">arXiv:2301.00876</a> (replaced) [<a href="/pdf/2301.00876" title="Download PDF">pdf</a>, <a href="/format/2301.00876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAUD: An Expert-Annotated Legal NLP Dataset for Merger Agreement  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S+H">Steven H. Wang</a>, 
<a href="/search/cs?searchtype=author&query=Scardigli%2C+A">Antoine Scardigli</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+L">Leonard Tang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Levkin%2C+D">Dimitry Levkin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+A">Anya Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ball%2C+S">Spencer Ball</a>, 
<a href="/search/cs?searchtype=author&query=Woodside%2C+T">Thomas Woodside</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+O">Oliver Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hendrycks%2C+D">Dan Hendrycks</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023. 5 pages + appendix. Code and dataset are available at <a href="https://github.com/TheAtticusProject/maud">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.03151" title="Abstract">arXiv:2301.03151</a> (replaced) [<a href="/pdf/2301.03151" title="Download PDF">pdf</a>, <a href="/format/2301.03151" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $&#x393;$-convergent LDG method for large bending deformations of bilayer  plates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bonito%2C+A">Andrea Bonito</a>, 
<a href="/search/math?searchtype=author&query=Nochetto%2C+R+H">Ricardo H. Nochetto</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+S">Shuo Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.04643" title="Abstract">arXiv:2301.04643</a> (replaced) [<a href="/pdf/2301.04643" title="Download PDF">pdf</a>, <a href="/format/2301.04643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> tieval: An Evaluation Framework for Temporal Information Extraction  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sousa%2C+H">Hugo Sousa</a>, 
<a href="/search/cs?searchtype=author&query=Jorge%2C+A">Al&#xed;pio Jorge</a>, 
<a href="/search/cs?searchtype=author&query=Campos%2C+R">Ricardo Campos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.07486" title="Abstract">arXiv:2301.07486</a> (replaced) [<a href="/pdf/2301.07486" title="Download PDF">pdf</a>, <a href="/format/2301.07486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CINM (Cinnamon): A Compilation Infrastructure for Heterogeneous Compute  In-Memory and Compute Near-Memory Paradigms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+A+A">Asif Ali Khan</a>, 
<a href="/search/cs?searchtype=author&query=Farzaneh%2C+H">Hamid Farzaneh</a>, 
<a href="/search/cs?searchtype=author&query=Friebel%2C+K+F+A">Karl F. A. Friebel</a>, 
<a href="/search/cs?searchtype=author&query=Fournier%2C+C">Cl&#xe9;ment Fournier</a>, 
<a href="/search/cs?searchtype=author&query=Chelini%2C+L">Lorenzo Chelini</a>, 
<a href="/search/cs?searchtype=author&query=Castrillon%2C+J">Jeronimo Castrillon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.07747" title="Abstract">arXiv:2301.07747</a> (replaced) [<a href="/pdf/2301.07747" title="Download PDF">pdf</a>, <a href="/ps/2301.07747" title="Download PostScript">ps</a>, <a href="/format/2301.07747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Automata-based Framework for Verification and Bug Hunting in Quantum  Circuits (Technical Report)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yu-Fang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+K">Kai-Min Chung</a>, 
<a href="/search/cs?searchtype=author&query=Leng%C3%A1l%2C+O">Ond&#x159;ej Leng&#xe1;l</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jyun-Ao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+W">Wei-Lun Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Yen%2C+D">Di-De Yen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a technical report for the paper with the same name that appeared at PLDI'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11588" title="Abstract">arXiv:2301.11588</a> (replaced) [<a href="/pdf/2301.11588" title="Download PDF">pdf</a>, <a href="/format/2301.11588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bounding Box-based Multi-objective Bayesian Optimization of Risk  Measures under Input Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Inatsu%2C+Y">Yu Inatsu</a>, 
<a href="/search/stat?searchtype=author&query=Takeno%2C+S">Shion Takeno</a>, 
<a href="/search/stat?searchtype=author&query=Hanada%2C+H">Hiroyuki Hanada</a>, 
<a href="/search/stat?searchtype=author&query=Iwata%2C+K">Kazuki Iwata</a>, 
<a href="/search/stat?searchtype=author&query=Takeuchi%2C+I">Ichiro Takeuchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11873" title="Abstract">arXiv:2301.11873</a> (replaced) [<a href="/pdf/2301.11873" title="Download PDF">pdf</a>, <a href="/format/2301.11873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Deep Learning Method for Comparing Bayesian Hierarchical Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Elsem%C3%BCller%2C+L">Lasse Elsem&#xfc;ller</a>, 
<a href="/search/stat?searchtype=author&query=Schnuerch%2C+M">Martin Schnuerch</a>, 
<a href="/search/stat?searchtype=author&query=B%C3%BCrkner%2C+P">Paul-Christian B&#xfc;rkner</a>, 
<a href="/search/stat?searchtype=author&query=Radev%2C+S+T">Stefan T. Radev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.13636" title="Abstract">arXiv:2301.13636</a> (replaced) [<a href="/pdf/2301.13636" title="Download PDF">pdf</a>, <a href="/format/2301.13636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transport with Support: Data-Conditional Diffusion Bridges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tamir%2C+E">Ella Tamir</a>, 
<a href="/search/cs?searchtype=author&query=Trapp%2C+M">Martin Trapp</a>, 
<a href="/search/cs?searchtype=author&query=Solin%2C+A">Arno Solin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05104" title="Abstract">arXiv:2302.05104</a> (replaced) [<a href="/pdf/2302.05104" title="Download PDF">pdf</a>, <a href="/format/2302.05104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monte Carlo Neural PDE Solver for Learning PDEs via Probabilistic  Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+Q">Qi Meng</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+R">Rongchan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Wenlei Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shihua Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhi-Ming Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tie-Yan Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.07400" title="Abstract">arXiv:2302.07400</a> (replaced) [<a href="/pdf/2302.07400" title="Download PDF">pdf</a>, <a href="/format/2302.07400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Score-based Diffusion Models in Function Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lim%2C+J+H">Jae Hyun Lim</a>, 
<a href="/search/cs?searchtype=author&query=Kovachki%2C+N+B">Nikola B. Kovachki</a>, 
<a href="/search/cs?searchtype=author&query=Baptista%2C+R">Ricardo Baptista</a>, 
<a href="/search/cs?searchtype=author&query=Beckham%2C+C">Christopher Beckham</a>, 
<a href="/search/cs?searchtype=author&query=Azizzadenesheli%2C+K">Kamyar Azizzadenesheli</a>, 
<a href="/search/cs?searchtype=author&query=Kossaifi%2C+J">Jean Kossaifi</a>, 
<a href="/search/cs?searchtype=author&query=Voleti%2C+V">Vikram Voleti</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jiaming Song</a>, 
<a href="/search/cs?searchtype=author&query=Kreis%2C+K">Karsten Kreis</a>, 
<a href="/search/cs?searchtype=author&query=Kautz%2C+J">Jan Kautz</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+C">Christopher Pal</a>, 
<a href="/search/cs?searchtype=author&query=Vahdat%2C+A">Arash Vahdat</a>, 
<a href="/search/cs?searchtype=author&query=Anandkumar%2C+A">Anima Anandkumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 52 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Functional Analysis (math.FA); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09717" title="Abstract">arXiv:2302.09717</a> (replaced) [<a href="/pdf/2302.09717" title="Download PDF">pdf</a>, <a href="/ps/2302.09717" title="Download PostScript">ps</a>, <a href="/format/2302.09717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coordinating Multiple Intelligent Reflecting Surfaces without Channel  Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+F">Fan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jiawei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+W">Wenhai Lai</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+K">Kaiming Shen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zhi-Quan Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Signal Processing 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.12115" title="Abstract">arXiv:2302.12115</a> (replaced) [<a href="/pdf/2302.12115" title="Download PDF">pdf</a>, <a href="/format/2302.12115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic realization of miscellaneous profile services in elastic optical  networks using spectrum partitioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gheysari%2C+B">Behnam Gheysari</a> (1), 
<a href="/search/cs?searchtype=author&query=Rezaee%2C+A">Arash Rezaee</a> (2), 
<a href="/search/cs?searchtype=author&query=Beygi%2C+L">Lotfollah Beygi</a> (1) ((1) EE Department, K. N. Toosi University of Technology, Iran, (2) ECE Department, University of Massachusetts Lowell, USA)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14460" title="Abstract">arXiv:2302.14460</a> (replaced) [<a href="/pdf/2302.14460" title="Download PDF">pdf</a>, <a href="/format/2302.14460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable and intervenable ultrasonography-based machine learning  models for pediatric appendicitis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marcinkevi%C4%8Ds%2C+R">Ri&#x10d;ards Marcinkevi&#x10d;s</a>, 
<a href="/search/cs?searchtype=author&query=Wolfertstetter%2C+P+R">Patricia Reis Wolfertstetter</a>, 
<a href="/search/cs?searchtype=author&query=Klimiene%2C+U">Ugne Klimiene</a>, 
<a href="/search/cs?searchtype=author&query=Chin-Cheong%2C+K">Kieran Chin-Cheong</a>, 
<a href="/search/cs?searchtype=author&query=Paschke%2C+A">Alyssia Paschke</a>, 
<a href="/search/cs?searchtype=author&query=Zerres%2C+J">Julia Zerres</a>, 
<a href="/search/cs?searchtype=author&query=Denzinger%2C+M">Markus Denzinger</a>, 
<a href="/search/cs?searchtype=author&query=Niederberger%2C+D">David Niederberger</a>, 
<a href="/search/cs?searchtype=author&query=Wellmann%2C+S">Sven Wellmann</a>, 
<a href="/search/cs?searchtype=author&query=Ozkan%2C+E">Ece Ozkan</a>, 
<a href="/search/cs?searchtype=author&query=Knorr%2C+C">Christian Knorr</a>, 
<a href="/search/cs?searchtype=author&query=Vogt%2C+J+E">Julia E. Vogt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Medical Image Analysis (Elsevier)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Medical Image Analysis, 91, 103042 (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14512" title="Abstract">arXiv:2302.14512</a> (replaced) [<a href="/pdf/2302.14512" title="Download PDF">pdf</a>, <a href="/format/2302.14512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A DuMux Framework for Data-Driven Multi-Scale Parametrizations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Coltman%2C+E">Edward Coltman</a>, 
<a href="/search/math?searchtype=author&query=Schneider%2C+M">Martin Schneider</a>, 
<a href="/search/math?searchtype=author&query=Helmig%2C+R">Rainer Helmig</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00132" title="Abstract">arXiv:2303.00132</a> (replaced) [<a href="/pdf/2303.00132" title="Download PDF">pdf</a>, <a href="/format/2303.00132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Onboard dynamic-object detection and tracking for autonomous robot  navigation with RGB-D camera
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhefan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+X">Xiaoyang Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Xiu%2C+Y">Yumeng Xiu</a>, 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+C">Christopher Suzuki</a>, 
<a href="/search/cs?searchtype=author&query=Shimada%2C+K">Kenji Shimada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 10 figures, 2 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Robotics and Automation Letters, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00533" title="Abstract">arXiv:2303.00533</a> (replaced) [<a href="/pdf/2303.00533" title="Download PDF">pdf</a>, <a href="/format/2303.00533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Privacy-Preserving Dispute Resolution Protocol on Ethereum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gangemi%2C+A">Andrea Gangemi</a>, 
<a href="/search/cs?searchtype=author&query=Kharman%2C+A+M">Aida Manzano Kharman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01538" title="Abstract">arXiv:2303.01538</a> (replaced) [<a href="/pdf/2303.01538" title="Download PDF">pdf</a>, <a href="/format/2303.01538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature Perturbation Augmentation for Reliable Evaluation of Importance  Estimators in Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brocki%2C+L">Lennart Brocki</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+N+C">Neo Christopher Chung</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICLR 2023 Workshop on Trustworthy ML; Full Paper in Pattern
  Recognition Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03962" title="Abstract">arXiv:2303.03962</a> (replaced) [<a href="/pdf/2303.03962" title="Download PDF">pdf</a>, <a href="/ps/2303.03962" title="Download PostScript">ps</a>, <a href="/format/2303.03962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cops and Robbers on Multi-Layer Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Enright%2C+J">Jessica Enright</a>, 
<a href="/search/math?searchtype=author&query=Meeks%2C+K">Kitty Meeks</a>, 
<a href="/search/math?searchtype=author&query=Pettersson%2C+W">William Pettersson</a>, 
<a href="/search/math?searchtype=author&query=Sylvester%2C+J">John Sylvester</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 6 figures. Latest version contains a strengthening of Theorem 6.2
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03982" title="Abstract">arXiv:2303.03982</a> (replaced) [<a href="/pdf/2303.03982" title="Download PDF">pdf</a>, <a href="/format/2303.03982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structured State Space Models for In-Context Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Chris Lu</a>, 
<a href="/search/cs?searchtype=author&query=Schroecker%2C+Y">Yannick Schroecker</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+A">Albert Gu</a>, 
<a href="/search/cs?searchtype=author&query=Parisotto%2C+E">Emilio Parisotto</a>, 
<a href="/search/cs?searchtype=author&query=Foerster%2C+J">Jakob Foerster</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Satinder Singh</a>, 
<a href="/search/cs?searchtype=author&query=Behbahani%2C+F">Feryal Behbahani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.04689" title="Abstract">arXiv:2303.04689</a> (replaced) [<a href="/pdf/2303.04689" title="Download PDF">pdf</a>, <a href="/format/2303.04689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Privacy Preserving System for Movie Recommendations Using Federated  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neumann%2C+D">David Neumann</a>, 
<a href="/search/cs?searchtype=author&query=Lutz%2C+A">Andreas Lutz</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+K">Karsten M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Samek%2C+W">Wojciech Samek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in the ACM Transactions on Recommender Systems (TORS) Special Issue on Trustworthy Recommender Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08011" title="Abstract">arXiv:2303.08011</a> (replaced) [<a href="/pdf/2303.08011" title="Download PDF">pdf</a>, <a href="/format/2303.08011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model scale versus domain knowledge in statistical forecasting of  chaotic systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gilpin%2C+W">William Gilpin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08549" title="Abstract">arXiv:2303.08549</a> (replaced) [<a href="/pdf/2303.08549" title="Download PDF">pdf</a>, <a href="/format/2303.08549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Bregman-Kaczmarz method for nonlinear systems of equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Winkler%2C+M">Maximilian Winkler</a>, 
<a href="/search/math?searchtype=author&query=Lorenz%2C+D+A">Dirk A. Lorenz</a>, 
<a href="/search/math?searchtype=author&query=Gower%2C+R">Robert Gower</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09077" title="Abstract">arXiv:2303.09077</a> (replaced) [<a href="/pdf/2303.09077" title="Download PDF">pdf</a>, <a href="/format/2303.09077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards the Understanding of Receptivity and Affect in EMAs using  Physiological based Machine Learning Method: Analysis of Receptivity and  Affect
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=King%2C+Z+D">Zachary D King</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Han Yu</a>, 
<a href="/search/cs?searchtype=author&query=Vaessen%2C+T">Thomas Vaessen</a>, 
<a href="/search/cs?searchtype=author&query=Myin-Germeys%2C+I">Iniz Myin-Germeys</a>, 
<a href="/search/cs?searchtype=author&query=Sano%2C+A">Akane Sano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.14483" title="Abstract">arXiv:2303.14483</a> (replaced) [<a href="/pdf/2303.14483" title="Download PDF">pdf</a>, <a href="/format/2303.14483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatio-Temporal Graph Neural Networks for Predictive Learning in Urban  Computing: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+G">Guangyin Jin</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yuxuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuchen Fang</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Z">Zezhi Shao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jincai Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junbo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yu Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16210" title="Abstract">arXiv:2303.16210</a> (replaced) [<a href="/pdf/2303.16210" title="Download PDF">pdf</a>, <a href="/format/2303.16210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Reliable Uncertainty Quantification via Deep Ensembles in  Multi-output Regression Task
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sunwoong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yee%2C+K">Kwanjung Yee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00933" title="Abstract">arXiv:2304.00933</a> (replaced) [<a href="/pdf/2304.00933" title="Download PDF">pdf</a>, <a href="/format/2304.00933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Accumulation in Continually Learned Representations and the  Issue of Feature Forgetting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hess%2C+T">Timm Hess</a>, 
<a href="/search/cs?searchtype=author&query=Verwimp%2C+E">Eli Verwimp</a>, 
<a href="/search/cs?searchtype=author&query=van+de+Ven%2C+G+M">Gido M. van de Ven</a>, 
<a href="/search/cs?searchtype=author&query=Tuytelaars%2C+T">Tinne Tuytelaars</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05390" title="Abstract">arXiv:2304.05390</a> (replaced) [<a href="/pdf/2304.05390" title="Download PDF">pdf</a>, <a href="/format/2304.05390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HRS-Bench: Holistic, Reliable and Scalable Benchmark for Text-to-Image  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bakr%2C+E+M">Eslam Mohamed Bakr</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+P">Pengzhan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xiaoqian Shen</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+F+F">Faizan Farooq Khan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L+E">Li Erran Li</a>, 
<a href="/search/cs?searchtype=author&query=Elhoseiny%2C+M">Mohamed Elhoseiny</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07061" title="Abstract">arXiv:2304.07061</a> (replaced) [<a href="/pdf/2304.07061" title="Download PDF">pdf</a>, <a href="/format/2304.07061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoDroid-0shot: A Simple Baseline for GPT-powered UI-grounded  Smartphone Task Automation in Android
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+H">Hao Wen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaxuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanchun Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07067" title="Abstract">arXiv:2304.07067</a> (replaced) [<a href="/pdf/2304.07067" title="Download PDF">pdf</a>, <a href="/format/2304.07067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterization of the weak Pareto boundary of resource allocation  problems in wireless networks -- Implications to cell-less systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cavalcante%2C+R+L+G">Renato Luis Garrido Cavalcante</a>, 
<a href="/search/eess?searchtype=author&query=Miretti%2C+L">Lorenzo Miretti</a>, 
<a href="/search/eess?searchtype=author&query=Stanczak%2C+S">Slawomir Stanczak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE ICC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08120" title="Abstract">arXiv:2304.08120</a> (replaced) [<a href="/pdf/2304.08120" title="Download PDF">pdf</a>, <a href="/format/2304.08120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DAS-N2N: Machine learning Distributed Acoustic Sensing (DAS) signal  denoising without clean data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Lapins%2C+S">Sacha Lapins</a>, 
<a href="/search/physics?searchtype=author&query=Butcher%2C+A">Antony Butcher</a>, 
<a href="/search/physics?searchtype=author&query=Kendall%2C+J+-">J.-Michael Kendall</a>, 
<a href="/search/physics?searchtype=author&query=Hudson%2C+T+S">Thomas S. Hudson</a>, 
<a href="/search/physics?searchtype=author&query=Stork%2C+A+L">Anna L. Stork</a>, 
<a href="/search/physics?searchtype=author&query=Werner%2C+M+J">Maximilian J. Werner</a>, 
<a href="/search/physics?searchtype=author&query=Gunning%2C+J">Jemma Gunning</a>, 
<a href="/search/physics?searchtype=author&query=Brisbourne%2C+A+M">Alex M. Brisbourne</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for publication to Geophysical Journal International. For the purpose of open access, the author(s) has applied a Creative Commons Attribution (CC BY) licence to the Author Accepted Manuscript version arising from this submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geophysics (physics.geo-ph)</span>; Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13827" title="Abstract">arXiv:2304.13827</a> (replaced) [<a href="/pdf/2304.13827" title="Download PDF">pdf</a>, <a href="/format/2304.13827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multicast Transmission Design with Enhanced DoF for MIMO Coded Caching  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=NaseriTehrani%2C+M">Mohammad NaseriTehrani</a>, 
<a href="/search/cs?searchtype=author&query=Salehi%2C+M">MohammadJavad Salehi</a>, 
<a href="/search/cs?searchtype=author&query=T%C3%B6lli%2C+A">Antti T&#xf6;lli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.00557" title="Abstract">arXiv:2305.00557</a> (replaced) [<a href="/pdf/2305.00557" title="Download PDF">pdf</a>, <a href="/format/2305.00557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collective Relational Inference for learning heterogeneous interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhichao Han</a>, 
<a href="/search/cs?searchtype=author&query=Fink%2C+O">Olga Fink</a>, 
<a href="/search/cs?searchtype=author&query=Kammer%2C+D+S">David S. Kammer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review. Links to the supporting code can be found at the end of the main content
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.01569" title="Abstract">arXiv:2305.01569</a> (replaced) [<a href="/pdf/2305.01569" title="Download PDF">pdf</a>, <a href="/format/2305.01569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pick-a-Pic: An Open Dataset of User Preferences for Text-to-Image  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kirstain%2C+Y">Yuval Kirstain</a>, 
<a href="/search/cs?searchtype=author&query=Polyak%2C+A">Adam Polyak</a>, 
<a href="/search/cs?searchtype=author&query=Singer%2C+U">Uriel Singer</a>, 
<a href="/search/cs?searchtype=author&query=Matiana%2C+S">Shahbuland Matiana</a>, 
<a href="/search/cs?searchtype=author&query=Penna%2C+J">Joe Penna</a>, 
<a href="/search/cs?searchtype=author&query=Levy%2C+O">Omer Levy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.01962" title="Abstract">arXiv:2305.01962</a> (replaced) [<a href="/pdf/2305.01962" title="Download PDF">pdf</a>, <a href="/format/2305.01962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decidable (Ac)counting with Parikh and Muller: Adding Presburger  Arithmetic to Monadic Second-Order Logic over Tree-Interpretable Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Herrmann%2C+L">Luisa Herrmann</a>, 
<a href="/search/cs?searchtype=author&query=Peth%2C+V">Vincent Peth</a>, 
<a href="/search/cs?searchtype=author&query=Rudolph%2C+S">Sebastian Rudolph</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> extended version, accepted at CSL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03463" title="Abstract">arXiv:2305.03463</a> (replaced) [<a href="/pdf/2305.03463" title="Download PDF">pdf</a>, <a href="/format/2305.03463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reducing Idleness in Financial Cloud Services via Multi-objective  Evolutionary Reinforcement Learning based Load Balancer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+P">Peng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Laoming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haifeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guiying Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 14 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> SCIENCE CHINA Information Sciences, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06101" title="Abstract">arXiv:2305.06101</a> (replaced) [<a href="/pdf/2305.06101" title="Download PDF">pdf</a>, <a href="/format/2305.06101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Access-Redundancy Tradeoffs in Quantized Linear Computations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramkumar%2C+V">Vinayak Ramkumar</a>, 
<a href="/search/cs?searchtype=author&query=Raviv%2C+N">Netanel Raviv</a>, 
<a href="/search/cs?searchtype=author&query=Tamo%2C+I">Itzhak Tamo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented in part at ISIT 2023 and Allerton 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12401" title="Abstract">arXiv:2305.12401</a> (replaced) [<a href="/pdf/2305.12401" title="Download PDF">pdf</a>, <a href="/format/2305.12401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WOT-Class: Weakly Supervised Open-world Text Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianle Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weitang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+J">Jingbo Shang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CIKM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12476" title="Abstract">arXiv:2305.12476</a> (replaced) [<a href="/pdf/2305.12476" title="Download PDF">pdf</a>, <a href="/format/2305.12476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-shot Visual Relation Detection via Composite Visual Cues from Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lin Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jun Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guikun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Jian Shao</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Y">Yueting Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Long Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13417" title="Abstract">arXiv:2305.13417</a> (replaced) [<a href="/pdf/2305.13417" title="Download PDF">pdf</a>, <a href="/format/2305.13417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VISIT: Visualizing and Interpreting the Semantic Information Flow of  Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Katz%2C+S">Shahar Katz</a>, 
<a href="/search/cs?searchtype=author&query=Belinkov%2C+Y">Yonatan Belinkov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP Findings 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13455" title="Abstract">arXiv:2305.13455</a> (replaced) [<a href="/pdf/2305.13455" title="Download PDF">pdf</a>, <a href="/format/2305.13455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clembench: Using Game Play to Evaluate Chat-Optimized Language Models as  Conversational Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chalamalasetti%2C+K">Kranti Chalamalasetti</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B6tze%2C+J">Jana G&#xf6;tze</a>, 
<a href="/search/cs?searchtype=author&query=Hakimov%2C+S">Sherzod Hakimov</a>, 
<a href="/search/cs?searchtype=author&query=Madureira%2C+B">Brielen Madureira</a>, 
<a href="/search/cs?searchtype=author&query=Sadler%2C+P">Philipp Sadler</a>, 
<a href="/search/cs?searchtype=author&query=Schlangen%2C+D">David Schlangen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16099" title="Abstract">arXiv:2305.16099</a> (replaced) [<a href="/pdf/2305.16099" title="Download PDF">pdf</a>, <a href="/format/2305.16099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FAVANO: Federated AVeraging with Asynchronous NOdes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leconte%2C+L">Louis Leconte</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V+M">Van Minh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Moulines%2C+E">Eric Moulines</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16854" title="Abstract">arXiv:2305.16854</a> (replaced) [<a href="/pdf/2305.16854" title="Download PDF">pdf</a>, <a href="/format/2305.16854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Channel and Gradient-Importance Aware Device Scheduling for Over-the-Air  Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuchang Sun</a>, 
<a href="/search/cs?searchtype=author&query=lin%2C+Z">Zehong lin</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yuyi Mao</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Shi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17400" title="Abstract">arXiv:2305.17400</a> (replaced) [<a href="/pdf/2305.17400" title="Download PDF">pdf</a>, <a href="/format/2305.17400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Query-Policy Misalignment in Preference-Based Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianxiong Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+X">Xianyuan Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Q">Qing-Shan Jia</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Ya-Qin Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17455" title="Abstract">arXiv:2305.17455</a> (replaced) [<a href="/pdf/2305.17455" title="Download PDF">pdf</a>, <a href="/format/2305.17455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CrossGET: Cross-Guided Ensemble of Tokens for Accelerating  Vision-Language Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+D">Dachuan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+C">Chaofan Tao</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+A">Anyi Rao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhendong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Chun Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaqi Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18437" title="Abstract">arXiv:2305.18437</a> (replaced) [<a href="/pdf/2305.18437" title="Download PDF">pdf</a>, <a href="/ps/2305.18437" title="Download PostScript">ps</a>, <a href="/format/2305.18437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable Machine Learning for Categorical and Mixed Data with  Lossless Visualization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kovalerchuk%2C+B">Boris Kovalerchuk</a>, 
<a href="/search/cs?searchtype=author&query=McCoy%2C+E">Elijah McCoy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 46 pages, 32 figures, 29 tables. arXiv admin note: substantial text overlap with <a href="/abs/2206.06476">arXiv:2206.06476</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19190" title="Abstract">arXiv:2305.19190</a> (replaced) [<a href="/pdf/2305.19190" title="Download PDF">pdf</a>, <a href="/format/2305.19190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inverse Approximation Theory for Nonlinear Recurrent Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shida Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhong Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qianxiao Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19621" title="Abstract">arXiv:2305.19621</a> (replaced) [<a href="/pdf/2305.19621" title="Download PDF">pdf</a>, <a href="/format/2305.19621" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> XTransCT: Ultra-Fast Volumetric CT Reconstruction using Two Orthogonal  X-Ray Projections for Image-guided Radiation Therapy via a Transformer  Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+C">Chulong Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+L">Lin Liu</a>, 
<a href="/search/eess?searchtype=author&query=Dai%2C+J">Jingjing Dai</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+X">Xuan Liu</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+W">Wenfeng He</a>, 
<a href="/search/eess?searchtype=author&query=Chan%2C+Y">Yinping Chan</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+Y">Yaoqin Xie</a>, 
<a href="/search/eess?searchtype=author&query=Chi%2C+F">Feng Chi</a>, 
<a href="/search/eess?searchtype=author&query=Liang%2C+X">Xiaokun Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Medical Physics (physics.med-ph)

</div>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02659" title="Abstract">arXiv:2306.02659</a> (replaced) [<a href="/pdf/2306.02659" title="Download PDF">pdf</a>, <a href="/format/2306.02659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Trajectory Optimization for Autonomous Terrain Traversal of  Articulated Tracked Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhengzhe Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yanbo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jian%2C+Z">Zhuozhu Jian</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+J">Junbo Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xueqian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+B">Bin Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Robotics and Automation Letters (RA-L)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03292" title="Abstract">arXiv:2306.03292</a> (replaced) [<a href="/pdf/2306.03292" title="Download PDF">pdf</a>, <a href="/format/2306.03292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convex Relaxation for Fokker-Planck
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+Y">Yian Chen</a>, 
<a href="/search/math?searchtype=author&query=Khoo%2C+Y">Yuehaw Khoo</a>, 
<a href="/search/math?searchtype=author&query=Lim%2C+L">Lek-Heng Lim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06064" title="Abstract">arXiv:2306.06064</a> (replaced) [<a href="/pdf/2306.06064" title="Download PDF">pdf</a>, <a href="/format/2306.06064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Algorithmic Reasoning for Combinatorial Optimisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Georgiev%2C+D">Dobrik Georgiev</a>, 
<a href="/search/cs?searchtype=author&query=Numeroso%2C+D">Danilo Numeroso</a>, 
<a href="/search/cs?searchtype=author&query=Bacciu%2C+D">Davide Bacciu</a>, 
<a href="/search/cs?searchtype=author&query=Li%C3%B2%2C+P">Pietro Li&#xf2;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06394" title="Abstract">arXiv:2306.06394</a> (replaced) [<a href="/pdf/2306.06394" title="Download PDF">pdf</a>, <a href="/format/2306.06394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PEAR: Primitive enabled Adaptive Relabeling for boosting Hierarchical  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+U">Utsav Singh</a>, 
<a href="/search/cs?searchtype=author&query=Namboodiri%2C+V+P">Vinay P Namboodiri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10548" title="Abstract">arXiv:2306.10548</a> (replaced) [<a href="/pdf/2306.10548" title="Download PDF">pdf</a>, <a href="/format/2306.10548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MARBLE: Music Audio Representation Benchmark for Universal Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+R">Ruibin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yinghao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yizhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Ge Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xingran Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hanzhi Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zhuo%2C+L">Le Zhuo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yiqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiawen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zeyue Tian</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+B">Binyue Deng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Ningzhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chenghua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Benetos%2C+E">Emmanouil Benetos</a>, 
<a href="/search/cs?searchtype=author&query=Ragni%2C+A">Anton Ragni</a>, 
<a href="/search/cs?searchtype=author&query=Gyenge%2C+N">Norbert Gyenge</a>, 
<a href="/search/cs?searchtype=author&query=Dannenberg%2C+R">Roger Dannenberg</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenhu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+G">Gus Xia</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+W">Wei Xue</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Si Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruibo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yike Guo</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> camera-ready version for NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10841" title="Abstract">arXiv:2306.10841</a> (replaced) [<a href="/pdf/2306.10841" title="Download PDF">pdf</a>, <a href="/format/2306.10841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blockchain-Enabled Federated Learning: A Reference Architecture Design,  Implementation, and Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goh%2C+E">Eunsu Goh</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dae-Yeol Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kwangkee Lee</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+S">Suyeong Oh</a>, 
<a href="/search/cs?searchtype=author&query=Chae%2C+J">Jong-Eui Chae</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Do-Yup Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 15 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10988" title="Abstract">arXiv:2306.10988</a> (replaced) [<a href="/pdf/2306.10988" title="Download PDF">pdf</a>, <a href="/format/2306.10988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tame a Wild Camera: In-the-Wild Monocular Camera Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Shengjie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Abhinav Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+M">Masa Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoming Liu</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11380" title="Abstract">arXiv:2306.11380</a> (replaced) [<a href="/pdf/2306.11380" title="Download PDF">pdf</a>, <a href="/format/2306.11380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Bayesian Take on Gaussian Process Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Giudice%2C+E">Enrico Giudice</a>, 
<a href="/search/stat?searchtype=author&query=Kuipers%2C+J">Jack Kuipers</a>, 
<a href="/search/stat?searchtype=author&query=Moffa%2C+G">Giusi Moffa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12070" title="Abstract">arXiv:2306.12070</a> (replaced) [<a href="/pdf/2306.12070" title="Download PDF">pdf</a>, <a href="/format/2306.12070" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task-Robust Pre-Training for Worst-Case Downstream Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianghui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xingyu Xie</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Cong Fang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhouchen Lin</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NIPS (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13262" title="Abstract">arXiv:2306.13262</a> (replaced) [<a href="/pdf/2306.13262" title="Download PDF">pdf</a>, <a href="/format/2306.13262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On reliable computation over larger alphabets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+A+K">Andrew K. Tan</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+M">Matthew Ho</a>, 
<a href="/search/cs?searchtype=author&query=Chuang%2C+I+L">Isaac L. Chuang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13686" title="Abstract">arXiv:2306.13686</a> (replaced) [<a href="/pdf/2306.13686" title="Download PDF">pdf</a>, <a href="/ps/2306.13686" title="Download PostScript">ps</a>, <a href="/format/2306.13686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Broadening the perspective for sustainable AI: Comprehensive  sustainability criteria and indicators for AI systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rohde%2C+F">Friederike Rohde</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+J">Josephin Wagner</a>, 
<a href="/search/cs?searchtype=author&query=Meyer%2C+A">Andreas Meyer</a>, 
<a href="/search/cs?searchtype=author&query=Reinhard%2C+P">Philipp Reinhard</a>, 
<a href="/search/cs?searchtype=author&query=Voss%2C+M">Marcus Voss</a>, 
<a href="/search/cs?searchtype=author&query=Petschow%2C+U">Ulrich Petschow</a>, 
<a href="/search/cs?searchtype=author&query=Mollen%2C+A">Anne Mollen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13724" title="Abstract">arXiv:2306.13724</a> (replaced) [<a href="/pdf/2306.13724" title="Download PDF">pdf</a>, <a href="/format/2306.13724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Review of compressed embedding layers and their applications for  recommender systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hajgato%2C+T">Tamas Hajgato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13802" title="Abstract">arXiv:2306.13802</a> (replaced) [<a href="/pdf/2306.13802" title="Download PDF">pdf</a>, <a href="/format/2306.13802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing representations of high-dimensional data with persistent  homology: a case study in neuroimaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Easley%2C+T">Ty Easley</a>, 
<a href="/search/cs?searchtype=author&query=Freese%2C+K">Kevin Freese</a>, 
<a href="/search/cs?searchtype=author&query=Munch%2C+E">Elizabeth Munch</a>, 
<a href="/search/cs?searchtype=author&query=Bijsterbosch%2C+J">Janine Bijsterbosch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Revision of preprint of submission for NeurIPS 2023 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Image and Video Processing (eess.IV); Algebraic Topology (math.AT); Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15030" title="Abstract">arXiv:2306.15030</a> (replaced) [<a href="/pdf/2306.15030" title="Download PDF">pdf</a>, <a href="/format/2306.15030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Equivariant flow matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Klein%2C+L">Leon Klein</a>, 
<a href="/search/stat?searchtype=author&query=Kr%C3%A4mer%2C+A">Andreas Kr&#xe4;mer</a>, 
<a href="/search/stat?searchtype=author&query=No%C3%A9%2C+F">Frank No&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Chemical Physics (physics.chem-ph); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15374" title="Abstract">arXiv:2306.15374</a> (replaced) [<a href="/pdf/2306.15374" title="Download PDF">pdf</a>, <a href="/format/2306.15374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LeCo: Lightweight Compression via Learning Serial Correlations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yihao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xinyu Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huanchen Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15381" title="Abstract">arXiv:2306.15381</a> (replaced) [<a href="/pdf/2306.15381" title="Download PDF">pdf</a>, <a href="/format/2306.15381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asymptotic-Preserving Neural Networks for Multiscale Kinetic Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jin%2C+S">Shi Jin</a>, 
<a href="/search/math?searchtype=author&query=Ma%2C+Z">Zheng Ma</a>, 
<a href="/search/math?searchtype=author&query=Wu%2C+K">Keke Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04494" title="Abstract">arXiv:2307.04494</a> (replaced) [<a href="/pdf/2307.04494" title="Download PDF">pdf</a>, <a href="/format/2307.04494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enabling Faster Locomotion of Planetary Rovers with a  Mechanically-Hybrid Suspension
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rodr%C3%ADguez-Mart%C3%ADnez%2C+D">David Rodr&#xed;guez-Mart&#xed;nez</a>, 
<a href="/search/cs?searchtype=author&query=Uno%2C+K">Kentaro Uno</a>, 
<a href="/search/cs?searchtype=author&query=Sawa%2C+K">Kenta Sawa</a>, 
<a href="/search/cs?searchtype=author&query=Uda%2C+M">Masahiro Uda</a>, 
<a href="/search/cs?searchtype=author&query=Kudo%2C+G">Gen Kudo</a>, 
<a href="/search/cs?searchtype=author&query=Diaz%2C+G+H">Gustavo Hernan Diaz</a>, 
<a href="/search/cs?searchtype=author&query=Umemura%2C+A">Ayumi Umemura</a>, 
<a href="/search/cs?searchtype=author&query=Santra%2C+S">Shreya Santra</a>, 
<a href="/search/cs?searchtype=author&query=Yoshida%2C+K">Kazuya Yoshida</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 12 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Robotics and Automation Letters, November 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06346" title="Abstract">arXiv:2307.06346</a> (replaced) [<a href="/pdf/2307.06346" title="Download PDF">pdf</a>, <a href="/format/2307.06346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sound One-Phase Shape Analysis with Biabduction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sextl%2C+F">Florian Sextl</a> (1), 
<a href="/search/cs?searchtype=author&query=Rogalewicz%2C+A">Adam Rogalewicz</a> (2), 
<a href="/search/cs?searchtype=author&query=Vojnar%2C+T">Tom&#xe1;&#x161; Vojnar</a> (2), 
<a href="/search/cs?searchtype=author&query=Zuleger%2C+F">Florian Zuleger</a> (1) ((1) TU Wien, Institute of Logic and Computation, Research Unit for Formal Methods in Systems Engineering, (2) Brno University of Technology, FIT)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 7 figures, under submission. Changes since first version: theory of section 5 was extended and overall presentation was improved
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07697" title="Abstract">arXiv:2307.07697</a> (replaced) [<a href="/pdf/2307.07697" title="Download PDF">pdf</a>, <a href="/format/2307.07697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Think-on-Graph: Deep and Responsible Reasoning of Large Language Model  on Knowledge Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiashuo Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chengjin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+L">Lumingyuan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Saizhuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yeyun Gong</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+L+M">Lionel M. Ni</a>, 
<a href="/search/cs?searchtype=author&query=Shum%2C+H">Heung-Yeung Shum</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jian Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 13 figures, 20 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07871" title="Abstract">arXiv:2307.07871</a> (replaced) [<a href="/pdf/2307.07871" title="Download PDF">pdf</a>, <a href="/format/2307.07871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The SocialAI School: Insights from Developmental Psychology Towards  Artificial Socio-Cultural Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kova%C4%8D%2C+G">Grgur Kova&#x10d;</a>, 
<a href="/search/cs?searchtype=author&query=Portelas%2C+R">R&#xe9;my Portelas</a>, 
<a href="/search/cs?searchtype=author&query=Dominey%2C+P+F">Peter Ford Dominey</a>, 
<a href="/search/cs?searchtype=author&query=Oudeyer%2C+P">Pierre-Yves Oudeyer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint, see v1 for a shorter version (accepted at the "Workshop on Theory-of-Mind" at ICML 2023) See project website for demo and code: <a href="https://sites.google.com/view/socialai-school">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08187" title="Abstract">arXiv:2307.08187</a> (replaced) [<a href="/pdf/2307.08187" title="Download PDF">pdf</a>, <a href="/format/2307.08187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Investigation of Pre-trained Model Selection for  Out-of-Distribution Generalization and Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naganuma%2C+H">Hiroki Naganuma</a>, 
<a href="/search/cs?searchtype=author&query=Hataya%2C+R">Ryuichiro Hataya</a>, 
<a href="/search/cs?searchtype=author&query=Mitliagkas%2C+I">Ioannis Mitliagkas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09157" title="Abstract">arXiv:2307.09157</a> (replaced) [<a href="/pdf/2307.09157" title="Download PDF">pdf</a>, <a href="/format/2307.09157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design Patterns for Situated Visualization in Augmented Reality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+B">Benjamin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Sedlmair%2C+M">Michael Sedlmair</a>, 
<a href="/search/cs?searchtype=author&query=Schmalstieg%2C+D">Dieter Schmalstieg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE VIS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10684" title="Abstract">arXiv:2307.10684</a> (replaced) [<a href="/pdf/2307.10684" title="Download PDF">pdf</a>, <a href="/format/2307.10684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A second order directional split exponential integrator for systems of  advection--diffusion--reaction equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Caliari%2C+M">Marco Caliari</a>, 
<a href="/search/math?searchtype=author&query=Cassini%2C+F">Fabio Cassini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12777" title="Abstract">arXiv:2307.12777</a> (replaced) [<a href="/pdf/2307.12777" title="Download PDF">pdf</a>, <a href="/ps/2307.12777" title="Download PostScript">ps</a>, <a href="/format/2307.12777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proceeding of the 1st Workshop on Social Robots Personalisation At the  crossroads between engineering and humanities (CONCATENATE)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tarakli%2C+I">Imene Tarakli</a>, 
<a href="/search/cs?searchtype=author&query=Angelopoulos%2C+G">Georgios Angelopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Hellou%2C+M">Mehdi Hellou</a>, 
<a href="/search/cs?searchtype=author&query=Vindolet%2C+C">Camille Vindolet</a>, 
<a href="/search/cs?searchtype=author&query=Abramovic%2C+B">Boris Abramovic</a>, 
<a href="/search/cs?searchtype=author&query=Limongelli%2C+R">Rocco Limongelli</a>, 
<a href="/search/cs?searchtype=author&query=Lacroix%2C+D">Dimitri Lacroix</a>, 
<a href="/search/cs?searchtype=author&query=Bertolini%2C+A">Andrea Bertolini</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+S">Silvia Rossi</a>, 
<a href="/search/cs?searchtype=author&query=Di+Nuovo%2C+A">Alessandro Di Nuovo</a>, 
<a href="/search/cs?searchtype=author&query=Cangelosi%2C+A">Angelo Cangelosi</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+G">Gordon Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item637">[637]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14287" title="Abstract">arXiv:2307.14287</a> (replaced) [<a href="/pdf/2307.14287" title="Download PDF">pdf</a>, <a href="/format/2307.14287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of Data Enrichment Methods for Distributed Stream Processing  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scheinert%2C+D">Dominik Scheinert</a>, 
<a href="/search/cs?searchtype=author&query=Casares%2C+F">Fabian Casares</a>, 
<a href="/search/cs?searchtype=author&query=Geldenhuys%2C+M+K">Morgan K. Geldenhuys</a>, 
<a href="/search/cs?searchtype=author&query=Styp-Rekowski%2C+K">Kevin Styp-Rekowski</a>, 
<a href="/search/cs?searchtype=author&query=Kao%2C+O">Odej Kao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 13 figures, 2 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE IC2E (2023) 202-211
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item638">[638]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15064" title="Abstract">arXiv:2307.15064</a> (replaced) [<a href="/pdf/2307.15064" title="Download PDF">pdf</a>, <a href="/format/2307.15064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Visual Acoustic Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Somayazulu%2C+A">Arjun Somayazulu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Changan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Grauman%2C+K">Kristen Grauman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://vision.cs.utexas.edu/projects/ss_vam/">this https URL</a> . Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Computer Vision and Pattern Recognition (cs.CV); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item639">[639]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16215" title="Abstract">arXiv:2307.16215</a> (replaced) [<a href="/pdf/2307.16215" title="Download PDF">pdf</a>, <a href="/ps/2307.16215" title="Download PostScript">ps</a>, <a href="/format/2307.16215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Multi-Trip Autonomous Mobile Robot Scheduling Problem with Time  Windows in a Stochastic Environment at Smart Hospitals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Lulu Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+N">Ning Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhibin Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item640">[640]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16449" title="Abstract">arXiv:2307.16449</a> (replaced) [<a href="/pdf/2307.16449" title="Download PDF">pdf</a>, <a href="/format/2307.16449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MovieChat: From Dense Token to Sparse Memory for Long Video  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+E">Enxin Song</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+W">Wenhao Chai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guanhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yucheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Haoyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Feiyang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+H">Haozhe Chi</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xun Guo</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+T">Tian Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanting Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J">Jenq-Neng Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Gaoang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. Project Website <a href="https://rese1f.github.io/MovieChat/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item641">[641]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04223" title="Abstract">arXiv:2308.04223</a> (replaced) [<a href="/pdf/2308.04223" title="Download PDF">pdf</a>, <a href="/format/2308.04223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-Time Progressive Learning: Accumulate Knowledge from Control with  Neural-Network-Based Selective Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fei%2C+Y">Yiming Fei</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+J">Jiangang Li</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yanan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item642">[642]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05303" title="Abstract">arXiv:2308.05303</a> (replaced) [<a href="/pdf/2308.05303" title="Download PDF">pdf</a>, <a href="/format/2308.05303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Visual-Inertial System: Analysis, Calibration and Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yulin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Geneva%2C+P">Patrick Geneva</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Guoquan Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item643">[643]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07741" title="Abstract">arXiv:2308.07741</a> (replaced) [<a href="/pdf/2308.07741" title="Download PDF">pdf</a>, <a href="/format/2308.07741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real Robot Challenge 2022: Learning Dexterous Manipulation from Offline  Data in the Real World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=G%C3%BCrtler%2C+N">Nico G&#xfc;rtler</a>, 
<a href="/search/cs?searchtype=author&query=Widmaier%2C+F">Felix Widmaier</a>, 
<a href="/search/cs?searchtype=author&query=Sancaktar%2C+C">Cansu Sancaktar</a>, 
<a href="/search/cs?searchtype=author&query=Blaes%2C+S">Sebastian Blaes</a>, 
<a href="/search/cs?searchtype=author&query=Kolev%2C+P">Pavel Kolev</a>, 
<a href="/search/cs?searchtype=author&query=Bauer%2C+S">Stefan Bauer</a>, 
<a href="/search/cs?searchtype=author&query=W%C3%BCthrich%2C+M">Manuel W&#xfc;thrich</a>, 
<a href="/search/cs?searchtype=author&query=Wulfmeier%2C+M">Markus Wulfmeier</a>, 
<a href="/search/cs?searchtype=author&query=Riedmiller%2C+M">Martin Riedmiller</a>, 
<a href="/search/cs?searchtype=author&query=Allshire%2C+A">Arthur Allshire</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=McCarthy%2C+R">Robert McCarthy</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hangyeol Kim</a>, 
<a href="/search/cs?searchtype=author&query=Baek%2C+J">Jongchan Baek</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+W">Wookyong Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+S">Shanliang Qian</a>, 
<a href="/search/cs?searchtype=author&query=Toshimitsu%2C+Y">Yasunori Toshimitsu</a>, 
<a href="/search/cs?searchtype=author&query=Michelis%2C+M+Y">Mike Yan Michelis</a>, 
<a href="/search/cs?searchtype=author&query=Kazemipour%2C+A">Amirhossein Kazemipour</a>, 
<a href="/search/cs?searchtype=author&query=Raayatsanati%2C+A">Arman Raayatsanati</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hehui Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Cangan%2C+B+G">Barnabas Gavin Cangan</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6lkopf%2C+B">Bernhard Sch&#xf6;lkopf</a>, 
<a href="/search/cs?searchtype=author&query=Martius%2C+G">Georg Martius</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Typo in author list fixed
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item644">[644]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08467" title="Abstract">arXiv:2308.08467</a> (replaced) [<a href="/pdf/2308.08467" title="Download PDF">pdf</a>, <a href="/ps/2308.08467" title="Download PostScript">ps</a>, <a href="/format/2308.08467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Neural Quantum Support Vector Machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Simon%2C+L">Lars Simon</a>, 
<a href="/search/quant-ph?searchtype=author&query=Radons%2C+M">Manuel Radons</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 1 figure. arXiv admin note: substantial text overlap with <a href="/abs/2308.07204">arXiv:2308.07204</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item645">[645]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09043" title="Abstract">arXiv:2308.09043</a> (replaced) [<a href="/pdf/2308.09043" title="Download PDF">pdf</a>, <a href="/format/2308.09043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kernel-Based Tests for Likelihood-Free Hypothesis Testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Gerber%2C+P+R">Patrik R&#xf3;bert Gerber</a>, 
<a href="/search/stat?searchtype=author&query=Jiang%2C+T">Tianze Jiang</a>, 
<a href="/search/stat?searchtype=author&query=Polyanskiy%2C+Y">Yury Polyanskiy</a>, 
<a href="/search/stat?searchtype=author&query=Sun%2C+R">Rui Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item646">[646]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09549" title="Abstract">arXiv:2308.09549</a> (replaced) [<a href="/pdf/2308.09549" title="Download PDF">pdf</a>, <a href="/format/2308.09549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum and Probabilistic Computers Rigorously Powerful than Traditional  Computers, and Derandomization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+T">Tianrong Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> [v4] 35 pages, 5 figures; arXiv admin note: text overlap with <a href="/abs/2110.06211">arXiv:2110.06211</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item647">[647]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09687" title="Abstract">arXiv:2308.09687</a> (replaced) [<a href="/pdf/2308.09687" title="Download PDF">pdf</a>, <a href="/format/2308.09687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph of Thoughts: Solving Elaborate Problems with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Besta%2C+M">Maciej Besta</a>, 
<a href="/search/cs?searchtype=author&query=Blach%2C+N">Nils Blach</a>, 
<a href="/search/cs?searchtype=author&query=Kubicek%2C+A">Ales Kubicek</a>, 
<a href="/search/cs?searchtype=author&query=Gerstenberger%2C+R">Robert Gerstenberger</a>, 
<a href="/search/cs?searchtype=author&query=Gianinazzi%2C+L">Lukas Gianinazzi</a>, 
<a href="/search/cs?searchtype=author&query=Gajda%2C+J">Joanna Gajda</a>, 
<a href="/search/cs?searchtype=author&query=Lehmann%2C+T">Tomasz Lehmann</a>, 
<a href="/search/cs?searchtype=author&query=Podstawski%2C+M">Michal Podstawski</a>, 
<a href="/search/cs?searchtype=author&query=Niewiadomski%2C+H">Hubert Niewiadomski</a>, 
<a href="/search/cs?searchtype=author&query=Nyczyk%2C+P">Piotr Nyczyk</a>, 
<a href="/search/cs?searchtype=author&query=Hoefler%2C+T">Torsten Hoefler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item648">[648]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10192" title="Abstract">arXiv:2308.10192</a> (replaced) [<a href="/pdf/2308.10192" title="Download PDF">pdf</a>, <a href="/ps/2308.10192" title="Download PostScript">ps</a>, <a href="/format/2308.10192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EDDense-Net: Fully Dense Encoder Decoder Network for Joint Segmentation  of Optic Cup and Disc
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mehmood%2C+M">Mehwish Mehmood</a>, 
<a href="/search/eess?searchtype=author&query=Naveed%2C+K">Khuram Naveed</a>, 
<a href="/search/eess?searchtype=author&query=Aurangzeb%2C+K">Khursheed Aurangzeb</a>, 
<a href="/search/eess?searchtype=author&query=Khan%2C+H+A">Haroon Ahmed Khan</a>, 
<a href="/search/eess?searchtype=author&query=Alhussein%2C+M">Musaed Alhussein</a>, 
<a href="/search/eess?searchtype=author&query=Naqvi%2C+S+S">Syed Saud Naqvi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item649">[649]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11792" title="Abstract">arXiv:2308.11792</a> (replaced) [<a href="/pdf/2308.11792" title="Download PDF">pdf</a>, <a href="/format/2308.11792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Karasu: A Collaborative Approach to Efficient Cluster Configuration for  Big Data Analytics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scheinert%2C+D">Dominik Scheinert</a>, 
<a href="/search/cs?searchtype=author&query=Wiesner%2C+P">Philipp Wiesner</a>, 
<a href="/search/cs?searchtype=author&query=Wittkopp%2C+T">Thorsten Wittkopp</a>, 
<a href="/search/cs?searchtype=author&query=Thamsen%2C+L">Lauritz Thamsen</a>, 
<a href="/search/cs?searchtype=author&query=Will%2C+J">Jonathan Will</a>, 
<a href="/search/cs?searchtype=author&query=Kao%2C+O">Odej Kao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 9 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE IPCCC (2023) 403-412
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item650">[650]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12319" title="Abstract">arXiv:2308.12319</a> (replaced) [<a href="/pdf/2308.12319" title="Download PDF">pdf</a>, <a href="/format/2308.12319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RemovalNet: DNN Fingerprint Removal Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+H">Hongwei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kunzhe Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+J">Jian Lou</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhan Qin</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+K">Kui Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE TDSC, code is available at: <a href="https://github.com/grasses/RemovalNet">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item651">[651]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14936" title="Abstract">arXiv:2308.14936</a> (replaced) [<a href="/pdf/2308.14936" title="Download PDF">pdf</a>, <a href="/format/2308.14936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Auto-Prompting SAM for Mobile Friendly 3D Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chengyin Li</a>, 
<a href="/search/cs?searchtype=author&query=Khanduri%2C+P">Prashant Khanduri</a>, 
<a href="/search/cs?searchtype=author&query=Qiang%2C+Y">Yao Qiang</a>, 
<a href="/search/cs?searchtype=author&query=Sultan%2C+R+I">Rafi Ibn Sultan</a>, 
<a href="/search/cs?searchtype=author&query=Chetty%2C+I">Indrin Chetty</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+D">Dongxiao Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item652">[652]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16097" title="Abstract">arXiv:2308.16097</a> (replaced) [<a href="/pdf/2308.16097" title="Download PDF">pdf</a>, <a href="/ps/2308.16097" title="Download PostScript">ps</a>, <a href="/format/2308.16097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quasioptimal alternating projections and their use in low-rank  approximation of matrices and tensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Budzinskiy%2C+S">Stanislav Budzinskiy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated the experiments related to the maximum norm
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item653">[653]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16483" title="Abstract">arXiv:2308.16483</a> (replaced) [<a href="/pdf/2308.16483" title="Download PDF">pdf</a>, <a href="/format/2308.16483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Out-of-Distribution Detection in Echocardiographic View  Classication through Enhancing Semantic Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jeon%2C+J">Jaeik Jeon</a>, 
<a href="/search/eess?searchtype=author&query=Ha%2C+S">Seongmin Ha</a>, 
<a href="/search/eess?searchtype=author&query=Jang%2C+Y">Yeonggul Jang</a>, 
<a href="/search/eess?searchtype=author&query=Yoon%2C+Y+E">Yeonyee E. Yoon</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+J">Jiyeon Kim</a>, 
<a href="/search/eess?searchtype=author&query=Jeong%2C+H">Hyunseok Jeong</a>, 
<a href="/search/eess?searchtype=author&query=Jeong%2C+D">Dawun Jeong</a>, 
<a href="/search/eess?searchtype=author&query=Hong%2C+Y">Youngtaek Hong</a>, 
<a href="/search/eess?searchtype=author&query=Chang%2C+S+L+H">Seung-Ah Lee Hyuk-Jae Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item654">[654]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16748" title="Abstract">arXiv:2308.16748</a> (replaced) [<a href="/pdf/2308.16748" title="Download PDF">pdf</a>, <a href="/format/2308.16748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Perception and Semantic Mapping Method for Robot Autonomy in  Orchards
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yaoqiang Pan</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">Hao Cao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+K">Kewei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+H">Hanwen Kang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xing Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item655">[655]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00168" title="Abstract">arXiv:2309.00168</a> (replaced) [<a href="/pdf/2309.00168" title="Download PDF">pdf</a>, <a href="/format/2309.00168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pose-Graph Attentional Graph Neural Network for Lidar Place Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramezani%2C+M">Milad Ramezani</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Knights%2C+J">Joshua Knights</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhibin Li</a>, 
<a href="/search/cs?searchtype=author&query=Pounds%2C+P">Pauline Pounds</a>, 
<a href="/search/cs?searchtype=author&query=Moghadam%2C+P">Peyman Moghadam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures, 5 tables, Accepted for Publication in the IEEE Robotics and Automation Letters (RA-L)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item656">[656]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00544" title="Abstract">arXiv:2309.00544</a> (replaced) [<a href="/pdf/2309.00544" title="Download PDF">pdf</a>, <a href="/ps/2309.00544" title="Download PostScript">ps</a>, <a href="/format/2309.00544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modular, Multi-Robot Integration of Laboratories: An Autonomous  Solid-State Workflow for Powder X-Ray Diffraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lunt%2C+A+M">Amy. M. Lunt</a>, 
<a href="/search/cs?searchtype=author&query=Fakhruldeen%2C+H">Hatem Fakhruldeen</a>, 
<a href="/search/cs?searchtype=author&query=Pizzuto%2C+G">Gabriella Pizzuto</a>, 
<a href="/search/cs?searchtype=author&query=Longley%2C+L">Louis Longley</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+A">Alexander White</a>, 
<a href="/search/cs?searchtype=author&query=Rankin%2C+N">Nicola Rankin</a>, 
<a href="/search/cs?searchtype=author&query=Clowes%2C+R">Rob Clowes</a>, 
<a href="/search/cs?searchtype=author&query=Alston%2C+B">Ben Alston</a>, 
<a href="/search/cs?searchtype=author&query=Gigli%2C+L">Lucia Gigli</a>, 
<a href="/search/cs?searchtype=author&query=Day%2C+G+M">Graeme M. Day</a>, 
<a href="/search/cs?searchtype=author&query=Cooper%2C+A+I">Andrew I. Cooper</a>, 
<a href="/search/cs?searchtype=author&query=Chong%2C+S+Y">Sam. Y. Chong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item657">[657]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00851" title="Abstract">arXiv:2309.00851</a> (replaced) [<a href="/pdf/2309.00851" title="Download PDF">pdf</a>, <a href="/format/2309.00851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Drift Analysis with Fitness Levels for Elitist Evolutionary Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jun He</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuren Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item658">[658]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01805" title="Abstract">arXiv:2309.01805</a> (replaced) [<a href="/pdf/2309.01805" title="Download PDF">pdf</a>, <a href="/format/2309.01805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Kubernetes to Knactor: A Data-Centric Rethink of Service  Composition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+S">Silvery Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Teoh%2C+R">Ryan Teoh</a>, 
<a href="/search/cs?searchtype=author&query=Priadka%2C+T">Taras Priadka</a>, 
<a href="/search/cs?searchtype=author&query=Ratnasamy%2C+S">Sylvia Ratnasamy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Corrected terms
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item659">[659]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02301" title="Abstract">arXiv:2309.02301</a> (replaced) [<a href="/pdf/2309.02301" title="Download PDF">pdf</a>, <a href="/format/2309.02301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CIEM: Contrastive Instruction Evaluation Method for Better Instruction  Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hongyu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+M">Minyi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhenbang Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item660">[660]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02317" title="Abstract">arXiv:2309.02317</a> (replaced) [<a href="/pdf/2309.02317" title="Download PDF">pdf</a>, <a href="/format/2309.02317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A study on the impact of pre-trained model on Just-In-Time defect  prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuxiang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiaopeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+W+K">W.K.Chan</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Bo Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by QRS2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item661">[661]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03493" title="Abstract">arXiv:2309.03493</a> (replaced) [<a href="/pdf/2309.03493" title="Download PDF">pdf</a>, <a href="/format/2309.03493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAM3D: Segment Anything Model in Volumetric Medical Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bui%2C+N">Nhat-Tan Bui</a>, 
<a href="/search/eess?searchtype=author&query=Hoang%2C+D">Dinh-Hieu Hoang</a>, 
<a href="/search/eess?searchtype=author&query=Tran%2C+M">Minh-Triet Tran</a>, 
<a href="/search/eess?searchtype=author&query=Doretto%2C+G">Gianfranco Doretto</a>, 
<a href="/search/eess?searchtype=author&query=Adjeroh%2C+D">Donald Adjeroh</a>, 
<a href="/search/eess?searchtype=author&query=Patel%2C+B">Brijesh Patel</a>, 
<a href="/search/eess?searchtype=author&query=Choudhary%2C+A">Arabinda Choudhary</a>, 
<a href="/search/eess?searchtype=author&query=Le%2C+N">Ngan Le</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item662">[662]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04885" title="Abstract">arXiv:2309.04885</a> (replaced) [<a href="/pdf/2309.04885" title="Download PDF">pdf</a>, <a href="/format/2309.04885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symplectic Structure-Aware Hamiltonian (Graph) Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaxu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+X">Xinping Yi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianle Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaowei Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages main content with 5 pages appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Symplectic Geometry (math.SG)

</div>
</div>
</dd>
<dt><a name="item663">[663]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05238" title="Abstract">arXiv:2309.05238</a> (replaced) [<a href="/pdf/2309.05238" title="Download PDF">pdf</a>, <a href="/format/2309.05238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Natural Language Queries for More Effective Systematic Review  Screening Prioritisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Scells%2C+H">Harrisen Scells</a>, 
<a href="/search/cs?searchtype=author&query=Potthast%2C+M">Martin Potthast</a>, 
<a href="/search/cs?searchtype=author&query=Koopman%2C+B">Bevan Koopman</a>, 
<a href="/search/cs?searchtype=author&query=Zuccon%2C+G">Guido Zuccon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprints for Accepted paper in SIGIR-AP-2023, note that this is updated from ACM published paper. The working title was wrong in the ACM-published version due to a bug in data preprocessing; however, this does not have any influence on the final conclusion/observation made from the paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item664">[664]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07359" title="Abstract">arXiv:2309.07359</a> (replaced) [<a href="/pdf/2309.07359" title="Download PDF">pdf</a>, <a href="/ps/2309.07359" title="Download PostScript">ps</a>, <a href="/format/2309.07359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast WDM provisioning with minimal probing: the first field experiments  for DC exchanges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Nishizawa%2C+H">Hideki Nishizawa</a>, 
<a href="/search/eess?searchtype=author&query=Mano%2C+T">Toru Mano</a>, 
<a href="/search/eess?searchtype=author&query=De+Lima%2C+T+F">Thomas Ferreira De Lima</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+Y">Yue-Kai Huang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zehao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Ishida%2C+W">Wataru Ishida</a>, 
<a href="/search/eess?searchtype=author&query=Kawashima%2C+M">Masahisa Kawashima</a>, 
<a href="/search/eess?searchtype=author&query=Ip%2C+E">Ezra Ip</a>, 
<a href="/search/eess?searchtype=author&query=D%27Amico%2C+A">Andrea D&#x27;Amico</a>, 
<a href="/search/eess?searchtype=author&query=Okamoto%2C+S">Seiji Okamoto</a>, 
<a href="/search/eess?searchtype=author&query=Inoue%2C+T">Takeru Inoue</a>, 
<a href="/search/eess?searchtype=author&query=Anazawa%2C+K">Kazuya Anazawa</a>, 
<a href="/search/eess?searchtype=author&query=Curri%2C+V">Vittorio Curri</a>, 
<a href="/search/eess?searchtype=author&query=Zussman%2C+G">Gil Zussman</a>, 
<a href="/search/eess?searchtype=author&query=Kilper%2C+D">Daniel Kilper</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+T">Tingjun Chen</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+T">Ting Wang</a>, 
<a href="/search/eess?searchtype=author&query=Asahi%2C+K">Koji Asahi</a>, 
<a href="/search/eess?searchtype=author&query=Takasugi%2C+K">Koichi Takasugi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 11 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item665">[665]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08273" title="Abstract">arXiv:2309.08273</a> (replaced) [<a href="/pdf/2309.08273" title="Download PDF">pdf</a>, <a href="/format/2309.08273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Disentangling of Facial Representations with 3D-aware  Latent Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ruian He</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Z">Zhen Xing</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+W">Weimin Tan</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+B">Bo Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item666">[666]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08745" title="Abstract">arXiv:2309.08745</a> (replaced) [<a href="/pdf/2309.08745" title="Download PDF">pdf</a>, <a href="/format/2309.08745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Breast Cancer Diagnosis through Transfer Learning on  Hematoxylin and Eosin Stained Histology Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+F">Fahad Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Abdel-Salam%2C+R">Reem Abdel-Salam</a>, 
<a href="/search/cs?searchtype=author&query=Hamnett%2C+L">Leon Hamnett</a>, 
<a href="/search/cs?searchtype=author&query=Adewunmi%2C+M">Mary Adewunmi</a>, 
<a href="/search/cs?searchtype=author&query=Ayano%2C+T">Temitope Ayano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cell Behavior (q-bio.CB)

</div>
</div>
</dd>
<dt><a name="item667">[667]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09384" title="Abstract">arXiv:2309.09384</a> (replaced) [<a href="/pdf/2309.09384" title="Download PDF">pdf</a>, <a href="/format/2309.09384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Over-Smoothing and Over-Squashing using Augmentations of  Forman-Ricci Curvature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fesser%2C+L">Lukas Fesser</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+M">Melanie Weber</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item668">[668]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09904" title="Abstract">arXiv:2309.09904</a> (replaced) [<a href="/pdf/2309.09904" title="Download PDF">pdf</a>, <a href="/format/2309.09904" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Generate Lumped Hydrological Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Yang%2C+Y">Yang Yang</a>, 
<a href="/search/physics?searchtype=author&query=Chui%2C+T+F+M">Ting Fong May Chui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geophysics (physics.geo-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item669">[669]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09968" title="Abstract">arXiv:2309.09968</a> (replaced) [<a href="/pdf/2309.09968" title="Download PDF">pdf</a>, <a href="/format/2309.09968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating and Imputing Tabular Data via Diffusion and Flow-based  Gradient-Boosted Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jolicoeur-Martineau%2C+A">Alexia Jolicoeur-Martineau</a>, 
<a href="/search/cs?searchtype=author&query=Fatras%2C+K">Kilian Fatras</a>, 
<a href="/search/cs?searchtype=author&query=Kachman%2C+T">Tal Kachman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code: <a href="https://github.com/SamsungSAILMontreal/ForestDiffusion">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item670">[670]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11911" title="Abstract">arXiv:2309.11911</a> (replaced) [<a href="/pdf/2309.11911" title="Download PDF">pdf</a>, <a href="/format/2309.11911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InstructERC: Reforming Emotion Recognition in Conversation with a  Retrieval Multi-task LLMs Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+S">Shanglin Lei</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+G">Guanting Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Keheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sirui Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item671">[671]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12318" title="Abstract">arXiv:2309.12318</a> (replaced) [<a href="/pdf/2309.12318" title="Download PDF">pdf</a>, <a href="/ps/2309.12318" title="Download PostScript">ps</a>, <a href="/format/2309.12318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic scheduling of autonomous mobile robots at hospitals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Lulu Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+N">Ning Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+M">Mengge Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kan Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item672">[672]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12862" title="Abstract">arXiv:2309.12862</a> (replaced) [<a href="/pdf/2309.12862" title="Download PDF">pdf</a>, <a href="/format/2309.12862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Associative Transformer Is A Sparse Representation Learner
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuwei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ochiai%2C+H">Hideya Ochiai</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhirong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Stephen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Kanai%2C+R">Ryota Kanai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item673">[673]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14156" title="Abstract">arXiv:2309.14156</a> (replaced) [<a href="/pdf/2309.14156" title="Download PDF">pdf</a>, <a href="/format/2309.14156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing and evaluating an online reinforcement learning agent for  physical exercise recommendations in N-of-1 trials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meier%2C+D">Dominik Meier</a>, 
<a href="/search/cs?searchtype=author&query=Ensari%2C+I">Ipek Ensari</a>, 
<a href="/search/cs?searchtype=author&query=Konigorski%2C+S">Stefan Konigorski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item674">[674]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15643" title="Abstract">arXiv:2309.15643</a> (replaced) [<a href="/pdf/2309.15643" title="Download PDF">pdf</a>, <a href="/format/2309.15643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Why do Angular Margin Losses work well for Semi-Supervised Anomalous  Sound Detection?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wilkinghoff%2C+K">Kevin Wilkinghoff</a>, 
<a href="/search/eess?searchtype=author&query=Kurth%2C+F">Frank Kurth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item675">[675]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17169" title="Abstract">arXiv:2309.17169</a> (replaced) [<a href="/pdf/2309.17169" title="Download PDF">pdf</a>, <a href="/ps/2309.17169" title="Download PostScript">ps</a>, <a href="/format/2309.17169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An evaluation of GPT models for phenotype concept recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Groza%2C+T">Tudor Groza</a>, 
<a href="/search/cs?searchtype=author&query=Caufield%2C+H">Harry Caufield</a>, 
<a href="/search/cs?searchtype=author&query=Gration%2C+D">Dylan Gration</a>, 
<a href="/search/cs?searchtype=author&query=Baynam%2C+G">Gareth Baynam</a>, 
<a href="/search/cs?searchtype=author&query=Haendel%2C+M+A">Melissa A Haendel</a>, 
<a href="/search/cs?searchtype=author&query=Robinson%2C+P+N">Peter N Robinson</a>, 
<a href="/search/cs?searchtype=author&query=Mungall%2C+C+J">Christopher J Mungall</a>, 
<a href="/search/cs?searchtype=author&query=Reese%2C+J+T">Justin T Reese</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item676">[676]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17296" title="Abstract">arXiv:2309.17296</a> (replaced) [<a href="/pdf/2309.17296" title="Download PDF">pdf</a>, <a href="/format/2309.17296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigating the Design Space of Equivariant Diffusion-Based Generative  Models for De Novo 3D Molecule Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+T">Tuan Le</a>, 
<a href="/search/cs?searchtype=author&query=Cremer%2C+J">Julian Cremer</a>, 
<a href="/search/cs?searchtype=author&query=No%C3%A9%2C+F">Frank No&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Clevert%2C+D">Djork-Arn&#xe9; Clevert</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%BCtt%2C+K">Kristof Sch&#xfc;tt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item677">[677]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17389" title="Abstract">arXiv:2309.17389</a> (replaced) [<a href="/pdf/2309.17389" title="Download PDF">pdf</a>, <a href="/format/2309.17389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt-based test-time real image dehazing: a novel pipeline
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zixuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zewei He</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Ziqian Lu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xuecheng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhe-Ming Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> update github link (<a href="https://github.com/cecret3350/PTTD-Dehazing">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item678">[678]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00116" title="Abstract">arXiv:2310.00116</a> (replaced) [<a href="/pdf/2310.00116" title="Download PDF">pdf</a>, <a href="/format/2310.00116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Certified Robustness via Dynamic Margin Maximization and Improved  Lipschitz Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fazlyab%2C+M">Mahyar Fazlyab</a>, 
<a href="/search/cs?searchtype=author&query=Entesari%2C+T">Taha Entesari</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+A">Aniket Roy</a>, 
<a href="/search/cs?searchtype=author&query=Chellappa%2C+R">Rama Chellappa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item679">[679]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00574" title="Abstract">arXiv:2310.00574</a> (replaced) [<a href="/pdf/2310.00574" title="Download PDF">pdf</a>, <a href="/format/2310.00574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> YFlows: Systematic Dataflow Exploration and Code Generation for  Efficient Neural Network Inference using SIMD Architectures on CPUs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Cyrus Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hassman%2C+Z">Zack Hassman</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ruize Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+D">Dhirpal Shah</a>, 
<a href="/search/cs?searchtype=author&query=Richard%2C+V">Vaugnn Richard</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanjing Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Machine Learning (cs.LG); Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item680">[680]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00583" title="Abstract">arXiv:2310.00583</a> (replaced) [<a href="/pdf/2310.00583" title="Download PDF">pdf</a>, <a href="/format/2310.00583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> City Foundation Models for Learning General Purpose Representations from  OpenStreetMap
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balsebre%2C+P">Pasquale Balsebre</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Weiming Huang</a>, 
<a href="/search/cs?searchtype=author&query=Cong%2C+G">Gao Cong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yi Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item681">[681]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00648" title="Abstract">arXiv:2310.00648</a> (replaced) [<a href="/pdf/2310.00648" title="Download PDF">pdf</a>, <a href="/format/2310.00648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fewer is More: Trojan Attacks on Parameter-Efficient Fine-Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+L">Lauren Hong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Ting Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item682">[682]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00692" title="Abstract">arXiv:2310.00692</a> (replaced) [<a href="/pdf/2310.00692" title="Download PDF">pdf</a>, <a href="/format/2310.00692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Noise Geometry of Stochastic Gradient Descent: A Quantitative and  Analytical Characterization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mingze Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lei Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item683">[683]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00912" title="Abstract">arXiv:2310.00912</a> (replaced) [<a href="/pdf/2310.00912" title="Download PDF">pdf</a>, <a href="/ps/2310.00912" title="Download PostScript">ps</a>, <a href="/format/2310.00912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Resource-efficient FIR Filter Design Based on an RAG Improved  Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+M">Mengwei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhengxiong Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xianyang Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 3 figures, Conference paper for ICCS (International Conference on Circuits and Systems) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item684">[684]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01087" title="Abstract">arXiv:2310.01087</a> (replaced) [<a href="/pdf/2310.01087" title="Download PDF">pdf</a>, <a href="/format/2310.01087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel DID Method Leveraging the IOTA Tangle and its Integration into  OpenSSL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Claudio%2C+A">Alessio Claudio</a>, 
<a href="/search/cs?searchtype=author&query=Vesco%2C+A">Andrea Vesco</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item685">[685]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01225" title="Abstract">arXiv:2310.01225</a> (replaced) [<a href="/pdf/2310.01225" title="Download PDF">pdf</a>, <a href="/format/2310.01225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A path-norm toolkit for modern networks: consequences, promises and  challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Gonon%2C+A">Antoine Gonon</a>, 
<a href="/search/stat?searchtype=author&query=Brisebarre%2C+N">Nicolas Brisebarre</a>, 
<a href="/search/stat?searchtype=author&query=Riccietti%2C+E">Elisa Riccietti</a>, 
<a href="/search/stat?searchtype=author&query=Gribonval%2C+R">R&#xe9;mi Gribonval</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item686">[686]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01769" title="Abstract">arXiv:2310.01769</a> (replaced) [<a href="/pdf/2310.01769" title="Download PDF">pdf</a>, <a href="/format/2310.01769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Over-Parameterization Slows Down Gradient Descent in Matrix Sensing:  The Curses of Symmetry and Initialization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+N">Nuoya Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Lijun Ding</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+S+S">Simon S. Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item687">[687]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02428" title="Abstract">arXiv:2310.02428</a> (replaced) [<a href="/pdf/2310.02428" title="Download PDF">pdf</a>, <a href="/format/2310.02428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EGraFFBench: Evaluation of Equivariant Graph Neural Network Force Fields  for Atomistic Simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bihani%2C+V">Vaibhav Bihani</a>, 
<a href="/search/cs?searchtype=author&query=Pratiush%2C+U">Utkarsh Pratiush</a>, 
<a href="/search/cs?searchtype=author&query=Mannan%2C+S">Sajid Mannan</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+T">Tao Du</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhimin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Miret%2C+S">Santiago Miret</a>, 
<a href="/search/cs?searchtype=author&query=Micoulaut%2C+M">Matthieu Micoulaut</a>, 
<a href="/search/cs?searchtype=author&query=Smedskjaer%2C+M+M">Morten M Smedskjaer</a>, 
<a href="/search/cs?searchtype=author&query=Ranu%2C+S">Sayan Ranu</a>, 
<a href="/search/cs?searchtype=author&query=Krishnan%2C+N+M+A">N M Anoop Krishnan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Materials Science (cond-mat.mtrl-sci)

</div>
</div>
</dd>
<dt><a name="item688">[688]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02970" title="Abstract">arXiv:2310.02970</a> (replaced) [<a href="/pdf/2310.02970" title="Download PDF">pdf</a>, <a href="/format/2310.02970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast, Expressive SE$(n)$ Equivariant Networks through Weight-Sharing in  Position-Orientation Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bekkers%2C+E+J">Erik J Bekkers</a>, 
<a href="/search/cs?searchtype=author&query=Vadgama%2C+S">Sharvaree Vadgama</a>, 
<a href="/search/cs?searchtype=author&query=Hesselink%2C+R+D">Rob D Hesselink</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Linden%2C+P+A">Putri A van der Linden</a>, 
<a href="/search/cs?searchtype=author&query=Romero%2C+D+W">David W Romero</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Our code is publicly available at <a href="https://github.com/ebekkers/ponita">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Group Theory (math.GR)

</div>
</div>
</dd>
<dt><a name="item689">[689]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04227" title="Abstract">arXiv:2310.04227</a> (replaced) [<a href="/pdf/2310.04227" title="Download PDF">pdf</a>, <a href="/ps/2310.04227" title="Download PostScript">ps</a>, <a href="/format/2310.04227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Identification of Nonlinear Dynamics with Side Information  (SINDy-SI)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Machado%2C+G+F">Gabriel F. Machado</a>, 
<a href="/search/eess?searchtype=author&query=Jones%2C+M">Morgan Jones</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item690">[690]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04483" title="Abstract">arXiv:2310.04483</a> (replaced) [<a href="/pdf/2310.04483" title="Download PDF">pdf</a>, <a href="/format/2310.04483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reward Dropout Improves Control: Bi-objective Perspective on Reinforced  LM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Changhun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+C">Chiehyeon Lim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 13 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item691">[691]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04656" title="Abstract">arXiv:2310.04656</a> (replaced) [<a href="/pdf/2310.04656" title="Download PDF">pdf</a>, <a href="/format/2310.04656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerated high-index saddle dynamics method for searching high-index  saddle points
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Luo%2C+Y">Yue Luo</a>, 
<a href="/search/math?searchtype=author&query=Zheng%2C+X">Xiangcheng Zheng</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item692">[692]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05028" title="Abstract">arXiv:2310.05028</a> (replaced) [<a href="/pdf/2310.05028" title="Download PDF">pdf</a>, <a href="/format/2310.05028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Large Language Models as Zero-shot Relation Extractors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guozheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+W">Wenjun Ke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item693">[693]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05052" title="Abstract">arXiv:2310.05052</a> (replaced) [<a href="/pdf/2310.05052" title="Download PDF">pdf</a>, <a href="/format/2310.05052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accurate battery lifetime prediction across diverse aging conditions  with deep learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+H">Han Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yuqi Li</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+S">Shun Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+Z">Ziheng Lu</a>, 
<a href="/search/eess?searchtype=author&query=Gui%2C+X">Xiaofan Gui</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+W">Wei Xu</a>, 
<a href="/search/eess?searchtype=author&query=Bian%2C+J">Jiang Bian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item694">[694]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05898" title="Abstract">arXiv:2310.05898</a> (replaced) [<a href="/pdf/2310.05898" title="Download PDF">pdf</a>, <a href="/format/2310.05898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lion Secretly Solves Constrained Optimization: As Lyapunov Predicts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lizhang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+K">Kaizhao Liang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qiang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC); Applications (stat.AP); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item695">[695]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06110" title="Abstract">arXiv:2310.06110</a> (replaced) [<a href="/pdf/2310.06110" title="Download PDF">pdf</a>, <a href="/format/2310.06110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grokking as the Transition from Lazy to Rich Training Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Kumar%2C+T">Tanishq Kumar</a>, 
<a href="/search/stat?searchtype=author&query=Bordelon%2C+B">Blake Bordelon</a>, 
<a href="/search/stat?searchtype=author&query=Gershman%2C+S+J">Samuel J. Gershman</a>, 
<a href="/search/stat?searchtype=author&query=Pehlevan%2C+C">Cengiz Pehlevan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Adding new experiments on higher degree Hermite polynomials, multi-index targets and theoretical analysis with DMFT for high dimensional data
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item696">[696]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06214" title="Abstract">arXiv:2310.06214</a> (replaced) [<a href="/pdf/2310.06214" title="Download PDF">pdf</a>, <a href="/format/2310.06214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoT3DRef: Chain-of-Thoughts Data-Efficient 3D Visual Grounding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bakr%2C+E+M">Eslam Mohamed Bakr</a>, 
<a href="/search/cs?searchtype=author&query=Ayman%2C+M">Mohamed Ayman</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+M">Mahmoud Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Slim%2C+H">Habib Slim</a>, 
<a href="/search/cs?searchtype=author&query=Elhoseiny%2C+M">Mohamed Elhoseiny</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item697">[697]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06663" title="Abstract">arXiv:2310.06663</a> (replaced) [<a href="/pdf/2310.06663" title="Download PDF">pdf</a>, <a href="/ps/2310.06663" title="Download PostScript">ps</a>, <a href="/format/2310.06663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Cache-Friendly Priority Queue: Enhancing Heap-Tree Efficiency  for Modern Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parvizi%2C+K">Kiarash Parvizi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item698">[698]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07180" title="Abstract">arXiv:2310.07180</a> (replaced) [<a href="/pdf/2310.07180" title="Download PDF">pdf</a>, <a href="/format/2310.07180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrated Sensing and Communication enabled Multiple Base Stations  Cooperative Sensing Towards 6G
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhiqing Wei</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wangjun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhiyong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Huici Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Kaifeng Han</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ruizhong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Ping Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages 6 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE NetWork 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item699">[699]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08454" title="Abstract">arXiv:2310.08454</a> (replaced) [<a href="/pdf/2310.08454" title="Download PDF">pdf</a>, <a href="/ps/2310.08454" title="Download PostScript">ps</a>, <a href="/format/2310.08454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster Ascending Auctions via Polymatroid Sum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eickhoff%2C+K">Katharina Eickhoff</a>, 
<a href="/search/cs?searchtype=author&query=Peis%2C+B">Britta Peis</a>, 
<a href="/search/cs?searchtype=author&query=Rieken%2C+N">Niklas Rieken</a>, 
<a href="/search/cs?searchtype=author&query=Koch%2C+L+V">Laura Vargas Koch</a>, 
<a href="/search/cs?searchtype=author&query=V%C3%A9gh%2C+L+A">L&#xe1;szl&#xf3; A. V&#xe9;gh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Minor restructuring for better readibility of Section 4
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item700">[700]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08537" title="Abstract">arXiv:2310.08537</a> (replaced) [<a href="/pdf/2310.08537" title="Download PDF">pdf</a>, <a href="/format/2310.08537" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> XAI Benchmark for Visual Explanation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+S">Siyi Gu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">James Song</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+B">Bo Pan</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+G">Guangji Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Liang Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item701">[701]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08899" title="Abstract">arXiv:2310.08899</a> (replaced) [<a href="/pdf/2310.08899" title="Download PDF">pdf</a>, <a href="/format/2310.08899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploration with Principles for Diverse AI Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zaharia%2C+M">Matei Zaharia</a>, 
<a href="/search/cs?searchtype=author&query=Abbeel%2C+P">Pieter Abbeel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item702">[702]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09600" title="Abstract">arXiv:2310.09600</a> (replaced) [<a href="/pdf/2310.09600" title="Download PDF">pdf</a>, <a href="/format/2310.09600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hawkeye: A PyTorch-based Library for Fine-Grained Image Recognition with  Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiabei He</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xiu-Shen Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Ye Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM Multimedia 2023 Open Source Software Competition Winner Entry. X.-S. Wei is the corresponding author
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item703">[703]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10970" title="Abstract">arXiv:2310.10970</a> (replaced) [<a href="/pdf/2310.10970" title="Download PDF">pdf</a>, <a href="/format/2310.10970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning based Spatially Dependent Acoustical Properties Recovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruixian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gerstoft%2C+P">Peter Gerstoft</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item704">[704]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11122" title="Abstract">arXiv:2310.11122</a> (replaced) [<a href="/pdf/2310.11122" title="Download PDF">pdf</a>, <a href="/format/2310.11122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sensitivity-Aware Amortized Bayesian Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Elsem%C3%BCller%2C+L">Lasse Elsem&#xfc;ller</a>, 
<a href="/search/stat?searchtype=author&query=Olischl%C3%A4ger%2C+H">Hans Olischl&#xe4;ger</a>, 
<a href="/search/stat?searchtype=author&query=Schmitt%2C+M">Marvin Schmitt</a>, 
<a href="/search/stat?searchtype=author&query=B%C3%BCrkner%2C+P">Paul-Christian B&#xfc;rkner</a>, 
<a href="/search/stat?searchtype=author&query=K%C3%B6the%2C+U">Ullrich K&#xf6;the</a>, 
<a href="/search/stat?searchtype=author&query=Radev%2C+S+T">Stefan T. Radev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item705">[705]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13007" title="Abstract">arXiv:2310.13007</a> (replaced) [<a href="/pdf/2310.13007" title="Download PDF">pdf</a>, <a href="/format/2310.13007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Critical Survey on Fairness Benefits of XAI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deck%2C+L">Luca Deck</a>, 
<a href="/search/cs?searchtype=author&query=Schoeffer%2C+J">Jakob Schoeffer</a>, 
<a href="/search/cs?searchtype=author&query=De-Arteaga%2C+M">Maria De-Arteaga</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%BChl%2C+N">Niklas K&#xfc;hl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item706">[706]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13102" title="Abstract">arXiv:2310.13102</a> (replaced) [<a href="/pdf/2310.13102" title="Download PDF">pdf</a>, <a href="/format/2310.13102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Particle Guidance: non-I.I.D. Diverse Sampling with Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Corso%2C+G">Gabriele Corso</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yilun Xu</a>, 
<a href="/search/cs?searchtype=author&query=de+Bortoli%2C+V">Valentin de Bortoli</a>, 
<a href="/search/cs?searchtype=author&query=Barzilay%2C+R">Regina Barzilay</a>, 
<a href="/search/cs?searchtype=author&query=Jaakkola%2C+T">Tommi Jaakkola</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item707">[707]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14252" title="Abstract">arXiv:2310.14252</a> (replaced) [<a href="/pdf/2310.14252" title="Download PDF">pdf</a>, <a href="/format/2310.14252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proof of Irvine&#x27;s Conjecture via Mechanized Guessing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Shallit%2C+J">Jeffrey Shallit</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item708">[708]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14356" title="Abstract">arXiv:2310.14356</a> (replaced) [<a href="/pdf/2310.14356" title="Download PDF">pdf</a>, <a href="/format/2310.14356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cultural and Linguistic Diversity Improves Visual Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+A">Andre Ye</a>, 
<a href="/search/cs?searchtype=author&query=Santy%2C+S">Sebastin Santy</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J+D">Jena D. Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A+X">Amy X. Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Krishna%2C+R">Ranjay Krishna</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item709">[709]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14790" title="Abstract">arXiv:2310.14790</a> (replaced) [<a href="/pdf/2310.14790" title="Download PDF">pdf</a>, <a href="/format/2310.14790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weighted Joint Maximum Mean Discrepancy Enabled  Multi-Source-Multi-Target Unsupervised Domain Adaptation Fault Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zixuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Haoran Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haibo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+B">Bo Qin</a>, 
<a href="/search/cs?searchtype=author&query=Butala%2C+M+D">Mark D. Butala</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Weiming Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongwei Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item710">[710]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14948" title="Abstract">arXiv:2310.14948</a> (replaced) [<a href="/pdf/2310.14948" title="Download PDF">pdf</a>, <a href="/format/2310.14948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Informed Graph Convolutional Networks: Towards a generalized  framework for complex geometries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chenaud%2C+M">Marien Chenaud</a>, 
<a href="/search/cs?searchtype=author&query=Alves%2C+J">Jos&#xe9; Alves</a>, 
<a href="/search/cs?searchtype=author&query=Magoul%C3%A8s%2C+F">Fr&#xe9;d&#xe9;ric Magoul&#xe8;s</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Civil-Comp Conferences, Volume 5, Paper 4.2, Civil-Comp Press,
  Edinburgh, United Kingdom, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Mathematical Physics (math-ph); Analysis of PDEs (math.AP)

</div>
</div>
</dd>
<dt><a name="item711">[711]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15340" title="Abstract">arXiv:2310.15340</a> (replaced) [<a href="/pdf/2310.15340" title="Download PDF">pdf</a>, <a href="/format/2310.15340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Calculational Design of [In]Correctness Transformational Program Logics  by Abstract Interpretation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cousot%2C+P">Patrick Cousot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 62 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item712">[712]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15386" title="Abstract">arXiv:2310.15386</a> (replaced) [<a href="/pdf/2310.15386" title="Download PDF">pdf</a>, <a href="/format/2310.15386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Course Correcting Koopman Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fathi%2C+M">Mahan Fathi</a>, 
<a href="/search/cs?searchtype=author&query=Gehring%2C+C">Clement Gehring</a>, 
<a href="/search/cs?searchtype=author&query=Pilault%2C+J">Jonathan Pilault</a>, 
<a href="/search/cs?searchtype=author&query=Kanaa%2C+D">David Kanaa</a>, 
<a href="/search/cs?searchtype=author&query=Bacon%2C+P">Pierre-Luc Bacon</a>, 
<a href="/search/cs?searchtype=author&query=Goroshin%2C+R">Ross Goroshin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item713">[713]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15975" title="Abstract">arXiv:2310.15975</a> (replaced) [<a href="/pdf/2310.15975" title="Download PDF">pdf</a>, <a href="/ps/2310.15975" title="Download PostScript">ps</a>, <a href="/format/2310.15975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven Traffic Simulation: A Comprehensive Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Di Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Meixin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuesong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yinhai Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 7 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item714">[714]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17294" title="Abstract">arXiv:2310.17294</a> (replaced) [<a href="/pdf/2310.17294" title="Download PDF">pdf</a>, <a href="/format/2310.17294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scale-Adaptive Feature Aggregation for Efficient Space-Time Video  Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhewei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+A">Ailin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaotao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shuchang Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV2024, 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item715">[715]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17623" title="Abstract">arXiv:2310.17623</a> (replaced) [<a href="/pdf/2310.17623" title="Download PDF">pdf</a>, <a href="/format/2310.17623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proving Test Set Contamination in Black Box Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oren%2C+Y">Yonatan Oren</a>, 
<a href="/search/cs?searchtype=author&query=Meister%2C+N">Nicole Meister</a>, 
<a href="/search/cs?searchtype=author&query=Chatterji%2C+N">Niladri Chatterji</a>, 
<a href="/search/cs?searchtype=author&query=Ladhak%2C+F">Faisal Ladhak</a>, 
<a href="/search/cs?searchtype=author&query=Hashimoto%2C+T+B">Tatsunori B. Hashimoto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item716">[716]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18075" title="Abstract">arXiv:2310.18075</a> (replaced) [<a href="/pdf/2310.18075" title="Download PDF">pdf</a>, <a href="/format/2310.18075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DUMA: a Dual-Mind Conversational Agent with Fast and Slow Thinking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+X">Xiaoyu Tian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liangyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Na Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yaxuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+W">Wei Zou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kaijiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+M">Ming Cui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item717">[717]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18301" title="Abstract">arXiv:2310.18301</a> (replaced) [<a href="/pdf/2310.18301" title="Download PDF">pdf</a>, <a href="/format/2310.18301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive Joint Planning for Autonomous Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuxiao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Veer%2C+S">Sushant Veer</a>, 
<a href="/search/cs?searchtype=author&query=Karkus%2C+P">Peter Karkus</a>, 
<a href="/search/cs?searchtype=author&query=Pavone%2C+M">Marco Pavone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item718">[718]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18333" title="Abstract">arXiv:2310.18333</a> (replaced) [<a href="/pdf/2310.18333" title="Download PDF">pdf</a>, <a href="/format/2310.18333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> She had Cobalt Blue Eyes: Prompt Testing to Create Aligned and  Sustainable Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chatrath%2C+V">Veronica Chatrath</a>, 
<a href="/search/cs?searchtype=author&query=Bamgbose%2C+O">Oluwanifemi Bamgbose</a>, 
<a href="/search/cs?searchtype=author&query=Raza%2C+S">Shaina Raza</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item719">[719]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18802" title="Abstract">arXiv:2310.18802</a> (replaced) [<a href="/pdf/2310.18802" title="Download PDF">pdf</a>, <a href="/ps/2310.18802" title="Download PostScript">ps</a>, <a href="/format/2310.18802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finite element approximation of the Einstein tensor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gawlik%2C+E+S">Evan S. Gawlik</a>, 
<a href="/search/math?searchtype=author&query=Neunteufel%2C+M">Michael Neunteufel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2301.02159">arXiv:2301.02159</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Differential Geometry (math.DG)

</div>
</div>
</dd>
<dt><a name="item720">[720]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19106" title="Abstract">arXiv:2310.19106</a> (replaced) [<a href="/pdf/2310.19106" title="Download PDF">pdf</a>, <a href="/format/2310.19106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PACuna: Automated Fine-Tuning of Language Models for Particle  Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sulc%2C+A">Antonin Sulc</a>, 
<a href="/search/cs?searchtype=author&query=Kammering%2C+R">Raimund Kammering</a>, 
<a href="/search/cs?searchtype=author&query=Eichler%2C+A">Annika Eichler</a>, 
<a href="/search/cs?searchtype=author&query=Wilksen%2C+T">Tim Wilksen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item721">[721]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19204" title="Abstract">arXiv:2310.19204</a> (replaced) [<a href="/pdf/2310.19204" title="Download PDF">pdf</a>, <a href="/format/2310.19204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can ChatGPT advance software testing intelligence? An experience report  on metamorphic testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luu%2C+Q">Quang-Hung Luu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T+Y">Tsong Yueh Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages (short communications), 2 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item722">[722]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19653" title="Abstract">arXiv:2310.19653</a> (replaced) [<a href="/pdf/2310.19653" title="Download PDF">pdf</a>, <a href="/format/2310.19653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Upgrading VAE Training With Unlimited Data Plans Provided by Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Xiao%2C+T+Z">Tim Z. Xiao</a>, 
<a href="/search/stat?searchtype=author&query=Zenn%2C+J">Johannes Zenn</a>, 
<a href="/search/stat?searchtype=author&query=Bamler%2C+R">Robert Bamler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages + appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item723">[723]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20290" title="Abstract">arXiv:2310.20290</a> (replaced) [<a href="/pdf/2310.20290" title="Download PDF">pdf</a>, <a href="/format/2310.20290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Rayleigh Quotient Iteration for Dual Quaternion Hermitian Eigenvalue  Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Duan%2C+S">Shan-Qi Duan</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+Q">Qing-Wen Wang</a>, 
<a href="/search/math?searchtype=author&query=Duan%2C+X">Xue-Feng Duan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2111.12211">arXiv:2111.12211</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item724">[724]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20457" title="Abstract">arXiv:2310.20457</a> (replaced) [<a href="/pdf/2310.20457" title="Download PDF">pdf</a>, <a href="/format/2310.20457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlexTrain: A Dynamic Training Framework for Heterogeneous Devices  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Unsal%2C+M">Mert Unsal</a>, 
<a href="/search/cs?searchtype=author&query=Maatouk%2C+A">Ali Maatouk</a>, 
<a href="/search/cs?searchtype=author&query=De+Domenico%2C+A">Antonio De Domenico</a>, 
<a href="/search/cs?searchtype=author&query=Piovesan%2C+N">Nicola Piovesan</a>, 
<a href="/search/cs?searchtype=author&query=Ayed%2C+F">Fadhel Ayed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Workshop on Advancing Neural Network Training (WANT) at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item725">[725]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00860" title="Abstract">arXiv:2311.00860</a> (replaced) [<a href="/pdf/2311.00860" title="Download PDF">pdf</a>, <a href="/format/2311.00860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero Coordinate Shift: Whetted Automatic Differentiation for  Physics-informed Operator Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leng%2C+K">Kuangdai Leng</a>, 
<a href="/search/cs?searchtype=author&query=Shankar%2C+M">Mallikarjun Shankar</a>, 
<a href="/search/cs?searchtype=author&query=Thiyagalingam%2C+J">Jeyan Thiyagalingam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages; this minor revision gives clearer explanation on the reason of performance boost by ZCS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Numerical Analysis (math.NA); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item726">[726]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00996" title="Abstract">arXiv:2311.00996</a> (replaced) [<a href="/pdf/2311.00996" title="Download PDF">pdf</a>, <a href="/format/2311.00996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VCISR: Blind Single Image Super-Resolution with Video Compression  Synthetic Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+B">Boyang Wang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+B">Bowen Liu</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+S">Shiyu Liu</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+F">Fengyu Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item727">[727]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01017" title="Abstract">arXiv:2311.01017</a> (replaced) [<a href="/pdf/2311.01017" title="Download PDF">pdf</a>, <a href="/format/2311.01017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Unsupervised World Models for Autonomous Driving via Discrete  Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lunjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yuwen Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Ze Yang</a>, 
<a href="/search/cs?searchtype=author&query=Casas%2C+S">Sergio Casas</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+R">Rui Hu</a>, 
<a href="/search/cs?searchtype=author&query=Urtasun%2C+R">Raquel Urtasun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item728">[728]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01901" title="Abstract">arXiv:2311.01901</a> (replaced) [<a href="/pdf/2311.01901" title="Download PDF">pdf</a>, <a href="/format/2311.01901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agent-based Modelling of Credit Card Promotions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamill%2C+C+B">Conor B. Hamill</a>, 
<a href="/search/cs?searchtype=author&query=Khraishi%2C+R">Raad Khraishi</a>, 
<a href="/search/cs?searchtype=author&query=Gherghel%2C+S">Simona Gherghel</a>, 
<a href="/search/cs?searchtype=author&query=Lawrence%2C+J">Jerrard Lawrence</a>, 
<a href="/search/cs?searchtype=author&query=Mercuri%2C+S">Salvatore Mercuri</a>, 
<a href="/search/cs?searchtype=author&query=Okhrati%2C+R">Ramin Okhrati</a>, 
<a href="/search/cs?searchtype=author&query=Cowan%2C+G+A">Greig A. Cowan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; General Economics (econ.GN)

</div>
</div>
</dd>
<dt><a name="item729">[729]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02082" title="Abstract">arXiv:2311.02082</a> (replaced) [<a href="/pdf/2311.02082" title="Download PDF">pdf</a>, <a href="/ps/2311.02082" title="Download PostScript">ps</a>, <a href="/format/2311.02082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Modelling of Organizational Knowledge as a Basis for Enterprise  Data Governance 4.0 -- Application to a Unified Clinical Data Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oliveira%2C+M+A">Miguel AP Oliveira</a>, 
<a href="/search/cs?searchtype=author&query=Manara%2C+S">Stephane Manara</a>, 
<a href="/search/cs?searchtype=author&query=Mol%C3%A9%2C+B">Bruno Mol&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Muller%2C+T">Thomas Muller</a>, 
<a href="/search/cs?searchtype=author&query=Guillouche%2C+A">Aur&#xe9;lien Guillouche</a>, 
<a href="/search/cs?searchtype=author&query=Hesske%2C+L">Lysann Hesske</a>, 
<a href="/search/cs?searchtype=author&query=Jordan%2C+B">Bruce Jordan</a>, 
<a href="/search/cs?searchtype=author&query=Hubert%2C+G">Gilles Hubert</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+C">Chinmay Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Jagdev%2C+P">Pralipta Jagdev</a>, 
<a href="/search/cs?searchtype=author&query=Berger%2C+C+R">Cedric R. Berger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item730">[730]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02198" title="Abstract">arXiv:2311.02198</a> (replaced) [<a href="/pdf/2311.02198" title="Download PDF">pdf</a>, <a href="/format/2311.02198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imitation Bootstrapped Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hengyuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Mirchandani%2C+S">Suvir Mirchandani</a>, 
<a href="/search/cs?searchtype=author&query=Sadigh%2C+D">Dorsa Sadigh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item731">[731]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02651" title="Abstract">arXiv:2311.02651</a> (replaced) [<a href="/pdf/2311.02651" title="Download PDF">pdf</a>, <a href="/ps/2311.02651" title="Download PostScript">ps</a>, <a href="/format/2311.02651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compute at Scale: A Broad Investigation into the Data Center Industry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pilz%2C+K">Konstantin Pilz</a>, 
<a href="/search/cs?searchtype=author&query=Heim%2C+L">Lennart Heim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item732">[732]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02679" title="Abstract">arXiv:2311.02679</a> (replaced) [<a href="/pdf/2311.02679" title="Download PDF">pdf</a>, <a href="/format/2311.02679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regret Analysis of Learning-Based Linear Quadratic Gaussian Control with  Additive Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Athrey%2C+A">Archith Athrey</a>, 
<a href="/search/eess?searchtype=author&query=Mazhar%2C+O">Othmane Mazhar</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+M">Meichen Guo</a>, 
<a href="/search/eess?searchtype=author&query=De+Schutter%2C+B">Bart De Schutter</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+S">Shengling Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item733">[733]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02818" title="Abstract">arXiv:2311.02818</a> (replaced) [<a href="/pdf/2311.02818" title="Download PDF">pdf</a>, <a href="/format/2311.02818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Signal Processing Meets SGD: From Momentum to Filter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+Z">Zhipeng Yao</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+G">Guisong Chang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dazhou Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2010.07468">arXiv:2010.07468</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item734">[734]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03348" title="Abstract">arXiv:2311.03348</a> (replaced) [<a href="/pdf/2311.03348" title="Download PDF">pdf</a>, <a href="/format/2311.03348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable and Transferable Black-Box Jailbreaks for Language Models via  Persona Modulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shah%2C+R">Rusheb Shah</a>, 
<a href="/search/cs?searchtype=author&query=Feuillade--Montixi%2C+Q">Quentin Feuillade--Montixi</a>, 
<a href="/search/cs?searchtype=author&query=Pour%2C+S">Soroush Pour</a>, 
<a href="/search/cs?searchtype=author&query=Tagade%2C+A">Arush Tagade</a>, 
<a href="/search/cs?searchtype=author&query=Casper%2C+S">Stephen Casper</a>, 
<a href="/search/cs?searchtype=author&query=Rando%2C+J">Javier Rando</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item735">[735]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03469" title="Abstract">arXiv:2311.03469</a> (replaced) [<a href="/pdf/2311.03469" title="Download PDF">pdf</a>, <a href="/format/2311.03469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combinatorial Hodge Theory in Simplicial Signal Processing -- DAFx2023  Lecture Notes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Essl%2C+G">Georg Essl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 40 figures. arXiv admin note: substantial text overlap with <a href="/abs/2211.05821">arXiv:2211.05821</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item736">[736]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03561" title="Abstract">arXiv:2311.03561</a> (replaced) [<a href="/pdf/2311.03561" title="Download PDF">pdf</a>, <a href="/format/2311.03561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sea You Later: Metadata-Guided Long-Term Re-Identification for UAV-Based  Multi-Object Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Cheng-Yen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hsiang-Wei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhongyu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Kuo%2C+H">Heng-Cheng Kuo</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+J">Jie Mei</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chung-I Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J">Jenq-Neng Hwang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 1st place method (WACV Workshop Paper) of the UAV-based Multi-Object Tracking with Reidentification Challenge in MaCVi WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item737">[737]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03739" title="Abstract">arXiv:2311.03739</a> (replaced) [<a href="/pdf/2311.03739" title="Download PDF">pdf</a>, <a href="/format/2311.03739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Large Language Models for Automated Proof Synthesis in Rust
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jianan Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Ziqiao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weiteng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+W">Weidong Cui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item738">[738]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03996" title="Abstract">arXiv:2311.03996</a> (replaced) [<a href="/pdf/2311.03996" title="Download PDF">pdf</a>, <a href="/format/2311.03996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Initialization Schema for Neuronal Networks on Tabular Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fuhl%2C+W">Wolfgang Fuhl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item739">[739]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04517" title="Abstract">arXiv:2311.04517</a> (replaced) [<a href="/pdf/2311.04517" title="Download PDF">pdf</a>, <a href="/format/2311.04517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strategies for Parallelizing the Big-Means Algorithm: A Comprehensive  Tutorial for Effective Big Data Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mussabayev%2C+R">Ravil Mussabayev</a>, 
<a href="/search/cs?searchtype=author&query=Mussabayev%2C+R">Rustam Mussabayev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2310.09819">arXiv:2310.09819</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item740">[740]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04599" title="Abstract">arXiv:2311.04599</a> (replaced) [<a href="/pdf/2311.04599" title="Download PDF">pdf</a>, <a href="/format/2311.04599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable artificial intelligence model for identifying Market Value  in Professional Soccer Players
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chunyang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shaoliang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13pages, 6figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Computational Finance (q-fin.CP)

</div>
</div>
</dd>
<dt><a name="item741">[741]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04723" title="Abstract">arXiv:2311.04723</a> (replaced) [<a href="/pdf/2311.04723" title="Download PDF">pdf</a>, <a href="/format/2311.04723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication Complexity of Common Randomness Generation with Isotropic  States
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Dong%2C+Y">Yangjing Dong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yao%2C+P">Penghui Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 2 figures. Update funding information
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item742">[742]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04760" title="Abstract">arXiv:2311.04760</a> (replaced) [<a href="/pdf/2311.04760" title="Download PDF">pdf</a>, <a href="/format/2311.04760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Open-world Cross-Domain Sequential Recommendation: A  Model-Agnostic Contrastive Denoising Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wujiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+X">Xuying Ning</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Wenfang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ha%2C+M">Mingming Ha</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Q">Qiongxu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Q">Qianqiao Liang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+X">Xuewen Tao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Linxun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bing Han</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+M">Minnan Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item743">[743]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05286" title="Abstract">arXiv:2311.05286</a> (replaced) [<a href="/pdf/2311.05286" title="Download PDF">pdf</a>, <a href="/format/2311.05286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Inference from Text: Unveiling Interactions between Variables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuxiang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yulan He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 Findings (mark typo corrected)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item744">[744]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05309" title="Abstract">arXiv:2311.05309</a> (replaced) [<a href="/pdf/2311.05309" title="Download PDF">pdf</a>, <a href="/format/2311.05309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Liquid phase fast electron tomography unravels the true 3D structure of  colloidal assemblies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Esteban%2C+D+A">Daniel Arenas Esteban</a>, 
<a href="/search/cond-mat?searchtype=author&query=Wang%2C+D">Da Wang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Kadu%2C+A">Ajinkya Kadu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Olluyn%2C+N">Noa Olluyn</a>, 
<a href="/search/cond-mat?searchtype=author&query=Iglesias%2C+A+S">Ana S&#xe1;nchez Iglesias</a>, 
<a href="/search/cond-mat?searchtype=author&query=Perez%2C+A+G">Alejandro Gomez Perez</a>, 
<a href="/search/cond-mat?searchtype=author&query=Casablanca%2C+J+G">Jesus Gonzalez Casablanca</a>, 
<a href="/search/cond-mat?searchtype=author&query=Nicolopoulos%2C+S">Stavros Nicolopoulos</a>, 
<a href="/search/cond-mat?searchtype=author&query=Liz-Marz%C3%A1n%2C+L+M">Luis M. Liz-Marz&#xe1;n</a>, 
<a href="/search/cond-mat?searchtype=author&query=Bals%2C+S">Sara Bals</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 12 figures, 2 tables, submitted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Soft Condensed Matter (cond-mat.soft)</span>; Materials Science (cond-mat.mtrl-sci); Computational Engineering, Finance, and Science (cs.CE); Chemical Physics (physics.chem-ph)

</div>
</div>
</dd>
<dt><a name="item745">[745]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05784" title="Abstract">arXiv:2311.05784</a> (replaced) [<a href="/pdf/2311.05784" title="Download PDF">pdf</a>, <a href="/format/2311.05784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are &quot;Hierarchical&quot; Visual Representations Hierarchical?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+E">Ethan Shen</a>, 
<a href="/search/cs?searchtype=author&query=Farhadi%2C+A">Ali Farhadi</a>, 
<a href="/search/cs?searchtype=author&query=Kusupati%2C+A">Aditya Kusupati</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item746">[746]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05788" title="Abstract">arXiv:2311.05788</a> (replaced) [<a href="/pdf/2311.05788" title="Download PDF">pdf</a>, <a href="/format/2311.05788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structured Transforms Across Spaces with Cost-Regularized Optimal  Transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sebbouh%2C+O">Othmane Sebbouh</a>, 
<a href="/search/cs?searchtype=author&query=Cuturi%2C+M">Marco Cuturi</a>, 
<a href="/search/cs?searchtype=author&query=Peyr%C3%A9%2C+G">Gabriel Peyr&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item747">[747]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06025" title="Abstract">arXiv:2311.06025</a> (replaced) [<a href="/pdf/2311.06025" title="Download PDF">pdf</a>, <a href="/format/2311.06025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChiMed-GPT: A Chinese Medical Large Language Model with Full Training  Regime and Better Alignment to Human Preferences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuanhe Tian</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+R">Ruyi Gan</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yan Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaxing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongdong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item748">[748]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06031" title="Abstract">arXiv:2311.06031</a> (replaced) [<a href="/pdf/2311.06031" title="Download PDF">pdf</a>, <a href="/format/2311.06031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diagonal Hierarchical Consistency Learning for Semi-supervised Medical  Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koo%2C+H">Heejoon Koo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures, and 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item749">[749]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06214" title="Abstract">arXiv:2311.06214</a> (replaced) [<a href="/pdf/2311.06214" title="Download PDF">pdf</a>, <a href="/format/2311.06214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instant3D: Fast Text-to-3D with Sparse-View Generation and Large  Reconstruction Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiahao Li</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+H">Hao Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zexiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Luan%2C+F">Fujun Luan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yinghao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+Y">Yicong Hong</a>, 
<a href="/search/cs?searchtype=author&query=Sunkavalli%2C+K">Kalyan Sunkavalli</a>, 
<a href="/search/cs?searchtype=author&query=Shakhnarovich%2C+G">Greg Shakhnarovich</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+S">Sai Bi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project webpage: <a href="https://jiahao.ai/instant3d/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item750">[750]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06258" title="Abstract">arXiv:2311.06258</a> (replaced) [<a href="/pdf/2311.06258" title="Download PDF">pdf</a>, <a href="/format/2311.06258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Post-COVID Highlights: Challenges and Solutions of AI Techniques for  Swift Identification of COVID-19
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yingying Fang</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+X">Xiaodan Xing</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Walsh%2C+S">Simon Walsh</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guang Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item751">[751]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06330" title="Abstract">arXiv:2311.06330</a> (replaced) [<a href="/pdf/2311.06330" title="Download PDF">pdf</a>, <a href="/format/2311.06330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Smart Agent-Based Modeling: On the Use of Large Language Models in  Computer Simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zengqing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+R">Run Peng</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xu Han</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shuyuan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yixin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chuan Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Source codes are available at <a href="https://github.com/Roihn/SABM">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computational Engineering, Finance, and Science (cs.CE); Multiagent Systems (cs.MA); General Economics (econ.GN)

</div>
</div>
</dd>
<dt><a name="item752">[752]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06607" title="Abstract">arXiv:2311.06607</a> (replaced) [<a href="/pdf/2311.06607" title="Download PDF">pdf</a>, <a href="/format/2311.06607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monkey: Image Resolution and Text Label Are Important Things for Large  Multi-modal Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Biao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhiyin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jingxu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yabo Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiang Bai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item753">[753]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06622" title="Abstract">arXiv:2311.06622</a> (replaced) [<a href="/pdf/2311.06622" title="Download PDF">pdf</a>, <a href="/format/2311.06622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TrainerAgent: Customizable and Efficient Model Training through  LLM-Powered Multi-Agent System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Hao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianke Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhelun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+A">Aoxiong Yin</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+S">Siming Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+W">Wanggui He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item754">[754]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06928" title="Abstract">arXiv:2311.06928</a> (replaced) [<a href="/pdf/2311.06928" title="Download PDF">pdf</a>, <a href="/format/2311.06928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention for Causal Relationship Discovery from Biological Neural  Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Ziyu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Tabassum%2C+A">Anika Tabassum</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+S">Shruti Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+L">Lu Mi</a>, 
<a href="/search/cs?searchtype=author&query=Kutz%2C+J+N">J. Nathan Kutz</a>, 
<a href="/search/cs?searchtype=author&query=Shea-Brown%2C+E">Eric Shea-Brown</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+S">Seung-Hwan Lim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the NeurIPS 2023 Workshop on Causal Representation Learning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item755">[755]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06996" title="Abstract">arXiv:2311.06996</a> (replaced) [<a href="/pdf/2311.06996" title="Download PDF">pdf</a>, <a href="/format/2311.06996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AGRAMPLIFIER: Defending Federated Learning Against Poisoning Attacks  Through Local Update Amplification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+Z">Zirui Gong</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Liyue Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L+Y">Leo Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+G">Guangdong Bai</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+Y">Yong Xiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE TIFS, this is the complete version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item756">[756]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07075" title="Abstract">arXiv:2311.07075</a> (replaced) [<a href="/pdf/2311.07075" title="Download PDF">pdf</a>, <a href="/format/2311.07075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GazeForensics: DeepFake Detection via Gaze-guided Spatial Inconsistency  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Q">Qinlin He</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Chunlei Peng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Decheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Nannan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xinbo Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item757">[757]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07553" title="Abstract">arXiv:2311.07553</a> (replaced) [<a href="/pdf/2311.07553" title="Download PDF">pdf</a>, <a href="/format/2311.07553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Extensive Study on Adversarial Attack against Pre-trained Models of  Code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xiaohu Du</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+M">Ming Wen</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zichao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shangwen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Hai Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ESEC/FSE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item758">[758]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07585" title="Abstract">arXiv:2311.07585</a> (replaced) [<a href="/pdf/2311.07585" title="Download PDF">pdf</a>, <a href="/format/2311.07585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Input Reconstruction Attack against Vertical Federated Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+F">Fei Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item759">[759]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08228" title="Abstract">arXiv:2311.08228</a> (replaced) [<a href="/pdf/2311.08228" title="Download PDF">pdf</a>, <a href="/format/2311.08228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Counterfactual Explanation for Regression via Disentanglement in Latent  Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Broelemann%2C+K">Klaus Broelemann</a>, 
<a href="/search/cs?searchtype=author&query=Kasneci%2C+G">Gjergji Kasneci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CXAI workshop @ ICDM 2023. arXiv admin note: text overlap with <a href="/abs/2307.13390">arXiv:2307.13390</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item760">[760]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08745" title="Abstract">arXiv:2311.08745</a> (replaced) [<a href="/pdf/2311.08745" title="Download PDF">pdf</a>, <a href="/format/2311.08745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Stochastic Gradient Descent to Smooth Nonconvex Functions:  Analysis of Implicit Graduated Optimization with Optimal Noise Scheduling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sato%2C+N">Naoki Sato</a>, 
<a href="/search/cs?searchtype=author&query=Iiduka%2C+H">Hideaki Iiduka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The latest version was updated on Nov. 24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item761">[761]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08826" title="Abstract">arXiv:2311.08826</a> (replaced) [<a href="/pdf/2311.08826" title="Download PDF">pdf</a>, <a href="/format/2311.08826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-stage Euler-Maruyama methods for backward stochastic differential  equations driven by continuous-time Markov chains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kaneko%2C+A">Akihiro Kaneko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Numerical Analysis (math.NA); Mathematical Finance (q-fin.MF)

</div>
</div>
</dd>
<dt><a name="item762">[762]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09178" title="Abstract">arXiv:2311.09178</a> (replaced) [<a href="/pdf/2311.09178" title="Download PDF">pdf</a>, <a href="/format/2311.09178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RBPGAN: Recurrent Back-Projection GAN for Video Super Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sulaiman%2C+M">Marwah Sulaiman</a>, 
<a href="/search/cs?searchtype=author&query=Shehabeldin%2C+Z">Zahraa Shehabeldin</a>, 
<a href="/search/cs?searchtype=author&query=Fahmy%2C+I">Israa Fahmy</a>, 
<a href="/search/cs?searchtype=author&query=Barakat%2C+M">Mohammed Barakat</a>, 
<a href="/search/cs?searchtype=author&query=El-Naggar%2C+M">Mohammed El-Naggar</a>, 
<a href="/search/cs?searchtype=author&query=Hussein%2C+D">Dareen Hussein</a>, 
<a href="/search/cs?searchtype=author&query=Youssef%2C+M">Moustafa Youssef</a>, 
<a href="/search/cs?searchtype=author&query=Eraqi%2C+H">Hesham Eraqi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item763">[763]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09211" title="Abstract">arXiv:2311.09211</a> (replaced) [<a href="/pdf/2311.09211" title="Download PDF">pdf</a>, <a href="/ps/2311.09211" title="Download PostScript">ps</a>, <a href="/format/2311.09211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digitally reproducing the artistic style of XVI century artist Antonio  Campelo in Alegoria Prudencia
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oliveira%2C+J+F">Joao Fradinho Oliveira</a>, 
<a href="/search/cs?searchtype=author&query=Pereira%2C+J+M">Joao Madeiras Pereira</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Wrong references corrected
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
</div>
</dd>
<dt><a name="item764">[764]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09433" title="Abstract">arXiv:2311.09433</a> (replaced) [<a href="/pdf/2311.09433" title="Download PDF">pdf</a>, <a href="/format/2311.09433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Backdoor Activation Attack: Attack Large Language Models using  Activation Steering for Safety-Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+K">Kai Shu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item765">[765]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09740" title="Abstract">arXiv:2311.09740</a> (replaced) [<a href="/pdf/2311.09740" title="Download PDF">pdf</a>, <a href="/format/2311.09740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Redefining Super-Resolution: Fine-mesh PDE predictions without classical  simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Sarkar%2C+R+K">Rajat Kumar Sarkar</a>, 
<a href="/search/physics?searchtype=author&query=Majumdar%2C+R">Ritam Majumdar</a>, 
<a href="/search/physics?searchtype=author&query=Jadhav%2C+V">Vishal Jadhav</a>, 
<a href="/search/physics?searchtype=author&query=Sakhinana%2C+S+S">Sagar Srinivas Sakhinana</a>, 
<a href="/search/physics?searchtype=author&query=Runkana%2C+V">Venkataramana Runkana</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Machine Learning and the Physical Sciences Workshop, NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item766">[766]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10049" title="Abstract">arXiv:2311.10049</a> (replaced) [<a href="/pdf/2311.10049" title="Download PDF">pdf</a>, <a href="/format/2311.10049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inherently Interpretable Time Series Classification via Multiple  Instance Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Early%2C+J">Joseph Early</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+G+K">Gavin KC Cheung</a>, 
<a href="/search/cs?searchtype=author&query=Cutajar%2C+K">Kurt Cutajar</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Hanting Xie</a>, 
<a href="/search/cs?searchtype=author&query=Kandola%2C+J">Jas Kandola</a>, 
<a href="/search/cs?searchtype=author&query=Twomey%2C+N">Niall Twomey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. Under submission at ICLR 2024. 29 pages (9 main, 3 ref, 17 appendix)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item767">[767]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10057" title="Abstract">arXiv:2311.10057</a> (replaced) [<a href="/pdf/2311.10057" title="Download PDF">pdf</a>, <a href="/format/2311.10057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Song Describer Dataset: a Corpus of Audio Captions for  Music-and-Language Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manco%2C+I">Ilaria Manco</a>, 
<a href="/search/cs?searchtype=author&query=Weck%2C+B">Benno Weck</a>, 
<a href="/search/cs?searchtype=author&query=Doh%2C+S">SeungHeon Doh</a>, 
<a href="/search/cs?searchtype=author&query=Won%2C+M">Minz Won</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yixiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bogdanov%2C+D">Dmitry Bogdanov</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yusong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Ke Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tovstogan%2C+P">Philip Tovstogan</a>, 
<a href="/search/cs?searchtype=author&query=Benetos%2C+E">Emmanouil Benetos</a>, 
<a href="/search/cs?searchtype=author&query=Quinton%2C+E">Elio Quinton</a>, 
<a href="/search/cs?searchtype=author&query=Fazekas%2C+G">Gy&#xf6;rgy Fazekas</a>, 
<a href="/search/cs?searchtype=author&query=Nam%2C+J">Juhan Nam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023 Workshop on Machine Learning for Audio
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item768">[768]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10359" title="Abstract">arXiv:2311.10359</a> (replaced) [<a href="/pdf/2311.10359" title="Download PDF">pdf</a>, <a href="/format/2311.10359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FIKIT: Priority-Based Real-time GPU Multi-tasking Scheduling with Kernel  Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenqing Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 18 figures. Shorten the introduction section; Move some content from the introduction to the design section; Add Dataset References
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item769">[769]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10538" title="Abstract">arXiv:2311.10538</a> (replaced) [<a href="/pdf/2311.10538" title="Download PDF">pdf</a>, <a href="/format/2311.10538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Testing Language Model Agents Safely in the Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naihin%2C+S">Silen Naihin</a>, 
<a href="/search/cs?searchtype=author&query=Atkinson%2C+D">David Atkinson</a>, 
<a href="/search/cs?searchtype=author&query=Green%2C+M">Marc Green</a>, 
<a href="/search/cs?searchtype=author&query=Hamadi%2C+M">Merwane Hamadi</a>, 
<a href="/search/cs?searchtype=author&query=Swift%2C+C">Craig Swift</a>, 
<a href="/search/cs?searchtype=author&query=Schonholtz%2C+D">Douglas Schonholtz</a>, 
<a href="/search/cs?searchtype=author&query=Kalai%2C+A+T">Adam Tauman Kalai</a>, 
<a href="/search/cs?searchtype=author&query=Bau%2C+D">David Bau</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item770">[770]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10543" title="Abstract">arXiv:2311.10543</a> (replaced) [<a href="/pdf/2311.10543" title="Download PDF">pdf</a>, <a href="/ps/2311.10543" title="Download PostScript">ps</a>, <a href="/format/2311.10543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint covariance property under geometric image transformations for  spatio-temporal receptive fields according to the generalized Gaussian  derivative model for visual receptive fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lindeberg%2C+T">Tony Lindeberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item771">[771]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10642" title="Abstract">arXiv:2311.10642</a> (replaced) [<a href="/pdf/2311.10642" title="Download PDF">pdf</a>, <a href="/format/2311.10642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Attention: Exploring Shallow Feed-Forward Neural Networks as  an Alternative to Attention Layers in Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bozic%2C+V">Vukasin Bozic</a>, 
<a href="/search/cs?searchtype=author&query=Dordevic%2C+D">Danilo Dordevic</a>, 
<a href="/search/cs?searchtype=author&query=Coppola%2C+D">Daniele Coppola</a>, 
<a href="/search/cs?searchtype=author&query=Thommes%2C+J">Joseph Thommes</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S+P">Sidak Pal Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI24(<a href="https://aaai.org/aaai-conference/">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item772">[772]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10751" title="Abstract">arXiv:2311.10751</a> (replaced) [<a href="/pdf/2311.10751" title="Download PDF">pdf</a>, <a href="/format/2311.10751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProAgent: From Robotic Process Automation to Agentic Process Automation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yining Ye</a>, 
<a href="/search/cs?searchtype=author&query=Cong%2C+X">Xin Cong</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+S">Shizuo Tian</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jiannan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yujia Qin</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yaxi Lu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Heyang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huadong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yankai Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Maosong Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item773">[773]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10754" title="Abstract">arXiv:2311.10754</a> (replaced) [<a href="/pdf/2311.10754" title="Download PDF">pdf</a>, <a href="/ps/2311.10754" title="Download PostScript">ps</a>, <a href="/format/2311.10754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Recent Survey of the Advancements in Deep Learning Techniques for  Monkeypox Disease Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Khan%2C+S+H">Saddam Hussain Khan</a>, 
<a href="/search/eess?searchtype=author&query=Iqbal%2C+R">Rashid Iqbal</a>, 
<a href="/search/eess?searchtype=author&query=Naz%2C+S">Saeeda Naz</a> (Artifical Intelligence Lab, Department of Computer Systems Engineering, University of Engineering and Applied Science (UEAS), Swat, Pakistan)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 53 pages, 16 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item774">[774]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10986" title="Abstract">arXiv:2311.10986</a> (replaced) [<a href="/pdf/2311.10986" title="Download PDF">pdf</a>, <a href="/format/2311.10986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EdgeFM: Leveraging Foundation Model for Open-set Learning on the Edge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bufang Yang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Lixing He</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+N">Neiwen Ling</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zhenyu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+G">Guoliang Xing</a>, 
<a href="/search/cs?searchtype=author&query=Shuai%2C+X">Xian Shuai</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiaozhe Ren</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xin Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 21th ACM Conference on Embedded Networked Sensor Systems (SenSys 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item775">[775]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10996" title="Abstract">arXiv:2311.10996</a> (replaced) [<a href="/pdf/2311.10996" title="Download PDF">pdf</a>, <a href="/format/2311.10996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BrainZ-BP: A Non-invasive Cuff-less Blood Pressure Estimation Approach  Leveraging Brain Bio-impedance and Electrocardiogram
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bufang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Le Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenxuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Mengliang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongxing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+X">Xinbao Ning</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item776">[776]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11462" title="Abstract">arXiv:2311.11462</a> (replaced) [<a href="/pdf/2311.11462" title="Download PDF">pdf</a>, <a href="/format/2311.11462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM aided semi-supervision for Extractive Dialog Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mishra%2C+N">Nishant Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Sahu%2C+G">Gaurav Sahu</a>, 
<a href="/search/cs?searchtype=author&query=Calixto%2C+I">Iacer Calixto</a>, 
<a href="/search/cs?searchtype=author&query=Abu-Hanna%2C+A">Ameen Abu-Hanna</a>, 
<a href="/search/cs?searchtype=author&query=Laradji%2C+I+H">Issam H. Laradji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to be published in EMNLP Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item777">[777]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11762" title="Abstract">arXiv:2311.11762</a> (replaced) [<a href="/pdf/2311.11762" title="Download PDF">pdf</a>, <a href="/format/2311.11762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MUVO: A Multimodal Generative World Model for Autonomous Driving with  Geometric Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bogdoll%2C+D">Daniel Bogdoll</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yitian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Z%C3%B6llner%2C+J+M">J. Marius Z&#xf6;llner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Daniel Bogdoll and Yitian Yang contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item778">[778]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11851" title="Abstract">arXiv:2311.11851</a> (replaced) [<a href="/pdf/2311.11851" title="Download PDF">pdf</a>, <a href="/format/2311.11851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Crash-Stop Failures in Asynchronous Multiparty Session Types
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barwell%2C+A+D">Adam D. Barwell</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+P">Ping Hou</a>, 
<a href="/search/cs?searchtype=author&query=Yoshida%2C+N">Nobuko Yoshida</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+F">Fangyi Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2305.06238">arXiv:2305.06238</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item779">[779]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11995" title="Abstract">arXiv:2311.11995</a> (replaced) [<a href="/pdf/2311.11995" title="Download PDF">pdf</a>, <a href="/format/2311.11995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BrainWash: A Poisoning Attack to Forget in Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abbasi%2C+A">Ali Abbasi</a>, 
<a href="/search/cs?searchtype=author&query=Nooralinejad%2C+P">Parsa Nooralinejad</a>, 
<a href="/search/cs?searchtype=author&query=Pirsiavash%2C+H">Hamed Pirsiavash</a>, 
<a href="/search/cs?searchtype=author&query=Kolouri%2C+S">Soheil Kolouri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item780">[780]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12024" title="Abstract">arXiv:2311.12024</a> (replaced) [<a href="/pdf/2311.12024" title="Download PDF">pdf</a>, <a href="/format/2311.12024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PF-LRM: Pose-Free Large Reconstruction Model for Joint Pose and Shape  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+H">Hao Tan</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+S">Sai Bi</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yinghao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Luan%2C+F">Fujun Luan</a>, 
<a href="/search/cs?searchtype=author&query=Sunkavalli%2C+K">Kalyan Sunkavalli</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zexiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website: <a href="https://totoro97.github.io/pf-lrm">this https URL</a> ; add more experiments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item781">[781]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12144" title="Abstract">arXiv:2311.12144</a> (replaced) [<a href="/pdf/2311.12144" title="Download PDF">pdf</a>, <a href="/ps/2311.12144" title="Download PostScript">ps</a>, <a href="/format/2311.12144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applications of Large Scale Foundation Models for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yue Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhu Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages. arXiv admin note: text overlap with <a href="/abs/2304.03589">arXiv:2304.03589</a>, <a href="/abs/2111.05849">arXiv:2111.05849</a>, <a href="/abs/2306.03000">arXiv:2306.03000</a>, <a href="/abs/2309.17080">arXiv:2309.17080</a>, <a href="/abs/2301.02691">arXiv:2301.02691</a>, <a href="/abs/2309.16292">arXiv:2309.16292</a>, <a href="/abs/2309.10228">arXiv:2309.10228</a>, <a href="/abs/2310.01415">arXiv:2310.01415</a>, <a href="/abs/2309.09777">arXiv:2309.09777</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item782">[782]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12255" title="Abstract">arXiv:2311.12255</a> (replaced) [<a href="/pdf/2311.12255" title="Download PDF">pdf</a>, <a href="/format/2311.12255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Time Granularity on Temporal Graphs for Dynamic Link  Prediction in Real-world Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xiangjian Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+Y">Yanyi Pu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the Temporal Graph Learning Workshop @ NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item783">[783]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12367" title="Abstract">arXiv:2311.12367</a> (replaced) [<a href="/pdf/2311.12367" title="Download PDF">pdf</a>, <a href="/format/2311.12367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Meta-learning-based Adaptive Controller
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+F">Fengze Xie</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+G">Guanya Shi</a>, 
<a href="/search/cs?searchtype=author&query=O%27Connell%2C+M">Michael O&#x27;Connell</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Y">Yisong Yue</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+S">Soon-Jo Chung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item784">[784]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12379" title="Abstract">arXiv:2311.12379</a> (replaced) [<a href="/pdf/2311.12379" title="Download PDF">pdf</a>, <a href="/format/2311.12379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Infinite forecast combinations based on Dirichlet process
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yinuo Ren</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Feng Li</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yanfei Kang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jue Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item785">[785]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12401" title="Abstract">arXiv:2311.12401</a> (replaced) [<a href="/pdf/2311.12401" title="Download PDF">pdf</a>, <a href="/format/2311.12401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CASR: Refining Action Segmentation via Magrinalizing Frame-levle Causal  Relationships
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+K">Keqing Du</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xinyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hang Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item786">[786]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12553" title="Abstract">arXiv:2311.12553</a> (replaced) [<a href="/pdf/2311.12553" title="Download PDF">pdf</a>, <a href="/format/2311.12553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;HoVer-UNet&quot;: Accelerating HoVerNet with UNet-based multi-class nuclei  segmentation via knowledge distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tommasino%2C+C">Cristian Tommasino</a>, 
<a href="/search/eess?searchtype=author&query=Russo%2C+C">Cristiano Russo</a>, 
<a href="/search/eess?searchtype=author&query=Rinaldi%2C+A+M">Antonio Maria Rinaldi</a>, 
<a href="/search/eess?searchtype=author&query=Ciompi%2C+F">Francesco Ciompi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 2 figures, submitted to ISBI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item787">[787]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12564" title="Abstract">arXiv:2311.12564</a> (replaced) [<a href="/pdf/2311.12564" title="Download PDF">pdf</a>, <a href="/ps/2311.12564" title="Download PostScript">ps</a>, <a href="/format/2311.12564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Summary of the DISPLACE Challenge 2023 -- DIarization of SPeaker and  LAnguage in Conversational Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Baghel%2C+S">Shikha Baghel</a>, 
<a href="/search/eess?searchtype=author&query=Ramoji%2C+S">Shreyas Ramoji</a>, 
<a href="/search/eess?searchtype=author&query=Jain%2C+S">Somil Jain</a>, 
<a href="/search/eess?searchtype=author&query=Chowdhuri%2C+P+R">Pratik Roy Chowdhuri</a>, 
<a href="/search/eess?searchtype=author&query=Singh%2C+P">Prachi Singh</a>, 
<a href="/search/eess?searchtype=author&query=Vijayasenan%2C+D">Deepu Vijayasenan</a>, 
<a href="/search/eess?searchtype=author&query=Ganapathy%2C+S">Sriram Ganapathy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item788">[788]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12612" title="Abstract">arXiv:2311.12612</a> (replaced) [<a href="/pdf/2311.12612" title="Download PDF">pdf</a>, <a href="/ps/2311.12612" title="Download PostScript">ps</a>, <a href="/format/2311.12612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Type Of Upper And Lower Bounds On Right-Tail Probabilities Of  Continuous Random Variables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zlatanov%2C+N">Nikola Zlatanov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Minor typos corrected
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item789">[789]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12651" title="Abstract">arXiv:2311.12651</a> (replaced) [<a href="/pdf/2311.12651" title="Download PDF">pdf</a>, <a href="/format/2311.12651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mobile-Seed: Joint Semantic Segmentation and Boundary Detection for  Mobile Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Youqi Liao</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+S">Shuhao Kang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianping Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zhen Dong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bisheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xieyuanli Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, IEEE conference/letter underreview. Code and additional results are available at: <a href="https://github.com/WHU-USI3DV/Mobile-Seed">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item790">[790]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12670" title="Abstract">arXiv:2311.12670</a> (replaced) [<a href="/pdf/2311.12670" title="Download PDF">pdf</a>, <a href="/format/2311.12670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a more inductive world for drug repurposing approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+la+Fuente%2C+J">Jesus de la Fuente</a>, 
<a href="/search/cs?searchtype=author&query=Serrano%2C+G">Guillermo Serrano</a>, 
<a href="/search/cs?searchtype=author&query=Veleiro%2C+U">Ux&#xed;a Veleiro</a>, 
<a href="/search/cs?searchtype=author&query=Casals%2C+M">Mikel Casals</a>, 
<a href="/search/cs?searchtype=author&query=Vera%2C+L">Laura Vera</a>, 
<a href="/search/cs?searchtype=author&query=Pizurica%2C+M">Marija Pizurica</a>, 
<a href="/search/cs?searchtype=author&query=Pineda-Lucena%2C+A">Antonio Pineda-Lucena</a>, 
<a href="/search/cs?searchtype=author&query=Ochoa%2C+I">Idoia Ochoa</a>, 
<a href="/search/cs?searchtype=author&query=Vicent%2C+S">Silve Vicent</a>, 
<a href="/search/cs?searchtype=author&query=Gevaert%2C+O">Olivier Gevaert</a>, 
<a href="/search/cs?searchtype=author&query=Hernaez%2C+M">Mikel Hernaez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item791">[791]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12716" title="Abstract">arXiv:2311.12716</a> (replaced) [<a href="/pdf/2311.12716" title="Download PDF">pdf</a>, <a href="/format/2311.12716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> minimax: Efficient Baselines for Autocurricula in JAX
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Minqi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Dennis%2C+M">Michael Dennis</a>, 
<a href="/search/cs?searchtype=author&query=Grefenstette%2C+E">Edward Grefenstette</a>, 
<a href="/search/cs?searchtype=author&query=Rockt%C3%A4schel%2C+T">Tim Rockt&#xe4;schel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at ALOE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item792">[792]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12727" title="Abstract">arXiv:2311.12727</a> (replaced) [<a href="/pdf/2311.12727" title="Download PDF">pdf</a>, <a href="/format/2311.12727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Soft Random Sampling: A Theoretical and Empirical Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+X">Xiaodong Cui</a>, 
<a href="/search/cs?searchtype=author&query=Mittal%2C+A">Ashish Mittal</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Songtao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Saon%2C+G">George Saon</a>, 
<a href="/search/cs?searchtype=author&query=Kingsbury%2C+B">Brian Kingsbury</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item793">[793]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12778" title="Abstract">arXiv:2311.12778</a> (replaced) [<a href="/pdf/2311.12778" title="Download PDF">pdf</a>, <a href="/format/2311.12778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Calibration System and Algorithm Design for a Soft Hinged Micro Scanning  Mirror with a Triaxial Hall Effect Sensor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Di Wang</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+X">Xiaoyu Duan</a>, 
<a href="/search/cs?searchtype=author&query=Yeh%2C+S">Shu-Hao Yeh</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">Jun Zou</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Dezhen Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item794">[794]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12849" title="Abstract">arXiv:2311.12849</a> (replaced) [<a href="/pdf/2311.12849" title="Download PDF">pdf</a>, <a href="/format/2311.12849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reliability Analysis of Fault Tolerant Memory Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yigit%2C+Y">Yagmur Yigit</a>, 
<a href="/search/cs?searchtype=author&query=Maglaras%2C+L">Leandros Maglaras</a>, 
<a href="/search/cs?searchtype=author&query=Ferrag%2C+M+A">Mohamed Amine Ferrag</a>, 
<a href="/search/cs?searchtype=author&query=Moradpoor%2C+N">Naghmeh Moradpoor</a>, 
<a href="/search/cs?searchtype=author&query=Lambropoulos%2C+G">Georgios Lambropoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item795">[795]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12856" title="Abstract">arXiv:2311.12856</a> (replaced) [<a href="/pdf/2311.12856" title="Download PDF">pdf</a>, <a href="/format/2311.12856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Density of States Prediction of Crystalline Materials via Prompt-guided  Multi-Modal Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Lee%2C+N">Namkyeong Lee</a>, 
<a href="/search/cond-mat?searchtype=author&query=Noh%2C+H">Heewoong Noh</a>, 
<a href="/search/cond-mat?searchtype=author&query=Kim%2C+S">Sungwon Kim</a>, 
<a href="/search/cond-mat?searchtype=author&query=Hyun%2C+D">Dongmin Hyun</a>, 
<a href="/search/cond-mat?searchtype=author&query=Na%2C+G+S">Gyoung S. Na</a>, 
<a href="/search/cond-mat?searchtype=author&query=Park%2C+C">Chanyoung Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023. arXiv admin note: text overlap with <a href="/abs/2303.07000">arXiv:2303.07000</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item796">[796]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13110" title="Abstract">arXiv:2311.13110</a> (replaced) [<a href="/pdf/2311.13110" title="Download PDF">pdf</a>, <a href="/format/2311.13110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> White-Box Transformers via Sparse Rate Reduction: Compression Is All  There Is?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yaodong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Buchanan%2C+S">Sam Buchanan</a>, 
<a href="/search/cs?searchtype=author&query=Pai%2C+D">Druv Pai</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+T">Tianzhe Chu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Ziyang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+S">Shengbang Tong</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+H">Hao Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+Y">Yuexiang Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Haeffele%2C+B+D">Benjamin D. Haeffele</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yi Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper integrates the works <a href="/abs/2306.01129">arXiv:2306.01129</a> and <a href="/abs/2308.16271">arXiv:2308.16271</a> into a complete story. In this paper, we improve the writing and organization, and also add conceptual, empirical, and theoretical improvements over the previous work. V2: small typo fixes and formatting improvements
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item797">[797]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13120" title="Abstract">arXiv:2311.13120</a> (replaced) [<a href="/pdf/2311.13120" title="Download PDF">pdf</a>, <a href="/format/2311.13120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-modal In-Context Learning Makes an Ego-evolving Scene Text  Recognizer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jingqun Tang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chunhui Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Binghong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhizhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xin Tan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Can Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yuan Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item798">[798]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13180" title="Abstract">arXiv:2311.13180</a> (replaced) [<a href="/pdf/2311.13180" title="Download PDF">pdf</a>, <a href="/format/2311.13180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provably Efficient High-Dimensional Bandit Learning with Batched  Feedbacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Fan%2C+J">Jianqing Fan</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+Z">Zhaoran Wang</a>, 
<a href="/search/stat?searchtype=author&query=Yang%2C+Z">Zhuoran Yang</a>, 
<a href="/search/stat?searchtype=author&query=Ye%2C+C">Chenlu Ye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item799">[799]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13199" title="Abstract">arXiv:2311.13199</a> (replaced) [<a href="/pdf/2311.13199" title="Download PDF">pdf</a>, <a href="/format/2311.13199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DRIFu: Differentiable Rendering and Implicit Function-based Single-View  3D Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuang%2C+Z">Zijian Kuang</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+L">Lihang Ying</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Shi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Li Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/1905.05172">arXiv:1905.05172</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item800">[800]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13231" title="Abstract">arXiv:2311.13231</a> (replaced) [<a href="/pdf/2311.13231" title="Download PDF">pdf</a>, <a href="/format/2311.13231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Human Feedback to Fine-tune Diffusion Models without Any Reward  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kai Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+J">Jian Tao</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+J">Jiafei Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+C">Chunjiang Ge</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiaxin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qimai Li</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Weihan Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaolong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiu Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item801">[801]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13333" title="Abstract">arXiv:2311.13333</a> (replaced) [<a href="/pdf/2311.13333" title="Download PDF">pdf</a>, <a href="/format/2311.13333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trace-enabled Timing Model Synthesis for ROS2-based Autonomous  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abaza%2C+H">Hazem Abaza</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+D">Debayan Roy</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+S">Shiqing Fan</a>, 
<a href="/search/cs?searchtype=author&query=Saidi%2C+S">Selma Saidi</a>, 
<a href="/search/cs?searchtype=author&query=Motakis%2C+A">Antonios Motakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Operating Systems (cs.OS)</span>

</div>
</div>
</dd>
<dt><a name="item802">[802]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13384" title="Abstract">arXiv:2311.13384</a> (replaced) [<a href="/pdf/2311.13384" title="Download PDF">pdf</a>, <a href="/format/2311.13384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LucidDreamer: Domain-free Generation of 3D Gaussian Splatting Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chung%2C+J">Jaeyoung Chung</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Suyoung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Nam%2C+H">Hyeongjin Nam</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaerin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K+M">Kyoung Mu Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://luciddreamer-cvlab.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item803">[803]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13559" title="Abstract">arXiv:2311.13559</a> (replaced) [<a href="/pdf/2311.13559" title="Download PDF">pdf</a>, <a href="/ps/2311.13559" title="Download PostScript">ps</a>, <a href="/format/2311.13559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transfer Learning-based Real-time Handgun Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elmir%2C+Y">Youssef Elmir</a>, 
<a href="/search/cs?searchtype=author&query=Laouar%2C+S+A">Sid Ahmed Laouar</a>, 
<a href="/search/cs?searchtype=author&query=Hamdaoui%2C+L">Larbi Hamdaoui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 9 figures, and 3 tables. Accepted at The Iraqi Journal of Science, issued by College of Science at University of Baghdad
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item419">Cross-lists</a></li>
<li><a href="#item520">Replacements</a></li>
</ul>
<small>[ total of 803 entries:  <b>1-803</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2311">2311</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
