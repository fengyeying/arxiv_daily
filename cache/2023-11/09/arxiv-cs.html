<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Tue  7 Nov 23  to  Wed  8 Nov 23, announced Thu,  9 Nov 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item268">Cross-lists</a></li>
<li><a href="#item315">Replacements</a></li>
</ul>
<small>[ total of 519 entries:  <b>1-519</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Thu,  9 Nov 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04221" title="Abstract">arXiv:2311.04221</a> [<a href="/pdf/2311.04221" title="Download PDF">pdf</a>, <a href="/format/2311.04221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Software Architecture Challenges in Integrating Hybrid Classical-Quantum  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stirbu%2C+V">Vlad Stirbu</a>, 
<a href="/search/cs?searchtype=author&query=Mikkonen%2C+T">Tommi Mikkonen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2310.02598">arXiv:2310.02598</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The emergence of quantum computing proposes a revolutionary paradigm that can
radically transform numerous scientific and industrial application domains. The
ability of quantum computers to scale computations exponentially imply better
performance and efficiency for certain algorithmic tasks than current computers
provide. However, to gain benefit from such improvement, quantum computers must
be integrated with existing software systems, a process that is not
straightforward. In this paper, we investigate challenges that emerge from
building larger hybrid classical-quantum computers, and discuss some approaches
that could be employed to overcome these challenges.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04226" title="Abstract">arXiv:2311.04226</a> [<a href="/pdf/2311.04226" title="Download PDF">pdf</a>, <a href="/format/2311.04226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing Upper Limb Motor Function in the Immediate Post-Stroke Perioud  Using Accelerometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wallich%2C+M">Mackenzie Wallich</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+K">Kenneth Lai</a>, 
<a href="/search/cs?searchtype=author&query=Yanushkevich%2C+S">Svetlana Yanushkevich</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE Conference on Artificial Intelligence (CAI), Santa
  Clara, 2023, pp. 132-33
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Accelerometry has been extensively studied as an objective means of measuring
upper limb function in patients post-stroke. The objective of this paper is to
determine whether the accelerometry-derived measurements frequently used in
more long-term rehabilitation studies can also be used to monitor and rapidly
detect sudden changes in upper limb motor function in more recently
hospitalized stroke patients. Six binary classification models were created by
training on variable data window times of paretic upper limb accelerometer
feature data. The models were assessed on their effectiveness for
differentiating new input data into two classes: severe or moderately severe
motor function. The classification models yielded Area Under the Curve (AUC)
scores that ranged from 0.72 to 0.82 for 15-minute data windows to 0.77 to 0.94
for 120-minute data windows. These results served as a preliminary assessment
and a basis on which to further investigate the efficacy of using accelerometry
and machine learning to alert healthcare professionals to rapid changes in
motor function in the days immediately following a stroke.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04235" title="Abstract">arXiv:2311.04235</a> [<a href="/pdf/2311.04235" title="Download PDF">pdf</a>, <a href="/format/2311.04235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can LLMs Follow Simple Rules?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mu%2C+N">Norman Mu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sarah Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sizhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Karamardian%2C+D">David Karamardian</a>, 
<a href="/search/cs?searchtype=author&query=Aljeraisy%2C+L">Lulwa Aljeraisy</a>, 
<a href="/search/cs?searchtype=author&query=Hendrycks%2C+D">Dan Hendrycks</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+D">David Wagner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website: <a href="https://eecs.berkeley.edu/~normanmu/llm_rules">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">As Large Language Models (LLMs) are deployed with increasing real-world
responsibilities, it is important to be able to specify and constrain the
behavior of these systems in a reliable manner. Model developers may wish to
set explicit rules for the model, such as "do not generate abusive content",
but these may be circumvented by jailbreaking techniques. Evaluating how well
LLMs follow developer-provided rules in the face of adversarial inputs
typically requires manual review, which slows down monitoring and methods
development. To address this issue, we propose Rule-following Language
Evaluation Scenarios (RuLES), a programmatic framework for measuring
rule-following ability in LLMs. RuLES consists of 15 simple text scenarios in
which the model is instructed to obey a set of rules in natural language while
interacting with the human user. Each scenario has a concise evaluation program
to determine whether the model has broken any rules in a conversation. Through
manual exploration of model behavior in our scenarios, we identify 6 categories
of attack strategies and collect two suites of test cases: one consisting of
unique conversations from manual testing and one that systematically implements
strategies from the 6 categories. Across various popular proprietary and open
models such as GPT-4 and Llama 2, we find that all models are susceptible to a
wide variety of adversarial hand-crafted user inputs, though GPT-4 is the
best-performing model. Additionally, we evaluate open models under
gradient-based attacks and find significant vulnerabilities. We propose RuLES
as a challenging new setting for research into exploring and defending against
both manual and automatic attacks on LLMs.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04239" title="Abstract">arXiv:2311.04239</a> [<a href="/pdf/2311.04239" title="Download PDF">pdf</a>, <a href="/format/2311.04239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kindness in Multi-Agent Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alamiyan-Harandi%2C+F">Farinaz Alamiyan-Harandi</a>, 
<a href="/search/cs?searchtype=author&query=Hassanjani%2C+M">Mersad Hassanjani</a>, 
<a href="/search/cs?searchtype=author&query=Ramazi%2C+P">Pouria Ramazi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2302.12053">arXiv:2302.12053</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In human societies, people often incorporate fairness in their decisions and
treat reciprocally by being kind to those who act kindly. They evaluate the
kindness of others' actions not only by monitoring the outcomes but also by
considering the intentions. This behavioral concept can be adapted to train
cooperative agents in Multi-Agent Reinforcement Learning (MARL). We propose the
KindMARL method, where agents' intentions are measured by counterfactual
reasoning over the environmental impact of the actions that were available to
the agents. More specifically, the current environment state is compared with
the estimation of the current environment state provided that the agent had
chosen another action. The difference between each agent's reward, as the
outcome of its action, with that of its fellow, multiplied by the intention of
the fellow is then taken as the fellow's "kindness". If the result of each
reward-comparison confirms the agent's superiority, it perceives the fellow's
kindness and reduces its own reward. Experimental results in the Cleanup and
Harvest environments show that training based on the KindMARL method enabled
the agents to earn 89\% (resp. 37\%) and 44% (resp. 43\%) more total rewards
than training based on the Inequity Aversion and Social Influence methods. The
effectiveness of KindMARL is further supported by experiments in a traffic
light control problem.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04240" title="Abstract">arXiv:2311.04240</a> [<a href="/pdf/2311.04240" title="Download PDF">pdf</a>, <a href="/format/2311.04240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Environmental-Impact Based Multi-Agent Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alamiyan-Harandi%2C+F">Farinaz Alamiyan-Harandi</a>, 
<a href="/search/cs?searchtype=author&query=Ramazi%2C+P">Pouria Ramazi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">To promote cooperation and strengthen the individual impact on the collective
outcome in social dilemmas, we propose the Environmental-impact Multi-Agent
Reinforcement Learning (EMuReL) method where each agent estimates the
"environmental impact" of every other agent, that is, the difference in the
current environment state compared to the hypothetical environment in the
absence of that other agent. Inspired by the Inequity Aversion model, the agent
then compares its own reward with those of its fellows multiplied by their
environmental impacts. If its reward exceeds the scaled reward of one of its
fellows, the agent takes "social responsibility" toward that fellow by reducing
its own reward. Therefore, the less influential an agent is in reaching the
current state, the more social responsibility is taken by other agents.
Experiments in the Cleanup (resp. Harvest) test environment demonstrate that
agents trained based on EMuReL learn to cooperate more effectively and obtain
$54\%$ ($39\%$) and $20\%$ ($44\%$) more total rewards while preserving the
same cooperation levels compared to when they are trained based on the two
state-of-the-art reward reshaping methods inequity aversion and social
influence.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04243" title="Abstract">arXiv:2311.04243</a> [<a href="/pdf/2311.04243" title="Download PDF">pdf</a>, <a href="/format/2311.04243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Planet-Wide Traffic Camera Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vuong%2C+K">Khiem Vuong</a>, 
<a href="/search/cs?searchtype=author&query=Tamburo%2C+R">Robert Tamburo</a>, 
<a href="/search/cs?searchtype=author&query=Narasimhan%2C+S+G">Srinivasa G. Narasimhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in WACV 2024. Project webpage: <a href="https://www.khiemvuong.com/OpenTrafficCam3D">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite the widespread deployment of outdoor cameras, their potential for
automated analysis remains largely untapped due, in part, to calibration
challenges. The absence of precise camera calibration data, including intrinsic
and extrinsic parameters, hinders accurate real-world distance measurements
from captured videos. To address this, we present a scalable framework that
utilizes street-level imagery to reconstruct a metric 3D model, facilitating
precise calibration of in-the-wild traffic cameras. Notably, our framework
achieves 3D scene reconstruction and accurate localization of over 100 global
traffic cameras and is scalable to any camera with sufficient street-level
imagery. For evaluation, we introduce a dataset of 20 fully calibrated traffic
cameras, demonstrating our method's significant enhancements over existing
automatic calibration techniques. Furthermore, we highlight our approach's
utility in traffic analysis by extracting insights via 3D vehicle
reconstruction and speed measurement, thereby opening up the potential of using
outdoor cameras for automated analysis.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04244" title="Abstract">arXiv:2311.04244</a> [<a href="/pdf/2311.04244" title="Download PDF">pdf</a>, <a href="/ps/2311.04244" title="Download PostScript">ps</a>, <a href="/format/2311.04244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HKTGNN: Hierarchical Knowledge Transferable Graph Neural Network-based  Supply Chain Risk Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhanting Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+K">Kejun Bi</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yuyanzhen Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongfen Li</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+S">Shi Ying</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruijin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11pages, 3 figures, accepted and submitted by IEEE ISPA 2023(The 21st IEEE International Symposium on Parallel and Distributed Processing with Applications)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The strength of a supply chain is an important measure of a country's or
region's technical advancement and overall competitiveness. Establishing supply
chain risk assessment models for effective management and mitigation of
potential risks has become increasingly crucial. As the number of businesses
grows, the important relationships become more complicated and difficult to
measure. This emphasizes the need of extracting relevant information from graph
data. Previously, academics mostly employed knowledge inference to increase the
visibility of links between nodes in the supply chain. However, they have not
solved the data hunger problem of single node feature characteristics. We
propose a hierarchical knowledge transferable graph neural network-based
(HKTGNN) supply chain risk assessment model to address these issues. Our
approach is based on current graph embedding methods for assessing corporate
investment risk assessment. We embed the supply chain network corresponding to
individual goods in the supply chain using the graph embedding module,
resulting in a directed homogeneous graph with just product nodes. This reduces
the complicated supply chain network into a basic product network. It addresses
difficulties using the domain difference knowledge transferable module based on
centrality, which is presented by the premise that supply chain feature
characteristics may be biased in the actual world. Meanwhile, the feature
complement and message passing will alleviate the data hunger problem, which is
driven by domain differences. Our model outperforms in experiments on a
real-world supply chain dataset. We will give an equation to prove that our
comparative experiment is both effective and fair.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04245" title="Abstract">arXiv:2311.04245</a> [<a href="/pdf/2311.04245" title="Download PDF">pdf</a>, <a href="/format/2311.04245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPT-ST: Generative Pre-Training of Spatio-Temporal Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhonghang Li</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+L">Lianghao Xia</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by NeurIPS 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Thirty-seventh Conference on Neural Information Processing
  Systems(NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">In recent years, there has been a rapid development of spatio-temporal
prediction techniques in response to the increasing demands of traffic
management and travel planning. While advanced end-to-end models have achieved
notable success in improving predictive performance, their integration and
expansion pose significant challenges. This work aims to address these
challenges by introducing a spatio-temporal pre-training framework that
seamlessly integrates with downstream baselines and enhances their performance.
The framework is built upon two key designs: (i) We propose a spatio-temporal
mask autoencoder as a pre-training model for learning spatio-temporal
dependencies. The model incorporates customized parameter learners and
hierarchical spatial pattern encoding networks. These modules are specifically
designed to capture spatio-temporal customized representations and intra- and
inter-cluster region semantic relationships, which have often been neglected in
existing approaches. (ii) We introduce an adaptive mask strategy as part of the
pre-training mechanism. This strategy guides the mask autoencoder in learning
robust spatio-temporal representations and facilitates the modeling of
different relationships, ranging from intra-cluster to inter-cluster, in an
easy-to-hard training manner. Extensive experiments conducted on representative
benchmarks demonstrate the effectiveness of our proposed method. We have made
our model implementation publicly available at https://github.com/HKUDS/GPT-ST.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04246" title="Abstract">arXiv:2311.04246</a> [<a href="/pdf/2311.04246" title="Download PDF">pdf</a>, <a href="/format/2311.04246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ADFactory: Automated Data Factory for Optical Flow Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ling%2C+H">Han Ling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">A major challenge faced by current optical flow methods is the difficulty in
generalizing them well into the real world, mainly due to the high production
cost of datasets, which currently do not have a large real-world optical flow
dataset. To address this challenge, we introduce a novel optical flow training
framework that can efficiently train optical flow networks on the target data
domain without manual annotation. Specifically, we use advanced Nerf technology
to reconstruct scenes from photo groups collected by monocular cameras, and
calculate the optical flow results between camera pose pairs from the rendered
results. On this basis, we screen the generated training data from various
aspects such as Nerf's reconstruction quality, visual consistency of optical
flow labels, reconstruction depth consistency, etc. The filtered training data
can be directly used for network supervision. Experimentally, the
generalization ability of our scheme on KITTI surpasses existing
self-supervised optical flow and monocular scene flow algorithms. Moreover, it
can always surpass most supervised methods in real-world zero-point
generalization evaluation.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04247" title="Abstract">arXiv:2311.04247</a> [<a href="/pdf/2311.04247" title="Download PDF">pdf</a>, <a href="/format/2311.04247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis and Applications of Deep Learning with Finite Samples in Full  Life-Cycle Intelligence of Nuclear Power Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chenwei Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wenqiang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Caiyang Yu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhenan He</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jizhe Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shudong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jianming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+W">Wentao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+J">Jiancheng Lv</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The advent of Industry 4.0 has precipitated the incorporation of Artificial
Intelligence (AI) methods within industrial contexts, aiming to realize
intelligent manufacturing, operation as well as maintenance, also known as
industrial intelligence. However, intricate industrial milieus, particularly
those relating to energy exploration and production, frequently encompass data
characterized by long-tailed class distribution, sample imbalance, and domain
shift. These attributes pose noteworthy challenges to data-centric Deep
Learning (DL) techniques, crucial for the realization of industrial
intelligence. The present study centers on the intricate and distinctive
industrial scenarios of Nuclear Power Generation (NPG), meticulously
scrutinizing the application of DL techniques under the constraints of finite
data samples. Initially, the paper expounds on potential employment scenarios
for AI across the full life-cycle of NPG. Subsequently, we delve into an
evaluative exposition of DL's advancement, grounded in the finite sample
perspective. This encompasses aspects such as small-sample learning, few-shot
learning, zero-shot learning, and open-set recognition, also referring to the
unique data characteristics of NPG. The paper then proceeds to present two
specific case studies. The first revolves around the automatic recognition of
zirconium alloy metallography, while the second pertains to open-set
recognition for signal diagnosis of machinery sensors. These cases, spanning
the entirety of NPG's life-cycle, are accompanied by constructive outcomes and
insightful deliberations. By exploring and applying DL methodologies within the
constraints of finite sample availability, this paper not only furnishes a
robust technical foundation but also introduces a fresh perspective toward the
secure and efficient advancement and exploitation of this advanced energy
source.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04250" title="Abstract">arXiv:2311.04250</a> [<a href="/pdf/2311.04250" title="Download PDF">pdf</a>, <a href="/format/2311.04250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unifying Structure and Language Semantic for Efficient Contrastive  Knowledge Graph Completion with Structured Entity Anchors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Je%2C+S">Sang-Hyun Je</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+W">Wontae Choi</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+K">Kwangjin Oh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">The goal of knowledge graph completion (KGC) is to predict missing links in a
KG using trained facts that are already known. In recent, pre-trained language
model (PLM) based methods that utilize both textual and structural information
are emerging, but their performances lag behind state-of-the-art (SOTA)
structure-based methods or some methods lose their inductive inference
capabilities in the process of fusing structure embedding to text encoder. In
this paper, we propose a novel method to effectively unify structure
information and language semantics without losing the power of inductive
reasoning. We adopt entity anchors and these anchors and textual description of
KG elements are fed together into the PLM-based encoder to learn unified
representations. In addition, the proposed method utilizes additional random
negative samples which can be reused in the each mini-batch during contrastive
learning to learn a generalized entity representations. We verify the
effectiveness of the our proposed method through various experiments and
analysis. The experimental results on standard benchmark widely used in link
prediction task show that the proposed model outperforms existing the SOTA KGC
models. Especially, our method show the largest performance improvement on
FB15K-237, which is competitive to the SOTA of structure-based KGC methods.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04251" title="Abstract">arXiv:2311.04251</a> [<a href="/pdf/2311.04251" title="Download PDF">pdf</a>, <a href="/format/2311.04251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MixtureGrowth: Growing Neural Networks by Recombining Learned Parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pham%2C+C">Chau Pham</a>, 
<a href="/search/cs?searchtype=author&query=Teterwak%2C+P">Piotr Teterwak</a>, 
<a href="/search/cs?searchtype=author&query=Nelson%2C+S">Soren Nelson</a>, 
<a href="/search/cs?searchtype=author&query=Plummer%2C+B+A">Bryan A. Plummer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE Winter Conference on Applications of Computer Vision (WACV) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Most deep neural networks are trained under fixed network architectures and
require retraining when the architecture changes. If expanding the network's
size is needed, it is necessary to retrain from scratch, which is expensive. To
avoid this, one can grow from a small network by adding random weights over
time to gradually achieve the target network size. However, this naive approach
falls short in practice as it brings too much noise to the growing process.
Prior work tackled this issue by leveraging the already learned weights and
training data for generating new weights through conducting a computationally
expensive analysis step. In this paper, we introduce MixtureGrowth, a new
approach to growing networks that circumvents the initialization overhead in
prior work. Before growing, each layer in our model is generated with a linear
combination of parameter templates. Newly grown layer weights are generated by
using a new linear combination of existing templates for a layer. On one hand,
these templates are already trained for the task, providing a strong
initialization. On the other, the new coefficients provide flexibility for the
added layer weights to learn something new. We show that our approach boosts
top-1 accuracy over the state-of-the-art by 2-2.5% on CIFAR-100 and ImageNet
datasets, while achieving comparable performance with fewer FLOPs to a larger
network trained from scratch. Code is available at
https://github.com/chaudatascience/mixturegrowth.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04252" title="Abstract">arXiv:2311.04252</a> [<a href="/pdf/2311.04252" title="Download PDF">pdf</a>, <a href="/ps/2311.04252" title="Download PostScript">ps</a>, <a href="/format/2311.04252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CNN-Based Structural Damage Detection using Time-Series Sensor Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pathak%2C+I">Ishan Pathak</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+I">Ishan Jha</a>, 
<a href="/search/cs?searchtype=author&query=Sadana%2C+A">Aditya Sadana</a>, 
<a href="/search/cs?searchtype=author&query=Bhowmik%2C+B">Basuraj Bhowmik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Structural Health Monitoring (SHM) is vital for evaluating structural
condition, aiming to detect damage through sensor data analysis. It aligns with
predictive maintenance in modern industry, minimizing downtime and costs by
addressing potential structural issues. Various machine learning techniques
have been used to extract valuable information from vibration data, often
relying on prior structural knowledge. This research introduces an innovative
approach to structural damage detection, utilizing a new Convolutional Neural
Network (CNN) algorithm. In order to extract deep spatial features from time
series data, CNNs are taught to recognize long-term temporal connections. This
methodology combines spatial and temporal features, enhancing discrimination
capabilities when compared to methods solely reliant on deep spatial features.
Time series data are divided into two categories using the proposed neural
network: undamaged and damaged. To validate its efficacy, the method's accuracy
was tested using a benchmark dataset derived from a three-floor structure at
Los Alamos National Laboratory (LANL). The outcomes show that the new CNN
algorithm is very accurate in spotting structural degradation in the examined
structure.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04254" title="Abstract">arXiv:2311.04254</a> [<a href="/pdf/2311.04254" title="Download PDF">pdf</a>, <a href="/format/2311.04254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Everything of Thoughts: Defying the Law of Penrose Triangle for Thought  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+R">Ruomeng Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chaoyun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+M">Minghua Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+S">Si Qin</a>, 
<a href="/search/cs?searchtype=author&query=Rajmohan%2C+S">Saravan Rajmohan</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Q">Qingwei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongmei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advancements in Large Language Models (LLMs) have revolutionized
decision-making by breaking down complex problems into more manageable language
sequences referred to as ``thoughts''. An effective thought design should
consider three key perspectives: performance, efficiency, and flexibility.
However, existing thought can at most exhibit two of these attributes. To
address these limitations, we introduce a novel thought prompting approach
called ``Everything of Thoughts'' (XoT) to defy the law of ``Penrose triangle
of existing thought paradigms. XoT leverages pretrained reinforcement learning
and Monte Carlo Tree Search (MCTS) to incorporate external domain knowledge
into thoughts, thereby enhancing LLMs' capabilities and enabling them to
generalize to unseen problems efficiently. Through the utilization of the
MCTS-LLM collaborative thought revision framework, this approach autonomously
produces high-quality comprehensive cognitive mappings with minimal LLM
interactions. Additionally, XoT empowers LLMs to engage in unconstrained
thinking, allowing for flexible cognitive mappings for problems with multiple
solutions.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04256" title="Abstract">arXiv:2311.04256</a> [<a href="/pdf/2311.04256" title="Download PDF">pdf</a>, <a href="/ps/2311.04256" title="Download PostScript">ps</a>, <a href="/format/2311.04256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Foundational propositions of hesitant fuzzy sets and parameter  reductions of hesitant fuzzy information systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shizhan Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
<p class="mathjax">Hesitant fuzzy sets are widely used in the instances of uncertainty and
hesitation. The inclusion relationship is an important and foundational
definition for sets. Hesitant fuzzy set, as a kind of set, needs explicit
definition of inclusion relationship. Base on the hesitant fuzzy membership
degree of discrete form, several kinds of inclusion relationships for hesitant
fuzzy sets are proposed. And then some foundational propositions of hesitant
fuzzy sets and the families of hesitant fuzzy sets are presented. Finally, some
foundational propositions of hesitant fuzzy information systems with respect to
parameter reductions are put forward, and an example and an algorithm are given
to illustrate the processes of parameter reductions.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04257" title="Abstract">arXiv:2311.04257</a> [<a href="/pdf/2311.04257" title="Download PDF">pdf</a>, <a href="/format/2311.04257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> mPLUG-Owl2: Revolutionizing Multi-modal Large Language Model with  Modality Collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Q">Qinghao Ye</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haiyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jiabo Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+M">Ming Yan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haowei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Q">Qi Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Ji Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingren Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Multi-modal Large Language Models (MLLMs) have demonstrated impressive
instruction abilities across various open-ended tasks. However, previous
methods primarily focus on enhancing multi-modal capabilities. In this work, we
introduce a versatile multi-modal large language model, mPLUG-Owl2, which
effectively leverages modality collaboration to improve performance in both
text and multi-modal tasks. mPLUG-Owl2 utilizes a modularized network design,
with the language decoder acting as a universal interface for managing
different modalities. Specifically, mPLUG-Owl2 incorporates shared functional
modules to facilitate modality collaboration and introduces a modality-adaptive
module that preserves modality-specific features. Extensive experiments reveal
that mPLUG-Owl2 is capable of generalizing both text tasks and multi-modal
tasks and achieving state-of-the-art performances with a single generic model.
Notably, mPLUG-Owl2 is the first MLLM model that demonstrates the modality
collaboration phenomenon in both pure-text and multi-modal scenarios, setting a
pioneering path in the development of future multi-modal foundation models.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04260" title="Abstract">arXiv:2311.04260</a> [<a href="/pdf/2311.04260" title="Download PDF">pdf</a>, <a href="/format/2311.04260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fully Automated Task Management for Generation, Execution, and  Evaluation: A Framework for Fetch-and-Carry Tasks with Natural Language  Instructions in Continuous Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kambara%2C+M">Motonari Kambara</a>, 
<a href="/search/cs?searchtype=author&query=Sugiura%2C+K">Komei Sugiura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at presentation for CVPR 2023 Embodied AI Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This paper aims to develop a framework that enables a robot to execute tasks
based on visual information, in response to natural language instructions for
Fetch-and-Carry with Object Grounding (FCOG) tasks. Although there have been
many frameworks, they usually rely on manually given instruction sentences.
Therefore, evaluations have only been conducted with fixed tasks. Furthermore,
many multimodal language understanding models for the benchmarks only consider
discrete actions. To address the limitations, we propose a framework for the
full automation of the generation, execution, and evaluation of FCOG tasks. In
addition, we introduce an approach to solving the FCOG tasks by dividing them
into four distinct subtasks.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04261" title="Abstract">arXiv:2311.04261</a> [<a href="/pdf/2311.04261" title="Download PDF">pdf</a>, <a href="/format/2311.04261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Restoration of Analog Videos Using Swin-UNet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agnolucci%2C+L">Lorenzo Agnolucci</a>, 
<a href="/search/cs?searchtype=author&query=Galteri%2C+L">Leonardo Galteri</a>, 
<a href="/search/cs?searchtype=author&query=Bertini%2C+M">Marco Bertini</a>, 
<a href="/search/cs?searchtype=author&query=Del+Bimbo%2C+A">Alberto Del Bimbo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM MM 2022 (Demo)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">In this paper, we present a system to restore analog videos of historical
archives. These videos often contain severe visual degradation due to the
deterioration of their tape supports that require costly and slow manual
interventions to recover the original content. The proposed system uses a
multi-frame approach and is able to deal with severe tape mistracking, which
results in completely scrambled frames. Tests on real-world videos from a major
historical video archive show the effectiveness of our demo system. The code
and the pre-trained model are publicly available at
https://github.com/miccunifi/analog-video-restoration.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04262" title="Abstract">arXiv:2311.04262</a> [<a href="/pdf/2311.04262" title="Download PDF">pdf</a>, <a href="/format/2311.04262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ETDPC: A Multimodality Framework for Classifying Pages in Electronic  Theses and Dissertations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choudhury%2C+M+H">Muntabir Hasan Choudhury</a>, 
<a href="/search/cs?searchtype=author&query=Salsabil%2C+L">Lamia Salsabil</a>, 
<a href="/search/cs?searchtype=author&query=Ingram%2C+W+A">William A. Ingram</a>, 
<a href="/search/cs?searchtype=author&query=Fox%2C+E+A">Edward A. Fox</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jian Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures, accepted to Innovative Applications of Artificial Intelligence (IAAI-24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Digital Libraries (cs.DL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Electronic theses and dissertations (ETDs) have been proposed, advocated, and
generated for more than 25 years. Although ETDs are hosted by commercial or
institutional digital library repositories, they are still an understudied type
of scholarly big data, partially because they are usually longer than
conference proceedings and journals. Segmenting ETDs will allow researchers to
study sectional content. Readers can navigate to particular pages of interest,
discover, and explore the content buried in these long documents. Most existing
frameworks on document page classification are designed for classifying general
documents and perform poorly on ETDs. In this paper, we propose ETDPC. Its
backbone is a two-stream multimodal model with a cross-attention network to
classify ETD pages into 13 categories. To overcome the challenge of imbalanced
labeled samples, we augmented data for minority categories and employed a
hierarchical classifier. ETDPC outperforms the state-of-the-art models in all
categories, achieving an F1 of 0.84 -- 0.96 for 9 out of 13 categories. We also
demonstrated its data efficiency. The code and data can be found on GitHub
(https://github.com/lamps-lab/ETDMiner/tree/master/etd_segmentation).
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04263" title="Abstract">arXiv:2311.04263</a> [<a href="/pdf/2311.04263" title="Download PDF">pdf</a>, <a href="/format/2311.04263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perceptual Quality Improvement in Videoconferencing using  Keyframes-based GAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agnolucci%2C+L">Lorenzo Agnolucci</a>, 
<a href="/search/cs?searchtype=author&query=Galteri%2C+L">Leonardo Galteri</a>, 
<a href="/search/cs?searchtype=author&query=Bertini%2C+M">Marco Bertini</a>, 
<a href="/search/cs?searchtype=author&query=Del+Bimbo%2C+A">Alberto Del Bimbo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Transactions on Multimedia 2023 (IEEE TMM 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the latest years, videoconferencing has taken a fundamental role in
interpersonal relations, both for personal and business purposes. Lossy video
compression algorithms are the enabling technology for videoconferencing, as
they reduce the bandwidth required for real-time video streaming. However,
lossy video compression decreases the perceived visual quality. Thus, many
techniques for reducing compression artifacts and improving video visual
quality have been proposed in recent years. In this work, we propose a novel
GAN-based method for compression artifacts reduction in videoconferencing.
Given that, in this context, the speaker is typically in front of the camera
and remains the same for the entire duration of the transmission, we can
maintain a set of reference keyframes of the person from the higher-quality
I-frames that are transmitted within the video stream and exploit them to guide
the visual quality improvement; a novel aspect of this approach is the update
policy that maintains and updates a compact and effective set of reference
keyframes. First, we extract multi-scale features from the compressed and
reference frames. Then, our architecture combines these features in a
progressive manner according to facial landmarks. This allows the restoration
of the high-frequency details lost after the video compression. Experiments
show that the proposed approach improves visual quality and generates
photo-realistic results even with high compression rates. Code and pre-trained
networks are publicly available at
https://github.com/LorenzoAgnolucci/Keyframes-GAN.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04284" title="Abstract">arXiv:2311.04284</a> [<a href="/pdf/2311.04284" title="Download PDF">pdf</a>, <a href="/format/2311.04284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CRAB: Assessing the Strength of Causal Relationships Between Real-world  Events
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Romanou%2C+A">Angelika Romanou</a>, 
<a href="/search/cs?searchtype=author&query=Montariol%2C+S">Syrielle Montariol</a>, 
<a href="/search/cs?searchtype=author&query=Paul%2C+D">Debjit Paul</a>, 
<a href="/search/cs?searchtype=author&query=Laugier%2C+L">Leo Laugier</a>, 
<a href="/search/cs?searchtype=author&query=Aberer%2C+K">Karl Aberer</a>, 
<a href="/search/cs?searchtype=author&query=Bosselut%2C+A">Antoine Bosselut</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Understanding narratives requires reasoning about the cause-and-effect
relationships between events mentioned in the text. While existing foundation
models yield impressive results in many NLP tasks requiring reasoning, it is
unclear whether they understand the complexity of the underlying network of
causal relationships of events in narratives. In this work, we present CRAB, a
new Causal Reasoning Assessment Benchmark designed to evaluate causal
understanding of events in real-world narratives. CRAB contains fine-grained,
contextual causality annotations for ~2.7K pairs of real-world events that
describe various newsworthy event timelines (e.g., the acquisition of Twitter
by Elon Musk). Using CRAB, we measure the performance of several large language
models, demonstrating that most systems achieve poor performance on the task.
Motivated by classical causal principles, we also analyze the causal structures
of groups of events in CRAB, and find that models perform worse on causal
reasoning when events are derived from complex causal structures compared to
simple linear causal chains. We make our dataset and code available to the
research community.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04287" title="Abstract">arXiv:2311.04287</a> [<a href="/pdf/2311.04287" title="Download PDF">pdf</a>, <a href="/format/2311.04287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Holistic Evaluation of Text-To-Image Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+T">Tony Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yasunaga%2C+M">Michihiro Yasunaga</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+C">Chenlin Meng</a>, 
<a href="/search/cs?searchtype=author&query=Mai%2C+Y">Yifan Mai</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J+S">Joon Sung Park</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Agrim Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yunzhi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Narayanan%2C+D">Deepak Narayanan</a>, 
<a href="/search/cs?searchtype=author&query=Teufel%2C+H+B">Hannah Benita Teufel</a>, 
<a href="/search/cs?searchtype=author&query=Bellagente%2C+M">Marco Bellagente</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+M">Minguk Kang</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+T">Taesung Park</a>, 
<a href="/search/cs?searchtype=author&query=Leskovec%2C+J">Jure Leskovec</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jun-Yan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Fei-Fei%2C+L">Li Fei-Fei</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiajun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ermon%2C+S">Stefano Ermon</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P">Percy Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023. First three authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The stunning qualitative improvement of recent text-to-image models has led
to their widespread attention and adoption. However, we lack a comprehensive
quantitative understanding of their capabilities and risks. To fill this gap,
we introduce a new benchmark, Holistic Evaluation of Text-to-Image Models
(HEIM). Whereas previous evaluations focus mostly on text-image alignment and
image quality, we identify 12 aspects, including text-image alignment, image
quality, aesthetics, originality, reasoning, knowledge, bias, toxicity,
fairness, robustness, multilinguality, and efficiency. We curate 62 scenarios
encompassing these aspects and evaluate 26 state-of-the-art text-to-image
models on this benchmark. Our results reveal that no single model excels in all
aspects, with different models demonstrating different strengths. We release
the generated images and human evaluation results for full transparency at
https://crfm.stanford.edu/heim/v1.1.0 and the code at
https://github.com/stanford-crfm/helm, which is integrated with the HELM
codebase.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04289" title="Abstract">arXiv:2311.04289</a> [<a href="/pdf/2311.04289" title="Download PDF">pdf</a>, <a href="/format/2311.04289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameter Tuning in the Radial Kernel-Based Partition of Unity Method by  Bayesian Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cavoretto%2C+R">Roberto Cavoretto</a>, 
<a href="/search/math?searchtype=author&query=De+Rossi%2C+A">Alessandra De Rossi</a>, 
<a href="/search/math?searchtype=author&query=Lancellotti%2C+S">Sandro Lancellotti</a>, 
<a href="/search/math?searchtype=author&query=Romaniello%2C+F">Federico Romaniello</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 2 figures. arXiv admin note: text overlap with <a href="/abs/2311.04210">arXiv:2311.04210</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we employ Bayesian optimization to concurrently explore the
optimal values for both the shape parameter and the radius in the partition of
unity interpolation using radial basis functions. Bayesian optimization is a
probabilistic, iterative approach that models the error function through a
progressively self-updated Gaussian process. Meanwhile, the partition of unity
approach harnesses a meshfree method, allowing us to significantly reduce
computational expenses, particularly when considering a substantial number of
scattered data points. This reduction in computational cost is achieved by
decomposing the entire domain into several smaller subdomains, each of them
with a variable radius. We provide an estimation of the complexity of our
algorithm and carry out numerical experiments to illustrate the effectiveness
of our approach, dealing with test and real-world datasets.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04292" title="Abstract">arXiv:2311.04292</a> [<a href="/pdf/2311.04292" title="Download PDF">pdf</a>, <a href="/format/2311.04292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aspect-based Meeting Transcript Summarization: A Two-Stage Approach with  Weak Supervision on Sentence Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhongfen Deng</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+S">Seunghyun Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Bui%2C+T">Trung Bui</a>, 
<a href="/search/cs?searchtype=author&query=Dernoncourt%2C+F">Franck Dernoncourt</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+Q+H">Quan Hung Tran</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuaiqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wenting Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yibo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S. Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 2023 IEEE International Conference on Big Data
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Aspect-based meeting transcript summarization aims to produce multiple
summaries, each focusing on one aspect of content in a meeting transcript. It
is challenging as sentences related to different aspects can mingle together,
and those relevant to a specific aspect can be scattered throughout the long
transcript of a meeting. The traditional summarization methods produce one
summary mixing information of all aspects, which cannot deal with the above
challenges of aspect-based meeting transcript summarization. In this paper, we
propose a two-stage method for aspect-based meeting transcript summarization.
To select the input content related to specific aspects, we train a sentence
classifier on a dataset constructed from the AMI corpus with pseudo-labeling.
Then we merge the sentences selected for a specific aspect as the input for the
summarizer to produce the aspect-based summary. Experimental results on the AMI
corpus outperform many strong baselines, which verifies the effectiveness of
our proposed method.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04293" title="Abstract">arXiv:2311.04293</a> [<a href="/pdf/2311.04293" title="Download PDF">pdf</a>, <a href="/format/2311.04293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lie Point Symmetry and Physics Informed Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akhound-Sadegh%2C+T">Tara Akhound-Sadegh</a>, 
<a href="/search/cs?searchtype=author&query=Perreault-Levasseur%2C+L">Laurence Perreault-Levasseur</a>, 
<a href="/search/cs?searchtype=author&query=Brandstetter%2C+J">Johannes Brandstetter</a>, 
<a href="/search/cs?searchtype=author&query=Welling%2C+M">Max Welling</a>, 
<a href="/search/cs?searchtype=author&query=Ravanbakhsh%2C+S">Siamak Ravanbakhsh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Symmetries have been leveraged to improve the generalization of neural
networks through different mechanisms from data augmentation to equivariant
architectures. However, despite their potential, their integration into neural
solvers for partial differential equations (PDEs) remains largely unexplored.
We explore the integration of PDE symmetries, known as Lie point symmetries, in
a major family of neural solvers known as physics-informed neural networks
(PINNs). We propose a loss function that informs the network about Lie point
symmetries in the same way that PINN models try to enforce the underlying PDE
through a loss function. Intuitively, our symmetry loss ensures that the
infinitesimal generators of the Lie group conserve the PDE solutions.
Effectively, this means that once the network learns a solution, it also learns
the neighbouring solutions generated by Lie point symmetries. Empirical
evaluations indicate that the inductive bias introduced by the Lie point
symmetries of the PDEs greatly boosts the sample efficiency of PINNs.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04299" title="Abstract">arXiv:2311.04299</a> [<a href="/pdf/2311.04299" title="Download PDF">pdf</a>, <a href="/format/2311.04299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Node-Binded Communities for Interpolation on Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cavoretto%2C+R">Roberto Cavoretto</a>, 
<a href="/search/math?searchtype=author&query=De+Rossi%2C+A">Alessandra De Rossi</a>, 
<a href="/search/math?searchtype=author&query=Lancellotti%2C+S">Sandro Lancellotti</a>, 
<a href="/search/math?searchtype=author&query=Romaniello%2C+F">Federico Romaniello</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Partition of unity methods (PUMs) on graphs represent straightforward and
remarkably adaptable auxiliary techniques for graph signal processing. By
relying solely on the intrinsic graph structure, we propose the generation of a
partition of unity through centrality measures and modularity. Subsequently, we
integrate PUMs with a local graph basis function (GBF) approximation approach
to achieve low-cost global interpolation schemes.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04301" title="Abstract">arXiv:2311.04301</a> [<a href="/pdf/2311.04301" title="Download PDF">pdf</a>, <a href="/format/2311.04301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Class-Incremental Continual Learning for General Purpose Healthcare  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Amritpal Singh</a>, 
<a href="/search/cs?searchtype=author&query=Gurbuz%2C+M+B">Mustafa Burak Gurbuz</a>, 
<a href="/search/cs?searchtype=author&query=Gantha%2C+S+S">Shiva Souhith Gantha</a>, 
<a href="/search/cs?searchtype=author&query=Jasti%2C+P">Prahlad Jasti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 1 Figure. Accepted in NeurIPS 2023 (Medical Imaging meets NeurIPS Workshop)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Healthcare clinics regularly encounter dynamic data that changes due to
variations in patient populations, treatment policies, medical devices, and
emerging disease patterns. Deep learning models can suffer from catastrophic
forgetting when fine-tuned in such scenarios, causing poor performance on
previously learned tasks. Continual learning allows learning on new tasks
without performance drop on previous tasks. In this work, we investigate the
performance of continual learning models on four different medical imaging
scenarios involving ten classification datasets from diverse modalities,
clinical specialties, and hospitals. We implement various continual learning
approaches and evaluate their performance in these scenarios. Our results
demonstrate that a single model can sequentially learn new tasks from different
specialties and achieve comparable performance to naive methods. These findings
indicate the feasibility of recycling or sharing models across the same or
different medical specialties, offering another step towards the development of
general-purpose medical imaging AI that can be shared across institutions.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04302" title="Abstract">arXiv:2311.04302</a> [<a href="/pdf/2311.04302" title="Download PDF">pdf</a>, <a href="/format/2311.04302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Hard is Weak-Memory Testing?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+S">Soham Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Krishna%2C+S">Shankaranarayanan Krishna</a>, 
<a href="/search/cs?searchtype=author&query=Mathur%2C+U">Umang Mathur</a>, 
<a href="/search/cs?searchtype=author&query=Pavlogiannis%2C+A">Andreas Pavlogiannis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Weak-memory models are standard formal specifications of concurrency across
hardware, programming languages, and distributed systems. A fundamental
computational problem is consistency testing: is the observed execution of a
concurrent program in alignment with the specification of the underlying
system? The problem has been studied extensively across Sequential Consistency
(SC) and weak memory, and proven to be NP-complete when some aspect of the
input (e.g., number of threads/memory locations) is unbounded. This
unboundedness has left a natural question open: are there efficient
parameterized algorithms for testing?
<br />The main contribution of this paper is a deep hardness result for consistency
testing under many popular weak-memory models: the problem remains NP-complete
even in its bounded setting, where candidate executions contain a bounded
number of threads, memory locations, and values. This hardness spreads across
several Release-Acquire variants of C11, a popular variant of its Relaxed
fragment, popular Causal Consistency models, and the POWER architecture. To our
knowledge, this is the first result that fully exposes the hardness of
weak-memory testing and proves that the problem admits no parameterization
under standard input parameters. It also yields a computational separation of
these models from SC, x86-TSO, PSO, and Relaxed, for which bounded consistency
testing is either known (for SC), or shown here (for the rest), to be in
polynomial time.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04303" title="Abstract">arXiv:2311.04303</a> [<a href="/pdf/2311.04303" title="Download PDF">pdf</a>, <a href="/format/2311.04303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Stochastic Nonlinear Model Predictive Control with Look-ahead  Deep Reinforcement Learning for Autonomous Vehicle Motion Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zarrouki%2C+B">Baha Zarrouki</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+C">Chenyang Wang</a>, 
<a href="/search/eess?searchtype=author&query=Betz%2C+J">Johannes Betz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">In this paper, we present a Deep Reinforcement Learning (RL)-driven Adaptive
Stochastic Nonlinear Model Predictive Control (SNMPC) to optimize uncertainty
handling, constraints robustification, feasibility, and closed-loop
performance. To this end, we conceive an RL agent to proactively anticipate
upcoming control tasks and to dynamically determine the most suitable
combination of key SNMPC parameters - foremost the robustification factor
$\kappa$ and the Uncertainty Propagation Horizon (UPH) $T_u$. We analyze the
trained RL agent's decision-making process and highlight its ability to learn
context-dependent optimal parameters. One key finding is that adapting the
constraints robustification factor with the learned policy reduces conservatism
and improves closed-loop performance while adapting UPH renders previously
infeasible SNMPC problems feasible when faced with severe disturbances. We
showcase the enhanced robustness and feasibility of our Adaptive SNMPC (aSNMPC)
through the real-time motion control task of an autonomous passenger vehicle to
follow an optimal race line when confronted with significant time-variant
disturbances. Experimental findings demonstrate that our look-ahead RL-driven
aSNMPC outperforms its Static SNMPC (sSNMPC) counterpart in minimizing the
lateral deviation both with accurate and inaccurate disturbance assumptions and
even when driving in previously unexplored environments.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04306" title="Abstract">arXiv:2311.04306</a> [<a href="/pdf/2311.04306" title="Download PDF">pdf</a>, <a href="/ps/2311.04306" title="Download PostScript">ps</a>, <a href="/format/2311.04306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Order Numerical Method for 1D Non-local Diffusive Equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Do%2C+D">D. Do</a>, 
<a href="/search/math?searchtype=author&query=Matin%2C+H+N+Z">H. Nick Zinat Matin</a>, 
<a href="/search/math?searchtype=author&query=Monache%2C+M+L+D">M. L. Delle Monache</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages and 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper we present a non-local numerical scheme based on the Local
Discontinuous Galerkin method for a non-local diffusive partial differential
equation with application to traffic flow. In this model, the velocity is
determined by both the average of the traffic density as well as the changes in
the traffic density at a neighborhood of each point. We discuss nonphysical
behaviors that can arise when including diffusion, and our measures to prevent
them in our model. The numerical results suggest that this is an accurate
method for solving this type of equation and that the model can capture desired
traffic flow behavior. We show that computation of the non-local convolution
results in $\mathcal{O}(n^2)$ complexity, but the increased computation time
can be mitigated with high-order schemes like the one proposed.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04310" title="Abstract">arXiv:2311.04310</a> [<a href="/pdf/2311.04310" title="Download PDF">pdf</a>, <a href="/ps/2311.04310" title="Download PostScript">ps</a>, <a href="/format/2311.04310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KNIMEZoBot: Enhancing Literature Review with Zotero and KNIME OpenAI  Integration using Retrieval-Augmented Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alshammari%2C+S">Suad Alshammari</a>, 
<a href="/search/cs?searchtype=author&query=Basalelah%2C+L">Lama Basalelah</a>, 
<a href="/search/cs?searchtype=author&query=Rukbah%2C+W+A">Walaa Abu Rukbah</a>, 
<a href="/search/cs?searchtype=author&query=Alsuhibani%2C+A">Ali Alsuhibani</a>, 
<a href="/search/cs?searchtype=author&query=Wijesinghe%2C+D+S">Dayanjan S. Wijesinghe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Academic researchers face challenges keeping up with exponentially growing
published findings in their field. Performing comprehensive literature reviews
to synthesize knowledge is time-consuming and labor-intensive using manual
approaches. Recent advances in artificial intelligence provide promising
solutions, yet many require coding expertise, limiting accessibility.
KNIMEZoBot represents an innovative integration of Zotero, OpenAI, and the
KNIME visual programming platform to automate literature review tasks for users
with no coding experience. By leveraging KNIME's intuitive graphical interface,
researchers can create workflows to search their Zotero libraries and utilize
OpenAI models to extract key information without coding. Users simply provide
API keys and configure settings through a user-friendly interface in a locally
stored copy of the workflow. KNIMEZoBot then allows asking natural language
questions via a chatbot and retrieves relevant passages from papers to generate
synthesized answers. This system has significant potential to expedite
literature reviews for researchers unfamiliar with coding by automating
retrieval and analysis of publications in personal Zotero libraries. KNIMEZoBot
demonstrates how thoughtfully designed AI tools can expand accessibility and
accelerate knowledge building across diverse research domains.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04311" title="Abstract">arXiv:2311.04311</a> [<a href="/pdf/2311.04311" title="Download PDF">pdf</a>, <a href="/format/2311.04311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Approach for Radial Kernel Parameter Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cavoretto%2C+R">Roberto Cavoretto</a>, 
<a href="/search/math?searchtype=author&query=De+Rossi%2C+A">Alessandra De Rossi</a>, 
<a href="/search/math?searchtype=author&query=Lancellotti%2C+S">Sandro Lancellotti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 4 figures, 10 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper we present a new fast and accurate method for Radial Basis
Function (RBF) approximation, including interpolation as a special case, which
enables us to effectively find the optimal value of the RBF shape parameter. In
particular, we propose a statistical technique, called Bayesian optimization,
that consists in modelling the error function with a Gaussian process, by
which, through an iterative process, the optimal shape parameter is selected.
The process is step by step self-updated resulting in a relevant decrease in
search time with respect to the classical leave one out cross validation
technique. Numerical results deriving from some test examples and an
application to real data show the performance of the proposed method.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04313" title="Abstract">arXiv:2311.04313</a> [<a href="/pdf/2311.04313" title="Download PDF">pdf</a>, <a href="/ps/2311.04313" title="Download PostScript">ps</a>, <a href="/format/2311.04313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Child Text-to-Speech Synthesis through Fastpitch-based Transfer  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+R">Rishabh Jain</a>, 
<a href="/search/cs?searchtype=author&query=Corcoran%2C+P">Peter Corcoran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented in SpeD 23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Speech synthesis technology has witnessed significant advancements in recent
years, enabling the creation of natural and expressive synthetic speech. One
area of particular interest is the generation of synthetic child speech, which
presents unique challenges due to children's distinct vocal characteristics and
developmental stages. This paper presents a novel approach that leverages the
Fastpitch text-to-speech (TTS) model for generating high-quality synthetic
child speech. This study uses the transfer learning training pipeline. The
approach involved finetuning a multi-speaker TTS model to work with child
speech. We use the cleaned version of the publicly available MyST dataset (55
hours) for our finetuning experiments. We also release a prototype dataset of
synthetic speech samples generated from this research together with model code
to support further research. By using a pretrained MOSNet, we conducted an
objective assessment that showed a significant correlation between real and
synthetic child voices. Additionally, to validate the intelligibility of the
generated speech, we employed an automatic speech recognition (ASR) model to
compare the word error rates (WER) of real and synthetic child voices. The
speaker similarity between the real and generated speech is also measured using
a pretrained speaker encoder.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04315" title="Abstract">arXiv:2311.04315</a> [<a href="/pdf/2311.04315" title="Download PDF">pdf</a>, <a href="/format/2311.04315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Data Perspective on Enhanced Identity Preservation for Diffusion  Personalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xingzhe He</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhiwen Cao</a>, 
<a href="/search/cs?searchtype=author&query=Kolkin%2C+N">Nicholas Kolkin</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lantao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Rhodin%2C+H">Helge Rhodin</a>, 
<a href="/search/cs?searchtype=author&query=Kalarot%2C+R">Ratheesh Kalarot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large text-to-image models have revolutionized the ability to generate
imagery using natural language. However, particularly unique or personal visual
concepts, such as your pet, an object in your house, etc., will not be captured
by the original model. This has led to interest in how to inject new visual
concepts, bound to a new text token, using as few as 4-6 examples. Despite
significant progress, this task remains a formidable challenge, particularly in
preserving the subject's identity. While most researchers attempt to to address
this issue by modifying model architectures, our approach takes a data-centric
perspective, advocating the modification of data rather than the model itself.
We introduce a novel regularization dataset generation strategy on both the
text and image level; demonstrating the importance of a rich and structured
regularization dataset (automatically generated) to prevent losing text
coherence and better identity preservation. The better quality is enabled by
allowing up to 5x more fine-tuning iterations without overfitting and
degeneration. The generated renditions of the desired subject preserve even
fine details such as text and logos; all while maintaining the ability to
generate diverse samples that follow the input text prompt. Since our method
focuses on data augmentation, rather than adjusting the model architecture, it
is complementary and can be combined with prior work. We show on established
benchmarks that our data-centric approach forms the new state of the art in
terms of image quality, with the best trade-off between identity preservation,
diversity, and text alignment.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04319" title="Abstract">arXiv:2311.04319</a> [<a href="/pdf/2311.04319" title="Download PDF">pdf</a>, <a href="/format/2311.04319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On-The-Fly Static Analysis via Dynamic Bidirected Dyck Reachability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krishna%2C+S">Shankaranarayanan Krishna</a>, 
<a href="/search/cs?searchtype=author&query=Lal%2C+A">Aniket Lal</a>, 
<a href="/search/cs?searchtype=author&query=Pavlogiannis%2C+A">Andreas Pavlogiannis</a>, 
<a href="/search/cs?searchtype=author&query=Tuppe%2C+O">Omkar Tuppe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Formal Languages and Automata Theory (cs.FL); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Dyck reachability is a principled, graph-based formulation of a plethora of
static analyses. Bidirected graphs are used for capturing dataflow through
mutable heap data, and are usual formalisms of demand-driven points-to and
alias analyses. The best (offline) algorithm runs in $O(m+n\cdot \alpha(n))$
time, where $n$ is the number of nodes and $m$ is the number of edges in the
flow graph, which becomes $O(n^2)$ in the worst case.
<br />In the everyday practice of program analysis, the analyzed code is subject to
continuous change, with source code being added and removed. On-the-fly static
analysis under such continuous updates gives rise to dynamic Dyck reachability,
where reachability queries run on a dynamically changing graph, following
program updates. Naturally, executing the offline algorithm in this online
setting is inadequate, as the time required to process a single update is
prohibitively large.
<br />In this work we develop a novel dynamic algorithm for bidirected Dyck
reachability that has $O(n\cdot \alpha(n))$ worst-case performance per update,
thus beating the $O(n^2)$ bound, and is also optimal in certain settings. We
also implement our algorithm and evaluate its performance on on-the-fly
data-dependence and alias analyses, and compare it with two best known
alternatives, namely (i) the optimal offline algorithm, and (ii) a fully
dynamic Datalog solver. Our experiments show that our dynamic algorithm is
consistently, and by far, the top performing algorithm, exhibiting speedups in
the order of 1000X. The running time of each update is almost always
unnoticeable to the human eye, making it ideal for the on-the-fly analysis
setting.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04320" title="Abstract">arXiv:2311.04320</a> [<a href="/pdf/2311.04320" title="Download PDF">pdf</a>, <a href="/format/2311.04320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proprioceptive Invariant Robot State Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+T">Tzu-Yuan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tingjun Li</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+W">Wenzhe Tong</a>, 
<a href="/search/cs?searchtype=author&query=Ghaffari%2C+M">Maani Ghaffari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper reports on developing a real-time invariant proprioceptive robot
state estimation framework called DRIFT. A didactic introduction to invariant
Kalman filtering is provided to make this cutting-edge symmetry-preserving
approach accessible to a broader range of robotics applications. Furthermore,
this work dives into the development of a proprioceptive state estimation
framework for dead reckoning that only consumes data from an onboard inertial
measurement unit and kinematics of the robot, with two optional modules, a
contact estimator and a gyro filter for low-cost robots, enabling a significant
capability on a variety of robotics platforms to track the robot's state over
long trajectories in the absence of perceptual data. Extensive real-world
experiments using a legged robot, an indoor wheeled robot, a field robot, and a
full-size vehicle, as well as simulation results with a marine robot, are
provided to understand the limits of DRIFT.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04323" title="Abstract">arXiv:2311.04323</a> [<a href="/pdf/2311.04323" title="Download PDF">pdf</a>, <a href="/format/2311.04323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incident Angle Study for Designing an Endoscopic Tool for Intraoperative  Brain Tumor Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yamamoto%2C+K+Y">Kent Y. Yamamoto</a>, 
<a href="/search/cs?searchtype=author&query=Zachem%2C+T+J">Tanner J. Zachem</a>, 
<a href="/search/cs?searchtype=author&query=Ross%2C+W+A">Weston A. Ross</a>, 
<a href="/search/cs?searchtype=author&query=Codd%2C+P+J">Patrick J. Codd</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in Hamlyn Symposium on Medical Robotics, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In neurosurgical procedures maximizing the resection of tumor tissue while
avoiding healthy tissue is of paramount importance and a difficult task due to
many factors, such as surrounding eloquent brain. Swiftly identifying tumor
tissue for removal could increase surgical outcomes. The TumorID is a
laser-induced fluorescence spectroscopy device that utilizes endogenous
fluorophores such as NADH and FAD to detect tumor regions. With the goal of
creating an endoscopic tool for intraoperative tumor detection in mind, a study
of the TumorID was conducted to assess how the angle of incidence (AoI) affects
the collected spectral response of the scanned tumor. For this study, flat and
convex NADH/FAD gellan gum phantoms were scanned at various AoI (a range of 36
degrees) to observe the spectral behavior. Results showed that spectral
signature did not change significantly across flat and convex phantoms, and the
Area under Curve (AUC) values calculated for each spectrum had a standard
deviation of 0.02 and 0.01 for flat and convex phantoms, respectively.
Therefore, the study showed that AoI will affect the intensity of the spectral
response, but the peaks representative of the endogenous fluorophores are still
observable and similar. Future work includes conducting an AoI study with a
longer working-distance lens, then incorporating said lens to design an
endoscopic, intraoperative tumor detection device for minimally invasive
surgery, with first applications in endonasal endoscopic approaches for
pituitary tumors.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04325" title="Abstract">arXiv:2311.04325</a> [<a href="/pdf/2311.04325" title="Download PDF">pdf</a>, <a href="/format/2311.04325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extending Machine Learning-Based Early Sepsis Detection to Different  Demographics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parmar%2C+S">Surajsinh Parmar</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+T">Tao Shan</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">San Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yonghwan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J+Y">Jang Yong Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">Sepsis requires urgent diagnosis, but research is predominantly focused on
Western datasets. In this study, we perform a comparative analysis of two
ensemble learning methods, LightGBM and XGBoost, using the public eICU-CRD
dataset and a private South Korean St. Mary's Hospital's dataset. Our analysis
reveals the effectiveness of these methods in addressing healthcare data
imbalance and enhancing sepsis detection. Specifically, LightGBM shows a slight
edge in computational efficiency and scalability. The study paves the way for
the broader application of machine learning in critical care, thereby expanding
the reach of predictive analytics in healthcare globally.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04326" title="Abstract">arXiv:2311.04326</a> [<a href="/pdf/2311.04326" title="Download PDF">pdf</a>, <a href="/ps/2311.04326" title="Download PostScript">ps</a>, <a href="/format/2311.04326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Educating for AI Cybersecurity Work and Research: Ethics, Systems  Thinking, and Communication Requirements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Matei%2C+S+A">Sorin Adam Matei</a>, 
<a href="/search/cs?searchtype=author&query=Bertino%2C+E">Elisa Bertino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The present study explored managerial and instructor perceptions of their
freshly employed cybersecurity workers' or students' preparedness to work
effectively in a changing cybersecurity environment that includes AI tools.
Specifically, we related perceptions of technical preparedness to ethical,
systems thinking, and communication skills. We found that managers and
professors perceive preparedness to use AI tools in cybersecurity to be
significantly associated with all three non-technical skill sets. Most
important, ethics is a clear leader in the network of relationships. Contrary
to expectations that ethical concerns are left behind in the rush to adopt the
most advanced AI tools in security, both higher education instructors and
managers appreciate their role and see them closely associated with technical
prowess. Another significant finding is that professors over-estimate students'
preparedness for ethical, system thinking, and communication abilities compared
to IT managers' perceptions of their newly employed IT workers.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04327" title="Abstract">arXiv:2311.04327</a> [<a href="/pdf/2311.04327" title="Download PDF">pdf</a>, <a href="/ps/2311.04327" title="Download PostScript">ps</a>, <a href="/format/2311.04327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Promoting Rural Entrepreneurship through Technology: A Case Study using  Productivity Enhancing Technology Experience Kits (PETE-Kits)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rutherford%2C+M+W">Matthew W. Rutherford</a>, 
<a href="/search/cs?searchtype=author&query=Whitacre%2C+B+E">Brian E. Whitacre</a>, 
<a href="/search/cs?searchtype=author&query=Captain%2C+L">Levi Captain</a>, 
<a href="/search/cs?searchtype=author&query=Ekin%2C+S">Sabit Ekin</a>, 
<a href="/search/cs?searchtype=author&query=Angle%2C+J">Julie Angle</a>, 
<a href="/search/cs?searchtype=author&query=Hensley%2C+T">Tom Hensley</a>, 
<a href="/search/cs?searchtype=author&query=O%27Hara%2C+J+F">John F. O&#x27;Hara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Contribution: Case study of a rural-focused educational program with two
components: 1) introducing high school students and teachers to Smart and
Connected Technologies (SCTs) that can be used to solve local problems; 2)
engaging the local community in supporting local technology-driven
entrepreneurship.
<br />Background: Rural communities typically lag behind in terms of participation
in the digital economy, and use of technology in general. Yet they often have
the most to gain, due to high rates of self-employment and lower private-sector
job opportunities.
<br />Research Questions: Can a broadly-scoped rural technology education program
lead to improvements in 1) student and teacher SCT awareness, 2) SCT skills, 3)
aspirations for future SCT use directed toward entrepreneurship and overall
community wellbeing?
<br />Methodology: Our multidisciplinary team used a mixed-methods approach to
engage a rural high school robotics team as well as the local community. Over
the course of one year, students took part in hands-on-training with SCTs
("PETE-Kits" and associated curriculum) and brainstormed entrepreneurial
projects via ideation events. Community members were involved at the beginning
and end of the project, including judging a "shark-tank" style event where
student business ideas using SCT were presented.
<br />Findings: Results from student pre / post activity assessments suggest that
the program was effective at increasing comfort with technology and combining
technical skills with entrepreneurial opportunities. Post surveys from
community members, including teachers, demonstrated clear support for the
program and an appreciation of how SCTs / digital skills could benefit the
local economy and wellbeing.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04328" title="Abstract">arXiv:2311.04328</a> [<a href="/pdf/2311.04328" title="Download PDF">pdf</a>, <a href="/format/2311.04328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Pilot Study of a Human-Readable Robotic Process Automation Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gago%2C+P">Piotr Gago</a>, 
<a href="/search/cs?searchtype=author&query=Jab%C5%82o%C5%84ski%2C+D">Daniel Jab&#x142;o&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Voitenkova%2C+A">Anna Voitenkova</a>, 
<a href="/search/cs?searchtype=author&query=Debelyi%2C+I">Ihor Debelyi</a>, 
<a href="/search/cs?searchtype=author&query=Skorupska%2C+K">Kinga Skorupska</a>, 
<a href="/search/cs?searchtype=author&query=Grzeszczuk%2C+M">Maciej Grzeszczuk</a>, 
<a href="/search/cs?searchtype=author&query=Kope%C4%87%2C+W">Wies&#x142;aw Kope&#x107;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">In this paper, we explore the usability of a custom eXtensible Robotic
Language (XRL) we proposed. To evaluate the user experience and the interaction
with the potential XRL-based software robot, we conducted an exploratory study
comparing the notation of three business processes using our XRL language and
two languages used by the leading RPA solutions. The results of our exploratory
study show that the currently used XML-based formats perform worse in terms of
conciseness and readability. Our new XRL language is promising in terms of
increasing the readability of the language, thus reducing the time needed to
automate business processes.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04329" title="Abstract">arXiv:2311.04329</a> [<a href="/pdf/2311.04329" title="Download PDF">pdf</a>, <a href="/format/2311.04329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Formal Aspects of Language Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cotterell%2C+R">Ryan Cotterell</a>, 
<a href="/search/cs?searchtype=author&query=Svete%2C+A">Anej Svete</a>, 
<a href="/search/cs?searchtype=author&query=Meister%2C+C">Clara Meister</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+L">Li Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models have become one of the most commonly deployed NLP
inventions. In the past half-decade, their integration into core natural
language processing tools has dramatically increased the performance of such
tools, and they have entered the public discourse surrounding artificial
intelligence. Consequently, it is important for both developers and researchers
alike to understand the mathematical foundations of large language models, as
well as how to implement them. These notes are the accompaniment to the
theoretical portion of the ETH Z\"urich course on large language models,
covering what constitutes a language model from a formal, theoretical
perspective.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04330" title="Abstract">arXiv:2311.04330</a> [<a href="/pdf/2311.04330" title="Download PDF">pdf</a>, <a href="/format/2311.04330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-Free Source Seeking by a Novel Single-Integrator with Attenuating  Oscillations and Better Convergence: Robotic Experiments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bajpai%2C+S">Shivam Bajpai</a>, 
<a href="/search/cs?searchtype=author&query=Elgohary%2C+A+A">Ahmed A. Elgohary</a>, 
<a href="/search/cs?searchtype=author&query=Eisa%2C+S+A">Sameh A. Eisa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">The classic extremum seeking control (ESC) system has been used, including in
experiments, for over a decade as a mean for model-free, real-time method to
steer systems, such as mobile robots, to the source of a scalar physical
distribution (signal) using only local measurements of said signal. This is
referred to in literature as the (source seeking) problem. Similarly,
control-affine ESC systems, which are simpler in structure such as
single-integrator, have been used for source seeking as well; however, they
were rarely experimented on. Both classic ESC and control-affine ESC methods
suffer from persistent oscillations even after the system approaches the source
they are seeking. In this paper, we implement, and verify by novel robotic
experiments, recent results on control-affine ESC, which enable source seeking
with attenuating oscillations. We propose a simple, amended single-integrator
design which we use in our experiments. The experiments were conducted for a
light source seeking problem. Results imply that the proposed design has
significant potential as it also demonstrated much better convergence. We hope
this paper encourages expansion of the proposed design in other fields,
problems and experiments.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04333" title="Abstract">arXiv:2311.04333</a> [<a href="/pdf/2311.04333" title="Download PDF">pdf</a>, <a href="/format/2311.04333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Practical Parallel Algorithms for Near-Optimal Densest Subgraphs on  Massive Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sukprasert%2C+P">Pattara Sukprasert</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q+C">Quanquan C. Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dhulipala%2C+L">Laxman Dhulipala</a>, 
<a href="/search/cs?searchtype=author&query=Shun%2C+J">Julian Shun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in ALENEX 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">The densest subgraph problem has received significant attention, both in
theory and in practice, due to its applications in problems such as community
detection, social network analysis, and spam detection. Due to the high cost of
obtaining exact solutions, much attention has focused on designing approximate
densest subgraph algorithms. However, existing approaches are not able to scale
to massive graphs with billions of edges.
<br />In this paper, we introduce a new framework that combines approximate densest
subgraph algorithms with a pruning optimization. We design new parallel
variants of the state-of-the-art sequential Greedy++ algorithm, and plug it
into our framework in conjunction with a parallel pruning technique based on
$k$-core decomposition to obtain parallel $(1+\varepsilon)$-approximate densest
subgraph algorithms. On a single thread, our algorithms achieve
$2.6$--$34\times$ speedup over Greedy++, and obtain up to $22.37\times$ self
relative parallel speedup on a 30-core machine with two-way hyper-threading.
Compared with the state-of-the-art parallel algorithm by Harb et al.
[NeurIPS'22], we achieve up to a $114\times$ speedup on the same machine.
Finally, against the recent sequential algorithm of Xu et al. [PACMMOD'23], we
achieve up to a $25.9\times$ speedup. The scalability of our algorithms enables
us to obtain near-optimal density statistics on the hyperlink2012 (with roughly
113 billion edges) and clueweb (with roughly 37 billion edges) graphs for the
first time in the literature.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04335" title="Abstract">arXiv:2311.04335</a> [<a href="/pdf/2311.04335" title="Download PDF">pdf</a>, <a href="/format/2311.04335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sub-Sentence Encoder: Contrastive Learning of Propositional Semantic  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sihao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Ben Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenhao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Baolin Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Roth%2C+D">Dan Roth</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dong Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We introduce sub-sentence encoder, a contrastively-learned contextual
embedding model for fine-grained semantic representation of text. In contrast
to the standard practice with sentence embeddings, where the meaning of an
entire sequence of text is encoded into a fixed-length vector, the sub-sentence
encoder learns to produce distinct contextual embeddings corresponding to
different atomic propositions, i.e. atomic units of meaning expressed within a
text sequence. The sub-sentence embeddings are contrastively learned to
recognize (inferred) semantic equivalence between propositions across different
text sequences. Our experiments show the effectiveness of sub-sentence encoders
in applications, such as retrieving supporting facts for fine-grained text
attribution or recognizing the conditional semantic similarity between texts.
In practice, we demonstrate that sub-sentence encoders keep the same level of
inference cost and space complexity compared to sentence encoders.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04336" title="Abstract">arXiv:2311.04336</a> [<a href="/pdf/2311.04336" title="Download PDF">pdf</a>, <a href="/format/2311.04336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Semantic Matching with Hypercolumn Correlation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seungwook Kim</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+J">Juhong Min</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+M">Minsu Cho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WACV 2024. 17 pages including references and supplementary
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent studies show that leveraging the match-wise relationships within the
4D correlation map yields significant improvements in establishing semantic
correspondences - but at the cost of increased computation and latency. In this
work, we focus on the aspect that the performance improvements of recent
methods can also largely be attributed to the usage of multi-scale correlation
maps, which hold various information ranging from low-level geometric cues to
high-level semantic contexts. To this end, we propose HCCNet, an efficient yet
effective semantic matching method which exploits the full potential of
multi-scale correlation maps, while eschewing the reliance on expensive
match-wise relationship mining on the 4D correlation map. Specifically, HCCNet
performs feature slicing on the bottleneck features to yield a richer set of
intermediate features, which are used to construct a hypercolumn correlation.
HCCNet can consequently establish semantic correspondences in an effective
manner by reducing the volume of conventional high-dimensional convolution or
self-attention operations to efficient point-wise convolutions. HCCNet
demonstrates state-of-the-art or competitive performances on the standard
benchmarks of semantic matching, while incurring a notably lower latency and
computation overhead compared to the existing SoTA methods.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04338" title="Abstract">arXiv:2311.04338</a> [<a href="/pdf/2311.04338" title="Download PDF">pdf</a>, <a href="/format/2311.04338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convex Methods for Constrained Linear Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Afsharrad%2C+A">Amirhossein Afsharrad</a>, 
<a href="/search/cs?searchtype=author&query=Moradipari%2C+A">Ahmadreza Moradipari</a>, 
<a href="/search/cs?searchtype=author&query=Lall%2C+S">Sanjay Lall</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Recently, bandit optimization has received significant attention in
real-world safety-critical systems that involve repeated interactions with
humans. While there exist various algorithms with performance guarantees in the
literature, practical implementation of the algorithms has not received as much
attention. This work presents a comprehensive study on the computational
aspects of safe bandit algorithms, specifically safe linear bandits, by
introducing a framework that leverages convex programming tools to create
computationally efficient policies. In particular, we first characterize the
properties of the optimal policy for safe linear bandit problem and then
propose an end-to-end pipeline of safe linear bandit algorithms that only
involves solving convex problems. We also numerically evaluate the performance
of our proposed methods.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04343" title="Abstract">arXiv:2311.04343</a> [<a href="/pdf/2311.04343" title="Download PDF">pdf</a>, <a href="/ps/2311.04343" title="Download PostScript">ps</a>, <a href="/format/2311.04343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Soundbay: Deep Learning Framework for Marine Mammals and Bioacoustic  Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bressler%2C+N">Noam Bressler</a>, 
<a href="/search/cs?searchtype=author&query=Faran%2C+M">Michael Faran</a>, 
<a href="/search/cs?searchtype=author&query=Galor%2C+A">Amit Galor</a>, 
<a href="/search/cs?searchtype=author&query=Michelashvili%2C+M+M">Michael Moshe Michelashvili</a>, 
<a href="/search/cs?searchtype=author&query=Nachshon%2C+T">Tomer Nachshon</a>, 
<a href="/search/cs?searchtype=author&query=Weiss%2C+N">Noa Weiss</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This paper presents Soundbay, an open-source Python framework that allows
bio-acoustics and machine learning researchers to implement and utilize deep
learning-based algorithms for acoustic audio analysis. Soundbay provides an
easy and intuitive platform for applying existing models on one's data or
creating new models effortlessly. One of the main advantages of the framework
is the capability to compare baselines on different benchmarks, a crucial part
of emerging research and development related to the usage of deep-learning
algorithms for animal call analysis. We demonstrate this by providing a
benchmark for cetacean call detection on multiple datasets. The framework is
publicly accessible via https://github.com/deep-voice/soundbay
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04344" title="Abstract">arXiv:2311.04344</a> [<a href="/pdf/2311.04344" title="Download PDF">pdf</a>, <a href="/format/2311.04344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Tradition: Evaluating Agile feasibility in DO-178C for Aerospace  Software Development
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ribeiro%2C+J+E+F">J. Eduardo Ferreira Ribeiro</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+J+G">Jo&#xe3;o Gabriel Silva</a>, 
<a href="/search/cs?searchtype=author&query=Aguiar%2C+A">Ademar Aguiar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper consists of 14 pages and includes 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Domain-specific standards and guidelines play a crucial role in regulating
safety-critical systems, with one notable example being the DO-178C document
for the aerospace industry. This document provides guidelines for organisations
seeking to ensure the safety and certification of their software systems. This
paper analyses the DO-178C document within the context of software development
for safety-critical aerospace systems focusing on Agile software development,
aiming to assess its feasibility. Unlike restricting specific development
methods, DO-178C offers indispensable support that upholds confidence in
safety, aligning seamlessly with the objectives of aerospace industries. Our
analysis reveals that there are no limitations or restrictions within the
DO-178C that inhibit the adoption of Agile and provides guidelines and
objectives for achieving suitable evidence, allowing for various working
methods, including Agile methods, contrary to the overall opinion in the
industry that the traditional waterfall method is mandatory. Additionally, we
emphasise that the guidelines explanation is explicitly tailored to software
professionals using Agile methods, giving it a much more specific focus than
publications that only provide a generic overview of the standard.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04345" title="Abstract">arXiv:2311.04345</a> [<a href="/pdf/2311.04345" title="Download PDF">pdf</a>, <a href="/format/2311.04345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Taxonomy of Rater Disagreements: Surveying Challenges &amp; Opportunities  from the Perspective of Annotating Online Toxicity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenbo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hangzhi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Kivlichan%2C+I+D">Ian D Kivlichan</a>, 
<a href="/search/cs?searchtype=author&query=Prabhakaran%2C+V">Vinodkumar Prabhakaran</a>, 
<a href="/search/cs?searchtype=author&query=Yadav%2C+D">Davis Yadav</a>, 
<a href="/search/cs?searchtype=author&query=Yadav%2C+A">Amulya Yadav</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Toxicity is an increasingly common and severe issue in online spaces.
Consequently, a rich line of machine learning research over the past decade has
focused on computationally detecting and mitigating online toxicity. These
efforts crucially rely on human-annotated datasets that identify toxic content
of various kinds in social media texts. However, such annotations historically
yield low inter-rater agreement, which was often dealt with by taking the
majority vote or other such approaches to arrive at a single ground truth
label. Recent research has pointed out the importance of accounting for the
subjective nature of this task when building and utilizing these datasets, and
this has triggered work on analyzing and better understanding rater
disagreements, and how they could be effectively incorporated into the machine
learning developmental pipeline. While these efforts are filling an important
gap, there is a lack of a broader framework about the root causes of rater
disagreement, and therefore, we situate this work within that broader
landscape. In this survey paper, we analyze a broad set of literature on the
reasons behind rater disagreements focusing on online toxicity, and propose a
detailed taxonomy for the same. Further, we summarize and discuss the potential
solutions targeting each reason for disagreement. We also discuss several open
issues, which could promote the future development of online toxicity research.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04346" title="Abstract">arXiv:2311.04346</a> [<a href="/pdf/2311.04346" title="Download PDF">pdf</a>, <a href="/format/2311.04346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SaFL: Sybil-aware Federated Learning with Application to Face  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghafourian%2C+M">Mahdi Ghafourian</a>, 
<a href="/search/cs?searchtype=author&query=Fierrez%2C+J">Julian Fierrez</a>, 
<a href="/search/cs?searchtype=author&query=Vera-Rodriguez%2C+R">Ruben Vera-Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Tolosana%2C+R">Ruben Tolosana</a>, 
<a href="/search/cs?searchtype=author&query=Morales%2C+A">Aythami Morales</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Federated Learning (FL) is a machine learning paradigm to conduct
collaborative learning among clients on a joint model. The primary goal is to
share clients' local training parameters with an integrating server while
preserving their privacy. This method permits to exploit the potential of
massive mobile users' data for the benefit of machine learning models'
performance while keeping sensitive data on local devices. On the downside, FL
raises security and privacy concerns that have just started to be studied. To
address some of the key threats in FL, researchers have proposed to use secure
aggregation methods (e.g. homomorphic encryption, secure multiparty
computation, etc.). These solutions improve some security and privacy metrics,
but at the same time bring about other serious threats such as poisoning
attacks, backdoor attacks, and free running attacks. This paper proposes a new
defense method against poisoning attacks in FL called SaFL (Sybil-aware
Federated Learning) that minimizes the effect of sybils with a novel
time-variant aggregation scheme.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04348" title="Abstract">arXiv:2311.04348</a> [<a href="/pdf/2311.04348" title="Download PDF">pdf</a>, <a href="/format/2311.04348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the Effectiveness of Retrieval-Augmented Large Language  Models in Scientific Document Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Munikoti%2C+S">Sai Munikoti</a>, 
<a href="/search/cs?searchtype=author&query=Acharya%2C+A">Anurag Acharya</a>, 
<a href="/search/cs?searchtype=author&query=Wagle%2C+S">Sridevi Wagle</a>, 
<a href="/search/cs?searchtype=author&query=Horawalavithana%2C+S">Sameera Horawalavithana</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Despite the dramatic progress in Large Language Model (LLM) development, LLMs
often provide seemingly plausible but not factual information, often referred
to as hallucinations. Retrieval-augmented LLMs provide a non-parametric
approach to solve these issues by retrieving relevant information from external
data sources and augment the training process. These models help to trace
evidence from an externally provided knowledge base allowing the model
predictions to be better interpreted and verified. In this work, we critically
evaluate these models in their ability to perform in scientific document
reasoning tasks. To this end, we tuned multiple such model variants with
science-focused instructions and evaluated them on a scientific document
reasoning benchmark for the usefulness of the retrieved document passages. Our
findings suggest that models justify predictions in science tasks with
fabricated evidence and leveraging scientific corpus as pretraining data does
not alleviate the risk of evidence fabrication.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04350" title="Abstract">arXiv:2311.04350</a> [<a href="/pdf/2311.04350" title="Download PDF">pdf</a>, <a href="/format/2311.04350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Device Sampling and Resource Optimization for Federated Learning in  Cooperative Edge Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Su Wang</a>, 
<a href="/search/cs?searchtype=author&query=Morabito%2C+R">Roberto Morabito</a>, 
<a href="/search/cs?searchtype=author&query=Hosseinalipour%2C+S">Seyyedali Hosseinalipour</a>, 
<a href="/search/cs?searchtype=author&query=Chiang%2C+M">Mung Chiang</a>, 
<a href="/search/cs?searchtype=author&query=Brinton%2C+C+G">Christopher G. Brinton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE/ACM Transactions on Networking. arXiv admin note: substantial text overlap with <a href="/abs/2101.00787">arXiv:2101.00787</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
<p class="mathjax">The conventional federated learning (FedL) architecture distributes machine
learning (ML) across worker devices by having them train local models that are
periodically aggregated by a server. FedL ignores two important characteristics
of contemporary wireless networks, however: (i) the network may contain
heterogeneous communication/computation resources, and (ii) there may be
significant overlaps in devices' local data distributions. In this work, we
develop a novel optimization methodology that jointly accounts for these
factors via intelligent device sampling complemented by device-to-device (D2D)
offloading. Our optimization methodology aims to select the best combination of
sampled nodes and data offloading configuration to maximize FedL training
accuracy while minimizing data processing and D2D communication resource
consumption subject to realistic constraints on the network topology and device
capabilities. Theoretical analysis of the D2D offloading subproblem leads to
new FedL convergence bounds and an efficient sequential convex optimizer. Using
these results, we develop a sampling methodology based on graph convolutional
networks (GCNs) which learns the relationship between network attributes,
sampled nodes, and D2D data offloading to maximize FedL accuracy. Through
evaluation on popular datasets and real-world network measurements from our
edge testbed, we find that our methodology outperforms popular device sampling
methodologies from literature in terms of ML model performance, data processing
overhead, and energy consumption.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04351" title="Abstract">arXiv:2311.04351</a> [<a href="/pdf/2311.04351" title="Download PDF">pdf</a>, <a href="/ps/2311.04351" title="Download PostScript">ps</a>, <a href="/format/2311.04351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Deep Learning Approach to Video Anomaly Detection using Convolutional  Autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pavuluri%2C+G">Gopikrishna Pavuluri</a>, 
<a href="/search/cs?searchtype=author&query=Annem%2C+G">Gayathri Annem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 Pages,2 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this research we propose a deep learning approach for detecting anomalies
in videos using convolutional autoencoder and decoder neural networks on the
UCSD dataset.Our method utilizes a convolutional autoencoder to learn the
spatiotemporal patterns of normal videos and then compares each frame of a test
video to this learned representation. We evaluated our approach on the UCSD
dataset and achieved an overall accuracy of 99.35% on the Ped1 dataset and
99.77% on the Ped2 dataset, demonstrating the effectiveness of our method for
detecting anomalies in surveillance videos. The results show that our method
outperforms other state-of-the-art methods, and it can be used in real-world
applications for video anomaly detection.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04354" title="Abstract">arXiv:2311.04354</a> [<a href="/pdf/2311.04354" title="Download PDF">pdf</a>, <a href="/format/2311.04354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncovering Causal Variables in Transformers using Circuit Probing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lepori%2C+M+A">Michael A. Lepori</a>, 
<a href="/search/cs?searchtype=author&query=Serre%2C+T">Thomas Serre</a>, 
<a href="/search/cs?searchtype=author&query=Pavlick%2C+E">Ellie Pavlick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Neural network models have achieved high performance on a wide variety of
complex tasks, but the algorithms that they implement are notoriously difficult
to interpret. In order to understand these algorithms, it is often necessary to
hypothesize intermediate variables involved in the network's computation. For
example, does a language model depend on particular syntactic properties when
generating a sentence? However, existing analysis tools make it difficult to
test hypotheses of this type. We propose a new analysis technique -- circuit
probing -- that automatically uncovers low-level circuits that compute
hypothesized intermediate variables. This enables causal analysis through
targeted ablation at the level of model parameters. We apply this method to
models trained on simple arithmetic tasks, demonstrating its effectiveness at
(1) deciphering the algorithms that models have learned, (2) revealing modular
structure within a model, and (3) tracking the development of circuits over
training. We compare circuit probing to other methods across these three
experiments, and find it on par or more effective than existing analysis
methods. Finally, we demonstrate circuit probing on a real-world use case,
uncovering circuits that are responsible for subject-verb agreement and
reflexive anaphora in GPT2-Small and Medium.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04362" title="Abstract">arXiv:2311.04362</a> [<a href="/pdf/2311.04362" title="Download PDF">pdf</a>, <a href="/format/2311.04362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast and forward stable randomized algorithms for linear least-squares  problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Epperly%2C+E+N">Ethan N. Epperly</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Iterative sketching and sketch-and-precondition are randomized algorithms
used for solving overdetermined linear least-squares problems. When implemented
in exact arithmetic, these algorithms produce high-accuracy solutions to
least-squares problems faster than standard direct methods based on QR
factorization. Recently, Meier, Nakatsukasa, Townsend, and Webb demonstrated
numerical instabilities in a version of sketch-and-precondition in floating
point arithmetic (<a href="/abs/2302.07202">arXiv:2302.07202</a>). The work of Meier et al. raises the
question: Is there a randomized least-squares solver that is both fast and
stable? This paper resolves this question in the affirmative by proving that
iterative sketching, appropriately implemented, is forward stable. Numerical
experiments confirm the theoretical findings, demonstrating that iterative
sketching is stable and faster than QR-based solvers for large problem
instances.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04364" title="Abstract">arXiv:2311.04364</a> [<a href="/pdf/2311.04364" title="Download PDF">pdf</a>, <a href="/format/2311.04364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Syntax-Guided Transformers: Elevating Compositional Generalization and  Grounding in Multimodal Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kamali%2C+D">Danial Kamali</a>, 
<a href="/search/cs?searchtype=author&query=Kordjamshidi%2C+P">Parisa Kordjamshidi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Compositional generalization, the ability of intelligent models to
extrapolate understanding of components to novel compositions, is a fundamental
yet challenging facet in AI research, especially within multimodal
environments. In this work, we address this challenge by exploiting the
syntactic structure of language to boost compositional generalization. This
paper elevates the importance of syntactic grounding, particularly through
attention masking techniques derived from text input parsing. We introduce and
evaluate the merits of using syntactic information in the multimodal grounding
problem. Our results on grounded compositional generalization underscore the
positive impact of dependency parsing across diverse tasks when utilized with
Weight Sharing across the Transformer encoder. The results push the
state-of-the-art in multimodal grounding and parameter-efficient modeling and
provide insights for future research.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04368" title="Abstract">arXiv:2311.04368</a> [<a href="/pdf/2311.04368" title="Download PDF">pdf</a>, <a href="/ps/2311.04368" title="Download PostScript">ps</a>, <a href="/format/2311.04368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating multiple large language models in pediatric ophthalmology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Holmes%2C+J">Jason Holmes</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+R">Rui Peng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jinyu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zihao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Huan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Hong Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">Jie Zou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Y">Yi Shao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">IMPORTANCE The response effectiveness of different large language models
(LLMs) and various individuals, including medical students, graduate students,
and practicing physicians, in pediatric ophthalmology consultations, has not
been clearly established yet. OBJECTIVE Design a 100-question exam based on
pediatric ophthalmology to evaluate the performance of LLMs in highly
specialized scenarios and compare them with the performance of medical students
and physicians at different levels. DESIGN, SETTING, AND PARTICIPANTS This
survey study assessed three LLMs, namely ChatGPT (GPT-3.5), GPT-4, and PaLM2,
were assessed alongside three human cohorts: medical students, postgraduate
students, and attending physicians, in their ability to answer questions
related to pediatric ophthalmology. It was conducted by administering
questionnaires in the form of test papers through the LLM network interface,
with the valuable participation of volunteers. MAIN OUTCOMES AND MEASURES Mean
scores of LLM and humans on 100 multiple-choice questions, as well as the
answer stability, correlation, and response confidence of each LLM. RESULTS
GPT-4 performed comparably to attending physicians, while ChatGPT (GPT-3.5) and
PaLM2 outperformed medical students but slightly trailed behind postgraduate
students. Furthermore, GPT-4 exhibited greater stability and confidence when
responding to inquiries compared to ChatGPT (GPT-3.5) and PaLM2. CONCLUSIONS
AND RELEVANCE Our results underscore the potential for LLMs to provide medical
assistance in pediatric ophthalmology and suggest significant capacity to guide
the education of medical students.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04371" title="Abstract">arXiv:2311.04371</a> [<a href="/pdf/2311.04371" title="Download PDF">pdf</a>, <a href="/ps/2311.04371" title="Download PostScript">ps</a>, <a href="/format/2311.04371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Charles Babbage invented the Computer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rojas%2C+R">Raul Rojas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Numerical Analysis (math.NA); History and Philosophy of Physics (physics.hist-ph)

</div>
<p class="mathjax">This paper provides an overview of the successive stages in the development
of Charles Babbage's Analytical Engine, based on the blueprints held in the
Babbage Papers Archive, accessible online through the Science Museum in London.
The first person to decipher these schematics was Allan Bromley, whose
contributions in the 1980s and 1990s significantly advanced our understanding
of Babbage's pioneering work. The Science Museum's digitization of the Babbage
Papers enables a chronological exploration of the evolution of Babbage's
machines. The focus is on the Analytical Engine, shedding light on its lesser
known but crucial transitional phases.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04372" title="Abstract">arXiv:2311.04372</a> [<a href="/pdf/2311.04372" title="Download PDF">pdf</a>, <a href="/ps/2311.04372" title="Download PostScript">ps</a>, <a href="/format/2311.04372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Malware Detection by Integrating Machine Learning with Cuckoo  Sandbox
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alshmarni%2C+A+F">Amaal F. Alshmarni</a>, 
<a href="/search/cs?searchtype=author&query=Alliheedi%2C+M+A">Mohammed A. Alliheedi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">In the modern era, malware is experiencing a significant increase in both its
variety and quantity, aligning with the widespread adoption of the digital
world. This surge in malware has emerged as a critical challenge in the realm
of cybersecurity, prompting numerous research endeavors and contributions to
address the issue. Machine learning algorithms have been leveraged for malware
detection due to their ability to uncover concealed patterns within vast
datasets. However, deep learning algorithms, characterized by their
multi-layered structure, surpass the limitations of traditional machine
learning approaches. By employing deep learning techniques such as CNN
(Convolutional Neural Network) and RNN (Recurrent Neural Network), this study
aims to classify and identify malware extracted from a dataset containing API
call sequences. The performance of these algorithms is compared with that of
conventional machine learning methods, including SVM (Support Vector Machine),
RF (Random Forest), KNN (K-Nearest Neighbors), XGB (Extreme Gradient Boosting),
and GBC (Gradient Boosting Classifier), all using the same dataset. The
outcomes of this research demonstrate that both deep learning and machine
learning algorithms achieve remarkably high levels of accuracy, reaching up to
99% in certain cases.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04373" title="Abstract">arXiv:2311.04373</a> [<a href="/pdf/2311.04373" title="Download PDF">pdf</a>, <a href="/format/2311.04373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Review of Leap Motion Controller-based Hand Gesture  Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chakravarthi%2C+B">Bharatesh Chakravarthi</a>, 
<a href="/search/cs?searchtype=author&query=M%2C+P+P+B">Prabhu Prasad B M</a>, 
<a href="/search/cs?searchtype=author&query=N%2C+P+K+B">Pavan Kumar B N</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">This paper comprehensively reviews hand gesture datasets based on Ultraleap's
leap motion controller, a popular device for capturing and tracking hand
gestures in real-time. The aim is to offer researchers and practitioners a
valuable resource for developing and evaluating gesture recognition algorithms.
The review compares various datasets found in the literature, considering
factors such as target domain, dataset size, gesture diversity, subject
numbers, and data modality. The strengths and limitations of each dataset are
discussed, along with the applications and research areas in which they have
been utilized. An experimental evaluation of the leap motion controller 2
device is conducted to assess its capabilities in generating gesture data for
various applications, specifically focusing on touchless interactive systems
and virtual reality. This review serves as a roadmap for researchers, aiding
them in selecting appropriate datasets for their specific gesture recognition
tasks and advancing the field of hand gesture recognition using leap motion
controller technology.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04375" title="Abstract">arXiv:2311.04375</a> [<a href="/pdf/2311.04375" title="Download PDF">pdf</a>, <a href="/ps/2311.04375" title="Download PostScript">ps</a>, <a href="/format/2311.04375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Experiment Design under Distributed Differential Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei-Ning Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cormode%2C+G">Graham Cormode</a>, 
<a href="/search/cs?searchtype=author&query=Bharadwaj%2C+A">Akash Bharadwaj</a>, 
<a href="/search/cs?searchtype=author&query=Romov%2C+P">Peter Romov</a>, 
<a href="/search/cs?searchtype=author&query=%C3%96zg%C3%BCr%2C+A">Ayfer &#xd6;zg&#xfc;r</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Applications (stat.AP)

</div>
<p class="mathjax">Experiment design has a rich history dating back over a century and has found
many critical applications across various fields since then. The use and
collection of users' data in experiments often involve sensitive personal
information, so additional measures to protect individual privacy are required
during data collection, storage, and usage. In this work, we focus on the
rigorous protection of users' privacy (under the notion of differential privacy
(DP)) while minimizing the trust toward service providers. Specifically, we
consider the estimation of the average treatment effect (ATE) under DP, while
only allowing the analyst to collect population-level statistics via secure
aggregation, a distributed protocol enabling a service provider to aggregate
information without accessing individual data. Although a vital component in
modern A/B testing workflows, private distributed experimentation has not
previously been studied. To achieve DP, we design local privatization
mechanisms that are compatible with secure aggregation and analyze the utility,
in terms of the width of confidence intervals, both asymptotically and
non-asymptotically. We show how these mechanisms can be scaled up to handle the
very large number of participants commonly found in practice. In addition, when
introducing DP noise, it is imperative to cleverly split privacy budgets to
estimate both the mean and variance of the outcomes and carefully calibrate the
confidence intervals according to the DP noise. Last, we present comprehensive
experimental evaluations of our proposed schemes and show the privacy-utility
trade-offs in experiment design.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04378" title="Abstract">arXiv:2311.04378</a> [<a href="/pdf/2311.04378" title="Download PDF">pdf</a>, <a href="/format/2311.04378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Watermarks in the Sand: Impossibility of Strong Watermarking for  Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanlin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Edelman%2C+B+L">Benjamin L. Edelman</a>, 
<a href="/search/cs?searchtype=author&query=Francati%2C+D">Danilo Francati</a>, 
<a href="/search/cs?searchtype=author&query=Venturi%2C+D">Daniele Venturi</a>, 
<a href="/search/cs?searchtype=author&query=Ateniese%2C+G">Giuseppe Ateniese</a>, 
<a href="/search/cs?searchtype=author&query=Barak%2C+B">Boaz Barak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Watermarking generative models consists of planting a statistical signal
(watermark) in a model's output so that it can be later verified that the
output was generated by the given model. A strong watermarking scheme satisfies
the property that a computationally bounded attacker cannot erase the watermark
without causing significant quality degradation. In this paper, we study the
(im)possibility of strong watermarking schemes. We prove that, under
well-specified and natural assumptions, strong watermarking is impossible to
achieve. This holds even in the private detection algorithm setting, where the
watermark insertion and detection algorithms share a secret key, unknown to the
attacker. To prove this result, we introduce a generic efficient watermark
attack; the attacker is not required to know the private key of the scheme or
even which scheme is used. Our attack is based on two assumptions: (1) The
attacker has access to a "quality oracle" that can evaluate whether a candidate
output is a high-quality response to a prompt, and (2) The attacker has access
to a "perturbation oracle" which can modify an output with a nontrivial
probability of maintaining quality, and which induces an efficiently mixing
random walk on high-quality outputs. We argue that both assumptions can be
satisfied in practice by an attacker with weaker computational capabilities
than the watermarked model itself, to which the attacker has only black-box
access. Furthermore, our assumptions will likely only be easier to satisfy over
time as models grow in capabilities and modalities. We demonstrate the
feasibility of our attack by instantiating it to attack three existing
watermarking schemes for large language models: Kirchenbauer et al. (2023),
Kuditipudi et al. (2023), and Zhao et al. (2023). The same attack successfully
removes the watermarks planted by all three schemes, with only minor quality
degradation.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04380" title="Abstract">arXiv:2311.04380</a> [<a href="/pdf/2311.04380" title="Download PDF">pdf</a>, <a href="/format/2311.04380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open RAN xApps Design and Evaluation: Lessons Learnt and Identified  Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoffmann%2C+M">Marcin Hoffmann</a>, 
<a href="/search/cs?searchtype=author&query=Janji%2C+S">Salim Janji</a>, 
<a href="/search/cs?searchtype=author&query=Samorzewski%2C+A">Adam Samorzewski</a>, 
<a href="/search/cs?searchtype=author&query=Kulacz%2C+L">Lukasz Kulacz</a>, 
<a href="/search/cs?searchtype=author&query=Adamczyk%2C+C">Cezary Adamczyk</a>, 
<a href="/search/cs?searchtype=author&query=Dryja%C5%84ski%2C+M">Marcin Dryja&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Kryszkiewicz%2C+P">Pawel Kryszkiewicz</a>, 
<a href="/search/cs?searchtype=author&query=Kliks%2C+A">Adrian Kliks</a>, 
<a href="/search/cs?searchtype=author&query=Bogucka%2C+H">Hanna Bogucka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in IEEE Journal on Selected Areas in Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Open Radio Access Networks (RAN) offer diverse economic opportunities. A
transition to a flexible, modular approach within the disaggregated RAN
framework is crucial, involving careful planning of RAN architecture and the
deployment of specialized software applications. Collaboration across sectors
is essential for efficiency and reliability, with the open-source community
driving innovation. This paper explores challenges for third-party application
developers in Open RAN. It provides a comparative analysis of solutions,
focusing on xApp development and implementation. Challenges arise in two areas:
the complexities of xApp development, particularly for advanced use cases like
beam management, and issues in low-level software implementation within open
platforms. In conclusion, key challenges must promote academia-industry
collaboration in Open RAN. This paper shares early lessons from xApp
development, guiding the field's evolution.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04382" title="Abstract">arXiv:2311.04382</a> [<a href="/pdf/2311.04382" title="Download PDF">pdf</a>, <a href="/format/2311.04382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Basis restricted elastic shape analysis on the space of unregistered  surfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hartman%2C+E">Emmanuel Hartman</a>, 
<a href="/search/cs?searchtype=author&query=Pierson%2C+E">Emery Pierson</a>, 
<a href="/search/cs?searchtype=author&query=Bauer%2C+M">Martin Bauer</a>, 
<a href="/search/cs?searchtype=author&query=Daoudi%2C+M">Mohamed Daoudi</a>, 
<a href="/search/cs?searchtype=author&query=Charon%2C+N">Nicolas Charon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 10 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Differential Geometry (math.DG)

</div>
<p class="mathjax">This paper introduces a new mathematical and numerical framework for surface
analysis derived from the general setting of elastic Riemannian metrics on
shape spaces. Traditionally, those metrics are defined over the infinite
dimensional manifold of immersed surfaces and satisfy specific invariance
properties enabling the comparison of surfaces modulo shape preserving
transformations such as reparametrizations. The specificity of the approach we
develop is to restrict the space of allowable transformations to predefined
finite dimensional bases of deformation fields. These are estimated in a
data-driven way so as to emulate specific types of surface transformations
observed in a training set. The use of such bases allows to simplify the
representation of the corresponding shape space to a finite dimensional latent
space. However, in sharp contrast with methods involving e.g. mesh
autoencoders, the latent space is here equipped with a non-Euclidean Riemannian
metric precisely inherited from the family of aforementioned elastic metrics.
We demonstrate how this basis restricted model can be then effectively
implemented to perform a variety of tasks on surface meshes which, importantly,
does not assume these to be pre-registered (i.e. with given point
correspondences) or to even have a consistent mesh structure. We specifically
validate our approach on human body shape and pose data as well as human face
scans, and show how it generally outperforms state-of-the-art methods on
problems such as shape registration, interpolation, motion transfer or random
pose generation.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04383" title="Abstract">arXiv:2311.04383</a> [<a href="/pdf/2311.04383" title="Download PDF">pdf</a>, <a href="/format/2311.04383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Collision Avoidance System for E-Scooters in Pedestrian  Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xuke Yan</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+D">Dan Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to SAE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In the dense fabric of urban areas, electric scooters have rapidly become a
preferred mode of transportation. As they cater to modern mobility demands,
they present significant safety challenges, especially when interacting with
pedestrians. In general, e-scooters are suggested to be ridden in bike
lanes/sidewalks or share the road with cars at the maximum speed of about 15-20
mph, which is more flexible and much faster than pedestrians and bicyclists.
Accurate prediction of pedestrian movement, coupled with assistant motion
control of scooters, is essential in minimizing collision risks and seamlessly
integrating scooters in areas dense with pedestrians. Addressing these safety
concerns, our research introduces a novel e-Scooter collision avoidance system
(eCAS) with a method for predicting pedestrian trajectories, employing an
advanced LSTM network integrated with a state refinement module. This proactive
model is designed to ensure unobstructed movement in areas with substantial
pedestrian traffic without collisions. Results are validated on two public
datasets, ETH and UCY, providing encouraging outcomes. Our model demonstrated
proficiency in anticipating pedestrian paths and augmented scooter path
planning, allowing for heightened adaptability in densely populated locales.
This study shows the potential of melding pedestrian trajectory prediction with
scooter motion planning. With the ubiquity of electric scooters in urban
environments, such advancements have become crucial to safeguard all
participants in urban transit.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04386" title="Abstract">arXiv:2311.04386</a> [<a href="/pdf/2311.04386" title="Download PDF">pdf</a>, <a href="/format/2311.04386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing Manycore Processors with Distributed Memory for Accelerated  Training of Sparse and Recurrent Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Finkbeiner%2C+J">Jan Finkbeiner</a>, 
<a href="/search/cs?searchtype=author&query=Gmeinder%2C+T">Thomas Gmeinder</a>, 
<a href="/search/cs?searchtype=author&query=Pupilli%2C+M">Mark Pupilli</a>, 
<a href="/search/cs?searchtype=author&query=Titterton%2C+A">Alexander Titterton</a>, 
<a href="/search/cs?searchtype=author&query=Neftci%2C+E">Emre Neftci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Current AI training infrastructure is dominated by single instruction
multiple data (SIMD) and systolic array architectures, such as Graphics
Processing Units (GPUs) and Tensor Processing Units (TPUs), that excel at
accelerating parallel workloads and dense vector matrix multiplications.
Potentially more efficient neural network models utilizing sparsity and
recurrence cannot leverage the full power of SIMD processor and are thus at a
severe disadvantage compared to today's prominent parallel architectures like
Transformers and CNNs, thereby hindering the path towards more sustainable AI.
To overcome this limitation, we explore sparse and recurrent model training on
a massively parallel multiple instruction multiple data (MIMD) architecture
with distributed local memory. We implement a training routine based on
backpropagation through time (BPTT) for the brain-inspired class of Spiking
Neural Networks (SNNs) that feature binary sparse activations. We observe a
massive advantage in using sparse activation tensors with a MIMD processor, the
Intelligence Processing Unit (IPU) compared to GPUs. On training workloads, our
results demonstrate 5-10x throughput gains compared to A100 GPUs and up to 38x
gains for higher levels of activation sparsity, without a significant slowdown
in training convergence or reduction in final model performance. Furthermore,
our results show highly promising trends for both single and multi IPU
configurations as we scale up to larger model sizes. Our work paves the way
towards more efficient, non-standard models via AI training hardware beyond
GPUs, and competitive large scale SNN models.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04389" title="Abstract">arXiv:2311.04389</a> [<a href="/pdf/2311.04389" title="Download PDF">pdf</a>, <a href="/format/2311.04389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structural Balance of Complex Weighted Graphs and Multi-partite  Consensus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wu%2C+H">Honghui Wu</a>, 
<a href="/search/eess?searchtype=author&query=Koru%2C+A+T">Ahmet Taha Koru</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+G">Guanxuan Wu</a>, 
<a href="/search/eess?searchtype=author&query=Lewis%2C+F+L">Frank L. Lewis</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+H">Hai Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The structural balance of a signed graph is known to be necessary and
sufficient to obtain a bipartite consensus among agents with friend-foe
relationships. In the real world, relationships are multifarious, and the
coexistence of different opinions is ubiquitous. We are therefore motivated to
study the multi-partite consensus problem of multi-agent systems, for which we
extend the concept of structural balance to graphs with complex edge weights.
It is shown that the generalized structural balance property is necessary and
sufficient for achieving multi-partite consensus.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04390" title="Abstract">arXiv:2311.04390</a> [<a href="/pdf/2311.04390" title="Download PDF">pdf</a>, <a href="/format/2311.04390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Force-Constrained Visual Policy: Safe Robot-Assisted Dressing via  Multi-Modal Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhanyi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yufei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Held%2C+D">David Held</a>, 
<a href="/search/cs?searchtype=author&query=Erickson%2C+Z">Zackory Erickson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Robot-assisted dressing could profoundly enhance the quality of life of
adults with physical disabilities. To achieve this, a robot can benefit from
both visual and force sensing. The former enables the robot to ascertain human
body pose and garment deformations, while the latter helps maintain safety and
comfort during the dressing process. In this paper, we introduce a new
technique that leverages both vision and force modalities for this assistive
task. Our approach first trains a vision-based dressing policy using
reinforcement learning in simulation with varying body sizes, poses, and types
of garments. We then learn a force dynamics model for action planning to ensure
safety. Due to limitations of simulating accurate force data when deformable
garments interact with the human body, we learn a force dynamics model directly
from real-world data. Our proposed method combines the vision-based policy,
trained in simulation, with the force dynamics model, learned in the real
world, by solving a constrained optimization problem to infer actions that
facilitate the dressing process without applying excessive force on the person.
We evaluate our system in simulation and in a real-world human study with 10
participants across 240 dressing trials, showing it greatly outperforms prior
baselines. Video demonstrations are available on our project
website\footnote{\url{https://sites.google.com/view/dressing-fcvp}}.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04391" title="Abstract">arXiv:2311.04391</a> [<a href="/pdf/2311.04391" title="Download PDF">pdf</a>, <a href="/format/2311.04391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3DiffTection: 3D Object Detection with Geometry-Aware Diffusion Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chenfeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+H">Huan Ling</a>, 
<a href="/search/cs?searchtype=author&query=Fidler%2C+S">Sanja Fidler</a>, 
<a href="/search/cs?searchtype=author&query=Litany%2C+O">Or Litany</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: \url{<a href="https://research.nvidia.com/labs/toronto-ai/3difftection/">this https URL</a>}
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present 3DiffTection, a state-of-the-art method for 3D object detection
from single images, leveraging features from a 3D-aware diffusion model.
Annotating large-scale image data for 3D detection is resource-intensive and
time-consuming. Recently, pretrained large image diffusion models have become
prominent as effective feature extractors for 2D perception tasks. However,
these features are initially trained on paired text and image data, which are
not optimized for 3D tasks, and often exhibit a domain gap when applied to the
target data. Our approach bridges these gaps through two specialized tuning
strategies: geometric and semantic. For geometric tuning, we fine-tune a
diffusion model to perform novel view synthesis conditioned on a single image,
by introducing a novel epipolar warp operator. This task meets two essential
criteria: the necessity for 3D awareness and reliance solely on posed image
data, which are readily available (e.g., from videos) and does not require
manual annotation. For semantic refinement, we further train the model on
target data with detection supervision. Both tuning phases employ ControlNet to
preserve the integrity of the original feature capabilities. In the final step,
we harness these enhanced capabilities to conduct a test-time prediction
ensemble across multiple virtual viewpoints. Through our methodology, we obtain
3D-aware features that are tailored for 3D detection and excel in identifying
cross-view point correspondences. Consequently, our model emerges as a powerful
3D detector, substantially surpassing previous benchmarks, e.g., Cube-RCNN, a
precedent in single-view 3D detection by 9.43\% in AP3D on the
Omni3D-ARkitscene dataset. Furthermore, 3DiffTection showcases robust data
efficiency and generalization to cross-domain data.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04397" title="Abstract">arXiv:2311.04397</a> [<a href="/pdf/2311.04397" title="Download PDF">pdf</a>, <a href="/format/2311.04397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ToP-ToM: Trust-aware Robot Policy with Theory of Mind
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chuang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Serhan%2C+B">Baris Serhan</a>, 
<a href="/search/cs?searchtype=author&query=Cangelosi%2C+A">Angelo Cangelosi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Theory of Mind (ToM) is a fundamental cognitive architecture that endows
humans with the ability to attribute mental states to others. Humans infer the
desires, beliefs, and intentions of others by observing their behavior and, in
turn, adjust their actions to facilitate better interpersonal communication and
team collaboration. In this paper, we investigated trust-aware robot policy
with the theory of mind in a multiagent setting where a human collaborates with
a robot against another human opponent. We show that by only focusing on team
performance, the robot may resort to the reverse psychology trick, which poses
a significant threat to trust maintenance. The human's trust in the robot will
collapse when they discover deceptive behavior by the robot. To mitigate this
problem, we adopt the robot theory of mind model to infer the human's trust
beliefs, including true belief and false belief (an essential element of ToM).
We designed a dynamic trust-aware reward function based on different trust
beliefs to guide the robot policy learning, which aims to balance between
avoiding human trust collapse due to robot reverse psychology. The experimental
results demonstrate the importance of the ToM-based robot policy for
human-robot trust and the effectiveness of our robot ToM-based robot policy in
multiagent interaction settings.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04398" title="Abstract">arXiv:2311.04398</a> [<a href="/pdf/2311.04398" title="Download PDF">pdf</a>, <a href="/format/2311.04398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Role and Design Space of Demand Sinks in Low-carbon  Power Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=van+der+Jagt%2C+S">Sam van der Jagt</a>, 
<a href="/search/eess?searchtype=author&query=Patankar%2C+N">Neha Patankar</a>, 
<a href="/search/eess?searchtype=author&query=Jenkins%2C+J">Jesse Jenkins</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">As the availability of weather-dependent, zero marginal cost resources such
as wind and solar power increases, a variety of flexible electricity loads, or
`demand sinks', could be deployed to use intermittently available low-cost
electricity to produce valuable outputs. This study provides a general
framework to evaluate any potential demand sink technology and understand its
viability to be deployed cost-effectively in low-carbon power systems. We use
an electricity system optimization model to assess 98 discrete combinations of
capital costs and output values that collectively span the range of feasible
characteristics of potential demand sink technologies. We find that candidates
like hydrogen electrolysis, direct air capture, and flexible electric heating
can all achieve significant installed capacity (&gt;10% of system peak load) if
lower capital costs are reached in the future. Demand sink technologies
significantly increase installed wind and solar capacity while not
significantly affecting battery storage, firm generating capacity, or the
average cost of electricity.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04400" title="Abstract">arXiv:2311.04400</a> [<a href="/pdf/2311.04400" title="Download PDF">pdf</a>, <a href="/format/2311.04400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LRM: Large Reconstruction Model for Single Image to 3D
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+Y">Yicong Hong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jiuxiang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+S">Sai Bi</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Difan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Feng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sunkavalli%2C+K">Kalyan Sunkavalli</a>, 
<a href="/search/cs?searchtype=author&query=Bui%2C+T">Trung Bui</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+H">Hao Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose the first Large Reconstruction Model (LRM) that predicts the 3D
model of an object from a single input image within just 5 seconds. In contrast
to many previous methods that are trained on small-scale datasets such as
ShapeNet in a category-specific fashion, LRM adopts a highly scalable
transformer-based architecture with 500 million learnable parameters to
directly predict a neural radiance field (NeRF) from the input image. We train
our model in an end-to-end manner on massive multi-view data containing around
1 million objects, including both synthetic renderings from Objaverse and real
captures from MVImgNet. This combination of a high-capacity model and
large-scale training data empowers our model to be highly generalizable and
produce high-quality 3D reconstructions from various testing inputs including
real-world in-the-wild captures and images from generative models. Video demos
and interactable 3D meshes can be found on this website:
https://yiconghong.me/LRM/.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04402" title="Abstract">arXiv:2311.04402</a> [<a href="/pdf/2311.04402" title="Download PDF">pdf</a>, <a href="/format/2311.04402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Likelihood Ratio Confidence Sets for Sequential Decision Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Emmenegger%2C+N">Nicolas Emmenegger</a>, 
<a href="/search/cs?searchtype=author&query=Mutn%C3%BD%2C+M">Mojm&#xed;r Mutn&#xfd;</a>, 
<a href="/search/cs?searchtype=author&query=Krause%2C+A">Andreas Krause</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Certifiable, adaptive uncertainty estimates for unknown quantities are an
essential ingredient of sequential decision-making algorithms. Standard
approaches rely on problem-dependent concentration results and are limited to a
specific combination of parameterization, noise family, and estimator. In this
paper, we revisit the likelihood-based inference principle and propose to use
likelihood ratios to construct any-time valid confidence sequences without
requiring specialized treatment in each application scenario. Our method is
especially suitable for problems with well-specified likelihoods, and the
resulting sets always maintain the prescribed coverage in a model-agnostic
manner. The size of the sets depends on a choice of estimator sequence in the
likelihood ratio. We discuss how to provably choose the best sequence of
estimators and shed light on connections to online convex optimization with
algorithms such as Follow-the-Regularized-Leader. To counteract the initially
large bias of the estimators, we propose a reweighting scheme that also opens
up deployment in non-parametric settings such as RKHS function classes. We
provide a non-asymptotic analysis of the likelihood ratio confidence sets size
for generalized linear models, using insights from convex duality and online
learning. We showcase the practical strength of our method on generalized
linear bandit problems, survival analysis, and bandits with various additive
noise distributions.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04403" title="Abstract">arXiv:2311.04403</a> [<a href="/pdf/2311.04403" title="Download PDF">pdf</a>, <a href="/format/2311.04403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human-Centered Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Kamra%2C+N">Nitin Kamra</a>, 
<a href="/search/cs?searchtype=author&query=Desai%2C+R">Ruta Desai</a>, 
<a href="/search/cs?searchtype=author&query=Halevy%2C+A">Alon Halevy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">LLMs have recently made impressive inroads on tasks whose output is
structured, such as coding, robotic planning and querying databases. The vision
of creating AI-powered personal assistants also involves creating structured
outputs, such as a plan for one's day, or for an overseas trip. Here, since the
plan is executed by a human, the output doesn't have to satisfy strict
syntactic constraints. A useful assistant should also be able to incorporate
vague constraints specified by the user in natural language. This makes LLMs an
attractive option for planning.
<br />We consider the problem of planning one's day. We develop an LLM-based
planner (LLMPlan) extended with the ability to self-reflect on its output and a
symbolic planner (SymPlan) with the ability to translate text constraints into
a symbolic representation. Despite no formal specification of constraints, we
find that LLMPlan performs explicit constraint satisfaction akin to the
traditional symbolic planners on average (2% performance difference), while
retaining the reasoning of implicit requirements. Consequently, LLM-based
planners outperform their symbolic counterparts in user satisfaction (70.5% vs.
40.4%) during interactive evaluation with 40 users.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04406" title="Abstract">arXiv:2311.04406</a> [<a href="/pdf/2311.04406" title="Download PDF">pdf</a>, <a href="/format/2311.04406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CompactTag: Minimizing Computation Overheads in Actively-Secure MPC for  Deep Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yongqin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+P">Pratik Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Koti%2C+N">Nishat Koti</a>, 
<a href="/search/cs?searchtype=author&query=Patra%2C+A">Arpita Patra</a>, 
<a href="/search/cs?searchtype=author&query=Annavaram%2C+M">Murali Annavaram</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Secure Multiparty Computation (MPC) protocols enable secure evaluation of a
circuit by several parties, even in the presence of an adversary who
maliciously corrupts all but one of the parties. These MPC protocols are
constructed using the well-known secret-sharing-based paradigm (SPDZ and
SPDZ2k), where the protocols ensure security against a malicious adversary by
computing Message Authentication Code (MAC) tags on the input shares and then
evaluating the circuit with these input shares and tags. However, this tag
computation adds a significant runtime overhead, particularly for machine
learning (ML) applications with numerous linear computation layers such as
convolutions and fully connected layers.
<br />To alleviate the tag computation overhead, we introduce CompactTag, a
lightweight algorithm for generating MAC tags specifically tailored for linear
layers in ML. Linear layer operations in ML, including convolutions, can be
transformed into Toeplitz matrix multiplications. For the multiplication of two
matrices with dimensions T1 x T2 and T2 x T3 respectively, SPDZ2k required O(T1
x T2 x T3) local multiplications for the tag computation. In contrast,
CompactTag only requires O(T1 x T2 + T1 x T3 + T2 x T3) local multiplications,
resulting in a substantial performance boost for various ML models.
<br />We empirically compared our protocol to the SPDZ2k protocol for various ML
circuits, including ResNet Training-Inference, Transformer Training-Inference,
and VGG16 Training-Inference. SPDZ2k dedicated around 30% of its online runtime
for tag computation. CompactTag speeds up this tag computation bottleneck by up
to 23x, resulting in up to 1.47x total online phase runtime speedups for
various ML workloads.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04410" title="Abstract">arXiv:2311.04410</a> [<a href="/pdf/2311.04410" title="Download PDF">pdf</a>, <a href="/format/2311.04410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Efficient Probabilistic Solution to Mapping Errors in LiDAR-Camera  Fusion for Autonomous Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+D">Dan Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhengming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+R">Renran Tian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yaobin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sherony%2C+R">Rini Sherony</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">LiDAR-camera fusion is one of the core processes for the perception system of
current automated driving systems. The typical sensor fusion process includes a
list of coordinate transformation operations following system calibration.
Although a significant amount of research has been done to improve the fusion
accuracy, there are still inherent data mapping errors in practice related to
system synchronization offsets, vehicle vibrations, the small size of the
target, and fast relative moving speeds. Moreover, more and more complicated
algorithms to improve fusion accuracy can overwhelm the onboard computational
resources, limiting the actual implementation. This study proposes a novel and
low-cost probabilistic LiDAR-Camera fusion method to alleviate these inherent
mapping errors in scene reconstruction. By calculating shape similarity using
KL-divergence and applying RANSAC-regression-based trajectory smoother, the
effects of LiDAR-camera mapping errors are minimized in object localization and
distance estimation. Designed experiments are conducted to prove the robustness
and effectiveness of the proposed strategy.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04412" title="Abstract">arXiv:2311.04412</a> [<a href="/pdf/2311.04412" title="Download PDF">pdf</a>, <a href="/ps/2311.04412" title="Download PostScript">ps</a>, <a href="/format/2311.04412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human Conditional Reasoning in Answer Set Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sakama%2C+C">Chiaki Sakama</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under consideration in Theory and Practice of Logic Programming (TPLP)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Given a conditional sentence P=&gt;Q (if P then Q) and respective facts, four
different types of inferences are observed in human reasoning. Affirming the
antecedent (AA) (or modus ponens) reasons Q from P; affirming the consequent
(AC) reasons P from Q; denying the antecedent (DA) reasons -Q from -P; and
denying the consequent (DC) (or modus tollens) reasons -P from -Q. Among them,
AA and DC are logically valid, while AC and DA are logically invalid and often
called logical fallacies. Nevertheless, humans often perform AC or DA as
pragmatic inference in daily life. In this paper, we realize AC, DA and DC
inferences in answer set programming. Eight different types of completion are
introduced and their semantics are given by answer sets. We investigate formal
properties and characterize human reasoning tasks in cognitive psychology.
Those completions are also applied to commonsense reasoning in AI.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04414" title="Abstract">arXiv:2311.04414</a> [<a href="/pdf/2311.04414" title="Download PDF">pdf</a>, <a href="/format/2311.04414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning the What and How of Annotation in Video Object Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Delatolas%2C+T">Thanos Delatolas</a>, 
<a href="/search/cs?searchtype=author&query=Kalogeiton%2C+V">Vicky Kalogeiton</a>, 
<a href="/search/cs?searchtype=author&query=Papadopoulos%2C+D+P">Dim P. Papadopoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video Object Segmentation (VOS) is crucial for several applications, from
video editing to video data generation. Training a VOS model requires an
abundance of manually labeled training videos. The de-facto traditional way of
annotating objects requires humans to draw detailed segmentation masks on the
target objects at each video frame. This annotation process, however, is
tedious and time-consuming. To reduce this annotation cost, in this paper, we
propose EVA-VOS, a human-in-the-loop annotation framework for video object
segmentation. Unlike the traditional approach, we introduce an agent that
predicts iteratively both which frame ("What") to annotate and which annotation
type ("How") to use. Then, the annotator annotates only the selected frame that
is used to update a VOS module, leading to significant gains in annotation
time. We conduct experiments on the MOSE and the DAVIS datasets and we show
that: (a) EVA-VOS leads to masks with accuracy close to the human agreement
3.5x faster than the standard way of annotating videos; (b) our frame selection
achieves state-of-the-art performance; (c) EVA-VOS yields significant
performance gains in terms of annotation time compared to all other methods and
baselines.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04417" title="Abstract">arXiv:2311.04417</a> [<a href="/pdf/2311.04417" title="Download PDF">pdf</a>, <a href="/format/2311.04417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Emerging AI/ML Accelerators: IPU, RDU, and NVIDIA/AMD GPUs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hongwu Peng</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+C">Caiwen Ding</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+T">Tong Geng</a>, 
<a href="/search/cs?searchtype=author&query=Choudhury%2C+S">Sutanay Choudhury</a>, 
<a href="/search/cs?searchtype=author&query=Barker%2C+K">Kevin Barker</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Ang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG); Performance (cs.PF)

</div>
<p class="mathjax">The relentless advancement of artificial intelligence (AI) and machine
learning (ML) applications necessitates the development of specialized hardware
accelerators capable of handling the increasing complexity and computational
demands. Traditional computing architectures, based on the von Neumann model,
are being outstripped by the requirements of contemporary AI/ML algorithms,
leading to a surge in the creation of accelerators like the Graphcore
Intelligence Processing Unit (IPU), Sambanova Reconfigurable Dataflow Unit
(RDU), and enhanced GPU platforms. These hardware accelerators are
characterized by their innovative data-flow architectures and other design
optimizations that promise to deliver superior performance and energy
efficiency for AI/ML tasks.
<br />This research provides a preliminary evaluation and comparison of these
commercial AI/ML accelerators, delving into their hardware and software design
features to discern their strengths and unique capabilities. By conducting a
series of benchmark evaluations on common DNN operators and other AI/ML
workloads, we aim to illuminate the advantages of data-flow architectures over
conventional processor designs and offer insights into the performance
trade-offs of each platform. The findings from our study will serve as a
valuable reference for the design and performance expectations of research
prototypes, thereby facilitating the development of next-generation hardware
accelerators tailored for the ever-evolving landscape of AI/ML applications.
Through this analysis, we aspire to contribute to the broader understanding of
current accelerator technologies and to provide guidance for future innovations
in the field.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04420" title="Abstract">arXiv:2311.04420</a> [<a href="/pdf/2311.04420" title="Download PDF">pdf</a>, <a href="/format/2311.04420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Factors for Better Compositional Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yichen Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+M">Mohit Bansal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 (18 pages)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent diagnostic datasets on compositional generalization, such as SCAN
(Lake and Baroni, 2018) and COGS (Kim and Linzen, 2020), expose severe problems
in models trained from scratch on these datasets. However, in contrast to this
poor performance, state-of-the-art models trained on larger and more general
datasets show better generalization ability. In this work, to reconcile this
inconsistency, we conduct an empirical analysis by training Transformer models
on a variety of training sets with different data factors, including dataset
scale, pattern complexity, example difficulty, etc. First, we show that
increased dataset complexity can lead to better generalization behavior on
multiple different generalization challenges. To further understand this
improvement, we show two axes of the benefit from more complex datasets: they
provide more diverse examples so compositional understanding becomes more
effective, and they also prevent ungeneralizable memorization of the examples
due to reduced example repetition frequency. Finally, we explore how training
examples of different difficulty levels influence generalization differently.
On synthetic datasets, simple examples invoke stronger compositionality than
hard examples do. On larger-scale real language datasets, while hard examples
become more important potentially to ensure decent data coverage, a balanced
mixture of simple and hard examples manages to induce the strongest
generalizability. The code and data for this work are available at
https://github.com/owenzx/data4comp
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04427" title="Abstract">arXiv:2311.04427</a> [<a href="/pdf/2311.04427" title="Download PDF">pdf</a>, <a href="/format/2311.04427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clonemator: Composing Spatiotemporal Clones to Create Interactive  Automators in Virtual Reality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yi-Shuo Lin</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+C">Ching-Yi Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Lung-Pan Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Clonemator is a virtual reality (VR) system allowing users to create their
avatar clones and configure them spatially and temporally, forming automators
to accomplish complex tasks. In particular, clones can (1) freeze at a user's
body pose as static objects, (2) synchronously mimic the user's movement, and
(3) replay a sequence of the user's actions in a period of time later. Combined
with traditional techniques such as scaling, positional rearrangement, group
selection, and duplication, Clonemator enables users to iteratively develop
customized and reusable solutions by breaking down complex tasks into a
sequence of collaborations with clones. This bypasses implementing dedicated
interaction techniques or scripts while allowing flexible interactions in VR
applications. We demonstrate the flexibility of Clonemator with several
examples and validate its usability and effectiveness through a preliminary
user study. Finally, we discuss the potential of Clonemator in VR applications
such as gaming mechanisms, spatial interaction techniques, and multi-robot
control and provide our insights for future research.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04433" title="Abstract">arXiv:2311.04433</a> [<a href="/pdf/2311.04433" title="Download PDF">pdf</a>, <a href="/format/2311.04433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SyncBleed: A Realistic Threat Model and Mitigation Strategy for  Zero-Involvement Pairing and Authentication (ZIPA)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahlgren%2C+I">Isaac Ahlgren</a>, 
<a href="/search/cs?searchtype=author&query=West%2C+J">Jack West</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kyuin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Thiruvathukal%2C+G+K">George K. Thiruvathukal</a>, 
<a href="/search/cs?searchtype=author&query=Klingensmith%2C+N">Neil Klingensmith</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Zero Involvement Pairing and Authentication (ZIPA) is a promising technique
for auto-provisioning large networks of Internet-of-Things (IoT) devices.
Presently, these networks use password-based authentication, which is difficult
to scale to more than a handful of devices. To deal with this challenge, ZIPA
enabled devices autonomously extract identical authentication or encryption
keys from ambient environmental signals. However, during the key negotiation
process, existing ZIPA systems leak information on a public wireless channel
which can allow adversaries to learn the key. We demonstrate a passive attack
called SyncBleed, which uses leaked information to reconstruct keys generated
by ZIPA systems. To mitigate SyncBleed, we present TREVOR, an improved key
generation technique that produces nearly identical bit sequences from
environmental signals without leaking information. We demonstrate that TREVOR
can generate keys from a variety of environmental signal types under 4 seconds,
consistently achieving a 90-95% bit agreement rate across devices within
various environmental sources.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04434" title="Abstract">arXiv:2311.04434</a> [<a href="/pdf/2311.04434" title="Download PDF">pdf</a>, <a href="/format/2311.04434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hierarchical Spatial Transformer for Massive Point Samples in  Continuous Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+W">Wenchong He</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhe Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+T">Tingsong Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zelin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shigang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fick%2C+R">Ronald Fick</a>, 
<a href="/search/cs?searchtype=author&query=Medina%2C+M">Miles Medina</a>, 
<a href="/search/cs?searchtype=author&query=Angelini%2C+C">Christine Angelini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Transformers are widely used deep learning architectures. Existing
transformers are mostly designed for sequences (texts or time series), images
or videos, and graphs. This paper proposes a novel transformer model for
massive (up to a million) point samples in continuous space. Such data are
ubiquitous in environment sciences (e.g., sensor observations), numerical
simulations (e.g., particle-laden flow, astrophysics), and location-based
services (e.g., POIs and trajectories). However, designing a transformer for
massive spatial points is non-trivial due to several challenges, including
implicit long-range and multi-scale dependency on irregular points in
continuous space, a non-uniform point distribution, the potential high
computational costs of calculating all-pair attention across massive points,
and the risks of over-confident predictions due to varying point density. To
address these challenges, we propose a new hierarchical spatial transformer
model, which includes multi-resolution representation learning within a
quad-tree hierarchy and efficient spatial attention via coarse approximation.
We also design an uncertainty quantification branch to estimate prediction
confidence related to input feature noise and point sparsity. We provide a
theoretical analysis of computational time complexity and memory costs.
Extensive experiments on both real-world and synthetic datasets show that our
method outperforms multiple baselines in prediction accuracy and our model can
scale up to one million points on one NVIDIA A100 GPU. The code is available at
\url{https://github.com/spatialdatasciencegroup/HST}.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04438" title="Abstract">arXiv:2311.04438</a> [<a href="/pdf/2311.04438" title="Download PDF">pdf</a>, <a href="/format/2311.04438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reusing Convolutional Neural Network Models through Modularization and  Composition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+B">Binhang Qi</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hailong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiang Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM Transactions on Software Engineering and Methodology (TOSEM). arXiv admin note: substantial text overlap with <a href="/abs/2209.06116">arXiv:2209.06116</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">With the widespread success of deep learning technologies, many trained deep
neural network (DNN) models are now publicly available. However, directly
reusing the public DNN models for new tasks often fails due to mismatching
functionality or performance. Inspired by the notion of modularization and
composition in software reuse, we investigate the possibility of improving the
reusability of DNN models in a more fine-grained manner. Specifically, we
propose two modularization approaches named CNNSplitter and GradSplitter, which
can decompose a trained convolutional neural network (CNN) model for $N$-class
classification into $N$ small reusable modules. Each module recognizes one of
the $N$ classes and contains a part of the convolution kernels of the trained
CNN model. Then, the resulting modules can be reused to patch existing CNN
models or build new CNN models through composition. The main difference between
CNNSplitter and GradSplitter lies in their search methods: the former relies on
a genetic algorithm to explore search space, while the latter utilizes a
gradient-based search method. Our experiments with three representative CNNs on
three widely-used public datasets demonstrate the effectiveness of the proposed
approaches. Compared with CNNSplitter, GradSplitter incurs less accuracy loss,
produces much smaller modules (19.88% fewer kernels), and achieves better
results on patching weak models. In particular, experiments on GradSplitter
show that (1) by patching weak models, the average improvement in terms of
precision, recall, and F1-score is 17.13%, 4.95%, and 11.47%, respectively, and
(2) for a new task, compared with the models trained from scratch, reusing
modules achieves similar accuracy (the average loss of accuracy is only 2.46%)
without a costly training process. Our approaches provide a viable solution to
the rapid development and improvement of CNN models.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04441" title="Abstract">arXiv:2311.04441</a> [<a href="/pdf/2311.04441" title="Download PDF">pdf</a>, <a href="/format/2311.04441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MixTEA: Semi-supervised Entity Alignment with Mixture Teaching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+F">Feng Xie</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xin Song</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xiang Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xuechen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+L">Lei Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Yusong Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of EMNLP 2023; 11 pages, 4 figures; code see <a href="https://github.com/Xiefeng69/MixTEA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Semi-supervised entity alignment (EA) is a practical and challenging task
because of the lack of adequate labeled mappings as training data. Most works
address this problem by generating pseudo mappings for unlabeled entities.
However, they either suffer from the erroneous (noisy) pseudo mappings or
largely ignore the uncertainty of pseudo mappings. In this paper, we propose a
novel semi-supervised EA method, termed as MixTEA, which guides the model
learning with an end-to-end mixture teaching of manually labeled mappings and
probabilistic pseudo mappings. We firstly train a student model using few
labeled mappings as standard. More importantly, in pseudo mapping learning, we
propose a bi-directional voting (BDV) strategy that fuses the alignment
decisions in different directions to estimate the uncertainty via the joint
matching confidence score. Meanwhile, we also design a matching diversity-based
rectification (MDR) module to adjust the pseudo mapping learning, thus reducing
the negative influence of noisy mappings. Extensive results on benchmark
datasets as well as further analyses demonstrate the superiority and the
effectiveness of our proposed method.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04448" title="Abstract">arXiv:2311.04448</a> [<a href="/pdf/2311.04448" title="Download PDF">pdf</a>, <a href="/format/2311.04448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Static Resource Leak Detection via LLM-based Resource-Oriented  Intention Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xin Peng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+Y">Yiling Lou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Resource leaks, caused by resources not being released after acquisition,
often lead to performance issues and system crashes. Existing static detection
techniques rely on mechanical matching of predefined resource
acquisition/release APIs, posing challenges to their effectiveness, including
completeness of predefined APIs, identification of reachability validation, and
analysis complexity. To overcome these challenges, we propose InferROI, a novel
approach that leverages large language models (LLMs) to directly infer
resource-oriented intentions (acquisition, release, and reachability
validation) in code, based on resource management knowledge and code context
understanding, rather than mechanical API matching. InferROI uses a prompt to
instruct the LLM in inferring involved intentions from a given code snippet,
which are then translated into formal expressions. By aggregating these
inferred intentions, InferROI utilizes a lightweight static-analysis based
algorithm to analyze control-flow paths extracted from the code, thereby
detecting resource leaks.
<br />We evaluate InferROI on Java program and investigate its effectiveness in
both resource-oriented intention inference and resource leak detection.
Experimental results demonstrate that InferROI achieves a precision of 74.6%
and a recall of 81.8% in intention inference on 172 code snippets from the
DroidLeaks dataset. Additionally, InferROI covers a significant portion of
concerned Android resources listed in the dataset. When applied to 86 bugs from
the DroidLeaks dataset, InferROI exhibits a high bug detection rate (53.5%) and
a low false alarm rate (8.1%) compared to eight baseline detectors. Moreover,
we apply InferROI to resource leak detection in 100 methods from real-world
open-source projects, where it identifies 12 unknown resource leak bugs, with 7
of them being confirmed by developers.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04449" title="Abstract">arXiv:2311.04449</a> [<a href="/pdf/2311.04449" title="Download PDF">pdf</a>, <a href="/format/2311.04449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recursion in Recursion: Two-Level Nested Recursion for Length  Generalization with Scalability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+J+R">Jishnu Ray Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Caragea%2C+C">Cornelia Caragea</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Binary Balanced Tree RvNNs (BBT-RvNNs) enforce sequence composition according
to a preset balanced binary tree structure. Thus, their non-linear recursion
depth is just $\log_2 n$ ($n$ being the sequence length). Such logarithmic
scaling makes BBT-RvNNs efficient and scalable on long sequence tasks such as
Long Range Arena (LRA). However, such computational efficiency comes at a cost
because BBT-RvNNs cannot solve simple arithmetic tasks like ListOps. On the
flip side, RvNNs (e.g., Beam Tree RvNN) that do succeed on ListOps (and other
structure-sensitive tasks like formal logical inference) are generally several
times more expensive than even RNNs. In this paper, we introduce a novel
framework -- Recursion in Recursion (RIR) to strike a balance between the two
sides - getting some of the benefits from both worlds. In RIR, we use a form of
two-level nested recursion - where the outer recursion is a $k$-ary balanced
tree model with another recursive model (inner recursion) implementing its cell
function. For the inner recursion, we choose Beam Tree RvNNs (BT-RvNN). To
adjust BT-RvNNs within RIR we also propose a novel strategy of beam alignment.
Overall, this entails that the total recursive depth in RIR is upper-bounded by
$k \log_k n$. Our best RIR-based model is the first model that demonstrates
high ($\geq 90\%$) length-generalization performance on ListOps while at the
same time being scalable enough to be trainable on long sequence inputs from
LRA. Moreover, in terms of accuracy in the LRA language tasks, it performs
competitively with Structured State Space Models (SSMs) without any special
initialization - outperforming Transformers by a large margin. On the other
hand, while SSMs can marginally outperform RIR on LRA, they (SSMs) fail to
length-generalize on ListOps. Our code is available at:
\url{https://github.com/JRC1995/BeamRecursionFamily/}.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04451" title="Abstract">arXiv:2311.04451</a> [<a href="/pdf/2311.04451" title="Download PDF">pdf</a>, <a href="/ps/2311.04451" title="Download PostScript">ps</a>, <a href="/format/2311.04451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pseduo-Random and de Bruijn Array Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Etzion%2C+T">Tuvi Etzion</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Pseudo-random arrays and perfect maps are the two-dimensional analogs of
M-sequences and de Bruijn sequences, respectively. We modify the definitions to
be applied to codes. These codes are also the two-dimensional analogs of
certain factors in the de Bruijn graph. These factors are called zero factors
and perfect factors in the de Bruijn graph. We apply a folding technique to
construct pseudo-random array codes and examine the minimum distance of the
constructed codes. The folding is applied on sequences generated from
irreducible polynomials or a product of irreducible polynomials with the same
degree and the same exponent. Direct and recursive constructions for de Bruijn
array codes are presented and discussed.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04453" title="Abstract">arXiv:2311.04453</a> [<a href="/pdf/2311.04453" title="Download PDF">pdf</a>, <a href="/format/2311.04453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lewis&#x27;s Signaling Game as beta-VAE For Natural Word Lengths and Segments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ueda%2C+R">Ryo Ueda</a>, 
<a href="/search/cs?searchtype=author&query=Taniguchi%2C+T">Tadahiro Taniguchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">As a sub-discipline of evolutionary and computational linguistics, emergent
communication (EC) studies communication protocols, called emergent languages,
arising in simulations where agents communicate. A key goal of EC is to give
rise to languages that share statistical properties with natural languages. In
this paper, we reinterpret Lewis's signaling game, a frequently used setting in
EC, as beta-VAE and reformulate its objective function as ELBO. Consequently,
we clarify the existence of prior distributions of emergent languages and show
that the choice of the priors can influence their statistical properties.
Specifically, we address the properties of word lengths and segmentation, known
as Zipf's law of abbreviation (ZLA) and Harris's articulation scheme (HAS),
respectively. It has been reported that the emergent languages do not follow
them when using the conventional objective. We experimentally demonstrate that
by selecting an appropriate prior distribution, more natural segments emerge,
while suggesting that the conventional one prevents the languages from
following ZLA and HAS.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04454" title="Abstract">arXiv:2311.04454</a> [<a href="/pdf/2311.04454" title="Download PDF">pdf</a>, <a href="/format/2311.04454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Influencing Incidental Human-Robot Encounters: Expressive movement  improves pedestrians&#x27; impressions of a quadruped service robot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hauser%2C+E">Elliott Hauser</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+Y">Yao-Cheng Chan</a>, 
<a href="/search/cs?searchtype=author&query=Bhalani%2C+R">Ruchi Bhalani</a>, 
<a href="/search/cs?searchtype=author&query=Kuchimanchi%2C+A">Alekhya Kuchimanchi</a>, 
<a href="/search/cs?searchtype=author&query=Siddiqui%2C+H">Hanaa Siddiqui</a>, 
<a href="/search/cs?searchtype=author&query=Hart%2C+J">Justin Hart</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted HICSS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">A single mobile service robot may generate hundreds of encounters with
pedestrians, yet there is little published data on the factors influencing
these incidental human-robot encounters. We report the results of a
between-subjects experiment (n=222) testing the impact of robot body language,
defined as non-functional modifications to robot movement, upon incidental
pedestrian encounters with a quadruped service robot in a real-world setting.
We find that canine-inspired body language had a positive influence on
participants' perceptions of the robot compared to the robot's stock movement.
This effect was visible across all questions of a questionnaire on the
perceptions of robots (Godspeed). We argue that body language is a promising
and practical design space for improving pedestrian encounters with service
robots.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04456" title="Abstract">arXiv:2311.04456</a> [<a href="/pdf/2311.04456" title="Download PDF">pdf</a>, <a href="/format/2311.04456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> (Social) Trouble on the Road: Understanding and Addressing Social  Discomfort in Shared Car Trips
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bremers%2C+A">Alexandra Bremers</a>, 
<a href="/search/cs?searchtype=author&query=Friedman%2C+N">Natalie Friedman</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sam Lee</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Laurier%2C+E">Eric Laurier</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+M">Malte Jung</a>, 
<a href="/search/cs?searchtype=author&query=Ortiz%2C+J">Jorge Ortiz</a>, 
<a href="/search/cs?searchtype=author&query=Ju%2C+W">Wendy Ju</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Unpleasant social interactions on the road can have negative consequences
that affect driving safety. Any technological interventions to address these
common occurrences need to be built on an understanding of the nature of social
discomfort in vehicles. This paper contributes fine-grained empirical analysis
and a proposed definition and categorization of the problem of social
discomfort in cars to the HCI literature. We recorded nine families going on
drives and performed interaction analysis on this data. Discomfort in the car
could be divided into (1) local and full-body physical discomfort and (2)
individual, social, or cognitive-load-related psychological discomfort. We
define three strategies to address discomfort: contextual mediation, social
mediation, and social support. We discuss three video excerpts in detail to
illustrate the mitigation strategies. This work lays the foundation for the
design of interactive vehicular systems for mitigating social discomfort.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04457" title="Abstract">arXiv:2311.04457</a> [<a href="/pdf/2311.04457" title="Download PDF">pdf</a>, <a href="/format/2311.04457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Uncertainty Quantification approaches for Neural PDEs in  scientific applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dongre%2C+V">Vardhan Dongre</a>, 
<a href="/search/cs?searchtype=author&query=Hora%2C+G+S">Gurpreet Singh Hora</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures, 1 table, AI for Science Workshop Attention Track, neurips 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Physics (physics.comp-ph); Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">The accessibility of spatially distributed data, enabled by affordable
sensors, field, and numerical experiments, has facilitated the development of
data-driven solutions for scientific problems, including climate change,
weather prediction, and urban planning. Neural Partial Differential Equations
(Neural PDEs), which combine deep learning (DL) techniques with domain
expertise (e.g., governing equations) for parameterization, have proven to be
effective in capturing valuable correlations within spatiotemporal datasets.
However, sparse and noisy measurements coupled with modeling approximation
introduce aleatoric and epistemic uncertainties. Therefore, quantifying
uncertainties propagated from model inputs to outputs remains a challenge and
an essential goal for establishing the trustworthiness of Neural PDEs. This
work evaluates various Uncertainty Quantification (UQ) approaches for both
Forward and Inverse Problems in scientific applications. Specifically, we
investigate the effectiveness of Bayesian methods, such as Hamiltonian Monte
Carlo (HMC) and Monte-Carlo Dropout (MCD), and a more conventional approach,
Deep Ensembles (DE). To illustrate their performance, we take two canonical
PDEs: Burger's equation and the Navier-Stokes equation. Our results indicate
that Neural PDEs can effectively reconstruct flow systems and predict the
associated unknown parameters. However, it is noteworthy that the results
derived from Bayesian methods, based on our observations, tend to display a
higher degree of certainty in their predictions as compared to those obtained
using the DE. This elevated certainty in predictions suggests that Bayesian
techniques might underestimate the true underlying uncertainty, thereby
appearing more confident in their predictions than the DE approach.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04458" title="Abstract">arXiv:2311.04458</a> [<a href="/pdf/2311.04458" title="Download PDF">pdf</a>, <a href="/format/2311.04458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retargeting video with an end-to-end framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+T">Thi-Ngoc-Hanh Le</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">HuiGuang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yi-Ru Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+T">Tong-Yee Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted for publication on IEEE Transactions on Visualization and Computer Graphics, October 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Video holds significance in computer graphics applications. Because of the
heterogeneous of digital devices, retargeting videos becomes an essential
function to enhance user viewing experience in such applications. In the
research of video retargeting, preserving the relevant visual content in
videos, avoiding flicking, and processing time are the vital challenges.
Extending image retargeting techniques to the video domain is challenging due
to the high running time. Prior work of video retargeting mainly utilizes
time-consuming preprocessing to analyze frames. Plus, being tolerant of
different video content, avoiding important objects from shrinking, and the
ability to play with arbitrary ratios are the limitations that need to be
resolved in these systems requiring investigation. In this paper, we present an
end-to-end RETVI method to retarget videos to arbitrary aspect ratios. We
eliminate the computational bottleneck in the conventional approaches by
designing RETVI with two modules, content feature analyzer (CFA) and adaptive
deforming estimator (ADE). The extensive experiments and evaluations show that
our system outperforms previous work in quality and running time. Visit our
project website for more results at
$\href{<a href="http://graphics.csie.ncku.edu.tw/RETVI">this http URL</a>}{<a href="http://graphics.csie.ncku.edu.tw/RETVI">this http URL</a>}$.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04459" title="Abstract">arXiv:2311.04459</a> [<a href="/pdf/2311.04459" title="Download PDF">pdf</a>, <a href="/format/2311.04459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Pacing in Long-Form Story Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yichen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kevin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+D">Dan Klein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP Findings 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Existing LLM-based systems for writing long-form stories or story outlines
frequently suffer from unnatural pacing, whether glossing over important events
or over-elaborating on insignificant details, resulting in a jarring experience
for the reader. We propose a CONCrete Outline ConTrol (CONCOCT) system to
improve pacing when automatically generating story outlines. We first train a
concreteness evaluator to judge which of two events is more concrete
(low-level-detailed). This evaluator can then be used to control pacing in
hierarchical outline generation; in this work, we explore a vaguest-first
expansion procedure that aims for uniform pacing. We further use the evaluator
to filter new outline items based on predicted concreteness. Compared to a
baseline hierarchical outline generator, humans judge CONCOCT's pacing to be
more consistent over 57% of the time across multiple outline lengths; the gains
also translate to downstream stories. All code, data, and models are
open-sourced.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04464" title="Abstract">arXiv:2311.04464</a> [<a href="/pdf/2311.04464" title="Download PDF">pdf</a>, <a href="/format/2311.04464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Few-shot CLIP with Semantic-Aware Fine-Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuefeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+X">Xiaofeng Mao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhigang Li</a>, 
<a href="/search/cs?searchtype=author&query=lu%2C+W">Wang lu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jindong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+X">Xiangyang Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Learning generalized representations from limited training samples is crucial
for applying deep neural networks in low-resource scenarios. Recently, methods
based on Contrastive Language-Image Pre-training (CLIP) have exhibited
promising performance in few-shot adaptation tasks. To avoid catastrophic
forgetting and overfitting caused by few-shot fine-tuning, existing works
usually freeze the parameters of CLIP pre-trained on large-scale datasets,
overlooking the possibility that some parameters might not be suitable for
downstream tasks. To this end, we revisit CLIP's visual encoder with a specific
focus on its distinctive attention pooling layer, which performs a spatial
weighted-sum of the dense feature maps. Given that dense feature maps contain
meaningful semantic information, and different semantics hold varying
importance for diverse downstream tasks (such as prioritizing semantics like
ears and eyes in pet classification tasks rather than side mirrors), using the
same weighted-sum operation for dense features across different few-shot tasks
might not be appropriate. Hence, we propose fine-tuning the parameters of the
attention pooling layer during the training process to encourage the model to
focus on task-specific semantics. In the inference process, we perform residual
blending between the features pooled by the fine-tuned and the original
attention pooling layers to incorporate both the few-shot knowledge and the
pre-trained CLIP's prior knowledge. We term this method as Semantic-Aware
FinE-tuning (SAFE). SAFE is effective in enhancing the conventional few-shot
CLIP and is compatible with the existing adapter approach (termed SAFE-A).
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04465" title="Abstract">arXiv:2311.04465</a> [<a href="/pdf/2311.04465" title="Download PDF">pdf</a>, <a href="/format/2311.04465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving High Frequency and Multi-Scale PDEs with Gaussian Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+S">Shikai Fang</a>, 
<a href="/search/cs?searchtype=author&query=Cooley%2C+M">Madison Cooley</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+D">Da Long</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shibo Li</a>, 
<a href="/search/cs?searchtype=author&query=Kirby%2C+R">Robert Kirby</a>, 
<a href="/search/cs?searchtype=author&query=Zhe%2C+S">Shandian Zhe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">Machine learning based solvers have garnered much attention in physical
simulation and scientific computing, with a prominent example, physics-informed
neural networks (PINNs). However, PINNs often struggle to solve high-frequency
and multi-scale PDEs, which can be due to spectral bias during neural network
training. To address this problem, we resort to the Gaussian process (GP)
framework. To flexibly capture the dominant frequencies, we model the power
spectrum of the PDE solution with a student t mixture or Gaussian mixture. We
then apply the inverse Fourier transform to obtain the covariance function
(according to the Wiener-Khinchin theorem). The covariance derived from the
Gaussian mixture spectrum corresponds to the known spectral mixture kernel. We
are the first to discover its rationale and effectiveness for PDE solving.
Next,we estimate the mixture weights in the log domain, which we show is
equivalent to placing a Jeffreys prior. It automatically induces sparsity,
prunes excessive frequencies, and adjusts the remaining toward the ground
truth. Third, to enable efficient and scalable computation on massive
collocation points, which are critical to capture high frequencies, we place
the collocation points on a grid, and multiply our covariance function at each
input dimension. We use the GP conditional mean to predict the solution and its
derivatives so as to fit the boundary condition and the equation itself. As a
result, we can derive a Kronecker product structure in the covariance matrix.
We use Kronecker product properties and multilinear algebra to greatly promote
computational efficiency and scalability, without any low-rank approximations.
We show the advantage of our method in systematic experiments.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04467" title="Abstract">arXiv:2311.04467</a> [<a href="/pdf/2311.04467" title="Download PDF">pdf</a>, <a href="/format/2311.04467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RDGCN: Reinforced Dependency Graph Convolutional Network for  Aspect-based Sentiment Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xusheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Q">Qiong Dai</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xu Bai</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Huailiang Peng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yanbing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qinglang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S. Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 17th ACM International Conference on Web Search and Data Mining
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Aspect-based sentiment analysis (ABSA) is dedicated to forecasting the
sentiment polarity of aspect terms within sentences. Employing graph neural
networks to capture structural patterns from syntactic dependency parsing has
been confirmed as an effective approach for boosting ABSA. In most works, the
topology of dependency trees or dependency-based attention coefficients is
often loosely regarded as edges between aspects and opinions, which can result
in insufficient and ambiguous syntactic utilization. To address these problems,
we propose a new reinforced dependency graph convolutional network (RDGCN) that
improves the importance calculation of dependencies in both distance and type
views. Initially, we propose an importance calculation criterion for the
minimum distances over dependency trees. Under the criterion, we design a
distance-importance function that leverages reinforcement learning for weight
distribution search and dissimilarity control. Since dependency types often do
not have explicit syntax like tree distances, we use global attention and mask
mechanisms to design type-importance functions. Finally, we merge these weights
and implement feature aggregation and classification. Comprehensive experiments
on three popular datasets demonstrate the effectiveness of the criterion and
importance functions. RDGCN outperforms state-of-the-art GNN-based baselines in
all validations.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04472" title="Abstract">arXiv:2311.04472</a> [<a href="/pdf/2311.04472" title="Download PDF">pdf</a>, <a href="/ps/2311.04472" title="Download PostScript">ps</a>, <a href="/format/2311.04472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous Advanced Aerial Mobility -- An End-to-end Autonomy Framework  for UAVs and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mishra%2C+S">Sakshi Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Palanisamy%2C+P">Praveen Palanisamy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA); Systems and Control (eess.SY)

</div>
<p class="mathjax">Developing aerial robots that can both safely navigate and execute assigned
mission without any human intervention - i.e., fully autonomous aerial mobility
of passengers and goods - is the larger vision that guides the research,
design, and development efforts in the aerial autonomy space. However, it is
highly challenging to concurrently operationalize all types of aerial vehicles
that are operating fully autonomously sharing the airspace. Full autonomy of
the aerial transportation sector includes several aspects, such as design of
the technology that powers the vehicles, operations of multi-agent fleets, and
process of certification that meets stringent safety requirements of aviation
sector. Thereby, Autonomous Advanced Aerial Mobility is still a vague term and
its consequences for researchers and professionals are ambiguous. To address
this gap, we present a comprehensive perspective on the emerging field of
autonomous advanced aerial mobility, which involves the use of unmanned aerial
vehicles (UAVs) and electric vertical takeoff and landing (eVTOL) aircraft for
various applications, such as urban air mobility, package delivery, and
surveillance. The article proposes a scalable and extensible autonomy framework
consisting of four main blocks: sensing, perception, planning, and controls.
Furthermore, the article discusses the challenges and opportunities in
multi-agent fleet operations and management, as well as the testing,
validation, and certification aspects of autonomous aerial systems. Finally,
the article explores the potential of monolithic models for aerial autonomy and
analyzes their advantages and limitations. The perspective aims to provide a
holistic picture of the autonomous advanced aerial mobility field and its
future directions.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04474" title="Abstract">arXiv:2311.04474</a> [<a href="/pdf/2311.04474" title="Download PDF">pdf</a>, <a href="/format/2311.04474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergent Communication for Rules Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuxuan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Y">Yifan Hao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+E">Enshuai Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Z">Zidong Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xishan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xinkai Song</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yuanbo Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yongwei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xuehai Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiaming Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+Q">Qi Yi</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Shaohui Peng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">Di Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruizhi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yunji Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Research on emergent communication between deep-learning-based agents has
received extensive attention due to its inspiration for linguistics and
artificial intelligence. However, previous attempts have hovered around
emerging communication under perception-oriented environmental settings, that
forces agents to describe low-level perceptual features intra image or symbol
contexts. In this work, inspired by the classic human reasoning test (namely
Raven's Progressive Matrix), we propose the Reasoning Game, a
cognition-oriented environment that encourages agents to reason and communicate
high-level rules, rather than perceived low-level contexts. Moreover, we
propose 1) an unbiased dataset (namely rule-RAVEN) as a benchmark to avoid
overfitting, 2) and a two-stage curriculum agent training method as a baseline
for more stable convergence in the Reasoning Game, where contexts and semantics
are bilaterally drifting. Experimental results show that, in the Reasoning
Game, a semantically stable and compositional language emerges to solve
reasoning problems. The emerged language helps agents apply the extracted rules
to the generalization of unseen context attributes, and to the transfer between
different context attributes or even tasks.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04477" title="Abstract">arXiv:2311.04477</a> [<a href="/pdf/2311.04477" title="Download PDF">pdf</a>, <a href="/format/2311.04477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PLV-IEKF: Consistent Visual-Inertial Odometry using Points, Lines, and  Vanishing Points
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hua%2C+T">Tong Hua</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tao Li</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+L">Liang Pang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guoqing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xuanyuan%2C+W">Wencheng Xuanyuan</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+C">Chang Shu</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+L">Ling Pei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ROBIO 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this paper, we propose an Invariant Extended Kalman Filter (IEKF) based
Visual-Inertial Odometry (VIO) using multiple features in man-made
environments. Conventional EKF-based VIO usually suffers from system
inconsistency and angular drift that naturally occurs in feature-based methods.
However, in man-made environments, notable structural regularities, such as
lines and vanishing points, offer valuable cues for localization. To exploit
these structural features effectively and maintain system consistency, we
design a right invariant filter-based VIO scheme incorporating point, line, and
vanishing point features. We demonstrate that the conventional additive error
definition for point features can also preserve system consistency like the
invariant error definition by proving a mathematically equivalent measurement
model. And a similar conclusion is established for line features. Additionally,
we conduct an invariant filter-based observability analysis proving that
vanishing point measurement maintains unobservable directions naturally. Both
simulation and real-world tests are conducted to validate our methods' pose
accuracy and consistency. The experimental results validate the competitive
performance of our method, highlighting its ability to deliver accurate and
consistent pose estimation in man-made environments.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04479" title="Abstract">arXiv:2311.04479</a> [<a href="/pdf/2311.04479" title="Download PDF">pdf</a>, <a href="/ps/2311.04479" title="Download PostScript">ps</a>, <a href="/format/2311.04479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Twitter Sentiment Analysis of Covid Vacciness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenbo Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+T">Tiechuan Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AIVR 2021 5th International Conference on Artificial Intelligence and Virtual Reality
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">In this paper, we look at a database of tweets sorted by various keywords
that could indicate the users sentiment towards covid vaccines. With social
media becoming such a prevalent source of opinion, sorting and ranking tweets
that hold important information such as opinions on covid vaccines is of utmost
importance. Two different ranking scales were used, and ranking a tweet in this
way could represent the difference between an opinion being lost and an opinion
being featured on the site, which affects the decisions and behavior of people,
and why researchers were interested in it. Using natural language processing
techniques, our aim is to determine and categorize opinions about covid
vaccines with the highest accuracy possible.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04480" title="Abstract">arXiv:2311.04480</a> [<a href="/pdf/2311.04480" title="Download PDF">pdf</a>, <a href="/format/2311.04480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLearViD: Curriculum Learning for Video Description
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chuang%2C+C">Cheng-Yu Chuang</a>, 
<a href="/search/cs?searchtype=author&query=Fazli%2C+P">Pooyan Fazli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Video description entails automatically generating coherent natural language
sentences that narrate the content of a given video. We introduce CLearViD, a
transformer-based model for video description generation that leverages
curriculum learning to accomplish this task. In particular, we investigate two
curriculum strategies: (1) progressively exposing the model to more challenging
samples by gradually applying a Gaussian noise to the video data, and (2)
gradually reducing the capacity of the network through dropout during the
training process. These methods enable the model to learn more robust and
generalizable features. Moreover, CLearViD leverages the Mish activation
function, which provides non-linearity and non-monotonicity and helps alleviate
the issue of vanishing gradients. Our extensive experiments and ablation
studies demonstrate the effectiveness of the proposed model. The results on two
datasets, namely ActivityNet Captions and YouCook2, show that CLearViD
significantly outperforms existing state-of-the-art models in terms of both
accuracy and diversity metrics.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04482" title="Abstract">arXiv:2311.04482</a> [<a href="/pdf/2311.04482" title="Download PDF">pdf</a>, <a href="/ps/2311.04482" title="Download PostScript">ps</a>, <a href="/format/2311.04482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Distributed Networking with Big Data Scheduling and Cloud  Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenbo Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2022 International Conference on Cloud Computing, Internet of Things, and Computer Applications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">With the rapid transformation of computer hardware and algorithms, mobile
networking has evolved from low data carrying capacity and high latency to
better-optimized networks, either by enhancing the digital network or using
different approaches to reduce network traffic. This paper discusses the big
data applications and scheduling in the distributed networking and analyzes the
opportunities and challenges of data management systems. The analysis shows
that the big data scheduling in the cloud computing environment produces the
most efficient way to transfer and synchronize data. Since scheduling problems
and cloud models are very complex to analyze in different settings, we set it
to the typical software defined networks. The development of cloud management
models and coflow scheduling algorithm is proved to be the priority of the
digital communications and networks development in the future.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04491" title="Abstract">arXiv:2311.04491</a> [<a href="/pdf/2311.04491" title="Download PDF">pdf</a>, <a href="/format/2311.04491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable AI for Earth Observation: Current Methods, Open Challenges,  and Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taskin%2C+G">Gulsen Taskin</a>, 
<a href="/search/cs?searchtype=author&query=Aptoula%2C+E">Erchan Aptoula</a>, 
<a href="/search/cs?searchtype=author&query=Ert%C3%BCrk%2C+A">Alp Ert&#xfc;rk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep learning has taken by storm all fields involved in data analysis,
including remote sensing for Earth observation. However, despite significant
advances in terms of performance, its lack of explainability and
interpretability, inherent to neural networks in general since their inception,
remains a major source of criticism. Hence it comes as no surprise that the
expansion of deep learning methods in remote sensing is being accompanied by
increasingly intensive efforts oriented towards addressing this drawback
through the exploration of a wide spectrum of Explainable Artificial
Intelligence techniques. This chapter, organized according to prominent Earth
observation application fields, presents a panorama of the state-of-the-art in
explainable remote sensing image analysis.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04494" title="Abstract">arXiv:2311.04494</a> [<a href="/pdf/2311.04494" title="Download PDF">pdf</a>, <a href="/format/2311.04494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Rigid Shape Registration via Deep Functional Maps Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+P">Puhua Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Mingze Sun</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+R">Ruqi Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we propose a learning-based framework for non-rigid shape
registration without correspondence supervision. Traditional shape registration
techniques typically rely on correspondences induced by extrinsic proximity,
therefore can fail in the presence of large intrinsic deformations. Spectral
mapping methods overcome this challenge by embedding shapes into, geometric or
learned, high-dimensional spaces, where shapes are easier to align. However,
due to the dependency on abstract, non-linear embedding schemes, the latter can
be vulnerable with respect to perturbed or alien input. In light of this, our
framework takes the best of both worlds. Namely, we deform source mesh towards
the target point cloud, guided by correspondences induced by high-dimensional
embeddings learned from deep functional maps (DFM). In particular, the
correspondences are dynamically updated according to the intermediate
registrations and filtered by consistency prior, which prominently robustify
the overall pipeline. Moreover, in order to alleviate the requirement of
extrinsically aligned input, we train an orientation regressor on a set of
aligned synthetic shapes independent of the training shapes for DFM. Empirical
results show that, with as few as dozens of training shapes of limited
variability, our pipeline achieves state-of-the-art results on several
benchmarks of non-rigid point cloud matching, but also delivers high-quality
correspondences between unseen challenging shape pairs that undergo both
significant extrinsic and intrinsic deformations, in which case neither
traditional registration methods nor intrinsic methods work. The code is
available at https://github.com/rqhuang88/DFR.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04495" title="Abstract">arXiv:2311.04495</a> [<a href="/pdf/2311.04495" title="Download PDF">pdf</a>, <a href="/format/2311.04495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-label and Multi-target Sampling of Machine Annotation for  Computational Stance Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chieu%2C+H+L">Hai Leong Chieu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+N+F">Nancy F. Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of EMNLP 2023. arXiv admin note: text overlap with <a href="/abs/2305.19845">arXiv:2305.19845</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Data collection from manual labeling provides domain-specific and
task-aligned supervision for data-driven approaches, and a critical mass of
well-annotated resources is required to achieve reasonable performance in
natural language processing tasks. However, manual annotations are often
challenging to scale up in terms of time and budget, especially when domain
knowledge, capturing subtle semantic features, and reasoning steps are needed.
In this paper, we investigate the efficacy of leveraging large language models
on automated labeling for computational stance detection. We empirically
observe that while large language models show strong potential as an
alternative to human annotators, their sensitivity to task-specific
instructions and their intrinsic biases pose intriguing yet unique challenges
in machine annotation. We introduce a multi-label and multi-target sampling
strategy to optimize the annotation quality. Experimental results on the
benchmark stance detection corpora show that our method can significantly
improve performance and learning efficacy.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04496" title="Abstract">arXiv:2311.04496</a> [<a href="/pdf/2311.04496" title="Download PDF">pdf</a>, <a href="/format/2311.04496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PersonMAE: Person Re-Identification Pre-Training with Masked  AutoEncoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hezhen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xiaoyi Dong</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+J">Jianmin Bao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dongdong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Lu Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Houqiang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Pre-training is playing an increasingly important role in learning generic
feature representation for Person Re-identification (ReID). We argue that a
high-quality ReID representation should have three properties, namely,
multi-level awareness, occlusion robustness, and cross-region invariance. To
this end, we propose a simple yet effective pre-training framework, namely
PersonMAE, which involves two core designs into masked autoencoders to better
serve the task of Person Re-ID. 1) PersonMAE generates two regions from the
given image with RegionA as the input and \textit{RegionB} as the prediction
target. RegionA is corrupted with block-wise masking to mimic common occlusion
in ReID and its remaining visible parts are fed into the encoder. 2) Then
PersonMAE aims to predict the whole RegionB at both pixel level and semantic
feature level. It encourages its pre-trained feature representations with the
three properties mentioned above. These properties make PersonMAE compatible
with downstream Person ReID tasks, leading to state-of-the-art performance on
four downstream ReID tasks, i.e., supervised (holistic and occluded setting),
and unsupervised (UDA and USL setting). Notably, on the commonly adopted
supervised setting, PersonMAE with ViT-B backbone achieves 79.8% and 69.5% mAP
on the MSMT17 and OccDuke datasets, surpassing the previous state-of-the-art by
a large margin of +8.0 mAP, and +5.3 mAP, respectively.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04498" title="Abstract">arXiv:2311.04498</a> [<a href="/pdf/2311.04498" title="Download PDF">pdf</a>, <a href="/format/2311.04498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NExT-Chat: An LMM for Chat, Detection and Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Ao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Liming Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Chen-Wei Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yun Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+W">Wei Ji</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project: <a href="https://next-chatv.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">The development of large language models (LLMs) has greatly advanced the
field of multimodal understanding, leading to the emergence of large multimodal
models (LMMs). In order to enhance the level of visual comprehension, recent
studies have equipped LMMs with region-level understanding capabilities by
representing object bounding box coordinates as a series of text sequences
(pixel2seq). In this paper, we introduce a novel paradigm for object location
modeling called pixel2emb method, where we ask the LMM to output the location
embeddings and then decoded by different decoders. This paradigm allows for
different location formats (such as bounding boxes and masks) to be used in
multimodal conversations Furthermore, this kind of embedding based location
modeling enables the utilization of existing practices in localization tasks,
such as detection and segmentation. In scenarios with limited resources, our
pixel2emb demonstrates superior performance compared to existing
state-of-the-art (SOTA) approaches in both the location input and output tasks
under fair comparison. Leveraging the proposed pixel2emb method, we train an
LMM named NExT-Chat and demonstrate its capability of handling multiple tasks
like visual grounding, region caption, and grounded reasoning.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04499" title="Abstract">arXiv:2311.04499</a> [<a href="/pdf/2311.04499" title="Download PDF">pdf</a>, <a href="/format/2311.04499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Near-Linear Scaling Data Parallel Training with Overlapping-Aware  Gradient Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+L">Lin Meng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuzhong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weimin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Existing Data Parallel (DP) trainings for deep neural networks (DNNs) often
experience limited scalability in speedup due to substantial communication
overheads. While Overlapping technique can mitigate such problem by paralleling
communication and computation in DP, its effectiveness is constrained by the
high communication-to-computation ratios (CCR) of DP training tasks. Gradient
compression (GC) is a promising technique to obtain lower CCR by reducing
communication volume directly. However, it is challenging to obtain real
performance improvement by applying GC into Overlapping because of (1) severe
performance penalties in traditional GCs caused by high compression overhead
and (2) decline of Overlapping benefit owing to the possible data dependency in
GC schemes. In this paper, we propose COVAP, a novel GC scheme designing a new
coarse-grained filter, makes the compression overhead close to zero. COVAP
ensures an almost complete overlap of communication and computation by
employing adaptive compression ratios and tensor sharding tailored to specific
training tasks. COVAP also adopts an improved error feedback mechanism to
maintain training accuracy. Experiments are conducted on Alibaba Cloud ECS
instances with different DNNs of real-world applications. The results
illustrate that COVAP outperforms existent GC schemes in time-to-solution by
1.92x-15.39x and exhibits near-linear scaling. Furthermore, COVAP achieves best
scalability under experiments on four different cluster sizes.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04501" title="Abstract">arXiv:2311.04501</a> [<a href="/pdf/2311.04501" title="Download PDF">pdf</a>, <a href="/format/2311.04501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PRED: Pre-training via Semantic Rendering on LiDAR Point Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haiyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+D">Di Dai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liwei Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Pre-training is crucial in 3D-related fields such as autonomous driving where
point cloud annotation is costly and challenging. Many recent studies on point
cloud pre-training, however, have overlooked the issue of incompleteness, where
only a fraction of the points are captured by LiDAR, leading to ambiguity
during the training phase. On the other hand, images offer more comprehensive
information and richer semantics that can bolster point cloud encoders in
addressing the incompleteness issue inherent in point clouds. Yet,
incorporating images into point cloud pre-training presents its own challenges
due to occlusions, potentially causing misalignments between points and pixels.
In this work, we propose PRED, a novel image-assisted pre-training framework
for outdoor point clouds in an occlusion-aware manner. The main ingredient of
our framework is a Birds-Eye-View (BEV) feature map conditioned semantic
rendering, leveraging the semantics of images for supervision through neural
rendering. We further enhance our model's performance by incorporating
point-wise masking with a high mask ratio (95%). Extensive experiments
demonstrate PRED's superiority over prior point cloud pre-training methods,
providing significant improvements on various large-scale datasets for 3D
perception tasks. Codes will be available at https://github.com/PRED4pc/PRED.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04502" title="Abstract">arXiv:2311.04502</a> [<a href="/pdf/2311.04502" title="Download PDF">pdf</a>, <a href="/format/2311.04502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TADA: Making Node-link Diagrams Accessible to Blind and Low-Vision  People
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yichun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Nacenta%2C+M+A">Miguel A. Nacenta</a>, 
<a href="/search/cs?searchtype=author&query=Sukhai%2C+M+A">Mahadeo A. Sukhai</a>, 
<a href="/search/cs?searchtype=author&query=Somanath%2C+S">Sowmya Somanath</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Diagrams often appear as node-link representations in many contexts, such as
taxonomies, mind maps and networks in textbooks. Despite their pervasiveness,
they present significant accessibility challenges for blind and low-vision
people. To address this challenge, we introduce Touch-and-Audio-based Diagram
Access (TADA), a tablet-based interactive system that makes diagram exploration
accessible through musical tones and speech. We designed and developed TADA
informed by insights gained from an interview study with 15 participants who
shared their challenges and strategies for accessing diagrams. TADA enables
people to access a diagram by: i) engaging in open-ended touch-based
explorations, ii) allowing searching of specific nodes, iii) navigating from
one node to another and iv) filtering information. We evaluated TADA with 25
participants and found that it can be a useful tool for gaining different
perspectives about the diagram and participants could complete several
diagram-related tasks.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04503" title="Abstract">arXiv:2311.04503</a> [<a href="/pdf/2311.04503" title="Download PDF">pdf</a>, <a href="/format/2311.04503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constrained Adaptive Attacks: Realistic Evaluation of Adversarial  Examples and Robust Training of Deep Neural Networks for Tabular Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Simonetto%2C+T">Thibault Simonetto</a>, 
<a href="/search/cs?searchtype=author&query=Ghamizi%2C+S">Salah Ghamizi</a>, 
<a href="/search/cs?searchtype=author&query=Desjardins%2C+A">Antoine Desjardins</a>, 
<a href="/search/cs?searchtype=author&query=Cordy%2C+M">Maxime Cordy</a>, 
<a href="/search/cs?searchtype=author&query=Traon%2C+Y+L">Yves Le Traon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">State-of-the-art deep learning models for tabular data have recently achieved
acceptable performance to be deployed in industrial settings. However, the
robustness of these models remains scarcely explored. Contrary to computer
vision, there is to date no realistic protocol to properly evaluate the
adversarial robustness of deep tabular models due to intrinsic properties of
tabular data such as categorical features, immutability, and feature
relationship constraints. To fill this gap, we propose CAA, the first efficient
evasion attack for constrained tabular deep learning models. CAA is an
iterative parameter-free attack that combines gradient and search attacks to
generate adversarial examples under constraints. We leverage CAA to build a
benchmark of deep tabular models across three popular use cases: credit
scoring, phishing and botnet attacks detection. Our benchmark supports ten
threat models with increasing capabilities of the attacker, and reflects
real-world attack scenarios for each use case. Overall, our results demonstrate
how domain knowledge, adversarial training, and attack budgets impact the
robustness assessment of deep tabular models and provide security practitioners
with a set of recommendations to improve the robustness of deep tabular models
against various evasion attack scenarios.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04505" title="Abstract">arXiv:2311.04505</a> [<a href="/pdf/2311.04505" title="Download PDF">pdf</a>, <a href="/format/2311.04505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NITEC: Versatile Hand-Annotated Eye Contact Dataset for Ego-Vision  Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hempel%2C+T">Thorsten Hempel</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+M">Magnus Jung</a>, 
<a href="/search/cs?searchtype=author&query=Abdelrahman%2C+A+A">Ahmed A. Abdelrahman</a>, 
<a href="/search/cs?searchtype=author&query=Al-Hamadi%2C+A">Ayoub Al-Hamadi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE/CVF Winter Conference on Applications of Computer Vision (WACV 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Eye contact is a crucial non-verbal interaction modality and plays an
important role in our everyday social life. While humans are very sensitive to
eye contact, the capabilities of machines to capture a person's gaze are still
mediocre. We tackle this challenge and present NITEC, a hand-annotated eye
contact dataset for ego-vision interaction. NITEC exceeds existing datasets for
ego-vision eye contact in size and variety of demographics, social contexts,
and lighting conditions, making it a valuable resource for advancing
ego-vision-based eye contact research. Our extensive evaluations on NITEC
demonstrate strong cross-dataset performance, emphasizing its effectiveness and
adaptability in various scenarios, that allows seamless utilization to the
fields of computer vision, human-computer interaction, and social robotics. We
make our NITEC dataset publicly available to foster reproducibility and further
exploration in the field of ego-vision interaction.
https://github.com/thohemp/nitec
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04507" title="Abstract">arXiv:2311.04507</a> [<a href="/pdf/2311.04507" title="Download PDF">pdf</a>, <a href="/format/2311.04507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conversation Understanding using Relational Temporal Graph Neural  Networks with Auxiliary Cross-Modality Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+C+T">Cam-Van Thi Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Mai%2C+A">Anh-Tuan Mai</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+T">The-Son Le</a>, 
<a href="/search/cs?searchtype=author&query=Kieu%2C+H">Hai-Dang Kieu</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+D">Duc-Trong Le</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Emotion recognition is a crucial task for human conversation understanding.
It becomes more challenging with the notion of multimodal data, e.g., language,
voice, and facial expressions. As a typical solution, the global- and the local
context information are exploited to predict the emotional label for every
single sentence, i.e., utterance, in the dialogue. Specifically, the global
representation could be captured via modeling of cross-modal interactions at
the conversation level. The local one is often inferred using the temporal
information of speakers or emotional shifts, which neglects vital factors at
the utterance level. Additionally, most existing approaches take fused features
of multiple modalities in an unified input without leveraging modality-specific
representations. Motivating from these problems, we propose the Relational
Temporal Graph Neural Network with Auxiliary Cross-Modality Interaction
(CORECT), an novel neural network framework that effectively captures
conversation-level cross-modality interactions and utterance-level temporal
dependencies with the modality-specific manner for conversation understanding.
Extensive experiments demonstrate the effectiveness of CORECT via its
state-of-the-art results on the IEMOCAP and CMU-MOSEI datasets for the
multimodal ERC task.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04509" title="Abstract">arXiv:2311.04509</a> [<a href="/pdf/2311.04509" title="Download PDF">pdf</a>, <a href="/format/2311.04509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Discriminative Features for Crowd Counting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuehai Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Crowd counting models in highly congested areas confront two main challenges:
weak localization ability and difficulty in differentiating between foreground
and background, leading to inaccurate estimations. The reason is that objects
in highly congested areas are normally small and high-level features extracted
by convolutional neural networks are less discriminative to represent small
objects. To address these problems, we propose a learning discriminative
features framework for crowd counting, which is composed of a masked feature
prediction module (MPM) and a supervised pixel-level contrastive learning
module (CLM). The MPM randomly masks feature vectors in the feature map and
then reconstructs them, allowing the model to learn about what is present in
the masked regions and improving the model's ability to localize objects in
high-density regions. The CLM pulls targets close to each other and pushes them
far away from background in the feature space, enabling the model to
discriminate foreground objects from background. Additionally, the proposed
modules can be beneficial in various computer vision tasks, such as crowd
counting and object detection, where dense scenes or cluttered environments
pose challenges to accurate localization. The proposed two modules are
plug-and-play, incorporating the proposed modules into existing models can
potentially boost their performance in these scenarios.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04511" title="Abstract">arXiv:2311.04511</a> [<a href="/pdf/2311.04511" title="Download PDF">pdf</a>, <a href="/ps/2311.04511" title="Download PostScript">ps</a>, <a href="/format/2311.04511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solution of FPK Equation for Stochastic Dynamics Subjected to Additive  Gaussian Noise via Deep Learning Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khodabakhsh%2C+A+H">Amir H. Khodabakhsh</a>, 
<a href="/search/cs?searchtype=author&query=Pourtakdoust%2C+S+H">Seid H. Pourtakdoust</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 43 pages, 21 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Struct Saf, 106 (2024) 102399
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Dynamical Systems (math.DS); Probability (math.PR); Applications (stat.AP)

</div>
<p class="mathjax">The Fokker-Plank-Kolmogorov (FPK) equation is an idealized model representing
many stochastic systems commonly encountered in the analysis of stochastic
structures as well as many other applications. Its solution thus provides an
invaluable insight into the performance of many engineering systems. Despite
its great importance, the solution of the FPK equation is still extremely
challenging. For systems of practical significance, the FPK equation is usually
high dimensional, rendering most of the numerical methods ineffective. In this
respect, the present work introduces the FPK-DP Net as a physics-informed
network that encodes the physical insights, i.e. the governing constrained
differential equations emanated out of physical laws, into a deep neural
network. FPK-DP Net is a mesh-free learning method that can solve the density
evolution of stochastic dynamics subjected to additive white Gaussian noise
without any prior simulation data and can be used as an efficient surrogate
model afterward. FPK-DP Net uses the dimension-reduced FPK equation. Therefore,
it can be used to address high-dimensional practical problems as well. To
demonstrate the potential applicability of the proposed framework, and to study
its accuracy and efficacy, numerical implementations on five different
benchmark problems are investigated.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04512" title="Abstract">arXiv:2311.04512</a> [<a href="/pdf/2311.04512" title="Download PDF">pdf</a>, <a href="/format/2311.04512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FFINet: Future Feedback Interaction Network for Motion Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+M">Miao Kang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shengqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Sanping Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+K">Ke Ye</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jingjing Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+N">Nanning Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures, 12 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Motion forecasting plays a crucial role in autonomous driving, with the aim
of predicting the future reasonable motions of traffic agents. Most existing
methods mainly model the historical interactions between agents and the
environment, and predict multi-modal trajectories in a feedforward process,
ignoring potential trajectory changes caused by future interactions between
agents. In this paper, we propose a novel Future Feedback Interaction Network
(FFINet) to aggregate features the current observations and potential future
interactions for trajectory prediction. Firstly, we employ different
spatial-temporal encoders to embed the decomposed position vectors and the
current position of each scene, providing rich features for the subsequent
cross-temporal aggregation. Secondly, the relative interaction and
cross-temporal aggregation strategies are sequentially adopted to integrate
features in the current fusion module, observation interaction module, future
feedback module and global fusion module, in which the future feedback module
can enable the understanding of pre-action by feeding the influence of preview
information to feedforward prediction. Thirdly, the comprehensive interaction
features are further fed into final predictor to generate the joint predicted
trajectories of multiple agents. Extensive experimental results show that our
FFINet achieves the state-of-the-art performance on Argoverse 1 and Argoverse 2
motion forecasting benchmarks.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04513" title="Abstract">arXiv:2311.04513</a> [<a href="/pdf/2311.04513" title="Download PDF">pdf</a>, <a href="/format/2311.04513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Validity of Credit-Based Shaper Delay Guarantees in Decentralized  Reservation Protocols
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maile%2C+L">Lisa Maile</a>, 
<a href="/search/cs?searchtype=author&query=Voitlein%2C+D">Dominik Voitlein</a>, 
<a href="/search/cs?searchtype=author&query=Grigorjew%2C+A">Alexej Grigorjew</a>, 
<a href="/search/cs?searchtype=author&query=Hielscher%2C+K+J">Kai-Steffen J. Hielscher</a>, 
<a href="/search/cs?searchtype=author&query=German%2C+R">Reinhard German</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Association for Computing Machinery (ACM)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 31st International Conference on Real-Time
  Networks and Systems 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Resource reservation is a fundamental mechanism for ensuring quality of
service in time-sensitive networks, which can be decentralized by using
reservation protocols. In the Ethernet technology Time-Sensitive Networking,
this has been proposed in conjunction with the Credit-Based Shaper. For the
reservation, the standards assume a maximum worst-case latency bound at each
hop. However, we will show through formal analysis and simulation that these
worst-case latency bounds are not safe. To face this, we propose an extension
to the current standards to allow the reservation of time-sensitive traffic
with reliable latency guarantees. The effectiveness of our approach is
demonstrated through simulations of both synthetic and industrial networks.
Finally, by providing additional information about neighboring devices, we
could further increase the maximum reservable traffic by up to 20% in our test
cases.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04517" title="Abstract">arXiv:2311.04517</a> [<a href="/pdf/2311.04517" title="Download PDF">pdf</a>, <a href="/format/2311.04517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strategies for Parallelizing the Big-Means Algorithm: A Comprehensive  Tutorial for Effective Big Data Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mussabayev%2C+R">Ravil Mussabayev</a>, 
<a href="/search/cs?searchtype=author&query=Mussabayev%2C+R">Rustam Mussabayev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2310.09819">arXiv:2310.09819</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">This study focuses on the optimization of the Big-means algorithm for
clustering large-scale datasets, exploring four distinct parallelization
strategies. We conducted extensive experiments to assess the computational
efficiency, scalability, and clustering performance of each approach, revealing
their benefits and limitations. The paper also delves into the trade-offs
between computational efficiency and clustering quality, examining the impacts
of various factors. Our insights provide practical guidance on selecting the
best parallelization strategy based on available resources and dataset
characteristics, contributing to a deeper understanding of parallelization
techniques for the Big-means algorithm.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04518" title="Abstract">arXiv:2311.04518</a> [<a href="/pdf/2311.04518" title="Download PDF">pdf</a>, <a href="/format/2311.04518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Democratizing AI: A Comparative Analysis of AI as a Service  Platforms and the Open Space for Machine Learning Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rall%2C+D">Dennis Rall</a>, 
<a href="/search/cs?searchtype=author&query=Bauer%2C+B">Bernhard Bauer</a>, 
<a href="/search/cs?searchtype=author&query=Fraunholz%2C+T">Thomas Fraunholz</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 2023 7th International Conference on Cloud and
  Big Data Computing 34-39
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Recent AI research has significantly reduced the barriers to apply AI, but
the process of setting up the necessary tools and frameworks can still be a
challenge. While AI-as-a-Service platforms have emerged to simplify the
training and deployment of AI models, they still fall short of achieving true
democratization of AI. In this paper, we aim to address this gap by comparing
several popular AI-as-a-Service platforms and identifying the key requirements
for a platform that can achieve true democratization of AI. Our analysis
highlights the need for self-hosting options, high scalability, and openness.
To address these requirements, we propose our approach: the "Open Space for
Machine Learning" platform. Our platform is built on cutting-edge technologies
such as Kubernetes, Kubeflow Pipelines, and Ludwig, enabling us to overcome the
challenges of democratizing AI. We argue that our approach is more
comprehensive and effective in meeting the requirements of democratizing AI
than existing AI-as-a-Service platforms.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04519" title="Abstract">arXiv:2311.04519</a> [<a href="/pdf/2311.04519" title="Download PDF">pdf</a>, <a href="/format/2311.04519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synergy Among Flexible Demands: Forming a Coalition to Earn More from  Reserve Market
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gade%2C+P+A+V">Peter A. V. Gade</a>, 
<a href="/search/eess?searchtype=author&query=Skj%C3%B8tskift%2C+T">Trygve Skj&#xf8;tskift</a>, 
<a href="/search/eess?searchtype=author&query=Bindner%2C+H">Henrik Bindner</a>, 
<a href="/search/eess?searchtype=author&query=Kazempour%2C+J">Jalal Kazempour</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at IEEE International Conference on Communications, Control, and Computing Technologies for Smart Grids (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">We address potential synergy among flexible demands and how they may earn
more collectively than individually by forming a coalition and bidding to the
reserve market. We consider frequency-supporting ancillary service markets,
particularly the manual Frequency Restoration Reserve (mFRR) market. The
coalition of flexible demands provides more reliable mFRR services, where in
comparison to individual demands, is penalized less for their potential failure
and is paid more for their successful activation. This synergy effect is
quantified as a function of the number of homogeneous assets in the coalition.
A subsequent payment allocation mechanism using Shapley values is proposed to
distribute the total earnings of the coalition among demands, while
incentivizing them to remain in the coalition. For our numerical study, we use
real price data from the Danish mFRR market in 2022.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04521" title="Abstract">arXiv:2311.04521</a> [<a href="/pdf/2311.04521" title="Download PDF">pdf</a>, <a href="/format/2311.04521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Robust Multi-Scale Representation for Neural Radiance Fields  from Unposed Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+N">Nishant Jain</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Suryansh Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at International Journal of Computer Vision (IJCV). Draft info: 22 pages, 12 figures and 14 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce an improved solution to the neural image-based rendering problem
in computer vision. Given a set of images taken from a freely moving camera at
train time, the proposed approach could synthesize a realistic image of the
scene from a novel viewpoint at test time. The key ideas presented in this
paper are (i) Recovering accurate camera parameters via a robust pipeline from
unposed day-to-day images is equally crucial in neural novel view synthesis
problem; (ii) It is rather more practical to model object's content at
different resolutions since dramatic camera motion is highly likely in
day-to-day unposed images. To incorporate the key ideas, we leverage the
fundamentals of scene rigidity, multi-scale neural scene representation, and
single-image depth prediction. Concretely, the proposed approach makes the
camera parameters as learnable in a neural fields-based modeling framework. By
assuming per view depth prediction is given up to scale, we constrain the
relative pose between successive frames. From the relative poses, absolute
camera pose estimation is modeled via a graph-neural network-based multiple
motion averaging within the multi-scale neural-fields network, leading to a
single loss function. Optimizing the introduced loss function provides camera
intrinsic, extrinsic, and image rendering from unposed images. We demonstrate,
with examples, that for a unified framework to accurately model multiscale
neural scene representation from day-to-day acquired unposed multi-view images,
it is equally essential to have precise camera-pose estimates within the scene
representation framework. Without considering robustness measures in the camera
pose estimation pipeline, modeling for multi-scale aliasing artifacts can be
counterproductive. We present extensive experiments on several benchmark
datasets to demonstrate the suitability of our approach.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04522" title="Abstract">arXiv:2311.04522</a> [<a href="/pdf/2311.04522" title="Download PDF">pdf</a>, <a href="/format/2311.04522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Long-term Time Series Forecasting based on Decomposition and Neural  Ordinary Differential Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lim%2C+S">Seonkyu Lim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jaehyeon Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seojin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Wi%2C+H">Hyowon Wi</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+H">Haksoo Lim</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+J">Jinsung Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jeongwhan Choi</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+N">Noseong Park</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Long-term time series forecasting (LTSF) is a challenging task that has been
investigated in various domains such as finance investment, health care,
traffic, and weather forecasting. In recent years, Linear-based LTSF models
showed better performance, pointing out the problem of Transformer-based
approaches causing temporal information loss. However, Linear-based approach
has also limitations that the model is too simple to comprehensively exploit
the characteristics of the dataset. To solve these limitations, we propose
LTSF-DNODE, which applies a model based on linear ordinary differential
equations (ODEs) and a time series decomposition method according to data
statistical characteristics. We show that LTSF-DNODE outperforms the baselines
on various real-world datasets. In addition, for each dataset, we explore the
impacts of regularization in the neural ordinary differential equation (NODE)
framework.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04524" title="Abstract">arXiv:2311.04524</a> [<a href="/pdf/2311.04524" title="Download PDF">pdf</a>, <a href="/format/2311.04524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Validating ChatGPT Facts through RDF Knowledge Graphs and Sentence  Similarity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mountantonakis%2C+M">Michalis Mountantonakis</a>, 
<a href="/search/cs?searchtype=author&query=Tzitzikas%2C+Y">Yannis Tzitzikas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Since ChatGPT offers detailed responses without justifications, and erroneous
facts even for popular persons, events and places, in this paper we present a
novel pipeline that retrieves the response of ChatGPT in RDF and tries to
validate the ChatGPT facts using one or more RDF Knowledge Graphs (KGs). To
this end we leverage DBpedia and LODsyndesis (an aggregated Knowledge Graph
that contains 2 billion triples from 400 RDF KGs of many domains) and short
sentence embeddings, and introduce an algorithm that returns the more relevant
triple(s) accompanied by their provenance and a confidence score. This enables
the validation of ChatGPT responses and their enrichment with justifications
and provenance. To evaluate this service (such services in general), we create
an evaluation benchmark that includes 2,000 ChatGPT facts; specifically 1,000
facts for famous Greek Persons, 500 facts for popular Greek Places, and 500
facts for Events related to Greece. The facts were manually labelled
(approximately 73% of ChatGPT facts were correct and 27% of facts were
erroneous). The results are promising; indicatively for the whole benchmark, we
managed to verify the 85.3% of the correct facts of ChatGPT and to find the
correct answer for the 62.6% of the erroneous ChatGPT facts.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04527" title="Abstract">arXiv:2311.04527</a> [<a href="/pdf/2311.04527" title="Download PDF">pdf</a>, <a href="/format/2311.04527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extended Paper: API-driven Program Synthesis for Testing Static Typing  Implementations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sotiropoulos%2C+T">Thodoris Sotiropoulos</a>, 
<a href="/search/cs?searchtype=author&query=Chaliasos%2C+S">Stefanos Chaliasos</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Z">Zhendong Su</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">We introduce a novel approach for testing static typing implementations based
on the concept of API-driven program synthesis. The idea is to synthesize
type-intensive but small and well-typed programs by leveraging and combining
application programming interfaces (APIs) derived from existing software
libraries. Our primary insight is backed up by real-world evidence: a
significant number of compiler typing bugs are caused by small test cases that
employ APIs from the standard library of the language under test. This is
attributed to the inherent complexity of the majority of these APIs, which
often exercise a wide range of sophisticated type-related features. The main
contribution of our approach is the ability to produce small client programs
with increased feature coverage, without bearing the burden of generating the
corresponding well-formed API definitions from scratch. To validate diverse
aspects of static typing procedures (i.e., soundness, precision of type
inference), we also enrich our API-driven approach with fault-injection and
semantics-preserving modes, along with their corresponding test oracles.
<br />We evaluate our implemented tool, Thalia on testing the static typing
implementations of the compilers for three popular languages, namely, Scala,
Kotlin, and Groovy. Thalia has uncovered 84 typing bugs (77 confirmed and 22
fixed), most of which are triggered by test cases featuring APIs that rely on
parametric polymorphism, overloading, and higher-order functions. Our
comparison with state-of-the-art shows that Thalia yields test programs with
distinct characteristics, offering additional and complementary benefits.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04528" title="Abstract">arXiv:2311.04528</a> [<a href="/pdf/2311.04528" title="Download PDF">pdf</a>, <a href="/format/2311.04528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bandit Learning to Rank with Position-Based Click Models: Personalized  and Equal Treatments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianchen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+Y">Yang Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+C">Chaosheng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yetian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yi Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Online learning to rank (ONL2R) is a foundational problem for recommender
systems and has received increasing attention in recent years. Among the
existing approaches for ONL2R, a natural modeling architecture is the
multi-armed bandit framework coupled with the position-based click model.
However, developing efficient online learning policies for MAB-based ONL2R with
position-based click models is highly challenging due to the combinatorial
nature of the problem, and partial observability in the position-based click
model. To date, results in MAB-based ONL2R with position-based click models
remain rather limited, which motivates us to fill this gap in this work. Our
main contributions in this work are threefold: i) We propose the first general
MAB framework that captures all key ingredients of ONL2R with position-based
click models. Our model considers personalized and equal treatments in ONL2R
ranking recommendations, both of which are widely used in practice; ii) Based
on the above analytical framework, we develop two unified greed- and UCB-based
policies called GreedyRank and UCBRank, each of which can be applied to
personalized and equal ranking treatments; and iii) We show that both
GreedyRank and UCBRank enjoy $O(\sqrt{t}\ln t)$ and $O(\sqrt{t\ln t})$ anytime
sublinear regret for personalized and equal treatment, respectively. For the
fundamentally hard equal ranking treatment, we identify classes of collective
utility functions and their associated sufficient conditions under which
$O(\sqrt{t}\ln t)$ and $O(\sqrt{t\ln t})$ anytime sublinear regrets are still
achievable for GreedyRank and UCBRank, respectively. Our numerical experiments
also verify our theoretical results and demonstrate the efficiency of
GreedyRank and UCBRank in seeking the optimal action under various problem
settings.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04531" title="Abstract">arXiv:2311.04531</a> [<a href="/pdf/2311.04531" title="Download PDF">pdf</a>, <a href="/format/2311.04531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Unsupervised Deep Learning Approach for the Wave Equation Inverse  Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yan%2C+X">Xiong-Bin Yan</a>, 
<a href="/search/math?searchtype=author&query=Wu%2C+K">Keke Wu</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+Z+J">Zhi-Qin John Xu</a>, 
<a href="/search/math?searchtype=author&query=Ma%2C+Z">Zheng Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 Pages,22 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Full-waveform inversion (FWI) is a powerful geophysical imaging technique
that infers high-resolution subsurface physical parameters by solving a
non-convex optimization problem. However, due to limitations in observation,
e.g., limited shots or receivers, and random noise, conventional inversion
methods are confronted with numerous challenges, such as the local-minimum
problem. In recent years, a substantial body of work has demonstrated that the
integration of deep neural networks and partial differential equations for
solving full-waveform inversion problems has shown promising performance. In
this work, drawing inspiration from the expressive capacity of neural networks,
we provide an unsupervised learning approach aimed at accurately reconstructing
subsurface physical velocity parameters. This method is founded on a
re-parametrization technique for Bayesian inference, achieved through a deep
neural network with random weights. Notably, our proposed approach does not
hinge upon the requirement of the labeled training dataset, rendering it
exceedingly versatile and adaptable to diverse subsurface models. Extensive
experiments show that the proposed approach performs noticeably better than
existing conventional inversion methods.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04532" title="Abstract">arXiv:2311.04532</a> [<a href="/pdf/2311.04532" title="Download PDF">pdf</a>, <a href="/format/2311.04532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Diverse Large Language Models for Automatic and General Bug  Reproduction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+S">Sungmin Kang</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+J">Juyeon Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Askarbekkyzy%2C+N">Nargiz Askarbekkyzy</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+S">Shin Yoo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2209.11515">arXiv:2209.11515</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Bug reproduction is a critical developer activity that is also challenging to
automate, as bug reports are often in natural language and thus can be
difficult to transform to test cases consistently. As a result, existing
techniques mostly focused on crash bugs, which are easier to automatically
detect and verify. In this work, we overcome this limitation by using large
language models (LLMs), which have been demonstrated to be adept at natural
language processing and code generation. By prompting LLMs to generate
bug-reproducing tests, and via a post-processing pipeline to automatically
identify promising generated tests, our proposed technique LIBRO could
successfully reproduce about one-third of all bugs in the widely used Defects4J
benchmark. Furthermore, our extensive evaluation on 15 LLMs, including 11
open-source LLMs, suggests that open-source LLMs also demonstrate substantial
potential, with the StarCoder LLM achieving 70% of the reproduction performance
of the closed-source OpenAI LLM code-davinci-002 on the large Defects4J
benchmark, and 90% of performance on a held-out bug dataset likely not part of
any LLM's training data. In addition, our experiments on LLMs of different
sizes show that bug reproduction using LIBRO improves as LLM size increases,
providing information as to which LLMs can be used with the LIBRO pipeline.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04533" title="Abstract">arXiv:2311.04533</a> [<a href="/pdf/2311.04533" title="Download PDF">pdf</a>, <a href="/ps/2311.04533" title="Download PostScript">ps</a>, <a href="/format/2311.04533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Approximations for Ultrametric Violation Distance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Charikar%2C+M">Moses Charikar</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+R">Ruiquan Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SODA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We study the Ultrametric Violation Distance problem introduced by
Cohen-Addad, Fan, Lee, and Mesmay [FOCS, 2022]. Given pairwise distances $x\in
\mathbb{R}_{&gt;0}^{\binom{[n]}{2}}$ as input, the goal is to modify the minimum
number of distances so as to make it a valid ultrametric. In other words, this
is the problem of fitting an ultrametric to given data, where the quality of
the fit is measured by the $\ell_0$ norm of the error; variants of the problem
for the $\ell_\infty$ and $\ell_1$ norms are well-studied in the literature.
<br />Our main result is a 5-approximation algorithm for Ultrametric Violation
Distance, improving the previous best large constant factor ($\geq 1000$)
approximation algorithm. We give an $O(\min\{L,\log n\})$-approximation for
weighted Ultrametric Violation Distance where the weights satisfy triangle
inequality and $L$ is the number of distinct values in the input. We also give
a $16$-approximation for the problem on $k$-partite graphs, where the input is
specified on pairs of vertices that form a complete $k$-partite graph. All our
results use a unified algorithmic framework with small modifications for the
three cases.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04534" title="Abstract">arXiv:2311.04534</a> [<a href="/pdf/2311.04534" title="Download PDF">pdf</a>, <a href="/format/2311.04534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Loss Masking Is Not Needed in Decoder-only Transformer for  Discrete-token Based ASR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qinglin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Siqi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+C">Chong Deng</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yukun Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hai Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaqing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Recently, unified speech-text models, such as SpeechGPT, VioLA, and
AudioPaLM, have achieved remarkable performance on speech tasks. These models
convert continuous speech signals into discrete tokens (speech discretization)
and merge text and speech tokens into a shared vocabulary. Then they train a
single decoder-only Transformer on a mixture of speech tasks. Specifically, all
these models utilize Loss Masking on the input speech tokens for the ASR task,
which means that these models do not explicitly model the dependency between
the speech tokens. In this paper, we attempt to model the sequence of speech
tokens in an autoregressive manner like text. However, we find that applying
the conventional cross-entropy loss on input speech tokens does not
consistently improve the ASR performance over Loss Masking. Therefore, we
propose a novel approach denoted Smoothed Label Distillation (SLD), which
introduces a KL divergence loss with smoothed labels on the input speech tokens
to effectively model speech tokens. Experiments demonstrate that our SLD
approach alleviates the limitations of the cross-entropy loss and consistently
outperforms Loss Masking for decoder-only Transformer based ASR using different
speech discretization methods.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04535" title="Abstract">arXiv:2311.04535</a> [<a href="/pdf/2311.04535" title="Download PDF">pdf</a>, <a href="/format/2311.04535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RankAug: Augmented data ranking for text classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roy%2C+T+S">Tiasa Singha Roy</a>, 
<a href="/search/cs?searchtype=author&query=Basu%2C+P">Priyam Basu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the GEM workshop at EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Research on data generation and augmentation has been focused majorly on
enhancing generation models, leaving a notable gap in the exploration and
refinement of methods for evaluating synthetic data. There are several text
similarity metrics within the context of generated data filtering which can
impact the performance of specific Natural Language Understanding (NLU) tasks,
specifically focusing on intent and sentiment classification. In this study, we
propose RankAug, a text-ranking approach that detects and filters out the top
augmented texts in terms of being most similar in meaning with lexical and
syntactical diversity. Through experiments conducted on multiple datasets, we
demonstrate that the judicious selection of filtering techniques can yield a
substantial improvement of up to 35% in classification accuracy for
under-represented classes.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04536" title="Abstract">arXiv:2311.04536</a> [<a href="/pdf/2311.04536" title="Download PDF">pdf</a>, <a href="/format/2311.04536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Uniform Partitioning of a Region using Opaque ASYNC Luminous  Mobile Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pramanick%2C+S">Subhajit Pramanick</a>, 
<a href="/search/cs?searchtype=author&query=Jana%2C+S">Saswata Jana</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+A">Adri Bhattacharya</a>, 
<a href="/search/cs?searchtype=author&query=Mandal%2C+P+S">Partha Sarathi Mandal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper recently got accepted in ICDCN 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">We are given $N$ autonomous mobile robots inside a bounded region. The robots
are opaque which means that three collinear robots are unable to see each other
as one of the robots acts as an obstruction for the other two. They operate in
classical \emph{Look-Compute-Move} (LCM) activation cycles. Moreover, the
robots are oblivious except for a persistent light (which is why they are
called \emph{Luminous robots}) that can determine a color from a fixed color
set. Obliviousness does not allow the robots to remember any information from
past activation cycles. The Uniform Partitioning problem requires the robots to
partition the whole region into sub-regions of equal area, each of which
contains exactly one robot. Due to application-oriented motivation, we, in this
paper consider the region to be well-known geometric shapes such as rectangle,
square and circle. We investigate the problem in \emph{asynchronous} setting
where there is no notion of common time and any robot gets activated at any
time with a fair assumption that every robot needs to get activated infinitely
often. To the best of our knowledge, this is the first attempt to study the
Uniform Partitioning problem using oblivious opaque robots working under
asynchronous settings. We propose three algorithms considering three different
regions: rectangle, square and circle. Robots partition the region in a
distributed way and reach their respective positions in the partitions. The
algorithms proposed for rectangular and square regions run in $O(N)$ epochs
whereas the algorithm for circular regions runs in $O(N^2)$ epochs, where an
epoch is the smallest unit of time in which all robots are activated at least
once and execute their LCM cycles.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04538" title="Abstract">arXiv:2311.04538</a> [<a href="/pdf/2311.04538" title="Download PDF">pdf</a>, <a href="/ps/2311.04538" title="Download PostScript">ps</a>, <a href="/format/2311.04538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster Maximal Exact Matches with Lazy LCP Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goga%2C+A">Adri&#xe1;n Goga</a>, 
<a href="/search/cs?searchtype=author&query=Depuydt%2C+L">Lore Depuydt</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+N+K">Nathaniel K. Brown</a>, 
<a href="/search/cs?searchtype=author&query=Fostier%2C+J">Jan Fostier</a>, 
<a href="/search/cs?searchtype=author&query=Gagie%2C+T">Travis Gagie</a>, 
<a href="/search/cs?searchtype=author&query=Navarro%2C+G">Gonzalo Navarro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">MONI (Rossi et al., {\it JCB} 2022) is a BWT-based compressed index for
computing the matching statistics and maximal exact matches (MEMs) of a pattern
(usually a DNA read) with respect to a highly repetitive text (usually a
database of genomes) using two operations: LF-steps and longest common
extension (LCE) queries on a grammar-compressed representation of the text. In
practice, most of the operations are constant-time LF-steps but most of the
time is spent evaluating LCE queries. In this paper we show how (a variant of)
the latter can be evaluated lazily, so as to bound the total time MONI needs to
process the pattern in terms of the number of MEMs between the pattern and the
text, while maintaining logarithmic latency.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04542" title="Abstract">arXiv:2311.04542</a> [<a href="/pdf/2311.04542" title="Download PDF">pdf</a>, <a href="/format/2311.04542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FEIR: Quantifying and Reducing Envy and Inferiority for Fair  Recommendation of Limited Resources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Nan Li</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+B">Bo Kang</a>, 
<a href="/search/cs?searchtype=author&query=Lijffijt%2C+J">Jefrey Lijffijt</a>, 
<a href="/search/cs?searchtype=author&query=De+Bie%2C+T">Tijl De Bie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In settings such as e-recruitment and online dating, recommendation involves
distributing limited opportunities, calling for novel approaches to quantify
and enforce fairness. We introduce \emph{inferiority}, a novel (un)fairness
measure quantifying a user's competitive disadvantage for their recommended
items. Inferiority complements \emph{envy}, a fairness notion measuring
preference for others' recommendations. We combine inferiority and envy with
\emph{utility}, an accuracy-related measure of aggregated relevancy scores.
Since these measures are non-differentiable, we reformulate them using a
probabilistic interpretation of recommender systems, yielding differentiable
versions. We combine these loss functions in a multi-objective optimization
problem called \texttt{FEIR} (Fairness through Envy and Inferiority Reduction),
applied as post-processing for standard recommender systems. Experiments on
synthetic and real-world data demonstrate that our approach improves trade-offs
between inferiority, envy, and utility compared to naive recommendations and
the baseline methods.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04544" title="Abstract">arXiv:2311.04544</a> [<a href="/pdf/2311.04544" title="Download PDF">pdf</a>, <a href="/format/2311.04544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local Differential Privacy for Smart Meter Data Sharing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shanmugarasa%2C+Y">Yashothara Shanmugarasa</a>, 
<a href="/search/cs?searchtype=author&query=Chamikara%2C+M+A+P">M.A.P. Chamikara</a>, 
<a href="/search/cs?searchtype=author&query=Paik%2C+H">Hye-young Paik</a>, 
<a href="/search/cs?searchtype=author&query=Kanhere%2C+S+S">Salil S. Kanhere</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Liming Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
<p class="mathjax">Energy disaggregation techniques, which use smart meter data to infer
appliance energy usage, can provide consumers and energy companies valuable
insights into energy management. However, these techniques also present privacy
risks, such as the potential for behavioral profiling. Local differential
privacy (LDP) methods provide strong privacy guarantees with high efficiency in
addressing privacy concerns. However, existing LDP methods focus on protecting
aggregated energy consumption data rather than individual appliances.
Furthermore, these methods do not consider the fact that smart meter data are a
form of streaming data, and its processing methods should account for time
windows. In this paper, we propose a novel LDP approach (named LDP-SmartEnergy)
that utilizes randomized response techniques with sliding windows to facilitate
the sharing of appliance-level energy consumption data over time while not
revealing individual users' appliance usage patterns. Our evaluations show that
LDP-SmartEnergy runs efficiently compared to baseline methods. The results also
demonstrate that our solution strikes a balance between protecting privacy and
maintaining the utility of data for effective analysis.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04547" title="Abstract">arXiv:2311.04547</a> [<a href="/pdf/2311.04547" title="Download PDF">pdf</a>, <a href="/format/2311.04547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large GPT-like Models are Bad Babies: A Closer Look at the Relationship  between Linguistic Competence and Psycholinguistic Measures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Steuer%2C+J">Julius Steuer</a>, 
<a href="/search/cs?searchtype=author&query=Mosbach%2C+M">Marius Mosbach</a>, 
<a href="/search/cs?searchtype=author&query=Klakow%2C+D">Dietrich Klakow</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Research on the cognitive plausibility of language models (LMs) has so far
mostly concentrated on modelling psycholinguistic response variables such as
reading times, gaze durations and N400/P600 EEG signals, while mostly leaving
out the dimension of what Mahowald et al. (2023) described as formal and
functional linguistic competence, and developmental plausibility. We address
this gap by training a series of GPT-like language models of different sizes on
the strict version of the BabyLM pretraining corpus, evaluating on the
challenge tasks (BLiMP, GLUE, MSGS) and an additional reading time prediction
task. We find a positive correlation between LM size and performance on all
three challenge tasks, with different preferences for model width and depth in
each of the tasks. In contrast, a negative correlation was found between LM
size and reading time fit of linear mixed-effects models using LM surprisal as
a predictor, with the second-smallest LM achieving the largest log-likelihood
reduction over a baseline model without surprisal. This suggests that modelling
processing effort and linguistic competence may require an approach different
from training GPT-like LMs on a developmentally plausible corpus.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04549" title="Abstract">arXiv:2311.04549</a> [<a href="/pdf/2311.04549" title="Download PDF">pdf</a>, <a href="/format/2311.04549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Input to Output: A Multi-layer Knowledge Distillation Framework for  Compressing Recommendation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhangchi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">To reduce the size of recommendation models, there have been many studies on
compressing recommendation models using knowledge distillation. In this paper,
we decompose recommendation models into three layers, i.e., the input layer,
the intermediate layer, and the output layer, and address deficiencies layer by
layer. First, previous methods focus only on two layers, neglecting the input
layer. Second, in the intermediate layer, existing methods ignore the
inconsistency of user preferences induced by the projectors. Third, in the
output layer, existing methods use only hard labels rather than soft labels
from the teacher. To address these deficiencies, we propose
\textbf{M}ulti-layer \textbf{K}nowledge \textbf{D}istillation (MKD), which
consists of three components: 1) Distillation with Neighbor-based Knowledge
(NKD) utilizes the teacher's knowledge about entities with similar
characteristics in the input layer to enable the student to learn robust
representations. 2) Distillation with Consistent Preference (CPD) reduces the
inconsistency of user preferences caused by projectors in the intermediate
layer by two regularization terms. 3) Distillation with Soft Labels (SLD)
constructs soft labels in the output layer by considering the predictions of
both the teacher and the student. Our extensive experiments show that MKD even
outperforms the teacher with one-tenth of the model size.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04550" title="Abstract">arXiv:2311.04550</a> [<a href="/pdf/2311.04550" title="Download PDF">pdf</a>, <a href="/format/2311.04550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regression with Cost-based Rejection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xin Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yuzhou Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haobo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Hongxin Wei</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+B">Bo An</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+L">Lei Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Learning with rejection is an important framework that can refrain from
making predictions to avoid critical mispredictions by balancing between
prediction and rejection. Previous studies on cost-based rejection only focused
on the classification setting, which cannot handle the continuous and infinite
target space in the regression setting. In this paper, we investigate a novel
regression problem called regression with cost-based rejection, where the model
can reject to make predictions on some examples given certain rejection costs.
To solve this problem, we first formulate the expected risk for this problem
and then derive the Bayes optimal solution, which shows that the optimal model
should reject to make predictions on the examples whose variance is larger than
the rejection cost when the mean squared error is used as the evaluation
metric. Furthermore, we propose to train the model by a surrogate loss function
that considers rejection as binary classification and we provide conditions for
the model consistency, which implies that the Bayes optimal solution can be
recovered by our proposed surrogate loss. Extensive experiments demonstrate the
effectiveness of our proposed method.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04551" title="Abstract">arXiv:2311.04551</a> [<a href="/pdf/2311.04551" title="Download PDF">pdf</a>, <a href="/format/2311.04551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing crop diversity across scales using high-resolution remote  sensing over the European Union: first insights for agro-environmental  policies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Machefer%2C+M">Melissande Machefer</a>, 
<a href="/search/cs?searchtype=author&query=Zampieri%2C+M">Matteo Zampieri</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Velde%2C+M">Marijn van der Velde</a>, 
<a href="/search/cs?searchtype=author&query=Dentener%2C+F">Frank Dentener</a>, 
<a href="/search/cs?searchtype=author&query=Claverie%2C+M">Martin Claverie</a>, 
<a href="/search/cs?searchtype=author&query=Andrimont%2C+R+d">Raphael d Andrimont</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Understanding crop diversity is crucial for resilience in farming, ecosystem
services, and effective agro-environmental policies. We utilize a novel EU-wide
satellite product (2018, 10 m resolution) to assess crop diversity across
different scales. We define local crop diversity ($\alpha$-diversity) at 1 km
scale, which in the EU is proportional to the area covered by large farms or
clusters of small-to-medium sized farms. We also compute $\gamma$-diversity,
covering landscape, regional, and national levels crop diversity.
$\beta$-diversity ($\gamma$/$\alpha$) provides a measure of between
agroecosystems diversity. National $\alpha$, $\gamma$, and $\beta$ diversity
varies greatly ($\alpha$: 2.1-3.9, $\gamma$: 3.5-7.5, $\beta$: 1.22-2.27).
EU-wide $\gamma$-diversity increases logarithmically with spatial aggregation
(1 km: 2.85, 100 km: 4.27). We categorize EU Member States (MS) into four
groups for crop diversification policy recommendations. Compared to the USA,
the EU exhibits higher diversity related to differences in farm structure and
practices. High local $\alpha$-diversity is only found for MS with small farms
(&lt;25 ha), but their presence doesn't always guarantee high local diversity.
This study aids CAP implementation in the EU, with potential for annual
continental Copernicus crop type maps and ecosystem co-variates exploration for
a deeper understanding of agro-ecosystem services.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04554" title="Abstract">arXiv:2311.04554</a> [<a href="/pdf/2311.04554" title="Download PDF">pdf</a>, <a href="/format/2311.04554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing Distractors in Multiple-Choice Tests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raina%2C+V">Vatsal Raina</a>, 
<a href="/search/cs?searchtype=author&query=Liusie%2C+A">Adian Liusie</a>, 
<a href="/search/cs?searchtype=author&query=Gales%2C+M">Mark Gales</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 4th Workshop on Evaluation and Comparison of NLP Systems @ AACL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Multiple-choice tests are a common approach for assessing candidates'
comprehension skills. Standard multiple-choice reading comprehension exams
require candidates to select the correct answer option from a discrete set
based on a question in relation to a contextual passage. For appropriate
assessment, the distractor answer options must by definition be incorrect but
plausible and diverse. However, generating good quality distractors satisfying
these criteria is a challenging task for content creators. We propose automated
assessment metrics for the quality of distractors in multiple-choice reading
comprehension tests. Specifically, we define quality in terms of the
incorrectness, plausibility and diversity of the distractor options. We assess
incorrectness using the classification ability of a binary multiple-choice
reading comprehension system. Plausibility is assessed by considering the
distractor confidence - the probability mass associated with the distractor
options for a standard multi-class multiple-choice reading comprehension
system. Diversity is assessed by pairwise comparison of an embedding-based
equivalence metric between the distractors of a question. To further validate
the plausibility metric we compare against candidate distributions over
multiple-choice questions and agreement with a ChatGPT model's interpretation
of distractor plausibility and diversity.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04559" title="Abstract">arXiv:2311.04559</a> [<a href="/pdf/2311.04559" title="Download PDF">pdf</a>, <a href="/format/2311.04559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Individual and gender inequality in computer science: A career study of  cohorts from 1970 to 2000
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lietz%2C+H">Haiko Lietz</a>, 
<a href="/search/cs?searchtype=author&query=Jadidi%2C+M">Mohsen Jadidi</a>, 
<a href="/search/cs?searchtype=author&query=Kostic%2C+D">Daniel Kostic</a>, 
<a href="/search/cs?searchtype=author&query=Tsvetkova%2C+M">Milena Tsvetkova</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+C">Claudia Wagner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in Quantitative Science Studies. 33 pages, 7 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Inequality prevails in science. Individual inequality means that most perish
quickly and only a few are successful, while gender inequality implies that
there are differences in achievements for women and men. Using large-scale
bibliographic data and following a computational approach, we study the
evolution of individual and gender inequality for cohorts from 1970 to 2000 in
the whole field of computer science as it grows and becomes a team-based
science. We find that individual inequality in productivity (publications)
increases over a scholar's career but is historically invariant, while
individual inequality in impact (citations), albeit larger, is stable across
cohorts and careers. Gender inequality prevails regarding productivity, but
there is no evidence for differences in impact. The Matthew Effect is shown to
accumulate advantages to early achievements and to become stronger over the
decades, indicating the rise of a "publish or perish" imperative. Only some
authors manage to reap the benefits that publishing in teams promises. The
Matthew Effect then amplifies initial differences and propagates the gender
gap. Women continue to fall behind because they continue to be at a higher risk
of dropping out for reasons that have nothing to do with early-career
achievements or social support. Our findings suggest that mentoring programs
for women to improve their social-networking skills can help to reduce gender
inequality.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04561" title="Abstract">arXiv:2311.04561</a> [<a href="/pdf/2311.04561" title="Download PDF">pdf</a>, <a href="/format/2311.04561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information-Theoretic Generalization Bounds for Transductive Learning  and its Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Huayi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">In this paper, we develop data-dependent and algorithm-dependent
generalization bounds for transductive learning algorithms in the context of
information theory for the first time. We show that the generalization gap of
transductive learning algorithms can be bounded by the mutual information
between training labels and hypothesis. By innovatively proposing the concept
of transductive supersamples, we go beyond the inductive learning setting and
establish upper bounds in terms of various information measures. Furthermore,
we derive novel PAC-Bayesian bounds and build the connection between
generalization and loss landscape flatness under the transductive learning
setting. Finally, we present the upper bounds for adaptive optimization
algorithms and demonstrate the applications of results on semi-supervised
learning and graph learning scenarios. Our theoretic results are validated on
both synthetic and real-world datasets.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04562" title="Abstract">arXiv:2311.04562</a> [<a href="/pdf/2311.04562" title="Download PDF">pdf</a>, <a href="/format/2311.04562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAIS-DMA: A Decision-Making Assistant for Collaborative AI Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rimawi%2C+D">Diaeddin Rimawi</a>, 
<a href="/search/cs?searchtype=author&query=Lotta%2C+A">Antonio Lotta</a>, 
<a href="/search/cs?searchtype=author&query=Todescato%2C+M">Marco Todescato</a>, 
<a href="/search/cs?searchtype=author&query=Russo%2C+B">Barbara Russo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at PROFES 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">A Collaborative Artificial Intelligence System (CAIS) is a cyber-physical
system that learns actions in collaboration with humans in a shared environment
to achieve a common goal. In particular, a CAIS is equipped with an AI model to
support the decision-making process of this collaboration. When an event
degrades the performance of CAIS (i.e., a disruptive event), this
decision-making process may be hampered or even stopped. Thus, it is of
paramount importance to monitor the learning of the AI model, and eventually
support its decision-making process in such circumstances. This paper
introduces a new methodology to automatically support the decision-making
process in CAIS when the system experiences performance degradation after a
disruptive event. To this aim, we develop a framework that consists of three
components: one manages or simulates CAIS's environment and disruptive events,
the second automates the decision-making process, and the third provides a
visual analysis of CAIS behavior. Overall, our framework automatically monitors
the decision-making process, intervenes whenever a performance degradation
occurs, and recommends the next action. We demonstrate our framework by
implementing an example with a real-world collaborative robot, where the
framework recommends the next action that balances between minimizing the
recovery time (i.e., resilience), and minimizing the energy adverse effects
(i.e., greenness).
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04563" title="Abstract">arXiv:2311.04563</a> [<a href="/pdf/2311.04563" title="Download PDF">pdf</a>, <a href="/format/2311.04563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating the Nature of Disagreements on Mid-Scale Ratings: A Case  Study on the Abstractness-Concreteness Continuum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Knuple%C5%A1%2C+U">Urban Knuple&#x161;</a>, 
<a href="/search/cs?searchtype=author&query=Frassinelli%2C+D">Diego Frassinelli</a>, 
<a href="/search/cs?searchtype=author&query=Walde%2C+S+S+i">Sabine Schulte im Walde</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 13 figures, accepted to CoNLL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Humans tend to strongly agree on ratings on a scale for extreme cases (e.g.,
a CAT is judged as very concrete), but judgements on mid-scale words exhibit
more disagreement. Yet, collected rating norms are heavily exploited across
disciplines. Our study focuses on concreteness ratings and (i) implements
correlations and supervised classification to identify salient multi-modal
characteristics of mid-scale words, and (ii) applies a hard clustering to
identify patterns of systematic disagreement across raters. Our results suggest
to either fine-tune or filter mid-scale target words before utilising them.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04569" title="Abstract">arXiv:2311.04569</a> [<a href="/pdf/2311.04569" title="Download PDF">pdf</a>, <a href="/format/2311.04569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GResilience: Trading Off Between the Greenness and the Resilience of  Collaborative AI Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rimawi%2C+D">Diaeddin Rimawi</a>, 
<a href="/search/cs?searchtype=author&query=Liotta%2C+A">Antonio Liotta</a>, 
<a href="/search/cs?searchtype=author&query=Todescato%2C+M">Marco Todescato</a>, 
<a href="/search/cs?searchtype=author&query=Russo%2C+B">Barbara Russo</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Testing Software and Systems. ICTSS 2023. Lecture Notes in
  Computer Science, vol 14131. Springer, Cham
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">A Collaborative Artificial Intelligence System (CAIS) works with humans in a
shared environment to achieve a common goal. To recover from a disruptive event
that degrades its performance and ensures its resilience, a CAIS may then need
to perform a set of actions either by the system, by the humans, or
collaboratively together. As for any other system, recovery actions may cause
energy adverse effects due to the additional required energy. Therefore, it is
of paramount importance to understand which of the above actions can better
trade-off between resilience and greenness. In this in-progress work, we
propose an approach to automatically evaluate CAIS recovery actions for their
ability to trade-off between the resilience and greenness of the system. We
have also designed an experiment protocol and its application to a real CAIS
demonstrator. Our approach aims to attack the problem from two perspectives: as
a one-agent decision problem through optimization, which takes the decision
based on the score of resilience and greenness, and as a two-agent decision
problem through game theory, which takes the decision based on the payoff
computed for resilience and greenness as two players of a cooperative game.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04573" title="Abstract">arXiv:2311.04573</a> [<a href="/pdf/2311.04573" title="Download PDF">pdf</a>, <a href="/format/2311.04573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RAMIEL: A Parallel-Wire Driven Monopedal Robot for High and Continuous  Jumping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+T">Temma Suzuki</a>, 
<a href="/search/cs?searchtype=author&query=Toshimitsu%2C+Y">Yasunori Toshimitsu</a>, 
<a href="/search/cs?searchtype=author&query=Nagamatsu%2C+Y">Yuya Nagamatsu</a>, 
<a href="/search/cs?searchtype=author&query=Kawaharazuka%2C+K">Kento Kawaharazuka</a>, 
<a href="/search/cs?searchtype=author&query=Miki%2C+A">Akihiro Miki</a>, 
<a href="/search/cs?searchtype=author&query=Ribayashi%2C+Y">Yoshimoto Ribayashi</a>, 
<a href="/search/cs?searchtype=author&query=Bando%2C+M">Masahiro Bando</a>, 
<a href="/search/cs?searchtype=author&query=Kojima%2C+K">Kunio Kojima</a>, 
<a href="/search/cs?searchtype=author&query=Kakiuchi%2C+Y">Yohei Kakiuchi</a>, 
<a href="/search/cs?searchtype=author&query=Okada%2C+K">Kei Okada</a>, 
<a href="/search/cs?searchtype=author&query=Inaba%2C+M">Masayuki Inaba</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at IROS2022 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 2022, website - <a href="https://tenrobo18.github.io/ramiel-iros2022/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Legged robots with high locomotive performance have been extensively studied,
and various leg structures have been proposed. Especially, a leg structure that
can achieve both continuous and high jumps is advantageous for moving around in
a three-dimensional environment. In this study, we propose a parallel
wire-driven leg structure, which has one DoF of linear motion and two DoFs of
rotation and is controlled by six wires, as a structure that can achieve both
continuous jumping and high jumping. The proposed structure can simultaneously
achieve high controllability on each DoF, long acceleration distance and high
power required for jumping. In order to verify the jumping performance of the
parallel wire-driven leg structure, we have developed a parallel wire-driven
monopedal robot, RAMIEL. RAMIEL is equipped with quasi-direct drive, high power
wire winding mechanisms and a lightweight leg, and can achieve a maximum
jumping height of 1.6 m and a maximum of seven continuous jumps.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04574" title="Abstract">arXiv:2311.04574</a> [<a href="/pdf/2311.04574" title="Download PDF">pdf</a>, <a href="/ps/2311.04574" title="Download PostScript">ps</a>, <a href="/format/2311.04574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simple and Asymptotically Optimal Online Bipartite Edge Coloring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blikstad%2C+J">Joakim Blikstad</a>, 
<a href="/search/cs?searchtype=author&query=Svensson%2C+O">Ola Svensson</a>, 
<a href="/search/cs?searchtype=author&query=Vintan%2C+R">Radu Vintan</a>, 
<a href="/search/cs?searchtype=author&query=Wajc%2C+D">David Wajc</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, to appear in SOSA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We provide a simple online $\Delta(1+o(1))$-edge-coloring algorithm for
bipartite graphs of maximum degree $\Delta=\omega(\log n)$ under adversarial
vertex arrivals on one side of the graph. Our algorithm slightly improves the
result of (Cohen, Peng and Wajc, FOCS19), which was the first, and currently
only, to obtain an asymptotically optimal $\Delta(1+o(1))$ guarantee for an
adversarial arrival model. More importantly, our algorithm provides a new,
simpler approach for tackling online edge coloring.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04578" title="Abstract">arXiv:2311.04578</a> [<a href="/pdf/2311.04578" title="Download PDF">pdf</a>, <a href="/format/2311.04578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Version of q-ary Varshamov-Tenengolts Codes with More Efficient  Encoders: The Differential VT Codes and The Differential Shifted VT Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+T">Tuan Thanh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+K">Kui Cai</a>, 
<a href="/search/cs?searchtype=author&query=Siegel%2C+P+H">Paul H. Siegel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2212.10721">arXiv:2212.10721</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">The problem of correcting deletions and insertions has recently received
significantly increased attention due to the DNA-based data storage technology,
which suffers from deletions and insertions with extremely high probability. In
this work, we study the problem of constructing non-binary
burst-deletion/insertion correcting codes. Particularly, for the quaternary
alphabet, our designed codes are suited for correcting a burst of
deletions/insertions in DNA storage.
<br />Non-binary codes correcting a single deletion or insertion were introduced by
Tenengolts [1984], and the results were extended to correct a fixed-length
burst of deletions or insertions by Schoeny et al. [2017]. Recently, Wang et
al. [2021] proposed constructions of non-binary codes of length n, correcting a
burst of length at most two for q-ary alphabets with redundancy log n+O(log q
log log n) bits, for arbitrary even q. The common idea in those constructions
is to convert non-binary sequences into binary sequences, and the error
decoding algorithms for the q-ary sequences are mainly based on the success of
recovering the corresponding binary sequences, respectively. In this work, we
look at a natural solution in which the error detection and correction
algorithms are performed directly over q-ary sequences, and for certain cases,
our codes provide a more efficient encoder with lower redundancy than the
best-known encoder in the literature.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04579" title="Abstract">arXiv:2311.04579</a> [<a href="/pdf/2311.04579" title="Download PDF">pdf</a>, <a href="/ps/2311.04579" title="Download PostScript">ps</a>, <a href="/format/2311.04579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text Finder Application for Android
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Godase%2C+D+M">Dr. Milind Godase</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+D+C">Dr. Chandrani Singh</a>, 
<a href="/search/cs?searchtype=author&query=Dhongadi%2C+K">Kunal Dhongadi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">A Text Finder, an android application that utilizes Optical Character
Recognition (OCR) technology with the help of Google Cloud Vision API to
extract text from images taken with the device camera or from existing images
in the users phone. The extracted text can be saved to the device storage where
all previous extracts can be easily accessed on a user-friendly interface. The
application also features editing, deletion and sharing options for the
extracted text. The user interface is user-friendly, making the application
accessible to students, professional and organizations for a variety of
purposes, including document scanning, data entry, and information retrieval.
Manual extraction of text by typing or writing from images can be very
time-consuming and can be prone to errors. This application is an efficient and
simple solution for extracted texts and organizing important information from
the photos. This paper describes the technical details of the OCR technology
and Googles ML Kit Text Recognition API used in the application, as well as the
design, implementation and evaluation of the application in terms of
performance and accuracy. The research also explores the key objectives and
benefits of Text Finder, such as reducing the time and effort required and
increasing the efficiency of document-based tasks.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04581" title="Abstract">arXiv:2311.04581</a> [<a href="/pdf/2311.04581" title="Download PDF">pdf</a>, <a href="/format/2311.04581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KiD: A Hardware Design Framework Targeting Unified NTT Multiplication  for CRYSTALS-Kyber and CRYSTALS-Dilithium on FPGA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mandal%2C+S">Suraj Mandal</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+D+B">Debapriya Basu Roy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Large-degree polynomial multiplication is an integral component of
post-quantum secure lattice-based cryptographic algorithms like CRYSTALS-Kyber
and Dilithium. The computational complexity of large-degree polynomial
multiplication can be reduced significantly through Number Theoretic
Transformation (NTT). In this paper, we aim to develop a unified and shared NTT
architecture that can support polynomial multiplication for both CRYSTALS-Kyber
and Dilithium. More specifically, in this paper, we have proposed three
different unified architectures for NTT multiplication in CRYSTALS-Kyber and
Dilithium with varying numbers of configurable radix-2 butterfly units.
Additionally, the developed implementation is coupled with a conflict-free
memory mapping scheme that allows the architecture to be fully pipelined. We
have validated our implementation on Artix-7, Zynq-7000 and Zynq Ultrascale+
FPGAs. Our standalone implementations for NTT multiplication for CRYSTALS-Kyber
and Dilithium perform better than the existing works, and our unified
architecture shows excellent area and timing performance compared to both
standalone and existing unified implementations. This architecture can
potentially be used for compact and efficient implementation for CRYSTALS-Kyber
and Dilithium.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04584" title="Abstract">arXiv:2311.04584</a> [<a href="/pdf/2311.04584" title="Download PDF">pdf</a>, <a href="/format/2311.04584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly-supervised deepfake localization in diffusion-generated images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tantaru%2C+D">Dragos Tantaru</a>, 
<a href="/search/cs?searchtype=author&query=Oneata%2C+E">Elisabeta Oneata</a>, 
<a href="/search/cs?searchtype=author&query=Oneata%2C+D">Dan Oneata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The remarkable generative capabilities of denoising diffusion models have
raised new concerns regarding the authenticity of the images we see every day
on the Internet. However, the vast majority of existing deepfake detection
models are tested against previous generative approaches (e.g. GAN) and usually
provide only a "fake" or "real" label per image. We believe a more informative
output would be to augment the per-image label with a localization map
indicating which regions of the input have been manipulated. To this end, we
frame this task as a weakly-supervised localization problem and identify three
main categories of methods (based on either explanations, local scores or
attention), which we compare on an equal footing by using the Xception network
as the common backbone architecture. We provide a careful analysis of all the
main factors that parameterize the design space: choice of method, type of
supervision, dataset and generator used in the creation of manipulated images;
our study is enabled by constructing datasets in which only one of the
components is varied. Our results show that weakly-supervised localization is
attainable, with the best performing detection method (based on local scores)
being less sensitive to the looser supervision than to the mismatch in terms of
dataset or generator.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04587" title="Abstract">arXiv:2311.04587</a> [<a href="/pdf/2311.04587" title="Download PDF">pdf</a>, <a href="/format/2311.04587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Log Statements Generation via Deep Learning: Widening the Support  Provided to Developers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mastropaolo%2C+A">Antonio Mastropaolo</a>, 
<a href="/search/cs?searchtype=author&query=Ferrari%2C+V">Valentina Ferrari</a>, 
<a href="/search/cs?searchtype=author&query=Pascarella%2C+L">Luca Pascarella</a>, 
<a href="/search/cs?searchtype=author&query=Bavota%2C+G">Gabriele Bavota</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Logging assists in monitoring events that transpire during the execution of
software. Previous research has highlighted the challenges confronted by
developers when it comes to logging, including dilemmas such as where to log,
what data to record, and which log level to employ (e.g., info, fatal). In this
context, we introduced LANCE, an approach rooted in deep learning (DL) that has
demonstrated the ability to correctly inject a log statement into Java methods
in ~15% of cases. Nevertheless, LANCE grapples with two primary constraints:
(i) it presumes that a method necessitates the inclusion of logging statements
and; (ii) it allows the injection of only a single (new) log statement, even in
situations where the injection of multiple log statements might be essential.
To address these limitations, we present LEONID, a DL-based technique that can
distinguish between methods that do and do not require the inclusion of log
statements. Furthermore, LEONID supports the injection of multiple log
statements within a given method when necessary, and it also enhances LANCE's
proficiency in generating meaningful log messages through the combination of DL
and Information Retrieval (IR).
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04588" title="Abstract">arXiv:2311.04588</a> [<a href="/pdf/2311.04588" title="Download PDF">pdf</a>, <a href="/format/2311.04588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Army of Thieves: Enhancing Black-Box Model Extraction via Ensemble based  sample selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jindal%2C+A">Akshit Jindal</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+V">Vikram Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Anand%2C+S">Saket Anand</a>, 
<a href="/search/cs?searchtype=author&query=Arora%2C+C">Chetan Arora</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures, paper accepted to WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Machine Learning (ML) models become vulnerable to Model Stealing Attacks
(MSA) when they are deployed as a service. In such attacks, the deployed model
is queried repeatedly to build a labelled dataset. This dataset allows the
attacker to train a thief model that mimics the original model. To maximize
query efficiency, the attacker has to select the most informative subset of
data points from the pool of available data. Existing attack strategies utilize
approaches like Active Learning and Semi-Supervised learning to minimize costs.
However, in the black-box setting, these approaches may select sub-optimal
samples as they train only one thief model. Depending on the thief model's
capacity and the data it was pretrained on, the model might even select noisy
samples that harm the learning process. In this work, we explore the usage of
an ensemble of deep learning models as our thief model. We call our attack Army
of Thieves(AOT) as we train multiple models with varying complexities to
leverage the crowd's wisdom. Based on the ensemble's collective decision,
uncertain samples are selected for querying, while the most confident samples
are directly included in the training data. Our approach is the first one to
utilize an ensemble of thief models to perform model extraction. We outperform
the base approaches of existing state-of-the-art methods by at least 3% and
achieve a 21% higher adversarial sample transferability than previous work for
models trained on the CIFAR-10 dataset.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04589" title="Abstract">arXiv:2311.04589</a> [<a href="/pdf/2311.04589" title="Download PDF">pdf</a>, <a href="/format/2311.04589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TEAL: Tokenize and Embed ALL for Multi-modal Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingxue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+F">Fandong Meng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Multi-modal, Large Language Models, Tokenizer, Understanding and Generation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Despite Multi-modal Large Language Models (MM-LLMs) have made exciting
strides recently, they are still struggling to efficiently model the
interactions among multi-modal inputs and the generation in non-textual
modalities. In this work, we propose TEAL (Tokenize and Embed ALl)}, an
approach to treat the input from any modality as a token sequence and learn a
joint embedding space for all modalities. Specifically, for the input from any
modality, TEAL first discretizes it into a token sequence with the
off-the-shelf tokenizer and embeds the token sequence into a joint embedding
space with a learnable embedding matrix. MM-LLMs just need to predict the
multi-modal tokens autoregressively as the textual LLMs do. Finally, the
corresponding de-tokenizer is applied to generate the output in each modality
based on the predicted token sequence. With the joint embedding space, TEAL
enables the frozen LLMs to perform both understanding and generation tasks
involving non-textual modalities, such as image and audio. Thus, the textual
LLM can just work as an interface and maintain its high performance in textual
understanding and generation. Experiments show that TEAL achieves substantial
improvements in multi-modal understanding, and implements a simple scheme for
multi-modal generations.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04590" title="Abstract">arXiv:2311.04590</a> [<a href="/pdf/2311.04590" title="Download PDF">pdf</a>, <a href="/format/2311.04590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Cross-Domain Sequential Recommendation under Open-World  Assumptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wujiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qitian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Runzhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ha%2C+M">Mingming Ha</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Q">Qiongxu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Linxun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bing Han</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Cross-Domain Sequential Recommendation (CDSR) methods aim to tackle the data
sparsity and cold-start problems present in Single-Domain Sequential
Recommendation (SDSR). Existing CDSR works design their elaborate structures
relying on overlapping users to propagate the cross-domain information.
However, current CDSR methods make closed-world assumptions, assuming fully
overlapping users across multiple domains and that the data distribution
remains unchanged from the training environment to the test environment. As a
result, these methods typically result in lower performance on online
real-world platforms due to the data distribution shifts. To address these
challenges under open-world assumptions, we design an \textbf{A}daptive
\textbf{M}ulti-\textbf{I}nterest \textbf{D}ebiasing framework for cross-domain
sequential recommendation (\textbf{AMID}), which consists of a multi-interest
information module (\textbf{MIM}) and a doubly robust estimator (\textbf{DRE}).
Our framework is adaptive for open-world environments and can improve the model
of most off-the-shelf single-domain sequential backbone models for CDSR. Our
MIM establishes interest groups that consider both overlapping and
non-overlapping users, allowing us to effectively explore user intent and
explicit interest. To alleviate biases across multiple domains, we developed
the DRE for the CDSR methods. We also provide a theoretical analysis that
demonstrates the superiority of our proposed estimator in terms of bias and
tail bound, compared to the IPS estimator used in previous work.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04591" title="Abstract">arXiv:2311.04591</a> [<a href="/pdf/2311.04591" title="Download PDF">pdf</a>, <a href="/format/2311.04591" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Event-based Human Pose Estimation with 3D Event  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xiaoting Yin</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Hao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiaan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ze Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yaozu Ye</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+H">Huajian Ni</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kailun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kaiwei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of <a href="/abs/2206.04511">arXiv:2206.04511</a>. The code and dataset are available at <a href="https://github.com/MasterHow/EventPointPose">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM); Robotics (cs.RO); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Human pose estimation is a critical component in autonomous driving and
parking, enhancing safety by predicting human actions. Traditional frame-based
cameras and videos are commonly applied, yet, they become less reliable in
scenarios under high dynamic range or heavy motion blur. In contrast, event
cameras offer a robust solution for navigating these challenging contexts.
Predominant methodologies incorporate event cameras into learning frameworks by
accumulating events into event frames. However, such methods tend to
marginalize the intrinsic asynchronous and high temporal resolution
characteristics of events. This disregard leads to a loss in essential temporal
dimension data, crucial for safety-critical tasks associated with dynamic human
activities. To address this issue and to unlock the 3D potential of event
information, we introduce two 3D event representations: the Rasterized Event
Point Cloud (RasEPC) and the Decoupled Event Voxel (DEV). The RasEPC collates
events within concise temporal slices at identical positions, preserving 3D
attributes with statistical cues and markedly mitigating memory and
computational demands. Meanwhile, the DEV representation discretizes events
into voxels and projects them across three orthogonal planes, utilizing
decoupled event attention to retrieve 3D cues from the 2D planes. Furthermore,
we develop and release EV-3DPW, a synthetic event-based dataset crafted to
facilitate training and quantitative analysis in outdoor scenes. On the public
real-world DHP19 dataset, our event point cloud technique excels in real-time
mobile predictions, while the decoupled event voxel method achieves the highest
accuracy. Experiments reveal our proposed 3D representation methods' superior
generalization capacities against traditional RGB images and event frame
techniques. Our code and dataset are available at
https://github.com/MasterHow/EventPointPose.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04592" title="Abstract">arXiv:2311.04592</a> [<a href="/pdf/2311.04592" title="Download PDF">pdf</a>, <a href="/format/2311.04592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Characterizing the Evolution of Embedding Space of Neural Networks  using Algebraic Topology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suresh%2C+S">Suryaka Suresh</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+B">Bishshoy Das</a>, 
<a href="/search/cs?searchtype=author&query=Abrol%2C+V">Vinayak Abrol</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+S+D">Sumantra Dutta Roy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We study how the topology of feature embedding space changes as it passes
through the layers of a well-trained deep neural network (DNN) through Betti
numbers. Motivated by existing studies using simplicial complexes on shallow
fully connected networks (FCN), we present an extended analysis using Cubical
homology instead, with a variety of popular deep architectures and real image
datasets. We demonstrate that as depth increases, a topologically complicated
dataset is transformed into a simple one, resulting in Betti numbers attaining
their lowest possible value. The rate of decay in topological complexity (as a
metric) helps quantify the impact of architectural choices on the
generalization ability. Interestingly from a representation learning
perspective, we highlight several invariances such as topological invariance of
(1) an architecture on similar datasets; (2) embedding space of a dataset for
architectures of variable depth; (3) embedding space to input resolution/size,
and (4) data sub-sampling. In order to further demonstrate the link between
expressivity \&amp; the generalization capability of a network, we consider the
task of ranking pre-trained models for downstream classification task (transfer
learning). Compared to existing approaches, the proposed metric has a better
correlation to the actually achievable accuracy via fine-tuning the pre-trained
model.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04599" title="Abstract">arXiv:2311.04599</a> [<a href="/pdf/2311.04599" title="Download PDF">pdf</a>, <a href="/format/2311.04599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Market Value in Professional Soccer: Insights from  Explainable Machine Learning Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chunyang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shaoliang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9pages, 5figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Computational Finance (q-fin.CP)

</div>
<p class="mathjax">This study presents an innovative method for predicting the market value of
professional soccer players using explainable machine learning models. Using a
dataset curated from the FIFA website, we employ an ensemble machine learning
approach coupled with Shapley Additive exPlanations (SHAP) to provide detailed
explanations of the models' predictions. The GBDT model achieves the highest
mean R-Squared (0.8780) and the lowest mean Root Mean Squared Error
(3,221,632.175), indicating its superior performance among the evaluated
models. Our analysis reveals that specific skills such as ball control, short
passing, finishing, interceptions, dribbling, and tackling are paramount within
the skill dimension, whereas sprint speed and acceleration are critical in the
fitness dimension, and reactions are preeminent in the cognitive dimension. Our
results offer a more accurate, objective, and consistent framework for market
value estimation, presenting useful insights for managerial decisions in player
transfers.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04603" title="Abstract">arXiv:2311.04603</a> [<a href="/pdf/2311.04603" title="Download PDF">pdf</a>, <a href="/format/2311.04603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigating Resource Conflicts: Co-opetition and Fairness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singhal%2C+S">Shiksha Singhal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD thesis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">In today's dynamic and interconnected world, resource constraints pose
significant challenges across various domains, ranging from networks, logistics
and manufacturing to project management and optimization, etc.
Resource-constrained problems (RCPs) represent a class of complex computational
problems that require efficient allocation and utilization of limited resources
to achieve optimal outcomes. This thesis aims to delve into such problems
involving multiple agents, where agents aim to enhance their own payoffs, or a
neutral moderator aims to maximise the system revenue while distributing the
resources appropriately among all agents. In the former type of problems,
agents may seek collaboration to achieve higher individual shares, resulting in
a cooperative game with competition, i.e., co-opetition. Cooperative and
non-cooperative game theory tools are utilized to analyze such games. On the
other hand, for the latter kind of problems, we use tools from optimization and
Markov decision processes.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04606" title="Abstract">arXiv:2311.04606</a> [<a href="/pdf/2311.04606" title="Download PDF">pdf</a>, <a href="/ps/2311.04606" title="Download PostScript">ps</a>, <a href="/format/2311.04606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accurate Autism Spectrum Disorder prediction using Support Vector  Classifier based on Federated Learning (SVCFL)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohammadifar%2C+A">Ali Mohammadifar</a>, 
<a href="/search/cs?searchtype=author&query=Samadbin%2C+H">Hasan Samadbin</a>, 
<a href="/search/cs?searchtype=author&query=Daliri%2C+A">Arman Daliri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The path to an autism diagnosis can be long and difficult, and delays can
have serious consequences. Artificial intelligence can completely change the
way autism is diagnosed, especially when it comes to situations where it is
difficult to see the first signs of the disease. AI-based diagnostic tools may
help confirm a diagnosis or highlight the need for further testing by analyzing
large volumes of data and uncovering patterns that may not be immediately
apparent to human evaluators. After a successful and timely diagnosis, autism
can be treated through artificial intelligence using various methods. In this
article, by using four datasets and gathering them with the federated learning
method and diagnosing them with the support vector classifier method, the early
diagnosis of this disorder has been discussed. In this method, we have achieved
99% accuracy for predicting autism spectrum disorder and we have achieved 13%
improvement in the results.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04611" title="Abstract">arXiv:2311.04611</a> [<a href="/pdf/2311.04611" title="Download PDF">pdf</a>, <a href="/format/2311.04611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Byzantine-Tolerant Methods for Distributed Variational Inequalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tupitsa%2C+N">Nazarii Tupitsa</a>, 
<a href="/search/cs?searchtype=author&query=Almansoori%2C+A+J">Abdulla Jasem Almansoori</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yanlin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tak%C3%A1%C4%8D%2C+M">Martin Tak&#xe1;&#x10d;</a>, 
<a href="/search/cs?searchtype=author&query=Nandakumar%2C+K">Karthik Nandakumar</a>, 
<a href="/search/cs?searchtype=author&query=Horv%C3%A1th%2C+S">Samuel Horv&#xe1;th</a>, 
<a href="/search/cs?searchtype=author&query=Gorbunov%2C+E">Eduard Gorbunov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023; 69 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Robustness to Byzantine attacks is a necessity for various distributed
training scenarios. When the training reduces to the process of solving a
minimization problem, Byzantine robustness is relatively well-understood.
However, other problem formulations, such as min-max problems or, more
generally, variational inequalities, arise in many modern machine learning and,
in particular, distributed learning tasks. These problems significantly differ
from the standard minimization ones and, therefore, require separate
consideration. Nevertheless, only one work (Adibi et al., 2022) addresses this
important question in the context of Byzantine robustness. Our work makes a
further step in this direction by providing several (provably) Byzantine-robust
methods for distributed variational inequality, thoroughly studying their
theoretical convergence, removing the limitations of the previous work, and
providing numerical comparisons supporting the theoretical findings.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04614" title="Abstract">arXiv:2311.04614</a> [<a href="/pdf/2311.04614" title="Download PDF">pdf</a>, <a href="/format/2311.04614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LuminanceL1Loss: A loss function which measures percieved brightness and  colour differences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Jonge%2C+D">Dominic De Jonge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">We introduce LuminanceL1Loss, a novel loss function designed to enhance the
performance of image restoration tasks. We demonstrate its superiority over MSE
when applied to the Retinexformer, BUIFD and DnCNN architectures. Our proposed
LuminanceL1Loss leverages a unique approach by transforming images into
grayscale and subsequently computing the MSE loss for both grayscale and color
channels. Experimental results demonstrate that this innovative loss function
consistently outperforms traditional methods, showcasing its potential in image
denoising and other related tasks in image reconstruction. It demonstrates
gains up to 4.7dB. The results presented in this study highlight the efficacy
of LuminanceL1Loss for various image restoration tasks.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04615" title="Abstract">arXiv:2311.04615</a> [<a href="/pdf/2311.04615" title="Download PDF">pdf</a>, <a href="/ps/2311.04615" title="Download PostScript">ps</a>, <a href="/format/2311.04615" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discrete stochastic maximal $ L^p $-regularity and convergence of a  spatial semidiscretization for a stochastic parabolic equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+B">Binjie Li</a>, 
<a href="/search/math?searchtype=author&query=Zhou%2C+Q">Qin Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Probability (math.PR)

</div>
<p class="mathjax">We prove that the discrete Laplace operator has a bounded $
H^\infty$-calculus,independent of the spatial mesh size. As an application, we
obtain the discrete stochastic maximal $ L^p $-regularity estimate for a
spatial semidiscretization of a stochastic parabolic equation. In addition, we
derive some (nearly) sharp error estimates for this spatial semidiscretization.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04617" title="Abstract">arXiv:2311.04617</a> [<a href="/pdf/2311.04617" title="Download PDF">pdf</a>, <a href="/format/2311.04617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Patch-Matching with Graph-Based Learning in Street Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=She%2C+R">Rui She</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Q">Qiyu Kang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sijie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tay%2C+W+P">Wee Peng Tay</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+Y+L">Yong Liang Guan</a>, 
<a href="/search/cs?searchtype=author&query=Navarro%2C+D+N">Diego Navarro Navarro</a>, 
<a href="/search/cs?searchtype=author&query=Hartmannsgruber%2C+A">Andreas Hartmannsgruber</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Matching landmark patches from a real-time image captured by an on-vehicle
camera with landmark patches in an image database plays an important role in
various computer perception tasks for autonomous driving. Current methods focus
on local matching for regions of interest and do not take into account spatial
neighborhood relationships among the image patches, which typically correspond
to objects in the environment. In this paper, we construct a spatial graph with
the graph vertices corresponding to patches and edges capturing the spatial
neighborhood information. We propose a joint feature and metric learning model
with graph-based learning. We provide a theoretical basis for the graph-based
loss by showing that the information distance between the distributions
conditioned on matched and unmatched pairs is maximized under our framework. We
evaluate our model using several street-scene datasets and demonstrate that our
approach achieves state-of-the-art matching results.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04625" title="Abstract">arXiv:2311.04625</a> [<a href="/pdf/2311.04625" title="Download PDF">pdf</a>, <a href="/format/2311.04625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Summarization and Evaluation of Feature Refinement  Modules for CTR Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fangye Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yingxu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+H">Hansu Gu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tun Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+L">Li Shang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+N">Ning Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Click-through rate (CTR) prediction is widely used in academia and industry.
Most CTR tasks fall into a feature embedding \&amp; feature interaction paradigm,
where the accuracy of CTR prediction is mainly improved by designing practical
feature interaction structures. However, recent studies have argued that the
fixed feature embedding learned only through the embedding layer limits the
performance of existing CTR models. Some works apply extra modules on top of
the embedding layer to dynamically refine feature representations in different
instances, making it effective and easy to integrate with existing CTR methods.
Despite the promising results, there is a lack of a systematic review and
summarization of this new promising direction on the CTR task. To fill this
gap, we comprehensively summarize and define a new module, namely
\textbf{feature refinement} (FR) module, that can be applied between feature
embedding and interaction layers. We extract 14 FR modules from previous works,
including instances where the FR module was proposed but not clearly defined or
explained. We fully assess the effectiveness and compatibility of existing FR
modules through comprehensive and extensive experiments with over 200 augmented
models and over 4,000 runs for more than 15,000 GPU hours. The results offer
insightful guidelines for researchers, and all benchmarking code and
experimental results are open-sourced. In addition, we present a new
architecture of assigning independent FR modules to separate sub-networks for
parallel CTR models, as opposed to the conventional method of inserting a
shared FR module on top of the embedding layer. Our approach is also supported
by comprehensive experiments demonstrating its effectiveness.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04633" title="Abstract">arXiv:2311.04633</a> [<a href="/pdf/2311.04633" title="Download PDF">pdf</a>, <a href="/format/2311.04633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> General Framework to Evaluate Unlinkability in Biometric Template  Protection Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gomez-Barrero%2C+M">Marta Gomez-Barrero</a>, 
<a href="/search/cs?searchtype=author&query=Galbally%2C+J">Javier Galbally</a>, 
<a href="/search/cs?searchtype=author&query=Rathgeb%2C+C">Christian Rathgeb</a>, 
<a href="/search/cs?searchtype=author&query=Busch%2C+C">Christoph Busch</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Information Forensics and Security, vol. 13,
  no. 6, pp. 1406-1420, June 2018
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The wide deployment of biometric recognition systems in the last two decades
has raised privacy concerns regarding the storage and use of biometric data. As
a consequence, the ISO/IEC 24745 international standard on biometric
information protection has established two main requirements for protecting
biometric templates: irreversibility and unlinkability. Numerous efforts have
been directed to the development and analysis of irreversible templates.
However, there is still no systematic quantitative manner to analyse the
unlinkability of such templates. In this paper we address this shortcoming by
proposing a new general framework for the evaluation of biometric templates'
unlinkability. To illustrate the potential of the approach, it is applied to
assess the unlinkability of four state-of-the-art techniques for biometric
template protection: biometric salting, Bloom filters, Homomorphic Encryption
and block re-mapping. For the last technique, the proposed framework is
compared with other existing metrics to show its advantages.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04634" title="Abstract">arXiv:2311.04634</a> [<a href="/pdf/2311.04634" title="Download PDF">pdf</a>, <a href="/format/2311.04634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VET: Visual Error Tomography for Point Cloud Completion and High-Quality  Neural Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Franke%2C+L">Linus Franke</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%BCckert%2C+D">Darius R&#xfc;ckert</a>, 
<a href="/search/cs?searchtype=author&query=Fink%2C+L">Laura Fink</a>, 
<a href="/search/cs?searchtype=author&query=Innmann%2C+M">Matthias Innmann</a>, 
<a href="/search/cs?searchtype=author&query=Stamminger%2C+M">Marc Stamminger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">In the last few years, deep neural networks opened the doors for big advances
in novel view synthesis. Many of these approaches are based on a (coarse) proxy
geometry obtained by structure from motion algorithms. Small deficiencies in
this proxy can be fixed by neural rendering, but larger holes or missing parts,
as they commonly appear for thin structures or for glossy regions, still lead
to distracting artifacts and temporal instability. In this paper, we present a
novel neural-rendering-based approach to detect and fix such deficiencies. As a
proxy, we use a point cloud, which allows us to easily remove outlier geometry
and to fill in missing geometry without complicated topological operations.
Keys to our approach are (i) a differentiable, blending point-based renderer
that can blend out redundant points, as well as (ii) the concept of Visual
Error Tomography (VET), which allows us to lift 2D error maps to identify
3D-regions lacking geometry and to spawn novel points accordingly. Furthermore,
(iii) by adding points as nested environment maps, our approach allows us to
generate high-quality renderings of the surroundings in the same pipeline. In
our results, we show that our approach can improve the quality of a point cloud
obtained by structure from motion and thus increase novel view synthesis
quality significantly. In contrast to point growing techniques, the approach
can also fix large-scale holes and missing thin structures effectively.
Rendering quality outperforms state-of-the-art methods and temporal stability
is significantly improved, while rendering is possible at real-time frame
rates.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04635" title="Abstract">arXiv:2311.04635</a> [<a href="/pdf/2311.04635" title="Download PDF">pdf</a>, <a href="/format/2311.04635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Deeper, Lighter and Interpretable Cross Network for CTR  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fangye Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+H">Hansu Gu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tun Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+N">Ning Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by Proceedings of the 32nd ACM International Conference on Information and Knowledge Management (CIKM '23). In the Arxiv version, we add additional designs with associated experiments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Click Through Rate (CTR) prediction plays an essential role in recommender
systems and online advertising. It is crucial to effectively model feature
interactions to improve the prediction performance of CTR models. However,
existing methods face three significant challenges. First, while most methods
can automatically capture high-order feature interactions, their performance
tends to diminish as the order of feature interactions increases. Second,
existing methods lack the ability to provide convincing interpretations of the
prediction results, especially for high-order feature interactions, which
limits the trustworthiness of their predictions. Third, many methods suffer
from the presence of redundant parameters, particularly in the embedding layer.
This paper proposes a novel method called Gated Deep Cross Network (GDCN) and a
Field-level Dimension Optimization (FDO) approach to address these challenges.
As the core structure of GDCN, Gated Cross Network (GCN) captures explicit
high-order feature interactions and dynamically filters important interactions
with an information gate in each order. Additionally, we use the FDO approach
to learn condensed dimensions for each field based on their importance.
Comprehensive experiments on five datasets demonstrate the effectiveness,
superiority and interpretability of GDCN. Moreover, we verify the effectiveness
of FDO in learning various dimensions and reducing model parameters. The code
is available on \url{https://github.com/anonctr/GDCN}.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04638" title="Abstract">arXiv:2311.04638</a> [<a href="/pdf/2311.04638" title="Download PDF">pdf</a>, <a href="/format/2311.04638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DAG-Sword: A Simulator of Large-Scale Network Topologies for  DAG-Oriented Proof-of-Work Blockchains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pere%C5%A1%C3%ADni%2C+M">Martin Pere&#x161;&#xed;ni</a>, 
<a href="/search/cs?searchtype=author&query=Hladk%C3%BD%2C+T">Tom&#xe1;&#x161; Hladk&#xfd;</a>, 
<a href="/search/cs?searchtype=author&query=Malinka%2C+K">Kamil Malinka</a>, 
<a href="/search/cs?searchtype=author&query=Homoliak%2C+I">Ivan Homoliak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures, 3 tables, HiCSS'57 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The blockchain brought interesting properties for many practical
applications. However, some properties, such as the transaction processing
throughput remained limited, especially in Proof-of-Work blockchains.
Therefore, several promising directions, such as sharding designs and DAG-based
protocols emerged. In this paper, we focus on DAG-based consensus protocols and
present a discrete-event simulator for them. Our simulator can simulate
realistic blockchain networks created from data of a Bitcoin network, while its
network configuration and topology can be customized. The simulated network
consists of honest and malicious miners. Malicious miners do not make any
attack on consensus itself. Instead, they use a different transaction selection
strategy than honest miners (who select transactions randomly) with the
intention to earn unfairly more profits than honest miners at the cost of
downgrading the protocol performance by duplicate transactions. As a
consequence, this harms the performance of some DAG-based protocols (e.g.,
PHANTOM and GHOSTDAG) in terms of transaction processing throughput, which we
demonstrate in our experiments and extend the results of the related work that
contains a small-scale network of 10 nodes by the results obtained on a
large-scale network with 7000 nodes. Next, we empirically compare different
algorithms for the mempool structure, and we propose a composite mempool
structure that is memory-efficient and thus convenient for simulations of
resource-demanding large-scale networks.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04640" title="Abstract">arXiv:2311.04640</a> [<a href="/pdf/2311.04640" title="Download PDF">pdf</a>, <a href="/format/2311.04640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Object-Centric Learning with Slot Mixture Module
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kirilenko%2C+D">Daniil Kirilenko</a>, 
<a href="/search/cs?searchtype=author&query=Vorobyov%2C+V">Vitaliy Vorobyov</a>, 
<a href="/search/cs?searchtype=author&query=Kovalev%2C+A+K">Alexey K. Kovalev</a>, 
<a href="/search/cs?searchtype=author&query=Panov%2C+A+I">Aleksandr I. Panov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Object-centric architectures usually apply a differentiable module to the
entire feature map to decompose it into sets of entity representations called
slots. Some of these methods structurally resemble clustering algorithms, where
the cluster's center in latent space serves as a slot representation. Slot
Attention is an example of such a method, acting as a learnable analog of the
soft k-means algorithm. Our work employs a learnable clustering method based on
the Gaussian Mixture Model. Unlike other approaches, we represent slots not
only as centers of clusters but also incorporate information about the distance
between clusters and assigned vectors, leading to more expressive slot
representations. Our experiments demonstrate that using this approach instead
of Slot Attention improves performance in object-centric scenarios, achieving
state-of-the-art results in the set property prediction task.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04643" title="Abstract">arXiv:2311.04643</a> [<a href="/pdf/2311.04643" title="Download PDF">pdf</a>, <a href="/format/2311.04643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Software Architecture Recovery with Information Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yiran Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhengzi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chengwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongxu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jianwen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+D">Dong Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Understanding the architecture is vital for effectively maintaining and
managing large software systems. However, as software systems evolve over time,
their architectures inevitably change. To keep up with the change, architects
need to track the implementation-level changes and update the architectural
documentation accordingly, which is time-consuming and error-prone. Therefore,
many automatic architecture recovery techniques have been proposed to ease this
process. Despite efforts have been made to improve the accuracy of architecture
recovery, existing solutions still suffer from two limitations. First, most of
them only use one or two type of information for the recovery, ignoring the
potential usefulness of other sources. Second, they tend to use the information
in a coarse-grained manner, overlooking important details within it. To address
these limitations, we propose SARIF, a fully automated architecture recovery
technique, which incorporates three types of comprehensive information,
including dependencies, code text and folder structure. SARIF can recover
architecture more accurately by thoroughly analyzing the details of each type
of information and adaptively fusing them based on their relevance and quality.
To evaluate SARIF, we collected six projects with published ground-truth
architectures and three open-source projects labeled by our industrial
collaborators. We compared SARIF with nine state-of-the-art techniques using
three commonly-used architecture similarity metrics and two new metrics. The
experimental results show that SARIF is 36.1% more accurate than the best of
the previous techniques on average. By providing comprehensive architecture,
SARIF can help users understand systems effectively and reduce the manual
effort of obtaining ground-truth architectures.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04645" title="Abstract">arXiv:2311.04645</a> [<a href="/pdf/2311.04645" title="Download PDF">pdf</a>, <a href="/format/2311.04645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SKU-Patch: Towards Efficient Instance Segmentation for Unseen Objects in  Auto-Store
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Biqi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+W">Weiliang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiaojie Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xianzhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yun-Hui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+C">Chi-Wing Fu</a>, 
<a href="/search/cs?searchtype=author&query=Heng%2C+P">Pheng-Ann Heng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In large-scale storehouses, precise instance masks are crucial for robotic
bin picking but are challenging to obtain. Existing instance segmentation
methods typically rely on a tedious process of scene collection, mask
annotation, and network fine-tuning for every single Stock Keeping Unit (SKU).
This paper presents SKU-Patch, a new patch-guided instance segmentation
solution, leveraging only a few image patches for each incoming new SKU to
predict accurate and robust masks, without tedious manual effort and model
re-training. Technical-wise, we design a novel transformer-based network with
(i) a patch-image correlation encoder to capture multi-level image features
calibrated by patch information and (ii) a patch-aware transformer decoder with
parallel task heads to generate instance masks. Extensive experiments on four
storehouse benchmarks manifest that SKU-Patch is able to achieve the best
performance over the state-of-the-art methods. Also, SKU-Patch yields an
average of nearly 100% grasping success rate on more than 50 unseen SKUs in a
robot-aided auto-store logistic pipeline, showing its effectiveness and
practicality.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04648" title="Abstract">arXiv:2311.04648</a> [<a href="/pdf/2311.04648" title="Download PDF">pdf</a>, <a href="/format/2311.04648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chrono DEM-Engine: A Discrete Element Method dual-GPU simulator with  customizable contact forces and element shape
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruochun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tagliafierro%2C+B">Bonaventura Tagliafierro</a>, 
<a href="/search/cs?searchtype=author&query=Heuvel%2C+C+V">Colin Vanden Heuvel</a>, 
<a href="/search/cs?searchtype=author&query=Sabarwal1%2C+S">Shlok Sabarwal1</a>, 
<a href="/search/cs?searchtype=author&query=Bakke%2C+L">Luning Bakke</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Y">Yulong Yue</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xin Wei</a>, 
<a href="/search/cs?searchtype=author&query=Serban%2C+R">Radu Serban</a>, 
<a href="/search/cs?searchtype=author&query=Negrut%2C+D">Dan Negrut</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 30 figures, 9 tables. This preprint is submitted to Computer Physics Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Software Engineering (cs.SE); Numerical Analysis (math.NA)

</div>
<p class="mathjax">This paper introduces DEM-Engine, a new submodule of Project Chrono, that is
designed to carry out Discrete Element Method (DEM) simulations. Based on
spherical primitive shapes, DEM-Engine can simulate polydisperse granular
materials and handle complex shapes generated as assemblies of primitives,
referred to as clumps. DEM-Engine has a multi-tier parallelized structure that
is optimized to operate simultaneously on two GPUs. The code uses
custom-defined data types to reduce memory footprint and increase bandwidth. A
novel "delayed contact detection" algorithm allows the decoupling of the
contact detection and force computation, thus splitting the workload into two
asynchronous GPU streams. DEM-Engine uses just-in-time compilation to support
user-defined contact force models. This paper discusses its C++ and Python
interfaces and presents a variety of numerical tests, in which impact forces,
complex-shaped particle flows, and a custom force model are validated
considering well-known benchmark cases. Additionally, the full potential of the
simulator is demonstrated for the investigation of extraterrestrial rover
mobility on granular terrain. The chosen case study demonstrates that
large-scale co-simulations (comprising 11 million elements) spanning 15
seconds, in conjunction with an external multi-body dynamics system, can be
efficiently executed within a day. Lastly, a performance test suggests that
DEM-Engine displays linear scaling up to 150 million elements on two NVIDIA
A100 GPUs.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04649" title="Abstract">arXiv:2311.04649</a> [<a href="/pdf/2311.04649" title="Download PDF">pdf</a>, <a href="/format/2311.04649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AIRIC: Orchestration of Virtualized Radio Access Networks with Noisy  Neighbours
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lozano%2C+J+X+S">J. Xavier Salvat Lozano</a>, 
<a href="/search/cs?searchtype=author&query=Garcia-Saavedra%2C+A">Andres Garcia-Saavedra</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xi Li</a>, 
<a href="/search/cs?searchtype=author&query=Costa-Perez%2C+X">Xavier Costa-Perez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Radio Access Networks virtualization (vRAN) is on its way becoming a reality
driven by the new requirements in mobile networks, such as scalability and cost
reduction. Unfortunately, there is no free lunch but a high price to be paid in
terms of computing overhead introduced by noisy neighbors problem when multiple
virtualized base station instances share computing platforms. In this paper,
first, we thoroughly dissect the multiple sources of computing overhead in a
vRAN, quantifying their different contributions to the overall performance
degradation. Second, we design an AI-driven Radio Intelligent Controller
(AIRIC) to orchestrate vRAN computing resources. AIRIC relies upon a hybrid
neural network architecture combining a relation network (RN) and a deep
Q-Network (DQN) such that: (i) the demand of concurrent virtual base stations
is satisfied considering the overhead posed by the noisy neighbors problem
while the operating costs of the vRAN infrastructure is minimized; and (ii)
dynamically changing contexts in terms of network demand, signal-to-noise ratio
(SNR) and the number of base station instances are efficiently supported. Our
results show that AIRIC performs very closely to an offline optimal oracle,
attaining up to 30% resource savings, and substantially outperforms existing
benchmarks in service guarantees.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04651" title="Abstract">arXiv:2311.04651</a> [<a href="/pdf/2311.04651" title="Download PDF">pdf</a>, <a href="/ps/2311.04651" title="Download PostScript">ps</a>, <a href="/format/2311.04651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Higher-Order Bayesian Networks, Exactly (Extended version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Faggian%2C+C">Claudia Faggian</a>, 
<a href="/search/cs?searchtype=author&query=Pautasso%2C+D">Daniele Pautasso</a>, 
<a href="/search/cs?searchtype=author&query=Vanoni%2C+G">Gabriele Vanoni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Bayesian networks (BNs) are graphical \emph{first-order} probabilistic models
that allow for a compact representation of large probability distributions, and
for efficient inference, both exact and approximate. We introduce a
\emph{higher-order} programming language -- in the idealized form of a
$\lambda$-calculus -- which we prove \emph{sound and complete} w.r.t. BNs: each
BN can be encoded as a term, and conversely each (possibly higher-order and
recursive) program of ground type \emph{compiles} into a BN. The language
allows for the specification of recursive probability models and hierarchical
structures. Moreover, we provide a \emph{compositional} and \emph{cost-aware}
semantics which is based on factors, the standard mathematical tool used in
Bayesian inference. Our results rely on advanced techniques rooted into linear
logic, intersection types, rewriting theory, and Girard's geometry of
interaction, which are here combined in a novel way.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04653" title="Abstract">arXiv:2311.04653</a> [<a href="/pdf/2311.04653" title="Download PDF">pdf</a>, <a href="/format/2311.04653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Focal and Full-Range Attention Based Graph Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Minhong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhenhao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+W">Weiran Cai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The paradigm of Transformers using the self-attention mechanism has
manifested its advantage in learning graph-structured data. Yet, Graph
Transformers are capable of modeling full range dependencies but are often
deficient in extracting information from locality. A common practice is to
utilize Message Passing Neural Networks (MPNNs) as an auxiliary to capture
local information, which however are still inadequate for comprehending
substructures. In this paper, we present a purely attention-based architecture,
namely Focal and Full-Range Graph Transformer (FFGT), which can mitigate the
loss of local information in learning global correlations. The core component
of FFGT is a new mechanism of compound attention, which combines the
conventional full-range attention with K-hop focal attention on ego-nets to
aggregate both global and local information. Beyond the scope of canonical
Transformers, the FFGT has the merit of being more substructure-aware. Our
approach enhances the performance of existing Graph Transformers on various
open datasets, while achieves compatible SOTA performance on several Long-Range
Graph Benchmark (LRGB) datasets even with a vanilla transformer. We further
examine influential factors on the optimal focal length of attention via
introducing a novel synthetic dataset based on SBM-PATTERN.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04655" title="Abstract">arXiv:2311.04655</a> [<a href="/pdf/2311.04655" title="Download PDF">pdf</a>, <a href="/ps/2311.04655" title="Download PostScript">ps</a>, <a href="/format/2311.04655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two new algorithms for solving M&#xfc;ller games and their applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+Z">Zihui Liang</a>, 
<a href="/search/cs?searchtype=author&query=Khoussainov%2C+B">Bakh Khoussainov</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+M">Mingyu Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">M\"uller games form a well-established class of games for model checking and
verification. These games are played on directed graphs $\mathcal G$ where
Player 0 and Player 1 play by generating an infinite path through the graph.
The winner is determined by the set $X$ consisting of all vertices in the path
that occur infinitely often. If $X$ belongs to $\Omega$, a specified collection
of subsets of $\mathcal G$, then Player 0 wins. Otherwise, Player 1 claims the
win. These games are determined, enabling the partitioning of $\mathcal G$ into
two sets $W_0$ and $W_1$ of winning positions for Player 0 and Player 1,
respectively. Numerous algorithms exist that decide M\"uller games $\mathcal G$
by computing the sets $W_0$ and $W_1$. In this paper, we introduce two novel
algorithms that outperform all previously known methods for deciding explicitly
given M\"uller games, especially in the worst-case scenarios. The previously
known algorithms either reduce M\"uller games to other known games (e.g. safety
games) or recursively change the underlying graph $\mathcal G$ and the
collection of sets in $\Omega$. In contrast, our approach does not employ these
techniques but instead leverages subgames, the sets within $\Omega$, and their
interactions. This distinct methodology sets our algorithms apart from prior
approaches for deciding M\"uller games. Additionally, our algorithms offer
enhanced clarity and ease of comprehension. Importantly, our techniques are
applicable not only to M\"uller games but also to improving the performance of
existing algorithms that handle other game classes, including coloured M\"uller
games, McNaughton games, Rabin games, and Streett games.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04658" title="Abstract">arXiv:2311.04658</a> [<a href="/pdf/2311.04658" title="Download PDF">pdf</a>, <a href="/format/2311.04658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mass Adoption of NATs: Survey and experiments on carrier-grade NATs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kanaris%2C+O">Orestis Kanaris</a>, 
<a href="/search/cs?searchtype=author&query=Pouwelse%2C+J">Johan Pouwelse</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 11 fifures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">In recent times, the prevalence of home NATs and the widespread
implementation of Carrier-Grade NATs have posed significant challenges to
various applications, particularly those relying on Peer-to-Peer communication.
This paper addresses these issues by conducting a thorough review of related
literature and exploring potential techniques to mitigate the problems. The
literature review focuses on the disruptive effects of home NATs and CGNATs on
application performance. Additionally, the study examines existing approaches
used to alleviate these disruptions. Furthermore, this paper presents a
comprehensive guide on how to puncture a NAT and facilitate direct
communication between two peers behind any type of NAT. The techniques outlined
in the guide are rigorously tested using a simple application running the IPv8
network overlay, along with their built-in NAT penetration procedures. To
evaluate the effectiveness of the proposed techniques, 5G communication is
established between two phones using four different Dutch telephone carriers.
The results indicate successful cross-connectivity with three out of the four
carriers tested, showcasing the practical applicability of the suggested
methods.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04659" title="Abstract">arXiv:2311.04659</a> [<a href="/pdf/2311.04659" title="Download PDF">pdf</a>, <a href="/format/2311.04659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pragmatic Reasoning Unlocks Quantifier Semantics for Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Menon%2C+R+R">Rakesh R. Menon</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Sayan Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+S">Shashank Srivastava</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Generalized quantifiers (e.g., few, most) are used to indicate the
proportions predicates are satisfied (for example, some apples are red). One
way to interpret quantifier semantics is to explicitly bind these satisfactions
with percentage scopes (e.g., 30%-40% of apples are red). This approach can be
helpful for tasks like logic formalization and surface-form quantitative
reasoning (Gordon and Schubert, 2010; Roy et al., 2015). However, it remains
unclear if recent foundation models possess this ability, as they lack direct
training signals. To explore this, we introduce QuRe, a crowd-sourced dataset
of human-annotated generalized quantifiers in Wikipedia sentences featuring
percentage-equipped predicates. We explore quantifier comprehension in language
models using PRESQUE, a framework that combines natural language inference and
the Rational Speech Acts framework. Experimental results on the HVD dataset and
QuRe illustrate that PRESQUE, employing pragmatic reasoning, performs 20%
better than a literal reasoning baseline when predicting quantifier percentage
scopes, with no additional training required.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04661" title="Abstract">arXiv:2311.04661</a> [<a href="/pdf/2311.04661" title="Download PDF">pdf</a>, <a href="/format/2311.04661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Massive Editing for Large Language Models via Meta Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Chenmien Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Ge Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">While large language models (LLMs) have enabled learning knowledge from the
pre-training corpora, the acquired knowledge may be fundamentally incorrect or
outdated over time, which necessitates rectifying the knowledge of the language
model (LM) after the training. A promising approach involves employing a
hyper-network to generate parameter shift, whereas existing hyper-networks
suffer from inferior scalability in synchronous editing operation amount. To
mitigate the problem, we propose the MAssive Language Model Editing Network
(MALMEN), which formulates the parameter shift aggregation as the least square
problem, subsequently updating the LM parameters using the normal equation. To
accommodate editing multiple facts simultaneously with limited memory budgets,
we separate the computation on the hyper-network and LM, enabling arbitrary
batch size on both neural networks. Our method is evaluated by editing up to
thousands of facts on LMs with different architectures, i.e., BERT-base, GPT-2,
T5-XL (2.8B), and GPT-J (6B), across various knowledge-intensive NLP tasks,
i.e., closed book fact-checking and question answering. Remarkably, MALMEN is
capable of editing hundreds of times more facts than strong baselines with the
identical hyper-network architecture and outperforms editor specifically
designed for GPT. Our code is available at
https://github.com/ChenmienTan/malmen.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04662" title="Abstract">arXiv:2311.04662</a> [<a href="/pdf/2311.04662" title="Download PDF">pdf</a>, <a href="/format/2311.04662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Versatile Airborne Ultrasonic NDT Technologies via Active Omni-Sliding  with Over-Actuated Aerial Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hui%2C+T">Tong Hui</a>, 
<a href="/search/cs?searchtype=author&query=Braun%2C+F">Florian Braun</a>, 
<a href="/search/cs?searchtype=author&query=Scheidt%2C+N">Nicolas Scheidt</a>, 
<a href="/search/cs?searchtype=author&query=Fehr%2C+M">Marius Fehr</a>, 
<a href="/search/cs?searchtype=author&query=Fumagalli%2C+M">Matteo Fumagalli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper presents the utilization of advanced methodologies in aerial
manipulation to address meaningful industrial applications and develop
versatile ultrasonic Non-Destructive Testing (NDT) technologies with aerial
robots. The primary objectives of this work are to enable multi-point
measurements through sliding without re-approaching the work surface, and
facilitate the representation of material thickness with B and C scans via
dynamic scanning in arbitrary directions (i.e. omnidirections). To accomplish
these objectives, a payload that can slide in omnidirections (here we call the
omni-sliding payload) is designed for an over-actuated aerial vehicle, ensuring
truly omnidirectional sliding mobility while exerting consistent forces in
contact with a flat work surface. The omni-sliding payload is equipped with an
omniwheel-based active end-effector and an Electro Magnetic Acoustic Transducer
(EMAT). Furthermore, to ensure successful development of the designed payload
and integration with the aerial vehicle, a comprehensive studying on contact
conditions and system dynamics during active sliding is presented, and the
derived system constraints are later used as guidelines for the hardware
development and control setting. The proposed methods are validated through
experiments, encompassing both the wall-sliding task and dynamic scanning for
Ultrasonic Testing (UT), employing the aerial platform - Voliro T.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04664" title="Abstract">arXiv:2311.04664</a> [<a href="/pdf/2311.04664" title="Download PDF">pdf</a>, <a href="/format/2311.04664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speech language models lack important brain-relevant semantics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oota%2C+S+R">Subba Reddy Oota</a>, 
<a href="/search/cs?searchtype=author&query=%C3%87elik%2C+E">Emin &#xc7;elik</a>, 
<a href="/search/cs?searchtype=author&query=Deniz%2C+F">Fatma Deniz</a>, 
<a href="/search/cs?searchtype=author&query=Toneva%2C+M">Mariya Toneva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Despite known differences between reading and listening in the brain, recent
work has shown that text-based language models predict both text-evoked and
speech-evoked brain activity to an impressive degree. This poses the question
of what types of information language models truly predict in the brain. We
investigate this question via a direct approach, in which we eliminate
information related to specific low-level stimulus features (textual, speech,
and visual) in the language model representations, and observe how this
intervention affects the alignment with fMRI brain recordings acquired while
participants read versus listened to the same naturalistic stories. We further
contrast our findings with speech-based language models, which would be
expected to predict speech-evoked brain activity better, provided they model
language processing in the brain well. Using our direct approach, we find that
both text-based and speech-based language models align well with early sensory
regions due to shared low-level features. Text-based models continue to align
well with later language regions even after removing these features, while,
surprisingly, speech-based models lose most of their alignment. These findings
suggest that speech-based models can be further improved to better reflect
brain-like language processing.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04666" title="Abstract">arXiv:2311.04666</a> [<a href="/pdf/2311.04666" title="Download PDF">pdf</a>, <a href="/format/2311.04666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-training LLMs using human-like development data corpus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhardwaj%2C+K">Khushi Bhardwaj</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+R+S">Raj Sanjay Shah</a>, 
<a href="/search/cs?searchtype=author&query=Varma%2C+S">Sashank Varma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CoNLL and CMCL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Pre-trained Large Language Models (LLMs) have shown success in a diverse set
of language inference and understanding tasks. The pre-training stage of LLMs
looks at a large corpus of raw textual data. The BabyLM shared task compares
LLM pre-training to human language acquisition, where the number of tokens seen
by 13-year-old kids is magnitudes smaller than the number of tokens seen by
LLMs. In this work, we pre-train and evaluate LLMs on their ability to learn
contextual word representations using roughly the same number of tokens as seen
by children. We provide a strong set of baselines; with different
architectures, evaluation of changes in performance across epochs, and reported
pre-training metrics for the strict small and strict tracks of the task. We
also try to loosely replicate the RoBERTa baseline given by the task organizers
to observe the training robustness to hyperparameter selection and
replicability. We provide the submission details to the strict and strict-small
tracks in this report.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04678" title="Abstract">arXiv:2311.04678</a> [<a href="/pdf/2311.04678" title="Download PDF">pdf</a>, <a href="/format/2311.04678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly supervised cross-model learning in high-content screening
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gabriel%2C+W">Watkinson Gabriel</a>, 
<a href="/search/cs?searchtype=author&query=Ethan%2C+C">Cohen Ethan</a>, 
<a href="/search/cs?searchtype=author&query=Nicolas%2C+B">Bourriez Nicolas</a>, 
<a href="/search/cs?searchtype=author&query=Ihab%2C+B">Bendidi Ihab</a>, 
<a href="/search/cs?searchtype=author&query=Guillaume%2C+B">Bollot Guillaume</a>, 
<a href="/search/cs?searchtype=author&query=Auguste%2C+G">Genovesio Auguste</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">With the surge in available data from various modalities, there is a growing
need to bridge the gap between different data types. In this work, we introduce
a novel approach to learn cross-modal representations between image data and
molecular representations for drug discovery. We propose EMM and IMM, two
innovative loss functions built on top of CLIP that leverage weak supervision
and cross sites replicates in High-Content Screening. Evaluating our model
against known baseline on cross-modal retrieval, we show that our proposed
approach allows to learn better representations and mitigate batch effect. In
addition, we also present a preprocessing method for the JUMP-CP dataset that
effectively reduce the required space from 85Tb to a mere usable 7Tb size,
still retaining all perturbations and most of the information content.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04686" title="Abstract">arXiv:2311.04686</a> [<a href="/pdf/2311.04686" title="Download PDF">pdf</a>, <a href="/format/2311.04686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust and Communication-Efficient Federated Domain Adaptation via  Random Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhanbo Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuanjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jie Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+J">Jiong Lou</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+T">Tiebin Mi</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+R+C">Robert. C. Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Z">Zhenyu Liao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (stat.ML)

</div>
<p class="mathjax">Modern machine learning (ML) models have grown to a scale where training them
on a single machine becomes impractical. As a result, there is a growing trend
to leverage federated learning (FL) techniques to train large ML models in a
distributed and collaborative manner. These models, however, when deployed on
new devices, might struggle to generalize well due to domain shifts. In this
context, federated domain adaptation (FDA) emerges as a powerful approach to
address this challenge.
<br />Most existing FDA approaches typically focus on aligning the distributions
between source and target domains by minimizing their (e.g., MMD) distance.
Such strategies, however, inevitably introduce high communication overheads and
can be highly sensitive to network reliability.
<br />In this paper, we introduce RF-TCA, an enhancement to the standard Transfer
Component Analysis approach that significantly accelerates computation without
compromising theoretical and empirical performance. Leveraging the
computational advantage of RF-TCA, we further extend it to FDA setting with
FedRF-TCA. The proposed FedRF-TCA protocol boasts communication complexity that
is \emph{independent} of the sample size, while maintaining performance that is
either comparable to or even surpasses state-of-the-art FDA methods. We present
extensive experiments to showcase the superior performance and robustness (to
network condition) of FedRF-TCA.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04688" title="Abstract">arXiv:2311.04688</a> [<a href="/pdf/2311.04688" title="Download PDF">pdf</a>, <a href="/format/2311.04688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single Server Private Information Retrieval Protocols With Codes Over  Rings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bodur%2C+%C5%9E">&#x15e;eyma Bodur</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADnez-Moro%2C+E">Edgar Mart&#xed;nez-Moro</a>, 
<a href="/search/cs?searchtype=author&query=Ruano%2C+D">Diego Ruano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">A Private Information Retrieval (PIR) protocol based on coding theory for a
single server is proposed. It provides computational security against linear
algebra attacks, addressing the main drawback of previous PIR proposals based
on coding theory. The approach involves two types of codes each one over a
different ring, an inner non-free linear code that will be used as a
distinguisher of some elements added to the query matrix, and an outer code
that will be used for generating the query matrix. Moreover, it only uses
modular arithmetic at the server level and the recovering stage if the base
ring chosen for the inner code is $\mathbb Z_m$.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04692" title="Abstract">arXiv:2311.04692</a> [<a href="/pdf/2311.04692" title="Download PDF">pdf</a>, <a href="/format/2311.04692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Analysis of Just-in-Time Compilation in Modern Databases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+M">Miao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhengyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+K">Kongzhang Hao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liuyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chunling Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yi Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A peer-reviewed version of this paper is published on Australasian Database Conference (ADC) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">JIT (Just-in-Time) technology has garnered significant attention for
improving the efficiency of database execution. It offers higher performance by
eliminating interpretation overhead compared to traditional execution engines.
LLVM serves as the primary JIT architecture, which was implemented in
PostgreSQL since version 11. However, recent advancements in WASM-based
databases, such as Mutable, present an alternative JIT approach. This approach
minimizes the extensive engineering efforts associated with the execution
engine and focuses on optimizing supported operators for lower latency and
higher throughput. In this paper, we perform comprehensive experiments on these
two representative open-source databases to gain deeper insights into the
effectiveness of different JIT architectures.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04694" title="Abstract">arXiv:2311.04694</a> [<a href="/pdf/2311.04694" title="Download PDF">pdf</a>, <a href="/format/2311.04694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Generative Ad Hoc Information Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gienapp%2C+L">Lukas Gienapp</a>, 
<a href="/search/cs?searchtype=author&query=Scells%2C+H">Harrisen Scells</a>, 
<a href="/search/cs?searchtype=author&query=Deckers%2C+N">Niklas Deckers</a>, 
<a href="/search/cs?searchtype=author&query=Bevendorff%2C+J">Janek Bevendorff</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kiesel%2C+J">Johannes Kiesel</a>, 
<a href="/search/cs?searchtype=author&query=Syed%2C+S">Shahbaz Syed</a>, 
<a href="/search/cs?searchtype=author&query=Fr%C3%B6be%2C+M">Maik Fr&#xf6;be</a>, 
<a href="/search/cs?searchtype=author&query=Zucoon%2C+G">Guide Zucoon</a>, 
<a href="/search/cs?searchtype=author&query=Stein%2C+B">Benno Stein</a>, 
<a href="/search/cs?searchtype=author&query=Hagen%2C+M">Matthias Hagen</a>, 
<a href="/search/cs?searchtype=author&query=Potthast%2C+M">Martin Potthast</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Recent advances in large language models have enabled the development of
viable generative information retrieval systems. A generative retrieval system
returns a grounded generated text in response to an information need instead of
the traditional document ranking. Quantifying the utility of these types of
responses is essential for evaluating generative retrieval systems. As the
established evaluation methodology for ranking-based ad hoc retrieval may seem
unsuitable for generative retrieval, new approaches for reliable, repeatable,
and reproducible experimentation are required. In this paper, we survey the
relevant information retrieval and natural language processing literature,
identify search tasks and system architectures in generative retrieval, develop
a corresponding user model, and study its operationalization. This theoretical
analysis provides a foundation and new insights for the evaluation of
generative ad hoc retrieval systems.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04698" title="Abstract">arXiv:2311.04698</a> [<a href="/pdf/2311.04698" title="Download PDF">pdf</a>, <a href="/format/2311.04698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Challenging Common Assumptions in Multi-task Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elich%2C+C">Cathrin Elich</a>, 
<a href="/search/cs?searchtype=author&query=Kirchdorfer%2C+L">Lukas Kirchdorfer</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6hler%2C+J+M">Jan M. K&#xf6;hler</a>, 
<a href="/search/cs?searchtype=author&query=Schott%2C+L">Lukas Schott</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> -
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">While multi-task learning (MTL) has gained significant attention in recent
years, its underlying mechanisms remain poorly understood. Recent methods did
not yield consistent performance improvements over single task learning (STL)
baselines, underscoring the importance of gaining more profound insights about
challenges specific to MTL. In our study, we challenge common assumptions in
MTL in the context of STL: First, the choice of optimizer has only been mildly
investigated in MTL. We show the pivotal role of common STL tools such as the
Adam optimizer in MTL. We deduce the effectiveness of Adam to its partial
loss-scale invariance. Second, the notion of gradient conflicts has often been
phrased as a specific problem in MTL. We delve into the role of gradient
conflicts in MTL and compare it to STL. For angular gradient alignment we find
no evidence that this is a unique problem in MTL. We emphasize differences in
gradient magnitude as the main distinguishing factor. Lastly, we compare the
transferability of features learned through MTL and STL on common image
corruptions, and find no conclusive evidence that MTL leads to superior
transferability. Overall, we find surprising similarities between STL and MTL
suggesting to consider methods from both fields in a broader context.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04699" title="Abstract">arXiv:2311.04699</a> [<a href="/pdf/2311.04699" title="Download PDF">pdf</a>, <a href="/ps/2311.04699" title="Download PostScript">ps</a>, <a href="/format/2311.04699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Pose Estimation of Tomato Peduncle Nodes using Deep Keypoint  Detection and Point Cloud
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ci%2C+J">Jianchao Ci</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Rapado-Rinc%C3%B3n%2C+D">David Rapado-Rinc&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Burusa%2C+A+K">Akshay K. Burusa</a>, 
<a href="/search/cs?searchtype=author&query=Kootstra%2C+G">Gert Kootstra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 8 figures, 7 tables. Agricultural Biosystems Engineering Group, Department of Plant Sciences, 7 Wageningen University and Research, P.O. Box 16, Wageningen, 6700AA, 8 the Netherlands
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Greenhouse production of fruits and vegetables in developed countries is
challenged by labor 12 scarcity and high labor costs. Robots offer a good
solution for sustainable and cost-effective 13 production. Acquiring accurate
spatial information about relevant plant parts is vital for 14 successful robot
operation. Robot perception in greenhouses is challenging due to variations in
15 plant appearance, viewpoints, and illumination. This paper proposes a
keypoint-detection-based 16 method using data from an RGB-D camera to estimate
the 3D pose of peduncle nodes, which 17 provides essential information to
harvest the tomato bunches. 18 19 Specifically, this paper proposes a method
that detects four anatomical landmarks in the color 20 image and then
integrates 3D point-cloud information to determine the 3D pose. A 21
comprehensive evaluation was conducted in a commercial greenhouse to gain
insight into the 22 performance of different parts of the method. The results
showed: (1) high accuracy in object 23 detection, achieving an Average
Precision (AP) of AP@0.5=0.96; (2) an average Percentage of 24 Detected Joints
(PDJ) of the keypoints of PhDJ@0.2=94.31%; and (3) 3D pose estimation 25
accuracy with mean absolute errors (MAE) of 11.38o and 9.93o for the relative
upper and lower 26 angles between the peduncle and main stem, respectively.
Furthermore, the capability to handle 27 variations in viewpoint was
investigated, demonstrating the method was robust to view changes. 28 However,
canonical and higher views resulted in slightly higher performance compared to
other 29 views. Although tomato was selected as a use case, the proposed method
is also applicable to 30 other greenhouse crops like pepper.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04705" title="Abstract">arXiv:2311.04705</a> [<a href="/pdf/2311.04705" title="Download PDF">pdf</a>, <a href="/format/2311.04705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Negotiation Strategies in Ubiquitous Human-Computer Interaction: A Novel  Storyboards Scale &amp; Field Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yfantidou%2C+S">Sofia Yfantidou</a>, 
<a href="/search/cs?searchtype=author&query=Yfantidou%2C+G">Georgia Yfantidou</a>, 
<a href="/search/cs?searchtype=author&query=Balaska%2C+P">Panagiota Balaska</a>, 
<a href="/search/cs?searchtype=author&query=Vakali%2C+A">Athena Vakali</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">In today's connected society, self-tracking technologies (STTs), such as
wearables and mobile fitness apps, empower humans to improve their health and
well-being through ubiquitous physical activity monitoring, with several
personal and societal benefits. Despite the advances in such technologies'
hardware, low user engagement and decreased effectiveness limitations demand
more informed and theoretically-founded Human-Computer Interaction designs. To
address these challenges, we build upon the previously unexplored Leisure
Constraints Negotiation Model and the Transtheoretical Model to systematically
define and assess the effectiveness of STTs' features that acknowledge users'
contextual constraints and establish human-negotiated STTs narratives.
Specifically, we introduce and validate a human-centric scale, StoryWear, which
exploits and explores eleven dimensions of negotiation strategies that humans
utilize to overcome constraints regarding exercise participation, captured
through an inclusive storyboards format. Based on our preliminary studies,
StoryWear shows high reliability, rendering it suitable for future work in
ubiquitous computing. Our results indicate that negotiation strategies vary in
perceived effectiveness and have higher appeal for existing STTs' users, with
self-motivation, commitment, and understanding of the negative impact of
non-exercise placed at the top. Finally, we give actionable guidelines for
real-world implementation and a commentary on the future of personalized
training.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04707" title="Abstract">arXiv:2311.04707</a> [<a href="/pdf/2311.04707" title="Download PDF">pdf</a>, <a href="/format/2311.04707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Where Do We Meet? Key Factors Influencing Collaboration Across Meeting  Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Valadez%2C+I">Isaac Valadez</a>, 
<a href="/search/cs?searchtype=author&query=Trullemans%2C+S">Sandra Trullemans</a>, 
<a href="/search/cs?searchtype=author&query=Signer%2C+B">Beat Signer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Over the past years, there has been a shift towards online and hybrid meeting
forms in workplace environments, partly as a consequence of various COVID-19
restrictions. However, the decision-making process on how to best collaborate
with team members is predominantly driven by practical concerns. While there is
a significant body of literature about where to best meet, this knowledge is
fragmented across various disciplines and hard to use in novel meeting
solutions. We present the Cross-Space Collaboration model which identifies the
main factors that drive the features of in-person collaboration and the meeting
aspects that influence these factors such as cognitive load. We designed the
model to give guidance to teams and individuals on how to meet in order to have
a higher collaboration effectiveness. Finally, we outline how the model can
bring added value within new meeting solutions, next generation virtual reality
meeting spaces and educational settings.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04710" title="Abstract">arXiv:2311.04710</a> [<a href="/pdf/2311.04710" title="Download PDF">pdf</a>, <a href="/format/2311.04710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Quest for Content: A Survey of Search-Based Procedural Content  Generation for Video Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zamorano%2C+M">Mar Zamorano</a>, 
<a href="/search/cs?searchtype=author&query=Cetina%2C+C">Carlos Cetina</a>, 
<a href="/search/cs?searchtype=author&query=Sarro%2C+F">Federica Sarro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Video games demand is constantly increasing, which requires the costly
production of large amounts of content. Towards this challenge, researchers
have developed Search-Based Procedural Content Generation (SBPCG), that is, the
(semi-)automated creation of content through search algorithms. We survey the
current state of SBPCG, reporting work appeared in the field between 2011-2022
and identifying open research challenges. The results lead to recommendations
for practitioners and to the identification of several potential future
research avenues for SBPCG.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04711" title="Abstract">arXiv:2311.04711</a> [<a href="/pdf/2311.04711" title="Download PDF">pdf</a>, <a href="/ps/2311.04711" title="Download PostScript">ps</a>, <a href="/format/2311.04711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training CLIP models on Data from Scientific Papers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Metzger%2C+C">Calvin Metzger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023 Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Contrastive Language-Image Pretraining (CLIP) models are able to capture the
semantic relationship of images and texts and have enabled a wide range of
applications, from image retrieval to classification. These models are trained
with datasets extracted from web crawls, which are of large quantity but
limited quality. This paper explores whether limited amounts higher quality
data in a specific domain improve the general performance of CLIP models. To
this purpose, we extract text-image data from scientific papers hosted in the
arXiv and PubMed Central repositories. Experiments on small-scale CLIP models
(ViT B/32) show that model performance increases on average, but only
moderately. This result indicates that using the data sources considered in the
paper to train large-scale CLIP models is a worthwile research direction.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04726" title="Abstract">arXiv:2311.04726</a> [<a href="/pdf/2311.04726" title="Download PDF">pdf</a>, <a href="/format/2311.04726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Social Motion Prediction with Cognitive Hierarchies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wentao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+J">Jason Qin</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+Y">Yuke Lou</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Hang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaoxuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ci%2C+H">Hai Ci</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yizhou Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Humans exhibit a remarkable capacity for anticipating the actions of others
and planning their own actions accordingly. In this study, we strive to
replicate this ability by addressing the social motion prediction problem. We
introduce a new benchmark, a novel formulation, and a cognition-inspired
framework. We present Wusi, a 3D multi-person motion dataset under the context
of team sports, which features intense and strategic human interactions and
diverse pose distributions. By reformulating the problem from a multi-agent
reinforcement learning perspective, we incorporate behavioral cloning and
generative adversarial imitation learning to boost learning efficiency and
generalization. Furthermore, we take into account the cognitive aspects of the
human social action planning process and develop a cognitive hierarchy
framework to predict strategic human social interactions. We conduct
comprehensive experiments to validate the effectiveness of our proposed dataset
and approach. Code and data are available at
https://walter0807.github.io/Social-CH/.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04730" title="Abstract">arXiv:2311.04730</a> [<a href="/pdf/2311.04730" title="Download PDF">pdf</a>, <a href="/format/2311.04730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Properties of Nodes via Community-Aware Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kami%C5%84ski%2C+B">Bogumi&#x142; Kami&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Pra%C5%82at%2C+P">Pawe&#x142; Pra&#x142;at</a>, 
<a href="/search/cs?searchtype=author&query=Th%C3%A9berge%2C+F">Fran&#xe7;ois Th&#xe9;berge</a>, 
<a href="/search/cs?searchtype=author&query=Zaj%C4%85c%2C+S">Sebastian Zaj&#x105;c</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 3 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG); Combinatorics (math.CO)

</div>
<p class="mathjax">A community structure that is often present in complex networks plays an
important role not only in their formation but also shapes dynamics of these
networks, affecting properties of their nodes. In this paper, we propose a
family of community-aware node features and then investigate their properties.
We show that they have high predictive power for classification tasks. We also
verify that they contain information that cannot be recovered neither by
classical node features nor by node embeddings (both classical as well as
structural).
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04731" title="Abstract">arXiv:2311.04731</a> [<a href="/pdf/2311.04731" title="Download PDF">pdf</a>, <a href="/format/2311.04731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Best-arm Identification in Linear Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Vakili%2C+S">Sattar Vakili</a>, 
<a href="/search/cs?searchtype=author&query=Bogunovic%2C+I">Ilija Bogunovic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We study the robust best-arm identification problem (RBAI) in the case of
linear rewards. The primary objective is to identify a near-optimal robust arm,
which involves selecting arms at every round and assessing their robustness by
exploring potential adversarial actions. This approach is particularly relevant
when utilizing a simulator and seeking to identify a robust solution for
real-world transfer. To this end, we present an instance-dependent lower bound
for the robust best-arm identification problem with linear rewards.
Furthermore, we propose both static and adaptive bandit algorithms that achieve
sample complexity that matches the lower bound. In synthetic experiments, our
algorithms effectively identify the best robust arm and perform similarly to
the oracle strategy. As an application, we examine diabetes care and the
process of learning insulin dose recommendations that are robust with respect
to inaccuracies in standard calculators. Our algorithms prove to be effective
in identifying robust dosage values across various age ranges of patients.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04740" title="Abstract">arXiv:2311.04740</a> [<a href="/pdf/2311.04740" title="Download PDF">pdf</a>, <a href="/format/2311.04740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Multi-Agent Coordination through Common Operating Picture  Integration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+P">Peihong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+B">Bhoram Lee</a>, 
<a href="/search/cs?searchtype=author&query=Raghavan%2C+A">Aswin Raghavan</a>, 
<a href="/search/cs?searchtype=author&query=Samarasekara%2C+S">Supun Samarasekara</a>, 
<a href="/search/cs?searchtype=author&query=Tokekar%2C+P">Pratap Tokekar</a>, 
<a href="/search/cs?searchtype=author&query=Hare%2C+J+Z">James Zachary Hare</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to OODWorkshop@CoRL23; please see <a href="https://openreview.net/forum?id=fADcJl0B0P">this https URL</a> for the paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">In multi-agent systems, agents possess only local observations of the
environment. Communication between teammates becomes crucial for enhancing
coordination. Past research has primarily focused on encoding local information
into embedding messages which are unintelligible to humans. We find that using
these messages in agent's policy learning leads to brittle policies when tested
on out-of-distribution initial states. We present an approach to multi-agent
coordination, where each agent is equipped with the capability to integrate its
(history of) observations, actions and messages received into a Common
Operating Picture (COP) and disseminate the COP. This process takes into
account the dynamic nature of the environment and the shared mission. We
conducted experiments in the StarCraft2 environment to validate our approach.
Our results demonstrate the efficacy of COP integration, and show that
COP-based training leads to robust policies compared to state-of-the-art
Multi-Agent Reinforcement Learning (MARL) methods when faced with
out-of-distribution initial states.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04742" title="Abstract">arXiv:2311.04742</a> [<a href="/pdf/2311.04742" title="Download PDF">pdf</a>, <a href="/format/2311.04742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using large language models to study human memory for meaningful  narratives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Can%2C+A+G+T">Antonios Georgiou Tankut Can</a>, 
<a href="/search/cs?searchtype=author&query=Katkov%2C+M">Mikhail Katkov</a>, 
<a href="/search/cs?searchtype=author&query=Tsodyks%2C+M">Misha Tsodyks</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">One of the most impressive achievements of the AI revolution is the
development of large language models that can generate meaningful text and
respond to instructions in plain English with no additional training necessary.
Here we show that language models can be used as a scientific instrument for
studying human memory for meaningful material. We developed a pipeline for
designing large scale memory experiments and analyzing the obtained results. We
performed online memory experiments with a large number of participants and
collected recognition and recall data for narratives of different lengths. We
found that both recall and recognition performance scale linearly with
narrative length. Furthermore, in order to investigate the role of narrative
comprehension in memory, we repeated these experiments using scrambled versions
of the presented stories. We found that even though recall performance declined
significantly, recognition remained largely unaffected. Interestingly, recalls
in this condition seem to follow the original narrative order rather than the
scrambled presentation, pointing to a contextual reconstruction of the story in
memory.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04744" title="Abstract">arXiv:2311.04744</a> [<a href="/pdf/2311.04744" title="Download PDF">pdf</a>, <a href="/format/2311.04744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Euclidean, Projective, Conformal: Choosing a Geometric Algebra for  Equivariant Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Haan%2C+P">Pim de Haan</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+T">Taco Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Brehmer%2C+J">Johann Brehmer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as an extended abstract to the workshop Symmetry and Geometry in Neural Representations (NeurReps) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The Geometric Algebra Transformer (GATr) is a versatile architecture for
geometric deep learning based on projective geometric algebra. We generalize
this architecture into a blueprint that allows one to construct a scalable
transformer architecture given any geometric (or Clifford) algebra. We study
versions of this architecture for Euclidean, projective, and conformal
algebras, all of which are suited to represent 3D data, and evaluate them in
theory and practice. The simplest Euclidean architecture is computationally
cheap, but has a smaller symmetry group and is not as sample-efficient, while
the projective model is not sufficiently expressive. Both the conformal algebra
and an improved version of the projective algebra define powerful, performant
architectures.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04747" title="Abstract">arXiv:2311.04747</a> [<a href="/pdf/2311.04747" title="Download PDF">pdf</a>, <a href="/format/2311.04747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exchanging... Watch out!
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Liu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Woo%2C+J">Jieyeon Woo</a>, 
<a href="/search/cs?searchtype=author&query=Achard%2C+C">Catherine Achard</a>, 
<a href="/search/cs?searchtype=author&query=Pelachaud%2C+C">Catherine Pelachaud</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">During a conversation, individuals take turns speaking and engage in
exchanges, which can occur smoothly or involve interruptions. Listeners have
various ways of participating, such as displaying backchannels, signalling the
aim to take a turn, waiting for the speaker to yield the floor, or even
interrupting and taking over the conversation.
<br />These exchanges are commonplace in natural interactions. To create realistic
and engaging interactions between human participants and embodied
conversational agents (ECAs), it is crucial to equip virtual agents with the
ability to manage these exchanges. This includes being able to initiate or
respond to signals from the human user. In order to achieve this, we annotate,
analyze and characterize these exchanges in human-human conversations. In this
paper, we present an analysis of multimodal features, with a focus on prosodic
features such as pitch (F0) and loudness, as well as facial expressions, to
describe different types of exchanges.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04749" title="Abstract">arXiv:2311.04749</a> [<a href="/pdf/2311.04749" title="Download PDF">pdf</a>, <a href="/format/2311.04749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Min Cost Circulation for Multi-Object Tracking on Fragments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanbing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+J">Junyi Ji</a>, 
<a href="/search/cs?searchtype=author&query=Barbour%2C+W">William Barbour</a>, 
<a href="/search/cs?searchtype=author&query=Work%2C+D+B">Daniel B. Work</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2212.07907">arXiv:2212.07907</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Multi-object tracking (MOT) or global data association problem is commonly
approached as a minimum-cost-flow or minimum-cost-circulation problem on a
graph. While there have been numerous studies aimed at enhancing algorithm
efficiency, most of them focus on the batch problem, where all the data must be
available simultaneously to construct a static graph. However, with the growing
number of applications that generate streaming data, an efficient online
algorithm is required to handle the streaming nature of the input. In this
paper, we present an online extension of the well-known negative cycle
canceling algorithm for solving the multi-object tracking problem with
streaming fragmented data. We provide a proof of correctness for the proposed
algorithm and demonstrate its efficiency through numerical experiments.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04755" title="Abstract">arXiv:2311.04755</a> [<a href="/pdf/2311.04755" title="Download PDF">pdf</a>, <a href="/format/2311.04755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Understanding Emotions in Informal Developer Interactions: A  Gitter Chat Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sajadi%2C+A">Amirali Sajadi</a>, 
<a href="/search/cs?searchtype=author&query=Damevski%2C+K">Kostadin Damevski</a>, 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+P">Preetha Chatterjee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Emotions play a significant role in teamwork and collaborative activities
like software development. While researchers have analyzed developer emotions
in various software artifacts (e.g., issues, pull requests), few studies have
focused on understanding the broad spectrum of emotions expressed in chats. As
one of the most widely used means of communication, chats contain valuable
information in the form of informal conversations, such as negative
perspectives about adopting a tool. In this paper, we present a dataset of
developer chat messages manually annotated with a wide range of emotion labels
(and sub-labels), and analyze the type of information present in those
messages. We also investigate the unique signals of emotions specific to chats
and distinguish them from other forms of software communication. Our findings
suggest that chats have fewer expressions of Approval and Fear but more
expressions of Curiosity compared to GitHub comments. We also notice that
Confusion is frequently observed when discussing programming-related
information such as unexpected software behavior. Overall, our study highlights
the potential of mining emotions in developer chats for supporting software
maintenance and evolution tools.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04760" title="Abstract">arXiv:2311.04760</a> [<a href="/pdf/2311.04760" title="Download PDF">pdf</a>, <a href="/format/2311.04760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Open-world Cross-Domain Sequential Recommendation: A  Model-Agnostic Contrastive Denoising Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wujiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+X">Xuying Ning</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Wenfang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ha%2C+M">Mingming Ha</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Q">Qiongxu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Linxun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bing Han</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+M">Minnan Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Cross-domain sequential recommendation (CDSR) aims to address the data
sparsity problems that exist in traditional sequential recommendation (SR)
systems.
<br />The existing approaches aim to design a specific cross-domain unit that can
transfer and propagate information across multiple domains by relying on
overlapping users with abundant behaviors. However, in real-world recommender
systems, CDSR scenarios usually consist of a majority of long-tailed users with
sparse behaviors and cold-start users who only exist in one domain. This leads
to a drop in the performance of existing CDSR methods in the real-world
industry platform. Therefore, improving the consistency and effectiveness of
models in open-world CDSR scenarios is crucial for constructing CDSR models
(\textit{1st} CH). Recently, some SR approaches have utilized auxiliary
behaviors to complement the information for long-tailed users. However, these
multi-behavior SR methods cannot deliver promising performance in CDSR, as they
overlook the semantic gap between target and auxiliary behaviors, as well as
user interest deviation across domains (\textit{2nd} CH).
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04761" title="Abstract">arXiv:2311.04761</a> [<a href="/pdf/2311.04761" title="Download PDF">pdf</a>, <a href="/ps/2311.04761" title="Download PostScript">ps</a>, <a href="/format/2311.04761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FAIR Knowledge Graphs with Semantic Units: a Prototype
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vogt%2C+L">Lars Vogt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Knowledge graphs and ontologies are becoming increasingly important in the
context of making data and metadata findable, accessible, interoperable, and
reusable (FAIR). We introduce the concept of Semantic Units for organizing
Knowledge Graphs into identifiable and semantically meaningful subgraphs. Each
Semantic Unit is represented in the graph by its own resource that instantiates
a Semantic Unit class. Different types of Semantic Units are distinguished, and
together they can organize a Knowledge Graph into different levels of
representational granularity with partially overlapping, partially enclosed
subgraphs that users of Knowledge Graphs can refer to for making statements
about statements. The use of Semantic Units in Knowledge Graphs supports making
them FAIR and increases the human-reader-actionability of their data and
metadata by increasing the graph's cognitive interoperability by increasing its
explorability for a human reader. We introduce a minimal prototype web
application for a user-driven FAIR Knowledge Graph that is based on Semantic
Units.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04764" title="Abstract">arXiv:2311.04764</a> [<a href="/pdf/2311.04764" title="Download PDF">pdf</a>, <a href="/format/2311.04764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoWS: Automate Weights Streaming in Layer-wise Pipelined DNN  Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhewen Yu</a>, 
<a href="/search/cs?searchtype=author&query=Bouganis%2C+C">Christos-Savvas Bouganis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by DATE2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">With the great success of Deep Neural Networks (DNN), the design of efficient
hardware accelerators has triggered wide interest in the research community.
Existing research explores two architectural strategies: sequential layer
execution and layer-wise pipelining. While the former supports a wider range of
models, the latter is favoured for its enhanced customization and efficiency. A
challenge for the layer-wise pipelining architecture is its substantial demand
for the on-chip memory for weights storage, impeding the deployment of
large-scale networks on resource-constrained devices. This paper introduces
AutoWS, a pioneering memory management methodology that exploits both on-chip
and off-chip memory to optimize weight storage within a layer-wise pipelining
architecture, taking advantage of its static schedule. Through a comprehensive
investigation on both the hardware design and the Design Space Exploration, our
methodology is fully automated and enables the deployment of large-scale DNN
models on resource-constrained devices, which was not possible in existing
works that target layer-wise pipelining architectures. AutoWS is open-source:
https://github.com/Yu-Zhewen/AutoWS
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04765" title="Abstract">arXiv:2311.04765</a> [<a href="/pdf/2311.04765" title="Download PDF">pdf</a>, <a href="/format/2311.04765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The voraus-AD Dataset for Anomaly Detection in Robot Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brockmann%2C+J+T">Jan Thie&#xdf; Brockmann</a>, 
<a href="/search/cs?searchtype=author&query=Rudolph%2C+M">Marco Rudolph</a>, 
<a href="/search/cs?searchtype=author&query=Rosenhahn%2C+B">Bodo Rosenhahn</a>, 
<a href="/search/cs?searchtype=author&query=Wandt%2C+B">Bastian Wandt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 14 figures, accepted to Transactions on Robotics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">During the operation of industrial robots, unusual events may endanger the
safety of humans and the quality of production. When collecting data to detect
such cases, it is not ensured that data from all potentially occurring errors
is included as unforeseeable events may happen over time. Therefore, anomaly
detection (AD) delivers a practical solution, using only normal data to learn
to detect unusual events. We introduce a dataset that allows training and
benchmarking of anomaly detection methods for robotic applications based on
machine data which will be made publicly available to the research community.
As a typical robot task the dataset includes a pick-and-place application which
involves movement, actions of the end effector and interactions with the
objects of the environment. Since several of the contained anomalies are not
task-specific but general, evaluations on our dataset are transferable to other
robotics applications as well. Additionally, we present MVT-Flow (multivariate
time-series flow) as a new baseline method for anomaly detection: It relies on
deep-learning-based density estimation with normalizing flows, tailored to the
data domain by taking its structure into account for the architecture. Our
evaluation shows that MVT-Flow outperforms baselines from previous work by a
large margin of 6.2% in area under ROC.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04766" title="Abstract">arXiv:2311.04766</a> [<a href="/pdf/2311.04766" title="Download PDF">pdf</a>, <a href="/format/2311.04766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DualTalker: A Cross-Modal Dual Learning Approach for Speech-Driven 3D  Facial Animation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+G">Guinan Su</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yanwu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhifeng Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent years, audio-driven 3D facial animation has gained significant
attention, particularly in applications such as virtual reality, gaming, and
video conferencing. However, accurately modeling the intricate and subtle
dynamics of facial expressions remains a challenge. Most existing studies
approach the facial animation task as a single regression problem, which often
fail to capture the intrinsic inter-modal relationship between speech signals
and 3D facial animation and overlook their inherent consistency. Moreover, due
to the limited availability of 3D-audio-visual datasets, approaches learning
with small-size samples have poor generalizability that decreases the
performance. To address these issues, in this study, we propose a cross-modal
dual-learning framework, termed DualTalker, aiming at improving data usage
efficiency as well as relating cross-modal dependencies. The framework is
trained jointly with the primary task (audio-driven facial animation) and its
dual task (lip reading) and shares common audio/motion encoder components. Our
joint training framework facilitates more efficient data usage by leveraging
information from both tasks and explicitly capitalizing on the complementary
relationship between facial motion and audio to improve performance.
Furthermore, we introduce an auxiliary cross-modal consistency loss to mitigate
the potential over-smoothing underlying the cross-modal complementary
representations, enhancing the mapping of subtle facial expression dynamics.
Through extensive experiments and a perceptual user study conducted on the VOCA
and BIWI datasets, we demonstrate that our approach outperforms current
state-of-the-art methods both qualitatively and quantitatively. We have made
our code and video demonstrations available at
https://github.com/sabrina-su/iadf.git.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04767" title="Abstract">arXiv:2311.04767</a> [<a href="/pdf/2311.04767" title="Download PDF">pdf</a>, <a href="/format/2311.04767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpersonal Trust in OSS: Exploring Dimensions of Trust in GitHub Pull  Requests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sajadi%2C+A">Amirali Sajadi</a>, 
<a href="/search/cs?searchtype=author&query=Damevski%2C+K">Kostadin Damevski</a>, 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+P">Preetha Chatterjee</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE/ACM 45th International Conference on Software
  Engineering: New Ideas and Emerging Results (ICSE-NIER)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Interpersonal trust plays a crucial role in facilitating collaborative tasks,
such as software development. While previous research recognizes the
significance of trust in an organizational setting, there is a lack of
understanding in how trust is exhibited in OSS distributed teams, where there
is an absence of direct, in-person communications. To foster trust and
collaboration in OSS teams, we need to understand what trust is and how it is
exhibited in written developer communications (e.g., pull requests, chats). In
this paper, we first investigate various dimensions of trust to identify the
ways trusting behavior can be observed in OSS. Next, we sample a set of 100
GitHub pull requests from Apache Software Foundation (ASF) projects, to analyze
and demonstrate how each dimension of trust can be exhibited. Our findings
provide preliminary insights into cues that might be helpful to automatically
assess team dynamics and establish interpersonal trust in OSS teams, leading to
successful and sustainable OSS.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04770" title="Abstract">arXiv:2311.04770</a> [<a href="/pdf/2311.04770" title="Download PDF">pdf</a>, <a href="/format/2311.04770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vital Sign Forecasting for Sepsis Patients in ICUs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhatti%2C+A">Anubhav Bhatti</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dan%2C+C">Chen Dan</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+B">Bingjie Shen</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">San Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yonghwan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J+Y">Jang Yong Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 3 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Sepsis and septic shock are a critical medical condition affecting millions
globally, with a substantial mortality rate. This paper uses state-of-the-art
deep learning (DL) architectures to introduce a multi-step forecasting system
to predict vital signs indicative of septic shock progression in Intensive Care
Units (ICUs). Our approach utilizes a short window of historical vital sign
data to forecast future physiological conditions. We introduce a DL-based vital
sign forecasting system that predicts up to 3 hours of future vital signs from
6 hours of past data. We further adopt the DILATE loss function to capture
better the shape and temporal dynamics of vital signs, which are critical for
clinical decision-making. We compare three DL models, N-BEATS, N-HiTS, and
Temporal Fusion Transformer (TFT), using the publicly available eICU
Collaborative Research Database (eICU-CRD), highlighting their forecasting
capabilities in a critical care setting. We evaluate the performance of our
models using mean squared error (MSE) and dynamic time warping (DTW) metrics.
Our findings show that while TFT excels in capturing overall trends, N-HiTS is
superior in retaining short-term fluctuations within a predefined range. This
paper demonstrates the potential of deep learning in transforming the
monitoring systems in ICUs, potentially leading to significant improvements in
patient care and outcomes by accurately forecasting vital signs to assist
healthcare providers in detecting early signs of physiological instability and
anticipating septic shock.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04771" title="Abstract">arXiv:2311.04771</a> [<a href="/pdf/2311.04771" title="Download PDF">pdf</a>, <a href="/format/2311.04771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing $H^2$-conforming finite element approximations without having  to implement $C^1$-elements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ainsworth%2C+M">Mark Ainsworth</a>, 
<a href="/search/math?searchtype=author&query=Parker%2C+C">Charles Parker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We develop a method to compute the $H^2$-conforming finite element
approximation to planar fourth order elliptic problems without having to
implement $C^1$ elements. The algorithm consists of replacing the original
$H^2$-conforming scheme with pre-processing and post-processing steps that
require only an $H^1$-conforming Poisson type solve and an inner Stokes-like
problem that again only requires at most $H^1$-conformity. We then demonstrate
the method applied to the Morgan-Scott elements with three numerical examples.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04774" title="Abstract">arXiv:2311.04774</a> [<a href="/pdf/2311.04774" title="Download PDF">pdf</a>, <a href="/format/2311.04774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Unified Framework of Contrastive Learning for Disentangled  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Matthes%2C+S">Stefan Matthes</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhiwei Han</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Hao Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Contrastive learning has recently emerged as a promising approach for
learning data representations that discover and disentangle the explanatory
factors of the data. Previous analyses of such approaches have largely focused
on individual contrastive losses, such as noise-contrastive estimation (NCE)
and InfoNCE, and rely on specific assumptions about the data generating
process. This paper extends the theoretical guarantees for disentanglement to a
broader family of contrastive methods, while also relaxing the assumptions
about the data distribution. Specifically, we prove identifiability of the true
latents for four contrastive losses studied in this paper, without imposing
common independence assumptions. The theoretical findings are validated on
several benchmark datasets. Finally, practical limitations of these methods are
also investigated.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04777" title="Abstract">arXiv:2311.04777</a> [<a href="/pdf/2311.04777" title="Download PDF">pdf</a>, <a href="/format/2311.04777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lidar Annotation Is All You Need
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharafutdinov%2C+D">Dinar Sharafutdinov</a>, 
<a href="/search/cs?searchtype=author&query=Kuskov%2C+S">Stanislav Kuskov</a>, 
<a href="/search/cs?searchtype=author&query=Protasov%2C+S">Saian Protasov</a>, 
<a href="/search/cs?searchtype=author&query=Voropaev%2C+A">Alexey Voropaev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint, 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">In recent years, computer vision has transformed fields such as medical
imaging, object recognition, and geospatial analytics. One of the fundamental
tasks in computer vision is semantic image segmentation, which is vital for
precise object delineation. Autonomous driving represents one of the key areas
where computer vision algorithms are applied. The task of road surface
segmentation is crucial in self-driving systems, but it requires a
labor-intensive annotation process in several data domains. The work described
in this paper aims to improve the efficiency of image segmentation using a
convolutional neural network in a multi-sensor setup. This approach leverages
lidar (Light Detection and Ranging) annotations to directly train image
segmentation models on RGB images. Lidar supplements the images by emitting
laser pulses and measuring reflections to provide depth information. However,
lidar's sparse point clouds often create difficulties for accurate object
segmentation. Segmentation of point clouds requires time-consuming preliminary
data preparation and a large amount of computational resources. The key
innovation of our approach is the masked loss, addressing sparse ground-truth
masks from point clouds. By calculating loss exclusively where lidar points
exist, the model learns road segmentation on images by using lidar points as
ground truth. This approach allows for blending of different ground-truth data
types during model training. Experimental validation of the approach on
benchmark datasets shows comparable performance to a high-quality image
segmentation model. Incorporating lidar reduces the load on annotations and
enables training of image-segmentation models without loss of segmentation
quality. The methodology is tested on diverse datasets, both publicly available
and proprietary. The strengths and weaknesses of the proposed method are also
discussed in the paper.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04778" title="Abstract">arXiv:2311.04778</a> [<a href="/pdf/2311.04778" title="Download PDF">pdf</a>, <a href="/format/2311.04778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Multiple Roles of Ontologies in Explainable AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Confalonieri%2C+R">Roberto Confalonieri</a>, 
<a href="/search/cs?searchtype=author&query=Guizzardi%2C+G">Giancarlo Guizzardi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the Neurosymbolic AI journal: <a href="https://www.neurosymbolic-ai-journal.com/system/files/nai-paper-683.pdf">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This paper discusses the different roles that explicit knowledge, in
particular ontologies, can play in Explainable AI and in the development of
human-centric explainable systems and intelligible explanations. We consider
three main perspectives in which ontologies can contribute significantly,
namely reference modelling, common-sense reasoning, and knowledge refinement
and complexity management. We overview some of the existing approaches in the
literature, and we position them according to these three proposed
perspectives. The paper concludes by discussing what challenges still need to
be addressed to enable ontology-based approaches to explanation and to evaluate
their human-understandability and effectiveness.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04779" title="Abstract">arXiv:2311.04779</a> [<a href="/pdf/2311.04779" title="Download PDF">pdf</a>, <a href="/format/2311.04779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Deep Neural Network Approximation for Korobov Functions with  respect to Sobolev Norms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yang%2C+Y">Yahong Yang</a>, 
<a href="/search/math?searchtype=author&query=Lu%2C+Y">Yulong Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper establishes the nearly optimal rate of approximation for deep
neural networks (DNNs) when applied to Korobov functions, effectively
overcoming the curse of dimensionality. The approximation results presented in
this paper are measured with respect to $L_p$ norms and $H^1$ norms. Our
achieved approximation rate demonstrates a remarkable "super-convergence" rate,
outperforming traditional methods and any continuous function approximator.
These results are non-asymptotic, providing error bounds that consider both the
width and depth of the networks simultaneously.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04783" title="Abstract">arXiv:2311.04783</a> [<a href="/pdf/2311.04783" title="Download PDF">pdf</a>, <a href="/format/2311.04783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VioLA: Aligning Videos to 2D LiDAR Scans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chao%2C+J">Jun-Jee Chao</a>, 
<a href="/search/cs?searchtype=author&query=Engin%2C+S">Selim Engin</a>, 
<a href="/search/cs?searchtype=author&query=Chavan-Dafle%2C+N">Nikhil Chavan-Dafle</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+B">Bhoram Lee</a>, 
<a href="/search/cs?searchtype=author&query=Isler%2C+V">Volkan Isler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We study the problem of aligning a video that captures a local portion of an
environment to the 2D LiDAR scan of the entire environment. We introduce a
method (VioLA) that starts with building a semantic map of the local scene from
the image sequence, then extracts points at a fixed height for registering to
the LiDAR map. Due to reconstruction errors or partial coverage of the camera
scan, the reconstructed semantic map may not contain sufficient information for
registration. To address this problem, VioLA makes use of a pre-trained
text-to-image inpainting model paired with a depth completion model for filling
in the missing scene content in a geometrically consistent fashion to support
pose registration. We evaluate VioLA on two real-world RGB-D benchmarks, as
well as a self-captured dataset of a large office scene. Notably, our proposed
scene completion module improves the pose registration performance by up to
20%.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04787" title="Abstract">arXiv:2311.04787</a> [<a href="/pdf/2311.04787" title="Download PDF">pdf</a>, <a href="/ps/2311.04787" title="Download PostScript">ps</a>, <a href="/format/2311.04787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Why Do Clinical Probabilistic Models Fail To Transport Between Sites?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lasko%2C+T+A">Thomas A. Lasko</a>, 
<a href="/search/cs?searchtype=author&query=Strobl%2C+E+V">Eric V. Strobl</a>, 
<a href="/search/cs?searchtype=author&query=Stead%2C+W+W">William W. Stead</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Performance (cs.PF); Machine Learning (stat.ML)

</div>
<p class="mathjax">The rising popularity of artificial intelligence in healthcare is
highlighting the problem that a computational model achieving super-human
clinical performance at its training sites may perform substantially worse at
new sites. In this perspective, we present common sources for this failure to
transport, which we divide into sources under the control of the experimenter
and sources inherent to the clinical data-generating process. Of the inherent
sources we look a little deeper into site-specific clinical practices that can
affect the data distribution, and propose a potential solution intended to
isolate the imprint of those practices on the data from the patterns of disease
cause and effect that are the usual target of clinical models.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04788" title="Abstract">arXiv:2311.04788</a> [<a href="/pdf/2311.04788" title="Download PDF">pdf</a>, <a href="/format/2311.04788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-efficient Wireless Image Retrieval for IoT Devices by  Transmitting a TinyML Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shiraishi%2C+J">Junya Shiraishi</a>, 
<a href="/search/cs?searchtype=author&query=Thorsager%2C+M">Mathias Thorsager</a>, 
<a href="/search/cs?searchtype=author&query=Pandey%2C+S+R">Shashi Raj Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Popovski%2C+P">Petar Popovski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This work considers a scenario in which an edge server collects data from
Internet of Things (IoT) devices equipped with wake-up receivers. Although this
procedure enables on-demand data collection, there is still energy waste if the
content of the transmitted data following the wake-up is irrelevant. To
mitigate this, we advocate the use of Tiny Machine Learning (ML) to enable a
semantic response from the IoT devices, so they can send only semantically
relevant data. Nevertheless, receiving the ML model and the ML processing at
the IoT devices consumes additional energy. We consider the specific instance
of image retrieval and investigate the gain brought by the proposed scheme in
terms of energy efficiency, considering both the energy cost of introducing the
ML model as well as that of wireless communication. The numerical evaluation
shows that, compared to a baseline scheme, the proposed scheme can realize both
high retrieval accuracy and high energy efficiency, which reaches up to 70%
energy reduction when the number of stored images is equal to or larger than 8.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04789" title="Abstract">arXiv:2311.04789</a> [<a href="/pdf/2311.04789" title="Download PDF">pdf</a>, <a href="/format/2311.04789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Determination of toxic comments and unintended model bias minimization  using Deep learning approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+M+A">Md Azim Khan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Computers and Society (cs.CY)

</div>
<p class="mathjax">Online conversations can be toxic and subjected to threats, abuse, or
harassment. To identify toxic text comments, several deep learning and machine
learning models have been proposed throughout the years. However, recent
studies demonstrate that because of the imbalances in the training data, some
models are more likely to show unintended biases including gender bias and
identity bias. In this research, our aim is to detect toxic comment and reduce
the unintended bias concerning identity features such as race, gender, sex,
religion by fine-tuning an attention based model called BERT(Bidirectional
Encoder Representation from Transformers). We apply weighted loss to address
the issue of unbalanced data and compare the performance of a fine-tuned BERT
model with a traditional Logistic Regression model in terms of classification
and bias minimization. The Logistic Regression model with the TFIDF vectorizer
achieve 57.1% accuracy, and fine-tuned BERT model's accuracy is 89%. Code is
available at
https://github.com/zim10/Determine_Toxic_comment_and_identity_bias.git
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04797" title="Abstract">arXiv:2311.04797</a> [<a href="/pdf/2311.04797" title="Download PDF">pdf</a>, <a href="/format/2311.04797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CloverLeaf on Intel Multi-Core CPUs: A Case Study in Write-Allocate  Evasion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Laukemann%2C+J">Jan Laukemann</a>, 
<a href="/search/cs?searchtype=author&query=Gruber%2C+T">Thomas Gruber</a>, 
<a href="/search/cs?searchtype=author&query=Hager%2C+G">Georg Hager</a>, 
<a href="/search/cs?searchtype=author&query=Oryspayev%2C+D">Dossay Oryspayev</a>, 
<a href="/search/cs?searchtype=author&query=Wellein%2C+G">Gerhard Wellein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages including artifact appendix; 10 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF)

</div>
<p class="mathjax">In this paper we analyze the MPI-only version of the CloverLeaf code from the
SPEChpc 2021 benchmark suite on recent Intel Xeon "Ice Lake" and "Sapphire
Rapids" server CPUs. We observe peculiar breakdowns in performance when the
number of processes is prime. Investigating this effect, we create
first-principles data traffic models for each of the stencil-like hotspot
loops. With application measurements and microbenchmarks to study memory data
traffic behavior, we can connect the breakdowns to SpecI2M, a new
write-allocate evasion feature in current Intel CPUs. We identify conditions
under which SpecI2M works as intended and where it fails to avoid
write-allocate transfers. Write-allocate evasion works best if large arrays are
written consecutively; in the CloverLeaf code, non-temporal stores can be
employed on top for best results. For serial and full-node cases we are able to
predict the memory data volume analytically with an error of a few percent. We
find that if the number of processes is prime, SpecI2M fails to work properly,
which we can attribute to short inner loops emerging from the one-dimensional
domain decomposition in this case. We can also rule out other possible causes
of the prime number effect, such as breaking layer conditions, MPI
communication overhead, and load imbalance.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04798" title="Abstract">arXiv:2311.04798</a> [<a href="/pdf/2311.04798" title="Download PDF">pdf</a>, <a href="/format/2311.04798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tools for Refactoring to Microservices: A Preliminary Usability Report
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fritzsch%2C+J">Jonas Fritzsch</a>, 
<a href="/search/cs?searchtype=author&query=Correia%2C+F">Filipe Correia</a>, 
<a href="/search/cs?searchtype=author&query=Bogner%2C+J">Justus Bogner</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+S">Stefan Wagner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">While Microservices are a preferred choice for modern cloud-based
applications, the migration and architectural refactoring of existing legacy
systems is still a major challenge in industry. To address this, academia has
proposed many strategies and approaches that aim to automate the process of
decomposing a monolith into functional units. In this study, we review existing
migration approaches regarding techniques used and tool support. From 91
publications, we extracted 22 tools, 7 of which address service decomposition.
To assess them from an end-user perspective, we investigated their underlying
techniques, installation, documentation, usability and support. For 5 of them,
we generated service cuts using reference applications. The results of our
preliminary work suggest that the inspected tools pursue promising concepts,
but lack maturity and generalizability for reliable use by industry.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04799" title="Abstract">arXiv:2311.04799</a> [<a href="/pdf/2311.04799" title="Download PDF">pdf</a>, <a href="/format/2311.04799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DACBERT: Leveraging Dependency Agreement for Cost-Efficient Bert  Pretraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuo%2C+M">Martin Kuo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiran Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Building on the cost-efficient pretraining advancements brought about by
Crammed BERT, we enhance its performance and interpretability further by
introducing a novel pretrained model Dependency Agreement Crammed BERT
(DACBERT) and its two-stage pretraining framework - Dependency Agreement
Pretraining. This framework, grounded by linguistic theories, seamlessly weaves
syntax and semantic information into the pretraining process. The first stage
employs four dedicated submodels to capture representative dependency
agreements at the chunk level, effectively converting these agreements into
embeddings. The second stage uses these refined embeddings, in tandem with
conventional BERT embeddings, to guide the pretraining of the rest of the
model. Evaluated on the GLUE benchmark, our DACBERT demonstrates notable
improvement across various tasks, surpassing Crammed BERT by 3.13% in the RTE
task and by 2.26% in the MRPC task. Furthermore, our method boosts the average
GLUE score by 0.83%, underscoring its significant potential. The pretraining
process can be efficiently executed on a single GPU within a 24-hour cycle,
necessitating no supplementary computational resources or extending the
pretraining duration compared with the Crammed BERT. Extensive studies further
illuminate our approach's instrumental role in bolstering the interpretability
of pretrained language models for natural language understanding tasks.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04806" title="Abstract">arXiv:2311.04806</a> [<a href="/pdf/2311.04806" title="Download PDF">pdf</a>, <a href="/format/2311.04806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The PetShop Dataset -- Finding Causes of Performance Issues across  Microservices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hardt%2C+M">Michaela Hardt</a>, 
<a href="/search/cs?searchtype=author&query=Orchard%2C+W">William Orchard</a>, 
<a href="/search/cs?searchtype=author&query=Bl%C3%B6baum%2C+P">Patrick Bl&#xf6;baum</a>, 
<a href="/search/cs?searchtype=author&query=Kasiviswanathan%2C+S">Shiva Kasiviswanathan</a>, 
<a href="/search/cs?searchtype=author&query=Kirschbaum%2C+E">Elke Kirschbaum</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Identifying root causes for unexpected or undesirable behavior in complex
systems is a prevalent challenge. This issue becomes especially crucial in
modern cloud applications that employ numerous microservices. Although the
machine learning and systems research communities have proposed various
techniques to tackle this problem, there is currently a lack of standardized
datasets for quantitative benchmarking. Consequently, research groups are
compelled to create their own datasets for experimentation. This paper
introduces a dataset specifically designed for evaluating root cause analyses
in microservice-based applications. The dataset encompasses latency, requests,
and availability metrics emitted in 5-minute intervals from a distributed
application. In addition to normal operation metrics, the dataset includes 68
injected performance issues, which increase latency and reduce availability
throughout the system. We showcase how this dataset can be used to evaluate the
accuracy of a variety of methods spanning different causal and non-causal
characterisations of the root cause analysis problem. We hope the new dataset,
available at https://github.com/amazon-science/petshop-root-cause-analysis/
enables further development of techniques in this important area.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04808" title="Abstract">arXiv:2311.04808</a> [<a href="/pdf/2311.04808" title="Download PDF">pdf</a>, <a href="/format/2311.04808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Lightweight Architecture for Real-Time Neuronal-Spike Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Siddiqi%2C+M+A">Muhammad Ali Siddiqi</a>, 
<a href="/search/cs?searchtype=author&query=Vrijenhoek%2C+D">David Vrijenhoek</a>, 
<a href="/search/cs?searchtype=author&query=Landsmeer%2C+L+P+L">Lennart P. L. Landsmeer</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Kleij%2C+J">Job van der Kleij</a>, 
<a href="/search/cs?searchtype=author&query=Gebregiorgis%2C+A">Anteneh Gebregiorgis</a>, 
<a href="/search/cs?searchtype=author&query=Romano%2C+V">Vincenzo Romano</a>, 
<a href="/search/cs?searchtype=author&query=Bishnoi%2C+R">Rajendra Bishnoi</a>, 
<a href="/search/cs?searchtype=author&query=Hamdioui%2C+S">Said Hamdioui</a>, 
<a href="/search/cs?searchtype=author&query=Strydis%2C+C">Christos Strydis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">Electrophysiological recordings of neural activity in a mouse's brain are
very popular among neuroscientists for understanding brain function. One
particular area of interest is acquiring recordings from the Purkinje cells in
the cerebellum in order to understand brain injuries and the loss of motor
functions. However, current setups for such experiments do not allow the mouse
to move freely and, thus, do not capture its natural behaviour since they have
a wired connection between the animal's head stage and an acquisition device.
In this work, we propose a lightweight neuronal-spike detection and
classification architecture that leverages on the unique characteristics of the
Purkinje cells to discard unneeded information from the sparse neural data in
real time. This allows the (condensed) data to be easily stored on a removable
storage device on the head stage, alleviating the need for wires. Our proposed
implementation shows a &gt;95% overall classification accuracy while still
resulting in a small-form-factor design, which allows for the free movement of
mice during experiments. Moreover, the power-efficient nature of the design and
the usage of STT-RAM (Spin Transfer Torque Magnetic Random Access Memory) as
the removable storage allows the head stage to easily operate on a tiny battery
for up to approximately 4 days.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04810" title="Abstract">arXiv:2311.04810</a> [<a href="/pdf/2311.04810" title="Download PDF">pdf</a>, <a href="/format/2311.04810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finite Element Methods for the Stretching and Bending of Thin Structures  with Folding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bonito%2C+A">Andrea Bonito</a>, 
<a href="/search/math?searchtype=author&query=Guignard%2C+D">Diane Guignard</a>, 
<a href="/search/math?searchtype=author&query=Morvant%2C+A">Angelique Morvant</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 5 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In [Bonito et al., J. Comput. Phys. (2022)], a local discontinous Galerkin
method was proposed for approximating the large bending of prestrained plates,
and in [Bonito et al., IMA J. Numer. Anal. (2023)] the numerical properties of
this method were explored. These works considered deformations driven
predominantly by bending. Thus, a bending energy with a metric constraint was
considered. We extend these results to the case of an energy with both a
bending component and a nonconvex stretching component, and we also consider
folding across a crease. The proposed discretization of this energy features a
continuous finite element space, as well as a discrete Hessian operator. We
establish the $\Gamma$-convergence of the discrete to the continuous energy and
also present an energy-decreasing gradient flow for finding critical points of
the discrete energy. Finally, we provide numerical simulations illustrating the
convergence of minimizers and the capabilities of the model.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04811" title="Abstract">arXiv:2311.04811</a> [<a href="/pdf/2311.04811" title="Download PDF">pdf</a>, <a href="/format/2311.04811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image-Based Virtual Try-On: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Dan Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuanpu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Juan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+W">Weizhi Nie</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+R">Ruofeng Tong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">An-An Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image-based virtual try-on aims to synthesize a naturally dressed person
image with a clothing image, which revolutionizes online shopping and inspires
related topics within image generation, showing both research significance and
commercial potentials. However, there is a great gap between current research
progress and commercial applications and an absence of comprehensive overview
towards this field to accelerate the development. In this survey, we provide a
comprehensive analysis of the state-of-the-art techniques and methodologies in
aspects of pipeline architecture, person representation and key modules such as
try-on indication, clothing warping and try-on stage. We propose a new semantic
criteria with CLIP, and evaluate representative methods with uniformly
implemented evaluation metrics on the same dataset. In addition to quantitative
and qualitative evaluation of current open-source methods, we also utilize
ControlNet to fine-tune a recent large image generation model (PBE) to show
future potentials of large-scale models on image-based virtual try-on task.
Finally, unresolved issues are revealed and future research directions are
prospected to identify key trends and inspire further exploration. The
uniformly implemented evaluation metrics, dataset and collected methods will be
made public available at
https://github.com/little-misfit/Survey-Of-Virtual-Try-On.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04813" title="Abstract">arXiv:2311.04813</a> [<a href="/pdf/2311.04813" title="Download PDF">pdf</a>, <a href="/format/2311.04813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Be Careful When Evaluating Explanations Regarding Ground Truth
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baniecki%2C+H">Hubert Baniecki</a>, 
<a href="/search/cs?searchtype=author&query=Chrabaszcz%2C+M">Maciej Chrabaszcz</a>, 
<a href="/search/cs?searchtype=author&query=Holzinger%2C+A">Andreas Holzinger</a>, 
<a href="/search/cs?searchtype=author&query=Pfeifer%2C+B">Bastian Pfeifer</a>, 
<a href="/search/cs?searchtype=author&query=Saranti%2C+A">Anna Saranti</a>, 
<a href="/search/cs?searchtype=author&query=Biecek%2C+P">Przemyslaw Biecek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Evaluating explanations of image classifiers regarding ground truth, e.g.
segmentation masks defined by human perception, primarily evaluates the quality
of the models under consideration rather than the explanation methods
themselves. Driven by this observation, we propose a framework for
$\textit{jointly}$ evaluating the robustness of safety-critical systems that
$\textit{combine}$ a deep neural network with an explanation method. These are
increasingly used in real-world applications like medical image analysis or
robotics. We introduce a fine-tuning procedure to (mis)align
model$\unicode{x2013}$explanation pipelines with ground truth and use it to
quantify the potential discrepancy between worst and best-case scenarios of
human alignment. Experiments across various model architectures and post-hoc
local interpretation methods provide insights into the robustness of vision
transformers and the overall vulnerability of such AI systems to potential
adversarial attacks.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04815" title="Abstract">arXiv:2311.04815</a> [<a href="/pdf/2311.04815" title="Download PDF">pdf</a>, <a href="/format/2311.04815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Adaptive Object Detection via Balancing Between Self-Training and  Adversarial Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Munir%2C+M+A">Muhammad Akhtar Munir</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+M+H">Muhammad Haris Khan</a>, 
<a href="/search/cs?searchtype=author&query=Sarfraz%2C+M+S">M. Saquib Sarfraz</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+M">Mohsen Ali</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in IEEE Transactions on Pattern Analysis and Machine Intelligence (Volume: 45, Issue: 12, December 2023). arXiv admin note: substantial text overlap with <a href="/abs/2110.00249">arXiv:2110.00249</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep learning based object detectors struggle generalizing to a new target
domain bearing significant variations in object and background. Most current
methods align domains by using image or instance-level adversarial feature
alignment. This often suffers due to unwanted background and lacks
class-specific alignment. A straightforward approach to promote class-level
alignment is to use high confidence predictions on unlabeled domain as
pseudo-labels. These predictions are often noisy since model is poorly
calibrated under domain shift. In this paper, we propose to leverage model's
predictive uncertainty to strike the right balance between adversarial feature
alignment and class-level alignment. We develop a technique to quantify
predictive uncertainty on class assignments and bounding-box predictions. Model
predictions with low uncertainty are used to generate pseudo-labels for
self-training, whereas the ones with higher uncertainty are used to generate
tiles for adversarial feature alignment. This synergy between tiling around
uncertain object regions and generating pseudo-labels from highly certain
object regions allows capturing both image and instance-level context during
the model adaptation. We report thorough ablation study to reveal the impact of
different components in our approach. Results on five diverse and challenging
adaptation scenarios show that our approach outperforms existing
state-of-the-art methods with noticeable margins.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04816" title="Abstract">arXiv:2311.04816</a> [<a href="/pdf/2311.04816" title="Download PDF">pdf</a>, <a href="/format/2311.04816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MTGER: Multi-view Temporal Graph Enhanced Temporal Reasoning over  Time-Involved Document
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu%2C+Z">Zheng Chu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zekun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jiafeng Liang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Ming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+B">Bing Qin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of EMNLP 2023, long paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The facts and time in the document are intricately intertwined, making
temporal reasoning over documents challenging. Previous work models time
implicitly, making it difficult to handle such complex relationships. To
address this issue, we propose MTGER, a novel Multi-view Temporal Graph
Enhanced Temporal Reasoning framework for temporal reasoning over time-involved
documents. Concretely, MTGER explicitly models the temporal relationships among
facts by multi-view temporal graphs. On the one hand, the heterogeneous
temporal graphs explicitly model the temporal and discourse relationships among
facts; on the other hand, the multi-view mechanism captures both time-focused
and fact-focused information, allowing the two views to complement each other
through adaptive fusion. To further improve the implicit reasoning capability
of the model, we design a self-supervised time-comparing objective. Extensive
experimental results demonstrate the effectiveness of our method on the TimeQA
and SituatedQA datasets. Furthermore, MTGER gives more consistent answers under
question perturbations.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04817" title="Abstract">arXiv:2311.04817</a> [<a href="/pdf/2311.04817" title="Download PDF">pdf</a>, <a href="/format/2311.04817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralized Personalized Online Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Renzhi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+S">Saayan Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+A">Anup Rao</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE BigData 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Vanilla federated learning does not support learning in an online
environment, learning a personalized model on each client, and learning in a
decentralized setting. There are existing methods extending federated learning
in each of the three aspects. However, some important applications on
enterprise edge servers (e.g. online item recommendation at global scale)
involve the three aspects at the same time. Therefore, we propose a new
learning setting \textit{Decentralized Personalized Online Federated Learning}
that considers all the three aspects at the same time.
<br />In this new setting for learning, the first technical challenge is how to
aggregate the shared model parameters from neighboring clients to obtain a
personalized local model with good performance on each client. We propose to
directly learn an aggregation by optimizing the performance of the local model
with respect to the aggregation weights. This not only improves personalization
of each local model but also helps the local model adapting to potential data
shift by intelligently incorporating the right amount of information from its
neighbors. The second challenge is how to select the neighbors for each client.
We propose a peer selection method based on the learned aggregation weights
enabling each client to select the most helpful neighbors and reduce
communication cost at the same time. We verify the effectiveness and robustness
of our proposed method on three real-world item recommendation datasets and one
air quality prediction dataset.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04818" title="Abstract">arXiv:2311.04818</a> [<a href="/pdf/2311.04818" title="Download PDF">pdf</a>, <a href="/format/2311.04818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Silo Federated Learning Across Divergent Domains with Iterative  Parameter Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gorbett%2C+M">Matt Gorbett</a>, 
<a href="/search/cs?searchtype=author&query=Shirazi%2C+H">Hossein Shirazi</a>, 
<a href="/search/cs?searchtype=author&query=Ray%2C+I">Indrakshi Ray</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at IEEE Big Data 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Learning from the collective knowledge of data dispersed across private
sources can provide neural networks with enhanced generalization capabilities.
Federated learning, a method for collaboratively training a machine learning
model across remote clients, achieves this by combining client models via the
orchestration of a central server. However, current approaches face two
critical limitations: i) they struggle to converge when client domains are
sufficiently different, and ii) current aggregation techniques produce an
identical global model for each client. In this work, we address these issues
by reformulating the typical federated learning setup: rather than learning a
single global model, we learn N models each optimized for a common objective.
To achieve this, we apply a weighted distance minimization to model parameters
shared in a peer-to-peer topology. The resulting framework, Iterative Parameter
Alignment, applies naturally to the cross-silo setting, and has the following
properties: (i) a unique solution for each participant, with the option to
globally converge each model in the federation, and (ii) an optional
early-stopping mechanism to elicit fairness among peers in collaborative
learning settings. These characteristics jointly provide a flexible new
framework for iteratively learning from peer models trained on disparate
datasets. We find that the technique achieves competitive results on a variety
of data partitions compared to state-of-the-art approaches. Further, we show
that the method is robust to divergent domains (i.e. disjoint classes across
peers) where existing approaches struggle.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04823" title="Abstract">arXiv:2311.04823</a> [<a href="/pdf/2311.04823" title="Download PDF">pdf</a>, <a href="/format/2311.04823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchically Gated Recurrent Neural Network for Sequence Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhen Qin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Songlin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yiran Zhong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Spotlight. Zhen Qin and Songlin Yang contribute equally to this paper. Yiran Zhong is the corresponding author. The source code is available at <a href="https://github.com/OpenNLPLab/HGRN">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Transformers have surpassed RNNs in popularity due to their superior
abilities in parallel training and long-term dependency modeling. Recently,
there has been a renewed interest in using linear RNNs for efficient sequence
modeling. These linear RNNs often employ gating mechanisms in the output of the
linear recurrence layer while ignoring the significance of using forget gates
within the recurrence. In this paper, we propose a gated linear RNN model
dubbed Hierarchically Gated Recurrent Neural Network (HGRN), which includes
forget gates that are lower bounded by a learnable value. The lower bound
increases monotonically when moving up layers. This allows the upper layers to
model long-term dependencies and the lower layers to model more local,
short-term dependencies. Experiments on language modeling, image
classification, and long-range arena benchmarks showcase the efficiency and
effectiveness of our proposed model. The source code is available at
https://github.com/OpenNLPLab/HGRN.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04824" title="Abstract">arXiv:2311.04824</a> [<a href="/pdf/2311.04824" title="Download PDF">pdf</a>, <a href="/format/2311.04824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bilevel Relations and Their Applications to Data Insights
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xiangyao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Deep%2C+S">Shaleen Deep</a>, 
<a href="/search/cs?searchtype=author&query=Mahmood%2C+A">Ahmed Mahmood</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+U">Uyeong Jang</a>, 
<a href="/search/cs?searchtype=author&query=Viglas%2C+S">Stratis Viglas</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+S">Somesh Jha</a>, 
<a href="/search/cs?searchtype=author&query=Cieslewicz%2C+J">John Cieslewicz</a>, 
<a href="/search/cs?searchtype=author&query=Naughton%2C+J+F">Jeffrey F. Naughton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Some overlap on examples and experiments with <a href="/abs/2302.00120">arXiv:2302.00120</a>. The latter draft will be revised to focus on implementation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Programming Languages (cs.PL)

</div>
<p class="mathjax">Many data-insight analytic tasks in anomaly detection, metric attribution,
and experimentation analysis can be modeled as searching in a large space of
tables and finding important ones, where the notion of importance is defined in
some adhoc manner. While various frameworks have been proposed (e.g., DIFF,
VLDB 2019), a systematic and general treatment is lacking. This paper describes
bilevel relations and operators. While a relation (i.e., table) models a set of
tuples, a bilevel relation is a dictionary that explicitly models a set of
tables, where each ``value'' table is identified by a ``key'' of a (region,
features) pair, where region specifies key attributes of the table, and
features specify columns of the table. Bilevel relational operators are
BilevelRelation-to-BilevelRelation transformations and directly analyze a set
of tables. Bilevel relations and operators provide higher level abstractions
for creating and manipulating a set of tables, and are compatible with the
classic relational algebra. Together, they allow us to construct bilevel
queries, which can express succinctly a range of insight-analytical questions
with ``search+eval'' character. We have implemented and deployed a query engine
for bilevel queries as a service, which is a first of its kind. Bilevel queries
pose a rich algorithm and system design space, such as query optimization and
data format, in order to evaluate them efficiently. We describe our current
designs and lessons, and report empirical evaluations. Bilevel queries have
found many useful applications, and have attracted more than 30 internal teams
to build data-insight applications with it.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04828" title="Abstract">arXiv:2311.04828</a> [<a href="/pdf/2311.04828" title="Download PDF">pdf</a>, <a href="/format/2311.04828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SODAWideNet -- Salient Object Detection with an Attention augmented Wide  Encoder Decoder network without ImageNet pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dulam%2C+R+V+S">Rohit Venkata Sai Dulam</a>, 
<a href="/search/cs?searchtype=author&query=Kambhamettu%2C+C">Chandra Kambhamettu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ISVC'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Developing a new Salient Object Detection (SOD) model involves selecting an
ImageNet pre-trained backbone and creating novel feature refinement modules to
use backbone features. However, adding new components to a pre-trained backbone
needs retraining the whole network on the ImageNet dataset, which requires
significant time. Hence, we explore developing a neural network from scratch
directly trained on SOD without ImageNet pre-training. Such a formulation
offers full autonomy to design task-specific components. To that end, we
propose SODAWideNet, an encoder-decoder-style network for Salient Object
Detection. We deviate from the commonly practiced paradigm of narrow and deep
convolutional models to a wide and shallow architecture, resulting in a
parameter-efficient deep neural network. To achieve a shallower network, we
increase the receptive field from the beginning of the network using a
combination of dilated convolutions and self-attention. Therefore, we propose
Multi Receptive Field Feature Aggregation Module (MRFFAM) that efficiently
obtains discriminative features from farther regions at higher resolutions
using dilated convolutions. Next, we propose Multi-Scale Attention (MSA), which
creates a feature pyramid and efficiently computes attention across multiple
resolutions to extract global features from larger feature maps. Finally, we
propose two variants, SODAWideNet-S (3.03M) and SODAWideNet (9.03M), that
achieve competitive performance against state-of-the-art models on five
datasets.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04829" title="Abstract">arXiv:2311.04829</a> [<a href="/pdf/2311.04829" title="Download PDF">pdf</a>, <a href="/format/2311.04829" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Functional Bayesian Tucker Decomposition for Continuous-indexed Tensor  Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+S">Shikai Fang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shibo Li</a>, 
<a href="/search/cs?searchtype=author&query=Kirby%2C+M">Mike Kirby</a>, 
<a href="/search/cs?searchtype=author&query=Zhe%2C+S">Shandian Zhe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Tucker decomposition is a powerful tensor model to handle multi-aspect data.
It demonstrates the low-rank property by decomposing the grid-structured data
as interactions between a core tensor and a set of object representations
(factors). A fundamental assumption of such decomposition is that there were
finite objects in each aspect or mode, corresponding to discrete indexes of
data entries. However, many real-world data are not naturally posed in the
setting. For example, geographic data is represented as continuous indexes of
latitude and longitude coordinates, and cannot fit tensor models directly. To
generalize Tucker decomposition to such scenarios, we propose Functional
Bayesian Tucker Decomposition (FunBaT). We treat the continuous-indexed data as
the interaction between the Tucker core and a group of latent functions. We use
Gaussian processes (GP) as functional priors to model the latent functions, and
then convert the GPs into a state-space prior by constructing an equivalent
stochastic differential equation (SDE) to reduce computational cost. An
efficient inference algorithm is further developed for scalable posterior
approximation based on advanced message-passing techniques. The advantage of
our method is shown in both synthetic data and several real-world applications.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04830" title="Abstract">arXiv:2311.04830</a> [<a href="/pdf/2311.04830" title="Download PDF">pdf</a>, <a href="/format/2311.04830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-Time Recurrent Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lemmel%2C+J">Julian Lemmel</a>, 
<a href="/search/cs?searchtype=author&query=Grosu%2C+R">Radu Grosu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures, includes Appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Systems and Control (eess.SY)

</div>
<p class="mathjax">Recent advances in reinforcement learning, for partially-observable Markov
decision processes (POMDPs), rely on the biologically implausible
backpropagation through time algorithm (BPTT) to perform gradient-descent
optimisation. In this paper we propose a novel reinforcement learning algorithm
that makes use of random feedback local online learning (RFLO), a biologically
plausible approximation of realtime recurrent learning (RTRL) to compute the
gradients of the parameters of a recurrent neural network in an online manner.
By combining it with TD($\lambda$), a variant of temporaldifference
reinforcement learning with eligibility traces, we create a biologically
plausible, recurrent actor-critic algorithm, capable of solving discrete and
continuous control tasks in POMDPs. We compare BPTT, RTRL and RFLO as well as
different network architectures, and find that RFLO can perform just as well as
RTRL while exceeding even BPTT in terms of complexity. The proposed method,
called real-time recurrent reinforcement learning (RTRRL), serves as a model of
learning in biological neural networks mimicking reward pathways in the
mammalian brain.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04831" title="Abstract">arXiv:2311.04831</a> [<a href="/pdf/2311.04831" title="Download PDF">pdf</a>, <a href="/ps/2311.04831" title="Download PostScript">ps</a>, <a href="/format/2311.04831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A contribution to the MMSE conjecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mansanarez%2C+P">Paul Mansanarez</a>, 
<a href="/search/cs?searchtype=author&query=Poly%2C+G">Guillaume Poly</a>, 
<a href="/search/cs?searchtype=author&query=Swan%2C+Y">Yvik Swan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Comments most welcome!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Probability (math.PR)

</div>
<p class="mathjax">We investigate the so-called "MMSE conjecture" from Guo et al. (2011) which
asserts that two distributions on the real line with the same entropy along the
heat flow coincide up to translation and symmetry. Our approach follows the
path breaking contribution Ledoux (1995) which gave algebraic representations
of the derivatives of said entropy in terms of multivariate polynomials. The
main contributions in this note are (i) we obtain the leading terms in the
polynomials from Ledoux (1995), and (ii) we provide new conditions on the
source distributions ensuring the MMSE conjecture holds. As illustrating
examples, our findings cover the cases of uniform and Rademacher distributions,
for which previous results in the literature were inapplicable.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04833" title="Abstract">arXiv:2311.04833</a> [<a href="/pdf/2311.04833" title="Download PDF">pdf</a>, <a href="/format/2311.04833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anonymizing medical case-based explanations through disentanglement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Montenegro%2C+H">Helena Montenegro</a>, 
<a href="/search/cs?searchtype=author&query=Cardoso%2C+J+S">Jaime S. Cardoso</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Case-based explanations are an intuitive method to gain insight into the
decision-making process of deep learning models in clinical contexts. However,
medical images cannot be shared as explanations due to privacy concerns. To
address this problem, we propose a novel method for disentangling identity and
medical characteristics of images and apply it to anonymize medical images. The
disentanglement mechanism replaces some feature vectors in an image while
ensuring that the remaining features are preserved, obtaining independent
feature vectors that encode the images' identity and medical characteristics.
We also propose a model to manufacture synthetic privacy-preserving identities
to replace the original image's identity and achieve anonymization. The models
are applied to medical and biometric datasets, demonstrating their capacity to
generate realistic-looking anonymized images that preserve their original
medical content. Additionally, the experiments show the network's inherent
capacity to generate counterfactual images through the replacement of medical
features.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04834" title="Abstract">arXiv:2311.04834</a> [<a href="/pdf/2311.04834" title="Download PDF">pdf</a>, <a href="/format/2311.04834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Learning for Visual Relationship Detection through  Masked Bounding Box Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anastasakis%2C+Z">Zacharias Anastasakis</a>, 
<a href="/search/cs?searchtype=author&query=Mallis%2C+D">Dimitrios Mallis</a>, 
<a href="/search/cs?searchtype=author&query=Diomataris%2C+M">Markos Diomataris</a>, 
<a href="/search/cs?searchtype=author&query=Alexandridis%2C+G">George Alexandridis</a>, 
<a href="/search/cs?searchtype=author&query=Kollias%2C+S">Stefanos Kollias</a>, 
<a href="/search/cs?searchtype=author&query=Pitsikalis%2C+V">Vassilis Pitsikalis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Camera Ready paper version of WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present a novel self-supervised approach for representation learning,
particularly for the task of Visual Relationship Detection (VRD). Motivated by
the effectiveness of Masked Image Modeling (MIM), we propose Masked Bounding
Box Reconstruction (MBBR), a variation of MIM where a percentage of the
entities/objects within a scene are masked and subsequently reconstructed based
on the unmasked objects. The core idea is that, through object-level masked
modeling, the network learns context-aware representations that capture the
interaction of objects within a scene and thus are highly predictive of visual
object relationships. We extensively evaluate learned representations, both
qualitatively and quantitatively, in a few-shot setting and demonstrate the
efficacy of MBBR for learning robust visual representations, particularly
tailored for VRD. The proposed method is able to surpass state-of-the-art VRD
methods on the Predicate Detection (PredDet) evaluation setting, using only a
few annotated samples. We make our code available at
https://github.com/deeplab-ai/SelfSupervisedVRD.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04836" title="Abstract">arXiv:2311.04836</a> [<a href="/pdf/2311.04836" title="Download PDF">pdf</a>, <a href="/ps/2311.04836" title="Download PostScript">ps</a>, <a href="/format/2311.04836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparcle: Boosting the Accuracy of Data Cleaning Systems through Spatial  Awareness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuchuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Mokbel%2C+M+F">Mohamed F. Mokbel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Though data cleaning systems have earned great success and wide spread in
both academia and industry, they fall short when trying to clean spatial data.
The main reason is that state-of-the-art data cleaning systems mainly rely on
functional dependency rules where there is sufficient co-occurrence of value
pairs to learn that a certain value of an attribute leads to a corresponding
value of another attribute. However, for spatial attributes that represent
locations on the form of &lt;latitude, longitude&gt;, there is very little chance
that two records would have the same exact coordinates, and hence co-occurrence
would unlikely to exist. This paper presents Sparcle~(SPatially-AwaRe
CLEaning); a novel framework that injects spatial awareness into the core
engine of rule-based data cleaning systems as a means of boosting their
accuracy. Sparcle injects two main spatial concepts into the core engine of
data cleaning systems: (1) Spatial Neighborhood, where co-occurrence is relaxed
to be within a certain spatial proximity rather than same exact value, and (2)
Distance Weighting, where records are given different weights of whether they
satisfy a dependency rule, based on their relative distance. Experimental
results using a real deployment of Sparcle inside a state-of-the-art data
cleaning system, and real and synthetic datasets, show that Sparcle
significantly boosts the accuracy of data cleaning systems when dealing with
spatial data.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04837" title="Abstract">arXiv:2311.04837</a> [<a href="/pdf/2311.04837" title="Download PDF">pdf</a>, <a href="/format/2311.04837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying Semantic Component for Robust Molecular Property Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zijian Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zunhong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+R">Ruichu Cai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhenhui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yuguang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Z">Zhifeng Hao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guangyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Although graph neural networks have achieved great success in the task of
molecular property prediction in recent years, their generalization ability
under out-of-distribution (OOD) settings is still under-explored. Different
from existing methods that learn discriminative representations for prediction,
we propose a generative model with semantic-components identifiability, named
SCI. We demonstrate that the latent variables in this generative model can be
explicitly identified into semantic-relevant (SR) and semantic-irrelevant (SI)
components, which contributes to better OOD generalization by involving minimal
change properties of causal mechanisms. Specifically, we first formulate the
data generation process from the atom level to the molecular level, where the
latent space is split into SI substructures, SR substructures, and SR atom
variables. Sequentially, to reduce misidentification, we restrict the minimal
changes of the SR atom variables and add a semantic latent substructure
regularization to mitigate the variance of the SR substructure under augmented
domain changes. Under mild assumptions, we prove the block-wise identifiability
of the SR substructure and the comment-wise identifiability of SR atom
variables. Experimental studies achieve state-of-the-art performance and show
general improvement on 21 datasets in 3 mainstream benchmarks. Moreover, the
visualization results of the proposed SCI method provide insightful case
studies and explanations for the prediction results. The code is available at:
https://github.com/DMIRLAB-Group/SCI.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04838" title="Abstract">arXiv:2311.04838</a> [<a href="/pdf/2311.04838" title="Download PDF">pdf</a>, <a href="/format/2311.04838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Rapid, Optimal, and Feasible Power Dispatch through Generalized  Neural Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+M">Meiyi Li</a>, 
<a href="/search/eess?searchtype=author&query=Mohammadi%2C+J">Javad Mohammadi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The evolution towards a more distributed and interconnected grid necessitates
large-scale decision-making within strict temporal constraints. Machine
learning (ML) paradigms have demonstrated significant potential in improving
the efficacy of optimization processes. However, the feasibility of solutions
derived from ML models continues to pose challenges. It's imperative that ML
models produce solutions that are attainable and realistic within the given
system constraints of power systems. To address the feasibility issue and
expedite the solution search process, we proposed LOOP-LC 2.0(Learning to
Optimize the Optimization Process with Linear Constraints version 2.0) as a
learning-based approach for solving the power dispatch problem. A notable
advantage of the LOOP-LC 2.0 framework is its ability to ensure near-optimality
and strict feasibility of solutions without depending on computationally
intensive post-processing procedures, thus eliminating the need for iterative
processes. At the heart of the LOOP-LC 2.0 model lies the newly proposed
generalized gauge map method, capable of mapping any infeasible solution to a
feasible point within the linearly-constrained domain. The proposed generalized
gauge map method improves the traditional gauge map by exhibiting reduced
sensitivity to input variances while increasing search speeds significantly.
Utilizing the IEEE-200 test case as a benchmark, we demonstrate the
effectiveness of the LOOP-LC 2.0 methodology, confirming its superior
performance in terms of training speed, computational time, optimality, and
solution feasibility compared to existing methodologies.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04843" title="Abstract">arXiv:2311.04843</a> [<a href="/pdf/2311.04843" title="Download PDF">pdf</a>, <a href="/format/2311.04843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging Dimensions: Confident Reachability for High-Dimensional  Controllers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geng%2C+Y">Yuang Geng</a>, 
<a href="/search/cs?searchtype=author&query=Dutta%2C+S">Souradeep Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Ruchkin%2C+I">Ivan Ruchkin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Autonomous systems are increasingly implemented using end-end-end trained
controllers. Such controllers make decisions that are executed on the real
system with images as one of the primary sensing modalities. Deep neural
networks form a fundamental building block of such controllers. Unfortunately,
the existing neural-network verification tools do not scale to inputs with
thousands of dimensions. Especially when the individual inputs (such as pixels)
are devoid of clear physical meaning. This paper takes a step towards
connecting exhaustive closed-loop verification with high-dimensional
controllers. Our key insight is that the behavior of a high-dimensional
controller can be approximated with several low-dimensional controllers in
different regions of the state space. To balance approximation and
verifiability, we leverage the latest verification-aware knowledge
distillation. Then, if low-dimensional reachability results are inflated with
statistical approximation errors, they yield a high-confidence reachability
guarantee for the high-dimensional controller. We investigate two inflation
techniques -- based on trajectories and actions -- both of which show
convincing performance in two OpenAI gym benchmarks.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04846" title="Abstract">arXiv:2311.04846</a> [<a href="/pdf/2311.04846" title="Download PDF">pdf</a>, <a href="/format/2311.04846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incorporating temporal dynamics of mutations to enhance the prediction  capability of antiretroviral therapy&#x27;s outcome for HIV-1
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Di+Teodoro%2C+G">Giulia Di Teodoro</a>, 
<a href="/search/cs?searchtype=author&query=Pirkl%2C+M">Martin Pirkl</a>, 
<a href="/search/cs?searchtype=author&query=Incardona%2C+F">Francesca Incardona</a>, 
<a href="/search/cs?searchtype=author&query=Vicenti%2C+I">Ilaria Vicenti</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%B6nnerborg%2C+A">Anders S&#xf6;nnerborg</a>, 
<a href="/search/cs?searchtype=author&query=Kaiser%2C+R">Rolf Kaiser</a>, 
<a href="/search/cs?searchtype=author&query=Palagi%2C+L">Laura Palagi</a>, 
<a href="/search/cs?searchtype=author&query=Zazzi%2C+M">Maurizio Zazzi</a>, 
<a href="/search/cs?searchtype=author&query=Lengauer%2C+T">Thomas Lengauer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Motivation: In predicting HIV therapy outcomes, a critical clinical question
is whether using historical information can enhance predictive capabilities
compared with current or latest available data analysis. This study analyses
whether historical knowledge, which includes viral mutations detected in all
genotypic tests before therapy, their temporal occurrence, and concomitant
viral load measurements, can bring improvements. We introduce a method to weigh
mutations, considering the previously enumerated factors and the reference
mutation-drug Stanford resistance tables. We compare a model encompassing
history (H) with one not using it (NH). Results: The H-model demonstrates
superior discriminative ability, with a higher ROC-AUC score (76.34%) than the
NH-model (74.98%). Significant Wilcoxon test results confirm that incorporating
historical information improves consistently predictive accuracy for treatment
outcomes. The better performance of the H-model might be attributed to its
consideration of latent HIV reservoirs, probably obtained when leveraging
historical information. The findings emphasize the importance of temporal
dynamics in mutations, offering insights into HIV infection complexities.
However, our result also shows that prediction accuracy remains relatively high
even when no historical information is available. Supplementary information:
Supplementary material is available.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04850" title="Abstract">arXiv:2311.04850</a> [<a href="/pdf/2311.04850" title="Download PDF">pdf</a>, <a href="/format/2311.04850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Benchmark and Contamination for Language Models with  Rephrased Samples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chiang%2C+W">Wei-Lin Chiang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Lianmin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+J+E">Joseph E. Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Stoica%2C+I">Ion Stoica</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models are increasingly trained on all the data ever produced
by humans. Many have raised concerns about the trustworthiness of public
benchmarks due to potential contamination in pre-training or fine-tuning
datasets. While most data decontamination efforts apply string matching (e.g.,
n-gram overlap) to remove benchmark data, we show that these methods are
insufficient, and simple variations of test data (e.g., paraphrasing,
translation) can easily bypass these decontamination measures. Furthermore, we
demonstrate that if such variation of test data is not eliminated, a 13B model
can easily overfit a test benchmark and achieve drastically high performance,
on par with GPT-4. We validate such observations in widely used benchmarks such
as MMLU, GSK8k, and HumanEval. To address this growing risk, we propose a
stronger LLM-based decontamination method and apply it to widely used
pre-training and fine-tuning datasets, revealing significant previously unknown
test overlap. For example, in pre-training sets such as RedPajama-Data-1T and
StarCoder-Data, we identified that 8-18\% of the HumanEval benchmark overlaps.
Interestingly, we also find such contamination in synthetic dataset generated
by GPT-3.5/4, suggesting a potential risk of unintentional contamination. We
urge the community to adopt stronger decontamination approaches when using
public benchmarks. Moreover, we call for the community to actively develop
fresh one-time exams to evaluate models accurately. Our decontamination tool is
publicly available at https://github.com/lm-sys/llm-decontaminator.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04852" title="Abstract">arXiv:2311.04852</a> [<a href="/pdf/2311.04852" title="Download PDF">pdf</a>, <a href="/format/2311.04852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Control under Uncertainty with Data-Based Iterative Linear  Quadratic Regulator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+R">Raman Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Chakravorty%2C+S">Suman Chakravorty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY); Dynamical Systems (math.DS); Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper studies the learning-to-control problem under process and sensing
uncertainties for dynamical systems. In our previous work, we developed a
data-based generalization of the iterative linear quadratic regulator (iLQR) to
design closed-loop feedback control for high-dimensional dynamical systems with
partial state observation. This method required perfect simulation rollouts
which are not realistic in real applications. In this work, we briefly
introduce this method and explore its efficacy under process and sensing
uncertainties. We prove that in the fully observed case where the system
dynamics are corrupted with noise but the measurements are perfect, it still
converges to the global minimum. However, in the partially observed case where
both process and measurement noise exist in the system, this method converges
to a biased "optimum". Thus multiple rollouts need to be averaged to retrieve
the true optimum. The analysis is verified in two nonlinear robotic examples
simulated in the above cases.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04861" title="Abstract">arXiv:2311.04861</a> [<a href="/pdf/2311.04861" title="Download PDF">pdf</a>, <a href="/ps/2311.04861" title="Download PostScript">ps</a>, <a href="/format/2311.04861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sandi: A System for Accountability and Applications in Direct  Communication (Extended Abstract)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Durak%2C+F+B">F. Bet&#xfc;l Durak</a>, 
<a href="/search/cs?searchtype=author&query=Laine%2C+K">Kim Laine</a>, 
<a href="/search/cs?searchtype=author&query=Langowski%2C+S">Simon Langowski</a>, 
<a href="/search/cs?searchtype=author&query=Moreno%2C+R+C">Radames Cruz Moreno</a>, 
<a href="/search/cs?searchtype=author&query=Sim%2C+R">Robert Sim</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+S">Shrey Jain</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, extended abstract
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Reputation systems guide our decision making both in life and work: which
restaurant to eat at, which vendor to buy from, which software dependencies to
use, and who or what to trust. These systems are often based on old ideas and
are failing in the face of modern threats. Fraudsters have found ways to
manipulate them, undermining their integrity and utility. Generative AI adds to
the problem by enabling the creation of real-looking fake narratives at scale,
creating a false sense of consensus. Meanwhile, the need for reliable
reputation concepts is more important than ever, as wrong decisions lead to
increasingly severe outcomes: wasted time, poor service, and a feeling of
injustice at best, fraud, identity theft, and ransomware at worst.
<br />In this extended abstract we introduce Sandi, a new kind of reputation system
with a single well-defined purpose: to create trust through accountability in
one-to-one transactions. Examples of such transactions include sending an email
or making a purchase online. Sandi has strong security and privacy properties
that make it suitable for use also in sensitive contexts. Furthermore, Sandi
can guarantee reputation integrity and transparency for its registered users.
<br />As a primary application, we envision how Sandi could counter fraud and abuse
in direct communication. Concretely, message senders request a cryptographic
tag from Sandi that they send along with their message. If the receiver finds
the message inappropriate, they can report the sender using this tag. Notably,
only senders need registered accounts and do not need to manage long-term keys.
The design of Sandi ensures compatibility with any communication system that
allows for small binary data transmission.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04865" title="Abstract">arXiv:2311.04865</a> [<a href="/pdf/2311.04865" title="Download PDF">pdf</a>, <a href="/format/2311.04865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing the $5$-Edge-Connected Components in Linear Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kosinas%2C+E">Evangelos Kosinas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at SODA24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We provide a deterministic algorithm for computing the $5$-edge-connected
components of an undirected multigraph in linear time. There were probably good
indications that this computation can be performed in linear time, but no such
algorithm was actually known prior to this work. Thus, our paper answers a
theoretical question, and sheds light on the possibility that a solution may
exist for general $k$. A key component in our algorithm is an oracle for
answering connectivity queries for pairs of vertices in the presence of at most
four edge-failures. Specifically, the oracle has size $O(n)$, it can be
constructed in linear time, and it answers connectivity queries in the presence
of at most four edge-failures in worst-case constant time, where $n$ denotes
the number of vertices of the graph. We note that this is a result of
independent interest. Our paper can be considered as a follow-up of recent work
on computing the $4$-edge-connected components in linear time. However, in
dealing with the computation of the $5$-edge-connected components, we are faced
with unique challenges that do not appear when dealing with lower connectivity.
The problem is that the $4$-edge cuts in $3$-edge-connected graphs are
entangled in various complicated ways, that make it difficult to organize them
in a compact way. Here we provide a novel analysis of those cuts, that reveals
the existence of various interesting structures. These can be exploited so that
we can disentangle and collect only those cuts that are essential in computing
the $5$-edge-connected components. This analysis may provide a clue for a
general solution for the $k$-edge-connected components, or other related graph
connectivity problems.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04872" title="Abstract">arXiv:2311.04872</a> [<a href="/pdf/2311.04872" title="Download PDF">pdf</a>, <a href="/format/2311.04872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing with Residue Numbers in High-Dimensional Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kymn%2C+C+J">Christopher J. Kymn</a>, 
<a href="/search/cs?searchtype=author&query=Kleyko%2C+D">Denis Kleyko</a>, 
<a href="/search/cs?searchtype=author&query=Frady%2C+E+P">E. Paxon Frady</a>, 
<a href="/search/cs?searchtype=author&query=Bybee%2C+C">Connor Bybee</a>, 
<a href="/search/cs?searchtype=author&query=Kanerva%2C+P">Pentti Kanerva</a>, 
<a href="/search/cs?searchtype=author&query=Sommer%2C+F+T">Friedrich T. Sommer</a>, 
<a href="/search/cs?searchtype=author&query=Olshausen%2C+B+A">Bruno A. Olshausen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">We introduce Residue Hyperdimensional Computing, a computing framework that
unifies residue number systems with an algebra defined over random,
high-dimensional vectors. We show how residue numbers can be represented as
high-dimensional vectors in a manner that allows algebraic operations to be
performed with component-wise, parallelizable operations on the vector
elements. The resulting framework, when combined with an efficient method for
factorizing high-dimensional vectors, can represent and operate on numerical
values over a large dynamic range using vastly fewer resources than previous
methods, and it exhibits impressive robustness to noise. We demonstrate the
potential for this framework to solve computationally difficult problems in
visual perception and combinatorial optimization, showing improvement over
baseline methods. More broadly, the framework provides a possible account for
the computational operations of grid cells in the brain, and it suggests new
machine learning architectures for representing and manipulating numerical
data.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04874" title="Abstract">arXiv:2311.04874</a> [<a href="/pdf/2311.04874" title="Download PDF">pdf</a>, <a href="/ps/2311.04874" title="Download PostScript">ps</a>, <a href="/format/2311.04874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Framework for Programmability in Digital Currency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=George%2C+N">Nikhil George</a>, 
<a href="/search/cs?searchtype=author&query=Dryja%2C+T">Thaddeus Dryja</a>, 
<a href="/search/cs?searchtype=author&query=Narula%2C+N">Neha Narula</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Programmable money, enabled by digital currencies, facilitates outcomes
beyond simple payments by allowing users to attach conditions to the movement
of funds through code. However, there is a lack of clarity on defining
programmable money, where programmability can be implemented, and the resulting
tradeoffs. This paper provides a definition of programmable money with four key
components: a format for representing value, a set of programmable
instructions, an execution environment providing a coherence guarantee, and
rules around permissioning. We discuss programmability primitives, categorizing
them into levels based on expressiveness. We outline four locations
programmability could be offered - hardcoded into system rules, via
client-supplied programs/smart contracts, in client code, or via intermediaries
- analyzing benefits and risks of each. For policymakers evaluating central
bank digital currencies, we recommend considering these aspects holistically
and their interplay with regulation in system design. Our framework and
vocabulary enable more nuanced analysis of implementing programmability.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04875" title="Abstract">arXiv:2311.04875</a> [<a href="/pdf/2311.04875" title="Download PDF">pdf</a>, <a href="/format/2311.04875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fusionize++: Improving Serverless Application Performance Using Dynamic  Task Inlining and Infrastructure Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schirmer%2C+T">Trever Schirmer</a>, 
<a href="/search/cs?searchtype=author&query=Scheuner%2C+J">Joel Scheuner</a>, 
<a href="/search/cs?searchtype=author&query=Pfandzelter%2C+T">Tobias Pfandzelter</a>, 
<a href="/search/cs?searchtype=author&query=Bermbach%2C+D">David Bermbach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2204.11533">arXiv:2204.11533</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">The Function-as-a-Service (FaaS) execution model increases developer
productivity by removing operational concerns such as managing hardware or
software runtimes. Developers, however, still need to partition their
applications into FaaS functions, which is error-prone and complex:
Encapsulating only the smallest logical unit of an application as a FaaS
function maximizes flexibility and reusability. Yet, it also leads to
invocation overheads, additional cold starts, and may increase cost due to
double billing during synchronous invocations. Conversely, deploying an entire
application as a single FaaS function avoids these overheads but decreases
flexibility. In this paper we present Fusionize, a framework that automates
optimizing for this trade-off by automatically fusing application code into an
optimized multi-function composition. Developers only need to write
fine-grained application code following the serverless model, while Fusionize
automatically fuses different parts of the application into FaaS functions,
manages their interactions, and configures the underlying infrastructure. At
runtime, it monitors application performance and adapts it to minimize
request-response latency and costs. Real-world use cases show that Fusionize
can improve the deployment artifacts of the application, reducing both median
request-response latency and cost of an example IoT application by more than
35%.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04879" title="Abstract">arXiv:2311.04879</a> [<a href="/pdf/2311.04879" title="Download PDF">pdf</a>, <a href="/format/2311.04879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LongQLoRA: Efficient and Effective Method to Extend Context Length of  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianxin Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present LongQLoRA, an efficient and effective method to extend context
length of large language models with less training resources. LongQLoRA
combines the advantages of Position Interpolation, QLoRA and Shift Short
Attention of LongLoRA. With a single 32GB V100 GPU, LongQLoRA can extend the
context length of LLaMA2 7B and 13B from 4096 to 8192 and even to 12k within
1000 finetuning steps. LongQLoRA achieves competitive perplexity performance on
PG19 and Proof-pile datasets, our model outperforms LongLoRA and is very close
to MPT-7B-8K within the evaluation context length of 8192. We collect and build
39k long instruction data to extend context length of Vicuna-13B from 4096 to
8192 and achieve good performance both in long and short context generation
task. We also do some ablation experiments to study the effect of LoRA rank,
finetuning steps and attention patterns in inference.The model weights,
training data and code are avaliable at
https://github.com/yangjianxin1/LongQLoRA.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04881" title="Abstract">arXiv:2311.04881</a> [<a href="/pdf/2311.04881" title="Download PDF">pdf</a>, <a href="/ps/2311.04881" title="Download PostScript">ps</a>, <a href="/format/2311.04881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Transmit Signal and Beamforming Design for Integrated Sensing and  Power Transfer Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mayer%2C+K+M">Kenneth MacSporran Mayer</a>, 
<a href="/search/cs?searchtype=author&query=Shanin%2C+N">Nikita Shanin</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Z">Zhenlong You</a>, 
<a href="/search/cs?searchtype=author&query=Lotter%2C+S">Sebastian Lotter</a>, 
<a href="/search/cs?searchtype=author&query=Br%C3%BCckner%2C+S">Stefan Br&#xfc;ckner</a>, 
<a href="/search/cs?searchtype=author&query=Vossiek%2C+M">Martin Vossiek</a>, 
<a href="/search/cs?searchtype=author&query=Cottatellucci%2C+L">Laura Cottatellucci</a>, 
<a href="/search/cs?searchtype=author&query=Schober%2C+R">Robert Schober</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures, six page version of this paper has been submitted to IEEE ICC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Integrating different functionalities, conventionally implemented as
dedicated systems, into a single platform allows utilising the available
resources more efficiently. We consider an integrated sensing and power
transfer (ISAPT) system and propose the joint optimisation of the rectangular
pulse-shaped transmit signal and the beamforming design to combine sensing and
wireless power transfer (WPT) functionalities efficiently. In contrast to prior
works, we adopt an accurate non-linear circuit-based energy harvesting (EH)
model. We formulate a non-convex optimisation problem for a general number of
EH receivers and a single sensing target (ST) and solve the problem via a grid
search over the pulse duration, semidefinite relaxation (SDR), and successive
convex approximation (SCA). The average harvested power is shown to
monotonically increase with the pulse duration when the average transmit power
budget is large. We discuss the trade-off between sensing performance and power
transfer of the ISAPT system. The proposed approach significantly outperforms a
heuristic baseline scheme based on a linear EH model, which linearly combines
energy beamforming with the beamsteering vector in the direction to the ST as
its transmit strategy.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04885" title="Abstract">arXiv:2311.04885</a> [<a href="/pdf/2311.04885" title="Download PDF">pdf</a>, <a href="/format/2311.04885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Profiling Irony &amp; Stereotype: Exploring Sentiment, Topic, and Lexical  Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krols%2C+T+L+R">Tibor L. R. Krols</a>, 
<a href="/search/cs?searchtype=author&query=Mortensen%2C+M">Marie Mortensen</a>, 
<a href="/search/cs?searchtype=author&query=Oldenburg%2C+N">Ninell Oldenburg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Social media has become a very popular source of information. With this
popularity comes an interest in systems that can classify the information
produced. This study tries to create such a system detecting irony in Twitter
users. Recent work emphasize the importance of lexical features, sentiment
features and the contrast herein along with TF-IDF and topic models. Based on a
thorough feature selection process, the resulting model contains specific
sub-features from these areas. Our model reaches an F1-score of 0.84, which is
above the baseline. We find that lexical features, especially TF-IDF,
contribute the most to our models while sentiment and topic modeling features
contribute less to overall performance. Lastly, we highlight multiple
interesting and important paths for further exploration.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04886" title="Abstract">arXiv:2311.04886</a> [<a href="/pdf/2311.04886" title="Download PDF">pdf</a>, <a href="/format/2311.04886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SEMQA: Semi-Extractive Multi-Source Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schuster%2C+T">Tal Schuster</a>, 
<a href="/search/cs?searchtype=author&query=Lelkes%2C+A+D">Adam D. Lelkes</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Haitian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+J">Jai Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Berant%2C+J">Jonathan Berant</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+W+W">William W. Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Metzler%2C+D">Donald Metzler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recently proposed long-form question answering (QA) systems, supported by
large language models (LLMs), have shown promising capabilities. Yet,
attributing and verifying their generated abstractive answers can be difficult,
and automatically evaluating their accuracy remains an ongoing challenge.
<br />In this work, we introduce a new QA task for answering multi-answer questions
by summarizing multiple diverse sources in a semi-extractive fashion.
Specifically, Semi-extractive Multi-source QA (SEMQA) requires models to output
a comprehensive answer, while mixing factual quoted spans -- copied verbatim
from given input sources -- and non-factual free-text connectors that glue
these spans together into a single cohesive passage. This setting bridges the
gap between the outputs of well-grounded but constrained extractive QA systems
and more fluent but harder to attribute fully abstractive answers.
Particularly, it enables a new mode for language models that leverages their
advanced language generation capabilities, while also producing fine in-line
attributions by-design that are easy to verify, interpret, and evaluate.
<br />To study this task, we create the first dataset of this kind, QuoteSum, with
human-written semi-extractive answers to natural and generated questions, and
define text-based evaluation metrics. Experimenting with several LLMs in
various settings, we find this task to be surprisingly challenging,
demonstrating the importance of QuoteSum for developing and studying such
consolidation capabilities.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04887" title="Abstract">arXiv:2311.04887</a> [<a href="/pdf/2311.04887" title="Download PDF">pdf</a>, <a href="/format/2311.04887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoChip: Automating HDL Generation Using LLM Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thakur%2C+S">Shailja Thakur</a>, 
<a href="/search/cs?searchtype=author&query=Blocklove%2C+J">Jason Blocklove</a>, 
<a href="/search/cs?searchtype=author&query=Pearce%2C+H">Hammond Pearce</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+B">Benjamin Tan</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+S">Siddharth Garg</a>, 
<a href="/search/cs?searchtype=author&query=Karri%2C+R">Ramesh Karri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Traditionally, designs are written in Verilog hardware description language
(HDL) and debugged by hardware engineers. While this approach is effective, it
is time-consuming and error-prone for complex designs. Large language models
(LLMs) are promising in automating HDL code generation. LLMs are trained on
massive datasets of text and code, and they can learn to generate code that
compiles and is functionally accurate. We aim to evaluate the ability of LLMs
to generate functionally correct HDL models. We build AutoChip by combining the
interactive capabilities of LLMs and the output from Verilog simulations to
generate Verilog modules. We start with a design prompt for a module and the
context from compilation errors and debugging messages, which highlight
differences between the expected and actual outputs. This ensures that accurate
Verilog code can be generated without human intervention. We evaluate AutoChip
using problem sets from HDLBits. We conduct a comprehensive analysis of the
AutoChip using several LLMs and problem categories. The results show that
incorporating context from compiler tools, such as Icarus Verilog, improves the
effectiveness, yielding 24.20% more accurate Verilog. We release our evaluation
scripts and datasets as open-source contributions at the following link
https://github.com/shailja-thakur/AutoChip.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04888" title="Abstract">arXiv:2311.04888</a> [<a href="/pdf/2311.04888" title="Download PDF">pdf</a>, <a href="/format/2311.04888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Few-Annotation Learning in Computer Vision: Application to Image  Classification and Object Detection tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bouniot%2C+Q">Quentin Bouniot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD Thesis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">In this thesis, we develop theoretical, algorithmic and experimental
contributions for Machine Learning with limited labels, and more specifically
for the tasks of Image Classification and Object Detection in Computer Vision.
In a first contribution, we are interested in bridging the gap between theory
and practice for popular Meta-Learning algorithms used in Few-Shot
Classification. We make connections to Multi-Task Representation Learning,
which benefits from solid theoretical foundations, to verify the best
conditions for a more efficient meta-learning. Then, to leverage unlabeled data
when training object detectors based on the Transformer architecture, we
propose both an unsupervised pretraining and a semi-supervised learning method
in two other separate contributions. For pretraining, we improve Contrastive
Learning for object detectors by introducing the localization information.
Finally, our semi-supervised method is the first tailored to transformer-based
detectors.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04892" title="Abstract">arXiv:2311.04892</a> [<a href="/pdf/2311.04892" title="Download PDF">pdf</a>, <a href="/format/2311.04892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Shashank Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Shrivastava%2C+V">Vaishnavi Shrivastava</a>, 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+A">Ameet Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Kalyan%2C+A">Ashwin Kalyan</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+P">Peter Clark</a>, 
<a href="/search/cs?searchtype=author&query=Sabharwal%2C+A">Ashish Sabharwal</a>, 
<a href="/search/cs?searchtype=author&query=Khot%2C+T">Tushar Khot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://allenai.github.io/persona-bias">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent works have showcased the ability of large-scale language models (LLMs)
to embody diverse personas in their responses, exemplified by prompts like 'You
are Yoda. Explain the Theory of Relativity.' While this ability allows
personalization of LLMs and enables human behavior simulation, its effect on
LLMs' capabilities remain unclear. To fill this gap, we present the first
extensive study of the unintended side-effects of persona assignment on the
ability of LLMs, specifically ChatGPT, to perform basic reasoning tasks. Our
study covers 24 reasoning datasets and 16 diverse personas spanning 5
socio-demographic groups: race, gender, religion, disability, and political
affiliation. Our experiments unveil that ChatGPT carries deep rooted bias
against various socio-demographics underneath a veneer of fairness. While it
overtly rejects stereotypes when explicitly asked ('Are Black people less
skilled at mathematics?'), it manifests stereotypical and often erroneous
presumptions when prompted to answer questions while taking on a persona. These
can be observed as abstentions in the model responses, e.g., 'As a Black
person, I am unable to answer this question as it requires math knowledge', and
generally result in a substantial drop in performance on reasoning tasks. We
find that this inherent deep bias is ubiquitous - 80% of our personas
demonstrated bias; it is significant - certain datasets had relative drops in
performance of 70%+; and can be especially harmful for certain groups - certain
personas had stat. sign. drops on more than 80% of the datasets. Further
analysis shows that these persona-induced errors can be hard-to-discern and
hard-to-avoid. Our findings serve as a cautionary tale that the practice of
assigning personas to LLMs - a trend on the rise - can surface their
deep-rooted biases and have unforeseeable and detrimental side-effects.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04894" title="Abstract">arXiv:2311.04894</a> [<a href="/pdf/2311.04894" title="Download PDF">pdf</a>, <a href="/format/2311.04894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DAMEX: Dataset-aware Mixture-of-Experts for visual understanding of  mixture-of-datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+Y">Yash Jain</a>, 
<a href="/search/cs?searchtype=author&query=Behl%2C+H">Harkirat Behl</a>, 
<a href="/search/cs?searchtype=author&query=Kira%2C+Z">Zsolt Kira</a>, 
<a href="/search/cs?searchtype=author&query=Vineet%2C+V">Vibhav Vineet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://github.com/jinga-lala/DAMEX">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Construction of a universal detector poses a crucial question: How can we
most effectively train a model on a large mixture of datasets? The answer lies
in learning dataset-specific features and ensembling their knowledge but do all
this in a single model. Previous methods achieve this by having separate
detection heads on a common backbone but that results in a significant increase
in parameters. In this work, we present Mixture-of-Experts as a solution,
highlighting that MoEs are much more than a scalability tool. We propose
Dataset-Aware Mixture-of-Experts, DAMEX where we train the experts to become an
`expert' of a dataset by learning to route each dataset tokens to its mapped
expert. Experiments on Universal Object-Detection Benchmark show that we
outperform the existing state-of-the-art by average +10.2 AP score and improve
over our non-MoE baseline by average +2.0 AP score. We also observe consistent
gains while mixing datasets with (1) limited availability, (2) disparate
domains and (3) divergent label sets. Further, we qualitatively show that DAMEX
is robust against expert representation collapse.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04895" title="Abstract">arXiv:2311.04895</a> [<a href="/pdf/2311.04895" title="Download PDF">pdf</a>, <a href="/format/2311.04895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Monadic Theory of Toric Words
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berth%C3%A9%2C+V">Val&#xe9;rie Berth&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Karimov%2C+T">Toghrul Karimov</a>, 
<a href="/search/cs?searchtype=author&query=Ouaknine%2C+J">Jo&#xeb;l Ouaknine</a>, 
<a href="/search/cs?searchtype=author&query=Vahanwala%2C+M">Mihir Vahanwala</a>, 
<a href="/search/cs?searchtype=author&query=Worrell%2C+J">James Worrell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">For which unary predicates $P_1, \ldots, P_m$ is the MSO theory of the
structure $\langle \mathbb{N}; &lt;, P_1, \ldots, P_m \rangle$ decidable? We
survey the state of the art, leading us to investigate combinatorial properties
of almost-periodic, morphic, and toric words. In doing so, we show that if each
$P_i$ can be generated by a toric dynamical system of a certain kind, then the
attendant MSO theory is decidable.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04896" title="Abstract">arXiv:2311.04896</a> [<a href="/pdf/2311.04896" title="Download PDF">pdf</a>, <a href="/format/2311.04896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimized measurements of chaotic dynamical systems via the information  bottleneck
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Murphy%2C+K+A">Kieran A. Murphy</a>, 
<a href="/search/cs?searchtype=author&query=Bassett%2C+D+S">Dani S. Bassett</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://distributed-information-bottleneck.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Chaotic Dynamics (nlin.CD)

</div>
<p class="mathjax">Deterministic chaos permits a precise notion of a "perfect measurement" as
one that, when obtained repeatedly, captures all of the information created by
the system's evolution with minimal redundancy. Finding an optimal measurement
is challenging, and has generally required intimate knowledge of the dynamics
in the few cases where it has been done. We establish an equivalence between a
perfect measurement and a variant of the information bottleneck. As a
consequence, we can employ machine learning to optimize measurement processes
that efficiently extract information from trajectory data. We obtain
approximately optimal measurements for multiple chaotic maps and lay the
necessary groundwork for efficient information extraction from general time
series.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04897" title="Abstract">arXiv:2311.04897</a> [<a href="/pdf/2311.04897" title="Download PDF">pdf</a>, <a href="/format/2311.04897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Future Lens: Anticipating Subsequent Tokens from a Single Hidden State
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pal%2C+K">Koyena Pal</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiuding Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+A">Andrew Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wallace%2C+B+C">Byron C. Wallace</a>, 
<a href="/search/cs?searchtype=author&query=Bau%2C+D">David Bau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at CoNLL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We conjecture that hidden state vectors corresponding to individual input
tokens encode information sufficient to accurately predict several tokens
ahead. More concretely, in this paper we ask: Given a hidden (internal)
representation of a single token at position $t$ in an input, can we reliably
anticipate the tokens that will appear at positions $\geq t + 2$? To test this,
we measure linear approximation and causal intervention methods in GPT-J-6B to
evaluate the degree to which individual hidden states in the network contain
signal rich enough to predict future hidden states and, ultimately, token
outputs. We find that, at some layers, we can approximate a model's output with
more than 48% accuracy with respect to its prediction of subsequent tokens
through a single hidden state. Finally we present a "Future Lens" visualization
that uses these methods to create a new view of transformer states.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04898" title="Abstract">arXiv:2311.04898</a> [<a href="/pdf/2311.04898" title="Download PDF">pdf</a>, <a href="/format/2311.04898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two Complementary Perspectives to Continual Learning: Ask Not Only What  to Optimize, But Also How
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hess%2C+T">Timm Hess</a>, 
<a href="/search/cs?searchtype=author&query=Tuytelaars%2C+T">Tinne Tuytelaars</a>, 
<a href="/search/cs?searchtype=author&query=van+de+Ven%2C+G+M">Gido M. van de Ven</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pre-registered report, accepted at the 1st ContinualAI Unconference. Full paper with the results of the proposed experiment is expected to follow by June 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
<p class="mathjax">Recent years have seen considerable progress in the continual training of
deep neural networks, predominantly thanks to approaches that add replay or
regularization terms to the loss function to approximate the joint loss over
all tasks so far. However, we show that even with a perfect approximation to
the joint loss, these approaches still suffer from temporary but substantial
forgetting when starting to train on a new task. Motivated by this 'stability
gap', we propose that continual learning strategies should focus not only on
the optimization objective, but also on the way this objective is optimized.
While there is some continual learning work that alters the optimization
trajectory (e.g., using gradient projection techniques), this line of research
is positioned as alternative to improving the optimization objective, while we
argue it should be complementary. To evaluate the merits of our proposition, we
plan to combine replay-approximated joint objectives with gradient
projection-based optimization routines to test whether the addition of the
latter provides benefits in terms of (1) alleviating the stability gap, (2)
increasing the learning efficiency and (3) improving the final learning
outcome.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04900" title="Abstract">arXiv:2311.04900</a> [<a href="/pdf/2311.04900" title="Download PDF">pdf</a>, <a href="/format/2311.04900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Abstract Is Linguistic Generalization in Large Language Models?  Experiments with Argument Structure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wilson%2C+M">Michael Wilson</a>, 
<a href="/search/cs?searchtype=author&query=Petty%2C+J">Jackson Petty</a>, 
<a href="/search/cs?searchtype=author&query=Frank%2C+R">Robert Frank</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to TACL; Presented at EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Language models are typically evaluated on their success at predicting the
distribution of specific words in specific contexts. Yet linguistic knowledge
also encodes relationships between contexts, allowing inferences between word
distributions. We investigate the degree to which pre-trained Transformer-based
large language models (LLMs) represent such relationships, focusing on the
domain of argument structure. We find that LLMs perform well in generalizing
the distribution of a novel noun argument between related contexts that were
seen during pre-training (e.g., the active object and passive subject of the
verb spray), succeeding by making use of the semantically-organized structure
of the embedding space for word embeddings. However, LLMs fail at
generalizations between related contexts that have not been observed during
pre-training, but which instantiate more abstract, but well-attested structural
generalizations (e.g., between the active object and passive subject of an
arbitrary verb). Instead, in this case, LLMs show a bias to generalize based on
linear order. This finding points to a limitation with current models and
points to a reason for which their training is data-intensive.s reported here
are available at https://github.com/clay-lab/structural-alternations.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04901" title="Abstract">arXiv:2311.04901</a> [<a href="/pdf/2311.04901" title="Download PDF">pdf</a>, <a href="/format/2311.04901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GENOME: GenerativE Neuro-symbOlic visual reasoning by growing and  reusing ModulEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenfang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+R">Rui Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenjun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+Y">Yining Hong</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+C">Chuang Gan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent works have shown that Large Language Models (LLMs) could empower
traditional neuro-symbolic models via programming capabilities to translate
language into module descriptions, thus achieving strong visual reasoning
results while maintaining the model's transparency and efficiency. However,
these models usually exhaustively generate the entire code snippet given each
new instance of a task, which is extremely ineffective. We propose generative
neuro-symbolic visual reasoning by growing and reusing modules. Specifically,
our model consists of three unique stages, module initialization, module
generation, and module execution. First, given a vision-language task, we adopt
LLMs to examine whether we could reuse and grow over established modules to
handle this new task. If not, we initialize a new module needed by the task and
specify the inputs and outputs of this new module. After that, the new module
is created by querying LLMs to generate corresponding code snippets that match
the requirements. In order to get a better sense of the new module's ability,
we treat few-shot training examples as test cases to see if our new module
could pass these cases. If yes, the new module is added to the module library
for future reuse. Finally, we evaluate the performance of our model on the
testing set by executing the parsed programs with the newly made visual modules
to get the results. We find the proposed model possesses several advantages.
First, it performs competitively on standard tasks like visual question
answering and referring expression comprehension; Second, the modules learned
from one task can be seamlessly transferred to new tasks; Last but not least,
it is able to adapt to new visual reasoning tasks by observing a few training
examples and reusing modules.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04902" title="Abstract">arXiv:2311.04902</a> [<a href="/pdf/2311.04902" title="Download PDF">pdf</a>, <a href="/format/2311.04902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Size: How Gradients Shape Pruning Decisions in Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Das%2C+R+J">Rocktim Jyoti Das</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Liqun Ma</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zhiqiang Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report. Code and models at <a href="https://github.com/RocktimJyotiDas/GBLM-Pruner">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models (LLMs) with a billion or more parameters are prime
targets for network pruning, which aims to reduce a portion of the network
weights without compromising performance. Prior approaches such as Weights
Magnitude, SparseGPT, and Wanda, either concentrated solely on weights or
integrated weights with activations for sparsity. However, they overlooked the
informative gradients derived from pretrained large language models. In this
paper, we present a novel sparsity-centric pruning method for pretrained LLMs,
termed Gradient-based Language Model Pruner (GBLM-Pruner). GBLM-Pruner
leverages the first-order term of the Taylor expansion, operating in a
training-free manner by harnessing properly normalized gradients from a few
calibration samples to determine the importance pruning score, and
substantially outperforms competitive counterparts like SparseGPT and Wanda in
multiple benchmarks. Intriguing, after incorporating gradients, the
unstructured pruning method tends to reveal some structural patterns
post-pruning, which mirrors the geometric interdependence inherent in the LLMs'
parameter structure. Additionally, GBLM-Pruner functions without any subsequent
retraining or weight updates to maintain its simplicity as other counterparts.
Extensive evaluations on LLaMA-1 and LLaMA-2 across various language benchmarks
and perplexity show that GBLM-Pruner surpasses magnitude pruning, Wanda
(weights+activations) and SparseGPT (weights+activations+weight update) by
significant margins. Our code and models are available at
https://github.com/RocktimJyotiDas/GBLM-Pruner.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Thu,  9 Nov 23</h3>
<dl>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04223" title="Abstract">arXiv:2311.04223</a> (cross-list from eess.SP) [<a href="/pdf/2311.04223" title="Download PDF">pdf</a>, <a href="/ps/2311.04223" title="Download PostScript">ps</a>, <a href="/format/2311.04223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual band wireless transmission over 75-150GHz millimeter wave carriers  using frequency-locked laser pairs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Z">Zichuan Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Kassem%2C+A">Amany Kassem</a>, 
<a href="/search/eess?searchtype=author&query=Seddon%2C+J">James Seddon</a>, 
<a href="/search/eess?searchtype=author&query=Sillekens%2C+E">Eric Sillekens</a>, 
<a href="/search/eess?searchtype=author&query=Darwazeh%2C+I">Izzat Darwazeh</a>, 
<a href="/search/eess?searchtype=author&query=Bayvel%2C+P">Polina Bayvel</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Z">Zhixin Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages, 2 figures, conference submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY); Optics (physics.optics)

</div>
<p class="mathjax">We generate and transmit 75-GHz-bandwidth OFDM signals over the air using
three mutually frequency-locked lasers, achieving minimal frequency gap between
the wireless W and D bands using optical-assisted approaches, resulting in
173.5 Gb/s detected capacity.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04224" title="Abstract">arXiv:2311.04224</a> (cross-list from eess.SP) [<a href="/pdf/2311.04224" title="Download PDF">pdf</a>, <a href="/format/2311.04224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MELEP: A Novel Predictive Measure of Transferability in Multi-Label ECG  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+C+V">Cuong V. Nguyen</a>, 
<a href="/search/eess?searchtype=author&query=Duong%2C+H+M">Hieu Minh Duong</a>, 
<a href="/search/eess?searchtype=author&query=Do%2C+C+D">Cuong D.Do</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce MELEP, which stands for Muti-label Expected Log of Empirical
Predictions, a novel measure to estimate how effective it is to transfer
knowledge from a pre-trained model to a downstream task in a multi-label
settings. The measure is generic to work with new target data having a
different label set from source data. It is also computationally efficient,
only requires forward passing the downstream dataset through the pre-trained
model once. To the best of our knowledge, we are the first to develop such a
transferability metric for multi-label ECG classification problems. Our
experiments show that MELEP can predict the performance of pre-trained
convolutional and recurrent deep neural networks, on small and imbalanced ECG
data. Specifically, strong correlation coefficients, with absolute values
exceeding 0.6 in most cases, were observed between MELEP and the actual average
F1 scores of the fine-tuned models.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04225" title="Abstract">arXiv:2311.04225</a> (cross-list from eess.SP) [<a href="/pdf/2311.04225" title="Download PDF">pdf</a>, <a href="/ps/2311.04225" title="Download PostScript">ps</a>, <a href="/format/2311.04225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast, accurate, and interpretable decoding of electrocorticographic  signals using dynamic mode decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fukuma%2C+R">Ryohei Fukuma</a>, 
<a href="/search/eess?searchtype=author&query=Majima%2C+K">Kei Majima</a>, 
<a href="/search/eess?searchtype=author&query=Kawahara%2C+Y">Yoshinobu Kawahara</a>, 
<a href="/search/eess?searchtype=author&query=Yamashita%2C+O">Okito Yamashita</a>, 
<a href="/search/eess?searchtype=author&query=Shiraishi%2C+Y">Yoshiyuki Shiraishi</a>, 
<a href="/search/eess?searchtype=author&query=Kishima%2C+H">Haruhiko Kishima</a>, 
<a href="/search/eess?searchtype=author&query=Yanagisawa%2C+T">Takufumi Yanagisawa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Dynamic mode (DM) decomposition decomposes spatiotemporal signals into basic
oscillatory components (DMs). DMs can improve the accuracy of neural decoding
when used with the nonlinear Grassmann kernel, compared to conventional power
features. However, such kernel-based machine learning algorithms have three
limitations: large computational time preventing real-time application,
incompatibility with non-kernel algorithms, and low interpretability. Here, we
propose a mapping function corresponding to the Grassmann kernel that
explicitly transforms DMs into spatial DM (sDM) features, which can be used in
any machine learning algorithm. Using electrocorticographic signals recorded
during various movement and visual perception tasks, the sDM features were
shown to improve the decoding accuracy and computational time compared to
conventional methods. Furthermore, the components of the sDM features
informative for decoding showed similar characteristics to the high-$\gamma$
power of the signals, but with higher trial-to-trial reproducibility. The
proposed sDM features enable fast, accurate, and interpretable neural decoding.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04228" title="Abstract">arXiv:2311.04228</a> (cross-list from eess.SP) [<a href="/pdf/2311.04228" title="Download PDF">pdf</a>, <a href="/format/2311.04228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Neural Networks for Topological Feature Extraction in ECG  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zeinalipour%2C+K">Kamyar Zeinalipour</a>, 
<a href="/search/eess?searchtype=author&query=Gori%2C+M">Marco Gori</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for WIRN 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">The electrocardiogram (ECG) is a dependable instrument for assessing the
function of the cardiovascular system. There has recently been much emphasis on
precisely classifying ECGs. While ECG situations have numerous similarities,
little attention has been paid to categorizing ECGs using graph neural
networks. In this study, we offer three distinct techniques for classifying
heartbeats using deep graph neural networks to classify the ECG signals
accurately. We suggest using different methods to extract topological features
from the ECG signal and then using a branch of the graph neural network named
graph isomorphism network for classifying the ECGs. On the PTB Diagnostics data
set, we tested the three proposed techniques. According to the findings, the
three proposed techniques are capable of making arrhythmia classification
predictions with the accuracy of 99.38, 98.76, and 91.93 percent, respectively.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04229" title="Abstract">arXiv:2311.04229</a> (cross-list from eess.SP) [<a href="/pdf/2311.04229" title="Download PDF">pdf</a>, <a href="/format/2311.04229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Best Practices for ECG Signal Processing in Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Salimi%2C+A">Amir Salimi</a>, 
<a href="/search/eess?searchtype=author&query=Kalmady%2C+S+V">Sunil Vasu Kalmady</a>, 
<a href="/search/eess?searchtype=author&query=Hindle%2C+A">Abram Hindle</a>, 
<a href="/search/eess?searchtype=author&query=Zaiane%2C+O">Osmar Zaiane</a>, 
<a href="/search/eess?searchtype=author&query=Kaul%2C+P">Padma Kaul</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this work we search for best practices in pre-processing of
Electrocardiogram (ECG) signals in order to train better classifiers for the
diagnosis of heart conditions. State of the art machine learning algorithms
have achieved remarkable results in classification of some heart conditions
using ECG data, yet there appears to be no consensus on pre-processing best
practices. Is this lack of consensus due to different conditions and
architectures requiring different processing steps for optimal performance? Is
it possible that state of the art deep-learning models have rendered
pre-processing unnecessary? In this work we apply down-sampling, normalization,
and filtering functions to 3 different multi-label ECG datasets and measure
their effects on 3 different high-performing time-series classifiers. We find
that sampling rates as low as 50Hz can yield comparable results to the commonly
used 500Hz. This is significant as smaller sampling rates will result in
smaller datasets and models, which require less time and resources to train.
Additionally, despite their common usage, we found min-max normalization to be
slightly detrimental overall, and band-passing to make no measurable
difference. We found the blind approach to pre-processing of ECGs for
multi-label classification to be ineffective, with the exception of sample rate
reduction which reliably reduces computational resources, but does not increase
accuracy.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04231" title="Abstract">arXiv:2311.04231</a> (cross-list from eess.SP) [<a href="/pdf/2311.04231" title="Download PDF">pdf</a>, <a href="/format/2311.04231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Practical Large-Scale Roadside Multi-View Multi-Sensor Spatial  Synchronization Framework for Intelligent Transportation Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yong Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+Z">Zhiguo Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yunli Chen</a>, 
<a href="/search/eess?searchtype=author&query=Tian%2C+R">Rui Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 15 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Spatial synchronization in roadside scenarios is essential for integrating
data from multiple sensors at different locations. Current methods using
cascading spatial transformation (CST) often lead to cumulative errors in
large-scale deployments. Manual camera calibration is insufficient and requires
extensive manual work, and existing methods are limited to controlled or
single-view scenarios. To address these challenges, our research introduces a
parallel spatial transformation (PST)-based framework for large-scale,
multi-view, multi-sensor scenarios. PST parallelizes sensor coordinate system
transformation, reducing cumulative errors. We incorporate deep learning for
precise roadside monocular global localization, reducing manual work.
Additionally, we use geolocation cues and an optimization algorithm for
improved synchronization accuracy. Our framework has been tested in real-world
scenarios, outperforming CST-based methods. It significantly enhances
large-scale roadside multi-perspective, multi-sensor spatial synchronization,
reducing deployment costs.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04234" title="Abstract">arXiv:2311.04234</a> (cross-list from eess.SP) [<a href="/pdf/2311.04234" title="Download PDF">pdf</a>, <a href="/ps/2311.04234" title="Download PostScript">ps</a>, <a href="/format/2311.04234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging sinusoidal representation networks to predict fMRI signals  from EEG
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yamin Li</a>, 
<a href="/search/eess?searchtype=author&query=Lou%2C+A">Ange Lou</a>, 
<a href="/search/eess?searchtype=author&query=Chang%2C+C">Catie Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">In modern neuroscience, functional magnetic resonance imaging (fMRI) has been
a crucial and irreplaceable tool that provides a non-invasive window into the
dynamics of whole-brain activity. Nevertheless, fMRI is limited by hemodynamic
blurring as well as high cost, immobility, and incompatibility with metal
implants. Electroencephalography (EEG) is complementary to fMRI and can
directly record the cortical electrical activity at high temporal resolution,
but has more limited spatial resolution and is unable to recover information
about deep subcortical brain structures. The ability to obtain fMRI information
from EEG would enable cost-effective, imaging across a wider set of brain
regions. Further, beyond augmenting the capabilities of EEG, cross-modality
models would facilitate the interpretation of fMRI signals. However, as both
EEG and fMRI are high-dimensional and prone to artifacts, it is currently
challenging to model fMRI from EEG. To address this challenge, we propose a
novel architecture that can predict fMRI signals directly from multi-channel
EEG without explicit feature engineering. Our model achieves this by
implementing a Sinusoidal Representation Network (SIREN) to learn frequency
information in brain dynamics from EEG, which serves as the input to a
subsequent encoder-decoder to effectively reconstruct the fMRI signal from a
specific brain region. We evaluate our model using a simultaneous EEG-fMRI
dataset with 8 subjects and investigate its potential for predicting
subcortical fMRI signals. The present results reveal that our model outperforms
a recent state-of-the-art model, and indicates the potential of leveraging
periodic activation functions in deep neural networks to model functional
neuroimaging data.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04236" title="Abstract">arXiv:2311.04236</a> (cross-list from eess.SP) [<a href="/pdf/2311.04236" title="Download PDF">pdf</a>, <a href="/format/2311.04236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Agent-Based Collaborative Learning in Cross-Individual  Wearable Sensor-Based Human Activity Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Esmaeili%2C+A">Ahmad Esmaeili</a>, 
<a href="/search/eess?searchtype=author&query=Ghorrati%2C+Z">Zahra Ghorrati</a>, 
<a href="/search/eess?searchtype=author&query=Matson%2C+E+T">Eric T. Matson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">The rapid growth of wearable sensor technologies holds substantial promise
for the field of personalized and context-aware Human Activity Recognition.
Given the inherently decentralized nature of data sources within this domain,
the utilization of multi-agent systems with their inherent decentralization
capabilities presents an opportunity to facilitate the development of scalable,
adaptable, and privacy-conscious methodologies. This paper introduces a
collaborative distributed learning approach rooted in multi-agent principles,
wherein individual users of sensor-equipped devices function as agents within a
distributed network, collectively contributing to the comprehensive process of
learning and classifying human activities. In this proposed methodology, not
only is the privacy of activity monitoring data upheld for each individual,
eliminating the need for an external server to oversee the learning process,
but the system also exhibits the potential to surmount the limitations of
conventional centralized models and adapt to the unique attributes of each
user. The proposed approach has been empirically tested on two publicly
accessible human activity recognition datasets, specifically PAMAP2 and HARTH,
across varying settings. The provided empirical results conclusively highlight
the efficacy of inter-individual collaborative learning when contrasted with
centralized configurations, both in terms of local and global generalization.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04237" title="Abstract">arXiv:2311.04237</a> (cross-list from quant-ph) [<a href="/pdf/2311.04237" title="Download PDF">pdf</a>, <a href="/ps/2311.04237" title="Download PostScript">ps</a>, <a href="/format/2311.04237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Learning Quantum States with the Logarithmic Loss via VB-FTRL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Tseng%2C+W">Wei-Fu Tseng</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+K">Kai-Chun Chen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Xiao%2C+Z">Zi-Hong Xiao</a>, 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+Y">Yen-Huan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">Online learning quantum states with the logarithmic loss (LL-OLQS) is a
quantum generalization of online portfolio selection, a classic open problem in
the field of online learning for over three decades. The problem also emerges
in designing randomized optimization algorithms for maximum-likelihood quantum
state tomography. Recently, Jezequel et al. (<a href="/abs/2209.13932">arXiv:2209.13932</a>) proposed the
VB-FTRL algorithm, the first nearly regret-optimal algorithm for OPS with
moderate computational complexity. In this note, we generalize VB-FTRL for
LL-OLQS. Let $d$ denote the dimension and $T$ the number of rounds. The
generalized algorithm achieves a regret rate of $O ( d^2 \log ( d + T ) )$ for
LL-OLQS. Each iteration of the algorithm consists of solving a semidefinite
program that can be implemented in polynomial time by, e.g., cutting-plane
methods. For comparison, the best-known regret rate for LL-OLQS is currently $O
( d^2 \log T )$, achieved by the exponential weight method. However, there is
no explicit implementation available for the exponential weight method for
LL-OLQS. To facilitate the generalization, we introduce the notion of
VB-convexity. VB-convexity is a sufficient condition for the logarithmic
barrier associated with any function to be convex and is of independent
interest.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04241" title="Abstract">arXiv:2311.04241</a> (cross-list from eess.SP) [<a href="/pdf/2311.04241" title="Download PDF">pdf</a>, <a href="/ps/2311.04241" title="Download PostScript">ps</a>, <a href="/format/2311.04241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-Enabled Unmanned Vehicle-Assisted Reconfigurable Intelligent  Surfaces: Deployment, Prototyping, Experiments, and Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shen%2C+L">Li-Hsiang Shen</a>, 
<a href="/search/eess?searchtype=author&query=Feng%2C+K">Kai-Ten Feng</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+T">Ta-Sung Lee</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+Y">Yuan-Chun Lin</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+S">Shih-Cheng Lin</a>, 
<a href="/search/eess?searchtype=author&query=Chang%2C+C">Chia-Chan Chang</a>, 
<a href="/search/eess?searchtype=author&query=Chang%2C+S">Sheng-Fuh Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The requirement of wireless data demands is increasingly high as the
sixth-generation (6G) technology evolves. Reconfigurable intelligent surface
(RIS) is promisingly deemed to be one of 6G techniques for extending service
coverage, reducing power consumption, and enhancing spectral efficiency. In
this article, we have provided some fundamentals of RIS deployment in theory
and hardware perspectives as well as utilization of artificial intelligence
(AI) and machine learning. We conducted an intelligent deployment of RIS
(i-Dris) prototype, including dual-band auto-guided vehicle (AGV) assisted RISs
associated with an mmWave base station (BS) and a receiver. The RISs are
deployed on the AGV with configured incident/reflection angles. While, both the
mmWave BS and receiver are associated with an edge server monitoring downlink
packets for obtaining system throughput. We have designed a federated
multi-agent reinforcement learning scheme associated with several AGV-RIS
agents and sub-agents per AGV-RIS consisting of the deployment of position,
height, orientation and elevation angles. The experimental results presented
the stationary measurement in different aspects and scenarios. The i-Dris can
reach up to 980 Mbps transmission throughput under a bandwidth of 100 MHz with
comparably low complexity as well as rapid deployment, which outperforms the
other existing works. At last, we highlight some opportunities and future
issues in leveraging RIS-empowered wireless communication networks.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04253" title="Abstract">arXiv:2311.04253</a> (cross-list from eess.SP) [<a href="/pdf/2311.04253" title="Download PDF">pdf</a>, <a href="/ps/2311.04253" title="Download PostScript">ps</a>, <a href="/format/2311.04253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blind Federated Learning via Over-the-Air q-QAM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Razavikia%2C+S">Saeed Razavikia</a>, 
<a href="/search/eess?searchtype=author&query=Da+Silva+J%C3%BAnior%2C+J+M+B">Jos&#xe9; Mairton Barros Da Silva J&#xfa;nior</a>, 
<a href="/search/eess?searchtype=author&query=Fischione%2C+C">Carlo Fischione</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this work, we investigate federated edge learning over a fading multiple
access channel. To alleviate the communication burden between the edge devices
and the access point, we introduce a pioneering digital over-the-air
computation strategy employing q-ary quadrature amplitude modulation,
culminating in a low latency communication scheme. Indeed, we propose a new
federated edge learning framework in which edge devices use digital modulation
for over-the-air uplink transmission to the edge server while they have no
access to the channel state information. Furthermore, we incorporate multiple
antennas at the edge server to overcome the fading inherent in wireless
communication. We analyze the number of antennas required to mitigate the
fading impact effectively. We prove a non-asymptotic upper bound for the mean
squared error for the proposed federated learning with digital over-the-air
uplink transmissions under both noisy and fading conditions. Leveraging the
derived upper bound, we characterize the convergence rate of the learning
process of a non-convex loss function in terms of the mean square error of
gradients due to the fading channel. Furthermore, we substantiate the
theoretical assurances through numerical experiments concerning mean square
error and the convergence efficacy of the digital federated edge learning
framework. Notably, the results demonstrate that augmenting the number of
antennas at the edge server and adopting higher-order modulations improve the
model accuracy up to 60\%.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04258" title="Abstract">arXiv:2311.04258</a> (cross-list from eess.SP) [<a href="/pdf/2311.04258" title="Download PDF">pdf</a>, <a href="/ps/2311.04258" title="Download PostScript">ps</a>, <a href="/format/2311.04258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IoT-Based Environmental Control System for Fish Farms with Sensor  Integration and Machine Learning Decision Support
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dhinakaran%2C+D">D. Dhinakaran</a>, 
<a href="/search/eess?searchtype=author&query=Gopalakrishnan%2C+S">S. Gopalakrishnan</a>, 
<a href="/search/eess?searchtype=author&query=Manigandan%2C+M+D">M.D. Manigandan</a>, 
<a href="/search/eess?searchtype=author&query=Anish%2C+T+P">T. P. Anish</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In response to the burgeoning global demand for seafood and the challenges of
managing fish farms, we introduce an innovative IoT based environmental control
system that integrates sensor technology and advanced machine learning decision
support. Deploying a network of wireless sensors within the fish farm, we
continuously collect real-time data on crucial environmental parameters,
including water temperature, pH levels, humidity, and fish behavior. This data
undergoes meticulous preprocessing to ensure its reliability, including
imputation, outlier detection, feature engineering, and synchronization. At the
heart of our system are four distinct machine learning algorithms: Random
Forests predict and optimize water temperature and pH levels for the fish,
fostering their health and growth; Support Vector Machines (SVMs) function as
an early warning system, promptly detecting diseases and parasites in fish;
Gradient Boosting Machines (GBMs) dynamically fine-tune the feeding schedule
based on real-time environmental conditions, promoting resource efficiency and
fish productivity; Neural Networks manage the operation of critical equipment
like water pumps and heaters to maintain the desired environmental conditions
within the farm. These machine learning algorithms collaboratively make
real-time decisions to ensure that the fish farm's environmental conditions
align with predefined specifications, leading to improved fish health and
productivity while simultaneously reducing resource wastage, thereby
contributing to increased profitability and sustainability. This research
article showcases the power of data-driven decision support in fish farming,
promising to meet the growing demand for seafood while emphasizing
environmental responsibility and economic viability, thus revolutionizing the
future of fish farming.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04259" title="Abstract">arXiv:2311.04259</a> (cross-list from astro-ph.IM) [<a href="/pdf/2311.04259" title="Download PDF">pdf</a>, <a href="/format/2311.04259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ookami: An A64FX Computing Resource
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Calder%2C+A+C">A. C. Calder</a>, 
<a href="/search/astro-ph?searchtype=author&query=Siegmann%2C+E">E. Siegmann</a>, 
<a href="/search/astro-ph?searchtype=author&query=Feldman%2C+C">C. Feldman</a>, 
<a href="/search/astro-ph?searchtype=author&query=Chheda%2C+S">S. Chheda</a>, 
<a href="/search/astro-ph?searchtype=author&query=Smolarski%2C+D+C">D. C. Smolarski</a>, 
<a href="/search/astro-ph?searchtype=author&query=Swesty%2C+F+D">F. D. Swesty</a>, 
<a href="/search/astro-ph?searchtype=author&query=Curtis%2C+A">A. Curtis</a>, 
<a href="/search/astro-ph?searchtype=author&query=Dey%2C+J">J. Dey</a>, 
<a href="/search/astro-ph?searchtype=author&query=Carlson%2C+D">D. Carlson</a>, 
<a href="/search/astro-ph?searchtype=author&query=Michalowicz%2C+B">B. Michalowicz</a>, 
<a href="/search/astro-ph?searchtype=author&query=Harrison%2C+R+J">R. J. Harrison</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 3 figures, submitted to the Proceedings of 15th International Conference on Numerical Modeling of Space Plasma Flows
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; High Energy Astrophysical Phenomena (astro-ph.HE); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">We present a look at Ookami, a project providing community access to a
testbed supercomputer with the ARM-based A64FX processors developed by a
collaboration between RIKEN and Fujitsu and deployed in the Japanese
supercomputer Fugaku. We describe the project, provide details about the user
base and education/training program, and present highlights from performance
studies of two astrophysical simulation codes.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04285" title="Abstract">arXiv:2311.04285</a> (cross-list from quant-ph) [<a href="/pdf/2311.04285" title="Download PDF">pdf</a>, <a href="/format/2311.04285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compilation of product-formula Hamiltonian simulation via reinforcement  learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Trenkwalder%2C+L+M">Lea M. Trenkwalder</a>, 
<a href="/search/quant-ph?searchtype=author&query=Scerri%2C+E">Eleanor Scerri</a>, 
<a href="/search/quant-ph?searchtype=author&query=O%27Brien%2C+T+E">Thomas E. O&#x27;Brien</a>, 
<a href="/search/quant-ph?searchtype=author&query=Dunjko%2C+V">Vedran Dunjko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Hamiltonian simulation is believed to be one of the first tasks where quantum
computers can yield a quantum advantage. One of the most popular methods of
Hamiltonian simulation is Trotterization, which makes use of the approximation
$e^{i\sum_jA_j}\sim \prod_je^{iA_j}$ and higher-order corrections thereto.
However, this leaves open the question of the order of operations (i.e. the
order of the product over $j$, which is known to affect the quality of
approximation). In some cases this order is fixed by the desire to minimise the
error of approximation; when it is not the case, we propose that the order can
be chosen to optimize compilation to a native quantum architecture. This
presents a new compilation problem -- order-agnostic quantum circuit
compilation -- which we prove is NP-hard in the worst case. In lieu of an
easily-computable exact solution, we turn to methods of heuristic optimization
of compilation. We focus on reinforcement learning due to the sequential nature
of the compilation task, comparing it to simulated annealing and Monte Carlo
tree search. While two of the methods outperform a naive heuristic,
reinforcement learning clearly outperforms all others, with a gain of around
12% with respect to the second-best method and of around 50% compared to the
naive heuristic in terms of the gate count. We further test the ability of RL
to generalize across instances of the compilation problem, and find that a
single learner is able to solve entire problem families. This demonstrates the
ability of machine learning techniques to provide assistance in an
order-agnostic quantum compilation task.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04322" title="Abstract">arXiv:2311.04322</a> (cross-list from eess.SP) [<a href="/pdf/2311.04322" title="Download PDF">pdf</a>, <a href="/ps/2311.04322" title="Download PostScript">ps</a>, <a href="/format/2311.04322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NEAT-MUSIC: Auto-calibration of DOA Estimation for Terahertz-Band  Massive MIMO Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Elbir%2C+A+M">Ahmet M. Elbir</a>, 
<a href="/search/eess?searchtype=author&query=Celik%2C+A">Abdulkadir Celik</a>, 
<a href="/search/eess?searchtype=author&query=Eltawil%2C+A+M">Ahmed M. Eltawil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted paper in IEEE Wireless Communications Letters. arXiv admin note: text overlap with <a href="/abs/2310.16724">arXiv:2310.16724</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Terahertz (THz) band is envisioned for the future sixth generation wireless
systems thanks to its abundant bandwidth and very narrow beamwidth. These
features are one of the key enabling factors for high resolution sensing with
milli-degree level direction-of-arrival (DOA) estimation. Therefore, this paper
investigates the DOA estimation problem in THz systems in the presence of two
major error sources: 1) gain-phase mismatches, which occur due to the
deviations in the radio-frequency circuitry; 2) beam-squint, which is caused
because of the deviations in the generated beams at different subcarriers due
to ultra-wide bandwidth. An auto-calibration approach, namely NoisE subspAce
correcTion technique for MUltiple SIgnal Classification (NEAT-MUSIC), is
proposed based on the correction of the noise subspace for accurate DOA
estimation in the presence of gain-phase mismatches and beam-squint. To gauge
the performance of the proposed approach, the Cramer-Rao bounds are also
derived. Numerical results show the effectiveness of the proposed approach.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04339" title="Abstract">arXiv:2311.04339</a> (cross-list from eess.AS) [<a href="/pdf/2311.04339" title="Download PDF">pdf</a>, <a href="/format/2311.04339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InstrumentGen: Generating Sample-Based Musical Instruments From Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Nercessian%2C+S">Shahan Nercessian</a>, 
<a href="/search/eess?searchtype=author&query=Imort%2C+J">Johannes Imort</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">We introduce the text-to-instrument task, which aims at generating
sample-based musical instruments based on textual prompts. Accordingly, we
propose InstrumentGen, a model that extends a text-prompted generative audio
framework to condition on instrument family, source type, pitch (across an
88-key spectrum), velocity, and a joint text/audio embedding. Furthermore, we
present a differentiable loss function to evaluate the intra-instrument timbral
consistency of sample-based instruments. Our results establish a foundational
text-to-instrument baseline, extending research in the domain of automatic
sample-based instrument generation.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04374" title="Abstract">arXiv:2311.04374</a> (cross-list from econ.TH) [<a href="/pdf/2311.04374" title="Download PDF">pdf</a>, <a href="/format/2311.04374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Common Knowledge, Regained
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Gonczarowski%2C+Y+A">Yannai A. Gonczarowski</a>, 
<a href="/search/econ?searchtype=author&query=Moses%2C+Y">Yoram Moses</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Formally, for common knowledge to arise in a dynamic setting, knowledge that
it has arisen must be simultaneously attained by all players. As a result, new
common knowledge is unattainable in many realistic settings, due to timing
frictions. This unintuitive phenomenon, observed by Halpern and Moses (1990),
was discussed by Arrow et al. (1987) and by Aumann (1989), was called a paradox
by Morris (2014), and has evaded satisfactory resolution for four decades. We
resolve this paradox by proposing a new definition for common knowledge, which
coincides with the traditional one in static settings but generalizes it in
dynamic settings. Under our definition, common knowledge can arise without
simultaneity, particularly in canonical examples of the Haplern-Moses paradox.
We demonstrate its usefulness by deriving for it an agreement theorem \`a la
Aumann (1976), and showing that it arises in the setting of Geanakoplos and
Polemarchakis (1982) with timing frictions added.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04418" title="Abstract">arXiv:2311.04418</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2311.04418" title="Download PDF">pdf</a>, <a href="/format/2311.04418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-accelerated Discovery of Altermagnetic Materials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Gao%2C+Z">Ze-Feng Gao</a>, 
<a href="/search/cond-mat?searchtype=author&query=Qu%2C+S">Shuai Qu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zeng%2C+B">Bocheng Zeng</a>, 
<a href="/search/cond-mat?searchtype=author&query=Wen%2C+J">Ji-Rong Wen</a>, 
<a href="/search/cond-mat?searchtype=author&query=Sun%2C+H">Hao Sun</a>, 
<a href="/search/cond-mat?searchtype=author&query=Guo%2C+P">Pengjie Guo</a>, 
<a href="/search/cond-mat?searchtype=author&query=Lu%2C+Z">Zhong-Yi Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages; 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Artificial Intelligence (cs.AI); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Altermagnetism, a new magnetic phase, has been theoretically proposed and
experimentally verified to be distinct from ferromagnetism and
antiferromagnetism. Although altermagnets have been found to possess many
exotic physical properties, the very limited availability of known
altermagnetic materials~(e.g., 14 confirmed materials) hinders the study of
such properties. Hence, discovering more types of altermagnetic materials is
crucial for a comprehensive understanding of altermagnetism and thus
facilitating new applications in the next generation information technologies,
e.g., storage devices and high-sensitivity sensors. Here, we report 25 new
altermagnetic materials that cover metals, semiconductors, and insulators,
discovered by an AI search engine unifying symmetry analysis, graph neural
network pre-training, optimal transport theory, and first-principles electronic
structure calculation. The wide range of electronic structural characteristics
reveals that various innovative physical properties manifest in these newly
discovered altermagnetic materials, e.g., anomalous Hall effect, anomalous Kerr
effect, and topological property. Noteworthy, we discovered 8 $i$-wave
altermagnetic materials for the first time. Overall, the AI search engine
performs much better than human experts and suggests a set of new altermagnetic
materials with unique properties, outlining its potential for accelerated
discovery of altermagnetic materials.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04419" title="Abstract">arXiv:2311.04419</a> (cross-list from q-bio.BM) [<a href="/pdf/2311.04419" title="Download PDF">pdf</a>, <a href="/ps/2311.04419" title="Download PostScript">ps</a>, <a href="/format/2311.04419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PepLand: a large-scale pre-trained peptide representation model for a  comprehensive landscape of both canonical and non-canonical amino acids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+R">Ruochi Zhang</a> (1,2,3), 
<a href="/search/q-bio?searchtype=author&query=Wu%2C+H">Haoran Wu</a> (3), 
<a href="/search/q-bio?searchtype=author&query=Xiu%2C+Y">Yuting Xiu</a> (3), 
<a href="/search/q-bio?searchtype=author&query=Li%2C+K">Kewei Li</a> (1,4), 
<a href="/search/q-bio?searchtype=author&query=Chen%2C+N">Ningning Chen</a> (3), 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+Y">Yu Wang</a> (3), 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+Y">Yan Wang</a> (1,2,4), 
<a href="/search/q-bio?searchtype=author&query=Gao%2C+X">Xin Gao</a> (5,6,7), 
<a href="/search/q-bio?searchtype=author&query=Zhou%2C+F">Fengfeng Zhou</a> (1,4,7) ((1) Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, China. (2) School of Artificial Intelligence, Jilin University, Changchun, China. (3) Syneron Technology, Guangzhou, China. (4) College of Computer Science and Technology, Jilin University, Changchun, China. (5) Computational Bioscience Research Center, King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia. (6) Computer Science Program, Computer, Electrical and Mathematical Sciences and Engineering Division, King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia. (7) Corresponding Authors)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Artificial Intelligence (cs.AI); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">In recent years, the scientific community has become increasingly interested
on peptides with non-canonical amino acids due to their superior stability and
resistance to proteolytic degradation. These peptides present promising
modifications to biological, pharmacological, and physiochemical attributes in
both endogenous and engineered peptides. Notwithstanding their considerable
advantages, the scientific community exhibits a conspicuous absence of an
effective pre-trained model adept at distilling feature representations from
such complex peptide sequences. We herein propose PepLand, a novel pre-training
architecture for representation and property analysis of peptides spanning both
canonical and non-canonical amino acids. In essence, PepLand leverages a
comprehensive multi-view heterogeneous graph neural network tailored to unveil
the subtle structural representations of peptides. Empirical validations
underscore PepLand's effectiveness across an array of peptide property
predictions, encompassing protein-protein interactions, permeability,
solubility, and synthesizability. The rigorous evaluation confirms PepLand's
unparalleled capability in capturing salient synthetic peptide features,
thereby laying a robust foundation for transformative advances in
peptide-centric research domains. We have made all the source code utilized in
this study publicly accessible via GitHub at
https://github.com/zhangruochi/pepland
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04429" title="Abstract">arXiv:2311.04429</a> (cross-list from math.CO) [<a href="/pdf/2311.04429" title="Download PDF">pdf</a>, <a href="/format/2311.04429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quasi-Transitive Mixed Graphs and Undirected Squares of Oriented Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Duffy%2C+C">Christopher Duffy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We consider the problem of classifying those graphs that arise as an
undirected square of an oriented graph by generalising the notion of
quasi-transitive directed graphs to mixed graphs. We fully classify those
graphs of maximum degree three and those graphs of girth at least four that
arise an undirected square of an oriented graph. In contrast to the recognition
problem for graphs that admit a quasi-transitive orientation, we find it is
NP-complete to decide if a graph admits a partial orientation as a
quasi-transitive mixed graph. We prove the problem is Polynomial when
restricted to inputs of maximum degree three, but remains NP-complete when
restricted to inputs with maximum degree at least five. Our proof further
implies that for fixed $k \geq 3$, it is NP-complete to decide if a graph
arises as an undirected square of an orientation of a graph with $\Delta = k$.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04430" title="Abstract">arXiv:2311.04430</a> (cross-list from eess.IV) [<a href="/pdf/2311.04430" title="Download PDF">pdf</a>, <a href="/format/2311.04430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blurry Video Compression: A Trade-off between Visual Enhancement and  Data Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Argaw%2C+D+M">Dawit Mureja Argaw</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+J">Junsik Kim</a>, 
<a href="/search/eess?searchtype=author&query=Kweon%2C+I+S">In So Kweon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Existing video compression (VC) methods primarily aim to reduce the spatial
and temporal redundancies between consecutive frames in a video while
preserving its quality. In this regard, previous works have achieved remarkable
results on videos acquired under specific settings such as instant (known)
exposure time and shutter speed which often result in sharp videos. However,
when these methods are evaluated on videos captured under different temporal
priors, which lead to degradations like motion blur and low frame rate, they
fail to maintain the quality of the contents. In this work, we tackle the VC
problem in a general scenario where a given video can be blurry due to
predefined camera settings or dynamics in the scene. By exploiting the natural
trade-off between visual enhancement and data compression, we formulate VC as a
min-max optimization problem and propose an effective framework and training
strategy to tackle the problem. Extensive experimental results on several
benchmark datasets confirm the effectiveness of our method compared to several
state-of-the-art VC approaches.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04442" title="Abstract">arXiv:2311.04442</a> (cross-list from eess.IV) [<a href="/pdf/2311.04442" title="Download PDF">pdf</a>, <a href="/format/2311.04442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SS-MAE: Spatial-Spectral Masked Auto-Encoder for Multi-Source Remote  Sensing Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lin%2C+J">Junyan Lin</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+F">Feng Gao</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+X">Xiaocheng Shi</a>, 
<a href="/search/eess?searchtype=author&query=Dong%2C+J">Junyu Dong</a>, 
<a href="/search/eess?searchtype=author&query=Du%2C+Q">Qian Du</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE TGRS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Masked image modeling (MIM) is a highly popular and effective self-supervised
learning method for image understanding. Existing MIM-based methods mostly
focus on spatial feature modeling, neglecting spectral feature modeling.
Meanwhile, existing MIM-based methods use Transformer for feature extraction,
some local or high-frequency information may get lost. To this end, we propose
a spatial-spectral masked auto-encoder (SS-MAE) for HSI and LiDAR/SAR data
joint classification. Specifically, SS-MAE consists of a spatial-wise branch
and a spectral-wise branch. The spatial-wise branch masks random patches and
reconstructs missing pixels, while the spectral-wise branch masks random
spectral channels and reconstructs missing channels. Our SS-MAE fully exploits
the spatial and spectral representations of the input data. Furthermore, to
complement local features in the training stage, we add two lightweight CNNs
for feature extraction. Both global and local features are taken into account
for feature modeling. To demonstrate the effectiveness of the proposed SS-MAE,
we conduct extensive experiments on three publicly available datasets.
Extensive experiments on three multi-source datasets verify the superiority of
our SS-MAE compared with several state-of-the-art baselines. The source codes
are available at \url{https://github.com/summitgao/SS-MAE}.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04455" title="Abstract">arXiv:2311.04455</a> (cross-list from math.OC) [<a href="/pdf/2311.04455" title="Download PDF">pdf</a>, <a href="/ps/2311.04455" title="Download PostScript">ps</a>, <a href="/format/2311.04455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vector-Valued Gossip over $w$-Holonomic Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bayram%2C+E">Erkan Bayram</a>, 
<a href="/search/math?searchtype=author&query=Belabbas%2C+M">Mohamed-Ali Belabbas</a>, 
<a href="/search/math?searchtype=author&query=Ba%C5%9Far%2C+T">Tamer Ba&#x15f;ar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">We study the weighted average consensus problem for a gossip network of
agents with vector-valued states. For a given matrix-weighted graph, the gossip
process is described by a sequence of pairs of adjacent agents communicating
and updating their states based on the edge matrix weight. Our key contribution
is providing conditions for the convergence of this non-homogeneous Markov
process as well as the characterization of its limit set. To this end, we
introduce the notion of "$w$-holonomy" of a set of stochastic matrices, which
enables the characterization of sequences of gossiping pairs resulting in
reaching a desired consensus in a decentralized manner. Stated otherwise, our
result characterizes the limiting behavior of infinite products of
(non-commuting, possibly with absorbing states) stochastic matrices.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04473" title="Abstract">arXiv:2311.04473</a> (cross-list from physics.optics) [<a href="/pdf/2311.04473" title="Download PDF">pdf</a>, <a href="/ps/2311.04473" title="Download PostScript">ps</a>, <a href="/format/2311.04473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> All-Optical Phase Conjugation Using Diffractive Wavefront Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Shen%2C+C">Che-Yung Shen</a>, 
<a href="/search/physics?searchtype=author&query=Li%2C+J">Jingxi Li</a>, 
<a href="/search/physics?searchtype=author&query=Gan%2C+T">Tianyi Gan</a>, 
<a href="/search/physics?searchtype=author&query=Jarrahi%2C+M">Mona Jarrahi</a>, 
<a href="/search/physics?searchtype=author&query=Ozcan%2C+A">Aydogan Ozcan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 Pages, 9 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Computer Vision and Pattern Recognition (cs.CV); Applied Physics (physics.app-ph)

</div>
<p class="mathjax">Optical phase conjugation (OPC) is a nonlinear technique used for
counteracting wavefront distortions, with various applications ranging from
imaging to beam focusing. Here, we present the design of a diffractive
wavefront processor to approximate all-optical phase conjugation operation for
input fields with phase aberrations. Leveraging deep learning, a set of passive
diffractive layers was optimized to all-optically process an arbitrary
phase-aberrated coherent field from an input aperture, producing an output
field with a phase distribution that is the conjugate of the input wave. We
experimentally validated the efficacy of this wavefront processor by 3D
fabricating diffractive layers trained using deep learning and performing OPC
on phase distortions never seen by the diffractive processor during its
training. Employing terahertz radiation, our physical diffractive processor
successfully performed the OPC task through a shallow spatially-engineered
volume that axially spans tens of wavelengths. In addition to this transmissive
OPC configuration, we also created a diffractive phase-conjugate mirror by
combining deep learning-optimized diffractive layers with a standard mirror.
Given its compact, passive and scalable nature, our diffractive wavefront
processor can be used for diverse OPC-related applications, e.g., turbidity
suppression and aberration correction, and is also adaptable to different parts
of the electromagnetic spectrum, especially those where cost-effective
wavefront engineering solutions do not exist.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04520" title="Abstract">arXiv:2311.04520</a> (cross-list from math.OC) [<a href="/pdf/2311.04520" title="Download PDF">pdf</a>, <a href="/ps/2311.04520" title="Download PostScript">ps</a>, <a href="/format/2311.04520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Mirror Descent Bilevel Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Huang%2C+F">Feihu Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages. arXiv admin note: text overlap with <a href="/abs/2303.03944">arXiv:2303.03944</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In the paper, we propose a class of efficient adaptive bilevel methods based
on mirror descent for nonconvex bilevel optimization, where its upper-level
problem is nonconvex possibly with nonsmooth regularization, and its
lower-level problem is also nonconvex while satisfies Polyak-{\L}ojasiewicz
(PL) condition. To solve these deterministic bilevel problems, we present an
efficient adaptive projection-aid gradient (i.e., AdaPAG) method based on
mirror descent, and prove that it obtains the best known gradient complexity of
$O(\epsilon^{-1})$ for finding an $\epsilon$-stationary solution of nonconvex
bilevel problems. To solve these stochastic bilevel problems, we propose an
efficient adaptive stochastic projection-aid gradient (i.e., AdaVSPAG) methods
based on mirror descent and variance-reduced techniques, and prove that it
obtains the best known gradient complexity of $O(\epsilon^{-3/2})$ for finding
an $\epsilon$-stationary solution. Since the PL condition relaxes the strongly
convex, our algorithms can be used to nonconvex strongly-convex bilevel
optimization. Theoretically, we provide a useful convergence analysis framework
for our methods under some mild conditions, and prove that our methods have a
fast convergence rate of $O(\frac{1}{T})$, where $T$ denotes the number of
iterations.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04537" title="Abstract">arXiv:2311.04537</a> (cross-list from eess.SP) [<a href="/pdf/2311.04537" title="Download PDF">pdf</a>, <a href="/format/2311.04537" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning Assisted Multiuser MIMO Load Modulated Systems for  Enhanced Downlink mmWave Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yu%2C+E">Ercong Yu</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+J">Jinle Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Q">Qiang Li</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Z">Zilong Liu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+H">Hongyang Chen</a>, 
<a href="/search/eess?searchtype=author&query=Shamai%2C+S">Shlomo Shamai</a> (Shitz), 
<a href="/search/eess?searchtype=author&query=Poor%2C+H+V">H. Vincent Poor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, Journal, accepted by IEEE TWC
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper is focused on multiuser load modulation arrays (MU-LMAs) which are
attractive due to their low system complexity and reduced cost for millimeter
wave (mmWave) multi-input multi-output (MIMO) systems. The existing precoding
algorithm for downlink MU-LMA relies on a sub-array structured (SAS)
transmitter which may suffer from decreased degrees of freedom and complex
system configuration. Furthermore, a conventional LMA codebook with codewords
uniformly distributed on a hypersphere may not be channel-adaptive and may lead
to increased signal detection complexity. In this paper, we conceive an MU-LMA
system employing a full-array structured (FAS) transmitter and propose two
algorithms accordingly. The proposed FAS-based system addresses the SAS
structural problems and can support larger numbers of users. For LMA-imposed
constant-power downlink precoding, we propose an FAS-based normalized block
diagonalization (FAS-NBD) algorithm. However, the forced normalization may
result in performance degradation. This degradation, together with the
aforementioned codebook design problems, is difficult to solve analytically.
This motivates us to propose a Deep Learning-enhanced (FAS-DL-NBD) algorithm
for adaptive codebook design and codebook-independent decoding. It is shown
that the proposed algorithms are robust to imperfect knowledge of channel state
information and yield excellent error performance. Moreover, the FAS-DL-NBD
algorithm enables signal detection with low complexity as the number of bits
per codeword increases.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04546" title="Abstract">arXiv:2311.04546</a> (cross-list from eess.SP) [<a href="/pdf/2311.04546" title="Download PDF">pdf</a>, <a href="/ps/2311.04546" title="Download PostScript">ps</a>, <a href="/format/2311.04546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discerning and Enhancing the Weighted Sum-Rate Maximization Algorithms  in Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Z">Zepeng Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+Z">Ziping Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Shen%2C+K">Kaiming Shen</a>, 
<a href="/search/eess?searchtype=author&query=Palomar%2C+D+P">Daniel P. Palomar</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+W">Wei Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Weighted sum-rate (WSR) maximization plays a critical role in communication
system design. This paper examines three optimization methods for WSR
maximization, which ensure convergence to stationary points: two block
coordinate ascent (BCA) algorithms, namely, weighted sum-minimum mean-square
error (WMMSE) and WSR maximization via fractional programming (WSR-FP), along
with a minorization-maximization (MM) algorithm, WSR maximization via MM
(WSR-MM). Our contributions are threefold. Firstly, we delineate the exact
relationships among WMMSE, WSR-FP, and WSR-MM, which, despite their extensive
use in the literature, lack a comprehensive comparative study. By probing the
theoretical underpinnings linking the BCA and MM algorithmic frameworks, we
reveal the direct correlations between the equivalent transformation
techniques, essential to the development of WMMSE and WSR-FP, and the surrogate
functions pivotal to WSR-MM. Secondly, we propose a novel algorithm, WSR-MM+,
harnessing the flexibility of selecting surrogate functions in MM framework. By
circumventing the repeated matrix inversions in the search for optimal Lagrange
multipliers in existing algorithms, WSR-MM+ significantly reduces the
computational load per iteration and accelerates convergence. Thirdly, we
reconceptualize WSR-MM+ within the BCA framework, introducing a new equivalent
transform, which gives rise to an enhanced version of WSR-FP, named as WSR-FP+.
We further demonstrate that WSR-MM+ can be construed as the basic gradient
projection method. This perspective yields a deeper understanding into its
computational intricacies. Numerical simulations corroborate the connections
between WMMSE, WSR-FP, and WSR-MM and confirm the efficacy of the proposed
WSR-MM+ and WSR-FP+ algorithms.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04552" title="Abstract">arXiv:2311.04552</a> (cross-list from eess.IV) [<a href="/pdf/2311.04552" title="Download PDF">pdf</a>, <a href="/format/2311.04552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A 3D generative model of pathological multi-modal MR images and  segmentations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fernandez%2C+V">Virginia Fernandez</a>, 
<a href="/search/eess?searchtype=author&query=Pinaya%2C+W+H+L">Walter Hugo Lopez Pinaya</a>, 
<a href="/search/eess?searchtype=author&query=Borges%2C+P">Pedro Borges</a>, 
<a href="/search/eess?searchtype=author&query=Graham%2C+M+S">Mark S. Graham</a>, 
<a href="/search/eess?searchtype=author&query=Vercauteren%2C+T">Tom Vercauteren</a>, 
<a href="/search/eess?searchtype=author&query=Cardoso%2C+M+J">M. Jorge Cardoso</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at the 2023 Deep Generative Models (DGM4MICCAI) MICCAI workshop (Vancouver, Canada)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Generative modelling and synthetic data can be a surrogate for real medical
imaging datasets, whose scarcity and difficulty to share can be a nuisance when
delivering accurate deep learning models for healthcare applications. In recent
years, there has been an increased interest in using these models for data
augmentation and synthetic data sharing, using architectures such as generative
adversarial networks (GANs) or diffusion models (DMs). Nonetheless, the
application of synthetic data to tasks such as 3D magnetic resonance imaging
(MRI) segmentation remains limited due to the lack of labels associated with
the generated images. Moreover, many of the proposed generative MRI models lack
the ability to generate arbitrary modalities due to the absence of explicit
contrast conditioning. These limitations prevent the user from adjusting the
contrast and content of the images and obtaining more generalisable data for
training task-specific models. In this work, we propose brainSPADE3D, a 3D
generative model for brain MRI and associated segmentations, where the user can
condition on specific pathological phenotypes and contrasts. The proposed joint
imaging-segmentation generative model is shown to generate high-fidelity
synthetic images and associated segmentations, with the ability to combine
pathologies. We demonstrate how the model can alleviate issues with
segmentation model performance when unexpected pathologies are present in the
data.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04558" title="Abstract">arXiv:2311.04558</a> (cross-list from physics.optics) [<a href="/pdf/2311.04558" title="Download PDF">pdf</a>, <a href="/format/2311.04558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Free-Space Optical Spiking Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Ahmadi%2C+R">Reyhane Ahmadi</a>, 
<a href="/search/physics?searchtype=author&query=Ahmadnejad%2C+A">Amirreza Ahmadnejad</a>, 
<a href="/search/physics?searchtype=author&query=Koohi%2C+S">Somayyeh Koohi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Neuromorphic engineering has emerged as a promising avenue for developing
brain-inspired computational systems. However, conventional electronic AI-based
processors often encounter challenges related to processing speed and thermal
dissipation. As an alternative, optical implementations of such processors have
been proposed, capitalizing on the intrinsic information-processing
capabilities of light. Within the realm of optical neuromorphic engineering,
various optical neural networks (ONNs) have been explored. Among these, Spiking
Neural Networks (SNNs) have exhibited notable success in emulating the
computational principles of the human brain. Nevertheless, the integration of
optical SNN processors has presented formidable obstacles, mainly when dealing
with the computational demands of large datasets. In response to these
challenges, we introduce a pioneering concept: the Free-space Optical deep
Spiking Convolutional Neural Network (OSCNN). This novel approach draws
inspiration from computational models of the human eye. We have meticulously
designed various optical components within the OSCNN to tackle object detection
tasks across prominent benchmark datasets, including MNIST, ETH 80, and
Caltech. Our results demonstrate promising performance with minimal latency and
power consumption compared to their electronic ONN counterparts. Additionally,
we conducted several pertinent simulations, such as optical intensity
to-latency conversion and synchronization. Of particular significance is the
evaluation of the feature extraction layer, employing a Gabor filter bank,
which stands to impact the practical deployment of diverse ONN architectures
significantly.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04575" title="Abstract">arXiv:2311.04575</a> (cross-list from quant-ph) [<a href="/pdf/2311.04575" title="Download PDF">pdf</a>, <a href="/format/2311.04575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep learning as a tool for quantum error reduction in quantum image  processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Werner%2C+K">Krzysztof Werner</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wereszczy%C5%84ski%2C+K">Kamil Wereszczy&#x144;ski</a>, 
<a href="/search/quant-ph?searchtype=author&query=Potempa%2C+R">Rafa&#x142; Potempa</a>, 
<a href="/search/quant-ph?searchtype=author&query=Cyran%2C+K">Krzysztof Cyran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Despite the limited availability and quantum volume of quantum computers,
quantum image representation is a widely researched area. Currently developed
methods use quantum entanglement to encode information about pixel positions.
These methods range from using the angle parameter of the rotation gate (e.g.,
the Flexible Representation of Quantum Images, FRQI), sequences of qubits
(e.g., Novel Enhanced Quantum Representation, NEQR), or the angle parameter of
the phase shift gates (e.g., Local Phase Image Quantum Encoding, LPIQE) for
storing color information. All these methods are significantly affected by
decoherence and other forms of quantum noise, which is an inseparable part of
quantum computing in the noisy intermediate-scale quantum era. These phenomena
can highly influence the measurements and result in extracted images that are
visually dissimilar to the originals. Because this process is at its foundation
quantum, the computational reversal of this process is possible. There are many
methods for error correction, mitigation, and reduction, but all of them use
quantum computer time or additional qubits to achieve the desired result. We
report the successful use of a generative adversarial network trained for
image-to-image translation, in conjunction with Phase Distortion Unraveling
error reduction method, for reducing overall error in images encoded using
LPIQE.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04580" title="Abstract">arXiv:2311.04580</a> (cross-list from math.OC) [<a href="/pdf/2311.04580" title="Download PDF">pdf</a>, <a href="/format/2311.04580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient computation of Lipschitz constants for MPC with symmetries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Teichrib%2C+D">Dieter Teichrib</a>, 
<a href="/search/math?searchtype=author&query=Darup%2C+M+S">Moritz Schulze Darup</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures, 2 tables, to be published in the proceedings of the 62nd IEEE Conference on Decision and Control (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Lipschitz constants for linear MPC are useful for certifying inherent
robustness against unmodeled disturbances or robustness for neural
network-based approximations of the control law. In both cases, knowing the
minimum Lipschitz constant leads to less conservative certifications. Computing
this minimum Lipschitz constant is trivial given the explicit MPC. However, the
computation of the explicit MPC may be intractable for complex systems. The
paper discusses a method for efficiently computing the minimum Lipschitz
constant without using the explicit control law. The proposed method simplifies
a recently presented mixed-integer linear program (MILP) that computes the
minimum Lipschitz constant. The simplification is obtained by exploiting
saturation and symmetries of the control law and irrelevant constraints of the
optimal control problem.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04600" title="Abstract">arXiv:2311.04600</a> (cross-list from eess.SP) [<a href="/pdf/2311.04600" title="Download PDF">pdf</a>, <a href="/ps/2311.04600" title="Download PostScript">ps</a>, <a href="/format/2311.04600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Deep Learning Based Resource Allocator for Communication Systems with  Dynamic User Utility Demands
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Behmandpoor%2C+P">Pourya Behmandpoor</a>, 
<a href="/search/eess?searchtype=author&query=Patrinos%2C+P">Panagiotis Patrinos</a>, 
<a href="/search/eess?searchtype=author&query=Moonen%2C+M">Marc Moonen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI); Optimization and Control (math.OC)

</div>
<p class="mathjax">Deep learning (DL) based resource allocation (RA) has recently gained a lot
of attention due to its performance efficiency. However, most of the related
studies assume an ideal case where the number of users and their utility
demands, e.g., data rate constraints, are fixed and the designed DL based RA
scheme exploits a policy trained only for these fixed parameters. A
computationally complex policy retraining is required whenever these parameters
change. Therefore, in this paper, a DL based resource allocator (ALCOR) is
introduced, which allows users to freely adjust their utility demands based on,
e.g., their application layer. ALCOR employs deep neural networks (DNNs), as
the policy, in an iterative optimization algorithm. The optimization algorithm
aims to optimize the on-off status of users in a time-sharing problem to
satisfy their utility demands in expectation. The policy performs unconstrained
RA (URA) -- RA without taking into account user utility demands -- among active
users to maximize the sum utility (SU) at each time instant. Based on the
chosen URA scheme, ALCOR can perform RA in a model-based or model-free manner
and in a centralized or distributed scenario. Derived convergence analyses
provide guarantees for the convergence of ALCOR, and numerical experiments
corroborate its effectiveness.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04604" title="Abstract">arXiv:2311.04604</a> (cross-list from eess.SP) [<a href="/pdf/2311.04604" title="Download PDF">pdf</a>, <a href="/format/2311.04604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zeroth-order Asynchronous Learning with Bounded Delays with a Use-case  in Resource Allocation in Communication Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Behmandpoor%2C+P">Pourya Behmandpoor</a>, 
<a href="/search/eess?searchtype=author&query=Moonen%2C+M">Marc Moonen</a>, 
<a href="/search/eess?searchtype=author&query=Patrinos%2C+P">Panagiotis Patrinos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA); Optimization and Control (math.OC)

</div>
<p class="mathjax">Distributed optimization has experienced a significant surge in interest due
to its wide-ranging applications in distributed learning and adaptation. While
various scenarios, such as shared-memory, local-memory, and consensus-based
approaches, have been extensively studied in isolation, there remains a need
for further exploration of their interconnections. This paper specifically
concentrates on a scenario where agents collaborate toward a unified mission
while potentially having distinct tasks. Each agent's actions can potentially
impact other agents through interactions. Within this context, the objective
for the agents is to optimize their local parameters based on the aggregate of
local reward functions, where only local zeroth-order oracles are available.
Notably, the learning process is asynchronous, meaning that agents update and
query their zeroth-order oracles asynchronously while communicating with other
agents subject to bounded but possibly random communication delays. This paper
presents theoretical convergence analyses and establishes a convergence rate
for the proposed approach. Furthermore, it addresses the relevant issue of deep
learning-based resource allocation in communication networks and conducts
numerical experiments in which agents, acting as transmitters, collaboratively
train their individual (possibly unique) policies to maximize a common
performance metric.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04627" title="Abstract">arXiv:2311.04627</a> (cross-list from math.OC) [<a href="/pdf/2311.04627" title="Download PDF">pdf</a>, <a href="/format/2311.04627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fokker-Planck analysis of superresolution microscopy images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Annunziato%2C+M">Mario Annunziato</a>, 
<a href="/search/math?searchtype=author&query=Borz%C3%AC%2C+A">Alfio Borz&#xec;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA); Biological Physics (physics.bio-ph)

</div>
<p class="mathjax">A method for the analysis of superresolution microscopy images is presented.
This method is based on the analysis of stochastic trajectories of particles
moving on the membrane of a cell with the assumption that this motion is
determined by the properties of this membrane. Thus, the purpose of this method
is to recover the structural properties of the membrane by solving an inverse
problem governed by the Fokker-Planck equation related to the stochastic
trajectories. Results of numerical experiments demonstrate the ability of the
proposed method to reconstruct the potential of a cell membrane by using
synthetic data similar those captured by superresolution microscopy of
luminescent activated proteins.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04636" title="Abstract">arXiv:2311.04636</a> (cross-list from stat.ML) [<a href="/pdf/2311.04636" title="Download PDF">pdf</a>, <a href="/format/2311.04636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Linear Gaussian Polytree Models with Interventions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Tramontano%2C+D">D. Tramontano</a>, 
<a href="/search/stat?searchtype=author&query=Waldmann%2C+L">L. Waldmann</a>, 
<a href="/search/stat?searchtype=author&query=Drton%2C+M">M. Drton</a>, 
<a href="/search/stat?searchtype=author&query=Duarte%2C+E">E. Duarte</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in: IEEE Journal on Selected Areas in Information Theory, Special Issue: Causality: Fundamental Limits and Applications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We present a consistent and highly scalable local approach to learn the
causal structure of a linear Gaussian polytree using data from interventional
experiments with known intervention targets. Our methods first learn the
skeleton of the polytree and then orient its edges. The output is a CPDAG
representing the interventional equivalence class of the polytree of the true
underlying distribution. The skeleton and orientation recovery procedures we
use rely on second order statistics and low-dimensional marginal distributions.
We assess the performance of our methods under different scenarios in synthetic
data sets and apply our algorithm to learn a polytree in a gene expression
interventional data set. Our simulation studies demonstrate that our approach
is fast, has good accuracy in terms of structural Hamming distance, and handles
problems with thousands of nodes.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04644" title="Abstract">arXiv:2311.04644</a> (cross-list from math.NT) [<a href="/pdf/2311.04644" title="Download PDF">pdf</a>, <a href="/ps/2311.04644" title="Download PostScript">ps</a>, <a href="/format/2311.04644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bounds on the density of smooth lattice coverings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ordentlich%2C+O">Or Ordentlich</a>, 
<a href="/search/math?searchtype=author&query=Regev%2C+O">Oded Regev</a>, 
<a href="/search/math?searchtype=author&query=Weiss%2C+B">Barak Weiss</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Number Theory (math.NT)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Let $K$ be a convex body in $\mathbb{R}^n$, let $L$ be a lattice with
covolume one, and let $\eta&gt;0$. We say that $K$ and $L$ form an $\eta$-smooth
cover if each point $x \in \mathbb{R}^n$ is covered by $(1 \pm \eta) vol(K)$
translates of $K$ by $L$. We prove that for any positive $\sigma, \eta$,
asymptotically as $n \to \infty$, for any $K$ of volume $n^{3+\sigma}$, one can
find a lattice $L$ for which $L, K$ form an $\eta$-smooth cover. Moreover, this
property is satisfied with high probability for a lattice chosen randomly,
according to the Haar-Siegel measure on the space of lattices. Similar results
hold for random construction A lattices, albeit with a worse power law,
provided the ratio between the covering and packing radii of $\mathbb{Z}^n$
with respect to $K$ is at most polynomial in $n$. Our proofs rely on a recent
breakthrough by Dhar and Dvir on the discrete Kakeya problem.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04656" title="Abstract">arXiv:2311.04656</a> (cross-list from math.CO) [<a href="/pdf/2311.04656" title="Download PDF">pdf</a>, <a href="/ps/2311.04656" title="Download PostScript">ps</a>, <a href="/format/2311.04656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing pivot-minors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dabrowski%2C+K+K">Konrad K. Dabrowski</a>, 
<a href="/search/math?searchtype=author&query=Dross%2C+F">Fran&#xe7;ois Dross</a>, 
<a href="/search/math?searchtype=author&query=Jeong%2C+J">Jisu Jeong</a>, 
<a href="/search/math?searchtype=author&query=Kant%C3%A9%2C+M+M">Mamadou Moustapha Kant&#xe9;</a>, 
<a href="/search/math?searchtype=author&query=Kwon%2C+O">O-joung Kwon</a>, 
<a href="/search/math?searchtype=author&query=Oum%2C+S">Sang-il Oum</a>, 
<a href="/search/math?searchtype=author&query=Paulusma%2C+D">Dani&#xeb;l Paulusma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 9 figures. An extended abstract appeared in the proceedings of WG2018
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">A graph $G$ contains a graph $H$ as a pivot-minor if $H$ can be obtained from
$G$ by applying a sequence of vertex deletions and edge pivots. Pivot-minors
play an important role in the study of rank-width. Pivot-minors have mainly
been studied from a structural perspective. In this paper we perform the first
systematic computational complexity study of pivot-minors. We first prove that
the Pivot-Minor problem, which asks if a given graph $G$ contains a pivot-minor
isomorphic to a given graph $H$, is NP-complete. If $H$ is not part of the
input, we denote the problem by $H$-Pivot-Minor. We give a certifying
polynomial-time algorithm for $H$-Pivot-Minor when (1) $H$ is an induced
subgraph of $P_3+tP_1$ for some integer $t\geq 0$, (2) $H=K_{1,t}$ for some
integer $t\geq 1$, or (3) $|V(H)|\leq 4$ except when $H \in \{K_4,C_3+ P_1\}$.
Let ${\cal F}_H$ be the set of induced-subgraph-minimal graphs that contain a
pivot-minor isomorphic to $H$. To prove the above statement, we either show
that there is an integer $c_H$ such that all graphs in ${\cal F}_H$ have at
most $c_H$ vertices, or we determine ${\cal F}_H$ precisely, for each of the
above cases.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04673" title="Abstract">arXiv:2311.04673</a> (cross-list from stat.ML) [<a href="/pdf/2311.04673" title="Download PDF">pdf</a>, <a href="/format/2311.04673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compressive Recovery of Sparse Precision Matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Vayer%2C+T">Titouan Vayer</a>, 
<a href="/search/stat?searchtype=author&query=Lasalle%2C+E">Etienne Lasalle</a>, 
<a href="/search/stat?searchtype=author&query=Gribonval%2C+R">R&#xe9;mi Gribonval</a>, 
<a href="/search/stat?searchtype=author&query=Gon%C3%A7alves%2C+P">Paulo Gon&#xe7;alves</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We consider the problem of learning a graph modeling the statistical
relations of the $d$ variables of a dataset with $n$ samples $X \in
\mathbb{R}^{n \times d}$. Standard approaches amount to searching for a
precision matrix $\Theta$ representative of a Gaussian graphical model that
adequately explains the data. However, most maximum likelihood-based estimators
usually require storing the $d^{2}$ values of the empirical covariance matrix,
which can become prohibitive in a high-dimensional setting. In this work, we
adopt a compressive viewpoint and aim to estimate a sparse $\Theta$ from a
sketch of the data, i.e. a low-dimensional vector of size $m \ll d^{2}$
carefully designed from $X$ using nonlinear random features. Under certain
assumptions on the spectrum of $\Theta$ (or its condition number), we show that
it is possible to estimate it from a sketch of size $m=\Omega((d+2k)\log(d))$
where $k$ is the maximal number of edges of the underlying graph. These
information-theoretic guarantees are inspired by compressed sensing theory and
involve restricted isometry properties and instance optimal decoders. We
investigate the possibility of achieving practical recovery with an iterative
algorithm based on the graphical lasso, viewed as a specific denoiser. We
compare our approach and graphical lasso on synthetic datasets, demonstrating
its favorable performance even when the dataset is compressed.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04691" title="Abstract">arXiv:2311.04691</a> (cross-list from stat.AP) [<a href="/pdf/2311.04691" title="Download PDF">pdf</a>, <a href="/ps/2311.04691" title="Download PostScript">ps</a>, <a href="/format/2311.04691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sustainable Collaborative Strategy in Pharmaceutical Refrigerated  Logistics Routing Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Chen%2C+T">Tingting Chen</a>, 
<a href="/search/stat?searchtype=author&query=Chu%2C+F">Feng Chu</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+J">Jiantong Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Sun%2C+J">Jiaqing Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applications (stat.AP)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">The rapid growth of pharmaceutical refrigerated logistics poses
sustainability challenges, including elevated costs, energy consumption, and
resource inefficiency. Collaborating multiple depots can enhance logistics
efficiency when standalone distribution centers have limited transport
resources, i.e., refrigerated vehicles. However, the sustainable benefits and
performance across different strategies remain unexplored. This study fills
this research gap by addressing a refrigerated pharmaceutical routing problem.
While many collaborative strategies prioritize economic and environmental
benefits, our approach highlights a vital social indicator: maintaining vehicle
flow equilibrium at each depot during collaboration. This ensures the stability
of transport resources for all stakeholders, promoting sustainable
collaborative logistics. The problem is formulated as a multi-depot vehicle
routing problem with time windows (MDVRPTW). Three collaborative strategies
using Clustering VRP (CLUVRP) and improved Open VRP (OVRP) are proposed and
compared. We develop two approaches to address traditional OVRP limitations in
ensuring vehicle flow equilibrium at each depot. Our models consider perishable
pharmaceuticals and time-dependent travel speeds. Three hybrid heuristics based
on Simulated Annealing and Variable Neighborhood Search (SAVNS) are proposed
and evaluated for efficacy. Computational experiments and a case study
demonstrate distinct sustainable benefits across various strategies, offering
valuable insights for decision-makers in the refrigerated logistics market.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04693" title="Abstract">arXiv:2311.04693</a> (cross-list from eess.AS) [<a href="/pdf/2311.04693" title="Download PDF">pdf</a>, <a href="/format/2311.04693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diff-HierVC: Diffusion-based Hierarchical Voice Conversion with Robust  Pitch Generation and Masked Prior for Zero-shot Speaker Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Choi%2C+H">Ha-Yeong Choi</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+S">Sang-Hoon Lee</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+S">Seong-Whan Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> INTERSPEECH 2023 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Signal Processing (eess.SP)

</div>
<p class="mathjax">Although voice conversion (VC) systems have shown a remarkable ability to
transfer voice style, existing methods still have an inaccurate pitch and low
speaker adaptation quality. To address these challenges, we introduce
Diff-HierVC, a hierarchical VC system based on two diffusion models. We first
introduce DiffPitch, which can effectively generate F0 with the target voice
style. Subsequently, the generated F0 is fed to DiffVoice to convert the speech
with a target voice style. Furthermore, using the source-filter encoder, we
disentangle the speech and use the converted Mel-spectrogram as a data-driven
prior in DiffVoice to improve the voice style transfer capacity. Finally, by
using the masked prior in diffusion models, our model can improve the speaker
adaptation quality. Experimental results verify the superiority of our model in
pitch generation and voice style transfer performance, and our model also
achieves a CER of 0.83% and EER of 3.29% in zero-shot VC scenarios.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04723" title="Abstract">arXiv:2311.04723</a> (cross-list from quant-ph) [<a href="/pdf/2311.04723" title="Download PDF">pdf</a>, <a href="/format/2311.04723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication Complexity of Common Randomness Generation with Isotropic  States
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Dong%2C+Y">Yangjing Dong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yao%2C+P">Penghui Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">This paper addresses the problem of generating a common random string with
min-entropy k using an unlimited supply of noisy EPR pairs or quantum isotropic
states, with minimal communication between Alice and Bob. The paper considers
two communication models -- one-way classical communication and one-way quantum
communication, and derives upper bounds on the optimal common randomness rate
for both models. We show that in the case of classical communication, quantum
isotropic states have no advantage over noisy classical correlation, and that
the optimal common randomness rate can be achieved by a classical strategy, in
which Alice and Bob share classical $\rho$-correlated random variables. In the
case of quantum communication, we demonstrate that the common randomness rate
can be increased by using superdense coding on quantum isotropic states. Our
main result is an upper bound on the optimal common randomness rate achievable
by using one-way quantum communication. We also provide an application of this
result, which yields upper bounds on the classical capacity of the noiseless
quantum channel assisted by noisy entanglement.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04748" title="Abstract">arXiv:2311.04748</a> (cross-list from math.ST) [<a href="/pdf/2311.04748" title="Download PDF">pdf</a>, <a href="/format/2311.04748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Natural Bayesian Cram&#xe9;r-Rao Bound with an Application to Covariance  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bouchard%2C+F">Florent Bouchard</a>, 
<a href="/search/math?searchtype=author&query=Renaux%2C+A">Alexandre Renaux</a>, 
<a href="/search/math?searchtype=author&query=Ginolhac%2C+G">Guillaume Ginolhac</a>, 
<a href="/search/math?searchtype=author&query=Breloy%2C+A">Arnaud Breloy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Machine Learning (cs.LG); Applications (stat.AP); Machine Learning (stat.ML)

</div>
<p class="mathjax">In this paper, we propose to develop a new Cram\'er-Rao Bound (CRB) when the
parameter to estimate lies in a manifold and follows a prior distribution. This
derivation leads to a natural inequality between an error criteria based on
geometrical properties and this new bound. This main contribution is
illustrated in the problem of covariance estimation when the data follow a
Gaussian distribution and the prior distribution is an inverse Wishart.
Numerical simulation shows new results where the proposed CRB allows to exhibit
interesting properties of the MAP estimator which are not observed with the
classical Bayesian CRB.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04769" title="Abstract">arXiv:2311.04769</a> (cross-list from eess.IV) [<a href="/pdf/2311.04769" title="Download PDF">pdf</a>, <a href="/ps/2311.04769" title="Download PostScript">ps</a>, <a href="/format/2311.04769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An attention-based deep learning network for predicting Platinum  resistance in ovarian cancer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhuang%2C+H">Haoming Zhuang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+B">Beibei Li</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+J">Jingtong Ma</a>, 
<a href="/search/eess?searchtype=author&query=Monkam%2C+P">Patrice Monkam</a>, 
<a href="/search/eess?searchtype=author&query=Qi%2C+S">Shouliang Qi</a>, 
<a href="/search/eess?searchtype=author&query=Qian%2C+W">Wei Qian</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+D">Dianning He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Background: Ovarian cancer is among the three most frequent gynecologic
cancers globally. High-grade serous ovarian cancer (HGSOC) is the most common
and aggressive histological type. Guided treatment for HGSOC typically involves
platinum-based combination chemotherapy, necessitating an assessment of whether
the patient is platinum-resistant. The purpose of this study is to propose a
deep learning-based method to determine whether a patient is platinum-resistant
using multimodal positron emission tomography/computed tomography (PET/CT)
images. Methods: 289 patients with HGSOC were included in this study. An
end-to-end SE-SPP-DenseNet model was built by adding Squeeze-Excitation Block
(SE Block) and Spatial Pyramid Pooling Layer (SPPLayer) to Dense Convolutional
Network (DenseNet). Multimodal data from PET/CT images of the regions of
interest (ROI) were used to predict platinum resistance in patients. Results:
Through five-fold cross-validation, SE-SPP-DenseNet achieved a high accuracy
rate and an area under the curve (AUC) in predicting platinum resistance in
patients, which were 92.6% and 0.93, respectively. The importance of
incorporating SE Block and SPPLayer into the deep learning model, and
considering multimodal data was substantiated by carrying out ablation studies
and experiments with single modality data. Conclusions: The obtained
classification results indicate that our proposed deep learning framework
performs better in predicting platinum resistance in patients, which can help
gynecologists make better treatment decisions. Keywords: PET/CT, CNN, SE Block,
SPP Layer, Platinum resistance, Ovarian cancer
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04772" title="Abstract">arXiv:2311.04772</a> (cross-list from eess.IV) [<a href="/pdf/2311.04772" title="Download PDF">pdf</a>, <a href="/format/2311.04772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GCS-ICHNet: Assessment of Intracerebral Hemorrhage Prognosis using  Self-Attention with Domain Knowledge Integration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shan%2C+X">Xuhao Shan</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xinyang Li</a>, 
<a href="/search/eess?searchtype=author&query=Ge%2C+R">Ruiquan Ge</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+S">Shibin Wu</a>, 
<a href="/search/eess?searchtype=author&query=Elazab%2C+A">Ahmed Elazab</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+J">Jichao Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+L">Lingyan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Jia%2C+G">Gangyong Jia</a>, 
<a href="/search/eess?searchtype=author&query=Xiao%2C+Q">Qingying Xiao</a>, 
<a href="/search/eess?searchtype=author&query=Wan%2C+X">Xiang Wan</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+C">Changmiao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures, 5 tables, published to BIBM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Intracerebral Hemorrhage (ICH) is a severe condition resulting from damaged
brain blood vessel ruptures, often leading to complications and fatalities.
Timely and accurate prognosis and management are essential due to its high
mortality rate. However, conventional methods heavily rely on subjective
clinician expertise, which can lead to inaccurate diagnoses and delays in
treatment. Artificial intelligence (AI) models have been explored to assist
clinicians, but many prior studies focused on model modification without
considering domain knowledge. This paper introduces a novel deep learning
algorithm, GCS-ICHNet, which integrates multimodal brain CT image data and the
Glasgow Coma Scale (GCS) score to improve ICH prognosis. The algorithm utilizes
a transformer-based fusion module for assessment. GCS-ICHNet demonstrates high
sensitivity 81.03% and specificity 91.59%, outperforming average clinicians and
other state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04780" title="Abstract">arXiv:2311.04780</a> (cross-list from eess.IV) [<a href="/pdf/2311.04780" title="Download PDF">pdf</a>, <a href="/format/2311.04780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FetMRQC: an open-source machine learning framework for multi-centric  fetal brain MRI quality control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sanchez%2C+T">Thomas Sanchez</a>, 
<a href="/search/eess?searchtype=author&query=Esteban%2C+O">Oscar Esteban</a>, 
<a href="/search/eess?searchtype=author&query=Gomez%2C+Y">Yvan Gomez</a>, 
<a href="/search/eess?searchtype=author&query=Pron%2C+A">Alexandre Pron</a>, 
<a href="/search/eess?searchtype=author&query=Koob%2C+M">M&#xe9;riam Koob</a>, 
<a href="/search/eess?searchtype=author&query=Dunet%2C+V">Vincent Dunet</a>, 
<a href="/search/eess?searchtype=author&query=Girard%2C+N">Nadine Girard</a>, 
<a href="/search/eess?searchtype=author&query=Jakab%2C+A">Andras Jakab</a>, 
<a href="/search/eess?searchtype=author&query=Eixarch%2C+E">Elisenda Eixarch</a>, 
<a href="/search/eess?searchtype=author&query=Auzias%2C+G">Guillaume Auzias</a>, 
<a href="/search/eess?searchtype=author&query=Cuadra%2C+M+B">Meritxell Bach Cuadra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 10 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Fetal brain MRI is becoming an increasingly relevant complement to
neurosonography for perinatal diagnosis, allowing fundamental insights into
fetal brain development throughout gestation. However, uncontrolled fetal
motion and heterogeneity in acquisition protocols lead to data of variable
quality, potentially biasing the outcome of subsequent studies. We present
FetMRQC, an open-source machine-learning framework for automated image quality
assessment and quality control that is robust to domain shifts induced by the
heterogeneity of clinical data. FetMRQC extracts an ensemble of quality metrics
from unprocessed anatomical MRI and combines them to predict experts' ratings
using random forests. We validate our framework on a pioneeringly large and
diverse dataset of more than 1600 manually rated fetal brain T2-weighted images
from four clinical centers and 13 different scanners. Our study shows that
FetMRQC's predictions generalize well to unseen data while being interpretable.
FetMRQC is a step towards more robust fetal brain neuroimaging, which has the
potential to shed new insights on the developing human brain.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04847" title="Abstract">arXiv:2311.04847</a> (cross-list from eess.IV) [<a href="/pdf/2311.04847" title="Download PDF">pdf</a>, <a href="/ps/2311.04847" title="Download PostScript">ps</a>, <a href="/format/2311.04847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are foundation models efficient for medical image segmentation?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ferreira%2C+D">Danielle Ferreira</a>, 
<a href="/search/eess?searchtype=author&query=Arnaout%2C+R">Rima Arnaout</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 2 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Foundation models are experiencing a surge in popularity. The Segment
Anything model (SAM) asserts an ability to segment a wide spectrum of objects
but required supervised training at unprecedented scale. We compared SAM's
performance (against clinical ground truth) and resources (labeling time,
compute) to a modality-specific, label-free self-supervised learning (SSL)
method on 25 measurements for 100 cardiac ultrasounds. SAM performed poorly and
required significantly more labeling and computing resources, demonstrating
worse efficiency than SSL.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04855" title="Abstract">arXiv:2311.04855</a> (cross-list from astro-ph.IM) [<a href="/pdf/2311.04855" title="Download PDF">pdf</a>, <a href="/format/2311.04855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithms for Non-Negative Matrix Factorization on Noisy Data With  Negative Values
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Green%2C+D">Dylan Green</a>, 
<a href="/search/astro-ph?searchtype=author&query=Bailey%2C+S">Stephen Bailey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures. Submitted to IEEE Transactions on Signal Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP); Methodology (stat.ME)

</div>
<p class="mathjax">Non-negative matrix factorization (NMF) is a dimensionality reduction
technique that has shown promise for analyzing noisy data, especially
astronomical data. For these datasets, the observed data may contain negative
values due to noise even when the true underlying physical signal is strictly
positive. Prior NMF work has not treated negative data in a statistically
consistent manner, which becomes problematic for low signal-to-noise data with
many negative values. In this paper we present two algorithms, Shift-NMF and
Nearly-NMF, that can handle both the noisiness of the input data and also any
introduced negativity. Both of these algorithms use the negative data space
without clipping, and correctly recover non-negative signals without any
introduced positive offset that occurs when clipping negative data. We
demonstrate this numerically on both simple and more realistic examples, and
prove that both algorithms have monotonically decreasing update rules.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Thu,  9 Nov 23</h3>
<dl>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2003.12810" title="Abstract">arXiv:2003.12810</a> (replaced) [<a href="/pdf/2003.12810" title="Download PDF">pdf</a>, <a href="/ps/2003.12810" title="Download PostScript">ps</a>, <a href="/format/2003.12810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automaton semigroup free products revisited
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Brough%2C+T+M">Tara Macalister Brough</a>, 
<a href="/search/math?searchtype=author&query=W%C3%A4chter%2C+J+P">Jan Philipp W&#xe4;chter</a>, 
<a href="/search/math?searchtype=author&query=Welker%2C+J">Janette Welker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 11 figures; substantial update to first version, including new results and new co-authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Group Theory (math.GR)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2102.05405" title="Abstract">arXiv:2102.05405</a> (replaced) [<a href="/pdf/2102.05405" title="Download PDF">pdf</a>, <a href="/format/2102.05405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated and Distributed Statistical Analysis of Economic Agent-Based  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Vandin%2C+A">Andrea Vandin</a>, 
<a href="/search/econ?searchtype=author&query=Giachini%2C+D">Daniele Giachini</a>, 
<a href="/search/econ?searchtype=author&query=Lamperti%2C+F">Francesco Lamperti</a>, 
<a href="/search/econ?searchtype=author&query=Chiaromonte%2C+F">Francesca Chiaromonte</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Economics (econ.GN)</span>; Multiagent Systems (cs.MA); Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.09864" title="Abstract">arXiv:2104.09864</a> (replaced) [<a href="/pdf/2104.09864" title="Download PDF">pdf</a>, <a href="/format/2104.09864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RoFormer: Enhanced Transformer with Rotary Position Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+J">Jianlin Su</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shengfeng Pan</a>, 
<a href="/search/cs?searchtype=author&query=Murtadha%2C+A">Ahmed Murtadha</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+B">Bo Wen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yunfeng Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> fixed some typos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.01434" title="Abstract">arXiv:2108.01434</a> (replaced) [<a href="/pdf/2108.01434" title="Download PDF">pdf</a>, <a href="/format/2108.01434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wavelet-Based Network For High Dynamic Range Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dai%2C+T">Tianhong Dai</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/eess?searchtype=author&query=Cao%2C+X">Xilei Cao</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+J">Jianzhuang Liu</a>, 
<a href="/search/eess?searchtype=author&query=Jia%2C+X">Xu Jia</a>, 
<a href="/search/eess?searchtype=author&query=Leonardis%2C+A">Ales Leonardis</a>, 
<a href="/search/eess?searchtype=author&query=Yan%2C+Y">Youliang Yan</a>, 
<a href="/search/eess?searchtype=author&query=Yuan%2C+S">Shanxin Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.08289" title="Abstract">arXiv:2112.08289</a> (replaced) [<a href="/pdf/2112.08289" title="Download PDF">pdf</a>, <a href="/format/2112.08289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decomposing Natural Logic Inferences in Neural NLI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rozanova%2C+J">Julia Rozanova</a>, 
<a href="/search/cs?searchtype=author&query=Ferreira%2C+D">Deborah Ferreira</a>, 
<a href="/search/cs?searchtype=author&query=Valentino%2C+M">Marco Valentino</a>, 
<a href="/search/cs?searchtype=author&query=Thayaparan%2C+M">Mokanrarangan Thayaparan</a>, 
<a href="/search/cs?searchtype=author&query=Freitas%2C+A">Andre Freitas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.00907" title="Abstract">arXiv:2203.00907</a> (replaced) [<a href="/e-print/2203.00907" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Split Semantic Detection in Sandplay Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xiaokun Feng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaotang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jian Jia</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kaiqi Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> replace by new version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.10517" title="Abstract">arXiv:2203.10517</a> (replaced) [<a href="/pdf/2203.10517" title="Download PDF">pdf</a>, <a href="/format/2203.10517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Whole Heart Mesh Generation From Patient Images For  Computational Simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kong%2C+F">Fanwei Kong</a>, 
<a href="/search/eess?searchtype=author&query=Shadden%2C+S">Shawn Shadden</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Medical Imaging, vol. 42, no. 2, pp. 533-545,
  Feb. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computational Engineering, Finance, and Science (cs.CE); Computer Vision and Pattern Recognition (cs.CV); Medical Physics (physics.med-ph)

</div>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.13281" title="Abstract">arXiv:2203.13281</a> (replaced) [<a href="/pdf/2203.13281" title="Download PDF">pdf</a>, <a href="/format/2203.13281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Movie Genre Classification by Language Augmentation and Shot Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhongping Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yiwen Gu</a>, 
<a href="/search/cs?searchtype=author&query=Plummer%2C+B+A">Bryan A. Plummer</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+X">Xin Miao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiayi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huayan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.15203" title="Abstract">arXiv:2205.15203</a> (replaced) [<a href="/pdf/2205.15203" title="Download PDF">pdf</a>, <a href="/format/2205.15203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exponentials as Substitutions and the Cost of Cut Elimination in Linear  Logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Accattoli%2C+B">Beniamino Accattoli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> LMCS submission for the special issue of LICS 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.15270" title="Abstract">arXiv:2205.15270</a> (replaced) [<a href="/pdf/2205.15270" title="Download PDF">pdf</a>, <a href="/format/2205.15270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAT-Based Extraction of Behavioural Models for Java Libraries with  Collections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Safina%2C+L">Larisa Safina</a>, 
<a href="/search/cs?searchtype=author&query=Bliudze%2C+S">Simon Bliudze</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.10996" title="Abstract">arXiv:2206.10996</a> (replaced) [<a href="/pdf/2206.10996" title="Download PDF">pdf</a>, <a href="/format/2206.10996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProtoCLIP: Prototypical Contrastive Language Image Pretraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Delong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zaiquan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Huaxi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Ying Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+E">Erjin Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Transactions on Neural Networks and Learning Systems (TNNLS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.12532" title="Abstract">arXiv:2206.12532</a> (replaced) [<a href="/pdf/2206.12532" title="Download PDF">pdf</a>, <a href="/format/2206.12532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Scoring: A Framework for Effect Estimation, Effect Ordering, and  Effect Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Fern%C3%A1ndez-Lor%C3%ADa%2C+C">Carlos Fern&#xe1;ndez-Lor&#xed;a</a>, 
<a href="/search/stat?searchtype=author&query=Lor%C3%ADa%2C+J">Jorge Lor&#xed;a</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.13999" title="Abstract">arXiv:2206.13999</a> (replaced) [<a href="/pdf/2206.13999" title="Download PDF">pdf</a>, <a href="/ps/2206.13999" title="Download PostScript">ps</a>, <a href="/format/2206.13999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Orthogonal Delay-Doppler Division Multiplexing Modulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hai Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jinhong Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Corrected typos. The supplementary material of this work can be found at <a href="https://www.omu.ac.jp/eng/ees-sic/oddm/">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Trans. Wireless Commun., vol. 21, no. 12, pp. 11024-11037,
  Dec. 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.07074" title="Abstract">arXiv:2208.07074</a> (replaced) [<a href="/pdf/2208.07074" title="Download PDF">pdf</a>, <a href="/format/2208.07074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sound and Relatively Complete Belief Hoare Logic for Statistical  Hypothesis Testing Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kawamoto%2C+Y">Yusuke Kawamoto</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+T">Tetsuya Sato</a>, 
<a href="/search/cs?searchtype=author&query=Suenaga%2C+K">Kohei Suenaga</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the journal Artificial Intelligence (AI); an extended version of the KR'21 conference paper <a href="https://proceedings.kr.org/2021/39/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.05629" title="Abstract">arXiv:2209.05629</a> (replaced) [<a href="/pdf/2209.05629" title="Download PDF">pdf</a>, <a href="/format/2209.05629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Large (Visual) Language Models for Robot 3D Scene  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">William Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Siyi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Talak%2C+R">Rajat Talak</a>, 
<a href="/search/cs?searchtype=author&query=Carlone%2C+L">Luca Carlone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2206.04585">arXiv:2206.04585</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.00789" title="Abstract">arXiv:2210.00789</a> (replaced) [<a href="/pdf/2210.00789" title="Download PDF">pdf</a>, <a href="/format/2210.00789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nested Sequents for First-Order Modal Logics via Reachability Rules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyon%2C+T+S">Tim S. Lyon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Logic (math.LO)

</div>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.01645" title="Abstract">arXiv:2210.01645</a> (replaced) [<a href="/pdf/2210.01645" title="Download PDF">pdf</a>, <a href="/format/2210.01645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robotic Learning the Sequence of Packing Irregular Objects from Human  Demonstrations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Santos%2C+A">Andr&#xe9; Santos</a>, 
<a href="/search/cs?searchtype=author&query=Duarte%2C+N+F">Nuno Ferreira Duarte</a>, 
<a href="/search/cs?searchtype=author&query=Dehban%2C+A">Atabak Dehban</a>, 
<a href="/search/cs?searchtype=author&query=Santos-Victor%2C+J">Jos&#xe9; Santos-Victor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.03232" title="Abstract">arXiv:2210.03232</a> (replaced) [<a href="/pdf/2210.03232" title="Download PDF">pdf</a>, <a href="/format/2210.03232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Double Averaging and Gradient Projection: Convergence Guarantees for  Decentralized Constrained Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Shahriari-Mehr%2C+F">Firooz Shahriari-Mehr</a>, 
<a href="/search/math?searchtype=author&query=Panahi%2C+A">Ashkan Panahi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.05794" title="Abstract">arXiv:2210.05794</a> (replaced) [<a href="/pdf/2210.05794" title="Download PDF">pdf</a>, <a href="/format/2210.05794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing Robust Transformers using Robust Kernel Density Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xing Han</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+T">Tongzheng Ren</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+M">Tan Minh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+K">Khai Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+J">Joydeep Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+N">Nhat Ho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023 as a poster; 23 pages, 5 figures, 11 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.07290" title="Abstract">arXiv:2210.07290</a> (replaced) [<a href="/pdf/2210.07290" title="Download PDF">pdf</a>, <a href="/format/2210.07290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint control variate for faster black-box variational inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Geffner%2C+T">Tomas Geffner</a>, 
<a href="/search/cs?searchtype=author&query=Domke%2C+J">Justin Domke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.08349" title="Abstract">arXiv:2210.08349</a> (replaced) [<a href="/pdf/2210.08349" title="Download PDF">pdf</a>, <a href="/format/2210.08349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When to Update Your Model: Constrained Model-based Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+T">Tianying Ji</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yu Luo</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+F">Fuchun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+M">Mingxuan Jing</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+F">Fengxiang He</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wenbing Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.12040" title="Abstract">arXiv:2210.12040</a> (replaced) [<a href="/pdf/2210.12040" title="Download PDF">pdf</a>, <a href="/ps/2210.12040" title="Download PostScript">ps</a>, <a href="/format/2210.12040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neuro-Symbolic Causal Reasoning Meets Signaling Game for Emergent  Semantic Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thomas%2C+C+K">Christo Kurisummoottil Thomas</a>, 
<a href="/search/cs?searchtype=author&query=Saad%2C+W">Walid Saad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.12953" title="Abstract">arXiv:2210.12953</a> (replaced) [<a href="/pdf/2210.12953" title="Download PDF">pdf</a>, <a href="/format/2210.12953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implementation of Trained Factorization Machine Recommendation System on  Quantum Annealer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+C">Chen-Yu Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+H">Hsin-Yu Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liao%2C+P">Pei-Yen Liao</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lai%2C+C">Ching-Jui Lai</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hsieh%2C+M">Min-Hsiu Hsieh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.03418" title="Abstract">arXiv:2211.03418</a> (replaced) [<a href="/pdf/2211.03418" title="Download PDF">pdf</a>, <a href="/ps/2211.03418" title="Download PostScript">ps</a>, <a href="/format/2211.03418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Quantum-Powered Photorealistic Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">YuanFu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Min Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.06506" title="Abstract">arXiv:2211.06506</a> (replaced) [<a href="/pdf/2211.06506" title="Download PDF">pdf</a>, <a href="/format/2211.06506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral Evolution and Invariance in Linear-width Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhichao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Engel%2C+A">Andrew Engel</a>, 
<a href="/search/cs?searchtype=author&query=Sarwate%2C+A">Anand Sarwate</a>, 
<a href="/search/cs?searchtype=author&query=Dumitriu%2C+I">Ioana Dumitriu</a>, 
<a href="/search/cs?searchtype=author&query=Chiang%2C+T">Tony Chiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.06739" title="Abstract">arXiv:2211.06739</a> (replaced) [<a href="/pdf/2211.06739" title="Download PDF">pdf</a>, <a href="/format/2211.06739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Partial Binarization of Neural Networks for Budget-Aware Efficient  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bamba%2C+U">Udbhav Bamba</a>, 
<a href="/search/cs?searchtype=author&query=Anand%2C+N">Neeraj Anand</a>, 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+S">Saksham Aggarwal</a>, 
<a href="/search/cs?searchtype=author&query=Prasad%2C+D+K">Dilip K. Prasad</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+D+K">Deepak K. Gupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV 2023 Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.09983" title="Abstract">arXiv:2211.09983</a> (replaced) [<a href="/pdf/2211.09983" title="Download PDF">pdf</a>, <a href="/ps/2211.09983" title="Download PostScript">ps</a>, <a href="/format/2211.09983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Approximation Property of Fully Convolutional Neural Networks  with Zero Padding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hwang%2C+G">Geonho Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+M">Myungjoo Kang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.06566" title="Abstract">arXiv:2212.06566</a> (replaced) [<a href="/pdf/2212.06566" title="Download PDF">pdf</a>, <a href="/format/2212.06566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to select an objective function using information theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hodson%2C+T+O">Timothy O. Hodson</a>, 
<a href="/search/cs?searchtype=author&query=Over%2C+T+M">Thomas M. Over</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+T+J">Tyler J. Smith</a>, 
<a href="/search/cs?searchtype=author&query=Marshall%2C+L+M">Lucy M. Marshall</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 3 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.08094" title="Abstract">arXiv:2212.08094</a> (replaced) [<a href="/pdf/2212.08094" title="Download PDF">pdf</a>, <a href="/format/2212.08094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint processing of linguistic properties in brains and language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oota%2C+S+R">Subba Reddy Oota</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+M">Manish Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Toneva%2C+M">Mariya Toneva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 12 figures, To be published in the proceedings of the 37th Conference on Neural Information Processing Systems (NeurIPS 2023), New Orleans, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.01589" title="Abstract">arXiv:2301.01589</a> (replaced) [<a href="/pdf/2301.01589" title="Download PDF">pdf</a>, <a href="/ps/2301.01589" title="Download PostScript">ps</a>, <a href="/format/2301.01589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Feasibility Labeling for NP-complete Vertex Coloring Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Zhan%2C+J">Junpeng Zhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Optimization and Control (math.OC); Quantum Algebra (math.QA)

</div>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.08107" title="Abstract">arXiv:2301.08107</a> (replaced) [<a href="/pdf/2301.08107" title="Download PDF">pdf</a>, <a href="/format/2301.08107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SHITARA: Sending Haptic Induced Touchable Alarm by Ring-shaped Air  vortex
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kojima%2C+R">Ryosei Kojima</a>, 
<a href="/search/cs?searchtype=author&query=Shitara%2C+A">Akihisa Shitara</a>, 
<a href="/search/cs?searchtype=author&query=Fushimi%2C+T">Tatsuki Fushimi</a>, 
<a href="/search/cs?searchtype=author&query=Niwa%2C+R">Ryogo Niwa</a>, 
<a href="/search/cs?searchtype=author&query=Shinoda%2C+A">Atushi Shinoda</a>, 
<a href="/search/cs?searchtype=author&query=Iijima%2C+R">Ryo Iijima</a>, 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+K">Kengo Tanaka</a>, 
<a href="/search/cs?searchtype=author&query=Sarcar%2C+S">Sayan Sarcar</a>, 
<a href="/search/cs?searchtype=author&query=Ochiai%2C+Y">Yoichi Ochiai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 22 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10611" title="Abstract">arXiv:2301.10611</a> (replaced) [<a href="/pdf/2301.10611" title="Download PDF">pdf</a>, <a href="/format/2301.10611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discriminator-free Unsupervised Domain Adaptation for Multi-label Image  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+I+P">Indel Pal Singh</a>, 
<a href="/search/cs?searchtype=author&query=Ghorbel%2C+E">Enjie Ghorbel</a>, 
<a href="/search/cs?searchtype=author&query=Kacem%2C+A">Anis Kacem</a>, 
<a href="/search/cs?searchtype=author&query=Rathinam%2C+A">Arunkumar Rathinam</a>, 
<a href="/search/cs?searchtype=author&query=Aouada%2C+D">Djamila Aouada</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.00695" title="Abstract">arXiv:2302.00695</a> (replaced) [<a href="/pdf/2302.00695" title="Download PDF">pdf</a>, <a href="/format/2302.00695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Versatile Energy-Based Probabilistic Models for High Energy Physics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+T">Taoli Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Courville%2C+A">Aaron Courville</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; High Energy Physics - Experiment (hep-ex); High Energy Physics - Phenomenology (hep-ph); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01734" title="Abstract">arXiv:2302.01734</a> (replaced) [<a href="/pdf/2302.01734" title="Download PDF">pdf</a>, <a href="/format/2302.01734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Policy Gradient Methods: Improved Sample Complexity for  Fisher-non-degenerate Policies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fatkhullin%2C+I">Ilyas Fatkhullin</a>, 
<a href="/search/cs?searchtype=author&query=Barakat%2C+A">Anas Barakat</a>, 
<a href="/search/cs?searchtype=author&query=Kireeva%2C+A">Anastasia Kireeva</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+N">Niao He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work was initially submitted in October 2022
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 40th International Conference on Machine
  Learning, PMLR 202:9827-9869, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02004" title="Abstract">arXiv:2302.02004</a> (replaced) [<a href="/pdf/2302.02004" title="Download PDF">pdf</a>, <a href="/format/2302.02004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sharp Spectral Rates for Koopman Operator Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kostic%2C+V">Vladimir Kostic</a>, 
<a href="/search/cs?searchtype=author&query=Lounici%2C+K">Karim Lounici</a>, 
<a href="/search/cs?searchtype=author&query=Novelli%2C+P">Pietro Novelli</a>, 
<a href="/search/cs?searchtype=author&query=Pontil%2C+M">Massimiliano Pontil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the thirty-seventh Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05981" title="Abstract">arXiv:2302.05981</a> (replaced) [<a href="/pdf/2302.05981" title="Download PDF">pdf</a>, <a href="/format/2302.05981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MarioGPT: Open-Ended Text2Level Generation through Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sudhakaran%2C+S">Shyam Sudhakaran</a>, 
<a href="/search/cs?searchtype=author&query=Gonz%C3%A1lez-Duque%2C+M">Miguel Gonz&#xe1;lez-Duque</a>, 
<a href="/search/cs?searchtype=author&query=Glanois%2C+C">Claire Glanois</a>, 
<a href="/search/cs?searchtype=author&query=Freiberger%2C+M">Matthias Freiberger</a>, 
<a href="/search/cs?searchtype=author&query=Najarro%2C+E">Elias Najarro</a>, 
<a href="/search/cs?searchtype=author&query=Risi%2C+S">Sebastian Risi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.07025" title="Abstract">arXiv:2302.07025</a> (replaced) [<a href="/pdf/2302.07025" title="Download PDF">pdf</a>, <a href="/format/2302.07025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Transport for Change Detection on LiDAR Point Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fiorucci%2C+M">Marco Fiorucci</a>, 
<a href="/search/cs?searchtype=author&query=Naylor%2C+P">Peter Naylor</a>, 
<a href="/search/cs?searchtype=author&query=Yamada%2C+M">Makoto Yamada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This project has received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No101027956. Marie Sk{\l}odowska-Curie Action (Individual Fellowship): OPtimal Transport for Identifying Marauder Activities on LiDAR (OPTIMAL) <a href="https://cordis.europa.eu/project/id/101027956">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IGARSS 2023 - 2023 IEEE International Geoscience and Remote
  Sensing Symposium, Pasadena, CA, USA, 2023, pp. 982-985
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.07849" title="Abstract">arXiv:2302.07849</a> (replaced) [<a href="/pdf/2302.07849" title="Download PDF">pdf</a>, <a href="/format/2302.07849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot Anomaly Detection via Batch Normalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Aodong Li</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+C">Chen Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Kloft%2C+M">Marius Kloft</a>, 
<a href="/search/cs?searchtype=author&query=Smyth%2C+P">Padhraic Smyth</a>, 
<a href="/search/cs?searchtype=author&query=Rudolph%2C+M">Maja Rudolph</a>, 
<a href="/search/cs?searchtype=author&query=Mandt%2C+S">Stephan Mandt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.07867" title="Abstract">arXiv:2302.07867</a> (replaced) [<a href="/pdf/2302.07867" title="Download PDF">pdf</a>, <a href="/format/2302.07867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Performance-Improving Code Edits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shypula%2C+A">Alexander Shypula</a>, 
<a href="/search/cs?searchtype=author&query=Madaan%2C+A">Aman Madaan</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yimeng Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Alon%2C+U">Uri Alon</a>, 
<a href="/search/cs?searchtype=author&query=Gardner%2C+J">Jacob Gardner</a>, 
<a href="/search/cs?searchtype=author&query=Hashemi%2C+M">Milad Hashemi</a>, 
<a href="/search/cs?searchtype=author&query=Neubig%2C+G">Graham Neubig</a>, 
<a href="/search/cs?searchtype=author&query=Ranganathan%2C+P">Parthasarathy Ranganathan</a>, 
<a href="/search/cs?searchtype=author&query=Bastani%2C+O">Osbert Bastani</a>, 
<a href="/search/cs?searchtype=author&query=Yazdanbakhsh%2C+A">Amir Yazdanbakhsh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website: <a href="https://pie4perf.com/.">this https URL</a> Preprint, under review. This version extends with significant changes
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09043" title="Abstract">arXiv:2302.09043</a> (replaced) [<a href="/pdf/2302.09043" title="Download PDF">pdf</a>, <a href="/format/2302.09043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Representation Learning from Temporal Ordering of  Automated Driving Sequences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lang%2C+C">Christopher Lang</a>, 
<a href="/search/cs?searchtype=author&query=Braun%2C+A">Alexander Braun</a>, 
<a href="/search/cs?searchtype=author&query=Schillingmann%2C+L">Lars Schillingmann</a>, 
<a href="/search/cs?searchtype=author&query=Haug%2C+K">Karsten Haug</a>, 
<a href="/search/cs?searchtype=author&query=Valada%2C+A">Abhinav Valada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.10844" title="Abstract">arXiv:2302.10844</a> (replaced) [<a href="/pdf/2302.10844" title="Download PDF">pdf</a>, <a href="/ps/2302.10844" title="Download PostScript">ps</a>, <a href="/format/2302.10844" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Mean Estimation Without Moments for Symmetric Distributions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Novikov%2C+G">Gleb Novikov</a>, 
<a href="/search/cs?searchtype=author&query=Steurer%2C+D">David Steurer</a>, 
<a href="/search/cs?searchtype=author&query=Tiegel%2C+S">Stefan Tiegel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.12231" title="Abstract">arXiv:2302.12231</a> (replaced) [<a href="/pdf/2302.12231" title="Download PDF">pdf</a>, <a href="/format/2302.12231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffusioNeRF: Regularizing Neural Radiance Fields with Denoising  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wynn%2C+J">Jamie Wynn</a>, 
<a href="/search/cs?searchtype=author&query=Turmukhambetov%2C+D">Daniyar Turmukhambetov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2023. Updated LPIPS scores in Table 1
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00648" title="Abstract">arXiv:2303.00648</a> (replaced) [<a href="/pdf/2303.00648" title="Download PDF">pdf</a>, <a href="/format/2303.00648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimized event generator for strong-field QED simulations within the  hi-$&#x3c7;$ framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Volokitin%2C+V">Valentin Volokitin</a>, 
<a href="/search/physics?searchtype=author&query=Magnusson%2C+J">Joel Magnusson</a>, 
<a href="/search/physics?searchtype=author&query=Bashinov%2C+A">Aleksei Bashinov</a>, 
<a href="/search/physics?searchtype=author&query=Efimenko%2C+E">Evgeny Efimenko</a>, 
<a href="/search/physics?searchtype=author&query=Muraviev%2C+A">Alexander Muraviev</a>, 
<a href="/search/physics?searchtype=author&query=Meyerov%2C+I">Iosif Meyerov</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Computational Science, Volume 74, 2023, 102170
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01385" title="Abstract">arXiv:2303.01385</a> (replaced) [<a href="/pdf/2303.01385" title="Download PDF">pdf</a>, <a href="/format/2303.01385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyperlink communities in higher-order networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lotito%2C+Q+F">Quintino Francesco Lotito</a>, 
<a href="/search/cs?searchtype=author&query=Musciotto%2C+F">Federico Musciotto</a>, 
<a href="/search/cs?searchtype=author&query=Montresor%2C+A">Alberto Montresor</a>, 
<a href="/search/cs?searchtype=author&query=Battiston%2C+F">Federico Battiston</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02500" title="Abstract">arXiv:2303.02500</a> (replaced) [<a href="/pdf/2303.02500" title="Download PDF">pdf</a>, <a href="/ps/2303.02500" title="Download PostScript">ps</a>, <a href="/format/2303.02500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Derivatives of mutual information in Gaussian channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+M">Minh-Toan Nguyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05385" title="Abstract">arXiv:2303.05385</a> (replaced) [<a href="/pdf/2303.05385" title="Download PDF">pdf</a>, <a href="/format/2303.05385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PyGenStability: Multiscale community detection with generalized Markov  Stability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arnaudon%2C+A">Alexis Arnaudon</a>, 
<a href="/search/cs?searchtype=author&query=Schindler%2C+D+J">Dominik J. Schindler</a>, 
<a href="/search/cs?searchtype=author&query=Peach%2C+R+L">Robert L. Peach</a>, 
<a href="/search/cs?searchtype=author&query=Gosztolai%2C+A">Adam Gosztolai</a>, 
<a href="/search/cs?searchtype=author&query=Hodges%2C+M">Maxwell Hodges</a>, 
<a href="/search/cs?searchtype=author&query=Schaub%2C+M+T">Michael T. Schaub</a>, 
<a href="/search/cs?searchtype=author&query=Barahona%2C+M">Mauricio Barahona</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Mathematical Software (cs.MS)

</div>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08269" title="Abstract">arXiv:2303.08269</a> (replaced) [<a href="/pdf/2303.08269" title="Download PDF">pdf</a>, <a href="/format/2303.08269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Positive Unlabeled Learning Selected Not At Random (PULSNAR): class  proportion estimation when the SCAR assumption does not hold
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+P">Praveen Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Lambert%2C+C+G">Christophe G. Lambert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10517" title="Abstract">arXiv:2303.10517</a> (replaced) [<a href="/pdf/2303.10517" title="Download PDF">pdf</a>, <a href="/format/2303.10517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evolution of Automated Weakness Detection in Ethereum Bytecode: a  Comprehensive Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=di+Angelo%2C+M">Monika di Angelo</a>, 
<a href="/search/cs?searchtype=author&query=Durieux%2C+T">Thomas Durieux</a>, 
<a href="/search/cs?searchtype=author&query=Ferreira%2C+J+F">Jo&#xe3;o F. Ferreira</a>, 
<a href="/search/cs?searchtype=author&query=Salzer%2C+G">Gernot Salzer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10937" title="Abstract">arXiv:2303.10937</a> (replaced) [<a href="/pdf/2303.10937" title="Download PDF">pdf</a>, <a href="/format/2303.10937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Weakly Supervised Object Detection using Fusion and Priors from  Hallucinated Depth
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gungor%2C+C">Cagri Gungor</a>, 
<a href="/search/cs?searchtype=author&query=Kovashka%2C+A">Adriana Kovashka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15413" title="Abstract">arXiv:2303.15413</a> (replaced) [<a href="/pdf/2303.15413" title="Download PDF">pdf</a>, <a href="/format/2303.15413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Debiasing Scores and Prompts of 2D Diffusion for View-consistent  Text-to-3D Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+S">Susung Hong</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+D">Donghoon Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seungryong Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023. Project Page: <a href="https://susunghong.github.io/Debiased-Score-Distillation-Sampling/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Graphics (cs.GR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03546" title="Abstract">arXiv:2304.03546</a> (replaced) [<a href="/pdf/2304.03546" title="Download PDF">pdf</a>, <a href="/format/2304.03546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hermitian Preconditioning for a class of Non-Hermitian Linear Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Spillane%2C+N">Nicole Spillane</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05879" title="Abstract">arXiv:2304.05879</a> (replaced) [<a href="/pdf/2304.05879" title="Download PDF">pdf</a>, <a href="/format/2304.05879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FetMRQC: Automated Quality Control for fetal brain MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sanchez%2C+T">Thomas Sanchez</a>, 
<a href="/search/eess?searchtype=author&query=Esteban%2C+O">Oscar Esteban</a>, 
<a href="/search/eess?searchtype=author&query=Gomez%2C+Y">Yvan Gomez</a>, 
<a href="/search/eess?searchtype=author&query=Eixarch%2C+E">Elisenda Eixarch</a>, 
<a href="/search/eess?searchtype=author&query=Cuadra%2C+M+B">Meritxell Bach Cuadra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures. Perinatal, Preterm and Paediatric Image Analysis Workshop 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06373" title="Abstract">arXiv:2304.06373</a> (replaced) [<a href="/pdf/2304.06373" title="Download PDF">pdf</a>, <a href="/format/2304.06373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3DoF Localization from a Single Image and an Object Map: the Flatlandia  Problem and Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Toso%2C+M">Matteo Toso</a>, 
<a href="/search/cs?searchtype=author&query=Taiana%2C+M">Matteo Taiana</a>, 
<a href="/search/cs?searchtype=author&query=James%2C+S">Stuart James</a>, 
<a href="/search/cs?searchtype=author&query=Del+Bue%2C+A">Alessio Del Bue</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07143" title="Abstract">arXiv:2304.07143</a> (replaced) [<a href="/pdf/2304.07143" title="Download PDF">pdf</a>, <a href="/ps/2304.07143" title="Download PostScript">ps</a>, <a href="/format/2304.07143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Review on Car-Following Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+T">Tianya Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Jin%2C+P+J">Peter J. Jin</a>, 
<a href="/search/eess?searchtype=author&query=Bayen%2C+A">Alexandre Bayen</a>, 
<a href="/search/eess?searchtype=author&query=D.%2C+P">Ph.D.</a>, 
<a href="/search/eess?searchtype=author&query=Piccoli%2C+B">Benedetto Piccoli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07361" title="Abstract">arXiv:2304.07361</a> (replaced) [<a href="/pdf/2304.07361" title="Download PDF">pdf</a>, <a href="/format/2304.07361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PTW: Pivotal Tuning Watermarking for Pre-Trained Image Generators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lukas%2C+N">Nils Lukas</a>, 
<a href="/search/cs?searchtype=author&query=Kerschbaum%2C+F">Florian Kerschbaum</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> USENIX Security 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14238" title="Abstract">arXiv:2304.14238</a> (replaced) [<a href="/pdf/2304.14238" title="Download PDF">pdf</a>, <a href="/format/2304.14238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Intended Uses of Automated Fact-Checking Artefacts: Why, How and Who
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schlichtkrull%2C+M">Michael Schlichtkrull</a>, 
<a href="/search/cs?searchtype=author&query=Ousidhoum%2C+N">Nedjma Ousidhoum</a>, 
<a href="/search/cs?searchtype=author&query=Vlachos%2C+A">Andreas Vlachos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02153" title="Abstract">arXiv:2305.02153</a> (replaced) [<a href="/pdf/2305.02153" title="Download PDF">pdf</a>, <a href="/format/2305.02153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic cellular automaton model of culture formation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Klausen%2C+F+R">Frederik Ravn Klausen</a>, 
<a href="/search/physics?searchtype=author&query=Lauritsen%2C+A+B">Asbj&#xf8;rn B&#xe6;kgaard Lauritsen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 12 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Phys. Rev. E 108, 054307 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI); Cellular Automata and Lattice Gases (nlin.CG)

</div>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02480" title="Abstract">arXiv:2305.02480</a> (replaced) [<a href="/pdf/2305.02480" title="Download PDF">pdf</a>, <a href="/format/2305.02480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Quantitative Analysis and Guideline of Data Streaming Accelerator in  Intel 4th Gen Xeon Scalable Processors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuper%2C+R">Reese Kuper</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+I">Ipoom Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yifan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jiayu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ren Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ranganathan%2C+N">Narayan Ranganathan</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+N+S">Nam Sung Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03785" title="Abstract">arXiv:2305.03785</a> (replaced) [<a href="/pdf/2305.03785" title="Download PDF">pdf</a>, <a href="/format/2305.03785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zelda: Video Analytics using Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Romero%2C+F">Francisco Romero</a>, 
<a href="/search/cs?searchtype=author&query=Winston%2C+C">Caleb Winston</a>, 
<a href="/search/cs?searchtype=author&query=Hauswald%2C+J">Johann Hauswald</a>, 
<a href="/search/cs?searchtype=author&query=Zaharia%2C+M">Matei Zaharia</a>, 
<a href="/search/cs?searchtype=author&query=Kozyrakis%2C+C">Christos Kozyrakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03807" title="Abstract">arXiv:2305.03807</a> (replaced) [<a href="/pdf/2305.03807" title="Download PDF">pdf</a>, <a href="/format/2305.03807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evading Watermark based Detection of AI-Generated Content
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhengyuan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jinghuai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+N+Z">Neil Zhenqiang Gong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in ACM Conference on Computer and Communications Security (CCS), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04833" title="Abstract">arXiv:2305.04833</a> (replaced) [<a href="/pdf/2305.04833" title="Download PDF">pdf</a>, <a href="/format/2305.04833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Table Detection Datasets for Visually Rich Documents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+B">Bin Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Simsek%2C+M">Murat Simsek</a>, 
<a href="/search/cs?searchtype=author&query=Kantarci%2C+B">Burak Kantarci</a>, 
<a href="/search/cs?searchtype=author&query=Alkheir%2C+A+A">Ala Abu Alkheir</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06026" title="Abstract">arXiv:2305.06026</a> (replaced) [<a href="/pdf/2305.06026" title="Download PDF">pdf</a>, <a href="/ps/2305.06026" title="Download PostScript">ps</a>, <a href="/format/2305.06026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty in GNN Learning Evaluations: The Importance of a Consistent  Benchmark for Community Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leeney%2C+W">William Leeney</a>, 
<a href="/search/cs?searchtype=author&query=McConville%2C+R">Ryan McConville</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Twelfth International Conference on Complex Networks &amp; Their Applications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09644" title="Abstract">arXiv:2305.09644</a> (replaced) [<a href="/pdf/2305.09644" title="Download PDF">pdf</a>, <a href="/format/2305.09644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RAMP: A Benchmark for Evaluating Robotic Assembly Manipulation and  Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Collins%2C+J">Jack Collins</a>, 
<a href="/search/cs?searchtype=author&query=Robson%2C+M">Mark Robson</a>, 
<a href="/search/cs?searchtype=author&query=Yamada%2C+J">Jun Yamada</a>, 
<a href="/search/cs?searchtype=author&query=Sridharan%2C+M">Mohan Sridharan</a>, 
<a href="/search/cs?searchtype=author&query=Janik%2C+K">Karol Janik</a>, 
<a href="/search/cs?searchtype=author&query=Posner%2C+I">Ingmar Posner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website: <a href="https://sites.google.com/oxfordrobotics.institute/ramp">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10406" title="Abstract">arXiv:2305.10406</a> (replaced) [<a href="/pdf/2305.10406" title="Download PDF">pdf</a>, <a href="/format/2305.10406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variational Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhuliawala%2C+S">Shehzaad Dhuliawala</a>, 
<a href="/search/cs?searchtype=author&query=Sachan%2C+M">Mrinmaya Sachan</a>, 
<a href="/search/cs?searchtype=author&query=Allen%2C+C">Carl Allen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10782" title="Abstract">arXiv:2305.10782</a> (replaced) [<a href="/pdf/2305.10782" title="Download PDF">pdf</a>, <a href="/format/2305.10782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human Behavioral Benchmarking: Numeric Magnitude Comparison Effects in  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shah%2C+R+S">Raj Sanjay Shah</a>, 
<a href="/search/cs?searchtype=author&query=Marupudi%2C+V">Vijay Marupudi</a>, 
<a href="/search/cs?searchtype=author&query=Koenen%2C+R">Reba Koenen</a>, 
<a href="/search/cs?searchtype=author&query=Bhardwaj%2C+K">Khushi Bhardwaj</a>, 
<a href="/search/cs?searchtype=author&query=Varma%2C+S">Sashank Varma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACL findings 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11243" title="Abstract">arXiv:2305.11243</a> (replaced) [<a href="/pdf/2305.11243" title="Download PDF">pdf</a>, <a href="/ps/2305.11243" title="Download PostScript">ps</a>, <a href="/format/2305.11243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing Machines and Children: Using Developmental Psychology  Experiments to Assess the Strengths and Weaknesses of LaMDA Responses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kosoy%2C+E">Eliza Kosoy</a>, 
<a href="/search/cs?searchtype=author&query=Reagan%2C+E+R">Emily Rose Reagan</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+L">Leslie Lai</a>, 
<a href="/search/cs?searchtype=author&query=Gopnik%2C+A">Alison Gopnik</a>, 
<a href="/search/cs?searchtype=author&query=Cobb%2C+D+K">Danielle Krettek Cobb</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11414" title="Abstract">arXiv:2305.11414</a> (replaced) [<a href="/pdf/2305.11414" title="Download PDF">pdf</a>, <a href="/format/2305.11414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Foundation Models: Privacy-Preserving and Collaborative  Learning for Large Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Sixing Yu</a>, 
<a href="/search/cs?searchtype=author&query=Mu%C3%B1oz%2C+J+P">J. Pablo Mu&#xf1;oz</a>, 
<a href="/search/cs?searchtype=author&query=Jannesari%2C+A">Ali Jannesari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12011" title="Abstract">arXiv:2305.12011</a> (replaced) [<a href="/pdf/2305.12011" title="Download PDF">pdf</a>, <a href="/format/2305.12011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Crop Classification by Hierarchically Fusing Satellite,  Rotational, and Contextual Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barriere%2C+V">Valentin Barriere</a>, 
<a href="/search/cs?searchtype=author&query=Claverie%2C+M">Martin Claverie</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+M">Maja Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Lemoine%2C+G">Guido Lemoine</a>, 
<a href="/search/cs?searchtype=author&query=d%27Andrimont%2C+R">Rapha&#xeb;l d&#x27;Andrimont</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to Remote Sensing of Environment, special issue Deep Learning for Time Series. Version 2
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12280" title="Abstract">arXiv:2305.12280</a> (replaced) [<a href="/pdf/2305.12280" title="Download PDF">pdf</a>, <a href="/format/2305.12280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contextualizing Argument Quality Assessment with Relevant Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+D">Darshan Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Sourati%2C+Z">Zhivar Sourati</a>, 
<a href="/search/cs?searchtype=author&query=Ilievski%2C+F">Filip Ilievski</a>, 
<a href="/search/cs?searchtype=author&query=Morstatter%2C+F">Fred Morstatter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12495" title="Abstract">arXiv:2305.12495</a> (replaced) [<a href="/pdf/2305.12495" title="Download PDF">pdf</a>, <a href="/format/2305.12495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fair Without Leveling Down: A New Intersectional Fairness Definition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maheshwari%2C+G">Gaurav Maheshwari</a>, 
<a href="/search/cs?searchtype=author&query=Bellet%2C+A">Aur&#xe9;lien Bellet</a>, 
<a href="/search/cs?searchtype=author&query=Denis%2C+P">Pascal Denis</a>, 
<a href="/search/cs?searchtype=author&query=Keller%2C+M">Mikaela Keller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper has been accepted at: The 2023 Conference on Empirical Methods in Natural Language Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13117" title="Abstract">arXiv:2305.13117</a> (replaced) [<a href="/pdf/2305.13117" title="Download PDF">pdf</a>, <a href="/format/2305.13117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AVeriTeC: A Dataset for Real-world Claim Verification with Evidence from  the Web
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schlichtkrull%2C+M">Michael Schlichtkrull</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhijiang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Vlachos%2C+A">Andreas Vlachos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023 Datasets &amp; Benchmarks Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13583" title="Abstract">arXiv:2305.13583</a> (replaced) [<a href="/pdf/2305.13583" title="Download PDF">pdf</a>, <a href="/format/2305.13583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incongruity-Aware Hierarchical Crossmodal Transformer with Dynamic  Modality Gating: A Study on Affect Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaoting Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanchao Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P+P">Paul Pu Liang</a>, 
<a href="/search/cs?searchtype=author&query=Morency%2C+L">Louis-Philippe Morency</a>, 
<a href="/search/cs?searchtype=author&query=Bell%2C+P">Peter Bell</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+C">Catherine Lai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> *First two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Multimedia (cs.MM); Audio and Speech Processing (eess.AS); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14453" title="Abstract">arXiv:2305.14453</a> (replaced) [<a href="/pdf/2305.14453" title="Download PDF">pdf</a>, <a href="/format/2305.14453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Robustness of Finetuned Transformer-based NLP Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neerudu%2C+P+K+R">Pavan Kalyan Reddy Neerudu</a>, 
<a href="/search/cs?searchtype=author&query=Oota%2C+S+R">Subba Reddy Oota</a>, 
<a href="/search/cs?searchtype=author&query=Marreddy%2C+M">Mounika Marreddy</a>, 
<a href="/search/cs?searchtype=author&query=Kagita%2C+V+R">Venkateswara Rao Kagita</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+M">Manish Gupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 8 figures, To be published in the proceedings of the Conference on Empirical Methods in Natural Language Processing (Findings of EMNLP 2023), Singapore, Long paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14815" title="Abstract">arXiv:2305.14815</a> (replaced) [<a href="/pdf/2305.14815" title="Download PDF">pdf</a>, <a href="/format/2305.14815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Reading Comprehension using Case-based Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thai%2C+D">Dung Thai</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+D">Dhruv Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhary%2C+M">Mudit Chaudhary</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wenlong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+R">Rajarshi Das</a>, 
<a href="/search/cs?searchtype=author&query=Zaheer%2C+M">Manzil Zaheer</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jay-Yoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hajishirzi%2C+H">Hannaneh Hajishirzi</a>, 
<a href="/search/cs?searchtype=author&query=McCallum%2C+A">Andrew McCallum</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14979" title="Abstract">arXiv:2305.14979</a> (replaced) [<a href="/pdf/2305.14979" title="Download PDF">pdf</a>, <a href="/format/2305.14979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessment of the Reliablity of a Model&#x27;s Decision by Generalizing  Attribution to the Wavelet Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kasmi%2C+G">Gabriel Kasmi</a>, 
<a href="/search/cs?searchtype=author&query=Dubus%2C+L">Laurent Dubus</a>, 
<a href="/search/cs?searchtype=author&query=Drenan%2C+Y+S">Yves-Marie Saint Drenan</a>, 
<a href="/search/cs?searchtype=author&query=Blanc%2C+P">Philippe Blanc</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 10 figures, 3 tables. Camera-ready version accepted at the XAI in action workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15022" title="Abstract">arXiv:2305.15022</a> (replaced) [<a href="/pdf/2305.15022" title="Download PDF">pdf</a>, <a href="/format/2305.15022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical clustering with dot products recovers hidden tree structure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Gray%2C+A">Annie Gray</a>, 
<a href="/search/stat?searchtype=author&query=Modell%2C+A">Alexander Modell</a>, 
<a href="/search/stat?searchtype=author&query=Rubin-Delanchy%2C+P">Patrick Rubin-Delanchy</a>, 
<a href="/search/stat?searchtype=author&query=Whiteley%2C+N">Nick Whiteley</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15296" title="Abstract">arXiv:2305.15296</a> (replaced) [<a href="/pdf/2305.15296" title="Download PDF">pdf</a>, <a href="/format/2305.15296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MultiFusion: Fusing Pre-Trained Models for Multi-Lingual, Multi-Modal  Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bellagente%2C+M">Marco Bellagente</a>, 
<a href="/search/cs?searchtype=author&query=Brack%2C+M">Manuel Brack</a>, 
<a href="/search/cs?searchtype=author&query=Teufel%2C+H">Hannah Teufel</a>, 
<a href="/search/cs?searchtype=author&query=Friedrich%2C+F">Felix Friedrich</a>, 
<a href="/search/cs?searchtype=author&query=Deiseroth%2C+B">Bj&#xf6;rn Deiseroth</a>, 
<a href="/search/cs?searchtype=author&query=Eichenberg%2C+C">Constantin Eichenberg</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+A">Andrew Dai</a>, 
<a href="/search/cs?searchtype=author&query=Baldock%2C+R">Robert Baldock</a>, 
<a href="/search/cs?searchtype=author&query=Nanda%2C+S">Souradeep Nanda</a>, 
<a href="/search/cs?searchtype=author&query=Oostermeijer%2C+K">Koen Oostermeijer</a>, 
<a href="/search/cs?searchtype=author&query=Cruz-Salinas%2C+A+F">Andres Felipe Cruz-Salinas</a>, 
<a href="/search/cs?searchtype=author&query=Schramowski%2C+P">Patrick Schramowski</a>, 
<a href="/search/cs?searchtype=author&query=Kersting%2C+K">Kristian Kersting</a>, 
<a href="/search/cs?searchtype=author&query=Weinbach%2C+S">Samuel Weinbach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of Advances in Neural Information Processing Systems: Annual Conference on Neural Information Processing Systems (NeurIPS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15775" title="Abstract">arXiv:2305.15775</a> (replaced) [<a href="/pdf/2305.15775" title="Download PDF">pdf</a>, <a href="/format/2305.15775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concept-Centric Transformers: Enhancing Model Interpretability through  Object-Centric Concept Learning within a Shared Global Workspace
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+J">Jinyung Hong</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+K+H">Keun Hee Park</a>, 
<a href="/search/cs?searchtype=author&query=Pavlic%2C+T+P">Theodore P. Pavlic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 9 tables, 18 figures, Accepted at WACV2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16483" title="Abstract">arXiv:2305.16483</a> (replaced) [<a href="/pdf/2305.16483" title="Download PDF">pdf</a>, <a href="/format/2305.16483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample Efficient Reinforcement Learning in Mixed Systems through  Augmented Samples and Its Applications to Queueing Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Honghao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weina Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+L">Lei Ying</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16681" title="Abstract">arXiv:2305.16681</a> (replaced) [<a href="/pdf/2305.16681" title="Download PDF">pdf</a>, <a href="/format/2305.16681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAILA: Concept-Aware Intra-Layer Adapters for Compositional Zero-Shot  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zhaoheng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Haidong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Nevatia%2C+R">Ram Nevatia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024 Camera Ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16941" title="Abstract">arXiv:2305.16941</a> (replaced) [<a href="/pdf/2305.16941" title="Download PDF">pdf</a>, <a href="/format/2305.16941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Engagement, User Satisfaction, and the Amplification of Divisive Content  on Social Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Milli%2C+S">Smitha Milli</a>, 
<a href="/search/cs?searchtype=author&query=Carroll%2C+M">Micah Carroll</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yike Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pandey%2C+S">Sashrika Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Sebastian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Dragan%2C+A+D">Anca D. Dragan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17489" title="Abstract">arXiv:2305.17489</a> (replaced) [<a href="/pdf/2305.17489" title="Download PDF">pdf</a>, <a href="/format/2305.17489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text-to-image Editing by Image Information Removal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhongping Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jian Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+J+Z">Jacob Zhiyuan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Plummer%2C+B+A">Bryan A. Plummer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full paper is accepted by WACV2024; Best paper runner-up of AI4CC@CVPR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18869" title="Abstract">arXiv:2305.18869</a> (replaced) [<a href="/pdf/2305.18869" title="Download PDF">pdf</a>, <a href="/format/2305.18869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dissecting Chain-of-Thought: Compositionality through In-Context  Filtering and Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yingcong Li</a>, 
<a href="/search/cs?searchtype=author&query=Sreenivasan%2C+K">Kartik Sreenivasan</a>, 
<a href="/search/cs?searchtype=author&query=Giannou%2C+A">Angeliki Giannou</a>, 
<a href="/search/cs?searchtype=author&query=Papailiopoulos%2C+D">Dimitris Papailiopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Oymak%2C+S">Samet Oymak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for NeurIPS 2023. Changes in this version: refined title, restructured content, included new out-of-distribution experiments, and code now available
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19254" title="Abstract">arXiv:2305.19254</a> (replaced) [<a href="/pdf/2305.19254" title="Download PDF">pdf</a>, <a href="/format/2305.19254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Can We Learn from Unlearnable Datasets?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sandoval-Segura%2C+P">Pedro Sandoval-Segura</a>, 
<a href="/search/cs?searchtype=author&query=Singla%2C+V">Vasu Singla</a>, 
<a href="/search/cs?searchtype=author&query=Geiping%2C+J">Jonas Geiping</a>, 
<a href="/search/cs?searchtype=author&query=Goldblum%2C+M">Micah Goldblum</a>, 
<a href="/search/cs?searchtype=author&query=Goldstein%2C+T">Tom Goldstein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023. Code available at <a href="https://github.com/psandovalsegura/learn-from-unlearnable">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01066" title="Abstract">arXiv:2306.01066</a> (replaced) [<a href="/pdf/2306.01066" title="Download PDF">pdf</a>, <a href="/format/2306.01066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating Navigation Strategies in the Morris Water Maze through  Deep Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Andrew Liu</a>, 
<a href="/search/cs?searchtype=author&query=Borisyuk%2C+A">Alla Borisyuk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03286" title="Abstract">arXiv:2306.03286</a> (replaced) [<a href="/pdf/2306.03286" title="Download PDF">pdf</a>, <a href="/format/2306.03286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Survival Instinct in Offline Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Anqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Misra%2C+D">Dipendra Misra</a>, 
<a href="/search/cs?searchtype=author&query=Kolobov%2C+A">Andrey Kolobov</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+C">Ching-An Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04031" title="Abstract">arXiv:2306.04031</a> (replaced) [<a href="/pdf/2306.04031" title="Download PDF">pdf</a>, <a href="/format/2306.04031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Certified Deductive Reasoning with Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Poesia%2C+G">Gabriel Poesia</a>, 
<a href="/search/cs?searchtype=author&query=Gandhi%2C+K">Kanishk Gandhi</a>, 
<a href="/search/cs?searchtype=author&query=Zelikman%2C+E">Eric Zelikman</a>, 
<a href="/search/cs?searchtype=author&query=Goodman%2C+N+D">Noah D. Goodman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04922" title="Abstract">arXiv:2306.04922</a> (replaced) [<a href="/pdf/2306.04922" title="Download PDF">pdf</a>, <a href="/format/2306.04922" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient and Equivariant Graph Networks for Predicting Quantum  Hamiltonian
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Haiyang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+X">Xiaofeng Qian</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+X">Xiaoning Qian</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shuiwang Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05986" title="Abstract">arXiv:2306.05986</a> (replaced) [<a href="/pdf/2306.05986" title="Download PDF">pdf</a>, <a href="/format/2306.05986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fair Allocation with Binary Valuations for Mixed Divisible and  Indivisible Goods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kawase%2C+Y">Yasushi Kawase</a>, 
<a href="/search/cs?searchtype=author&query=Nishimura%2C+K">Koichi Nishimura</a>, 
<a href="/search/cs?searchtype=author&query=Sumita%2C+H">Hanna Sumita</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07107" title="Abstract">arXiv:2306.07107</a> (replaced) [<a href="/pdf/2306.07107" title="Download PDF">pdf</a>, <a href="/format/2306.07107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards continuous-time MPC: a novel trajectory optimization algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Das%2C+S">Souvik Das</a>, 
<a href="/search/math?searchtype=author&query=Ganguly%2C+S">Siddhartha Ganguly</a>, 
<a href="/search/math?searchtype=author&query=Anjali%2C+M">Muthyala Anjali</a>, 
<a href="/search/math?searchtype=author&query=Chatterjee%2C+D">Debasish Chatterjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in IEEE Conference on Decision and Control (CDC), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07623" title="Abstract">arXiv:2306.07623</a> (replaced) [<a href="/pdf/2306.07623" title="Download PDF">pdf</a>, <a href="/format/2306.07623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Invariants and Home Spaces in Transition Systems and Petri Nets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Memmi%2C+G">Gerard Memmi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 83 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07915" title="Abstract">arXiv:2306.07915</a> (replaced) [<a href="/pdf/2306.07915" title="Download PDF">pdf</a>, <a href="/format/2306.07915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Captioners Are Scalable Vision Learners Too
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tschannen%2C+M">Michael Tschannen</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+M">Manoj Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Steiner%2C+A">Andreas Steiner</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xiaohua Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Houlsby%2C+N">Neil Houlsby</a>, 
<a href="/search/cs?searchtype=author&query=Beyer%2C+L">Lucas Beyer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023. v2 adds SugarCrepe results and more ablations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08013" title="Abstract">arXiv:2306.08013</a> (replaced) [<a href="/pdf/2306.08013" title="Download PDF">pdf</a>, <a href="/format/2306.08013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TopP&amp;R: Robust Support Estimation Approach for Evaluating Fidelity and  Diversity in Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+P+J">Pum Jun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+Y">Yoojin Jang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jisu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+J">Jaejun Yoo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09244" title="Abstract">arXiv:2306.09244</a> (replaced) [<a href="/pdf/2306.09244" title="Download PDF">pdf</a>, <a href="/format/2306.09244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text Promptable Surgical Instrument Segmentation with Vision-Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zijian Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Alabi%2C+O">Oluwatosin Alabi</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+M">Meng Wei</a>, 
<a href="/search/cs?searchtype=author&query=Vercauteren%2C+T">Tom Vercauteren</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+M">Miaojing Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12214" title="Abstract">arXiv:2306.12214</a> (replaced) [<a href="/pdf/2306.12214" title="Download PDF">pdf</a>, <a href="/format/2306.12214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> More PAC-Bayes bounds: From bounded losses, to losses with general tail  behaviors, to anytime-validity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Rodr%C3%ADguez-G%C3%A1lvez%2C+B">Borja Rodr&#xed;guez-G&#xe1;lvez</a>, 
<a href="/search/stat?searchtype=author&query=Thobaben%2C+R">Ragnar Thobaben</a>, 
<a href="/search/stat?searchtype=author&query=Skoglund%2C+M">Mikael Skoglund</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages: ~13 of main text, ~4 of references, and ~14 of appendices. Sections 2 and 3 are presented as short papers in the "PAC-Bayes Meets Interactive Learning" workshop at ICML 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13477" title="Abstract">arXiv:2306.13477</a> (replaced) [<a href="/pdf/2306.13477" title="Download PDF">pdf</a>, <a href="/format/2306.13477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Stabilized Circuit-Consistent Foil Conductor Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Paakkunainen%2C+E">Elias Paakkunainen</a>, 
<a href="/search/math?searchtype=author&query=Bundschuh%2C+J">Jonas Bundschuh</a>, 
<a href="/search/math?searchtype=author&query=Garcia%2C+I+C">Idoia Cortes Garcia</a>, 
<a href="/search/math?searchtype=author&query=De+Gersem%2C+H">Herbert De Gersem</a>, 
<a href="/search/math?searchtype=author&query=Sch%C3%B6ps%2C+S">Sebastian Sch&#xf6;ps</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15063" title="Abstract">arXiv:2306.15063</a> (replaced) [<a href="/pdf/2306.15063" title="Download PDF">pdf</a>, <a href="/format/2306.15063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pretraining task diversity and the emergence of non-Bayesian in-context  learning for regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ravent%C3%B3s%2C+A">Allan Ravent&#xf3;s</a>, 
<a href="/search/cs?searchtype=author&query=Paul%2C+M">Mansheej Paul</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Feng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ganguli%2C+S">Surya Ganguli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16359" title="Abstract">arXiv:2306.16359</a> (replaced) [<a href="/pdf/2306.16359" title="Download PDF">pdf</a>, <a href="/format/2306.16359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mulsemedia Communication Research Challenges for Metaverse in 6G  Wireless Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akyildiz%2C+I+F">Ian F. Akyildiz</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hongzhi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+R">Rui Dai</a>, 
<a href="/search/cs?searchtype=author&query=Gerstacker%2C+W">Wolfgang Gerstacker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16635" title="Abstract">arXiv:2306.16635</a> (replaced) [<a href="/pdf/2306.16635" title="Download PDF">pdf</a>, <a href="/format/2306.16635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Fairness in Deepfake Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ju%2C+Y">Yan Ju</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+S">Shan Jia</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G+H">George H. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+S">Siwei Lyu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16750" title="Abstract">arXiv:2306.16750</a> (replaced) [<a href="/pdf/2306.16750" title="Download PDF">pdf</a>, <a href="/format/2306.16750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eigensubspace of Temporal-Difference Dynamics and How It Improves Value  Approximation in Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Q">Qiang He</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+M">Meng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Maghsudi%2C+S">Setareh Maghsudi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ECML23. Code: <a href="https://sites.google.com/view/erc-ecml23/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16838" title="Abstract">arXiv:2306.16838</a> (replaced) [<a href="/pdf/2306.16838" title="Download PDF">pdf</a>, <a href="/format/2306.16838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Kernel Ridge Regression with Gradient-Based Optimization Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Allerbo%2C+O">Oskar Allerbo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Article <a href="/abs/2306.16838">arXiv:2306.16838v1</a> has been updated and split into two articles: this article and <a href="/abs/2311.01762">arXiv:2311.01762</a>. Thus, some of the content in <a href="/abs/2306.16838">arXiv:2306.16838v1</a> is not a part of <a href="/abs/2306.16838">arXiv:2306.16838v2</a>, but of <a href="/abs/2311.01762">arXiv:2311.01762</a>. (The only difference between <a href="/abs/2306.16838">arXiv:2306.16838v2</a> and <a href="/abs/2306.16838">arXiv:2306.16838v3</a> is this comment.)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16884" title="Abstract">arXiv:2306.16884</a> (replaced) [<a href="/pdf/2306.16884" title="Download PDF">pdf</a>, <a href="/format/2306.16884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Policy Space Diversity for Non-Transitive Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jian Yao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weiming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Haobo Fu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yaodong Yang</a>, 
<a href="/search/cs?searchtype=author&query=McAleer%2C+S">Stephen McAleer</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Q">Qiang Fu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wei Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17658" title="Abstract">arXiv:2306.17658</a> (replaced) [<a href="/pdf/2306.17658" title="Download PDF">pdf</a>, <a href="/format/2306.17658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ODE Transformations of Nonlinear DAE Power Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kazma%2C+M+H">Mohamad H. Kazma</a>, 
<a href="/search/eess?searchtype=author&query=Taha%2C+A+F">Ahmad F. Taha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00383" title="Abstract">arXiv:2307.00383</a> (replaced) [<a href="/pdf/2307.00383" title="Download PDF">pdf</a>, <a href="/format/2307.00383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Dexterity in Robotic Manipulation via Hierarchical Contact  Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xianyi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Patil%2C+S">Sarvesh Patil</a>, 
<a href="/search/cs?searchtype=author&query=Temel%2C+Z">Zeynep Temel</a>, 
<a href="/search/cs?searchtype=author&query=Kroemer%2C+O">Oliver Kroemer</a>, 
<a href="/search/cs?searchtype=author&query=Mason%2C+M+T">Matthew T. Mason</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The IEEE Robotics and Automation Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03718" title="Abstract">arXiv:2307.03718</a> (replaced) [<a href="/pdf/2307.03718" title="Download PDF">pdf</a>, <a href="/format/2307.03718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frontier AI Regulation: Managing Emerging Risks to Public Safety
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anderljung%2C+M">Markus Anderljung</a>, 
<a href="/search/cs?searchtype=author&query=Barnhart%2C+J">Joslyn Barnhart</a>, 
<a href="/search/cs?searchtype=author&query=Korinek%2C+A">Anton Korinek</a>, 
<a href="/search/cs?searchtype=author&query=Leung%2C+J">Jade Leung</a>, 
<a href="/search/cs?searchtype=author&query=O%27Keefe%2C+C">Cullen O&#x27;Keefe</a>, 
<a href="/search/cs?searchtype=author&query=Whittlestone%2C+J">Jess Whittlestone</a>, 
<a href="/search/cs?searchtype=author&query=Avin%2C+S">Shahar Avin</a>, 
<a href="/search/cs?searchtype=author&query=Brundage%2C+M">Miles Brundage</a>, 
<a href="/search/cs?searchtype=author&query=Bullock%2C+J">Justin Bullock</a>, 
<a href="/search/cs?searchtype=author&query=Cass-Beggs%2C+D">Duncan Cass-Beggs</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+B">Ben Chang</a>, 
<a href="/search/cs?searchtype=author&query=Collins%2C+T">Tantum Collins</a>, 
<a href="/search/cs?searchtype=author&query=Fist%2C+T">Tim Fist</a>, 
<a href="/search/cs?searchtype=author&query=Hadfield%2C+G">Gillian Hadfield</a>, 
<a href="/search/cs?searchtype=author&query=Hayes%2C+A">Alan Hayes</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+L">Lewis Ho</a>, 
<a href="/search/cs?searchtype=author&query=Hooker%2C+S">Sara Hooker</a>, 
<a href="/search/cs?searchtype=author&query=Horvitz%2C+E">Eric Horvitz</a>, 
<a href="/search/cs?searchtype=author&query=Kolt%2C+N">Noam Kolt</a>, 
<a href="/search/cs?searchtype=author&query=Schuett%2C+J">Jonas Schuett</a>, 
<a href="/search/cs?searchtype=author&query=Shavit%2C+Y">Yonadav Shavit</a>, 
<a href="/search/cs?searchtype=author&query=Siddarth%2C+D">Divya Siddarth</a>, 
<a href="/search/cs?searchtype=author&query=Trager%2C+R">Robert Trager</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+K">Kevin Wolf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Update July 11th: - Added missing footnote back in. - Adjusted author order (mistakenly non-alphabetical among the first 6 authors) and adjusted affiliations (Jess Whittlestone's affiliation was mistagged and Gillian Hadfield had SRI added to her affiliations) Updated September 4th: Various typos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05448" title="Abstract">arXiv:2307.05448</a> (replaced) [<a href="/pdf/2307.05448" title="Download PDF">pdf</a>, <a href="/format/2307.05448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polynomial-Time Linear-Swap Regret Minimization in Imperfect-Information  Sequential Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farina%2C+G">Gabriele Farina</a>, 
<a href="/search/cs?searchtype=author&query=Pipis%2C+C">Charilaos Pipis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07320" title="Abstract">arXiv:2307.07320</a> (replaced) [<a href="/pdf/2307.07320" title="Download PDF">pdf</a>, <a href="/format/2307.07320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Linear Estimating Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ying%2C+M">Mufang Ying</a>, 
<a href="/search/math?searchtype=author&query=Khamaru%2C+K">Koulik Khamaru</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+C">Cun-Hui Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper is accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08032" title="Abstract">arXiv:2307.08032</a> (replaced) [<a href="/pdf/2307.08032" title="Download PDF">pdf</a>, <a href="/ps/2307.08032" title="Download PostScript">ps</a>, <a href="/format/2307.08032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nested Sequents for Quantified Modal Logics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lyon%2C+T+S">Tim S. Lyon</a>, 
<a href="/search/math?searchtype=author&query=Orlandelli%2C+E">Eugenio Orlandelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to TABLEAUX 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09342" title="Abstract">arXiv:2307.09342</a> (replaced) [<a href="/pdf/2307.09342" title="Download PDF">pdf</a>, <a href="/format/2307.09342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Select SAT Encodings for Pseudo-Boolean and Linear Integer  Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ulrich-Oltean%2C+F">Felix Ulrich-Oltean</a>, 
<a href="/search/cs?searchtype=author&query=Nightingale%2C+P">Peter Nightingale</a>, 
<a href="/search/cs?searchtype=author&query=Walker%2C+J+A">James Alfred Walker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 10 figures, accapted by Constraints Journal (Springer, 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09933" title="Abstract">arXiv:2307.09933</a> (replaced) [<a href="/pdf/2307.09933" title="Download PDF">pdf</a>, <a href="/format/2307.09933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spuriosity Didn&#x27;t Kill the Classifier: Using Invariant Predictions to  Harness Spurious Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eastwood%2C+C">Cian Eastwood</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Shashank Singh</a>, 
<a href="/search/cs?searchtype=author&query=Nicolicioiu%2C+A+L">Andrei Liviu Nicolicioiu</a>, 
<a href="/search/cs?searchtype=author&query=Vlastelica%2C+M">Marin Vlastelica</a>, 
<a href="/search/cs?searchtype=author&query=von+K%C3%BCgelgen%2C+J">Julius von K&#xfc;gelgen</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6lkopf%2C+B">Bernhard Sch&#xf6;lkopf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Camera-Ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10779" title="Abstract">arXiv:2307.10779</a> (replaced) [<a href="/pdf/2307.10779" title="Download PDF">pdf</a>, <a href="/format/2307.10779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Beam Tree Recursion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+J+R">Jishnu Ray Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Caragea%2C+C">Cornelia Caragea</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11244" title="Abstract">arXiv:2307.11244</a> (replaced) [<a href="/pdf/2307.11244" title="Download PDF">pdf</a>, <a href="/format/2307.11244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimization approaches for the design and operation of open-loop  shallow geothermal systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Halilovic%2C+S">S. Halilovic</a>, 
<a href="/search/math?searchtype=author&query=B%C3%B6ttcher%2C+F">F. B&#xf6;ttcher</a>, 
<a href="/search/math?searchtype=author&query=Zosseder%2C+K">K. Zosseder</a>, 
<a href="/search/math?searchtype=author&query=Hamacher%2C+T">T. Hamacher</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 3 figures; submitted to Advances in Geosciences
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13639" title="Abstract">arXiv:2307.13639</a> (replaced) [<a href="/pdf/2307.13639" title="Download PDF">pdf</a>, <a href="/format/2307.13639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fake It Without Making It: Conditioned Face Generation for Accurate 3D  Face Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rowan%2C+W">Will Rowan</a>, 
<a href="/search/cs?searchtype=author&query=Huber%2C+P">Patrik Huber</a>, 
<a href="/search/cs?searchtype=author&query=Pears%2C+N">Nick Pears</a>, 
<a href="/search/cs?searchtype=author&query=Keeling%2C+A">Andrew Keeling</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14953" title="Abstract">arXiv:2307.14953</a> (replaced) [<a href="/pdf/2307.14953" title="Download PDF">pdf</a>, <a href="/format/2307.14953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Source Domain Adaptation through Dataset Dictionary Learning in  Wasserstein Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Montesuma%2C+E+F">Eduardo Fernandes Montesuma</a>, 
<a href="/search/cs?searchtype=author&query=Mboula%2C+F+N">Fred Ngol&#xe8; Mboula</a>, 
<a href="/search/cs?searchtype=author&query=Souloumiac%2C+A">Antoine Souloumiac</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages,8 figures,Published as a conference paper at the 26th European Conference on Artificial Intelligence; v2: corrected typos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00113" title="Abstract">arXiv:2308.00113</a> (replaced) [<a href="/pdf/2308.00113" title="Download PDF">pdf</a>, <a href="/format/2308.00113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Three Bricks to Consolidate Watermarks for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fernandez%2C+P">Pierre Fernandez</a>, 
<a href="/search/cs?searchtype=author&query=Chaffin%2C+A">Antoine Chaffin</a>, 
<a href="/search/cs?searchtype=author&query=Tit%2C+K">Karim Tit</a>, 
<a href="/search/cs?searchtype=author&query=Chappelier%2C+V">Vivien Chappelier</a>, 
<a href="/search/cs?searchtype=author&query=Furon%2C+T">Teddy Furon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at WIFS 2023. Code at <a href="https://github.com/facebookresearch/three_bricks">this https URL</a> - webpage at <a href="https://pierrefdz.github.io/publications/threebricks/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00158" title="Abstract">arXiv:2308.00158</a> (replaced) [<a href="/pdf/2308.00158" title="Download PDF">pdf</a>, <a href="/format/2308.00158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predictive Data Analytics with AI: assessing the need for post-editing  of MT output by fine-tuning OpenAI LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gladkoff%2C+S">Serge Gladkoff</a>, 
<a href="/search/cs?searchtype=author&query=Erofeev%2C+G">Gleb Erofeev</a>, 
<a href="/search/cs?searchtype=author&query=Sorokina%2C+I">Irina Sorokina</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+L">Lifeng Han</a>, 
<a href="/search/cs?searchtype=author&query=Nenadic%2C+G">Goran Nenadic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to present at AMTA2023: Generative AI and the Future of Machine Translation (non-archival oral presentation) \url{<a href="https://machinetranslate.org/amta2023">this https URL</a>}. Association for Machine Translation in the Americas
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00530" title="Abstract">arXiv:2308.00530</a> (replaced) [<a href="/pdf/2308.00530" title="Download PDF">pdf</a>, <a href="/format/2308.00530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tolerating Annotation Displacement in Dense Object Counting via Point  Annotation Probability Map
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuehai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Badong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gang%2C+H">Hua Gang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+S">Shaoyi Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01020" title="Abstract">arXiv:2308.01020</a> (replaced) [<a href="/pdf/2308.01020" title="Download PDF">pdf</a>, <a href="/format/2308.01020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Model Predictive Approach for Enhancing Transient Stability of  Grid-Forming Converters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Arjomandi-Nezhad%2C+A">Ali Arjomandi-Nezhad</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+Y">Yifei Guo</a>, 
<a href="/search/eess?searchtype=author&query=Pal%2C+B+C">Bikash C. Pal</a>, 
<a href="/search/eess?searchtype=author&query=Varagnolo%2C+D">Damiano Varagnolo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01098" title="Abstract">arXiv:2308.01098</a> (replaced) [<a href="/pdf/2308.01098" title="Download PDF">pdf</a>, <a href="/format/2308.01098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Better Query Classification with Multi-Expert Knowledge  Condensation in JD Ads Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ning%2C+K">Kun-Peng Ning</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+M">Ming Pang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zheng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xue Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xi-Wei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Chang-Ping Peng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhan-Gang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jing-He Hu</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Jing-Ping Shao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02560" title="Abstract">arXiv:2308.02560</a> (replaced) [<a href="/pdf/2308.02560" title="Download PDF">pdf</a>, <a href="/format/2308.02560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Discrete Tokens to High-Fidelity Audio Using Multi-Band Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roman%2C+R+S">Robin San Roman</a>, 
<a href="/search/cs?searchtype=author&query=Adi%2C+Y">Yossi Adi</a>, 
<a href="/search/cs?searchtype=author&query=Deleforge%2C+A">Antoine Deleforge</a>, 
<a href="/search/cs?searchtype=author&query=Serizel%2C+R">Romain Serizel</a>, 
<a href="/search/cs?searchtype=author&query=Synnaeve%2C+G">Gabriel Synnaeve</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%A9fossez%2C+A">Alexandre D&#xe9;fossez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Thirty-seventh Conference on Neural Information Processing Systems
  (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03644" title="Abstract">arXiv:2308.03644</a> (replaced) [<a href="/pdf/2308.03644" title="Download PDF">pdf</a>, <a href="/format/2308.03644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perceptually Uniform Construction of Illustrative Textures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sterzik%2C+A">Anna Sterzik</a>, 
<a href="/search/cs?searchtype=author&query=Meuschke%2C+M">Monique Meuschke</a>, 
<a href="/search/cs?searchtype=author&query=Cunningham%2C+D+W">Douglas W. Cunningham</a>, 
<a href="/search/cs?searchtype=author&query=Lawonn%2C+K">Kai Lawonn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 15 figures, to be published in IEEE Transactions on Visualization and Computer Graphics The supplementary material is available at <a href="https://www.doi.org/10.17605/OSF.IO/43C6V">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03898" title="Abstract">arXiv:2308.03898</a> (replaced) [<a href="/pdf/2308.03898" title="Download PDF">pdf</a>, <a href="/format/2308.03898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> System Identification and Control of Front-Steered Ackermann Vehicles  through Differentiable Physics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gonultas%2C+B+M">Burak M. Gonultas</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+P">Pratik Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Poyrazoglu%2C+O+G">O. Goktug Poyrazoglu</a>, 
<a href="/search/cs?searchtype=author&query=Isler%2C+V">Volkan Isler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for IROS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03940" title="Abstract">arXiv:2308.03940</a> (replaced) [<a href="/pdf/2308.03940" title="Download PDF">pdf</a>, <a href="/ps/2308.03940" title="Download PostScript">ps</a>, <a href="/format/2308.03940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simulating the Software Development Lifecycle: The Waterfall Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saravanos%2C+A">Antonios Saravanos</a> (1), 
<a href="/search/cs?searchtype=author&query=Curinga%2C+M+X">Mathew X. Curinga</a> (2) ((1) New York University, (2) MIXI Institute for STEM and the Imagination, Adelphi University)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04150" title="Abstract">arXiv:2308.04150</a> (replaced) [<a href="/pdf/2308.04150" title="Download PDF">pdf</a>, <a href="/format/2308.04150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perception of Line Attributes for Visualization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sterzik%2C+A">Anna Sterzik</a>, 
<a href="/search/cs?searchtype=author&query=Lichtenberg%2C+N">Nils Lichtenberg</a>, 
<a href="/search/cs?searchtype=author&query=Wilms%2C+J">Jana Wilms</a>, 
<a href="/search/cs?searchtype=author&query=Krone%2C+M">Michael Krone</a>, 
<a href="/search/cs?searchtype=author&query=Cunningham%2C+D+W">Douglas W. Cunningham</a>, 
<a href="/search/cs?searchtype=author&query=Lawonn%2C+K">Kai Lawonn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 9 figures, to be published in IEEE Transactions on Visualization and Computer Graphics The supplemental material for this paper is available at <a href="https://www.doi.org/10.17605/OSF.IO/7SCF8">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06202" title="Abstract">arXiv:2308.06202</a> (replaced) [<a href="/pdf/2308.06202" title="Download PDF">pdf</a>, <a href="/format/2308.06202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Predicate Visual Context in Detecting Human-Object  Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F+Z">Frederic Z. Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yuhui Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Campbell%2C+D">Dylan Campbell</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Z">Zhuoyao Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Gould%2C+S">Stephen Gould</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06283" title="Abstract">arXiv:2308.06283</a> (replaced) [<a href="/pdf/2308.06283" title="Download PDF">pdf</a>, <a href="/format/2308.06283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extract and Characterize Hairpin Vortices in Turbulent Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zafar%2C+A">Adeel Zafar</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Di Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guoning Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06744" title="Abstract">arXiv:2308.06744</a> (replaced) [<a href="/pdf/2308.06744" title="Download PDF">pdf</a>, <a href="/format/2308.06744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Token-Scaled Logit Distillation for Ternary Weight Generative Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minsoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sihwa Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Janghwan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+S">Sukjin Hong</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+D">Du-Seong Chang</a>, 
<a href="/search/cs?searchtype=author&query=Sung%2C+W">Wonyong Sung</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jungwook Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09078" title="Abstract">arXiv:2308.09078</a> (replaced) [<a href="/pdf/2308.09078" title="Download PDF">pdf</a>, <a href="/format/2308.09078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conditional Sampling of Variational Autoencoders via Iterated  Approximate Ancestral Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Simkus%2C+V">Vaidotas Simkus</a>, 
<a href="/search/cs?searchtype=author&query=Gutmann%2C+M+U">Michael U. Gutmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Transactions on Machine Learning Research (TMLR), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16336" title="Abstract">arXiv:2308.16336</a> (replaced) [<a href="/pdf/2308.16336" title="Download PDF">pdf</a>, <a href="/format/2308.16336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ToddlerBERTa: Exploiting BabyBERTa for Grammar Learning and Language  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cagatan%2C+O+V">Omer Veysel Cagatan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CoNLL--CMCL 2023 Shared Task: The BabyLM Challenge, Camera-Ready Version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01825" title="Abstract">arXiv:2309.01825</a> (replaced) [<a href="/pdf/2309.01825" title="Download PDF">pdf</a>, <a href="/format/2309.01825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LoopTune: Optimizing Tensor Computations with Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grubisic%2C+D">Dejan Grubisic</a>, 
<a href="/search/cs?searchtype=author&query=Wasti%2C+B">Bram Wasti</a>, 
<a href="/search/cs?searchtype=author&query=Cummins%2C+C">Chris Cummins</a>, 
<a href="/search/cs?searchtype=author&query=Mellor-Crummey%2C+J">John Mellor-Crummey</a>, 
<a href="/search/cs?searchtype=author&query=Zlateski%2C+A">Aleksandar Zlateski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04898" title="Abstract">arXiv:2309.04898</a> (replaced) [<a href="/pdf/2309.04898" title="Download PDF">pdf</a>, <a href="/format/2309.04898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-Constrained Programmable Matter Under Unfair Adversaries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weber%2C+J+W">Jamison W. Weber</a>, 
<a href="/search/cs?searchtype=author&query=Chhabra%2C+T">Tishya Chhabra</a>, 
<a href="/search/cs?searchtype=author&query=Richa%2C+A+W">Andr&#xe9;a W. Richa</a>, 
<a href="/search/cs?searchtype=author&query=Daymude%2C+J+J">Joshua J. Daymude</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 4 figures, 1 table. To appear in the proceedings of OPODIS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06055" title="Abstract">arXiv:2309.06055</a> (replaced) [<a href="/pdf/2309.06055" title="Download PDF">pdf</a>, <a href="/format/2309.06055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Backdoor Attacks and Countermeasures in Natural Language Processing  Models: A Comprehensive Security Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Pengzhou Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zongru Wu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+W">Wei Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Haodong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Wei Lu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Gongshen Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06183" title="Abstract">arXiv:2309.06183</a> (replaced) [<a href="/pdf/2309.06183" title="Download PDF">pdf</a>, <a href="/format/2309.06183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing the Generalization Gap of Learning-Based Speech Enhancement  Systems in Noisy and Reverberant Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gonzalez%2C+P">Philippe Gonzalez</a>, 
<a href="/search/eess?searchtype=author&query=Alstr%C3%B8m%2C+T+S">Tommy Sonne Alstr&#xf8;m</a>, 
<a href="/search/eess?searchtype=author&query=May%2C+T">Tobias May</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE/ACM TASLP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06597" title="Abstract">arXiv:2309.06597</a> (replaced) [<a href="/pdf/2309.06597" title="Download PDF">pdf</a>, <a href="/format/2309.06597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rank2Tell: A Multimodal Driving Dataset for Joint Importance Ranking and  Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sachdeva%2C+E">Enna Sachdeva</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+N">Nakul Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Chundi%2C+S">Suhas Chundi</a>, 
<a href="/search/cs?searchtype=author&query=Roelofs%2C+S">Sean Roelofs</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiachen Li</a>, 
<a href="/search/cs?searchtype=author&query=Kochenderfer%2C+M">Mykel Kochenderfer</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+C">Chiho Choi</a>, 
<a href="/search/cs?searchtype=author&query=Dariush%2C+B">Behzad Dariush</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06763" title="Abstract">arXiv:2309.06763</a> (replaced) [<a href="/pdf/2309.06763" title="Download PDF">pdf</a>, <a href="/format/2309.06763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving rescheduling problems in heterogeneous urban railway networks  using hybrid quantum-classical approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Koniorczyk%2C+M">M&#xe1;ty&#xe1;s Koniorczyk</a>, 
<a href="/search/quant-ph?searchtype=author&query=Krawiec%2C+K">Krzysztof Krawiec</a>, 
<a href="/search/quant-ph?searchtype=author&query=Botelho%2C+L">Ludmila Botelho</a>, 
<a href="/search/quant-ph?searchtype=author&query=Be%C5%A1inovi%C4%87%2C+N">Nikola Be&#x161;inovi&#x107;</a>, 
<a href="/search/quant-ph?searchtype=author&query=Domino%2C+K">Krzysztof Domino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07670" title="Abstract">arXiv:2309.07670</a> (replaced) [<a href="/pdf/2309.07670" title="Download PDF">pdf</a>, <a href="/format/2309.07670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Dataset Dictionary Learning for Multi-Source Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Castellon%2C+F+E">Fabiola Espinoza Castellon</a>, 
<a href="/search/cs?searchtype=author&query=Montesuma%2C+E+F">Eduardo Fernandes Montesuma</a>, 
<a href="/search/cs?searchtype=author&query=Mboula%2C+F+N">Fred Ngol&#xe8; Mboula</a>, 
<a href="/search/cs?searchtype=author&query=Mayoue%2C+A">Aur&#xe9;lien Mayoue</a>, 
<a href="/search/cs?searchtype=author&query=Souloumiac%2C+A">Antoine Souloumiac</a>, 
<a href="/search/cs?searchtype=author&query=Gouy-Pailler%2C+C">C&#xe9;dric Gouy-Pailler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages,2 figures; v2: fixed typos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08125" title="Abstract">arXiv:2309.08125</a> (replaced) [<a href="/pdf/2309.08125" title="Download PDF">pdf</a>, <a href="/format/2309.08125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Oobleck: Resilient Distributed Training of Large Models Using Pipeline  Templates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jang%2C+I">Insu Jang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhenning Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xin Jin</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+M">Mosharaf Chowdhury</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SOSP'23 | Camera-ready + figures and numbers are corrected
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08589" title="Abstract">arXiv:2309.08589</a> (replaced) [<a href="/pdf/2309.08589" title="Download PDF">pdf</a>, <a href="/format/2309.08589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chain-of-Thought Reasoning is a Policy Improvement Operator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hugh Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Parkes%2C+D+C">David C. Parkes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08637" title="Abstract">arXiv:2309.08637</a> (replaced) [<a href="/pdf/2309.08637" title="Download PDF">pdf</a>, <a href="/format/2309.08637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TextBind: Multi-turn Interleaved Multimodal Instruction-following in the  Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huayang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Siheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+D">Deng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Longyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lemao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Watanabe%2C+T">Taro Watanabe</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yujiu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shuming Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://textbind.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08646" title="Abstract">arXiv:2309.08646</a> (replaced) [<a href="/pdf/2309.08646" title="Download PDF">pdf</a>, <a href="/format/2309.08646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoCA: Fusing position embedding with Collinear Constrained Attention for  fine-tuning free context window extending
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Shiyi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jing Ye</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yifan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianguo Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08872" title="Abstract">arXiv:2309.08872</a> (replaced) [<a href="/pdf/2309.08872" title="Download PDF">pdf</a>, <a href="/format/2309.08872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PDFTriage: Question Answering over Long, Structured Documents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saad-Falcon%2C+J">Jon Saad-Falcon</a>, 
<a href="/search/cs?searchtype=author&query=Barrow%2C+J">Joe Barrow</a>, 
<a href="/search/cs?searchtype=author&query=Siu%2C+A">Alexa Siu</a>, 
<a href="/search/cs?searchtype=author&query=Nenkova%2C+A">Ani Nenkova</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+D+S">David Seunghyun Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+R+A">Ryan A. Rossi</a>, 
<a href="/search/cs?searchtype=author&query=Dernoncourt%2C+F">Franck Dernoncourt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11119" title="Abstract">arXiv:2309.11119</a> (replaced) [<a href="/pdf/2309.11119" title="Download PDF">pdf</a>, <a href="/format/2309.11119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BroadBEV: Collaborative LiDAR-camera Fusion for Broad-sighted Bird&#x27;s Eye  View Map Construction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minsu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+G">Giseop Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+K+H">Kyong Hwan Jin</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+S">Sunwook Choi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12214" title="Abstract">arXiv:2309.12214</a> (replaced) [<a href="/pdf/2309.12214" title="Download PDF">pdf</a>, <a href="/format/2309.12214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can We Reliably Improve the Robustness to Image Acquisition of Remote  Sensing of PV Systems?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kasmi%2C+G">Gabriel Kasmi</a>, 
<a href="/search/cs?searchtype=author&query=Dubus%2C+L">Laurent Dubus</a>, 
<a href="/search/cs?searchtype=author&query=Saint-Drenan%2C+Y">Yves-Marie Saint-Drenan</a>, 
<a href="/search/cs?searchtype=author&query=Blanc%2C+P">Philippe Blanc</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 11 figures, 4 tables. Camera ready version accepted for the Tackling Climate Change with Machine Learning workshop at NeurIPS 2023. Note: Appendix B.1. overlaps with <a href="/abs/2305.14979">arXiv:2305.14979</a> (Assessment of the Reliablity of a Model's Decision by Generalizing Attribution to the Wavelet Domain)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16536" title="Abstract">arXiv:2309.16536</a> (replaced) [<a href="/pdf/2309.16536" title="Download PDF">pdf</a>, <a href="/format/2309.16536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty Quantification for Eosinophil Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lin%2C+K">Kevin Lin</a>, 
<a href="/search/eess?searchtype=author&query=Brown%2C+D">Donald Brown</a>, 
<a href="/search/eess?searchtype=author&query=Syed%2C+S">Sana Syed</a>, 
<a href="/search/eess?searchtype=author&query=Greene%2C+A">Adam Greene</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint, Final Article Submitted to ICBRA 2023 and will be published in the International Conference Proceedings by ACM, Association for Computing Machinery (ISBN: 979-8-4007-0815-2), which will be archived in ACM Digital Library, indexed by Ei Compendex and Scopus
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00034" title="Abstract">arXiv:2310.00034</a> (replaced) [<a href="/pdf/2310.00034" title="Download PDF">pdf</a>, <a href="/format/2310.00034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PB-LLM: Partially Binarized Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shang%2C+Y">Yuzhang Shang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zhihang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qiang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zhen Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Frist work using network binarization for large language model compression
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01235" title="Abstract">arXiv:2310.01235</a> (replaced) [<a href="/pdf/2310.01235" title="Download PDF">pdf</a>, <a href="/format/2310.01235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COIN-LIO: Complementary Intensity-Augmented LiDAR Inertial Odometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pfreundschuh%2C+P">Patrick Pfreundschuh</a>, 
<a href="/search/cs?searchtype=author&query=Oleynikova%2C+H">Helen Oleynikova</a>, 
<a href="/search/cs?searchtype=author&query=Cadena%2C+C">Cesar Cadena</a>, 
<a href="/search/cs?searchtype=author&query=Siegwart%2C+R">Roland Siegwart</a>, 
<a href="/search/cs?searchtype=author&query=Andersson%2C+O">Olov Andersson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02367" title="Abstract">arXiv:2310.02367</a> (replaced) [<a href="/pdf/2310.02367" title="Download PDF">pdf</a>, <a href="/format/2310.02367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear Recurrent Units for Sequential Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+Z">Zhenrui Yue</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yueqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhankui He</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+H">Huimin Zeng</a>, 
<a href="/search/cs?searchtype=author&query=McAuley%2C+J">Julian McAuley</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WSDM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03482" title="Abstract">arXiv:2310.03482</a> (replaced) [<a href="/pdf/2310.03482" title="Download PDF">pdf</a>, <a href="/format/2310.03482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Geometric Structure of Fully-Connected ReLU Layers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vallin%2C+J">Jonatan Vallin</a>, 
<a href="/search/cs?searchtype=author&query=Larsson%2C+K">Karl Larsson</a>, 
<a href="/search/cs?searchtype=author&query=Larson%2C+M+G">Mats G. Larson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03661" title="Abstract">arXiv:2310.03661</a> (replaced) [<a href="/pdf/2310.03661" title="Download PDF">pdf</a>, <a href="/format/2310.03661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robustness-Guided Image Synthesis for Data-Free Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jianhong Bai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuchen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+H">Huanpeng Chu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hualiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zuozhu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruizhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiaoxuan He</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+L">Lianrui Mu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+C">Chengfei Cai</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Haoji Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03912" title="Abstract">arXiv:2310.03912</a> (replaced) [<a href="/pdf/2310.03912" title="Download PDF">pdf</a>, <a href="/ps/2310.03912" title="Download PostScript">ps</a>, <a href="/format/2310.03912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RTDK-BO: High Dimensional Bayesian Optimization with Reinforced  Transformer Deep kernels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shmakov%2C+A">Alexander Shmakov</a>, 
<a href="/search/cs?searchtype=author&query=Naug%2C+A">Avisek Naug</a>, 
<a href="/search/cs?searchtype=author&query=Gundecha%2C+V">Vineet Gundecha</a>, 
<a href="/search/cs?searchtype=author&query=Ghorbanpour%2C+S">Sahand Ghorbanpour</a>, 
<a href="/search/cs?searchtype=author&query=Gutierrez%2C+R+L">Ricardo Luna Gutierrez</a>, 
<a href="/search/cs?searchtype=author&query=Babu%2C+A+R">Ashwin Ramesh Babu</a>, 
<a href="/search/cs?searchtype=author&query=Guillen%2C+A">Antonio Guillen</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+S">Soumyendu Sarkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 IEEE 19th International Conference on Automation Science and Engineering (CASE)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04655" title="Abstract">arXiv:2310.04655</a> (replaced) [<a href="/pdf/2310.04655" title="Download PDF">pdf</a>, <a href="/format/2310.04655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VLAttack: Multimodal Adversarial Attacks on Vision-Language Tasks via  Pre-trained Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Ziyi Yin</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+M">Muchao Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianrong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+T">Tianyu Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jinguo Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Han Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jinghui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Ting Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+F">Fenglong Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05036" title="Abstract">arXiv:2310.05036</a> (replaced) [<a href="/pdf/2310.05036" title="Download PDF">pdf</a>, <a href="/format/2310.05036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AvalonBench: Evaluating LLMs Playing the Game of Avalon
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Light%2C+J">Jonathan Light</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+M">Min Cai</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+S">Sheng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Ziniu Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08051" title="Abstract">arXiv:2310.08051</a> (replaced) [<a href="/pdf/2310.08051" title="Download PDF">pdf</a>, <a href="/format/2310.08051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LGL-BCI: A Lightweight Geometric Learning Framework for Motor  Imagery-Based Brain-Computer Interfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jianchao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuzhe Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+J">Jiaqi Ge</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+Q+Z">Quan Z. Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xi Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08759" title="Abstract">arXiv:2310.08759</a> (replaced) [<a href="/pdf/2310.08759" title="Download PDF">pdf</a>, <a href="/ps/2310.08759" title="Download PostScript">ps</a>, <a href="/format/2310.08759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Question Answering for Electronic Health Records: A Scoping Review of  datasets and models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bardhan%2C+J">Jayetri Bardhan</a>, 
<a href="/search/cs?searchtype=author&query=Roberts%2C+K">Kirk Roberts</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D+Z">Daisy Zhe Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 tables, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09689" title="Abstract">arXiv:2310.09689</a> (replaced) [<a href="/pdf/2310.09689" title="Download PDF">pdf</a>, <a href="/format/2310.09689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Partially Supervised Reinforcement Learning Framework for Visual  Active Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+A">Anindya Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Jacobs%2C+N">Nathan Jacobs</a>, 
<a href="/search/cs?searchtype=author&query=Vorobeychik%2C+Y">Yevgeniy Vorobeychik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 20 figures, Accepted to NeurIPS 2023, Code is available at <a href="https://github.com/anindyasarkarIITH/PSRL_VAS/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11097" title="Abstract">arXiv:2310.11097</a> (replaced) [<a href="/pdf/2310.11097" title="Download PDF">pdf</a>, <a href="/format/2310.11097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experimenting AI Technologies for Disinformation Combat: the IDMO  Project
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Canale%2C+L">Lorenzo Canale</a>, 
<a href="/search/cs?searchtype=author&query=Messina%2C+A">Alberto Messina</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13032" title="Abstract">arXiv:2310.13032</a> (replaced) [<a href="/pdf/2310.13032" title="Download PDF">pdf</a>, <a href="/format/2310.13032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quality-Diversity through AI Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bradley%2C+H">Herbie Bradley</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+A">Andrew Dai</a>, 
<a href="/search/cs?searchtype=author&query=Teufel%2C+H">Hannah Teufel</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jenny Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Oostermeijer%2C+K">Koen Oostermeijer</a>, 
<a href="/search/cs?searchtype=author&query=Bellagente%2C+M">Marco Bellagente</a>, 
<a href="/search/cs?searchtype=author&query=Clune%2C+J">Jeff Clune</a>, 
<a href="/search/cs?searchtype=author&query=Stanley%2C+K">Kenneth Stanley</a>, 
<a href="/search/cs?searchtype=author&query=Schott%2C+G">Gr&#xe9;gory Schott</a>, 
<a href="/search/cs?searchtype=author&query=Lehman%2C+J">Joel Lehman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> minor edits, correction in appendix for improved clarity
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13067" title="Abstract">arXiv:2310.13067</a> (replaced) [<a href="/pdf/2310.13067" title="Download PDF">pdf</a>, <a href="/format/2310.13067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Existence and Structure of Universal Partial Cycles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Fillmore%2C+D">Dylan Fillmore</a>, 
<a href="/search/math?searchtype=author&query=Goeckner%2C+B">Bennet Goeckner</a>, 
<a href="/search/math?searchtype=author&query=Kirsch%2C+R">Rachel Kirsch</a>, 
<a href="/search/math?searchtype=author&query=Martin%2C+K">Kirin Martin</a>, 
<a href="/search/math?searchtype=author&query=McGinnis%2C+D">Daniel McGinnis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 10 figures. v2: Slight modification to the definition of autocorrelation and corresponding updates to Section 7.4. All results remain unchanged
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13564" title="Abstract">arXiv:2310.13564</a> (replaced) [<a href="/pdf/2310.13564" title="Download PDF">pdf</a>, <a href="/format/2310.13564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $hp$-optimal convergence of the original DG method for linear hyperbolic  problems on special simplicial meshes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dong%2C+Z">Zhaonan Dong</a>, 
<a href="/search/math?searchtype=author&query=Mascotto%2C+L">Lorenzo Mascotto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14948" title="Abstract">arXiv:2310.14948</a> (replaced) [<a href="/pdf/2310.14948" title="Download PDF">pdf</a>, <a href="/format/2310.14948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Informed Graph Convolutional Networks: Towards a generalized  framework for complex geometries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chenaud%2C+M">Marien Chenaud</a>, 
<a href="/search/cs?searchtype=author&query=Alves%2C+J">Jos&#xe9; Alves</a>, 
<a href="/search/cs?searchtype=author&query=Magoul%C3%A8s%2C+F">Fr&#xe9;d&#xe9;ric Magoul&#xe8;s</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Civil-Comp Conferences, Volume 5, Paper 4.2, Civil-Comp Press,
  Edinburgh, United Kingdom, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Mathematical Physics (math-ph); Analysis of PDEs (math.AP)

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16870" title="Abstract">arXiv:2310.16870</a> (replaced) [<a href="/pdf/2310.16870" title="Download PDF">pdf</a>, <a href="/format/2310.16870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MACP: Efficient Model Adaptation for Cooperative Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yunsheng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Juanwu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+C">Can Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Sicheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+W">Wenqian Ye</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziran Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WACV 2024, 10 pages, 8 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16872" title="Abstract">arXiv:2310.16872</a> (replaced) [<a href="/pdf/2310.16872" title="Download PDF">pdf</a>, <a href="/format/2310.16872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SonoSAMTrack -- Segment and Track Anything on Ultrasound Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ravishankar%2C+H">Hariharan Ravishankar</a>, 
<a href="/search/eess?searchtype=author&query=Patil%2C+R">Rohan Patil</a>, 
<a href="/search/eess?searchtype=author&query=Melapudi%2C+V">Vikram Melapudi</a>, 
<a href="/search/eess?searchtype=author&query=Anzengruber%2C+S">Stephan Anzengruber</a>, 
<a href="/search/eess?searchtype=author&query=Bhatia%2C+P">Parminder Bhatia</a>, 
<a href="/search/eess?searchtype=author&query=Taha%2C+K">Kass-Hout Taha</a>, 
<a href="/search/eess?searchtype=author&query=Annangi%2C+P">Pavan Annangi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17021" title="Abstract">arXiv:2310.17021</a> (replaced) [<a href="/pdf/2310.17021" title="Download PDF">pdf</a>, <a href="/format/2310.17021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Streaming Factor Trajectory Learning for Temporal Tensor Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+S">Shikai Fang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shibo Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kirby%2C+R">Robert Kirby</a>, 
<a href="/search/cs?searchtype=author&query=Zhe%2C+S">Shandian Zhe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18130" title="Abstract">arXiv:2310.18130</a> (replaced) [<a href="/pdf/2310.18130" title="Download PDF">pdf</a>, <a href="/format/2310.18130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DELPHI: Data for Evaluating LLMs&#x27; Performance in Handling Controversial  Issues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+D+Q">David Q. Sun</a>, 
<a href="/search/cs?searchtype=author&query=Abzaliev%2C+A">Artem Abzaliev</a>, 
<a href="/search/cs?searchtype=author&query=Kotek%2C+H">Hadas Kotek</a>, 
<a href="/search/cs?searchtype=author&query=Xiu%2C+Z">Zidi Xiu</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+C">Christopher Klein</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+J+D">Jason D. Williams</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP Industry Track 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18471" title="Abstract">arXiv:2310.18471</a> (replaced) [<a href="/pdf/2310.18471" title="Download PDF">pdf</a>, <a href="/format/2310.18471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal disentanglement of multimodal data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Walker%2C+E">Elise Walker</a>, 
<a href="/search/cs?searchtype=author&query=Actor%2C+J+A">Jonas A. Actor</a>, 
<a href="/search/cs?searchtype=author&query=Martinez%2C+C">Carianne Martinez</a>, 
<a href="/search/cs?searchtype=author&query=Trask%2C+N">Nathaniel Trask</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18626" title="Abstract">arXiv:2310.18626</a> (replaced) [<a href="/pdf/2310.18626" title="Download PDF">pdf</a>, <a href="/ps/2310.18626" title="Download PostScript">ps</a>, <a href="/format/2310.18626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmark Generation Framework with Customizable Distortions for Image  Classifier Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+S">Soumyendu Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Babu%2C+A+R">Ashwin Ramesh Babu</a>, 
<a href="/search/cs?searchtype=author&query=Mousavi%2C+S">Sajad Mousavi</a>, 
<a href="/search/cs?searchtype=author&query=Carmichael%2C+Z">Zachariah Carmichael</a>, 
<a href="/search/cs?searchtype=author&query=Gundecha%2C+V">Vineet Gundecha</a>, 
<a href="/search/cs?searchtype=author&query=Ghorbanpour%2C+S">Sahand Ghorbanpour</a>, 
<a href="/search/cs?searchtype=author&query=Luna%2C+R">Ricardo Luna</a>, 
<a href="/search/cs?searchtype=author&query=Guillen%2C+G+A">Gutierrez Antonio Guillen</a>, 
<a href="/search/cs?searchtype=author&query=Naug%2C+A">Avisek Naug</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18660" title="Abstract">arXiv:2310.18660</a> (replaced) [<a href="/pdf/2310.18660" title="Download PDF">pdf</a>, <a href="/format/2310.18660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Foundation Models for Generalist Geospatial Artificial Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jakubik%2C+J">Johannes Jakubik</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+S">Sujit Roy</a>, 
<a href="/search/cs?searchtype=author&query=Phillips%2C+C+E">C. E. Phillips</a>, 
<a href="/search/cs?searchtype=author&query=Fraccaro%2C+P">Paolo Fraccaro</a>, 
<a href="/search/cs?searchtype=author&query=Godwin%2C+D">Denys Godwin</a>, 
<a href="/search/cs?searchtype=author&query=Zadrozny%2C+B">Bianca Zadrozny</a>, 
<a href="/search/cs?searchtype=author&query=Szwarcman%2C+D">Daniela Szwarcman</a>, 
<a href="/search/cs?searchtype=author&query=Gomes%2C+C">Carlos Gomes</a>, 
<a href="/search/cs?searchtype=author&query=Nyirjesy%2C+G">Gabby Nyirjesy</a>, 
<a href="/search/cs?searchtype=author&query=Edwards%2C+B">Blair Edwards</a>, 
<a href="/search/cs?searchtype=author&query=Kimura%2C+D">Daiki Kimura</a>, 
<a href="/search/cs?searchtype=author&query=Simumba%2C+N">Naomi Simumba</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+L">Linsong Chu</a>, 
<a href="/search/cs?searchtype=author&query=Mukkavilli%2C+S+K">S. Karthik Mukkavilli</a>, 
<a href="/search/cs?searchtype=author&query=Lambhate%2C+D">Devyani Lambhate</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+K">Kamal Das</a>, 
<a href="/search/cs?searchtype=author&query=Bangalore%2C+R">Ranjini Bangalore</a>, 
<a href="/search/cs?searchtype=author&query=Oliveira%2C+D">Dario Oliveira</a>, 
<a href="/search/cs?searchtype=author&query=Muszynski%2C+M">Michal Muszynski</a>, 
<a href="/search/cs?searchtype=author&query=Ankur%2C+K">Kumar Ankur</a>, 
<a href="/search/cs?searchtype=author&query=Ramasubramanian%2C+M">Muthukumaran Ramasubramanian</a>, 
<a href="/search/cs?searchtype=author&query=Gurung%2C+I">Iksha Gurung</a>, 
<a href="/search/cs?searchtype=author&query=Khallaghi%2C+S">Sam Khallaghi</a>, 
<a href="/search/cs?searchtype=author&query=Hanxi">Hanxi</a> (Steve)Li, 
<a href="/search/cs?searchtype=author&query=Cecil%2C+M">Michael Cecil</a>, 
<a href="/search/cs?searchtype=author&query=Ahmadi%2C+M">Maryam Ahmadi</a>, 
<a href="/search/cs?searchtype=author&query=Kordi%2C+F">Fatemeh Kordi</a>, 
<a href="/search/cs?searchtype=author&query=Alemohammad%2C+H">Hamed Alemohammad</a>, 
<a href="/search/cs?searchtype=author&query=Maskey%2C+M">Manil Maskey</a>, 
<a href="/search/cs?searchtype=author&query=Ganti%2C+R">Raghu Ganti</a>, 
<a href="/search/cs?searchtype=author&query=Weldemariam%2C+K">Kommy Weldemariam</a>, 
<a href="/search/cs?searchtype=author&query=Ramachandran%2C+R">Rahul Ramachandran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18679" title="Abstract">arXiv:2310.18679</a> (replaced) [<a href="/pdf/2310.18679" title="Download PDF">pdf</a>, <a href="/ps/2310.18679" title="Download PostScript">ps</a>, <a href="/format/2310.18679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> N-Critics: Self-Refinement of Large Language Models with Ensemble of  Critics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mousavi%2C+S">Sajad Mousavi</a>, 
<a href="/search/cs?searchtype=author&query=Guti%C3%A9rrez%2C+R+L">Ricardo Luna Guti&#xe9;rrez</a>, 
<a href="/search/cs?searchtype=author&query=Rengarajan%2C+D">Desik Rengarajan</a>, 
<a href="/search/cs?searchtype=author&query=Gundecha%2C+V">Vineet Gundecha</a>, 
<a href="/search/cs?searchtype=author&query=Babu%2C+A+R">Ashwin Ramesh Babu</a>, 
<a href="/search/cs?searchtype=author&query=Naug%2C+A">Avisek Naug</a>, 
<a href="/search/cs?searchtype=author&query=Guillen%2C+A">Antonio Guillen</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+S">Soumyendu Sarkar</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS 2023 Workshop on Robustness of Few-shot and Zero-shot
  Learning in Foundation Models 2023(NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18840" title="Abstract">arXiv:2310.18840</a> (replaced) [<a href="/pdf/2310.18840" title="Download PDF">pdf</a>, <a href="/format/2310.18840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Customizing 360-Degree Panoramas through Text-to-Image Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+X">Xiaoyu Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yuchen Fan</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+J">Jing-Hao Xue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WACV 2024, Project Page: <a href="https://littlewhitesea.github.io/stitchdiffusion.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19233" title="Abstract">arXiv:2310.19233</a> (replaced) [<a href="/pdf/2310.19233" title="Download PDF">pdf</a>, <a href="/format/2310.19233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building Real-World Meeting Summarization Systems using Large Language  Models: A Practical Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Laskar%2C+M+T+R">Md Tahmid Rahman Laskar</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xue-Yong Fu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Cheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=TN%2C+S+B">Shashi Bhushan TN</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 Industry Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19673" title="Abstract">arXiv:2310.19673</a> (replaced) [<a href="/pdf/2310.19673" title="Download PDF">pdf</a>, <a href="/format/2310.19673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design and Analysis of a Novel Radial Deployment Mechanism of Payloads  in Sounding Rockets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Singh%2C+T+P+G">Thakur Pranav G. Singh</a>, 
<a href="/search/eess?searchtype=author&query=Anand%2C+U">Utkarsh Anand</a>, 
<a href="/search/eess?searchtype=author&query=Agrawal%2C+T">Tanvi Agrawal</a>, 
<a href="/search/eess?searchtype=author&query=G%2C+S">Srinivas G</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 Pages, 11 Figures, 1 Table, Submitted to Journal of Applied Mechanics and is in Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19802" title="Abstract">arXiv:2310.19802</a> (replaced) [<a href="/pdf/2310.19802" title="Download PDF">pdf</a>, <a href="/format/2310.19802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Thermodynamics of Learning Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parsi%2C+S+S">Shervin Sadat Parsi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20101" title="Abstract">arXiv:2310.20101</a> (replaced) [<a href="/pdf/2310.20101" title="Download PDF">pdf</a>, <a href="/format/2310.20101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Medical Image Denosing via Explainable AI Feature Preserving Loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dong%2C+G">Guanfang Dong</a>, 
<a href="/search/eess?searchtype=author&query=Basu%2C+A">Anup Basu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20654" title="Abstract">arXiv:2310.20654</a> (replaced) [<a href="/pdf/2310.20654" title="Download PDF">pdf</a>, <a href="/format/2310.20654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretability, Generalizability, and Memory of Reinforcement Learning  Agents in Closed Drafting Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rezai%2C+R">Ryan Rezai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jason Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 5 figures, equal contribution
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00081" title="Abstract">arXiv:2311.00081</a> (replaced) [<a href="/pdf/2311.00081" title="Download PDF">pdf</a>, <a href="/format/2311.00081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convolution Quadrature for the quasilinear subdiffusion equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=L%C3%B3pez-Fern%C3%A1ndez%2C+M">Maria L&#xf3;pez-Fern&#xe1;ndez</a>, 
<a href="/search/math?searchtype=author&query=P%C5%82ociniczak%2C+%C5%81">&#x141;ukasz P&#x142;ociniczak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00232" title="Abstract">arXiv:2311.00232</a> (replaced) [<a href="/pdf/2311.00232" title="Download PDF">pdf</a>, <a href="/format/2311.00232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mechanically-Inflatable Bio-Inspired Locomotion for Robotic Pipeline  Inspection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Atalla%2C+M+A">Mostafa A. Atalla</a>, 
<a href="/search/cs?searchtype=author&query=Trauzettel%2C+F">Fabian Trauzettel</a>, 
<a href="/search/cs?searchtype=author&query=van+Gelder%2C+S+P">Sebastiaan P. van Gelder</a>, 
<a href="/search/cs?searchtype=author&query=Breedveld%2C+P">Paul Breedveld</a>, 
<a href="/search/cs?searchtype=author&query=Wiertlewski%2C+M">Micha&#xeb;l Wiertlewski</a>, 
<a href="/search/cs?searchtype=author&query=Sakes%2C+A">Aim&#xe9;e Sakes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00322" title="Abstract">arXiv:2311.00322</a> (replaced) [<a href="/pdf/2311.00322" title="Download PDF">pdf</a>, <a href="/format/2311.00322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Graph Clustering via Meta Weighting for Noisy Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jo%2C+H">Hyeonsoo Jo</a>, 
<a href="/search/cs?searchtype=author&query=Bu%2C+F">Fanchen Bu</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+K">Kijung Shin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CIKM '23: Proceedings of the 32nd ACM International Conference on Information and Knowledge Management
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00332" title="Abstract">arXiv:2311.00332</a> (replaced) [<a href="/pdf/2311.00332" title="Download PDF">pdf</a>, <a href="/format/2311.00332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SDF4CHD: Generative Modeling of Cardiac Anatomies with Congenital Heart  Defects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Kong%2C+F">Fanwei Kong</a>, 
<a href="/search/q-bio?searchtype=author&query=Stocker%2C+S">Sascha Stocker</a>, 
<a href="/search/q-bio?searchtype=author&query=Choi%2C+P+S">Perry S. Choi</a>, 
<a href="/search/q-bio?searchtype=author&query=Ma%2C+M">Michael Ma</a>, 
<a href="/search/q-bio?searchtype=author&query=Ennis%2C+D+B">Daniel B. Ennis</a>, 
<a href="/search/q-bio?searchtype=author&query=Marsden%2C+A">Alison Marsden</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Tissues and Organs (q-bio.TO)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00466" title="Abstract">arXiv:2311.00466</a> (replaced) [<a href="/pdf/2311.00466" title="Download PDF">pdf</a>, <a href="/format/2311.00466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameterized covering in semi-ladder-free hypergraphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guillemot%2C+S">Sylvain Guillemot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00660" title="Abstract">arXiv:2311.00660</a> (replaced) [<a href="/pdf/2311.00660" title="Download PDF">pdf</a>, <a href="/format/2311.00660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TPSeNCE: Towards Artifact-Free Realistic Rain Generation for Deraining  and Object Detection in Rain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Changjie Lu</a>, 
<a href="/search/cs?searchtype=author&query=Narasimhan%2C+S+G">Srinivasa G. Narasimhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00844" title="Abstract">arXiv:2311.00844</a> (replaced) [<a href="/pdf/2311.00844" title="Download PDF">pdf</a>, <a href="/format/2311.00844" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Electronic excited states from physically-constrained machine learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Cignoni%2C+E">Edoardo Cignoni</a>, 
<a href="/search/physics?searchtype=author&query=Suman%2C+D">Divya Suman</a>, 
<a href="/search/physics?searchtype=author&query=Nigam%2C+J">Jigyasa Nigam</a>, 
<a href="/search/physics?searchtype=author&query=Cupellini%2C+L">Lorenzo Cupellini</a>, 
<a href="/search/physics?searchtype=author&query=Mennucci%2C+B">Benedetta Mennucci</a>, 
<a href="/search/physics?searchtype=author&query=Ceriotti%2C+M">Michele Ceriotti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01007" title="Abstract">arXiv:2311.01007</a> (replaced) [<a href="/pdf/2311.01007" title="Download PDF">pdf</a>, <a href="/format/2311.01007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effective Human-AI Teams via Learned Natural Language Rules and  Onboarding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mozannar%2C+H">Hussein Mozannar</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+J">Jimin J Lee</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+D">Dennis Wei</a>, 
<a href="/search/cs?searchtype=author&query=Sattigeri%2C+P">Prasanna Sattigeri</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Subhro Das</a>, 
<a href="/search/cs?searchtype=author&query=Sontag%2C+D">David Sontag</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Spotlight
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01343" title="Abstract">arXiv:2311.01343</a> (replaced) [<a href="/pdf/2311.01343" title="Download PDF">pdf</a>, <a href="/format/2311.01343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative Large Language Model for Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yaochen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Liang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+L">Liangjie Hong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jundong Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01467" title="Abstract">arXiv:2311.01467</a> (replaced) [<a href="/pdf/2311.01467" title="Download PDF">pdf</a>, <a href="/ps/2311.01467" title="Download PostScript">ps</a>, <a href="/format/2311.01467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The numerical linear algebra of weights: from the spectral analysis to  conditioning and preconditioning in the Laplacian case
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bruno%2C+L+B">Ludovico Bruni Bruno</a>, 
<a href="/search/math?searchtype=author&query=Semplice%2C+M">Matteo Semplice</a>, 
<a href="/search/math?searchtype=author&query=Serra-Capizzano%2C+S">Stefano Serra-Capizzano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 10 figures, 6 tables. arXiv admin note: text overlap with <a href="/abs/2206.05171">arXiv:2206.05171</a> by other authors [v2]: improved readability, small correction on bibliography format
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01813" title="Abstract">arXiv:2311.01813</a> (replaced) [<a href="/pdf/2311.01813" title="Download PDF">pdf</a>, <a href="/format/2311.01813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FETV: A Benchmark for Fine-Grained Evaluation of Open-Domain  Text-to-Video Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanxin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Shuhuai Ren</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+R">Rundong Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shicheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sishuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+L">Lu Hou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Datasets and Benchmarks Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02205" title="Abstract">arXiv:2311.02205</a> (replaced) [<a href="/pdf/2311.02205" title="Download PDF">pdf</a>, <a href="/format/2311.02205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Introduction to Natural Language Processing Techniques and Framework  for Clinical Implementation in Radiation Oncology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khanmohammadi%2C+R">Reza Khanmohammadi</a>, 
<a href="/search/cs?searchtype=author&query=Ghassemi%2C+M+M">Mohammad M. Ghassemi</a>, 
<a href="/search/cs?searchtype=author&query=Verdecchia%2C+K">Kyle Verdecchia</a>, 
<a href="/search/cs?searchtype=author&query=Ghanem%2C+A+I">Ahmed I. Ghanem</a>, 
<a href="/search/cs?searchtype=author&query=Bing%2C+L">Luo Bing</a>, 
<a href="/search/cs?searchtype=author&query=Chetty%2C+I+J">Indrin J. Chetty</a>, 
<a href="/search/cs?searchtype=author&query=Bagher-Ebadian%2C+H">Hassan Bagher-Ebadian</a>, 
<a href="/search/cs?searchtype=author&query=Siddiqui%2C+F">Farzan Siddiqui</a>, 
<a href="/search/cs?searchtype=author&query=Elshaikh%2C+M">Mohamed Elshaikh</a>, 
<a href="/search/cs?searchtype=author&query=Movsas%2C+B">Benjamin Movsas</a>, 
<a href="/search/cs?searchtype=author&query=Thind%2C+K">Kundan Thind</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02265" title="Abstract">arXiv:2311.02265</a> (replaced) [<a href="/pdf/2311.02265" title="Download PDF">pdf</a>, <a href="/format/2311.02265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Not all layers are equally as important: Every Layer Counts BERT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Charpentier%2C+L+G+G">Lucas Georges Gabriel Charpentier</a>, 
<a href="/search/cs?searchtype=author&query=Samuel%2C+D">David Samuel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02382" title="Abstract">arXiv:2311.02382</a> (replaced) [<a href="/pdf/2311.02382" title="Download PDF">pdf</a>, <a href="/format/2311.02382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ultra-Long Sequence Distributed Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lyngaas%2C+I">Isaac Lyngaas</a>, 
<a href="/search/cs?searchtype=author&query=Tsaris%2C+A">Aristeidis Tsaris</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dash%2C+S">Sajal Dash</a>, 
<a href="/search/cs?searchtype=author&query=Shekar%2C+M+C">Mayanka Chandra Shekar</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+T">Tao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+H">Hong-Jun Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Wahib%2C+M">Mohamed Wahib</a>, 
<a href="/search/cs?searchtype=author&query=Gouley%2C+J">John Gouley</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02766" title="Abstract">arXiv:2311.02766</a> (replaced) [<a href="/pdf/2311.02766" title="Download PDF">pdf</a>, <a href="/format/2311.02766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Riemannian Laplace Approximation with the Fisher Metric
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hanlin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Hartmann%2C+M">Marcelo Hartmann</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+B">Bernardo Williams</a>, 
<a href="/search/cs?searchtype=author&query=Girolami%2C+M">Mark Girolami</a>, 
<a href="/search/cs?searchtype=author&query=Klami%2C+A">Arto Klami</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02847" title="Abstract">arXiv:2311.02847</a> (replaced) [<a href="/pdf/2311.02847" title="Download PDF">pdf</a>, <a href="/format/2311.02847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kinematic-aware Prompting for Generalizable Articulated Object  Manipulation with LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+W">Wenke Xia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+X">Xincheng Pang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhigang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+D">Di Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02898" title="Abstract">arXiv:2311.02898</a> (replaced) [<a href="/pdf/2311.02898" title="Download PDF">pdf</a>, <a href="/format/2311.02898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transduce and Speak: Neural Transducer for Text-to-Speech with Semantic  Token Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kim%2C+M">Minchan Kim</a>, 
<a href="/search/eess?searchtype=author&query=Jeong%2C+M">Myeonghun Jeong</a>, 
<a href="/search/eess?searchtype=author&query=Choi%2C+B+J">Byoung Jin Choi</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+D">Dongjune Lee</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+N+S">Nam Soo Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ASRU2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02926" title="Abstract">arXiv:2311.02926</a> (replaced) [<a href="/pdf/2311.02926" title="Download PDF">pdf</a>, <a href="/format/2311.02926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Image Semantic Communication Model for Artificial Intelligent  Internet of Things
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+L+P">Li Ping Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+S">Sikai Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Huijie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X+S">Xuemin Sherman Shen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaoniu Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02985" title="Abstract">arXiv:2311.02985</a> (replaced) [<a href="/pdf/2311.02985" title="Download PDF">pdf</a>, <a href="/ps/2311.02985" title="Download PostScript">ps</a>, <a href="/format/2311.02985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Transformer-Based Reverse Dictionary Model for Quality  Estimation of Definitions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guit%C3%A9-Vinet%2C+J">Julien Guit&#xe9;-Vinet</a>, 
<a href="/search/cs?searchtype=author&query=Mass%C3%A9%2C+A+B">Alexandre Blondin Mass&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Sadat%2C+F">Fatiha Sadat</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03084" title="Abstract">arXiv:2311.03084</a> (replaced) [<a href="/pdf/2311.03084" title="Download PDF">pdf</a>, <a href="/format/2311.03084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple yet Efficient Ensemble Approach for AI-generated Text Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abburi%2C+H">Harika Abburi</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+K">Kalyani Roy</a>, 
<a href="/search/cs?searchtype=author&query=Suesserman%2C+M">Michael Suesserman</a>, 
<a href="/search/cs?searchtype=author&query=Pudota%2C+N">Nirmala Pudota</a>, 
<a href="/search/cs?searchtype=author&query=Veeramani%2C+B">Balaji Veeramani</a>, 
<a href="/search/cs?searchtype=author&query=Bowen%2C+E">Edward Bowen</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+S">Sanmitra Bhattacharya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03150" title="Abstract">arXiv:2311.03150</a> (replaced) [<a href="/pdf/2311.03150" title="Download PDF">pdf</a>, <a href="/format/2311.03150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Brain-inspired Theory of Collective Mind Model for Efficient Social  Cooperation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhuoya Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+F">Feifei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiwen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yinqian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yi Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03340" title="Abstract">arXiv:2311.03340</a> (replaced) [<a href="/pdf/2311.03340" title="Download PDF">pdf</a>, <a href="/format/2311.03340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multitask Kernel-based Learning with First-Order Logic Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Diligenti%2C+M">Michelangelo Diligenti</a>, 
<a href="/search/cs?searchtype=author&query=Gori%2C+M">Marco Gori</a>, 
<a href="/search/cs?searchtype=author&query=Maggini%2C+M">Marco Maggini</a>, 
<a href="/search/cs?searchtype=author&query=Rigutini%2C+L">Leonardo Rigutini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 20th International Conference on Inductive Logic Programming (ILP 2010). Florence, Italy. June 27-30 2010
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of The 20th International Conference on Inductive
  Logic Programming (ILP 2010)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03429" title="Abstract">arXiv:2311.03429</a> (replaced) [<a href="/pdf/2311.03429" title="Download PDF">pdf</a>, <a href="/format/2311.03429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProPath: Disease-Specific Protein Language Model for Variant  Pathogenicity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Zhan%2C+H">Huixin Zhan</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+Z">Zijun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by MLCB 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03712" title="Abstract">arXiv:2311.03712</a> (replaced) [<a href="/pdf/2311.03712" title="Download PDF">pdf</a>, <a href="/format/2311.03712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contributions of Individual Generators to Nodal Carbon Emissions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yize Chen</a>, 
<a href="/search/eess?searchtype=author&query=Deka%2C+D">Deepjyoti Deka</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+Y">Yuanyuan Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ACM e-Energy 2024. Code available at <a href="https://github.com/chennnnnyize/Carbon_Emission_Power_Grids">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03725" title="Abstract">arXiv:2311.03725</a> (replaced) [<a href="/pdf/2311.03725" title="Download PDF">pdf</a>, <a href="/ps/2311.03725" title="Download PostScript">ps</a>, <a href="/format/2311.03725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepInspect: An AI-Powered Defect Detection for Manufacturing Industries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumbhar%2C+A">Arti Kumbhar</a>, 
<a href="/search/cs?searchtype=author&query=Chougule%2C+A">Amruta Chougule</a>, 
<a href="/search/cs?searchtype=author&query=Lokhande%2C+P">Priya Lokhande</a>, 
<a href="/search/cs?searchtype=author&query=Navaghane%2C+S">Saloni Navaghane</a>, 
<a href="/search/cs?searchtype=author&query=Burud%2C+A">Aditi Burud</a>, 
<a href="/search/cs?searchtype=author&query=Nimbalkar%2C+S">Saee Nimbalkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Research Paper for Defect Detection for Manufacturing Industries Using Deep Learning Techniques: 5 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03784" title="Abstract">arXiv:2311.03784</a> (replaced) [<a href="/pdf/2311.03784" title="Download PDF">pdf</a>, <a href="/format/2311.03784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UP-NeRF: Unconstrained Pose-Prior-Free Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+I">Injae Kim</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+M">Minhyuk Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H+J">Hyunwoo J. Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Neural Information Processing Systems (NeurIPS), 2023. The code is available at <a href="https://github.com/mlvlab/UP-NeRF">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03932" title="Abstract">arXiv:2311.03932</a> (replaced) [<a href="/pdf/2311.03932" title="Download PDF">pdf</a>, <a href="/format/2311.03932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TempoGRAPHer: Aggregation Based Temporal Graph Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsoukanara%2C+E">Evangelia Tsoukanara</a>, 
<a href="/search/cs?searchtype=author&query=Koloniari%2C+G">Georgia Koloniari</a>, 
<a href="/search/cs?searchtype=author&query=Pitoura%2C+E">Evaggelia Pitoura</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03959" title="Abstract">arXiv:2311.03959</a> (replaced) [<a href="/pdf/2311.03959" title="Download PDF">pdf</a>, <a href="/format/2311.03959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving the Effectiveness of Deep Generative Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Schmedding%2C+S">Sabrina Schmedding</a>, 
<a href="/search/cs?searchtype=author&query=Huber%2C+M+F">Marco F. Huber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WACV2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03989" title="Abstract">arXiv:2311.03989</a> (replaced) [<a href="/pdf/2311.03989" title="Download PDF">pdf</a>, <a href="/format/2311.03989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learned Causal Method Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Shantanu Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hilmkil%2C+A">Agrin Hilmkil</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04155" title="Abstract">arXiv:2311.04155</a> (replaced) [<a href="/pdf/2311.04155" title="Download PDF">pdf</a>, <a href="/format/2311.04155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Black-Box Prompt Optimization: Aligning Large Language Models without  Model Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jiale Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+K">Kehan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+P">Pei Ke</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongning Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yuxiao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jie Tang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Minlie Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04212" title="Abstract">arXiv:2311.04212</a> (replaced) [<a href="/pdf/2311.04212" title="Download PDF">pdf</a>, <a href="/format/2311.04212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video Instance Matting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiachen Li</a>, 
<a href="/search/cs?searchtype=author&query=Henschel%2C+R">Roberto Henschel</a>, 
<a href="/search/cs?searchtype=author&query=Goel%2C+V">Vidit Goel</a>, 
<a href="/search/cs?searchtype=author&query=Ohanyan%2C+M">Marianna Ohanyan</a>, 
<a href="/search/cs?searchtype=author&query=Navasardyan%2C+S">Shant Navasardyan</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Humphrey Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item268">Cross-lists</a></li>
<li><a href="#item315">Replacements</a></li>
</ul>
<small>[ total of 519 entries:  <b>1-519</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2311">2311</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
