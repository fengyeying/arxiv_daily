<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Thu  2 Nov 23  to  Fri  3 Nov 23, announced Mon,  6 Nov 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item228">Cross-lists</a></li>
<li><a href="#item274">Replacements</a></li>
</ul>
<small>[ total of 456 entries:  <b>1-456</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Mon,  6 Nov 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01463" title="Abstract">arXiv:2311.01463</a> [<a href="/pdf/2311.01463" title="Download PDF">pdf</a>, <a href="/format/2311.01463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+M+A">Muhammad Aurangzeb Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Yaramis%2C+I">Ilker Yaramis</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+T+D">Taposh Dutta Roy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Large language models have proliferated across multiple domains in as short
period of time. There is however hesitation in the medical and healthcare
domain towards their adoption because of issues like factuality, coherence, and
hallucinations. Give the high stakes nature of healthcare, many researchers
have even cautioned against its usage until these issues are resolved. The key
to the implementation and deployment of LLMs in healthcare is to make these
models trustworthy, transparent (as much possible) and explainable. In this
paper we describe the key elements in creating reliable, trustworthy, and
unbiased models as a necessary condition for their adoption in healthcare.
Specifically we focus on the quantification, validation, and mitigation of
hallucinations in the context in healthcare. Lastly, we discuss how the future
of LLMs in healthcare may look like.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01467" title="Abstract">arXiv:2311.01467</a> [<a href="/pdf/2311.01467" title="Download PDF">pdf</a>, <a href="/ps/2311.01467" title="Download PostScript">ps</a>, <a href="/format/2311.01467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The numerical linear algebra of weights: from the spectral analysis to  conditioning and preconditioning in the Laplacian case
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bruno%2C+L+B">Ludovico Bruni Bruno</a>, 
<a href="/search/math?searchtype=author&query=Semplice%2C+M">Matteo Semplice</a>, 
<a href="/search/math?searchtype=author&query=Serra-Capizzano%2C+S">Stefano Serra-Capizzano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 10 figures, 6 tables. arXiv admin note: text overlap with <a href="/abs/2206.05171">arXiv:2206.05171</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Weights are geometrical degrees of freedom that allow to generalise
Lagrangian finite elements. They are defined through integrals over specific
supports, well understood in terms of differential forms and integration, and
lie within the framework of finite element exterior calculus. In this work we
exploit this formalism with the target of identifying supports that are
appealing for finite element approximation. To do so, we study the related
parametric matrix-sequences, with the matrix order tending to infinity as the
mesh size tends to zero. We describe the conditioning and the spectral global
behavior in terms of the standard Toeplitz machinery and GLT theory, leading to
the identification of the optimal choices for weights. Moreover, we propose and
test ad hoc preconditioners, in dependence of the discretization parameters and
in connection with conjugate gradient method. The model problem we consider is
a onedimensional Laplacian, both with constant and non constant coefficients.
Numerical visualizations and experimental tests are reported and critically
discussed, demonstrating the advantages of weights-induced bases over standard
Lagrangian ones. Open problems and future steps are listed in the conclusive
section, especially regarding the multidimensional case.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01468" title="Abstract">arXiv:2311.01468</a> [<a href="/pdf/2311.01468" title="Download PDF">pdf</a>, <a href="/format/2311.01468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Remember what you did so you know what to do next
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ciosici%2C+M+R">Manuel R. Ciosici</a>, 
<a href="/search/cs?searchtype=author&query=Hedges%2C+A">Alex Hedges</a>, 
<a href="/search/cs?searchtype=author&query=Kankanampati%2C+Y">Yash Kankanampati</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+J">Justin Martin</a>, 
<a href="/search/cs?searchtype=author&query=Freedman%2C+M">Marjorie Freedman</a>, 
<a href="/search/cs?searchtype=author&query=Weischedel%2C+R">Ralph Weischedel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Identical to EMNLP 2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We explore using a moderately sized large language model (GPT-J 6B
parameters) to create a plan for a simulated robot to achieve 30 classes of
goals in ScienceWorld, a text game simulator for elementary science
experiments. Previously published empirical work claimed that large language
models (LLMs) are a poor fit (Wang et al., 2022) compared to reinforcement
learning. Using the Markov assumption (a single previous step), the LLM
outperforms the reinforcement learning-based approach by a factor of 1.4. When
we fill the LLM's input buffer with as many prior steps as possible,
improvement rises to 3.5x. Even when training on only 6.5% of the training
data, we observe a 2.2x improvement over the reinforcement-learning-based
approach. Our experiments show that performance varies widely across the 30
classes of actions, indicating that averaging over tasks can hide significant
performance issues. In work contemporaneous with ours, Lin et al. (2023)
demonstrated a two-part approach (SwiftSage) that uses a small LLM (T5-large)
complemented by OpenAI's massive LLMs to achieve outstanding results in
ScienceWorld. Our 6-B parameter, single-stage GPT-J matches the performance of
SwiftSage's two-stage architecture when it incorporates GPT-3.5 turbo which has
29-times more parameters than GPT-J.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01469" title="Abstract">arXiv:2311.01469</a> [<a href="/pdf/2311.01469" title="Download PDF">pdf</a>, <a href="/format/2311.01469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Language Models to Detect Greenwashing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vinella%2C+A">Avalon Vinella</a>, 
<a href="/search/cs?searchtype=author&query=Capetz%2C+M">Margaret Capetz</a>, 
<a href="/search/cs?searchtype=author&query=Pattichis%2C+R">Rebecca Pattichis</a>, 
<a href="/search/cs?searchtype=author&query=Chance%2C+C">Christina Chance</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+R">Reshmi Ghosh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In recent years, climate change repercussions have increasingly captured
public interest. Consequently, corporations are emphasizing their environmental
efforts in sustainability reports to bolster their public image. Yet, the
absence of stringent regulations in review of such reports allows potential
greenwashing. In this study, we introduce a novel methodology to train a
language model on generated labels for greenwashing risk. Our primary
contributions encompass: developing a mathematical formulation to quantify
greenwashing risk, a fine-tuned ClimateBERT model for this problem, and a
comparative analysis of results. On a test set comprising of sustainability
reports, our best model achieved an average accuracy score of 86.34% and F1
score of 0.67, demonstrating that our methods show a promising direction of
exploration for this task.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01472" title="Abstract">arXiv:2311.01472</a> [<a href="/pdf/2311.01472" title="Download PDF">pdf</a>, <a href="/format/2311.01472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relation Extraction from News Articles (RENA): A Tool for Epidemic  Surveillance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+J">Jaeff Hong</a>, 
<a href="/search/cs?searchtype=author&query=Dung%2C+D">Duong Dung</a>, 
<a href="/search/cs?searchtype=author&query=Hutchinson%2C+D">Danielle Hutchinson</a>, 
<a href="/search/cs?searchtype=author&query=Akhtar%2C+Z">Zubair Akhtar</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Rosalie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dawson%2C+R">Rebecca Dawson</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+A">Aditya Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+S">Samsung Lim</a>, 
<a href="/search/cs?searchtype=author&query=MacIntyre%2C+C+R">C Raina MacIntyre</a>, 
<a href="/search/cs?searchtype=author&query=Gurdasani%2C+D">Deepti Gurdasani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review in AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Relation Extraction from News Articles (RENA) is a browser-based tool
designed to extract key entities and their semantic relationships in English
language news articles related to infectious diseases. Constructed using the
React framework, this system presents users with an elegant and user-friendly
interface. It enables users to input a news article and select from a choice of
two models to generate a comprehensive list of relations within the provided
text. As a result, RENA allows real-time parsing of news articles to extract
key information for epidemic surveillance, contributing to EPIWATCH, an
open-source intelligence-based epidemic warning system.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01473" title="Abstract">arXiv:2311.01473</a> [<a href="/pdf/2311.01473" title="Download PDF">pdf</a>, <a href="/format/2311.01473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Examples in the Physical World: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiakai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Donghua Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Siyang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+T">Tingsong Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+W">Wen Yao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Aishan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xianglong Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Adversarial examples, physical-world scenarios, attacks and defenses
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep neural networks (DNNs) have demonstrated high vulnerability to
adversarial examples. Besides the attacks in the digital world, the practical
implications of adversarial examples in the physical world present significant
challenges and safety concerns. However, current research on physical
adversarial examples (PAEs) lacks a comprehensive understanding of their unique
characteristics, leading to limited significance and understanding. In this
paper, we address this gap by thoroughly examining the characteristics of PAEs
within a practical workflow encompassing training, manufacturing, and
re-sampling processes. By analyzing the links between physical adversarial
attacks, we identify manufacturing and re-sampling as the primary sources of
distinct attributes and particularities in PAEs. Leveraging this knowledge, we
develop a comprehensive analysis and classification framework for PAEs based on
their specific characteristics, covering over 100 studies on physical-world
adversarial examples. Furthermore, we investigate defense strategies against
PAEs and identify open challenges and opportunities for future research. We aim
to provide a fresh, thorough, and systematic understanding of PAEs, thereby
promoting the development of robust adversarial learning and its application in
open-world scenarios.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01474" title="Abstract">arXiv:2311.01474</a> [<a href="/pdf/2311.01474" title="Download PDF">pdf</a>, <a href="/ps/2311.01474" title="Download PostScript">ps</a>, <a href="/format/2311.01474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new proof of Euclid&#x27;s algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salwicki%2C+A">Andrzej Salwicki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Data Structures and Algorithms (cs.DS); Logic (math.LO)

</div>
<p class="mathjax">Our main result is a new proof of correctness of Euclid's algorithm. The
proof is conducted in algorithmic theory of natural numbers Th3. A formula H is
constructed that expresses the halting property of the algorithm. Next, the
proof of H is is presented. In the proof we make use of inference rules of
calculus of programs. The only formulas accepted without the proof are axioms
of program calculus or axioms of the theory Th3. We complete our result by
showing that the theorem on correctness of Euclid's algorithm can not be proved
in any elementary theory of natural numbers.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01475" title="Abstract">arXiv:2311.01475</a> [<a href="/pdf/2311.01475" title="Download PDF">pdf</a>, <a href="/format/2311.01475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Patch-Based Deep Unsupervised Image Segmentation using Graph Cuts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wasserman%2C+I">Isaac Wasserman</a>, 
<a href="/search/cs?searchtype=author&query=Neto%2C+J+F+S+R">Jeova Farias Sales Rocha Neto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Unsupervised image segmentation aims at grouping different semantic patterns
in an image without the use of human annotation. Similarly, image clustering
searches for groupings of images based on their semantic content without
supervision. Classically, both problems have captivated researchers as they
drew from sound mathematical concepts to produce concrete applications. With
the emergence of deep learning, the scientific community turned its attention
to complex neural network-based solvers that achieved impressive results in
those domains but rarely leveraged the advances made by classical methods. In
this work, we propose a patch-based unsupervised image segmentation strategy
that bridges advances in unsupervised feature extraction from deep clustering
methods with the algorithmic help of classical graph-based methods. We show
that a simple convolutional neural network, trained to classify image patches
and iteratively regularized using graph cuts, naturally leads to a
state-of-the-art fully-convolutional unsupervised pixel-level segmenter.
Furthermore, we demonstrate that this is the ideal setting for leveraging the
patch-level pairwise features generated by vision transformer models. Our
results on real image data demonstrate the effectiveness of our proposed
methodology.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01477" title="Abstract">arXiv:2311.01477</a> [<a href="/pdf/2311.01477" title="Download PDF">pdf</a>, <a href="/format/2311.01477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FAITHSCORE: Evaluating Hallucinations in Large Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jing%2C+L">Liqiang Jing</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruosen Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yunmo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+M">Mengzhao Jia</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xinya Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce FAITHSCORE (Faithfulness to Atomic Image Facts Score), a
reference-free and fine-grained evaluation metric that measures the
faithfulness of the generated free-form answers from large vision-language
models (LVLMs). The FAITHSCORE evaluation first identifies sub-sentences
containing descriptive statements that need to be verified, then extracts a
comprehensive list of atomic facts from these sub-sentences, and finally
conducts consistency verification between fine-grained atomic facts and the
input image. Meta-evaluation demonstrates that our metric highly correlates
with human judgments of faithfulness. We collect two benchmark datasets (i.e.
LLaVA-1k and MSCOCO-Cap) for evaluating LVLMs instruction-following
hallucinations. We measure hallucinations in state-of-the-art LVLMs with
FAITHSCORE on the datasets. Results reveal that current systems are prone to
generate hallucinated content unfaithful to the image, which leaves room for
future improvements. Further, we find that current LVLMs despite doing well on
color and counting, still struggle with long answers, relations, and multiple
objects.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01478" title="Abstract">arXiv:2311.01478</a> [<a href="/pdf/2311.01478" title="Download PDF">pdf</a>, <a href="/format/2311.01478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversary ML Resilience in Autonomous Driving Through Human Centered  Perception Mechanisms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shah%2C+A">Aakriti Shah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Physical adversarial attacks on road signs are continuously exploiting
vulnerabilities in modern day autonomous vehicles (AVs) and impeding their
ability to correctly classify what type of road sign they encounter. Current
models cannot generalize input data well, resulting in overfitting or
underfitting. In overfitting, the model memorizes the input data but cannot
generalize to new scenarios. In underfitting, the model does not learn enough
of the input data to accurately classify these road signs. This paper explores
the resilience of autonomous driving systems against three main physical
adversarial attacks (tape, graffiti, illumination), specifically targeting
object classifiers. Several machine learning models were developed and
evaluated on two distinct datasets: road signs (stop signs, speed limit signs,
traffic lights, and pedestrian crosswalk signs) and geometric shapes (octagons,
circles, squares, and triangles). The study compared algorithm performance
under different conditions, including clean and adversarial training and
testing on these datasets. To build robustness against attacks, defense
techniques like adversarial training and transfer learning were implemented.
Results demonstrated transfer learning models played a crucial role in
performance by allowing knowledge gained from shape training to improve
generalizability of road sign classification, despite the datasets being
completely different. The paper suggests future research directions, including
human-in-the-loop validation, security analysis, real-world testing, and
explainable AI for transparency. This study aims to contribute to improving
security and robustness of object classifiers in autonomous vehicles and
mitigating adversarial example impacts on driving systems.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01479" title="Abstract">arXiv:2311.01479</a> [<a href="/pdf/2311.01479" title="Download PDF">pdf</a>, <a href="/format/2311.01479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Out-of-Distribution Through the Lens of Neural Collapse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Litian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yao Qin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Out-of-distribution (OOD) detection is essential for the safe deployment of
AI. Particularly, OOD detectors should generalize effectively across diverse
scenarios. To improve upon the generalizability of existing OOD detectors, we
introduce a highly versatile OOD detector, called Neural Collapse inspired OOD
detector (NC-OOD). We extend the prevalent observation that in-distribution
(ID) features tend to form clusters, whereas OOD features are far away.
Particularly, based on the recent observation, Neural Collapse, we further
demonstrate that ID features tend to cluster in proximity to weight vectors.
From our extended observation, we propose to detect OOD based on feature
proximity to weight vectors. To further rule out OOD samples, we leverage the
observation that OOD features tend to reside closer to the origin than ID
features. Extensive experiments show that our approach enhances the
generalizability of existing work and can consistently achieve state-of-the-art
OOD detection performance across a wide range of OOD Benchmarks over different
classification tasks, training losses, and model architectures.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01483" title="Abstract">arXiv:2311.01483</a> [<a href="/pdf/2311.01483" title="Download PDF">pdf</a>, <a href="/format/2311.01483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedSN: A General Federated Learning Framework over LEO Satellite  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zihan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xianhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yue Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Recently, a large number of Low Earth Orbit (LEO) satellites have been
launched and deployed successfully in space by commercial companies, such as
SpaceX. Due to multimodal sensors equipped by the LEO satellites, they serve
not only for communication but also for various machine learning applications,
such as space modulation recognition, remote sensing image classification, etc.
However, the ground station (GS) may be incapable of downloading such a large
volume of raw sensing data for centralized model training due to the limited
contact time with LEO satellites (e.g. 5 minutes). Therefore, federated
learning (FL) has emerged as the promising solution to address this problem via
on-device training. Unfortunately, to enable FL on LEO satellites, we still
face three critical challenges that are i) heterogeneous computing and memory
capabilities, ii) limited uplink rate, and iii) model staleness. To this end,
we propose FedSN as a general FL framework to tackle the above challenges, and
fully explore data diversity on LEO satellites. Specifically, we first present
a novel sub-structure scheme to enable heterogeneous local model training
considering different computing, memory, and communication constraints on LEO
satellites. Additionally, we propose a pseudo-synchronous model aggregation
strategy to dynamically schedule model aggregation for compensating model
staleness. To further demonstrate the effectiveness of the FedSN, we evaluate
it using space modulation recognition and remote sensing image classification
tasks by leveraging the data from real-world satellite networks. Extensive
experimental results demonstrate that FedSN framework achieves higher accuracy,
lower computing, and communication overhead than the state-of-the-art
benchmarks and the effectiveness of each components in FedSN.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01487" title="Abstract">arXiv:2311.01487</a> [<a href="/pdf/2311.01487" title="Download PDF">pdf</a>, <a href="/format/2311.01487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Makes for Good Visual Instructions? Synthesizing Complex Visual  Reasoning Instructions for Visual Instruction Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yifan Du</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hangyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W+X">Wayne Xin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chuyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+M">Mingchen Cai</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+R">Ruihua Song</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Ji-Rong Wen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Visual instruction tuning is an essential approach to improving the zero-shot
generalization capability of Multi-modal Large Language Models (MLLMs). A surge
of visual instruction datasets with various focuses and characteristics have
been proposed recently, enabling MLLMs to achieve surprising results on
evaluation benchmarks. To develop more capable MLLMs, in this paper, we aim to
investigate a more fundamental question: ``what makes for good visual
instructions?''. By conducting a comprehensive empirical study, we find that
instructions focused on complex visual reasoning tasks are particularly
effective in improving the performance of MLLMs on evaluation benchmarks.
Building upon this finding, we design a systematic approach to automatically
creating high-quality complex visual reasoning instructions. Our approach
employs a synthesis-complication-reformulation paradigm, leveraging multiple
stages to gradually increase the complexity of the instructions while
guaranteeing quality. Based on this approach, we create the synthetic visual
reasoning instruction dataset consisting of 32K examples, namely ComVint, and
fine-tune four MLLMs on it. Experimental results demonstrate that our dataset
consistently enhances the performance of all the compared MLLMs, e.g.,
improving the performance of MiniGPT-4 and BLIP-2 on MME-Cognition by 32.6% and
28.8%, respectively. Our code and data are publicly available at the link:
https://github.com/RUCAIBox/ComVint.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01490" title="Abstract">arXiv:2311.01490</a> [<a href="/pdf/2311.01490" title="Download PDF">pdf</a>, <a href="/ps/2311.01490" title="Download PostScript">ps</a>, <a href="/format/2311.01490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Behavior of Large Language Models When Prompted to Generate Code  Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oli%2C+P">Priti Oli</a>, 
<a href="/search/cs?searchtype=author&query=Banjade%2C+R">Rabin Banjade</a>, 
<a href="/search/cs?searchtype=author&query=Chapagain%2C+J">Jeevan Chapagain</a>, 
<a href="/search/cs?searchtype=author&query=Rus%2C+V">Vasile Rus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper systematically explores how Large Language Models (LLMs) generate
explanations of code examples of the type used in intro-to-programming courses.
As we show, the nature of code explanations generated by LLMs varies
considerably based on the wording of the prompt, the target code examples being
explained, the programming language, the temperature parameter, and the version
of the LLM. Nevertheless, they are consistent in two major respects for Java
and Python: the readability level, which hovers around 7-8 grade, and lexical
density, i.e., the relative size of the meaningful words with respect to the
total explanation size. Furthermore, the explanations score very high in
correctness but less on three other metrics: completeness, conciseness, and
contextualization.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01511" title="Abstract">arXiv:2311.01511</a> [<a href="/pdf/2311.01511" title="Download PDF">pdf</a>, <a href="/ps/2311.01511" title="Download PostScript">ps</a>, <a href="/format/2311.01511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dispersion, Capacitated Nodes, and the Power of a Trusted Shepherd
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moses%2C+W+K">William K. Moses Jr.</a>, 
<a href="/search/cs?searchtype=author&query=Redlich%2C+A">Amanda Redlich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">In this paper, we look at and expand the problems of dispersion and Byzantine
dispersion of mobile robots on a graph, introduced by Augustine and
Moses~Jr.~[ICDCN~2018] and by Molla, Mondal, and Moses~Jr.~[ALGOSENSORS~2020],
respectively, to graphs where nodes have variable capacities. We use the idea
of a single shepherd, a more powerful robot that will never act in a Byzantine
manner, to achieve fast Byzantine dispersion, even when other robots may be
strong Byzantine in nature. We also show the benefit of a shepherd for
dispersion on capacitated graphs when no Byzantine robots are present.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01515" title="Abstract">arXiv:2311.01515</a> [<a href="/pdf/2311.01515" title="Download PDF">pdf</a>, <a href="/format/2311.01515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implementation and Synthesis of Math Library Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Briggs%2C+I">Ian Briggs</a>, 
<a href="/search/cs?searchtype=author&query=Lad%2C+Y">Yash Lad</a>, 
<a href="/search/cs?searchtype=author&query=Panchekha%2C+P">Pavel Panchekha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Achieving speed and accuracy for math library functions like exp, sin, and
log is difficult. This is because low-level implementation languages like C do
not help math library developers catch mathematical errors, build
implementations incrementally, or separate high-level and low-level decision
making. This ultimately puts development of such functions out of reach for all
but the most experienced experts. To address this, we introduce MegaLibm, a
domain-specific language for implementing, testing, and tuning math library
implementations. MegaLibm is safe, modular, and tunable. Implementations in
MegaLibm can automatically detect mathematical mistakes like sign flips via
semantic wellformedness checks, and components like range reductions can be
implemented in a modular, composable way, simplifying implementations. Once the
high-level algorithm is done, tuning parameters like working precisions and
evaluation schemes can be adjusted through orthogonal tuning parameters to
achieve the desired speed and accuracy. MegaLibm also enables math library
developers to work interactively, compiling, testing, and tuning their
implementations and invoking tools like Sollya and type-directed synthesis to
complete components and synthesize entire implementations. MegaLibm can express
8 state-of-the-art math library implementations with comparable speed and
accuracy to the original C code, and can synthesize 5 variations and 3
from-scratch implementations with minimal guidance.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01517" title="Abstract">arXiv:2311.01517</a> [<a href="/pdf/2311.01517" title="Download PDF">pdf</a>, <a href="/format/2311.01517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimating Infinite-Dimensional Continuum Robot States From the Tip
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+T">Tongjia Zheng</a>, 
<a href="/search/cs?searchtype=author&query=McFarland%2C+C">Ciera McFarland</a>, 
<a href="/search/cs?searchtype=author&query=Coad%2C+M">Margaret Coad</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hai Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Knowing the state of a robot is critical for many problems, such as feedback
control. For continuum robots, state estimation is incredibly challenging.
First, the motion of a continuum robot involves many kinematic states,
including poses, strains, and velocities. Second, all these states are
infinite-dimensional due to the robot's flexible property. It has remained
unclear whether these infinite-dimensional states are observable at all using
existing sensing techniques. Recently, we presented a solution to this
challenge. It was a mechanics-based dynamic state estimation algorithm, called
a Cosserat theoretic boundary observer, which could recover all the
infinite-dimensional robot states by only measuring the velocity twist of the
tip. In this work, we generalize the algorithm to incorporate tip pose
measurements for more tuning freedom. We also validate this algorithm offline
using recorded experimental data of a tendon-driven continuum robot.
Specifically, we feed the recorded tension of the tendon and the recorded tip
measurements into a numerical solver of the Cosserat rod model based on our
continuum robot. It is observed that, even with purposely deviated
initialization, the state estimates by our algorithm quickly converge to the
recorded ground truth states and closely follow the robot's actual motion.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01520" title="Abstract">arXiv:2311.01520</a> [<a href="/pdf/2311.01520" title="Download PDF">pdf</a>, <a href="/format/2311.01520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 4D-Former: Multimodal 4D Panoptic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Athar%2C+A">Ali Athar</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+E">Enxu Li</a>, 
<a href="/search/cs?searchtype=author&query=Casas%2C+S">Sergio Casas</a>, 
<a href="/search/cs?searchtype=author&query=Urtasun%2C+R">Raquel Urtasun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at CoRL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">4D panoptic segmentation is a challenging but practically useful task that
requires every point in a LiDAR point-cloud sequence to be assigned a semantic
class label, and individual objects to be segmented and tracked over time.
Existing approaches utilize only LiDAR inputs which convey limited information
in regions with point sparsity. This problem can, however, be mitigated by
utilizing RGB camera images which offer appearance-based information that can
reinforce the geometry-based LiDAR features. Motivated by this, we propose
4D-Former: a novel method for 4D panoptic segmentation which leverages both
LiDAR and image modalities, and predicts semantic masks as well as temporally
consistent object masks for the input point-cloud sequence. We encode semantic
classes and objects using a set of concise queries which absorb feature
information from both data modalities. Additionally, we propose a learned
mechanism to associate object tracks over time which reasons over both
appearance and spatial location. We apply 4D-Former to the nuScenes and
SemanticKITTI datasets where it achieves state-of-the-art results.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01522" title="Abstract">arXiv:2311.01522</a> [<a href="/pdf/2311.01522" title="Download PDF">pdf</a>, <a href="/format/2311.01522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Efficient Detection and Control System for Underwater Docking using  Machine Learning and Realistic Simulation: A Comprehensive Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chavez-Galaviz%2C+J">Jalil Chavez-Galaviz</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianwen Li</a>, 
<a href="/search/cs?searchtype=author&query=Bergman%2C+M">Matthew Bergman</a>, 
<a href="/search/cs?searchtype=author&query=Mengdibayev%2C+M">Miras Mengdibayev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Underwater docking is critical to enable the persistent operation of
Autonomous Underwater Vehicles (AUVs). For this, the AUV must be capable of
detecting and localizing the docking station, which is complex due to the
highly dynamic undersea environment. Image-based solutions offer a high
acquisition rate and versatile alternative to adapt to this environment;
however, the underwater environment presents challenges such as low visibility,
high turbidity, and distortion. In addition to this, field experiments to
validate underwater docking capabilities can be costly and dangerous due to the
specialized equipment and safety considerations required to conduct the
experiments. This work compares different deep-learning architectures to
perform underwater docking detection and classification. The architecture with
the best performance is then compressed using knowledge distillation under the
teacher-student paradigm to reduce the network's memory footprint, allowing
real-time implementation. To reduce the simulation-to-reality gap, a Generative
Adversarial Network (GAN) is used to do image-to-image translation, converting
the Gazebo simulation image into a realistic underwater-looking image. The
obtained image is then processed using an underwater image formation model to
simulate image attenuation over distance under different water types. The
proposed method is finally evaluated according to the AUV docking success rate
and compared with classical vision methods. The simulation results show an
improvement of 20% in the high turbidity scenarios regardless of the underwater
currents. Furthermore, we show the performance of the proposed approach by
showing experimental results on the off-the-shelf AUV Iver3.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01526" title="Abstract">arXiv:2311.01526</a> [<a href="/pdf/2311.01526" title="Download PDF">pdf</a>, <a href="/format/2311.01526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ATGNN: Audio Tagging Graph Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Shubhr Singh</a>, 
<a href="/search/cs?searchtype=author&query=Steinmetz%2C+C+J">Christian J. Steinmetz</a>, 
<a href="/search/cs?searchtype=author&query=Benetos%2C+E">Emmanouil Benetos</a>, 
<a href="/search/cs?searchtype=author&query=Phan%2C+H">Huy Phan</a>, 
<a href="/search/cs?searchtype=author&query=Stowell%2C+D">Dan Stowell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Deep learning models such as CNNs and Transformers have achieved impressive
performance for end-to-end audio tagging. Recent works have shown that despite
stacking multiple layers, the receptive field of CNNs remains severely limited.
Transformers on the other hand are able to map global context through
self-attention, but treat the spectrogram as a sequence of patches which is not
flexible enough to capture irregular audio objects. In this work, we treat the
spectrogram in a more flexible way by considering it as graph structure and
process it with a novel graph neural architecture called ATGNN. ATGNN not only
combines the capability of CNNs with the global information sharing ability of
Graph Neural Networks, but also maps semantic relationships between learnable
class embeddings and corresponding spectrogram regions. We evaluate ATGNN on
two audio tagging tasks, where it achieves 0.585 mAP on the FSD50K dataset and
0.335 mAP on the AudioSet-balanced dataset, achieving comparable results to
Transformer based models with significantly lower number of learnable
parameters.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01530" title="Abstract">arXiv:2311.01530</a> [<a href="/pdf/2311.01530" title="Download PDF">pdf</a>, <a href="/format/2311.01530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NOD-TAMP: Multi-Step Manipulation Planning with Neural Object  Descriptors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Shuo Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Garrett%2C+C">Caelan Garrett</a>, 
<a href="/search/cs?searchtype=author&query=Mandlekar%2C+A">Ajay Mandlekar</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Danfei Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Developing intelligent robots for complex manipulation tasks in household and
factory settings remains challenging due to long-horizon tasks, contact-rich
manipulation, and the need to generalize across a wide variety of object shapes
and scene layouts. While Task and Motion Planning (TAMP) offers a promising
solution, its assumptions such as kinodynamic models limit applicability in
novel contexts. Neural object descriptors (NODs) have shown promise in object
and scene generalization but face limitations in addressing broader tasks. Our
proposed TAMP-based framework, NOD-TAMP, extracts short manipulation
trajectories from a handful of human demonstrations, adapts these trajectories
using NOD features, and composes them to solve broad long-horizon tasks.
Validated in a simulation environment, NOD-TAMP effectively tackles varied
challenges and outperforms existing methods, establishing a cohesive framework
for manipulation planning. For videos and other supplemental material, see the
project website: https://sites.google.com/view/nod-tamp/.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01532" title="Abstract">arXiv:2311.01532</a> [<a href="/pdf/2311.01532" title="Download PDF">pdf</a>, <a href="/format/2311.01532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VFCFinder: Seamlessly Pairing Security Advisories and Patches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dunlap%2C+T">Trevor Dunlap</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+E">Elizabeth Lin</a>, 
<a href="/search/cs?searchtype=author&query=Enck%2C+W">William Enck</a>, 
<a href="/search/cs?searchtype=author&query=Reaves%2C+B">Bradley Reaves</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Security advisories are the primary channel of communication for discovered
vulnerabilities in open-source software, but they often lack crucial
information. Specifically, 63% of vulnerability database reports are missing
their patch links, also referred to as vulnerability fixing commits (VFCs).
This paper introduces VFCFinder, a tool that generates the top-five ranked set
of VFCs for a given security advisory using Natural Language Programming
Language (NL-PL) models. VFCFinder yields a 96.6% recall for finding the
correct VFC within the Top-5 commits, and an 80.0% recall for the Top-1 ranked
commit. VFCFinder generalizes to nine different programming languages and
outperforms state-of-the-art approaches by 36 percentage points in terms of
Top-1 recall. As a practical contribution, we used VFCFinder to backfill over
300 missing VFCs in the GitHub Security Advisory (GHSA) database. All of the
VFCs were accepted and merged into the GHSA database. In addition to
demonstrating a practical pairing of security advisories to VFCs, our general
open-source implementation will allow vulnerability database maintainers to
drastically improve data quality, supporting efforts to secure the software
supply chain.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01534" title="Abstract">arXiv:2311.01534</a> [<a href="/pdf/2311.01534" title="Download PDF">pdf</a>, <a href="/format/2311.01534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximate Multiagent Reinforcement Learning for On-Demand Urban  Mobility Problem on a Large Map (extended version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garces%2C+D">Daniel Garces</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+S">Sushmita Bhattacharya</a>, 
<a href="/search/cs?searchtype=author&query=Bertsekas%2C+D">Dimitri Bertsekas</a>, 
<a href="/search/cs?searchtype=author&query=Gil%2C+S">Stephanie Gil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures, 1 lemma, and 2 theorems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">In this paper, we focus on the autonomous multiagent taxi routing problem for
a large urban environment where the location and number of future ride requests
are unknown a-priori, but follow an estimated empirical distribution. Recent
theory has shown that if a base policy is stable then a rollout-based algorithm
with such a base policy produces a near-optimal stable policy. Although,
rollout-based approaches are well-suited for learning cooperative multiagent
policies with considerations for future demand, applying such methods to a
large urban environment can be computationally expensive. Large environments
tend to have a large volume of requests, and hence require a large fleet of
taxis to guarantee stability. In this paper, we aim to address the
computational bottleneck of multiagent (one-at-a-time) rollout, where the
computational complexity grows linearly in the number of agents. We propose an
approximate one-at-a-time rollout-based two-phase algorithm that reduces the
computational cost, while still achieving a stable near-optimal policy. Our
approach partitions the graph into sectors based on the predicted demand and an
user-defined maximum number of agents that can be planned for using the
one-at-a-time rollout approach. The algorithm then applies instantaneous
assignment (IA) for re-balancing taxis across sectors and a sector-wide
one-at-a-time rollout algorithm that is executed in parallel for each sector.
We characterize the number of taxis $m$ that is sufficient for IA base policy
to be stable, and derive a necessary condition on $m$ as time goes to infinity.
Our numerical results show that our approach achieves stability for an $m$ that
satisfies the theoretical conditions. We also empirically demonstrate that our
proposed two-phase algorithm has comparable performance to the one-at-a-time
rollout over the entire map, but with significantly lower runtimes.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01540" title="Abstract">arXiv:2311.01540</a> [<a href="/pdf/2311.01540" title="Download PDF">pdf</a>, <a href="/format/2311.01540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open-Set Object Recognition Using Mechanical Properties During  Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Uttayopas%2C+P">Pakorn Uttayopas</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xiaoxiao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Burdet%2C+E">Etienne Burdet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">while most of the tactile robots are operated in close-set conditions, it is
challenging for them to operate in open-set conditions where test objects are
beyond the robots' knowledge. We proposed an open-set recognition framework
using mechanical properties to recongise known objects and incrementally label
novel objects. The main contribution is a clustering algorithm that exploits
knowledge of known objects to estimate cluster centre and sizes, unlike a
typical algorithm that randomly selects them. The framework is validated with
the mechanical properties estimated from a real object during interaction. The
results show that the framework could recognise objects better than alternative
methods contributed by the novelty detector. Importantly, our clustering
algorithm yields better clustering performance than other methods. Furthermore,
the hyperparameters studies show that cluster size is important to clustering
results and needed to be tuned properly.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01544" title="Abstract">arXiv:2311.01544</a> [<a href="/pdf/2311.01544" title="Download PDF">pdf</a>, <a href="/format/2311.01544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Divergent Token Metrics: Measuring degradation to prune away LLM  components -- and optimize quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deiseroth%2C+B">Bj&#xf6;rn Deiseroth</a>, 
<a href="/search/cs?searchtype=author&query=Meuer%2C+M">Max Meuer</a>, 
<a href="/search/cs?searchtype=author&query=Gritsch%2C+N">Nikolas Gritsch</a>, 
<a href="/search/cs?searchtype=author&query=Eichenberg%2C+C">Constantin Eichenberg</a>, 
<a href="/search/cs?searchtype=author&query=Schramowski%2C+P">Patrick Schramowski</a>, 
<a href="/search/cs?searchtype=author&query=A%C3%9Fenmacher%2C+M">Matthias A&#xdf;enmacher</a>, 
<a href="/search/cs?searchtype=author&query=Kersting%2C+K">Kristian Kersting</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models (LLMs) have reshaped natural language processing with
their impressive capabilities. Their ever-increasing size, however, raised
concerns about their effective deployment and the need for LLM compressions.
This study introduces the Divergent Token metrics (DTMs), a novel approach for
assessing compressed LLMs, addressing the limitations of traditional measures
like perplexity that fail to accurately reflect text generation quality. DTMs
focus on token divergence, providing deeper insights into the subtleties of
model compression. Our results indicate that significant levels of precision
and sparsity can be achieved without compromising text generation quality.
Moreover, DTMs offers a more precise evaluation of each component's impact
individually. Utilizing the First Divergent Token metric (FDTM) in model
sparsification reveals that nearly 20% of all components can be pruned over
90%. In terms of quantization, the FDTM suggests that over 80% of parameters
can be straightforwardly transformed to int8 without special outlier
management.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01550" title="Abstract">arXiv:2311.01550</a> [<a href="/pdf/2311.01550" title="Download PDF">pdf</a>, <a href="/ps/2311.01550" title="Download PostScript">ps</a>, <a href="/format/2311.01550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Market Concentration Implications of Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vipra%2C+J">Jai Vipra</a>, 
<a href="/search/cs?searchtype=author&query=Korinek%2C+A">Anton Korinek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Working Paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; General Economics (econ.GN)

</div>
<p class="mathjax">We analyze the structure of the market for foundation models, i.e., large AI
models such as those that power ChatGPT and that are adaptable to downstream
uses, and we examine the implications for competition policy and regulation. We
observe that the most capable models will have a tendency towards natural
monopoly and may have potentially vast markets. This calls for a two-pronged
regulatory response: (i) Antitrust authorities need to ensure the
contestability of the market by tackling strategic behavior, in particular by
ensuring that monopolies do not propagate vertically to downstream uses, and
(ii) given the diminished potential for market discipline, there is a role for
regulators to ensure that the most capable models meet sufficient quality
standards (including safety, privacy, non-discrimination, reliability and
interoperability standards) to maximally contribute to social welfare.
Regulators should also ensure a level regulatory playing field between AI and
non-AI applications in all sectors of the economy. For models that are behind
the frontier, we expect competition to be quite intense, implying a more
limited role for competition policy, although a role for regulation remains.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01553" title="Abstract">arXiv:2311.01553</a> [<a href="/pdf/2311.01553" title="Download PDF">pdf</a>, <a href="/format/2311.01553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Total Variation Meets Differential Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghazi%2C+E">Elena Ghazi</a> (1), 
<a href="/search/cs?searchtype=author&query=Issa%2C+I">Ibrahim Issa</a> (1) ((1) American University of Beirut)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures, Partially published at 2023 IEEE ISIT and partially submitted at IEEE Journal on Selected Areas in Information Theory
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">The framework of approximate differential privacy is considered, and
augmented by introducing the notion of "the total variation of a
(privacy-preserving) mechanism" (denoted by $\eta$-TV). With this refinement,
an exact composition result is derived, and shown to be significantly tighter
than the optimal bounds for differential privacy (which do not consider the
total variation). Furthermore, it is shown that $(\varepsilon,\delta)$-DP with
$\eta$-TV is closed under subsampling. The induced total variation of commonly
used mechanisms are computed. Moreover, the notion of total variation of a
mechanism is extended to the local privacy setting and privacy-utility
tradeoffs are investigated. In particular, total variation distance and KL
divergence are considered as utility functions and upper bounds are derived.
Finally, the results are compared and connected to the (purely) locally
differentially private setting.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01555" title="Abstract">arXiv:2311.01555</a> [<a href="/pdf/2311.01555" title="Download PDF">pdf</a>, <a href="/format/2311.01555" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instruction Distillation Makes Large Language Models Efficient Zero-shot  Rankers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weiwei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xinyu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+L">Lingyong Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuaiqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+P">Pengjie Ren</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhumin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+D">Dawei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zhaochun Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Recent studies have demonstrated the great potential of Large Language Models
(LLMs) serving as zero-shot relevance rankers. The typical approach involves
making comparisons between pairs or lists of documents. Although effective,
these listwise and pairwise methods are not efficient and also heavily rely on
intricate prompt engineering. To tackle this problem, we introduce a novel
instruction distillation method. The key idea is to distill the pairwise
ranking ability of open-sourced LLMs to a simpler but more efficient pointwise
ranking. Specifically, given the same LLM, we first rank documents using the
effective pairwise approach with complex instructions, and then distill the
teacher predictions to the pointwise approach with simpler instructions.
Evaluation results on the BEIR, TREC, and ReDial datasets demonstrate that
instruction distillation can improve efficiency by 10 to 100x and also enhance
the ranking performance of LLMs. Furthermore, our approach surpasses the
performance of existing supervised methods like monoT5 and is on par with the
state-of-the-art zero-shot methods. The code to reproduce our results is
available at www.github.com/sunnweiwei/RankGPT.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01556" title="Abstract">arXiv:2311.01556</a> [<a href="/pdf/2311.01556" title="Download PDF">pdf</a>, <a href="/format/2311.01556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MemorySeg: Online LiDAR Semantic Segmentation with a Latent Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+E">Enxu Li</a>, 
<a href="/search/cs?searchtype=author&query=Casas%2C+S">Sergio Casas</a>, 
<a href="/search/cs?searchtype=author&query=Urtasun%2C+R">Raquel Urtasun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Semantic segmentation of LiDAR point clouds has been widely studied in recent
years, with most existing methods focusing on tackling this task using a single
scan of the environment. However, leveraging the temporal stream of
observations can provide very rich contextual information on regions of the
scene with poor visibility (e.g., occlusions) or sparse observations (e.g., at
long range), and can help reduce redundant computation frame after frame. In
this paper, we tackle the challenge of exploiting the information from the past
frames to improve the predictions of the current frame in an online fashion. To
address this challenge, we propose a novel framework for semantic segmentation
of a temporal sequence of LiDAR point clouds that utilizes a memory network to
store, update and retrieve past information. Our framework also includes a
regularizer that penalizes prediction variations in the neighborhood of the
point cloud. Prior works have attempted to incorporate memory in range view
representations for semantic segmentation, but these methods fail to handle
occlusions and the range view representation of the scene changes drastically
as agents nearby move. Our proposed framework overcomes these limitations by
building a sparse 3D latent representation of the surroundings. We evaluate our
method on SemanticKITTI, nuScenes, and PandaSet. Our experiments demonstrate
the effectiveness of the proposed framework compared to the state-of-the-art.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01559" title="Abstract">arXiv:2311.01559</a> [<a href="/pdf/2311.01559" title="Download PDF">pdf</a>, <a href="/format/2311.01559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The effect of disruptive events on spatial and social interactions: An  assessment of structural changes in pre-and post-COVID-19 pandemic networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koylu%2C+C">Caglar Koylu</a>, 
<a href="/search/cs?searchtype=author&query=Torkashvand%2C+M">Maryam Torkashvand</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of GIScience 2023 Workshop on Disruptive Movement Analysis, September 12, 2023, Leeds, UK
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Disruptive events significantly alter spatial and social interactions among
people and places. To examine the structural changes in spatial and social
interaction networks in pre- and post-periods of the COVID-19 pandemic, we
employ the Louvain method to algorithmically detect regions (communities)
within the county-to-county networks of the SafeGraph mobility and Facebook
social connectedness. We then utilize a range of partition similarity metrics,
including adjusted Rand, z-Rand, Normalized Mutual Information (NMI), and
Jaccard indices, to quantitatively measure the similarity of regions between
the pre- and post-periods partitions of each network. Our findings reveal that
in the post-pandemic period, spatial interactions led to the formation of
localized geographic communities or regions characterized by higher modular
activity within each region. In contrast, online social interactions shifted
towards longer distance connections, resulting in the emergence of larger
regions marked by strong friendship ties that often encompassed multiple
states. By understanding these changes, we contribute to a better comprehension
of the pandemic's impact on our interconnected physical-virtual world,
providing valuable insights for future research and informing strategies to
adapt to the evolving dynamics of human interactions.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01563" title="Abstract">arXiv:2311.01563</a> [<a href="/pdf/2311.01563" title="Download PDF">pdf</a>, <a href="/format/2311.01563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assist Is Just as Important as the Goal: Image Resurfacing to Aid  Model&#x27;s Robust Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Abhijith Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Munz%2C+P">Phil Munz</a>, 
<a href="/search/cs?searchtype=author&query=Narayan%2C+A">Apurva Narayan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Adversarial patches threaten visual AI models in the real world. The number
of patches in a patch attack is variable and determines the attack's potency in
a specific environment. Most existing defenses assume a single patch in the
scene, and the multiple patch scenarios are shown to overcome them. This paper
presents a model-agnostic defense against patch attacks based on total
variation for image resurfacing (TVR). The TVR is an image-cleansing method
that processes images to remove probable adversarial regions. TVR can be
utilized solely or augmented with a defended model, providing multi-level
security for robust prediction. TVR nullifies the influence of patches in a
single image scan with no prior assumption on the number of patches in the
scene. We validate TVR on the ImageNet-Patch benchmark dataset and with
real-world physical objects, demonstrating its ability to mitigate patch
attack.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01567" title="Abstract">arXiv:2311.01567</a> [<a href="/pdf/2311.01567" title="Download PDF">pdf</a>, <a href="/format/2311.01567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Hyperparameter Space of Image Diffusion Models for  Echocardiogram Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reynaud%2C+H">Hadrien Reynaud</a>, 
<a href="/search/cs?searchtype=author&query=Kainz%2C+B">Bernhard Kainz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MedNeurIPS 2023 poster
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This work presents an extensive hyperparameter search on Image Diffusion
Models for Echocardiogram generation. The objective is to establish
foundational benchmarks and provide guidelines within the realm of ultrasound
image and video generation. This study builds over the latest advancements,
including cutting-edge model architectures and training methodologies. We also
examine the distribution shift between real and generated samples and consider
potential solutions, crucial to train efficient models on generated data. We
determine an Optimal FID score of $0.88$ for our research problem and achieve
an FID of $2.60$. This work is aimed at contributing valuable insights and
serving as a reference for further developments in the specialized field of
ultrasound image and video generation.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01568" title="Abstract">arXiv:2311.01568</a> [<a href="/pdf/2311.01568" title="Download PDF">pdf</a>, <a href="/format/2311.01568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anytime-Competitive Reinforcement Learning with Policy Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pengfei Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tongxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Wierman%2C+A">Adam Wierman</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Shaolei Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper studies the problem of Anytime-Competitive Markov Decision Process
(A-CMDP). Existing works on Constrained Markov Decision Processes (CMDPs) aim
to optimize the expected reward while constraining the expected cost over
random dynamics, but the cost in a specific episode can still be
unsatisfactorily high. In contrast, the goal of A-CMDP is to optimize the
expected reward while guaranteeing a bounded cost in each round of any episode
against a policy prior. We propose a new algorithm, called Anytime-Competitive
Reinforcement Learning (ACRL), which provably guarantees the anytime cost
constraints. The regret analysis shows the policy asymptotically matches the
optimal reward achievable under the anytime competitive constraints.
Experiments on the application of carbon-intelligent computing verify the
reward performance and cost constraint guarantee of ACRL.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01570" title="Abstract">arXiv:2311.01570</a> [<a href="/pdf/2311.01570" title="Download PDF">pdf</a>, <a href="/format/2311.01570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sequential Subset Matching for Dataset Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+J">Jiawei Du</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Q">Qin Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J+T">Joey Tianyi Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Dataset distillation is a newly emerging task that synthesizes a small-size
dataset used in training deep neural networks (DNNs) for reducing data storage
and model training costs. The synthetic datasets are expected to capture the
essence of the knowledge contained in real-world datasets such that the former
yields a similar performance as the latter. Recent advancements in distillation
methods have produced notable improvements in generating synthetic datasets.
However, current state-of-the-art methods treat the entire synthetic dataset as
a unified entity and optimize each synthetic instance equally. This static
optimization approach may lead to performance degradation in dataset
distillation. Specifically, we argue that static optimization can give rise to
a coupling issue within the synthetic data, particularly when a larger amount
of synthetic data is being optimized. This coupling issue, in turn, leads to
the failure of the distilled dataset to extract the high-level features learned
by the deep neural network (DNN) in the latter epochs.
<br />In this study, we propose a new dataset distillation strategy called
Sequential Subset Matching (SeqMatch), which tackles this problem by adaptively
optimizing the synthetic data to encourage sequential acquisition of knowledge
during dataset distillation. Our analysis indicates that SeqMatch effectively
addresses the coupling issue by sequentially generating the synthetic
instances, thereby enhancing its performance significantly. Our proposed
SeqMatch outperforms state-of-the-art methods in various datasets, including
SVNH, CIFAR-10, CIFAR-100, and Tiny ImageNet. Our code is available at
https://github.com/shqii1j/seqmatch.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01571" title="Abstract">arXiv:2311.01571</a> [<a href="/pdf/2311.01571" title="Download PDF">pdf</a>, <a href="/format/2311.01571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preserving the knowledge of long clinical texts using aggregated  ensembles of large language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hasan%2C+M+J">Mohammad Junayed Hasan</a>, 
<a href="/search/cs?searchtype=author&query=Noor%2C+S">Suhra Noor</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+M+A">Mohammad Ashrafuzzaman Khan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 4 figures, 4 tables, 9 equations and 1 algorithm
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Clinical texts, such as admission notes, discharge summaries, and progress
notes, contain rich and valuable information that can be used for various
clinical outcome prediction tasks. However, applying large language models,
such as BERT-based models, to clinical texts poses two major challenges: the
limitation of input length and the diversity of data sources. This paper
proposes a novel method to preserve the knowledge of long clinical texts using
aggregated ensembles of large language models. Unlike previous studies which
use model ensembling or text aggregation methods separately, we combine
ensemble learning with text aggregation and train multiple large language
models on two clinical outcome tasks: mortality prediction and length of stay
prediction. We show that our method can achieve better results than baselines,
ensembling, and aggregation individually, and can improve the performance of
large language models while handling long inputs and diverse datasets. We
conduct extensive experiments on the admission notes from the MIMIC-III
clinical database by combining multiple unstructured and high-dimensional
datasets, demonstrating our method's effectiveness and superiority over
existing approaches. We also provide a comprehensive analysis and discussion of
our results, highlighting our method's applications and limitations for future
research in the domain of clinical healthcare. The results and analysis of this
study is supportive of our method assisting in clinical healthcare systems by
enabling clinical decision-making with robust performance overcoming the
challenges of long text inputs and varied datasets.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01573" title="Abstract">arXiv:2311.01573</a> [<a href="/pdf/2311.01573" title="Download PDF">pdf</a>, <a href="/format/2311.01573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Fairness using Vision-Language Driven Image Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%27Inc%C3%A0%2C+M">Moreno D&#x27;Inc&#xe0;</a>, 
<a href="/search/cs?searchtype=author&query=Tzelepis%2C+C">Christos Tzelepis</a>, 
<a href="/search/cs?searchtype=author&query=Patras%2C+I">Ioannis Patras</a>, 
<a href="/search/cs?searchtype=author&query=Sebe%2C+N">Nicu Sebe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Fairness is crucial when training a deep-learning discriminative model,
especially in the facial domain. Models tend to correlate specific
characteristics (such as age and skin color) with unrelated attributes
(downstream tasks), resulting in biases which do not correspond to reality. It
is common knowledge that these correlations are present in the data and are
then transferred to the models during training. This paper proposes a method to
mitigate these correlations to improve fairness. To do so, we learn
interpretable and meaningful paths lying in the semantic space of a pre-trained
diffusion model (DiffAE) -- such paths being supervised by contrastive text
dipoles. That is, we learn to edit protected characteristics (age and skin
color). These paths are then applied to augment images to improve the fairness
of a given dataset. We test the proposed method on CelebA-HQ and UTKFace on
several downstream tasks with age and skin color as protected characteristics.
As a proxy for fairness, we compute the difference in accuracy with respect to
the protected characteristics. Quantitative results show how the augmented
images help the model improve the overall accuracy, the aforementioned metric,
and the disparity of equal opportunity. Code is available at:
https://github.com/Moreno98/Vision-Language-Bias-Control.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01575" title="Abstract">arXiv:2311.01575</a> [<a href="/pdf/2311.01575" title="Download PDF">pdf</a>, <a href="/format/2311.01575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Convergence of Encoder-only Shallow Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yongtao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fanghui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chrysos%2C+G+G">Grigorios G Chrysos</a>, 
<a href="/search/cs?searchtype=author&query=Cevher%2C+V">Volkan Cevher</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this paper, we aim to build the global convergence theory of encoder-only
shallow Transformers under a realistic setting from the perspective of
architectures, initialization, and scaling under a finite width regime. The
difficulty lies in how to tackle the softmax in self-attention mechanism, the
core ingredient of Transformer. In particular, we diagnose the scaling scheme,
carefully tackle the input/output of softmax, and prove that quadratic
overparameterization is sufficient for global convergence of our shallow
Transformers under commonly-used He/LeCun initialization in practice. Besides,
neural tangent kernel (NTK) based analysis is also given, which facilitates a
comprehensive comparison. Our theory demonstrates the separation on the
importance of different scaling schemes and initialization. We believe our
results can pave the way for a better understanding of modern Transformers,
particularly on training dynamics.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01580" title="Abstract">arXiv:2311.01580</a> [<a href="/pdf/2311.01580" title="Download PDF">pdf</a>, <a href="/format/2311.01580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MetaReVision: Meta-Learning with Retrieval for Visually Grounded  Compositional Concept Acquisition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Guangyue Xu</a>, 
<a href="/search/cs?searchtype=author&query=Kordjamshidi%2C+P">Parisa Kordjamshidi</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+J">Joyce Chai</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EMNLP-Finding(2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Humans have the ability to learn novel compositional concepts by recalling
and generalizing primitive concepts acquired from past experiences. Inspired by
this observation, in this paper, we propose MetaReVision, a retrieval-enhanced
meta-learning model to address the visually grounded compositional concept
learning problem. The proposed MetaReVision consists of a retrieval module and
a meta-learning module which are designed to incorporate retrieved primitive
concepts as a supporting set to meta-train vision-anguage models for grounded
compositional concept recognition. Through meta-learning from episodes
constructed by the retriever, MetaReVision learns a generic compositional
representation that can be fast updated to recognize novel compositional
concepts. We create CompCOCO and CompFlickr to benchmark the grounded
compositional concept learning. Our experimental results show that MetaReVision
outperforms other competitive baselines and the retrieval module plays an
important role in this compositional learning process.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01581" title="Abstract">arXiv:2311.01581</a> [<a href="/pdf/2311.01581" title="Download PDF">pdf</a>, <a href="/format/2311.01581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Many-to-Many Routing for Dynamic Taxi Sharing with Meeting Points
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Laupichler%2C+M">Moritz Laupichler</a>, 
<a href="/search/cs?searchtype=author&query=Sanders%2C+P">Peter Sanders</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 7 figures, 4 tables. To be presented at ALENEX'24. arXiv admin note: substantial text overlap with <a href="/abs/2305.05417">arXiv:2305.05417</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We introduce an improved algorithm for the dynamic taxi sharing problem, i.e.
a dispatcher that schedules a fleet of shared taxis as it is used by services
like UberXShare and Lyft Shared. We speed up the basic online algorithm that
looks for all possible insertions of a new customer into a set of existing
routes, we generalize the objective function, and we efficiently support a
large number of possible pick-up and drop-off locations. This lays an
algorithmic foundation for taxi sharing systems with higher vehicle occupancy -
enabling greatly reduced cost and ecological impact at comparable service
quality. We find that our algorithm computes assignments between vehicles and
riders several times faster than a previous state-of-the-art approach. Further,
we observe that allowing meeting points for vehicles and riders can reduce the
operating cost of vehicle fleets by up to 15% while also reducing rider wait
and trip times.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01584" title="Abstract">arXiv:2311.01584</a> [<a href="/pdf/2311.01584" title="Download PDF">pdf</a>, <a href="/format/2311.01584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secured Fiscal Credit Model: Multi-Agent Systems And Decentralized  Autonomous Organisations For Tax Credit&#x27;s Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Gasperis%2C+G">Giovanni De Gasperis</a>, 
<a href="/search/cs?searchtype=author&query=Facchini%2C+S+D">Sante Dino Facchini</a>, 
<a href="/search/cs?searchtype=author&query=Letteri%2C+I">Ivan Letteri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">Tax incentives and fiscal bonuses have had a significant impact on the
Italian economy over the past decade. In particular, the "Superbonus 110" tax
relief in 2020, offering a generous 110% deduction for expenses related to
energy efficiency improvements and seismic risk reduction in buildings, has
played a pivotal role. However, the surge in construction activities has also
brought about an unfortunate increase in fraudulent activities. To address this
challenge, our research introduces a practical system for monitoring and
managing the entire process of the Superbonus 110 tax credit, from its
initiation to redemption. This system leverages artificial intelligence and
blockchain technology to streamline tax credit management and incorporates
controllers based on a Decentralised Autonomous Organisation architecture,
bolstered by a Multi-agent System. The outcome of our work is a system capable
of establishing a tokenomics framework that caters to the needs and
functionalities of both investors and operators. Moreover, it features a robust
control system to prevent inadvertent errors like double spending,
overspending, and deceitful practices such as false claims of completed work.
The collaborative approach between the Decentralised Autonomous Organisation
and the Multi-agent System enhances trust and security levels among
participants in a competitive environment where potential fraudsters might
attempt to exploit the system. It also enables comprehensive tracking and
monitoring of the entire Superbonus process. In the realm of engineering, our
project represents an innovative fusion of blockchain technology and
Multi-agent Systems, advancing the application of artificial intelligence. This
integration guarantees the validation, recording, and execution of transactions
with a remarkable level of trust and transparency.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01589" title="Abstract">arXiv:2311.01589</a> [<a href="/pdf/2311.01589" title="Download PDF">pdf</a>, <a href="/format/2311.01589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Statistical Guarantee for Representation Transfer in Multitask  Imitation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chan%2C+B">Bryan Chan</a>, 
<a href="/search/cs?searchtype=author&query=Pereida%2C+K">Karime Pereida</a>, 
<a href="/search/cs?searchtype=author&query=Bergstra%2C+J">James Bergstra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023 Workshop on Robot Learning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Transferring representation for multitask imitation learning has the
potential to provide improved sample efficiency on learning new tasks, when
compared to learning from scratch. In this work, we provide a statistical
guarantee indicating that we can indeed achieve improved sample efficiency on
the target task when a representation is trained using sufficiently diverse
source tasks. Our theoretical results can be readily extended to account for
commonly used neural network architectures with realistic assumptions. We
conduct empirical analyses that align with our theoretical findings on four
simulated environments$\unicode{x2014}$in particular leveraging more data from
source tasks can improve sample efficiency on learning in the new task.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01591" title="Abstract">arXiv:2311.01591</a> [<a href="/pdf/2311.01591" title="Download PDF">pdf</a>, <a href="/format/2311.01591" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Better Fair than Sorry: Adversarial Missing Data Imputation for Fair  GNNs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lina%2C+D+H">Debolina Halder Lina</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+A">Arlei Silva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper addresses the problem of learning fair Graph Neural Networks
(GNNs) under missing protected attributes. GNNs have achieved state-of-the-art
results in many relevant tasks where decisions might disproportionately impact
specific communities. However, existing work on fair GNNs assumes that either
protected attributes are fully-observed or that the missing data imputation is
fair. In practice, biases in the imputation will be propagated to the model
outcomes, leading them to overestimate the fairness of their predictions. We
address this challenge by proposing Better Fair than Sorry (BFtS), a fair
missing data imputation model for protected attributes used by fair GNNs. The
key design principle behind BFtS is that imputations should approximate the
worst-case scenario for the fair GNN -- i.e. when optimizing fairness is the
hardest. We implement this idea using a 3-player adversarial scheme where two
adversaries collaborate against the fair GNN. Experiments using synthetic and
real datasets show that BFtS often achieves a better fairness $\times$ accuracy
trade-off than existing alternatives.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01597" title="Abstract">arXiv:2311.01597</a> [<a href="/pdf/2311.01597" title="Download PDF">pdf</a>, <a href="/format/2311.01597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vertical Decomposition in 3D and 4D with Applications to Line  Nearest-Neighbor Searching in 3D
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+P+K">Pankaj K. Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Ezra%2C+E">Esther Ezra</a>, 
<a href="/search/cs?searchtype=author&query=Sharir%2C+M">Micha Sharir</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">Vertical decomposition is a widely used general technique for decomposing the
cells of arrangements of semi-algebraic sets in $d$-space into
constant-complexity subcells. In this paper, we settle in the affirmative a few
long-standing open problems involving the vertical decomposition of
substructures of arrangements for $d=3,4$: (i) Let $\mathcal{S}$ be a
collection of $n$ semi-algebraic sets of constant complexity in 3D, and let
$U(m)$ be an upper bound on the complexity of the union
$\mathcal{U}(\mathcal{S}')$ of any subset $\mathcal{S}'\subseteq \mathcal{S}$
of size at most $m$. We prove that the complexity of the vertical decomposition
of the complement of $\mathcal{U}(\mathcal{S})$ is $O^*(n^2+U(n))$ (where the
$O^*(\cdot)$ notation hides subpolynomial factors). We also show that the
complexity of the vertical decomposition of the entire arrangement
$\mathcal{A}(\mathcal{S})$ is $O^*(n^2+X)$, where $X$ is the number of vertices
in $\mathcal{A}(\mathcal{S})$. (ii) Let $\mathcal{F}$ be a collection of $n$
trivariate functions whose graphs are semi-algebraic sets of constant
complexity. We show that the complexity of the vertical decomposition of the
portion of the arrangement $\mathcal{A}(\mathcal{F})$ in 4D lying below the
lower envelope of $\mathcal{F}$ is $O^*(n^3)$.
<br />These results lead to efficient algorithms for a variety of problems
involving these decompositions, including algorithms for constructing the
decompositions themselves, and for constructing $(1/r)$-cuttings of
substructures of arrangements of the kinds considered above. One additional
algorithm of interest is for output-sensitive point enclosure queries amid
semi-algebraic sets in three or four dimensions. In addition, as a main domain
of applications, we study various proximity problems involving points and lines
in 3D.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01598" title="Abstract">arXiv:2311.01598</a> [<a href="/pdf/2311.01598" title="Download PDF">pdf</a>, <a href="/format/2311.01598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CiFlow: Dataflow Analysis and Optimization of Key Switching for  Homomorphic Encryption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neda%2C+N">Negar Neda</a>, 
<a href="/search/cs?searchtype=author&query=Ebel%2C+A">Austin Ebel</a>, 
<a href="/search/cs?searchtype=author&query=Reynwar%2C+B">Benedict Reynwar</a>, 
<a href="/search/cs?searchtype=author&query=Reagen%2C+B">Brandon Reagen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Hardware Architecture (cs.AR); Performance (cs.PF)

</div>
<p class="mathjax">Homomorphic encryption (HE) is a privacy-preserving computation technique
that enables computation on encrypted data. Today, the potential of HE remains
largely unrealized as it is impractically slow, preventing it from being used
in real applications. A major computational bottleneck in HE is the
key-switching operation, accounting for approximately 70% of the overall HE
execution time and involving a large amount of data for inputs, intermediates,
and keys. Prior research has focused on hardware accelerators to improve HE
performance, typically featuring large on-chip SRAMs and high off-chip
bandwidth to deal with large scale data. In this paper, we present a novel
approach to improve key-switching performance by rigorously analyzing its
dataflow. Our primary goal is to optimize data reuse with limited on-chip
memory to minimize off-chip data movement. We introduce three distinct
dataflows: Max-Parallel (MP), Digit-Centric (DC), and Output-Centric (OC), each
with unique scheduling approaches for key-switching computations. Through our
analysis, we show how our proposed Output-Centric technique can effectively
reuse data by significantly lowering the intermediate key-switching working set
and alleviating the need for massive off-chip bandwidth. We thoroughly evaluate
the three dataflows using the RPU, a recently published vector processor
tailored for ring processing algorithms, which includes HE. This evaluation
considers sweeps of bandwidth and computational throughput, and whether keys
are buffered on-chip or streamed. With OC, we demonstrate up to 4.16x speedup
over the MP dataflow and show how OC can save 16x on-chip SRAM by streaming
keys for minimal performance penalty.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01599" title="Abstract">arXiv:2311.01599</a> [<a href="/pdf/2311.01599" title="Download PDF">pdf</a>, <a href="/ps/2311.01599" title="Download PostScript">ps</a>, <a href="/format/2311.01599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local Borsuk-Ulam, Stability, and Replicability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chase%2C+Z">Zachary Chase</a>, 
<a href="/search/cs?searchtype=author&query=Chornomaz%2C+B">Bogdan Chornomaz</a>, 
<a href="/search/cs?searchtype=author&query=Moran%2C+S">Shay Moran</a>, 
<a href="/search/cs?searchtype=author&query=Yehudayoff%2C+A">Amir Yehudayoff</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We use and adapt the Borsuk-Ulam Theorem from topology to derive limitations
on list-replicable and globally stable learning algorithms. We further
demonstrate the applicability of our methods in combinatorics and topology.
<br />We show that, besides trivial cases, both list-replicable and globally stable
learning are impossible in the agnostic PAC setting. This is in contrast with
the realizable case where it is known that any class with a finite Littlestone
dimension can be learned by such algorithms. In the realizable PAC setting, we
sharpen previous impossibility results and broaden their scope. Specifically,
we establish optimal bounds for list replicability and global stability numbers
in finite classes. This provides an exponential improvement over previous works
and implies an exponential separation from the Littlestone dimension. We
further introduce lower bounds for weak learners, i.e., learners that are only
marginally better than random guessing. Lower bounds from previous works apply
only to stronger learners.
<br />To offer a broader and more comprehensive view of our topological approach,
we prove a local variant of the Borsuk-Ulam theorem in topology and a result in
combinatorics concerning Kneser colorings. In combinatorics, we prove that if
$c$ is a coloring of all non-empty subsets of $[n]$ such that disjoint sets
have different colors, then there is a chain of subsets that receives at least
$1+ \lfloor n/2\rfloor$ colors (this bound is sharp). In topology, we prove
e.g. that for any open antipodal-free cover of the $d$-dimensional sphere,
there is a point $x$ that belongs to at least $t=\lceil\frac{d+3}{2}\rceil$
sets.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01602" title="Abstract">arXiv:2311.01602</a> [<a href="/pdf/2311.01602" title="Download PDF">pdf</a>, <a href="/format/2311.01602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DRNet: A Decision-Making Method for Autonomous Lane Changingwith Deep  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kunpeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lifei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shengrui Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Machine learning techniques have outperformed numerous rule-based methods for
decision-making in autonomous vehicles. Despite recent efforts, lane changing
remains a major challenge, due to the complex driving scenarios and changeable
social behaviors of surrounding vehicles. To help improve the state of the art,
we propose to leveraging the emerging \underline{D}eep
\underline{R}einforcement learning (DRL) approach for la\underline{NE} changing
at the \underline{T}actical level. To this end, we present "DRNet", a novel and
highly efficient DRL-based framework that enables a DRL agent to learn to drive
by executing reasonable lane changing on simulated highways with an arbitrary
number of lanes, and considering driving style of surrounding vehicles to make
better decisions. Furthermore, to achieve a safe policy for decision-making,
DRNet incorporates ideas from safety verification, the most important component
of autonomous driving, to ensure that only safe actions are chosen at any time.
The setting of our state representation and reward function enables the trained
agent to take appropriate actions in a real-world-like simulator. Our DRL agent
has the ability to learn the desired task without causing collisions and
outperforms DDQN and other baseline models.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01603" title="Abstract">arXiv:2311.01603</a> [<a href="/pdf/2311.01603" title="Download PDF">pdf</a>, <a href="/ps/2311.01603" title="Download PostScript">ps</a>, <a href="/format/2311.01603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of distributional Riemann curvature tensor in any dimension
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gopalakrishnan%2C+J">Jay Gopalakrishnan</a>, 
<a href="/search/math?searchtype=author&query=Neunteufel%2C+M">Michael Neunteufel</a>, 
<a href="/search/math?searchtype=author&query=Sch%C3%B6berl%2C+J">Joachim Sch&#xf6;berl</a>, 
<a href="/search/math?searchtype=author&query=Wardetzky%2C+M">Max Wardetzky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Differential Geometry (math.DG)

</div>
<p class="mathjax">In this paper we propose a definition of the distributional Riemann curvature
tensor in dimension $N\geq 2$ if the underlying metric tensor $g$ defined on a
triangulation $\mathcal{T}$ possesses only single-valued tangential-tangential
components on codimension 1 simplices. We analyze the convergence of the
curvature approximation in the $H^{-2}$-norm if a sequence of interpolants
$g_h$ of polynomial order $k\geq 0$ of a smooth metric $g$ is given. We show
that for dimension $N=2$ convergence rates of order $\mathcal{O}(h^{k+1})$ are
obtained. For $N\geq 3$ convergence holds only in the case $k\geq 1$. Numerical
examples demonstrate that our theoretical results are sharp. By choosing
appropriate test functions we show that the distributional Gauss and scalar
curvature in 2D respectively any dimension are obtained. Further, a first
definition of the distributional Ricci curvature tensor in arbitrary dimension
is derived, for which our analysis is applicable.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01605" title="Abstract">arXiv:2311.01605</a> [<a href="/pdf/2311.01605" title="Download PDF">pdf</a>, <a href="/ps/2311.01605" title="Download PostScript">ps</a>, <a href="/format/2311.01605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faithful and Robust Local Interpretability for Textual Predictions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lopardo%2C+G">Gianluigi Lopardo</a>, 
<a href="/search/cs?searchtype=author&query=Precioso%2C+F">Frederic Precioso</a>, 
<a href="/search/cs?searchtype=author&query=Garreau%2C+D">Damien Garreau</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Interpretability is essential for machine learning models to be trusted and
deployed in critical domains. However, existing methods for interpreting text
models are often complex, lack solid mathematical foundations, and their
performance is not guaranteed. In this paper, we propose FRED (Faithful and
Robust Explainer for textual Documents), a novel method for interpreting
predictions over text. FRED identifies key words in a document that
significantly impact the prediction when removed. We establish the reliability
of FRED through formal definitions and theoretical analyses on interpretable
classifiers. Additionally, our empirical evaluation against state-of-the-art
methods demonstrates the effectiveness of FRED in providing insights into text
models.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01606" title="Abstract">arXiv:2311.01606</a> [<a href="/pdf/2311.01606" title="Download PDF">pdf</a>, <a href="/format/2311.01606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KG-FRUS: a Novel Graph-based Dataset of 127 Years of US Diplomatic  Relations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C3%96zsoy%2C+G">G&#xf6;kberk &#xd6;zsoy</a>, 
<a href="/search/cs?searchtype=author&query=Salamanca%2C+L">Luis Salamanca</a>, 
<a href="/search/cs?searchtype=author&query=Connelly%2C+M">Matthew Connelly</a>, 
<a href="/search/cs?searchtype=author&query=Hicks%2C+R">Raymond Hicks</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez-Cruz%2C+F">Fernando P&#xe9;rez-Cruz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures, 2 tables, submitted to NeurIPS databases. Mixed of social sciences and data analysis content
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In the current paper, we present the KG-FRUS dataset, comprised of more than
300,000 US government diplomatic documents encoded in a Knowledge Graph (KG).
We leverage the data of the Foreign Relations of the United States (FRUS)
(available as XML files) to extract information about the documents and the
individuals and countries mentioned within them. We use the extracted entities,
and associated metadata, to create a graph-based dataset. Further, we
supplement the created KG with additional entities and relations from Wikidata.
The relations in the KG capture the synergies and dynamics required to study
and understand the complex fields of diplomacy, foreign relations, and
politics. This goes well beyond a simple collection of documents which neglects
the relations between entities in the text. We showcase a range of
possibilities of the current dataset by illustrating different approaches to
probe the KG. In the paper, we exemplify how to use a query language to answer
simple research questions and how to use graph algorithms such as Node2Vec and
PageRank, that benefit from the complete graph structure. More importantly, the
chosen structure provides total flexibility for continuously expanding and
enriching the graph. Our solution is general, so the proposed pipeline for
building the KG can encode other original corpora of time-dependent and complex
phenomena. Overall, we present a mechanism to create KG databases providing a
more versatile representation of time-dependent related text data and a
particular application to the all-important FRUS database.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01609" title="Abstract">arXiv:2311.01609</a> [<a href="/pdf/2311.01609" title="Download PDF">pdf</a>, <a href="/format/2311.01609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Responsible Emergent Multi-Agent Behavior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grupen%2C+N+A">Niko A. Grupen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 234 pages, 46 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Responsible AI has risen to the forefront of the AI research community. As
neural network-based learning algorithms continue to permeate real-world
applications, the field of Responsible AI has played a large role in ensuring
that such systems maintain a high-level of human-compatibility. Despite this
progress, the state of the art in Responsible AI has ignored one crucial point:
human problems are multi-agent problems. Predominant approaches largely
consider the performance of a single AI system in isolation, but human problems
are, by their very nature, multi-agent. From driving in traffic to negotiating
economic policy, human problem-solving involves interaction and the interplay
of the actions and motives of multiple individuals.
<br />This dissertation develops the study of responsible emergent multi-agent
behavior, illustrating how researchers and practitioners can better understand
and shape multi-agent learning with respect to three pillars of Responsible AI:
interpretability, fairness, and robustness. First, I investigate multi-agent
interpretability, presenting novel techniques for understanding emergent
multi-agent behavior at multiple levels of granularity. With respect to
low-level interpretability, I examine the extent to which implicit
communication emerges as an aid to coordination in multi-agent populations. I
introduce a novel curriculum-driven method for learning high-performing
policies in difficult, sparse reward environments and show through a measure of
position-based social influence that multi-agent teams that learn sophisticated
coordination strategies exchange significantly more information through
implicit signals than lesser-coordinated agents. Then, at a high-level, I study
concept-based interpretability in the context of multi-agent learning. I
propose a novel method for learning intrinsically interpretable, concept-based
policies and show that it enables...
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01615" title="Abstract">arXiv:2311.01615</a> [<a href="/pdf/2311.01615" title="Download PDF">pdf</a>, <a href="/format/2311.01615" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FLAP: Fast Language-Audio Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yeh%2C+C">Ching-Feng Yeh</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+P">Po-Yao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+V">Vasu Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shang-Wen Li</a>, 
<a href="/search/cs?searchtype=author&query=Gosh%2C+G">Gargi Gosh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We propose Fast Language-Audio Pre-training (FLAP), a self-supervised
approach that efficiently and effectively learns aligned audio and language
representations through masking, contrastive learning and reconstruction. For
efficiency, FLAP randomly drops audio spectrogram tokens, focusing solely on
the remaining ones for self-supervision. Through inter-modal contrastive
learning, FLAP learns to align paired audio and text representations in a
shared latent space. Notably, FLAP leverages multiple augmented views via
masking for inter-modal contrast and learns to reconstruct the masked portion
of audio tokens. Moreover, FLAP leverages large language models (LLMs) to
augment the text inputs, contributing to improved performance. These approaches
lead to more robust and informative audio-text representations, enabling FLAP
to achieve state-of-the-art (SoTA) performance on audio-text retrieval tasks on
AudioCaps (achieving 53.0% R@1) and Clotho (achieving 25.5% R@1).
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01617" title="Abstract">arXiv:2311.01617</a> [<a href="/pdf/2311.01617" title="Download PDF">pdf</a>, <a href="/format/2311.01617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Look-Ahead Selective Plasticity for Continual Learning of Visual Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meshkinnejad%2C+R">Rouzbeh Meshkinnejad</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+J">Jie Mei</a>, 
<a href="/search/cs?searchtype=author&query=Lizotte%2C+D">Daniel Lizotte</a>, 
<a href="/search/cs?searchtype=author&query=Mohsenzadeh%2C+Y">Yalda Mohsenzadeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Contrastive representation learning has emerged as a promising technique for
continual learning as it can learn representations that are robust to
catastrophic forgetting and generalize well to unseen future tasks. Previous
work in continual learning has addressed forgetting by using previous task data
and trained models. Inspired by event models created and updated in the brain,
we propose a new mechanism that takes place during task boundaries, i.e., when
one task finishes and another starts. By observing the redundancy-inducing
ability of contrastive loss on the output of a neural network, our method
leverages the first few samples of the new task to identify and retain
parameters contributing most to the transfer ability of the neural network,
freeing up the remaining parts of the network to learn new features. We
evaluate the proposed methods on benchmark computer vision datasets including
CIFAR10 and TinyImagenet and demonstrate state-of-the-art performance in the
task-incremental, class-incremental, and domain-incremental continual learning
scenarios.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01619" title="Abstract">arXiv:2311.01619</a> [<a href="/pdf/2311.01619" title="Download PDF">pdf</a>, <a href="/format/2311.01619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InsPLAD: A Dataset and Benchmark for Power Line Asset Inspection in UAV  Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Silva%2C+A+L+B+V+e">Andr&#xe9; Luiz Buarque Vieira e Silva</a>, 
<a href="/search/cs?searchtype=author&query=de+Castro+Felix%2C+H">Heitor de Castro Felix</a>, 
<a href="/search/cs?searchtype=author&query=Sim%C3%B5es%2C+F+P+M">Franscisco Paulo Magalh&#xe3;es Sim&#xf5;es</a>, 
<a href="/search/cs?searchtype=author&query=Teichrieb%2C+V">Veronica Teichrieb</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+M+M+d">Michel Mozinho dos Santos</a>, 
<a href="/search/cs?searchtype=author&query=Santiago%2C+H">Hemir Santiago</a>, 
<a href="/search/cs?searchtype=author&query=Sgotti%2C+V">Virginia Sgotti</a>, 
<a href="/search/cs?searchtype=author&query=Neto%2C+H+L">Henrique Lott Neto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article has been accepted for publication in the International Journal of Remote Sensing, published by Taylor &amp; Francis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Power line maintenance and inspection are essential to avoid power supply
interruptions, reducing its high social and financial impacts yearly.
Automating power line visual inspections remains a relevant open problem for
the industry due to the lack of public real-world datasets of power line
components and their various defects to foster new research. This paper
introduces InsPLAD, a Power Line Asset Inspection Dataset and Benchmark
containing 10,607 high-resolution Unmanned Aerial Vehicles colour images. The
dataset contains seventeen unique power line assets captured from real-world
operating power lines. Additionally, five of those assets present six defects:
four of which are corrosion, one is a broken component, and one is a bird's
nest presence. All assets were labelled according to their condition, whether
normal or the defect name found on an image level. We thoroughly evaluate
state-of-the-art and popular methods for three image-level computer vision
tasks covered by InsPLAD: object detection, through the AP metric; defect
classification, through Balanced Accuracy; and anomaly detection, through the
AUROC metric. InsPLAD offers various vision challenges from uncontrolled
environments, such as multi-scale objects, multi-size class instances, multiple
objects per image, intra-class variation, cluttered background, distinct
point-of-views, perspective distortion, occlusion, and varied lighting
conditions. To the best of our knowledge, InsPLAD is the first large real-world
dataset and benchmark for power line asset inspection with multiple components
and defects for various computer vision tasks, with a potential impact to
improve state-of-the-art methods in the field. It will be publicly available in
its integrity on a repository with a thorough description. It can be found at
https://github.com/andreluizbvs/InsPLAD.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01620" title="Abstract">arXiv:2311.01620</a> [<a href="/pdf/2311.01620" title="Download PDF">pdf</a>, <a href="/format/2311.01620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ACQUIRED: A Dataset for Answering Counterfactual Questions In Real-Life  Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Te-Lin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Z">Zi-Yi Dou</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qingyuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yu Hou</a>, 
<a href="/search/cs?searchtype=author&query=Chandra%2C+N+R">Nischal Reddy Chandra</a>, 
<a href="/search/cs?searchtype=author&query=Freedman%2C+M">Marjorie Freedman</a>, 
<a href="/search/cs?searchtype=author&query=Weischedel%2C+R+M">Ralph M. Weischedel</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+N">Nanyun Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Multimodal counterfactual reasoning is a vital yet challenging ability for AI
systems. It involves predicting the outcomes of hypothetical circumstances
based on vision and language inputs, which enables AI models to learn from
failures and explore hypothetical scenarios. Despite its importance, there are
only a few datasets targeting the counterfactual reasoning abilities of
multimodal models. Among them, they only cover reasoning over synthetic
environments or specific types of events (e.g. traffic collisions), making them
hard to reliably benchmark the model generalization ability in diverse
real-world scenarios and reasoning dimensions. To overcome these limitations,
we develop a video question answering dataset, ACQUIRED: it consists of 3.9K
annotated videos, encompassing a wide range of event types and incorporating
both first and third-person viewpoints, which ensures a focus on real-world
diversity. In addition, each video is annotated with questions that span three
distinct dimensions of reasoning, including physical, social, and temporal,
which can comprehensively evaluate the model counterfactual abilities along
multiple aspects. We benchmark our dataset against several state-of-the-art
language-only and multimodal models and experimental results demonstrate a
significant performance gap (&gt;13%) between models and humans. The findings
suggest that multimodal counterfactual reasoning remains an open challenge and
ACQUIRED is a comprehensive and reliable benchmark for inspiring future
research in this direction.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01623" title="Abstract">arXiv:2311.01623</a> [<a href="/pdf/2311.01623" title="Download PDF">pdf</a>, <a href="/ps/2311.01623" title="Download PostScript">ps</a>, <a href="/format/2311.01623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VQPy: An Object-Oriented Approach to Modern Video Analytics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhenting Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hanchen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Pengzhan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Padmanabhan%2C+A">Arthi Padmanabhan</a>, 
<a href="/search/cs?searchtype=author&query=Latapie%2C+H">Hugo Latapie</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Harry Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Video analytics is widely used in contemporary systems and services. At the
forefront of video analytics are video queries that users develop to find
objects of particular interest. Building upon the insight that video objects
(e.g., human, animals, cars, etc.), the center of video analytics, are similar
in spirit to objects modeled by traditional object-oriented languages, we
propose to develop an object-oriented approach to video analytics. This
approach, named VQPy, consists of a frontend$\unicode{x2015}$a Python variant
with constructs that make it easy for users to express video objects and their
interactions$\unicode{x2015}$as well as an extensible backend that can
automatically construct and optimize pipelines based on video objects. We have
implemented and open-sourced VQPy, which has been productized in Cisco as part
of its DeepVision framework.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01630" title="Abstract">arXiv:2311.01630</a> [<a href="/pdf/2311.01630" title="Download PDF">pdf</a>, <a href="/format/2311.01630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizations of Matrix Multiplication can solve the Light Bulb  Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alman%2C+J">Josh Alman</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hengjie Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> abstract shortened for arxiv
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">In the light bulb problem, one is given uniformly random vectors $x_1,
\ldots, x_n, y_1, \ldots, y_n \in \{-1,1\}^d$. They are all chosen
independently except a planted pair $(x_{i^*}, y_{j^*})$ is chosen with
correlation $\rho&gt;0$. The goal is to find the planted pair. This problem was
introduced over 30 years ago by L.~Valiant, and is known to have many
applications in data analysis, statistics, and learning theory.
<br />The naive algorithm runs in $\Omega(n^2)$ time, and algorithms based on
Locality-Sensitive Hashing approach quadratic time as $\rho \to 0$. In 2012,
G.~Valiant gave a breakthrough algorithm using fast matrix multiplication that
runs in time $O(n^{(5-\omega)/(4-\omega)}) &lt; O(n^{1.615})$, no matter how small
$\rho&gt;0$ is. This was subsequently refined by Karppa, Kaski, and Kohonen in
2016 to $O(n^{2 \omega / 3}) &lt; O(n^{1.582})$.
<br />In this paper, we propose a new approach which can replace matrix
multiplication tensor with other tensors. Those tensors can omit some terms one
is supposed to compute, and include additional error terms. Our new approach
can make use of any tensors which previously had no known algorithmic
applications, including tensors which arise naturally as intermediate steps in
border rank methods and in the Laser method.
<br />We further show that our approach can be combined with locality-sensitive
hashing to design an algorithm whose running time improves as $\rho$ gets
larger. To our knowledge, this is the first algorithm which combines fast
matrix multiplication with hashing for the light bulb problem or any closest
pair problem, and it leads to faster algorithms for small $\rho&gt;0$.
<br />We also introduce a new tensor $T_{2112}$, which has the same size of $2
\times 2$ matrix multiplication tensor, but runs faster than the Strassen's
algorithm for light bulb problem.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01634" title="Abstract">arXiv:2311.01634</a> [<a href="/pdf/2311.01634" title="Download PDF">pdf</a>, <a href="/ps/2311.01634" title="Download PostScript">ps</a>, <a href="/format/2311.01634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Close...but not as good as an educator.&quot; -- Using ChatGPT to provide  formative feedback in large-class collaborative learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ponte%2C+C+D">Cory Dal Ponte</a>, 
<a href="/search/cs?searchtype=author&query=Dushyanthen%2C+S">Sathana Dushyanthen</a>, 
<a href="/search/cs?searchtype=author&query=Lyons%2C+K">Kayley Lyons</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 2 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">Delivering personalised, formative feedback to multiple problem-based
learning groups in a short time period can be almost impossible. We employed
ChatGPT to provide personalised formative feedback in a one-hour Zoom break-out
room activity that taught practicing health professionals how to formulate
evaluation plans for digital health initiatives. Learners completed an
evaluation survey that included Likert scales and open-ended questions that
were analysed. Half of the 44 survey respondents had never used ChatGPT before.
Overall, respondents found the feedback favourable, described a wide range of
group dynamics, and had adaptive responses to the feedback, yet only three
groups used the feedback loop to improve their evaluation plans. Future
educators can learn from our experience including engineering prompts,
providing instructions on how to use ChatGPT, and scaffolding optimal group
interactions with ChatGPT. Future researchers should explore the influence of
ChatGPT on group dynamics and derive design principles for the use of ChatGPT
in collaborative learning.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01635" title="Abstract">arXiv:2311.01635</a> [<a href="/pdf/2311.01635" title="Download PDF">pdf</a>, <a href="/format/2311.01635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RTP: Rethinking Tensor Parallelism with Memory Deduplication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+C">Cheng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+T">Tianle Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Fox%2C+G">Geoffrey Fox</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">In the evolving landscape of neural network models, one prominent challenge
stand out: the significant memory overheads associated with training expansive
models. Addressing this challenge, this study delves deep into the Rotated
Tensor Parallelism (RTP). RTP is an innovative approach that strategically
focuses on memory deduplication in distributed training environments. It boasts
of unique features like a customized communication primitive and the Flyweight
Pattern initialization. Furthermore, RTP ensures a seamless overlap between
partition computation and partition weight communication, optimizing the
training process. Our empirical evaluations underscore RTP's efficiency,
revealing that its memory consumption during distributed system training is
remarkably close to the optimal - distributing the memory overhead of a single
machine equitably among multiple machines. The experimental results demonstrate
that RTP is capable of achieving comparable performance to Distributed Data
Parallel while providing support for significantly larger models with
near-linear scalability in terms of memory. Code of RTP is available at
https://github.com/wdlctc/rtp.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01642" title="Abstract">arXiv:2311.01642</a> [<a href="/pdf/2311.01642" title="Download PDF">pdf</a>, <a href="/format/2311.01642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Adversarial Reinforcement Learning via Bounded Rationality  Curricula
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reddi%2C+A">Aryaman Reddi</a>, 
<a href="/search/cs?searchtype=author&query=T%C3%B6lle%2C+M">Maximilian T&#xf6;lle</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+J">Jan Peters</a>, 
<a href="/search/cs?searchtype=author&query=Chalvatzaki%2C+G">Georgia Chalvatzaki</a>, 
<a href="/search/cs?searchtype=author&query=D%27Eramo%2C+C">Carlo D&#x27;Eramo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Robustness against adversarial attacks and distribution shifts is a
long-standing goal of Reinforcement Learning (RL). To this end, Robust
Adversarial Reinforcement Learning (RARL) trains a protagonist against
destabilizing forces exercised by an adversary in a competitive zero-sum Markov
game, whose optimal solution, i.e., rational strategy, corresponds to a Nash
equilibrium. However, finding Nash equilibria requires facing complex saddle
point optimization problems, which can be prohibitive to solve, especially for
high-dimensional control. In this paper, we propose a novel approach for
adversarial RL based on entropy regularization to ease the complexity of the
saddle point optimization problem. We show that the solution of this
entropy-regularized problem corresponds to a Quantal Response Equilibrium
(QRE), a generalization of Nash equilibria that accounts for bounded
rationality, i.e., agents sometimes play random actions instead of optimal
ones. Crucially, the connection between the entropy-regularized objective and
QRE enables free modulation of the rationality of the agents by simply tuning
the temperature coefficient. We leverage this insight to propose our novel
algorithm, Quantal Adversarial RL (QARL), which gradually increases the
rationality of the adversary in a curriculum fashion until it is fully
rational, easing the complexity of the optimization problem while retaining
robustness. We provide extensive evidence of QARL outperforming RARL and recent
baselines across several MuJoCo locomotion and navigation problems in overall
performance and robustness.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01644" title="Abstract">arXiv:2311.01644</a> [<a href="/pdf/2311.01644" title="Download PDF">pdf</a>, <a href="/format/2311.01644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Should Under-parameterized Student Networks Copy or Average Teacher  Weights?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C5%9Eim%C5%9Fek%2C+B">Berfin &#x15e;im&#x15f;ek</a>, 
<a href="/search/cs?searchtype=author&query=Bendjeddou%2C+A">Amire Bendjeddou</a>, 
<a href="/search/cs?searchtype=author&query=Gerstner%2C+W">Wulfram Gerstner</a>, 
<a href="/search/cs?searchtype=author&query=Brea%2C+J">Johanni Brea</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, to appear at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)

</div>
<p class="mathjax">Any continuous function $f^*$ can be approximated arbitrarily well by a
neural network with sufficiently many neurons $k$. We consider the case when
$f^*$ itself is a neural network with one hidden layer and $k$ neurons.
Approximating $f^*$ with a neural network with $n&lt; k$ neurons can thus be seen
as fitting an under-parameterized "student" network with $n$ neurons to a
"teacher" network with $k$ neurons. As the student has fewer neurons than the
teacher, it is unclear, whether each of the $n$ student neurons should copy one
of the teacher neurons or rather average a group of teacher neurons. For
shallow neural networks with erf activation function and for the standard
Gaussian input distribution, we prove that "copy-average" configurations are
critical points if the teacher's incoming vectors are orthonormal and its
outgoing weights are unitary. Moreover, the optimum among such configurations
is reached when $n-1$ student neurons each copy one teacher neuron and the
$n$-th student neuron averages the remaining $k-n+1$ teacher neurons. For the
student network with $n=1$ neuron, we provide additionally a closed-form
solution of the non-trivial critical point(s) for commonly used activation
functions through solving an equivalent constrained optimization problem.
Empirically, we find for the erf activation function that gradient flow
converges either to the optimal copy-average critical point or to another point
where each student neuron approximately copies a different teacher neuron.
Finally, we find similar results for the ReLU activation function, suggesting
that the optimal solution of underparameterized networks has a universal
structure.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01646" title="Abstract">arXiv:2311.01646</a> [<a href="/pdf/2311.01646" title="Download PDF">pdf</a>, <a href="/format/2311.01646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SemiGPC: Distribution-Aware Label Refinement for Imbalanced  Semi-Supervised Learning Using Gaussian Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lemkhenter%2C+A">Abdelhak Lemkhenter</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Manchen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zancato%2C+L">Luca Zancato</a>, 
<a href="/search/cs?searchtype=author&query=Swaminathan%2C+G">Gurumurthy Swaminathan</a>, 
<a href="/search/cs?searchtype=author&query=Favaro%2C+P">Paolo Favaro</a>, 
<a href="/search/cs?searchtype=author&query=Modolo%2C+D">Davide Modolo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper we introduce SemiGPC, a distribution-aware label refinement
strategy based on Gaussian Processes where the predictions of the model are
derived from the labels posterior distribution. Differently from other
buffer-based semi-supervised methods such as CoMatch and SimMatch, our SemiGPC
includes a normalization term that addresses imbalances in the global data
distribution while maintaining local sensitivity. This explicit control allows
SemiGPC to be more robust to confirmation bias especially under class
imbalance. We show that SemiGPC improves performance when paired with different
Semi-Supervised methods such as FixMatch, ReMixMatch, SimMatch and FreeMatch
and different pre-training strategies including MSN and Dino. We also show that
SemiGPC achieves state of the art results under different degrees of class
imbalance on standard CIFAR10-LT/CIFAR100-LT especially in the low data-regime.
Using SemiGPC also results in about 2% avg.accuracy increase compared to a new
competitive baseline on the more challenging benchmarks SemiAves, SemiCUB,
SemiFungi and Semi-iNat.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01647" title="Abstract">arXiv:2311.01647</a> [<a href="/pdf/2311.01647" title="Download PDF">pdf</a>, <a href="/ps/2311.01647" title="Download PostScript">ps</a>, <a href="/format/2311.01647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Calibrate and Boost Logical Expressiveness of GNN Over Multi-Relational  and Temporal Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yeyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dingmin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">As a powerful framework for graph representation learning, Graph Neural
Networks (GNNs) have garnered significant attention in recent years. However,
to the best of our knowledge, there has been no formal analysis of the logical
expressiveness of GNNs as Boolean node classifiers over multi-relational
graphs, where each edge carries a specific relation type. In this paper, we
investigate $\mathcal{FOC}_2$, a fragment of first-order logic with two
variables and counting quantifiers. On the negative side, we demonstrate that
the R$^2$-GNN architecture, which extends the local message passing GNN by
incorporating global readout, fails to capture $\mathcal{FOC}_2$ classifiers in
the general case. Nevertheless, on the positive side, we establish that
R$^2$-GNNs models are equivalent to $\mathcal{FOC}_2$ classifiers under certain
restricted yet reasonable scenarios. To address the limitations of R$^2$-GNNs
regarding expressiveness, we propose a simple graph transformation technique,
akin to a preprocessing step, which can be executed in linear time. This
transformation enables R$^2$-GNNs to effectively capture any $\mathcal{FOC}_2$
classifiers when applied to the "transformed" input graph. Moreover, we extend
our analysis of expressiveness and graph transformation to temporal graphs,
exploring several temporal GNN architectures and providing an expressiveness
hierarchy for them. To validate our findings, we implement R$^2$-GNNs and the
graph transformation technique and conduct empirical tests in node
classification tasks against various well-known GNN architectures that support
multi-relational or temporal graphs. Our experimental results consistently
demonstrate that R$^2$-GNN with the graph transformation outperforms the
baseline methods on both synthetic and real-world datasets
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01650" title="Abstract">arXiv:2311.01650</a> [<a href="/pdf/2311.01650" title="Download PDF">pdf</a>, <a href="/format/2311.01650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MARRS: Multimodal Reference Resolution System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ates%2C+H+C">Halim Cagri Ates</a>, 
<a href="/search/cs?searchtype=author&query=Bhargava%2C+S">Shruti Bhargava</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Site Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiarui Lu</a>, 
<a href="/search/cs?searchtype=author&query=Maddula%2C+S">Siddhardha Maddula</a>, 
<a href="/search/cs?searchtype=author&query=Moniz%2C+J+R+A">Joel Ruben Antony Moniz</a>, 
<a href="/search/cs?searchtype=author&query=Nalamalapu%2C+A+K">Anil Kumar Nalamalapu</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+R+H">Roman Hoang Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Ozyildirim%2C+M">Melis Ozyildirim</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+A">Alkesh Patel</a>, 
<a href="/search/cs?searchtype=author&query=Piraviperumal%2C+D">Dhivya Piraviperumal</a>, 
<a href="/search/cs?searchtype=author&query=Renkens%2C+V">Vincent Renkens</a>, 
<a href="/search/cs?searchtype=author&query=Samal%2C+A">Ankit Samal</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+T">Thy Tran</a>, 
<a href="/search/cs?searchtype=author&query=Tseng%2C+B">Bo-Hsiang Tseng</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+R">Rong Zou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Sixth Workshop on Computational Models of Reference, Anaphora and Coreference (CRAC 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Successfully handling context is essential for any dialog understanding task.
This context maybe be conversational (relying on previous user queries or
system responses), visual (relying on what the user sees, for example, on their
screen), or background (based on signals such as a ringing alarm or playing
music). In this work, we present an overview of MARRS, or Multimodal Reference
Resolution System, an on-device framework within a Natural Language
Understanding system, responsible for handling conversational, visual and
background context. In particular, we present different machine learning models
to enable handing contextual queries; specifically, one to enable reference
resolution, and one to handle context via query rewriting. We also describe how
these models complement each other to form a unified, coherent, lightweight
system that can understand context while preserving user privacy.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01651" title="Abstract">arXiv:2311.01651</a> [<a href="/pdf/2311.01651" title="Download PDF">pdf</a>, <a href="/ps/2311.01651" title="Download PostScript">ps</a>, <a href="/format/2311.01651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Keypoint Description by Symmetry Assessment -- Applications in  Biometrics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mikaelyan%2C+A">Anna Mikaelyan</a>, 
<a href="/search/cs?searchtype=author&query=Alonso-Fernandez%2C+F">Fernando Alonso-Fernandez</a>, 
<a href="/search/cs?searchtype=author&query=Bigun%2C+J">Josef Bigun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present a model-based feature extractor to describe neighborhoods around
keypoints by finite expansion, estimating the spatially varying orientation by
harmonic functions. The iso-curves of such functions are highly symmetric
w.r.t. the origin (a keypoint) and the estimated parameters have well defined
geometric interpretations. The origin is also a unique singularity of all
harmonic functions, helping to determine the location of a keypoint precisely,
whereas the functions describe the object shape of the neighborhood. This is
novel and complementary to traditional texture features which describe
texture-shape properties i.e. they are purposively invariant to translation
(within a texture). We report on experiments of verification and identification
of keypoints in forensic fingerprints by using publicly available data (NIST
SD27) and discuss the results in comparison to other studies. These support our
conclusions that the novel features can equip single cores or single minutia
with a significant verification power at 19% EER, and an identification power
of 24-78% for ranks of 1-20. Additionally, we report verification results of
periocular biometrics using near-infrared images, reaching an EER performance
of 13%, which is comparable to the state of the art. More importantly, fusion
of two systems, our and texture features (Gabor), result in a measurable
performance improvement. We report reduction of the EER to 9%, supporting the
view that the novel features capture relevant visual information, which
traditional texture features do not.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01655" title="Abstract">arXiv:2311.01655</a> [<a href="/pdf/2311.01655" title="Download PDF">pdf</a>, <a href="/format/2311.01655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Spurious Correlations via Robust Visual Concepts in Real and  AI-Generated Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dammu%2C+P+P+S">Preetam Prabhu Srikar Dammu</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+C">Chirag Shah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted at 37th Conference on Neural Information Processing Systems (NeurIPS 2023), XAIA Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Often machine learning models tend to automatically learn associations
present in the training data without questioning their validity or
appropriateness. This undesirable property is the root cause of the
manifestation of spurious correlations, which render models unreliable and
prone to failure in the presence of distribution shifts. Research shows that
most methods attempting to remedy spurious correlations are only effective for
a model's known spurious associations. Current spurious correlation detection
algorithms either rely on extensive human annotations or are too restrictive in
their formulation. Moreover, they rely on strict definitions of visual
artifacts that may not apply to data produced by generative models, as they are
known to hallucinate contents that do not conform to standard specifications.
In this work, we introduce a general-purpose method that efficiently detects
potential spurious correlations, and requires significantly less human
interference in comparison to the prior art. Additionally, the proposed method
provides intuitive explanations while eliminating the need for pixel-level
annotations. We demonstrate the proposed method's tolerance to the peculiarity
of AI-generated images, which is a considerably challenging task, one where
most of the existing methods fall short. Consequently, our method is also
suitable for detecting spurious correlations that may propagate to downstream
applications originating from generative models.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01659" title="Abstract">arXiv:2311.01659</a> [<a href="/pdf/2311.01659" title="Download PDF">pdf</a>, <a href="/format/2311.01659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Cloud Pipelines for Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jacoby%2C+D">Derek Jacoby</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Donglin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ribas%2C+W">Weder Ribas</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Minyi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Ting Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jayaraman%2C+V">Vishwanath Jayaraman</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+M">Mengdi Wei</a>, 
<a href="/search/cs?searchtype=author&query=De+Blois%2C+E">Emma De Blois</a>, 
<a href="/search/cs?searchtype=author&query=Coady%2C+Y">Yvonne Coady</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Since their introduction in 2020, Neural Radiance Fields (NeRFs) have taken
the computer vision community by storm. They provide a multi-view
representation of a scene or object that is ideal for eXtended Reality (XR)
applications and for creative endeavors such as virtual production, as well as
change detection operations in geospatial analytics. The computational cost of
these generative AI models is quite high, however, and the construction of
cloud pipelines to generate NeRFs is neccesary to realize their potential in
client applications. In this paper, we present pipelines on a high performance
academic computing cluster and compare it with a pipeline implemented on
Microsoft Azure. Along the way, we describe some uses of NeRFs in enabling
novel user interaction scenarios.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01660" title="Abstract">arXiv:2311.01660</a> [<a href="/pdf/2311.01660" title="Download PDF">pdf</a>, <a href="/format/2311.01660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximum Likelihood Estimation of Flexible Survival Densities with  Importance Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ketenci%2C+M">Mert Ketenci</a>, 
<a href="/search/cs?searchtype=author&query=Bhave%2C+S">Shreyas Bhave</a>, 
<a href="/search/cs?searchtype=author&query=Elhadad%2C+N">No&#xe9;mie Elhadad</a>, 
<a href="/search/cs?searchtype=author&query=Perotte%2C+A">Adler Perotte</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Survival analysis is a widely-used technique for analyzing time-to-event data
in the presence of censoring. In recent years, numerous survival analysis
methods have emerged which scale to large datasets and relax traditional
assumptions such as proportional hazards. These models, while being performant,
are very sensitive to model hyperparameters including: (1) number of bins and
bin size for discrete models and (2) number of cluster assignments for
mixture-based models. Each of these choices requires extensive tuning by
practitioners to achieve optimal performance. In addition, we demonstrate in
empirical studies that: (1) optimal bin size may drastically differ based on
the metric of interest (e.g., concordance vs brier score), and (2) mixture
models may suffer from mode collapse and numerical instability. We propose a
survival analysis approach which eliminates the need to tune hyperparameters
such as mixture assignments and bin sizes, reducing the burden on
practitioners. We show that the proposed approach matches or outperforms
baselines on several real-world datasets.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01661" title="Abstract">arXiv:2311.01661</a> [<a href="/pdf/2311.01661" title="Download PDF">pdf</a>, <a href="/ps/2311.01661" title="Download PostScript">ps</a>, <a href="/format/2311.01661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning-driven Community Resilience Rating based on Intertwined  Socio-Technical Systems Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+K">Kai Yin</a>, 
<a href="/search/cs?searchtype=author&query=Mostafavi%2C+A">Ali Mostafavi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Community resilience is a complex and muti-faceted phenomenon that emerges
from complex and nonlinear interactions among different socio-technical systems
and their resilience properties. However, present studies on community
resilience focus primarily on vulnerability assessment and utilize index-based
approaches, with limited ability to capture heterogeneous features within
community socio-technical systems and their nonlinear interactions in shaping
robustness, redundancy, and resourcefulness components of resilience. To
address this gap, this paper presents an integrated three-layer deep learning
model for community resilience rating (called Resili-Net). Twelve measurable
resilience features are specified and computed within community socio-technical
systems (i.e., facilities, infrastructures, and society) related to three
resilience components of robustness, redundancy, and resourcefulness. Using
publicly accessible data from multiple metropolitan statistical areas in the
United States, Resili-Net characterizes the resilience levels of spatial areas
into five distinct levels. The interpretability of the model outcomes enables
feature analysis for specifying the determinants of resilience in areas within
each resilience level, allowing for the identification of specific resilience
enhancement strategies. Changes in community resilience profiles under urban
development patterns are further examined by changing the value of related
socio-technical systems features. Accordingly, the outcomes provide novel
perspectives for community resilience assessment by harnessing machine
intelligence and heterogeneous urban big data.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01662" title="Abstract">arXiv:2311.01662</a> [<a href="/pdf/2311.01662" title="Download PDF">pdf</a>, <a href="/format/2311.01662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparando Estrat&#xe9;gias de Roteamento em Redes Qu&#xe2;nticas  Oportun&#xed;sticas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abreu%2C+D">Diego Abreu</a>, 
<a href="/search/cs?searchtype=author&query=Veloso%2C+A">Alan Veloso</a>, 
<a href="/search/cs?searchtype=author&query=Abel%C3%A9m%2C+A">Antonio Abel&#xe9;m</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> XIII Confer\^encia Nacional em Comunica\c{c}\~oes, Redes e Seguran\c{c}a da Informa\c{c}\~ao, in Portuguese language
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Emerging Technologies (cs.ET); Quantum Physics (quant-ph)

</div>
<p class="mathjax">This paper presents a comparative analysis of three routing strategies in
opportunistic quantum networks. Quantum communication networks face unique
challenges, such as the fragility of qubits and the need to create and maintain
pairs of entangled states for reliable transmission. In this context, efficient
and reliable routing is crucial to maximize the fidelity of the established
routes, minimize the creation of new entangled pairs, and reduce the need for
route recalculation. The routing strategies are compared based on the fidelity
of the chosen routes, the number of entangled pairs created, and the number of
route recalculations. The results obtained provide valuable information for the
design and optimization of opportunistic quantum networks, contributing to
advances in the efficiency and reliability of quantum communications.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01666" title="Abstract">arXiv:2311.01666</a> [<a href="/pdf/2311.01666" title="Download PDF">pdf</a>, <a href="/format/2311.01666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Plot Retrieval as an Assessment of Abstract Semantic Association
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shicheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+L">Liang Pang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiangnan Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+M">Mo Yu</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+F">Fandong Meng</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Huawei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xueqi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Retrieving relevant plots from the book for a query is a critical task, which
can improve the reading experience and efficiency of readers. Readers usually
only give an abstract and vague description as the query based on their own
understanding, summaries, or speculations of the plot, which requires the
retrieval model to have a strong ability to estimate the abstract semantic
associations between the query and candidate plots. However, existing
information retrieval (IR) datasets cannot reflect this ability well. In this
paper, we propose Plot Retrieval, a labeled dataset to train and evaluate the
performance of IR models on the novel task Plot Retrieval. Text pairs in Plot
Retrieval have less word overlap and more abstract semantic association, which
can reflect the ability of the IR models to estimate the abstract semantic
association, rather than just traditional lexical or semantic matching.
Extensive experiments across various lexical retrieval, sparse retrieval, dense
retrieval, and cross-encoder methods compared with human studies on Plot
Retrieval show current IR models still struggle in capturing abstract semantic
association between texts. Plot Retrieval can be the benchmark for further
research on the semantic association modeling ability of IR models.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01673" title="Abstract">arXiv:2311.01673</a> [<a href="/pdf/2311.01673" title="Download PDF">pdf</a>, <a href="/format/2311.01673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Content Significance Distribution of Sub-Text Blocks in Articles and Its  Application to Article-Organization Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">You Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jie Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We explore how to capture the significance of a sub-text block in an article
and how it may be used for text mining tasks. A sub-text block is a
sub-sequence of sentences in the article. We formulate the notion of content
significance distribution (CSD) of sub-text blocks, referred to as CSD of the
first kind and denoted by CSD-1. In particular, we leverage Hugging Face's
SentenceTransformer to generate contextual sentence embeddings, and use
MoverScore over text embeddings to measure how similar a sub-text block is to
the entire text. To overcome the exponential blowup on the number of sub-text
blocks, we present an approximation algorithm and show that the approximated
CSD-1 is almost identical to the exact CSD-1. Under this approximation, we show
that the average and median CSD-1's for news, scholarly research, argument, and
narrative articles share the same pattern. We also show that under a certain
linear transformation, the complement of the cumulative distribution function
of the beta distribution with certain values of $\alpha$ and $\beta$ resembles
a CSD-1 curve. We then use CSD-1's to extract linguistic features to train an
SVC classifier for assessing how well an article is organized. Through
experiments, we show that this method achieves high accuracy for assessing
student essays. Moreover, we study CSD of sentence locations, referred to as
CSD of the second kind and denoted by CSD-2, and show that average CSD-2's for
different types of articles possess distinctive patterns, which either conform
common perceptions of article structures or provide rectification with minor
deviation.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01676" title="Abstract">arXiv:2311.01676</a> [<a href="/pdf/2311.01676" title="Download PDF">pdf</a>, <a href="/format/2311.01676" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MineSegSAT: An automated system to evaluate mining disturbed area  extents from Sentinel-2 imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=MacDonald%2C+E">Ezra MacDonald</a>, 
<a href="/search/cs?searchtype=author&query=Jacoby%2C+D">Derek Jacoby</a>, 
<a href="/search/cs?searchtype=author&query=Coady%2C+Y">Yvonne Coady</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Assessing the environmental impact of the mineral extraction industry plays a
critical role in understanding and mitigating the ecological consequences of
extractive activities. This paper presents MineSegSAT, a model that presents a
novel approach to predicting environmentally impacted areas of mineral
extraction sites using the SegFormer deep learning segmentation architecture
trained on Sentinel-2 data. The data was collected from non-overlapping regions
over Western Canada in 2021 containing areas of land that have been
environmentally impacted by mining activities that were identified from
high-resolution satellite imagery in 2021. The SegFormer architecture, a
state-of-the-art semantic segmentation framework, is employed to leverage its
advanced spatial understanding capabilities for accurate land cover
classification. We investigate the efficacy of loss functions including Dice,
Tversky, and Lovasz loss respectively. The trained model was utilized for
inference over the test region in the ensuing year to identify potential areas
of expansion or contraction over these same periods. The Sentinel-2 data is
made available on Amazon Web Services through a collaboration with Earth Daily
Analytics which provides corrected and tiled analytics-ready data on the AWS
platform. The model and ongoing API to access the data on AWS allow the
creation of an automated tool to monitor the extent of disturbed areas
surrounding known mining sites to ensure compliance with their environmental
impact goals.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01677" title="Abstract">arXiv:2311.01677</a> [<a href="/pdf/2311.01677" title="Download PDF">pdf</a>, <a href="/format/2311.01677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DialogBench: Evaluating LLMs as Human-like Dialogue Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ou%2C+J">Jiao Ou</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Junda Lu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Che Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yihong Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fuzheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Di Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhongyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gai%2C+K">Kun Gai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 9 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) have achieved remarkable breakthroughs in new
dialogue capabilities, refreshing human's impressions on dialogue systems. The
long-standing goal of dialogue systems is to be human-like enough to establish
long-term connections with users by satisfying the need for communication,
affection and social belonging. Therefore, there has been an urgent need to
evaluate LLMs as human-like dialogue systems. In this paper, we propose
DialogBench, a dialogue evaluation benchmark that currently contains $12$
dialogue tasks to assess the capabilities of LLMs as human-like dialogue
systems should have. Specifically, we prompt GPT-4 to generate evaluation
instances for each task. We first design the basic prompt based on widely-used
design principles and further mitigate the existing biases to generate
higher-quality evaluation instances. Our extensive test over $28$ LLMs
(including pre-trained and supervised instruction-tuning) shows that
instruction fine-tuning benefits improve the human likeness of LLMs to a
certain extent, but there is still much room to improve those capabilities for
most LLMs as human-like dialogue systems. In addition, experimental results
also indicate that LLMs perform differently in various abilities that
human-like dialogue systems should have. We will publicly release DialogBench,
along with the associated evaluation code for the broader research community.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01678" title="Abstract">arXiv:2311.01678</a> [<a href="/pdf/2311.01678" title="Download PDF">pdf</a>, <a href="/ps/2311.01678" title="Download PostScript">ps</a>, <a href="/format/2311.01678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reduce, Reuse, Recycle: Building Greener Sustainable Software
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dutta%2C+K">Kaushik Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Vandermeer%2C+D">Debra Vandermeer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Performance (cs.PF)

</div>
<p class="mathjax">Technology use has grown rapidly in recent years. It is infused in virtually
every aspect of organizational and individual life. This technology runs on
servers, typically in data centers. As workloads grow, more serves are
required. Each server incrementally adds to the energy consumption footprint of
a data center. Currently, data centers account for more than one percent of all
power usage worldwide. Clearly, energy efficiency is a significant concern for
data centers. While many aspects of data center energy efficiency have received
attention, energy consumption is rarely considered in software development
organizations. In this work, we consider the energy consumption impacts of
fundamental software operations, and demonstrate that non-trivial energy
savings can be achieved in software by making energy-conscious decisions
regarding basic aspects of programming. This work has significant potential for
practical impact; applying the lessons learned in this study can lead to
greener sustainable software.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01680" title="Abstract">arXiv:2311.01680</a> [<a href="/pdf/2311.01680" title="Download PDF">pdf</a>, <a href="/ps/2311.01680" title="Download PostScript">ps</a>, <a href="/format/2311.01680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Case for Sustainability and Environment Friendliness in Software  Development and Architecture Decisions by Taking Energy-Efficient Design  Decisions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dutta%2C+K">Kaushik Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Vandermeer%2C+D">Debra Vandermeer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">IT power usage is a significant concern. Data center energy consumption is
estimated to account for 1% to 1.5% of all energy consumption worldwide.
Hardware designers, data center designers, and other members of the IT
community have been working to improve energy efficiency across many parts of
the IT infrastructure; however, little attention has been paid to the energy
efficiency of software components. Indeed, energy efficiency is currently not a
common performance criteria for software. In this work, we attempt to quantify
the potential for gains in energy efficiency in software, based on a set of
examples drawn from common, everyday decisions made by software developers and
enterprise architects. Our results show that there is potential for significant
energy savings through energy-conscious choices at software development and
selection time, making the software and IT artifact sustainable and environment
friendly.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01682" title="Abstract">arXiv:2311.01682</a> [<a href="/pdf/2311.01682" title="Download PDF">pdf</a>, <a href="/format/2311.01682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flow-Based Feature Fusion for Vehicle-Infrastructure Cooperative 3D  Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Haibao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yingjuan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+E">Enze Xie</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+J">Jilei Mao</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+Z">Zaiqing Nie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPs2023. arXiv admin note: text overlap with <a href="/abs/2303.10552">arXiv:2303.10552</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Cooperatively utilizing both ego-vehicle and infrastructure sensor data can
significantly enhance autonomous driving perception abilities. However, the
uncertain temporal asynchrony and limited communication conditions can lead to
fusion misalignment and constrain the exploitation of infrastructure data. To
address these issues in vehicle-infrastructure cooperative 3D (VIC3D) object
detection, we propose the Feature Flow Net (FFNet), a novel cooperative
detection framework. FFNet is a flow-based feature fusion framework that uses a
feature flow prediction module to predict future features and compensate for
asynchrony. Instead of transmitting feature maps extracted from still-images,
FFNet transmits feature flow, leveraging the temporal coherence of sequential
infrastructure frames. Furthermore, we introduce a self-supervised training
approach that enables FFNet to generate feature flow with feature prediction
ability from raw infrastructure sequences. Experimental results demonstrate
that our proposed method outperforms existing cooperative detection methods
while only requiring about 1/100 of the transmission cost of raw data and
covers all latency in one model on the DAIR-V2X dataset. The code is available
at
\href{https://github.com/haibao-yu/FFNet-VIC3D}{https://github.com/haibao-yu/FFNet-VIC3D}.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01684" title="Abstract">arXiv:2311.01684</a> [<a href="/pdf/2311.01684" title="Download PDF">pdf</a>, <a href="/format/2311.01684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CASE: Commonsense-Augmented Score with an Expanded Answer Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenkai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ravi%2C+S">Sahithya Ravi</a>, 
<a href="/search/cs?searchtype=author&query=Shwartz%2C+V">Vered Shwartz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">LLMs have demonstrated impressive zero-shot performance on NLP tasks thanks
to the knowledge they acquired in their training. In multiple-choice QA tasks,
the LM probabilities are used as an imperfect measure of the plausibility of
each answer choice. One of the major limitations of the basic score is that it
treats all words as equally important. We propose CASE, a Commonsense-Augmented
Score with an Expanded Answer Space. CASE addresses this limitation by
assigning importance weights for individual words based on their semantic
relations to other words in the input. The dynamic weighting approach
outperforms basic LM scores, not only because it reduces noise from unimportant
words, but also because it informs the model of implicit commonsense knowledge
that may be useful for answering the question. We then also follow prior work
in expanding the answer space by generating lexically-divergent answers that
are conceptually-similar to the choices. When combined with answer space
expansion, our method outperforms strong baselines on 5 commonsense benchmarks.
We further show these two approaches are complementary and may be especially
beneficial when using smaller LMs.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01686" title="Abstract">arXiv:2311.01686</a> [<a href="/pdf/2311.01686" title="Download PDF">pdf</a>, <a href="/format/2311.01686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disentangled Representation Learning with Transmitted Information  Bottleneck
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dang%2C+Z">Zhuohang Dang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+M">Minnan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+C">Chengyou Jia</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+G">Guang Dai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jihong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xiaojun Chang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingdong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Q">Qinghua Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Encoding only the task-related information from the raw data, \ie,
disentangled representation learning, can greatly contribute to the robustness
and generalizability of models. Although significant advances have been made by
regularizing the information in representations with information theory, two
major challenges remain: 1) the representation compression inevitably leads to
performance drop; 2) the disentanglement constraints on representations are in
complicated optimization. To these issues, we introduce Bayesian networks with
transmitted information to formulate the interaction among input and
representations during disentanglement. Building upon this framework, we
propose \textbf{DisTIB} (\textbf{T}ransmitted \textbf{I}nformation
\textbf{B}ottleneck for \textbf{Dis}entangled representation learning), a novel
objective that navigates the balance between information compression and
preservation. We employ variational inference to derive a tractable estimation
for DisTIB. This estimation can be simply optimized via standard gradient
descent with a reparameterization trick. Moreover, we theoretically prove that
DisTIB can achieve optimal disentanglement, underscoring its superior efficacy.
To solidify our claims, we conduct extensive experiments on various downstream
tasks to demonstrate the appealing efficacy of DisTIB and validate our
theoretical analyses.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01689" title="Abstract">arXiv:2311.01689</a> [<a href="/pdf/2311.01689" title="Download PDF">pdf</a>, <a href="/format/2311.01689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Free Distillation of Language Model by Text-to-Text Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+Z">Zheyuan Bai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinduo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hailin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+T">Tianyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qinghua Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunhe Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Data-Free Knowledge Distillation (DFKD) plays a vital role in compressing the
model when original training data is unavailable. Previous works for DFKD in
NLP mainly focus on distilling encoder-only structures like BERT on
classification tasks, which overlook the notable progress of generative
language modeling. In this work, we propose a novel DFKD framework, namely
DFKD-T$^{3}$, where the pretrained generative language model can also serve as
a controllable data generator for model compression. This novel framework
DFKD-T$^{3}$ leads to an end-to-end learnable text-to-text framework to
transform the general domain corpus to compression-friendly task data,
targeting to improve both the \textit{specificity} and \textit{diversity}.
Extensive experiments show that our method can boost the distillation
performance in various downstream tasks such as sentiment analysis, linguistic
acceptability, and information extraction. Furthermore, we show that the
generated texts can be directly used for distilling other language models and
outperform the SOTA methods, making our method more appealing in a general DFKD
setting. Our code is available at
https://gitee.com/mindspore/models/tree/master/research/nlp/DFKD\_T3.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01693" title="Abstract">arXiv:2311.01693</a> [<a href="/pdf/2311.01693" title="Download PDF">pdf</a>, <a href="/format/2311.01693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Computer Science Education with Pair Programming and Problem  Solving Studios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Orr%2C+J+W">J. Walker Orr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">This study examines the adaptation of the problem-solving studio to computer
science education by combining it with pair programming. Pair programming is a
software engineering practice in industry, but has seen mixed results in the
classroom. Recent research suggests that pair programming has promise and
potential to be an effective pedagogical tool, however what constitutes good
instructional design and implementation for pair programming in the classroom
is not clear. We developed a framework for instructional design for pair
programming by adapting the problem-solving studio (PSS), a pedagogy originally
from biomedical engineering. PSS involves teams of students solving open-ended
problems with real-time feedback given by the instructor. Notably, PSS uses
problems of adjustable difficulty to keep students of all levels engaged and
functioning within the zone of proximal development. The course structure has
three stages, first starting with demonstration, followed by a PSS session,
then finishing with a debrief. We studied the combination of PSS and pair
programming in a CS1 class over three years. Surveys of the students report a
high level of engagement, learning, and motivation.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01695" title="Abstract">arXiv:2311.01695</a> [<a href="/pdf/2311.01695" title="Download PDF">pdf</a>, <a href="/format/2311.01695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication-Efficient Federated Non-Linear Bandit Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chuanhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu-Xiang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated optimization studies the problem of collaborative function
optimization among multiple clients (e.g. mobile devices or organizations)
under the coordination of a central server. Since the data is collected
separately by each client and always remains decentralized, federated
optimization preserves data privacy and allows for large-scale computing, which
makes it a promising decentralized machine learning paradigm. Though it is
often deployed for tasks that are online in nature, e.g., next-word prediction
on keyboard apps, most works formulate it as an offline problem. The few
exceptions that consider federated bandit optimization are limited to very
simplistic function classes, e.g., linear, generalized linear, or
non-parametric function class with bounded RKHS norm, which severely hinders
its practical usage. In this paper, we propose a new algorithm, named
Fed-GO-UCB, for federated bandit optimization with generic non-linear objective
function. Under some mild conditions, we rigorously prove that Fed-GO-UCB is
able to achieve sub-linear rate for both cumulative regret and communication
cost. At the heart of our theoretical analysis are distributed regression
oracle and individual confidence set construction, which can be of independent
interests. Empirical evaluations also demonstrate the effectiveness of the
proposed algorithm.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01696" title="Abstract">arXiv:2311.01696</a> [<a href="/pdf/2311.01696" title="Download PDF">pdf</a>, <a href="/format/2311.01696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Perturbation-based Secret Key-Controlled Data Hiding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Donghua Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+W">Wen Yao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+T">Tingsong Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaoqian Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 8 tables, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Deep neural networks (DNNs) are demonstrated to be vulnerable to universal
perturbation, a single quasi-perceptible perturbation that can deceive the DNN
on most images. However, the previous works are focused on using universal
perturbation to perform adversarial attacks, while the potential usability of
universal perturbation as data carriers in data hiding is less explored,
especially for the key-controlled data hiding method. In this paper, we propose
a novel universal perturbation-based secret key-controlled data-hiding method,
realizing data hiding with a single universal perturbation and data decoding
with the secret key-controlled decoder. Specifically, we optimize a single
universal perturbation, which serves as a data carrier that can hide multiple
secret images and be added to most cover images. Then, we devise a secret
key-controlled decoder to extract different secret images from the single
container image constructed by the universal perturbation by using different
secret keys. Moreover, a suppress loss function is proposed to prevent the
secret image from leakage. Furthermore, we adopt a robust module to boost the
decoder's capability against corruption. Finally, A co-joint optimization
strategy is proposed to find the optimal universal perturbation and decoder.
Extensive experiments are conducted on different datasets to demonstrate the
effectiveness of the proposed method. Additionally, the physical test performed
on platforms (e.g., WeChat and Twitter) verifies the usability of the proposed
method in practice.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01697" title="Abstract">arXiv:2311.01697</a> [<a href="/pdf/2311.01697" title="Download PDF">pdf</a>, <a href="/format/2311.01697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CraterGrader: Autonomous Robotic Terrain Manipulation for Lunar Site  Preparation and Earthmoving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+R">Ryan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Younes%2C+B">Benjamin Younes</a>, 
<a href="/search/cs?searchtype=author&query=Pletta%2C+A">Alexander Pletta</a>, 
<a href="/search/cs?searchtype=author&query=Harrington%2C+J">John Harrington</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+R+Q">Russell Q. Wong</a>, 
<a href="/search/cs?searchtype=author&query=Whittaker%2C+W+%22">William &quot;Red&quot; Whittaker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Establishing lunar infrastructure is paramount to long-term habitation on the
Moon. To meet the demand for future lunar infrastructure development, we
present CraterGrader, a novel system for autonomous robotic earthmoving tasks
within lunar constraints. In contrast to the current approaches to construction
autonomy, CraterGrader uses online perception for dynamic mapping of deformable
terrain, devises an energy-efficient material movement plan using an
optimization-based transport planner, precisely localizes without GPS, and uses
integrated drive and tool control to manipulate regolith with unknown and
non-constant geotechnical parameters. We demonstrate CraterGrader's ability to
achieve unprecedented performance in autonomous smoothing and grading within a
lunar-like environment, showing that this framework is capable, robust, and a
benchmark for future planetary site preparation robotics.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01698" title="Abstract">arXiv:2311.01698</a> [<a href="/pdf/2311.01698" title="Download PDF">pdf</a>, <a href="/format/2311.01698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Attacks on Cooperative Multi-agent Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zuo%2C+J">Jinhang Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiyao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuchuang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Cheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuai Li</a>, 
<a href="/search/cs?searchtype=author&query=Lui%2C+J+C+S">John C.S. Lui</a>, 
<a href="/search/cs?searchtype=author&query=Hajiesmaili%2C+M">Mohammad Hajiesmaili</a>, 
<a href="/search/cs?searchtype=author&query=Wierman%2C+A">Adam Wierman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Cooperative multi-agent multi-armed bandits (CMA2B) consider the
collaborative efforts of multiple agents in a shared multi-armed bandit game.
We study latent vulnerabilities exposed by this collaboration and consider
adversarial attacks on a few agents with the goal of influencing the decisions
of the rest. More specifically, we study adversarial attacks on CMA2B in both
homogeneous settings, where agents operate with the same arm set, and
heterogeneous settings, where agents have distinct arm sets. In the homogeneous
setting, we propose attack strategies that, by targeting just one agent,
convince all agents to select a particular target arm $T-o(T)$ times while
incurring $o(T)$ attack costs in $T$ rounds. In the heterogeneous setting, we
prove that a target arm attack requires linear attack costs and propose attack
strategies that can force a maximum number of agents to suffer linear regrets
while incurring sublinear costs and only manipulating the observations of a few
target agents. Numerical experiments validate the effectiveness of our proposed
attack strategies.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01703" title="Abstract">arXiv:2311.01703</a> [<a href="/pdf/2311.01703" title="Download PDF">pdf</a>, <a href="/format/2311.01703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taking a PEEK into YOLOv5 for Satellite Component Recognition via  Entropy-based Visual Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meni%2C+M+J">Mackenzie J. Meni</a>, 
<a href="/search/cs?searchtype=author&query=Mahendrakar%2C+T">Trupti Mahendrakar</a>, 
<a href="/search/cs?searchtype=author&query=Raney%2C+O+D+M">Olivia D. M. Raney</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+R+T">Ryan T. White</a>, 
<a href="/search/cs?searchtype=author&query=Mayo%2C+M+L">Michael L. Mayo</a>, 
<a href="/search/cs?searchtype=author&query=Pilkiewicz%2C+K">Kevin Pilkiewicz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">The escalating risk of collisions and the accumulation of space debris in Low
Earth Orbit (LEO) has reached critical concern due to the ever increasing
number of spacecraft. Addressing this crisis, especially in dealing with
non-cooperative and unidentified space debris, is of paramount importance. This
paper contributes to efforts in enabling autonomous swarms of small chaser
satellites for target geometry determination and safe flight trajectory
planning for proximity operations in LEO. Our research explores on-orbit use of
the You Only Look Once v5 (YOLOv5) object detection model trained to detect
satellite components. While this model has shown promise, its inherent lack of
interpretability hinders human understanding, a critical aspect of validating
algorithms for use in safety-critical missions. To analyze the decision
processes, we introduce Probabilistic Explanations for Entropic Knowledge
extraction (PEEK), a method that utilizes information theoretic analysis of the
latent representations within the hidden layers of the model. Through both
synthetic in hardware-in-the-loop experiments, PEEK illuminates the
decision-making processes of the model, helping identify its strengths,
limitations and biases.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01707" title="Abstract">arXiv:2311.01707</a> [<a href="/pdf/2311.01707" title="Download PDF">pdf</a>, <a href="/format/2311.01707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Multi-Robot Multi-Target Tracking Using Heterogeneous  Limited-Range Sensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Abugurain%2C+M">Mohammed Abugurain</a>, 
<a href="/search/cs?searchtype=author&query=Dames%2C+P">Philip Dames</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Shinkyu Park</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents a cooperative multi-robot multi-target tracking framework
aimed at enhancing the efficiency of the heterogeneous sensor network and,
consequently, improving overall target tracking accuracy. The concept of
normalized unused sensing capacity is introduced to quantify the information a
sensor is currently gathering relative to its theoretical maximum. This
measurement can be computed using entirely local information and is applicable
to various sensor models, distinguishing it from previous literature on the
subject. It is then utilized to develop a distributed coverage control strategy
for a heterogeneous sensor network, adaptively balancing the workload based on
each sensor's current unused capacity. The algorithm is validated through a
series of ROS and MATLAB simulations, demonstrating superior results compared
to standard approaches that do not account for heterogeneity or current usage
rates.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01708" title="Abstract">arXiv:2311.01708</a> [<a href="/pdf/2311.01708" title="Download PDF">pdf</a>, <a href="/ps/2311.01708" title="Download PostScript">ps</a>, <a href="/format/2311.01708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Informed Generator-Encoder Adversarial Networks with Latent  Space Matching for Stochastic Differential Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+R">Ruisong Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Min Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jin Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">We propose a new class of physics-informed neural networks, called
Physics-Informed Generator-Encoder Adversarial Networks, to effectively address
the challenges posed by forward, inverse, and mixed problems in stochastic
differential equations. In these scenarios, while the governing equations are
known, the available data consist of only a limited set of snapshots for system
parameters. Our model consists of two key components: the generator and the
encoder, both updated alternately by gradient descent. In contrast to previous
approaches of directly matching the approximated solutions with real snapshots,
we employ an indirect matching that operates within the lower-dimensional
latent feature space. This method circumvents challenges associated with
high-dimensional inputs and complex data distributions, while yielding more
accurate solutions compared to existing neural network solvers. In addition,
the approach also mitigates the training instability issues encountered in
previous adversarial frameworks in an efficient manner. Numerical results
provide compelling evidence of the effectiveness of the proposed method in
solving different types of stochastic differential equations.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01712" title="Abstract">arXiv:2311.01712</a> [<a href="/pdf/2311.01712" title="Download PDF">pdf</a>, <a href="/format/2311.01712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Korean Text Classification Benchmark for Recognizing the Political  Intents in Online Newspapers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+B">Beomjune Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+E">Eunsun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Na%2C+D">Dongbin Na</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Many users reading online articles in various magazines may suffer
considerable difficulty in distinguishing the implicit intents in texts. In
this work, we focus on automatically recognizing the political intents of a
given online newspaper by understanding the context of the text. To solve this
task, we present a novel Korean text classification dataset that contains
various articles. We also provide deep-learning-based text classification
baseline models trained on the proposed dataset. Our dataset contains 12,000
news articles that may contain political intentions, from the politics section
of six of the most representative newspaper organizations in South Korea. All
the text samples are labeled simultaneously in two aspects (1) the level of
political orientation and (2) the level of pro-government. To the best of our
knowledge, our paper is the most large-scale Korean news dataset that contains
long text and addresses multi-task classification problems. We also train
recent state-of-the-art (SOTA) language models that are based on transformer
architectures and demonstrate that the trained models show decent text
classification performance. All the codes, datasets, and trained models are
available at https://github.com/Kdavid2355/KoPolitic-Benchmark-Dataset.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01713" title="Abstract">arXiv:2311.01713</a> [<a href="/pdf/2311.01713" title="Download PDF">pdf</a>, <a href="/format/2311.01713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Study of Benchmarking Chinese Aspect Sentiment Quad  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Junxian Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Haiqin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Junpeng%2C+Y">Ye Junpeng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yuxuan He</a>, 
<a href="/search/cs?searchtype=author&query=Mou%2C+H">Hao Mou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 tables, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Aspect sentiment quad prediction (ASQP) is a critical subtask of aspect-level
sentiment analysis. Current ASQP datasets are characterized by their small size
and low quadruple density, which hinders technical development. To expand
capacity, we construct two large Chinese ASQP datasets crawled from multiple
online platforms. The datasets hold several significant characteristics: larger
size (each with 10,000+ samples) and rich aspect categories, more words per
sentence, and higher density than existing ASQP datasets. Moreover, we are the
first to evaluate the performance of Generative Pre-trained Transformer (GPT)
series models on ASQP and exhibit potential issues. The experiments with
state-of-the-art ASQP baselines underscore the need to explore additional
techniques to address ASQP, as well as the importance of further investigation
into methods to improve the performance of GPTs.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01714" title="Abstract">arXiv:2311.01714</a> [<a href="/pdf/2311.01714" title="Download PDF">pdf</a>, <a href="/format/2311.01714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EXIM: A Hybrid Explicit-Implicit Representation for Text-Guided 3D Shape  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengzhe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jingyu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+K">Ka-Hei Hui</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xiaojuan Qi</a>, 
<a href="/search/cs?searchtype=author&query=Cohen-Or%2C+D">Daniel Cohen-Or</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+C">Chi-Wing Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SIGGRAPH Asia 2023 &amp; TOG
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents a new text-guided technique for generating 3D shapes. The
technique leverages a hybrid 3D shape representation, namely EXIM, combining
the strengths of explicit and implicit representations. Specifically, the
explicit stage controls the topology of the generated 3D shapes and enables
local modifications, whereas the implicit stage refines the shape and paints it
with plausible colors. Also, the hybrid approach separates the shape and color
and generates color conditioned on shape to ensure shape-color consistency.
Unlike the existing state-of-the-art methods, we achieve high-fidelity shape
generation from natural-language descriptions without the need for
time-consuming per-shape optimization or reliance on human-annotated texts
during training or test-time optimization. Further, we demonstrate the
applicability of our approach to generate indoor scenes with consistent styles
using text-induced 3D shapes. Through extensive experiments, we demonstrate the
compelling quality of our results and the high coherency of our generated
shapes with the input texts, surpassing the performance of existing methods by
a significant margin. Codes and models are released at
https://github.com/liuzhengzhe/EXIM.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01715" title="Abstract">arXiv:2311.01715</a> [<a href="/pdf/2311.01715" title="Download PDF">pdf</a>, <a href="/format/2311.01715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Acousto-optic reconstruction of exterior sound field based on concentric  circle sampling with circular harmonic expansion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+P+D">Phuc Duc Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Ishikawa%2C+K">Kenji Ishikawa</a>, 
<a href="/search/cs?searchtype=author&query=Harada%2C+N">Noboru Harada</a>, 
<a href="/search/cs?searchtype=author&query=Moriya%2C+T">Takehiro Moriya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)

</div>
<p class="mathjax">Acousto-optic sensing provides an alternative approach to traditional
microphone arrays by shedding light on the interaction of light with an
acoustic field. Sound field reconstruction is a fascinating and advanced
technique used in acousto-optics sensing. Current challenges in sound-field
reconstruction methods pertain to scenarios in which the sound source is
located within the reconstruction area, known as the exterior problem. Existing
reconstruction algorithms, primarily designed for interior scenarios, often
exhibit suboptimal performance when applied to exterior cases. This paper
introduces a novel technique for exterior sound-field reconstruction. The
proposed method leverages concentric circle sampling and a two-dimensional
exterior sound-field reconstruction approach based on circular harmonic
extensions. To evaluate the efficacy of this approach, both numerical
simulations and practical experiments are conducted. The results highlight the
superior accuracy of the proposed method when compared to conventional
reconstruction methods, all while utilizing a minimal amount of measured
projection data.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01717" title="Abstract">arXiv:2311.01717</a> [<a href="/pdf/2311.01717" title="Download PDF">pdf</a>, <a href="/format/2311.01717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Second-Order Convergent Collision-Constrained Optimization-Based Planner
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+C">Chen Liang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xifeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kui Wu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zherong Pan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Finding robot poses and trajectories represents a foundational aspect of
robot motion planning. Despite decades of research, efficiently and robustly
addressing these challenges is still difficult. Existing approaches are often
plagued by various limitations, such as intricate geometric approximations,
violations of collision constraints, or slow first-order convergence. In this
paper, we introduce two novel optimization formulations that offer provable
robustness, achieving second-order convergence while requiring only a convex
approximation of the robot's links and obstacles. Our first method, known as
the Explicit Collision Barrier (ECB) method, employs a barrier function to
guarantee separation between convex objects. ECB uses an efficient matrix
factorization technique, enabling a second-order Newton's method with an
iterative complexity linear in the number of separating planes. Our second
method, referred to as the Implicit Collision Barrier (ICB) method, further
transforms the separating planes into implicit functions of robot poses. We
show such an implicit objective function is twice-differentiable, with
derivatives evaluated at a linear complexity. To assess the effectiveness of
our approaches, we conduct a comparative study with a first-order baseline
algorithm across six testing scenarios. Our results unequivocally justify that
our method exhibits significantly faster convergence rates compared to the
baseline algorithm.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01720" title="Abstract">arXiv:2311.01720</a> [<a href="/pdf/2311.01720" title="Download PDF">pdf</a>, <a href="/format/2311.01720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Reduced-Order Soft Robot Controller
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+C">Chen Liang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xifeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kui Wu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zherong Pan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Deformable robots are notoriously difficult to model or control due to its
high-dimensional configuration spaces. Direct trajectory optimization suffers
from the curse-of-dimensionality and incurs a high computational cost, while
learning-based controller optimization methods are sensitive to hyper-parameter
tuning. To overcome these limitations, we hypothesize that high fidelity soft
robots can be both simulated and controlled by restricting to low-dimensional
spaces. Under such assumption, we propose a two-stage algorithm to identify
such simulation- and control-spaces. Our method first identifies the so-called
simulation-space that captures the salient deformation modes, to which the
robot's governing equation is restricted. We then identify the control-space,
to which control signals are restricted. We propose a multi-fidelity Riemannian
Bayesian bilevel optimization to identify task-specific control spaces. We show
that the dimension of control-space can be less than $10$ for a high-DOF soft
robot to accomplish walking and swimming tasks, allowing low-dimensional MPC
controllers to be applied to soft robots with tractable computational
complexity.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01722" title="Abstract">arXiv:2311.01722</a> [<a href="/pdf/2311.01722" title="Download PDF">pdf</a>, <a href="/format/2311.01722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heterogeneous federated collaborative filtering using FAIR: Federated  Averaging in Random Subspaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Desai%2C+A">Aditya Desai</a>, 
<a href="/search/cs?searchtype=author&query=Meisburger%2C+B">Benjamin Meisburger</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zichang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shrivastava%2C+A">Anshumali Shrivastava</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Recommendation systems (RS) for items (e.g., movies, books) and ads are
widely used to tailor content to users on various internet platforms.
Traditionally, recommendation models are trained on a central server. However,
due to rising concerns for data privacy and regulations like the GDPR,
federated learning is an increasingly popular paradigm in which data never
leaves the client device. Applying federated learning to recommendation models
is non-trivial due to large embedding tables, which often exceed the memory
constraints of most user devices. To include data from all devices in federated
learning, we must enable collective training of embedding tables on devices
with heterogeneous memory capacities. Current solutions to heterogeneous
federated learning can only accommodate a small range of capacities and thus
limit the number of devices that can participate in training. We present
Federated Averaging in Random subspaces (FAIR), which allows arbitrary
compression of embedding tables based on device capacity and ensures the
participation of all devices in training. FAIR uses what we call consistent and
collapsible subspaces defined by hashing-based random projections to jointly
train large embedding tables while using varying amounts of compression on user
devices. We evaluate FAIR on Neural Collaborative Filtering tasks with multiple
datasets and verify that FAIR can gather and share information from a wide
range of devices with varying capacities, allowing for seamless collaboration.
We prove the convergence of FAIR in the homogeneous setting with non-i.i.d data
distribution. Our code is open source at {https://github.com/apd10/FLCF}
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01723" title="Abstract">arXiv:2311.01723</a> [<a href="/pdf/2311.01723" title="Download PDF">pdf</a>, <a href="/format/2311.01723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Calibrated Robust Fine-Tuning of Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oh%2C+C">Changdae Oh</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Mijoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+H">Hyesu Lim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Junhyeok Park</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+E">Euiseog Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhi-Qi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+K">Kyungwoo Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress; NeurIPS 2023 Workshop on Distribution Shifts
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">While fine-tuning unleashes the potential of a pre-trained model to a
specific task, it trades off the model's generalization capability on
out-of-distribution (OOD) datasets. To mitigate this, robust fine-tuning aims
to ensure performance on OOD datasets as well as an in-distribution (ID)
dataset for which the model is being tuned. However, another criterion for
reliable machine learning (ML), confidence calibration, has been overlooked
despite its increasing demand for real-world high-stakes ML applications (e.g.,
autonomous driving and medical diagnosis). For the first time, we raise
concerns about the calibration of fine-tuned vision-language models (VLMs)
under distribution shift by showing that naive fine-tuning and even
state-of-the-art robust fine-tuning methods hurt the calibration of pre-trained
VLMs, especially on OOD datasets. To address this, we provide a simple
approach, called a calibrated robust fine-tuning (CaRot) that incentivizes the
calibration and robustness on both ID and OOD datasets. Empirical results on
ImageNet-1K distribution shift evaluation verify the effectiveness of our
method.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01725" title="Abstract">arXiv:2311.01725</a> [<a href="/pdf/2311.01725" title="Download PDF">pdf</a>, <a href="/ps/2311.01725" title="Download PostScript">ps</a>, <a href="/format/2311.01725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Recursive Programming with Quantum Case Statements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ying%2C+M">Mingsheng Ying</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhicheng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Logic in Computer Science (cs.LO); Quantum Physics (quant-ph)

</div>
<p class="mathjax">We introduce a novel scheme of quantum recursive programming, in which large
unitary transformations, i.e. quantum gates, can be recursively defined using
quantum case statements, which are quantum counterparts of conditionals and
case statements extensively used in classical programming. A simple programming
language for supporting this kind of quantum recursion is defined, and its
semantics is formally described. A series of examples are presented to show
that some quantum algorithms can be elegantly written as quantum recursive
programs.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01728" title="Abstract">arXiv:2311.01728</a> [<a href="/pdf/2311.01728" title="Download PDF">pdf</a>, <a href="/format/2311.01728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RDE: A Hybrid Policy Framework for Multi-Agent Path Finding Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jianqi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaoqing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+M">Mingshan Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Multi-agent path finding (MAPF) is an abstract model for the navigation of
multiple robots in warehouse automation, where multiple robots plan
collision-free paths from the start to goal positions. Reinforcement learning
(RL) has been employed to develop partially observable distributed MAPF
policies that can be scaled to any number of agents. However, RL-based MAPF
policies often get agents stuck in deadlock due to warehouse automation's dense
and structured obstacles. This paper proposes a novel hybrid MAPF policy, RDE,
based on switching among the RL-based MAPF policy, the Distance heat map
(DHM)-based policy and the Escape policy. The RL-based policy is used for
coordination among agents. In contrast, when no other agents are in the agent's
field of view, it can get the next action by querying the DHM. The escape
policy that randomly selects valid actions can help agents escape the deadlock.
We conduct simulations on warehouse-like structured grid maps using
state-of-the-art RL-based MAPF policies (DHC and DCC), which show that RDE can
significantly improve their performance.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01729" title="Abstract">arXiv:2311.01729</a> [<a href="/pdf/2311.01729" title="Download PDF">pdf</a>, <a href="/format/2311.01729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CDGraph: Dual Conditional Social Graph Synthesizing via Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsai%2C+J">Jui-Yi Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+Y">Ya-Wen Teng</a>, 
<a href="/search/cs?searchtype=author&query=Yew%2C+H+C">Ho Chiok Yew</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">De-Nian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L+Y">Lydia Y. Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The social graphs synthesized by the generative models are increasingly in
demand due to data scarcity and concerns over user privacy. One of the key
performance criteria for generating social networks is the fidelity to
specified conditionals, such as users with certain membership and financial
status. While recent diffusion models have shown remarkable performance in
generating images, their effectiveness in synthesizing graphs has not yet been
explored in the context of conditional social graphs. In this paper, we propose
the first kind of conditional diffusion model for social networks, CDGraph,
which trains and synthesizes graphs based on two specified conditions. We
propose the co-evolution dependency in the denoising process of CDGraph to
capture the mutual dependencies between the dual conditions and further
incorporate social homophily and social contagion to preserve the connectivity
between nodes while satisfying the specified conditions. Moreover, we introduce
a novel classifier loss, which guides the training of the diffusion process
through the mutual dependency of dual conditions. We evaluate CDGraph against
four existing graph generative methods, i.e., SPECTRE, GSM, EDGE, and DiGress,
on four datasets. Our results show that the generated graphs from CDGraph
achieve much higher dual-conditional validity and lower discrepancy in various
social network metrics than the baselines, thus demonstrating its proficiency
in generating dual-conditional social graphs.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01732" title="Abstract">arXiv:2311.01732</a> [<a href="/pdf/2311.01732" title="Download PDF">pdf</a>, <a href="/format/2311.01732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proto-lm: A Prototypical Network-Based Framework for Built-in  Interpretability in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Sean Xie</a>, 
<a href="/search/cs?searchtype=author&query=Vosoughi%2C+S">Soroush Vosoughi</a>, 
<a href="/search/cs?searchtype=author&query=Hassanpour%2C+S">Saeed Hassanpour</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) have significantly advanced the field of Natural
Language Processing (NLP), but their lack of interpretability has been a major
concern. Current methods for interpreting LLMs are post hoc, applied after
inference time, and have limitations such as their focus on low-level features
and lack of explainability at higher level text units. In this work, we
introduce proto-lm, a prototypical network-based white-box framework that
allows LLMs to learn immediately interpretable embeddings during the
fine-tuning stage while maintaining competitive performance. Our method's
applicability and interpretability are demonstrated through experiments on a
wide range of NLP tasks, and our results indicate a new possibility of creating
interpretable models without sacrificing performance. This novel approach to
interpretability in LLMs can pave the way for more interpretable models without
the need to sacrifice performance.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01734" title="Abstract">arXiv:2311.01734</a> [<a href="/pdf/2311.01734" title="Download PDF">pdf</a>, <a href="/format/2311.01734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MixCon3D: Synergizing Multi-View and Cross-Modal Contrastive Learning  for Enhancing 3D Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yipeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zeyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Wei-Shi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Cihang Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuyin Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technique report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Contrastive learning has emerged as a promising paradigm for 3D open-world
understanding, jointly with text, image, and point cloud. In this paper, we
introduce MixCon3D, which combines the complementary information between 2D
images and 3D point clouds to enhance contrastive learning. With the further
integration of multi-view 2D images, MixCon3D enhances the traditional
tri-modal representation by offering a more accurate and comprehensive
depiction of real-world 3D objects and bolstering text alignment. Additionally,
we pioneer the first thorough investigation of various training recipes for the
3D contrastive learning paradigm, building a solid baseline with improved
performance. Extensive experiments conducted on three representative benchmarks
reveal that our method renders significant improvement over the baseline,
surpassing the previous state-of-the-art performance on the challenging
1,156-category Objaverse-LVIS dataset by 5.7%. We further showcase the
effectiveness of our approach in more applications, including text-to-3D
retrieval and point cloud captioning. The code is available at
https://github.com/UCSC-VLAA/MixCon3D.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01737" title="Abstract">arXiv:2311.01737</a> [<a href="/pdf/2311.01737" title="Download PDF">pdf</a>, <a href="/format/2311.01737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoPriv: Network/Protocol Co-Optimization for Communication-Efficient  Private Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+W">Wenxuan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Meng Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Haichuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Wen-jie Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Runsheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+R">Ru Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Deep neural network (DNN) inference based on secure 2-party computation (2PC)
can offer cryptographically-secure privacy protection but suffers from orders
of magnitude latency overhead due to enormous communication. Previous works
heavily rely on a proxy metric of ReLU counts to approximate the communication
overhead and focus on reducing the ReLUs to improve the communication
efficiency. However, we observe these works achieve limited communication
reduction for state-of-the-art (SOTA) 2PC protocols due to the ignorance of
other linear and non-linear operations, which now contribute to the majority of
communication. In this work, we present CoPriv, a framework that jointly
optimizes the 2PC inference protocol and the DNN architecture. CoPriv features
a new 2PC protocol for convolution based on Winograd transformation and
develops DNN-aware optimization to significantly reduce the inference
communication. CoPriv further develops a 2PC-aware network optimization
algorithm that is compatible with the proposed protocol and simultaneously
reduces the communication for all the linear and non-linear operations. We
compare CoPriv with the SOTA 2PC protocol, CrypTFlow2, and demonstrate 2.1x
communication reduction for both ResNet-18 and ResNet-32 on CIFAR-100. We also
compare CoPriv with SOTA network optimization methods, including SNL,
MetaPruning, etc. CoPriv achieves 9.98x and 3.88x online and total
communication reduction with a higher accuracy compare to SNL, respectively.
CoPriv also achieves 3.87x online communication reduction with more than 3%
higher accuracy compared to MetaPruning.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01739" title="Abstract">arXiv:2311.01739</a> [<a href="/pdf/2311.01739" title="Download PDF">pdf</a>, <a href="/format/2311.01739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Algorithms for Monte Carlo Particle Transport on AI  Accelerator Hardware
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tramm%2C+J">John Tramm</a>, 
<a href="/search/cs?searchtype=author&query=Allen%2C+B">Bryce Allen</a>, 
<a href="/search/cs?searchtype=author&query=Yoshii%2C+K">Kazutomo Yoshii</a>, 
<a href="/search/cs?searchtype=author&query=Siegel%2C+A">Andrew Siegel</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+L">Leighton Wilson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF)

</div>
<p class="mathjax">The recent trend toward deep learning has led to the development of a variety
of highly innovative AI accelerator architectures. One such architecture, the
Cerebras Wafer-Scale Engine 2 (WSE-2), features 40 GB of on-chip SRAM, making
it a potentially attractive platform for latency- or bandwidth-bound HPC
simulation workloads. In this study, we examine the feasibility of performing
continuous energy Monte Carlo (MC) particle transport on the WSE-2 by porting a
key kernel from the MC transport algorithm to Cerebras's CSL programming model.
New algorithms for minimizing communication costs and for handling load
balancing are developed and tested. The WSE-2 is found to run \SPEEDUP~times
faster than a highly optimized CUDA version of the kernel run on an NVIDIA A100
GPU -- significantly outpacing the expected performance increase given the
difference in transistor counts between the architectures.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01740" title="Abstract">arXiv:2311.01740</a> [<a href="/pdf/2311.01740" title="Download PDF">pdf</a>, <a href="/format/2311.01740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAC$^3$: Reliable Hallucination Detection in Black-Box Language Models  via Semantic-aware Cross-check Consistency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuohang Li</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+K">Kamalika Das</a>, 
<a href="/search/cs?searchtype=author&query=Malin%2C+B+A">Bradley A. Malin</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sricharan Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been accepted by EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Hallucination detection is a critical step toward understanding the
trustworthiness of modern language models (LMs). To achieve this goal, we
re-examine existing detection approaches based on the self-consistency of LMs
and uncover two types of hallucinations resulting from 1) question-level and 2)
model-level, which cannot be effectively identified through self-consistency
check alone. Building upon this discovery, we propose a novel sampling-based
method, i.e., semantic-aware cross-check consistency (SAC$^3$) that expands on
the principle of self-consistency checking. Our SAC$^3$ approach incorporates
additional mechanisms to detect both question-level and model-level
hallucinations by leveraging advances including semantically equivalent
question perturbation and cross-model response consistency checking. Through
extensive and systematic empirical analysis, we demonstrate that SAC$^3$
outperforms the state of the art in detecting both non-factual and factual
statements across multiple question-answering and open-domain generation
benchmarks.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01743" title="Abstract">arXiv:2311.01743</a> [<a href="/pdf/2311.01743" title="Download PDF">pdf</a>, <a href="/format/2311.01743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy Efficiency Optimization for Subterranean LoRaWAN Using A  Reinforcement Learning Approach: A Direct-to-Satellite Scenario
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+K">Kaiqiang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ullah%2C+M+A">Muhammad Asad Ullah</a>, 
<a href="/search/cs?searchtype=author&query=Alves%2C+H">Hirley Alves</a>, 
<a href="/search/cs?searchtype=author&query=Mikhaylov%2C+K">Konstantin Mikhaylov</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+T">Tong Hao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 6 figures, paper accepted for publication in IEEE Wireless Communications Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">The integration of subterranean LoRaWAN and non-terrestrial networks (NTN)
delivers substantial economic and societal benefits in remote agriculture and
disaster rescue operations. The LoRa modulation leverages quasi-orthogonal
spreading factors (SFs) to optimize data rates, airtime, coverage and energy
consumption. However, it is still challenging to effectively assign SFs to end
devices for minimizing co-SF interference in massive subterranean LoRaWAN NTN.
To address this, we investigate a reinforcement learning (RL)-based SFs
allocation scheme to optimize the system's energy efficiency (EE). To
efficiently capture the device-to-environment interactions in dense networks,
we proposed an SFs allocation technique using the multi-agent dueling double
deep Q-network (MAD3QN) and the multi-agent advantage actor-critic (MAA2C)
algorithms based on an analytical reward mechanism. Our proposed RL-based SFs
allocation approach evinces better performance compared to four benchmarks in
the extreme underground direct-to-satellite scenario. Remarkably, MAD3QN shows
promising potentials in surpassing MAA2C in terms of convergence rate and EE.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01744" title="Abstract">arXiv:2311.01744</a> [<a href="/pdf/2311.01744" title="Download PDF">pdf</a>, <a href="/format/2311.01744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Centric Long-Tailed Image Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yanbiao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+L">Licheng Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Puhua Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the context of the long-tail scenario, models exhibit a strong demand for
high-quality data. Data-centric approaches aim to enhance both the quantity and
quality of data to improve model performance. Among these approaches,
information augmentation has been progressively introduced as a crucial
category. It achieves a balance in model performance by augmenting the richness
and quantity of samples in the tail classes. However, there is currently a lack
of research into the underlying mechanisms explaining the effectiveness of
information augmentation methods. Consequently, the utilization of information
augmentation in long-tail recognition tasks relies heavily on empirical and
intricate fine-tuning. This work makes two primary contributions. Firstly, we
approach the problem from the perspectives of feature diversity and
distribution shift, introducing the concept of Feature Diversity Gain (FDG) to
elucidate why information augmentation is effective. We find that the
performance of information augmentation can be explained by FDG, and its
performance peaks when FDG achieves an appropriate balance. Experimental
results demonstrate that by using FDG to select augmented data, we can further
enhance model performance without the need for any modifications to the model's
architecture. Thus, data-centric approaches hold significant potential in the
field of long-tail recognition, beyond the development of new model structures.
Furthermore, we systematically introduce the core components and fundamental
tasks of a data-centric long-tail learning framework for the first time. These
core components guide the implementation and deployment of the system, while
the corresponding fundamental tasks refine and expand the research area.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01749" title="Abstract">arXiv:2311.01749</a> [<a href="/pdf/2311.01749" title="Download PDF">pdf</a>, <a href="/format/2311.01749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Epidemic Decision-making System Based Federated Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yangxi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+J">Junping Du</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Z">Zhe Xue</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zhenhui Pan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weikang Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Epidemic decision-making can effectively help the government to
comprehensively consider public security and economic development to respond to
public health and safety emergencies. Epidemic decision-making can effectively
help the government to comprehensively consider public security and economic
development to respond to public health and safety emergencies. Some studies
have shown that intensive learning can effectively help the government to make
epidemic decision, thus achieving the balance between health security and
economic development. Some studies have shown that intensive learning can
effectively help the government to make epidemic decision, thus achieving the
balance between health security and economic development. However, epidemic
data often has the characteristics of limited samples and high privacy.
However, epidemic data often has the characteristics of limited samples and
high privacy. This model can combine the epidemic situation data of various
provinces for cooperative training to use as an enhanced learning model for
epidemic situation decision, while protecting the privacy of data. The
experiment shows that the enhanced federated learning can obtain more optimized
performance and return than the enhanced learning, and the enhanced federated
learning can also accelerate the training convergence speed of the training
model. accelerate the training convergence speed of the client. At the same
time, through the experimental comparison, A2C is the most suitable
reinforcement learning model for the epidemic situation decision-making.
learning model for the epidemic situation decision-making scenario, followed by
the PPO model, and the performance of DDPG is unsatisfactory.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01751" title="Abstract">arXiv:2311.01751</a> [<a href="/pdf/2311.01751" title="Download PDF">pdf</a>, <a href="/format/2311.01751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EmojiLM: Modeling the New Emoji Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+L">Letian Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zilong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+J">Jingbo Shang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">With the rapid development of the internet, online social media welcomes
people with different backgrounds through its diverse content. The increasing
usage of emoji becomes a noticeable trend thanks to emoji's rich information
beyond cultural or linguistic borders. However, the current study on emojis is
limited to single emoji prediction and there are limited data resources
available for further study of the interesting linguistic phenomenon. To this
end, we synthesize a large text-emoji parallel corpus, Text2Emoji, from a large
language model. Based on the parallel corpus, we distill a sequence-to-sequence
model, EmojiLM, which is specialized in the text-emoji bidirectional
translation. Extensive experiments on public benchmarks and human evaluation
demonstrate that our proposed model outperforms strong baselines and the
parallel corpus benefits emoji-related downstream tasks.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01752" title="Abstract">arXiv:2311.01752</a> [<a href="/pdf/2311.01752" title="Download PDF">pdf</a>, <a href="/ps/2311.01752" title="Download PostScript">ps</a>, <a href="/format/2311.01752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low Overhead Beam Alignment for Mobile Millimeter Channel Based on  Continuous-Time Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lin%2C+H">Huang-Chou Lin</a>, 
<a href="/search/eess?searchtype=author&query=Kuang-Hao">Kuang-Hao</a> (Stanley)Liu
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In millimeter-wave (mmWave) communications, directional transmission based on
beamforming is important to compensate for high pathloss. To maintain the
desired direction transmission gain, beam scanning that involves the
transmitter sending the pilot signal over all available beam directions to find
the optimal beam is often considered. Alternatively, beam tracking using
partial beams can save the beam training overhead through algorithms such as
statistical analysis models and kalman filter (KF). Unfortunately, existing
beam tracking solutions are limited to a fixed beam variation pattern. In this
work, we propose a beam alignment scheme called adaptive online beam alignment
(AOBA), which aims to reduce training overhead and achieve accurate beam
alignment for any movement profile. The proposed AOBA periodically performs
beam tracking using a small amount but carefully selected candidate beams and
switches to beam scanning using all available beams based on a given switching
rule. During the interval without the pilot signal, the optimal beam at an
arbitrary time instant is predicted with the aid of the recently proposed
ordinary differential equation (ODE)-long short-term memory (LSTM) model.
Extensive simulations are conducted to evaluate the performance of the proposed
AOBA in comparison with several existing beam alignment schemes.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01753" title="Abstract">arXiv:2311.01753</a> [<a href="/pdf/2311.01753" title="Download PDF">pdf</a>, <a href="/format/2311.01753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RiskQ: Risk-sensitive Multi-Agent Reinforcement Learning Value  Factorization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+S">Siqi Shen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chennan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chao Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weiquan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yongquan Fu</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+S">Songzhu Mei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinwang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cheng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 submission version: <a href="https://openreview.net/forum?id=FskZtRvMJI">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Multi-agent systems are characterized by environmental uncertainty, varying
policies of agents, and partial observability, which result in significant
risks. In the context of Multi-Agent Reinforcement Learning (MARL), learning
coordinated and decentralized policies that are sensitive to risk is
challenging. To formulate the coordination requirements in risk-sensitive MARL,
we introduce the Risk-sensitive Individual-Global-Max (RIGM) principle as a
generalization of the Individual-Global-Max (IGM) and Distributional IGM (DIGM)
principles. This principle requires that the collection of risk-sensitive
action selections of each agent should be equivalent to the risk-sensitive
action selection of the central policy. Current MARL value factorization
methods do not satisfy the RIGM principle for common risk metrics such as the
Value at Risk (VaR) metric or distorted risk measurements. Therefore, we
propose RiskQ to address this limitation, which models the joint return
distribution by modeling quantiles of it as weighted quantile mixtures of
per-agent return distribution utilities. RiskQ satisfies the RIGM principle for
the VaR and distorted risk metrics. We show that RiskQ can obtain promising
performance through extensive experiments. The source code of RiskQ is
available in https://github.com/xmu-rl-3dv/RiskQ.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01755" title="Abstract">arXiv:2311.01755</a> [<a href="/pdf/2311.01755" title="Download PDF">pdf</a>, <a href="/format/2311.01755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Unified Transformer-based Framework for Scene Graph Generation  and Human-object Interaction Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tao He</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Lianli Gao</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jingkuan Song</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuan-Fang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Scene graph generation (SGG) and human-object interaction (HOI) detection are
two important visual tasks aiming at localising and recognising relationships
between objects, and interactions between humans and objects, respectively.
<br />Prevailing works treat these tasks as distinct tasks, leading to the
development of task-specific models tailored to individual datasets. However,
we posit that the presence of visual relationships can furnish crucial
contextual and intricate relational cues that significantly augment the
inference of human-object interactions. This motivates us to think if there is
a natural intrinsic relationship between the two tasks, where scene graphs can
serve as a source for inferring human-object interactions. In light of this, we
introduce SG2HOI+, a unified one-step model based on the Transformer
architecture. Our approach employs two interactive hierarchical Transformers to
seamlessly unify the tasks of SGG and HOI detection. Concretely, we initiate a
relation Transformer tasked with generating relation triples from a suite of
visual features. Subsequently, we employ another transformer-based decoder to
predict human-object interactions based on the generated relation triples. A
comprehensive series of experiments conducted across established benchmark
datasets including Visual Genome, V-COCO, and HICO-DET demonstrates the
compelling performance of our SG2HOI+ model in comparison to prevalent
one-stage SGG models. Remarkably, our approach achieves competitive performance
when compared to state-of-the-art HOI methods. Additionally, we observe that
our SG2HOI+ jointly trained on both SGG and HOI tasks in an end-to-end manner
yields substantial improvements for both tasks compared to individualized
training paradigms.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01757" title="Abstract">arXiv:2311.01757</a> [<a href="/pdf/2311.01757" title="Download PDF">pdf</a>, <a href="/format/2311.01757" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Indo LEGO-ABSA: A Multitask Generative Aspect Based Sentiment Analysis  for Indonesian Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suchrady%2C+R+Z">Randy Zakya Suchrady</a>, 
<a href="/search/cs?searchtype=author&query=Purwarianti%2C+A">Ayu Purwarianti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at International Conference on Electrical Engineering and Informatics 2023 (ICEEI 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Aspect-based sentiment analysis is a method in natural language processing
aimed at identifying and understanding sentiments related to specific aspects
of an entity. Aspects are words or phrases that represent an aspect or
attribute of a particular entity. Previous research has utilized generative
pre-trained language models to perform aspect-based sentiment analysis.
LEGO-ABSA is one framework that has successfully employed generative
pre-trained language models in aspect-based sentiment analysis, particularly in
English. LEGO-ABSA uses a multitask learning and prompting approach to enhance
model performance. However, the application of this approach has not been done
in the context of Bahasa Indonesia. Therefore, this research aims to implement
the multitask learning and prompting approach in aspect-based sentiment
analysis for Bahasa Indonesia using generative pre-trained language models. In
this study, the Indo LEGO-ABSA model is developed, which is an aspect-based
sentiment analysis model utilizing generative pre-trained language models and
trained with multitask learning and prompting. Indo LEGO-ABSA is trained with a
hotel domain dataset in the Indonesian language. The obtained results include
an f1-score of 79.55% for the Aspect Sentiment Triplet Extraction task, 86.09%
for Unified Aspect-based Sentiment Analysis, 79.85% for Aspect Opinion Pair
Extraction, 87.45% for Aspect Term Extraction, and 88.09% for Opinion Term
Extraction. Indo LEGO-ABSA adopts the LEGO-ABSA framework that employs the T5
model, specifically mT5, by applying multitask learning to train all tasks
within aspect-based sentiment analysis.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01759" title="Abstract">arXiv:2311.01759</a> [<a href="/pdf/2311.01759" title="Download PDF">pdf</a>, <a href="/format/2311.01759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TinyFormer: Efficient Transformer Design and Deployment on Tiny Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianlei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+J">Jiacheng Liao</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+F">Fanding Lei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Meichen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+L">Lingkun Long</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+H">Han Wan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Weisheng Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Developing deep learning models on tiny devices (e.g. Microcontroller units,
MCUs) has attracted much attention in various embedded IoT applications.
However, it is challenging to efficiently design and deploy recent advanced
models (e.g. transformers) on tiny devices due to their severe hardware
resource constraints. In this work, we propose TinyFormer, a framework
specifically designed to develop and deploy resource-efficient transformers on
MCUs. TinyFormer mainly consists of SuperNAS, SparseNAS and SparseEngine.
Separately, SuperNAS aims to search for an appropriate supernet from a vast
search space. SparseNAS evaluates the best sparse single-path model including
transformer architecture from the identified supernet. Finally, SparseEngine
efficiently deploys the searched sparse models onto MCUs. To the best of our
knowledge, SparseEngine is the first deployment framework capable of performing
inference of sparse models with transformer on MCUs. Evaluation results on the
CIFAR-10 dataset demonstrate that TinyFormer can develop efficient transformers
with an accuracy of $96.1\%$ while adhering to hardware constraints of $1$MB
storage and $320$KB memory. Additionally, TinyFormer achieves significant
speedups in sparse inference, up to $12.2\times$, when compared to the CMSIS-NN
library. TinyFormer is believed to bring powerful transformers into TinyML
scenarios and greatly expand the scope of deep learning applications.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01764" title="Abstract">arXiv:2311.01764</a> [<a href="/pdf/2311.01764" title="Download PDF">pdf</a>, <a href="/ps/2311.01764" title="Download PostScript">ps</a>, <a href="/format/2311.01764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structure design and coordinated motion analysis of bionic crocodile  robot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jingya Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yuhang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kai Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Crocodiles, known as one of the oldest and most resilient species on Earth,
have demonstrated remarkable locomotor abilities both on land and in water,
evolving over millennia to adapt to diverse environments. In this paper, we
draw inspiration from crocodiles and introduce a highly biomimetic crocodile
robot equipped with multiple degrees of freedom and articulated trunk joints.
This design is based on a comprehensive analysis of the structural and motion
characteristics observed in real crocodiles. The bionic crocodile robot has the
problem of limb-torso incoordination during movement, in order to solve this
problem, we apply the D-H method for both forward and inverse kinematics
analysis of the robot's legs and spine. Through a series of simulation
experiments, we investigate the robot's stability of motion, fault tolerance,
and adaptability to the environment in two motor pattern: with and without the
involvement of the spine and tail in its movements. Experiment results
demonstrate that the bionic crocodile robot exhibits superior motion
performance when the spine and tail cooperate with the extremities. This
research not only showcases the potential of biomimicry in robotics but also
underscores the significance of understanding how nature's designs can inform
and enhance our technological innovations.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01766" title="Abstract">arXiv:2311.01766</a> [<a href="/pdf/2311.01766" title="Download PDF">pdf</a>, <a href="/format/2311.01766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Support or Refute: Analyzing the Stance of Evidence to Detect  Out-of-Context Mis- and Disinformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jie Guo</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+W">Weidong Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shujun Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Mis- and disinformation online have become a major societal problem as major
sources of online harms of different kinds. One common form of mis- and
disinformation is out-of-context (OOC) information, where different pieces of
information are falsely associated, e.g., a real image combined with a false
textual caption or a misleading textual description. Although some past studies
have attempted to defend against OOC mis- and disinformation through external
evidence, they tend to disregard the role of different pieces of evidence with
different stances. Motivated by the intuition that the stance of evidence
represents a bias towards different detection results, we propose a stance
extraction network (SEN) that can extract the stances of different pieces of
multi-modal evidence in a unified framework. Moreover, we introduce a
support-refutation score calculated based on the co-occurrence relations of
named entities into the textual SEN. Extensive experiments on a public
large-scale dataset demonstrated that our proposed method outperformed the
state-of-the-art baselines, with the best model achieving a performance gain of
3.2% in accuracy.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01767" title="Abstract">arXiv:2311.01767</a> [<a href="/pdf/2311.01767" title="Download PDF">pdf</a>, <a href="/format/2311.01767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PPTC Benchmark: Evaluating Large Language Models for PowerPoint Task  Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yiduo Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zekai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yaobo Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dongyan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Nan%2C+D">Duan Nan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> LLM evaluation, PPT task completion
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent evaluations of Large Language Models (LLMs) have centered around
testing their zero-shot/few-shot capabilities for basic natural language tasks
and their ability to translate instructions into tool APIs. However, the
evaluation of LLMs utilizing complex tools to finish multi-turn, multi-modal
instructions in a complex multi-modal environment has not been investigated. To
address this gap, we introduce the PowerPoint Task Completion (PPTC) benchmark
to assess LLMs' ability to create and edit PPT files based on user
instructions. It contains 279 multi-turn sessions covering diverse topics and
hundreds of instructions involving multi-modal operations. We also propose the
PPTX-Match Evaluation System that evaluates if LLMs finish the instruction
based on the prediction file rather than the label API sequence, thus it
supports various LLM-generated API sequences. We measure 3 closed LLMs and 6
open-source LLMs. The results show that GPT-4 outperforms other LLMs with
75.1\% accuracy in single-turn dialogue testing but faces challenges in
completing entire sessions, achieving just 6\% session accuracy. We find three
main error causes in our benchmark: error accumulation in the multi-turn
session, long PPT template processing, and multi-modality perception. These
pose great challenges for future LLM and agent systems. We release the data,
code, and evaluation system of PPTC at \url{https://github.com/gydpku/PPTC}.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01770" title="Abstract">arXiv:2311.01770</a> [<a href="/pdf/2311.01770" title="Download PDF">pdf</a>, <a href="/format/2311.01770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling the Uncertainty with Maximum Discrepant Students for  Semi-supervised 2D Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiaqi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+J">Junbiao Pang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qingming Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Semi-supervised pose estimation is a practically challenging task for
computer vision. Although numerous excellent semi-supervised classification
methods have emerged, these methods typically use confidence to evaluate the
quality of pseudo-labels, which is difficult to achieve in pose estimation
tasks. For example, in pose estimation, confidence represents only the
possibility that a position of the heatmap is a keypoint, not the quality of
that prediction. In this paper, we propose a simple yet efficient framework to
estimate the quality of pseudo-labels in semi-supervised pose estimation tasks
from the perspective of modeling the uncertainty of the pseudo-labels.
Concretely, under the dual mean-teacher framework, we construct the two maximum
discrepant students (MDSs) to effectively push two teachers to generate
different decision boundaries for the same sample. Moreover, we create multiple
uncertainties to assess the quality of the pseudo-labels. Experimental results
demonstrate that our method improves the performance of semi-supervised pose
estimation on three datasets.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01771" title="Abstract">arXiv:2311.01771</a> [<a href="/pdf/2311.01771" title="Download PDF">pdf</a>, <a href="/format/2311.01771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Generalized Low-Rank Tensor Contextual Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+Q">Qianxin Yi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yiyang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Shaojie Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">In this paper, we aim to build a novel bandits algorithm that is capable of
fully harnessing the power of multi-dimensional data and the inherent
non-linearity of reward functions to provide high-usable and accountable
decision-making services. To this end, we introduce a generalized low-rank
tensor contextual bandits model in which an action is formed from three feature
vectors, and thus can be represented by a tensor. In this formulation, the
reward is determined through a generalized linear function applied to the inner
product of the action's feature tensor and a fixed but unknown parameter tensor
with a low tubal rank. To effectively achieve the trade-off between exploration
and exploitation, we introduce a novel algorithm called "Generalized Low-Rank
Tensor Exploration Subspace then Refine" (G-LowTESTR). This algorithm first
collects raw data to explore the intrinsic low-rank tensor subspace information
embedded in the decision-making scenario, and then converts the original
problem into an almost lower-dimensional generalized linear contextual bandits
problem. Rigorous theoretical analysis shows that the regret bound of
G-LowTESTR is superior to those in vectorization and matricization cases. We
conduct a series of simulations and real data experiments to further highlight
the effectiveness of G-LowTESTR, leveraging its ability to capitalize on the
low-rank tensor structure for enhanced learning.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01773" title="Abstract">arXiv:2311.01773</a> [<a href="/pdf/2311.01773" title="Download PDF">pdf</a>, <a href="/format/2311.01773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PDF: Point Diffusion Implicit Function for Large-scale Scene Neural  Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yuhan Ding</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+F">Fukun Yin</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Jiayuan Fan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hui Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Chongshan Lu</a>, 
<a href="/search/cs?searchtype=author&query=YU%2C+G">Gang YU</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advances in implicit neural representations have achieved impressive
results by sampling and fusing individual points along sampling rays in the
sampling space. However, due to the explosively growing sampling space, finely
representing and synthesizing detailed textures remains a challenge for
unbounded large-scale outdoor scenes. To alleviate the dilemma of using
individual points to perceive the entire colossal space, we explore learning
the surface distribution of the scene to provide structural priors and reduce
the samplable space and propose a Point Diffusion implicit Function, PDF, for
large-scale scene neural representation. The core of our method is a
large-scale point cloud super-resolution diffusion module that enhances the
sparse point cloud reconstructed from several training images into a dense
point cloud as an explicit prior. Then in the rendering stage, only sampling
points with prior points within the sampling radius are retained. That is, the
sampling space is reduced from the unbounded space to the scene surface.
Meanwhile, to fill in the background of the scene that cannot be provided by
point clouds, the region sampling based on Mip-NeRF 360 is employed to model
the background representation. Expensive experiments have demonstrated the
effectiveness of our method for large-scale scene novel view synthesis, which
outperforms relevant state-of-the-art baselines.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01775" title="Abstract">arXiv:2311.01775</a> [<a href="/pdf/2311.01775" title="Download PDF">pdf</a>, <a href="/format/2311.01775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UP4LS: User Profile Constructed by Multiple Attributes for Enhancing  Linguistic Steganalysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+R">Ruiqi Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ru Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianyi Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Linguistic steganalysis (LS) tasks aim to effectively detect stegos generated
by linguistic steganography. Existing LS methods overlook the distinctive user
characteristics, leading to weak performance in social networks. The limited
occurrence of stegos further complicates detection. In this paper, we propose
the UP4LS, a novel framework with the User Profile for enhancing LS
performance. Specifically, by delving into post content, we explore user
attributes like writing habits, psychological states, and focal areas, thereby
building the user profile for LS. For each attribute, we design the identified
feature extraction module. The extracted features are mapped to
high-dimensional user features via deep-learning networks from existing
methods. Then the language model is employed to extract content features. The
user and content features are integrated to optimize feature representation.
During the training phase, we prioritize the distribution of stegos.
Experiments demonstrate that UP4LS can significantly enhance the performance of
existing methods, and an overall accuracy improvement of nearly 25%. In
particular, the improvement is especially pronounced with fewer stego samples.
Additionally, UP4LS also sets the stage for studies on related tasks,
encouraging extensive applications on LS tasks.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01781" title="Abstract">arXiv:2311.01781</a> [<a href="/pdf/2311.01781" title="Download PDF">pdf</a>, <a href="/format/2311.01781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Passive Handwriting Tracking via Weak mmWave Communication Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yu%2C+C">Chao Yu</a>, 
<a href="/search/eess?searchtype=author&query=Luo%2C+Y">Yan Luo</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+R">Renqi Chen</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+R">Rui Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this letter, a cooperative sensing framework based on millimeter wave
(mmWave) communication systems is proposed to detect tiny motions with a
millimeter-level resolution. Particularly, the cooperative sensing framework is
facilitated with one transmitter and two receivers. There are two radio
frequency (RF) chains at each receiver. Hence, the Doppler effect due to the
tiny motions can be detected via passive sensing respectively at the receivers,
and the velocities of the motions can be estimated by integrating the Doppler
frequencies. It is demonstrated that the proposed cooperative sensing system is
able to track the handwriting with 90% error below 6 mm. Moreover, the proposed
cooperative sensing is robust to the strength of received signal. For example,
it works even without the line-of-sight paths from the transmitter to the
receivers or the sensing target, where the received signal strength is not
sufficient for timing synchronization or demodulation.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01782" title="Abstract">arXiv:2311.01782</a> [<a href="/pdf/2311.01782" title="Download PDF">pdf</a>, <a href="/format/2311.01782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Unbiased Pseudo-labels via a Theoretically Guaranteed  Chebyshev Constraint to Unify Semi-supervised Classification and Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiaqi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+J">Junbiao Pang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qingming Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Both semi-supervised classification and regression are practically
challenging tasks for computer vision. However, semi-supervised classification
methods are barely applied to regression tasks. Because the threshold-to-pseudo
label process (T2L) in classification uses confidence to determine the quality
of label. It is successful for classification tasks but inefficient for
regression tasks. In nature, regression also requires unbiased methods to
generate high-quality labels. On the other hand, T2L for classification often
fails if the confidence is generated by a biased method. To address this issue,
in this paper, we propose a theoretically guaranteed constraint for generating
unbiased labels based on Chebyshev's inequality, combining multiple predictions
to generate superior quality labels from several inferior ones. In terms of
high-quality labels, the unbiased method naturally avoids the drawback of T2L.
Specially, we propose an Unbiased Pseudo-labels network (UBPL network) with
multiple branches to combine multiple predictions as pseudo-labels, where a
Feature Decorrelation loss (FD loss) is proposed based on Chebyshev constraint.
In principle, our method can be used for both classification and regression and
can be easily extended to any semi-supervised framework, e.g. Mean Teacher,
FixMatch, DualPose. Our approach achieves superior performance over SOTAs on
the pose estimation datasets Mouse, FLIC and LSP, as well as the classification
datasets CIFAR10/100 and SVHN.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01786" title="Abstract">arXiv:2311.01786</a> [<a href="/pdf/2311.01786" title="Download PDF">pdf</a>, <a href="/format/2311.01786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TCM-GPT: Efficient Pre-training of Large Language Models for Domain  Adaptation in Traditional Chinese Medicine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guoxing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jianyu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaohong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guangyu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Pre-training and fine-tuning have emerged as a promising paradigm across
various natural language processing (NLP) tasks. The effectiveness of
pretrained large language models (LLM) has witnessed further enhancement,
holding potential for applications in the field of medicine, particularly in
the context of Traditional Chinese Medicine (TCM). However, the application of
these general models to specific domains often yields suboptimal results,
primarily due to challenges like lack of domain knowledge, unique objectives,
and computational efficiency. Furthermore, their effectiveness in specialized
domains, such as Traditional Chinese Medicine, requires comprehensive
evaluation. To address the above issues, we propose a novel domain specific
TCMDA (TCM Domain Adaptation) approach, efficient pre-training with
domain-specific corpus. Specifically, we first construct a large TCM-specific
corpus, TCM-Corpus-1B, by identifying domain keywords and retreving from
general corpus. Then, our TCMDA leverages the LoRA which freezes the pretrained
model's weights and uses rank decomposition matrices to efficiently train
specific dense layers for pre-training and fine-tuning, efficiently aligning
the model with TCM-related tasks, namely TCM-GPT-7B. We further conducted
extensive experiments on two TCM tasks, including TCM examination and TCM
diagnosis. TCM-GPT-7B archived the best performance across both datasets,
outperforming other models by relative increments of 17% and 12% in accuracy,
respectively. To the best of our knowledge, our study represents the pioneering
validation of domain adaptation of a large language model with 7 billion
parameters in TCM domain. We will release both TCMCorpus-1B and TCM-GPT-7B
model once accepted to facilitate interdisciplinary development in TCM and NLP,
serving as the foundation for further study.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01788" title="Abstract">arXiv:2311.01788</a> [<a href="/pdf/2311.01788" title="Download PDF">pdf</a>, <a href="/format/2311.01788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast ellipsoidal conformal and quasi-conformal parameterization of  genus-0 closed surfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+G+P+T">Gary P. T. Choi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Graphics (cs.GR); Complex Variables (math.CV); Differential Geometry (math.DG)

</div>
<p class="mathjax">Surface parameterization plays a fundamental role in many science and
engineering problems. In particular, as genus-0 closed surfaces are
topologically equivalent to a sphere, many spherical parameterization methods
have been developed over the past few decades. However, in practice, mapping a
genus-0 closed surface onto a sphere may result in a large distortion due to
their geometric difference. In this work, we propose a new framework for
computing ellipsoidal conformal and quasi-conformal parameterizations of
genus-0 closed surfaces, in which the target parameter domain is an ellipsoid
instead of a sphere. By combining simple conformal transformations with
different types of quasi-conformal mappings, we can easily achieve a large
variety of ellipsoidal parameterizations with their bijectivity guaranteed by
quasi-conformal theory. Numerical experiments are presented to demonstrate the
effectiveness of the proposed framework.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01790" title="Abstract">arXiv:2311.01790</a> [<a href="/pdf/2311.01790" title="Download PDF">pdf</a>, <a href="/format/2311.01790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A First Order Theory of Diagram Chasing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahboubi%2C+A">Assia Mahboubi</a> (LS2N, GALLINETTE), 
<a href="/search/cs?searchtype=author&query=Piquerez%2C+M">Matthieu Piquerez</a> (GALLINETTE, LS2N)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">This paper discusses the formalization of proofs "by diagram chasing", a
standard technique for proving properties in abelian categories. We discuss how
the essence of diagram chases can be captured by a simple many-sorted
first-order theory, and we study the models and decidability of this theory.
The longer-term motivation of this work is the design of a computer-aided
instrument for writing reliable proofs in homological algebra, based on
interactive theorem provers.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01792" title="Abstract">arXiv:2311.01792</a> [<a href="/pdf/2311.01792" title="Download PDF">pdf</a>, <a href="/format/2311.01792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AFPQ: Asymmetric Floating Point Quantization for LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yijia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sicheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+S">Shijie Cao</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+D">Dayou Du</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jianyu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+T">Ting Cao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+N">Ningyi Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) show great performance in various tasks, but
face deployment challenges from limited memory capacity and bandwidth. Low-bit
weight quantization can save memory and accelerate inference. Although
floating-point (FP) formats show good performance in LLM quantization, they
tend to perform poorly with small group sizes or sub-4 bits. We find the reason
is that the absence of asymmetry in previous FP quantization makes it
unsuitable for handling asymmetric value distribution of LLM weight tensors. In
this work, we propose asymmetric FP quantization (AFPQ), which sets separate
scales for positive and negative values. Our method leads to large accuracy
improvements and can be easily plugged into other quantization methods,
including GPTQ and AWQ, for better performance. Besides, no additional storage
is needed compared with asymmetric integer (INT) quantization. The code is
available at https://github.com/zhangsichengsjtu/AFPQ.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01793" title="Abstract">arXiv:2311.01793</a> [<a href="/pdf/2311.01793" title="Download PDF">pdf</a>, <a href="/format/2311.01793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Near-Optimal Quantum Algorithms for Bounded Edit Distance and Lempel-Ziv  Factorization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gibney%2C+D">Daniel Gibney</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+C">Ce Jin</a>, 
<a href="/search/cs?searchtype=author&query=Kociumaka%2C+T">Tomasz Kociumaka</a>, 
<a href="/search/cs?searchtype=author&query=Thankachan%2C+S+V">Sharma V. Thankachan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to SODA 2024. arXiv admin note: substantial text overlap with <a href="/abs/2302.07235">arXiv:2302.07235</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">Classically, the edit distance of two length-$n$ strings can be computed in
$O(n^2)$ time, whereas an $O(n^{2-\epsilon})$-time procedure would falsify the
Orthogonal Vectors Hypothesis. If the edit distance does not exceed $k$, the
running time can be improved to $O(n+k^2)$, which is near-optimal (conditioned
on OVH) as a function of $n$ and $k$. Our first main contribution is a quantum
$\tilde{O}(\sqrt{nk}+k^2)$-time algorithm that uses $\tilde{O}(\sqrt{nk})$
queries, where $\tilde{O}(\cdot)$ hides polylogarithmic factors. This query
complexity is unconditionally optimal, and any significant improvement in the
time complexity would resolve a long-standing open question of whether edit
distance admits an $O(n^{2-\epsilon})$-time quantum algorithm. Our
divide-and-conquer quantum algorithm reduces the edit distance problem to a
case where the strings have small Lempel-Ziv factorizations. Then, it combines
a quantum LZ compression algorithm with a classical edit-distance subroutine
for compressed strings.
<br />The LZ factorization problem can be classically solved in $O(n)$ time, which
is unconditionally optimal in the quantum setting. We can, however, hope for a
quantum speedup if we parameterize the complexity in terms of the factorization
size $z$. Already a generic oracle identification algorithm yields the optimal
query complexity of $\tilde{O}(\sqrt{nz})$ at the price of exponential running
time. Our second main contribution is a quantum algorithm that achieves the
optimal time complexity of $\tilde{O}(\sqrt{nz})$. The key tool is a novel
LZ-like factorization of size $O(z\log^2n)$ whose subsequent factors can be
efficiently computed through a combination of classical and quantum techniques.
We can then obtain the string's run-length encoded Burrows-Wheeler Transform
(BWT), construct the $r$-index, and solve many fundamental string processing
problems in time $\tilde{O}(\sqrt{nz})$.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01796" title="Abstract">arXiv:2311.01796</a> [<a href="/pdf/2311.01796" title="Download PDF">pdf</a>, <a href="/format/2311.01796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Augment Distributions for Out-of-Distribution Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qizhou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhen Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yonggang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Feng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yixuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bo Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Open-world classification systems should discern out-of-distribution (OOD)
data whose labels deviate from those of in-distribution (ID) cases, motivating
recent studies in OOD detection. Advanced works, despite their promising
progress, may still fail in the open world, owing to the lack of knowledge
about unseen OOD data in advance. Although one can access auxiliary OOD data
(distinct from unseen ones) for model training, it remains to analyze how such
auxiliary data will work in the open world. To this end, we delve into such a
problem from a learning theory perspective, finding that the distribution
discrepancy between the auxiliary and the unseen real OOD data is the key to
affecting the open-world detection performance. Accordingly, we propose
Distributional-Augmented OOD Learning (DAL), alleviating the OOD distribution
discrepancy by crafting an OOD distribution set that contains all distributions
in a Wasserstein ball centered on the auxiliary OOD distribution. We justify
that the predictor trained over the worst OOD data in the ball can shrink the
OOD distribution discrepancy, thus improving the open-world detection
performance given only the auxiliary OOD data. We conduct extensive evaluations
across representative OOD detection setups, demonstrating the superiority of
our DAL over its advanced counterparts.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01797" title="Abstract">arXiv:2311.01797</a> [<a href="/pdf/2311.01797" title="Download PDF">pdf</a>, <a href="/format/2311.01797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Generalization Properties of Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Puheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhong Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huishuai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+J">Jiang Bian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Diffusion models are a class of generative models that serve to establish a
stochastic transport map between an empirically observed, yet unknown, target
distribution and a known prior. Despite their remarkable success in real-world
applications, a theoretical understanding of their generalization capabilities
remains underdeveloped. This work embarks on a comprehensive theoretical
exploration of the generalization attributes of diffusion models. We establish
theoretical estimates of the generalization gap that evolves in tandem with the
training dynamics of score-based diffusion models, suggesting a polynomially
small generalization error ($O(n^{-2/5}+m^{-4/5})$) on both the sample size $n$
and the model capacity $m$, evading the curse of dimensionality (i.e., not
exponentially large in the data dimension) when early-stopped. Furthermore, we
extend our quantitative analysis to a data-dependent scenario, wherein target
distributions are portrayed as a succession of densities with progressively
increasing distances between modes. This precisely elucidates the adverse
effect of "modes shift" in ground truths on the model generalization. Moreover,
these estimates are not solely theoretical constructs but have also been
confirmed through numerical simulations. Our findings contribute to the
rigorous understanding of diffusion models' generalization properties and
provide insights that may guide practical applications.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01800" title="Abstract">arXiv:2311.01800</a> [<a href="/pdf/2311.01800" title="Download PDF">pdf</a>, <a href="/format/2311.01800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Method development for lowering supply temperatures in existing  buildings using minimal building information and demand measurement data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=stock%2C+J">Jan stock</a>, 
<a href="/search/eess?searchtype=author&query=Althaus%2C+P">Philipp Althaus</a>, 
<a href="/search/eess?searchtype=author&query=Johnnen%2C+S">Sascha Johnnen</a>, 
<a href="/search/eess?searchtype=author&query=Xhonneux%2C+A">Andr&#xe9; Xhonneux</a>, 
<a href="/search/eess?searchtype=author&query=M%C3%BCller%2C+D">Dirk M&#xfc;ller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 1 table, 10 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 18th International IBPSA Conference and
  Exhibition Building Simulation 2023 (BuildingSimulation 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Regarding climate change, the need to reduce greenhouse gas emissions is
well-known. As building heating contributes to a high share of total energy
consumption, which relies mainly on fossil energy sources, improving heating
efficiency is promising to consider. Lowering supply temperatures of the
heating systems in buildings offers a huge potential for efficiency
improvements since different heat supply technologies, such as heat pumps or
district heating, benefit from low supply temperatures. However, most
estimations of possible temperature reductions in existing buildings are based
on available measurement data on room level or detailed building information
about the building's physics to develop simulation models.
<br />To reveal the potential of temperature reduction for several buildings and
strive for a wide applicability, the presented method focuses on estimations
for temperature reduction in existing buildings with limited input data. By
evaluating historic heat demand data on the building level, outdoor
temperatures and information about installed heaters, the minimal actual
necessary supply temperature is calculated for each heater in the building
using the LMTD approach. Based on the calculated required supply temperatures
for each room at different outdoor temperatures, the overall necessary supply
temperatures to be provided to the building are chosen. Thus, the minimal
heatcurve possible for an existing building is deduced.
<br />The method described is applied to multiple existing office buildings at the
campus of Forschungszentrum Juelich, Germany, demonstrating the fast
application for several buildings with limited expenditure. Furthermore, a
developed adapted heatcurve is implemented in one real building and evaluated
in relation to the previously applied heatcurve of the heating system.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01804" title="Abstract">arXiv:2311.01804</a> [<a href="/pdf/2311.01804" title="Download PDF">pdf</a>, <a href="/format/2311.01804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> inkn&#x27;hue: Enhancing Manga Colorization from Multiple Priors with  Alignment Multi-Encoder VAE
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiramahapokee%2C+T">Tawin Jiramahapokee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv preprint. CVPR2024 submission under review. Project page: <a href="https://github.com/rossiyareich/inknhue">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Manga, a form of Japanese comics and distinct visual storytelling, has
captivated readers worldwide. Traditionally presented in black and white,
manga's appeal lies in its ability to convey complex narratives and emotions
through intricate line art and shading. Yet, the desire to experience manga in
vibrant colors has sparked the pursuit of manga colorization, a task of
paramount significance for artists. However, existing methods, originally
designed for line art and sketches, face challenges when applied to manga.
These methods often fall short in achieving the desired results, leading to the
need for specialized manga-specific solutions. Existing approaches frequently
rely on a single training step or extensive manual artist intervention, which
can yield less satisfactory outcomes. To address these challenges, we propose a
specialized framework for manga colorization. Leveraging established models for
shading and vibrant coloring, our approach aligns both using a multi-encoder
VAE. This structured workflow ensures clear and colorful results, with the
option to incorporate reference images and manual hints.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01807" title="Abstract">arXiv:2311.01807</a> [<a href="/pdf/2311.01807" title="Download PDF">pdf</a>, <a href="/format/2311.01807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-modal Consistency Learning with Fine-grained Fusion Network for  Multimodal Fake News Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jun Li</a>, 
<a href="/search/cs?searchtype=author&query=Bin%2C+Y">Yi Bin</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">Jie Zou</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">Jie Zou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guoqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Previous studies on multimodal fake news detection have observed the mismatch
between text and images in the fake news and attempted to explore the
consistency of multimodal news based on global features of different
modalities. However, they fail to investigate this relationship between
fine-grained fragments in multimodal content. To gain public trust, fake news
often includes relevant parts in the text and the image, making such multimodal
content appear consistent. Using global features may suppress potential
inconsistencies in irrelevant parts. Therefore, in this paper, we propose a
novel Consistency-learning Fine-grained Fusion Network (CFFN) that separately
explores the consistency and inconsistency from high-relevant and low-relevant
word-region pairs. Specifically, for a multimodal post, we divide word-region
pairs into high-relevant and low-relevant parts based on their relevance
scores. For the high-relevant part, we follow the cross-modal attention
mechanism to explore the consistency. For low-relevant part, we calculate
inconsistency scores to capture inconsistent points. Finally, a selection
module is used to choose the primary clue (consistency or inconsistency) for
identifying the credibility of multimodal news. Extensive experiments on two
public datasets demonstrate that our CFFN substantially outperforms all the
baselines.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01811" title="Abstract">arXiv:2311.01811</a> [<a href="/pdf/2311.01811" title="Download PDF">pdf</a>, <a href="/format/2311.01811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffDub: Person-generic Visual Dubbing Using Inpainting Renderer with  Diffusion Auto-encoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+C">Chenpeng Du</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+S">Shuai Fan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Feilong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kai Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generating high-quality and person-generic visual dubbing remains a
challenge. Recent innovation has seen the advent of a two-stage paradigm,
decoupling the rendering and lip synchronization process facilitated by
intermediate representation as a conduit. Still, previous methodologies rely on
rough landmarks or are confined to a single speaker, thus limiting their
performance. In this paper, we propose DiffDub: Diffusion-based dubbing. We
first craft the Diffusion auto-encoder by an inpainting renderer incorporating
a mask to delineate editable zones and unaltered regions. This allows for
seamless filling of the lower-face region while preserving the remaining parts.
Throughout our experiments, we encountered several challenges. Primarily, the
semantic encoder lacks robustness, constricting its ability to capture
high-level features. Besides, the modeling ignored facial positioning, causing
mouth or nose jitters across frames. To tackle these issues, we employ
versatile strategies, including data augmentation and supplementary eye
guidance. Moreover, we encapsulated a conformer-based reference encoder and
motion generator fortified by a cross-attention mechanism. This enables our
model to learn person-specific textures with varying references and reduces
reliance on paired audio-visual data. Our rigorous experiments comprehensively
highlight that our ground-breaking approach outpaces existing methods with
considerable margins and delivers seamless, intelligible videos in
person-generic and multilingual scenarios.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01813" title="Abstract">arXiv:2311.01813</a> [<a href="/pdf/2311.01813" title="Download PDF">pdf</a>, <a href="/format/2311.01813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FETV: A Benchmark for Fine-Grained Evaluation of Open-Domain  Text-to-Video Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanxin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Shuhuai Ren</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+R">Rundong Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shicheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sishuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+L">Lu Hou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Datasets and Benchmarks Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, open-domain text-to-video (T2V) generation models have made
remarkable progress. However, the promising results are mainly shown by the
qualitative cases of generated videos, while the quantitative evaluation of T2V
models still faces two critical problems. Firstly, existing studies lack
fine-grained evaluation of T2V models on different categories of text prompts.
Although some benchmarks have categorized the prompts, their categorization
either only focuses on a single aspect or fails to consider the temporal
information in video generation. Secondly, it is unclear whether the automatic
evaluation metrics are consistent with human standards. To address these
problems, we propose FETV, a benchmark for Fine-grained Evaluation of
Text-to-Video generation. FETV is multi-aspect, categorizing the prompts based
on three orthogonal aspects: the major content, the attributes to control and
the prompt complexity. FETV is also temporal-aware, which introduces several
temporal categories tailored for video generation. Based on FETV, we conduct
comprehensive manual evaluations of four representative T2V models, revealing
their pros and cons on different categories of prompts from different aspects.
We also extend FETV as a testbed to evaluate the reliability of automatic T2V
metrics. The multi-aspect categorization of FETV enables fine-grained analysis
of the metrics' reliability in different scenarios. We find that existing
automatic metrics (e.g., CLIPScore and FVD) correlate poorly with human
evaluation. To address this problem, we explore several solutions to improve
CLIPScore and FVD, and develop two automatic metrics that exhibit significant
higher correlation with humans than existing metrics. Benchmark page:
https://github.com/llyx97/FETV.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01815" title="Abstract">arXiv:2311.01815</a> [<a href="/pdf/2311.01815" title="Download PDF">pdf</a>, <a href="/format/2311.01815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimating 3D Uncertainty Field: Quantifying Uncertainty for Neural  Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jianxiong Shen</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+R">Ruijie Ren</a>, 
<a href="/search/cs?searchtype=author&query=Ruiz%2C+A">Adria Ruiz</a>, 
<a href="/search/cs?searchtype=author&query=Moreno-Noguer%2C+F">Francesc Moreno-Noguer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under ICRA review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Current methods based on Neural Radiance Fields (NeRF) significantly lack the
capacity to quantify uncertainty in their predictions, particularly on the
unseen space including the occluded and outside scene content. This limitation
hinders their extensive applications in robotics, where the reliability of
model predictions has to be considered for tasks such as robotic exploration
and planning in unknown environments. To address this, we propose a novel
approach to estimate a 3D Uncertainty Field based on the learned incomplete
scene geometry, which explicitly identifies these unseen regions. By
considering the accumulated transmittance along each camera ray, our
Uncertainty Field infers 2D pixel-wise uncertainty, exhibiting high values for
rays directly casting towards occluded or outside the scene content. To
quantify the uncertainty on the learned surface, we model a stochastic radiance
field. Our experiments demonstrate that our approach is the only one that can
explicitly reason about high uncertainty both on 3D unseen regions and its
involved 2D rendered pixels, compared with recent methods. Furthermore, we
illustrate that our designed uncertainty field is ideally suited for real-world
robotics tasks, such as next-best-view selection.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01817" title="Abstract">arXiv:2311.01817</a> [<a href="/pdf/2311.01817" title="Download PDF">pdf</a>, <a href="/format/2311.01817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Framing Bias with Polarity Minimization Loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bang%2C+Y">Yejin Bang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+N">Nayeon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Fung%2C+P">Pascale Fung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, EMNLP2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Framing bias plays a significant role in exacerbating political polarization
by distorting the perception of actual events. Media outlets with divergent
political stances often use polarized language in their reporting of the same
event. We propose a new loss function that encourages the model to minimize the
polarity difference between the polarized input articles to reduce framing
bias. Specifically, our loss is designed to jointly optimize the model to map
polarity ends bidirectionally. Our experimental results demonstrate that
incorporating the proposed polarity minimization loss leads to a substantial
reduction in framing bias when compared to a BART-based multi-document
summarization model. Notably, we find that the effectiveness of this approach
is most pronounced when the model is trained to minimize the polarity loss
associated with informational framing bias (i.e., skewed selection of
information to report).
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01820" title="Abstract">arXiv:2311.01820</a> [<a href="/pdf/2311.01820" title="Download PDF">pdf</a>, <a href="/format/2311.01820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimalist Grammar: Construction without Overgeneration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maier%2C+I+K">Isidor Konrad Maier</a>, 
<a href="/search/cs?searchtype=author&query=Kuhn%2C+J">Johannes Kuhn</a>, 
<a href="/search/cs?searchtype=author&query=Beisegel%2C+J">Jesse Beisegel</a>, 
<a href="/search/cs?searchtype=author&query=Huber-Liebl%2C+M">Markus Huber-Liebl</a>, 
<a href="/search/cs?searchtype=author&query=Wolff%2C+M">Matthias Wolff</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this paper we give instructions on how to write a minimalist grammar (MG).
In order to present the instructions as an algorithm, we use a variant of
context free grammars (CFG) as an input format. We can exclude overgeneration,
if the CFG has no recursion, i.e. no non-terminal can (indirectly) derive to a
right-hand side containing itself. The constructed MGs utilize licensors/-ees
as a special way of exception handling. A CFG format for a derivation
$A\_eats\_B\mapsto^* peter\_eats\_apples$, where $A$ and $B$ generate noun
phrases, normally leads to overgeneration, e.\,g., $i\_eats\_apples$. In order
to avoid overgeneration, a CFG would need many non-terminal symbols and rules,
that mainly produce the same word, just to handle exceptions. In our MGs
however, we can summarize CFG rules that produce the same word in one item and
handle exceptions by a proper distribution of licensees/-ors. The difficulty
with this technique is that in most generations the majority of licensees/-ors
is not needed, but still has to be triggered somehow. We solve this problem
with $\epsilon$-items called \emph{adapters}.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01822" title="Abstract">arXiv:2311.01822</a> [<a href="/pdf/2311.01822" title="Download PDF">pdf</a>, <a href="/format/2311.01822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Random ISAC Signals Deserve Dedicated Precoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shihang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+F">Fuwang Dong</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yifeng Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Ya-Feng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Shi Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Radar systems typically employ well-designed deterministic signals for target
sensing, while integrated sensing and communications (ISAC) systems have to
adopt random signals to convey useful information. This paper analyzes the
sensing and ISAC performance relying on random signaling in a multiantenna
system. Towards this end, we define a new sensing performance metric, namely,
ergodic linear minimum mean square error (ELMMSE), which characterizes the
estimation error averaged over random ISAC signals. Then, we investigate a
data-dependent precoding (DDP) scheme to minimize the ELMMSE in sensing-only
scenarios, which attains the optimized performance at the cost of high
implementation overhead. To reduce the cost, we present an alternative
data-independent precoding (DIP) scheme by stochastic gradient projection
(SGP). Moreover, we shed light on the optimal structures of both sensing-only
DDP and DIP precoders. As a further step, we extend the proposed DDP and DIP
approaches to ISAC scenarios, which are solved via a tailored penalty-based
alternating optimization algorithm. Our numerical results demonstrate that the
proposed DDP and DIP methods achieve substantial performance gains over
conventional ISAC signaling schemes that treat the signal sample covariance
matrix as deterministic, which proves that random ISAC signals deserve
dedicated precoding designs.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01823" title="Abstract">arXiv:2311.01823</a> [<a href="/pdf/2311.01823" title="Download PDF">pdf</a>, <a href="/format/2311.01823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-LiDAR Localization and Mapping Pipeline for Urban Autonomous  Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sauerbeck%2C+F">Florian Sauerbeck</a>, 
<a href="/search/cs?searchtype=author&query=Kulmer%2C+D">Dominik Kulmer</a>, 
<a href="/search/cs?searchtype=author&query=Pielmeier%2C+M">Markus Pielmeier</a>, 
<a href="/search/cs?searchtype=author&query=Leitenstern%2C+M">Maximilian Leitenstern</a>, 
<a href="/search/cs?searchtype=author&query=Wei%C3%9F%2C+C">Christoph Wei&#xdf;</a>, 
<a href="/search/cs?searchtype=author&query=Betz%2C+J">Johannes Betz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted and presented at IEEE Sensors Conference 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Sensors Conference 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Signal Processing (eess.SP)

</div>
<p class="mathjax">Autonomous vehicles require accurate and robust localization and mapping
algorithms to navigate safely and reliably in urban environments. We present a
novel sensor fusion-based pipeline for offline mapping and online localization
based on LiDAR sensors. The proposed approach leverages four LiDAR sensors.
Mapping and localization algorithms are based on the KISS-ICP, enabling
real-time performance and high accuracy. We introduce an approach to generate
semantic maps for driving tasks such as path planning. The presented pipeline
is integrated into the ROS 2 based Autoware software stack, providing a robust
and flexible environment for autonomous driving applications. We show that our
pipeline outperforms state-of-the-art approaches for a given research vehicle
and real-world autonomous driving application.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01825" title="Abstract">arXiv:2311.01825</a> [<a href="/pdf/2311.01825" title="Download PDF">pdf</a>, <a href="/format/2311.01825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models to the Rescue: Reducing the Complexity in  Scientific Workflow Development Using ChatGPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%C3%A4nger%2C+M">Mario S&#xe4;nger</a>, 
<a href="/search/cs?searchtype=author&query=De+Mecquenem%2C+N">Ninon De Mecquenem</a>, 
<a href="/search/cs?searchtype=author&query=Lewi%C5%84ska%2C+K+E">Katarzyna Ewa Lewi&#x144;ska</a>, 
<a href="/search/cs?searchtype=author&query=Bountris%2C+V">Vasilis Bountris</a>, 
<a href="/search/cs?searchtype=author&query=Lehmann%2C+F">Fabian Lehmann</a>, 
<a href="/search/cs?searchtype=author&query=Leser%2C+U">Ulf Leser</a>, 
<a href="/search/cs?searchtype=author&query=Kosch%2C+T">Thomas Kosch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Scientific workflow systems are increasingly popular for expressing and
executing complex data analysis pipelines over large datasets, as they offer
reproducibility, dependability, and scalability of analyses by automatic
parallelization on large compute clusters. However, implementing workflows is
difficult due to the involvement of many black-box tools and the deep
infrastructure stack necessary for their execution. Simultaneously,
user-supporting tools are rare, and the number of available examples is much
lower than in classical programming languages. To address these challenges, we
investigate the efficiency of Large Language Models (LLMs), specifically
ChatGPT, to support users when dealing with scientific workflows. We performed
three user studies in two scientific domains to evaluate ChatGPT for
comprehending, adapting, and extending workflows. Our results indicate that
LLMs efficiently interpret workflows but achieve lower performance for
exchanging components or purposeful workflow extensions. We characterize their
limitations in these challenging scenarios and suggest future research
directions.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01828" title="Abstract">arXiv:2311.01828</a> [<a href="/pdf/2311.01828" title="Download PDF">pdf</a>, <a href="/format/2311.01828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unbiased Offline Evaluation for Learning to Rank with Business Rules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jakimov%2C+M">Matej Jakimov</a>, 
<a href="/search/cs?searchtype=author&query=Buchholz%2C+A">Alexander Buchholz</a>, 
<a href="/search/cs?searchtype=author&query=Stein%2C+Y">Yannik Stein</a>, 
<a href="/search/cs?searchtype=author&query=Joachims%2C+T">Thorsten Joachims</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">For industrial learning-to-rank (LTR) systems, it is common that the output
of a ranking model is modified, either as a results of post-processing logic
that enforces business requirements, or as a result of unforeseen design flaws
or bugs present in real-world production systems. This poses a challenge for
deploying off-policy learning and evaluation methods, as these often rely on
the assumption that rankings implied by the model's scores coincide with
displayed items to the users. Further requirements for reliable offline
evaluation are proper randomization and correct estimation of the propensities
of displaying each item in any given position of the ranking, which are also
impacted by the aforementioned post-processing. We investigate empirically how
these scenarios impair off-policy evaluation for learning-to-rank models. We
then propose a novel correction method based on the Birkhoff-von-Neumann
decomposition that is robust to this type of post-processing. We obtain more
accurate off-policy estimates in offline experiments, overcoming the problem of
post-processed rankings. To the best of our knowledge this is the first study
on the impact of real-world business rules on offline evaluation of LTR models.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01829" title="Abstract">arXiv:2311.01829</a> [<a href="/pdf/2311.01829" title="Download PDF">pdf</a>, <a href="/format/2311.01829" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mix-ME: Quality-Diversity for Multi-Agent Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ingvarsson%2C+G">Gar&#xf0;ar Ingvarsson</a>, 
<a href="/search/cs?searchtype=author&query=Samvelyan%2C+M">Mikayel Samvelyan</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+B">Bryan Lim</a>, 
<a href="/search/cs?searchtype=author&query=Flageat%2C+M">Manon Flageat</a>, 
<a href="/search/cs?searchtype=author&query=Cully%2C+A">Antoine Cully</a>, 
<a href="/search/cs?searchtype=author&query=Rockt%C3%A4schel%2C+T">Tim Rockt&#xe4;schel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 7 figures. Submitted and accepted to the ALOE workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">In many real-world systems, such as adaptive robotics, achieving a single,
optimised solution may be insufficient. Instead, a diverse set of
high-performing solutions is often required to adapt to varying contexts and
requirements. This is the realm of Quality-Diversity (QD), which aims to
discover a collection of high-performing solutions, each with their own unique
characteristics. QD methods have recently seen success in many domains,
including robotics, where they have been used to discover damage-adaptive
locomotion controllers. However, most existing work has focused on single-agent
settings, despite many tasks of interest being multi-agent. To this end, we
introduce Mix-ME, a novel multi-agent variant of the popular MAP-Elites
algorithm that forms new solutions using a crossover-like operator by mixing
together agents from different teams. We evaluate the proposed methods on a
variety of partially observable continuous control tasks. Our evaluation shows
that these multi-agent variants obtained by Mix-ME not only compete with
single-agent baselines but also often outperform them in multi-agent settings
under partial observability.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01831" title="Abstract">arXiv:2311.01831</a> [<a href="/pdf/2311.01831" title="Download PDF">pdf</a>, <a href="/format/2311.01831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Multi-modal Multi-domain Pre-trained Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wenqi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+R">Ruobing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+S">Shuqing Bian</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W+X">Wayne Xin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">There is a rapidly-growing research interest in modeling user preferences via
pre-training multi-domain interactions for recommender systems. However,
Existing pre-trained multi-domain recommendations mostly select the item texts
to be bridges across domains, and simply explore the user behaviors in target
domains. Hence, they ignore other informative multi-modal item contents (e.g.,
visual information), and also lack of thorough consideration of user behaviors
from all interactive domains. To address these issues, in this paper, we
propose to pre-train universal multi-modal item content presentation for
multi-domain recommendation, called UniM^2Rec, which could smoothly learn the
multi-modal item content presentations and the multi-modal user preferences
from all domains. With the pre-trained multi-domain recommendation model,
UniM^2Rec could be efficiently and effectively transferred to new target
domains in practice. Extensive experiments conducted on five real-world
datasets in target domains demonstrate the superiority of the proposed method
over existing competitive methods, especially for the real-world recommendation
scenarios that usually struggle with seriously missing or noisy item contents.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01832" title="Abstract">arXiv:2311.01832</a> [<a href="/pdf/2311.01832" title="Download PDF">pdf</a>, <a href="/format/2311.01832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Hand-Held Grippers and the Morphological Gap in Human Manipulation  Demonstration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doshi%2C+K">Kiran Doshi</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yijiang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Coros%2C+S">Stelian Coros</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Collecting manipulation demonstrations with robotic hardware is tedious - and
thus difficult to scale. Recording data on robot hardware ensures that it is in
the appropriate format for Learning from Demonstrations (LfD) methods. By
contrast, humans are proficient manipulators, and recording their actions would
be easy to scale, but it is challenging to use that data format with LfD
methods. The question we explore is whether there is a method to collect data
in a format that can be used with LfD while retaining some of the attractive
features of recording human manipulation. We propose equipping humans with
hand-held, hand-actuated parallel grippers and a head-mounted camera to record
demonstrations of manipulation tasks. Using customised and reproducible
grippers, we collect an initial dataset of common manipulation tasks. We show
that there are tasks that, against our initial intuition, can be performed
using parallel grippers. Qualitative insights are obtained regarding the impact
of the difference in morphology on LfD by comparing the strategies used to
complete tasks with human hands and grippers. Our data collection method
bridges the gap between robot- and human-native manipulation demonstration. By
making the design of our gripper prototype available, we hope to reduce other
researchers effort to collect manipulation data.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01833" title="Abstract">arXiv:2311.01833</a> [<a href="/pdf/2311.01833" title="Download PDF">pdf</a>, <a href="/format/2311.01833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Similarity network aggregation for the analysis of glacier ecosystems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ambrosini%2C+R">Roberto Ambrosini</a>, 
<a href="/search/cs?searchtype=author&query=Baccini%2C+F">Federica Baccini</a>, 
<a href="/search/cs?searchtype=author&query=Barabesi%2C+L">Lucio Barabesi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Applications (stat.AP); Methodology (stat.ME)

</div>
<p class="mathjax">The synthesis of information deriving from complex networks is a topic
receiving increasing relevance in ecology and environmental sciences. In
particular, the aggregation of multilayer networks, i.e. network structures
formed by multiple interacting networks (the layers), constitutes a
fast-growing field. In several environmental applications, the layers of a
multilayer network are modelled as a collection of similarity matrices
describing how similar pairs of biological entities are, based on different
types of features (e.g. biological traits). The present paper first discusses
two main techniques for combining the multi-layered information into a single
network (the so-called monoplex), i.e. Similarity Network Fusion (SNF) and
Similarity Matrix Average (SMA). Then, the effectiveness of the two methods is
tested on a real-world dataset of the relative abundance of microbial species
in the ecosystems of nine glaciers (four glaciers in the Alps and five in the
Andes). A preliminary clustering analysis on the monoplexes obtained with
different methods shows the emergence of a tightly connected community formed
by species that are typical of cryoconite holes worldwide. Moreover, the
weights assigned to different layers by the SMA algorithm suggest that two
large South American glaciers (Exploradores and Perito Moreno) are structurally
different from the smaller glaciers in both Europe and South America. Overall,
these results highlight the importance of integration methods in the discovery
of the underlying organizational structure of biological entities in multilayer
ecological networks.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01838" title="Abstract">arXiv:2311.01838</a> [<a href="/pdf/2311.01838" title="Download PDF">pdf</a>, <a href="/ps/2311.01838" title="Download PostScript">ps</a>, <a href="/format/2311.01838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When fairness is an abstraction: Equity and AI in Swedish compulsory  education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mod%C3%A9n%2C+M+U">Marie Utterberg Mod&#xe9;n</a>, 
<a href="/search/cs?searchtype=author&query=Ponti%2C+M">Marisa Ponti</a>, 
<a href="/search/cs?searchtype=author&query=Lundin%2C+J">Johan Lundin</a>, 
<a href="/search/cs?searchtype=author&query=Tallvid%2C+M">Martin Tallvid</a> (Department of Applied Information Technology, University of Gothenburg, Sweden)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Artificial intelligence experts often question whether AI is fair. They view
fairness as a property of AI systems rather than of sociopolitical and economic
systems. This paper emphasizes the need to be fair in the social, political,
and economic contexts within which an educational system operates and uses AI.
Taking Swedish decentralized compulsory education as the context, this paper
examines whether and how the use of AI envisaged by national authorities and
edtech companies exacerbates unfairness. A qualitative content analysis of
selected Swedish policy documents and edtech reports was conducted using the
concept of relevant social groups to understand how different groups view the
risks and benefits of AI for fairness. Three groups that view efficiency as a
key value of AI are identified, and interpreted as economical, pedagogical and
accessibility-related. By separating fairness from social justice, this paper
challenges the notion of fairness as the formal equality of opportunities.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01840" title="Abstract">arXiv:2311.01840</a> [<a href="/pdf/2311.01840" title="Download PDF">pdf</a>, <a href="/format/2311.01840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral Clustering of Attributed Multi-relational Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sadikaj%2C+Y">Ylli Sadikaj</a>, 
<a href="/search/cs?searchtype=author&query=Velaj%2C+Y">Yllka Velaj</a>, 
<a href="/search/cs?searchtype=author&query=Behzadi%2C+S">Sahar Behzadi</a>, 
<a href="/search/cs?searchtype=author&query=Plant%2C+C">Claudia Plant</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Association for Computing Machinery, Proceedings of the 27th ACM
  SIGKDD Conference on Knowledge Discovery and Data Mining, KDD 21, Virtual
  Event, Singapore, August 2021, Pages 1431-1440
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Graph clustering aims at discovering a natural grouping of the nodes such
that similar nodes are assigned to a common cluster. Many different algorithms
have been proposed in the literature: for simple graphs, for graphs with
attributes associated to nodes, and for graphs where edges represent different
types of relations among nodes. However, complex data in many domains can be
represented as both attributed and multi-relational networks.
<br />In this paper, we propose SpectralMix, a joint dimensionality reduction
technique for multi-relational graphs with categorical node attributes.
SpectralMix integrates all information available from the attributes, the
different types of relations, and the graph structure to enable a sound
interpretation of the clustering results. Moreover, it generalizes existing
techniques: it reduces to spectral embedding and clustering when only applied
to a single graph and to homogeneity analysis when applied to categorical data.
Experiments conducted on several real-world datasets enable us to detect
dependencies between graph structure and categorical attributes, moreover, they
exhibit the superiority of SpectralMix over existing methods.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01842" title="Abstract">arXiv:2311.01842</a> [<a href="/pdf/2311.01842" title="Download PDF">pdf</a>, <a href="/ps/2311.01842" title="Download PostScript">ps</a>, <a href="/format/2311.01842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Neural Radiance Field-Based Architecture for Intelligent Multilayered  View Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhinakaran%2C+D">D. Dhinakaran</a>, 
<a href="/search/cs?searchtype=author&query=Sankar%2C+S+M+U">S. M. Udhaya Sankar</a>, 
<a href="/search/cs?searchtype=author&query=Elumalai%2C+G">G. Elumalai</a>, 
<a href="/search/cs?searchtype=author&query=kumar%2C+N+J">N. Jagadish kumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">A mobile ad hoc network is made up of a number of wireless portable nodes
that spontaneously come together en route for establish a transitory network
with no need for any central management. A mobile ad hoc network (MANET) is
made up of a sizable and reasonably dense community of mobile nodes that travel
across any terrain and rely solely on wireless interfaces for communication,
not on any well before centralized management. Furthermore, routing be supposed
to offer a method for instantly delivering data across a network between any
two nodes. Finding the best packet routing from across infrastructure is the
major issue, though. The proposed protocol's major goal is to identify the
least-expensive nominal capacity acquisition that assures the transportation of
realistic transport that ensures its durability in the event of any node
failure. This study suggests the Optimized Route Selection via Red Imported
Fire Ants (RIFA) Strategy as a way to improve on-demand source routing systems.
Predicting Route Failure and energy Utilization is used to pick the path during
the routing phase. Proposed work assess the results of the comparisons based on
performance parameters like as energy usage, packet delivery rate (PDR), and
end-to-end (E2E) delay. The outcome demonstrates that the proposed strategy is
preferable and increases network lifetime while lowering node energy
consumption and typical E2E delay under the majority of network performance
measures and factors.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01843" title="Abstract">arXiv:2311.01843</a> [<a href="/pdf/2311.01843" title="Download PDF">pdf</a>, <a href="/format/2311.01843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Assistance with an Active and Soft Back-Support Exosuit to  Unknown External Loads via Model-Based Estimates of Internal Lumbosacral  Moments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moya-Esteban%2C+A">Alejandro Moya-Esteban</a>, 
<a href="/search/cs?searchtype=author&query=Sridar%2C+S">Saivimal Sridar</a>, 
<a href="/search/cs?searchtype=author&query=Refai%2C+M+I+M">Mohamed Irfan Mohamed Refai</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Kooij%2C+H">Herman van der Kooij</a>, 
<a href="/search/cs?searchtype=author&query=Sartori%2C+M">Massimo Sartori</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">State of the art controllers for back exoskeletons largely rely on body
kinematics. This results in control strategies which cannot provide adaptive
support under unknown external loads. We developed a neuromechanical
model-based controller (NMBC) for a soft back exosuit, wherein assistive forces
were proportional to the active component of lumbosacral joint moments, derived
from real-time electromyography-driven models. The exosuit provided adaptive
assistance forces with no a priori information on the external loading
conditions. Across 10 participants, who stoop-lifted 5 and 15 kg boxes, our
NMBC was compared to a non-adaptive virtual spring-based control(VSBC), in
which exosuit forces were proportional to trunk inclination. Peak cable
assistive forces were modulated across weight conditions for NMBC (5kg: 2.13
N/kg; 15kg: 2.82 N/kg) but not for VSBC (5kg: 1.92 N/kg; 15kg: 2.00 N/kg). The
proposed NMBC strategy resulted in larger reduction of cumulative compression
forces for 5 kg (NMBC: 18.2%; VSBC: 10.7%) and 15 kg conditions (NMBC: 21.3%;
VSBC: 10.2%). Our proposed methodology may facilitate the adoption of
non-hindering wearable robotics in real-life scenarios.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01850" title="Abstract">arXiv:2311.01850</a> [<a href="/pdf/2311.01850" title="Download PDF">pdf</a>, <a href="/ps/2311.01850" title="Download PostScript">ps</a>, <a href="/format/2311.01850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Mobile Learning Platforms for Flexible Education Delivery:  Bridging Educational Gaps in Afghanistan
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dawodi%2C+M">Mursal Dawodi</a>, 
<a href="/search/cs?searchtype=author&query=Baktash%2C+J+A">Jawid Ahmad Baktash</a>, 
<a href="/search/cs?searchtype=author&query=Dawodi%2C+S+M+R">Sayed Mohammad Reza Dawodi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">The educational landscape of Afghanistan, besieged by infrastructural
inadequacies and socio-political tribulations, presents a compelling case for
the integration of mobile learning platforms. This article embarks on an
exploratory voyage into the realms of mobile learning as a potential harbinger
of educational transformation in Afghanistan. It delineates the pervasive
educational challenges, underscores the technological innovations powering
mobile learning platforms, and illuminates the pathways through which mobile
learning can transcend the extant barriers to education. Enriched by real-world
case studies, the narrative unravels the pragmatic lessons that can be
harnessed to tailor mobile learning solutions to Afghanistan's unique context.
The discussion further traverses the collaborative horizon, elucidating the
synergistic interplay among academia, government, the private sector, and
international bodies essential for the successful implementation of mobile
learning platforms. The article also furnishes pragmatic recommendations,
emphasizing the triad of policy formulation, infrastructure enhancement, and
capacity building as cornerstone imperatives. The envisioned integration of
mobile learning platforms augurs a paradigmatic shift towards a more
accessible, inclusive, and resilient educational framework in Afghanistan, with
far-reaching implications for socio-economic development. Through a meticulous
amalgamation of technology, policy, and collaborative endeavors, this article
posits that Afghanistan stands on the cusp of an educational renaissance, with
mobile learning platforms serving as a pivotal conduit toward this envisioned
horizon.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01851" title="Abstract">arXiv:2311.01851</a> [<a href="/pdf/2311.01851" title="Download PDF">pdf</a>, <a href="/format/2311.01851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Holistic Representation Learning for Multitask Trajectory Anomaly  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stergiou%2C+A">Alexandros Stergiou</a>, 
<a href="/search/cs?searchtype=author&query=De+Weerdt%2C+B">Brent De Weerdt</a>, 
<a href="/search/cs?searchtype=author&query=Deligiannis%2C+N">Nikos Deligiannis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Winter Conference on Applications of Computer Vision (WACV) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video anomaly detection deals with the recognition of abnormal events in
videos. Apart from the visual signal, video anomaly detection has also been
addressed with the use of skeleton sequences. We propose a holistic
representation of skeleton trajectories to learn expected motions across
segments at different times. Our approach uses multitask learning to
reconstruct any continuous unobserved temporal segment of the trajectory
allowing the extrapolation of past or future segments and the interpolation of
in-between segments. We use an end-to-end attention-based encoder-decoder. We
encode temporally occluded trajectories, jointly learn latent representations
of the occluded segments, and reconstruct trajectories based on expected
motions across different temporal segments. Extensive experiments on three
trajectory-based video anomaly detection datasets show the advantages and
effectiveness of our approach with state-of-the-art results on anomaly
detection in skeleton trajectories.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01859" title="Abstract">arXiv:2311.01859</a> [<a href="/pdf/2311.01859" title="Download PDF">pdf</a>, <a href="/format/2311.01859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Control Design for Trajectory Tracking and Stabilization of Sensor LOS  in an Inertially Stabilized Platform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Agasti%2C+A">Abinash Agasti</a>, 
<a href="/search/eess?searchtype=author&query=Hazarika%2C+A">Angana Hazarika</a>, 
<a href="/search/eess?searchtype=author&query=Bhikkaji%2C+B">Bharath Bhikkaji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Optical sensors are often mounted on moving platforms to aid in a variety of
tasks like data collection, surveillance and navigation. This necessitates the
precise control of the inertial orientation of the optical sensor line-of-sight
(LOS) towards a desired stationary or mobile target. A two-axis gimbal assembly
is considered to achieve this control objective which can be broken into two
parts - stabilization and tracking. The dynamics of a two-axis gimbal system is
considered under a few design assumptions. Based on this dynamics, a novel
state space model is proposed. Using a suitable change of variables, this state
space model can be transformed into an LTI system. Feedback linearization based
control laws are proposed that achieve the desired objectives of stabilization
and tracking. The effectiveness of these control laws are demonstrated via
simulation in MATLAB based on typical data of a two-axis gimbal system.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01860" title="Abstract">arXiv:2311.01860</a> [<a href="/pdf/2311.01860" title="Download PDF">pdf</a>, <a href="/format/2311.01860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FAME: Flexible, Scalable Analogy Mappings Engine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jacob%2C+S">Shahar Jacob</a>, 
<a href="/search/cs?searchtype=author&query=Shani%2C+C">Chen Shani</a>, 
<a href="/search/cs?searchtype=author&query=Shahaf%2C+D">Dafna Shahaf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 main conference long paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Analogy is one of the core capacities of human cognition; when faced with new
situations, we often transfer prior experience from other domains. Most work on
computational analogy relies heavily on complex, manually crafted input. In
this work, we relax the input requirements, requiring only names of entities to
be mapped. We automatically extract commonsense representations and use them to
identify a mapping between the entities. Unlike previous works, our framework
can handle partial analogies and suggest new entities to be added. Moreover,
our method's output is easily interpretable, allowing for users to understand
why a specific mapping was chosen.
<br />Experiments show that our model correctly maps 81.2% of classical 2x2 analogy
problems (guess level=50%). On larger problems, it achieves 77.8% accuracy
(mean guess level=13.1%). In another experiment, we show our algorithm
outperforms human performance, and the automatic suggestions of new entities
resemble those suggested by humans. We hope this work will advance
computational analogy by paving the way to more flexible, realistic input
requirements, with broader applicability.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01862" title="Abstract">arXiv:2311.01862</a> [<a href="/pdf/2311.01862" title="Download PDF">pdf</a>, <a href="/format/2311.01862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $R^3$-NL2GQL: A Hybrid Models Approach for for Accuracy Enhancing and  Hallucinations Mitigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuhang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">He Yu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+S">Siyu Tian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Liuzhi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xinlin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+C">Chuanjun Ji</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+G">Guangnan Ye</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+H">Hongfeng Chai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Databases (cs.DB)

</div>
<p class="mathjax">While current NL2SQL tasks constructed using Foundation Models have achieved
commendable results, their direct application to Natural Language to Graph
Query Language (NL2GQL) tasks poses challenges due to the significant
differences between GQL and SQL expressions, as well as the numerous types of
GQL. Our extensive experiments reveal that in NL2GQL tasks, larger Foundation
Models demonstrate superior cross-schema generalization abilities, while
smaller Foundation Models struggle to improve their GQL generation capabilities
through fine-tuning. However, after fine-tuning, smaller models exhibit better
intent comprehension and higher grammatical accuracy. Diverging from rule-based
and slot-filling techniques, we introduce R3-NL2GQL, which employs both smaller
and larger Foundation Models as reranker, rewriter and refiner. The approach
harnesses the comprehension ability of smaller models for information reranker
and rewriter, and the exceptional generalization and generation capabilities of
larger models to transform input natural language queries and code structure
schema into any form of GQLs. Recognizing the lack of established datasets in
this nascent domain, we have created a bilingual dataset derived from graph
database documentation and some open-source Knowledge Graphs (KGs). We tested
our approach on this dataset and the experimental results showed that delivers
promising performance and robustness.Our code and dataset is available at
https://github.com/zhiqix/NL2GQL
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01864" title="Abstract">arXiv:2311.01864</a> [<a href="/pdf/2311.01864" title="Download PDF">pdf</a>, <a href="/format/2311.01864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SortNet: Learning To Rank By a Neural-Based Sorting Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rigutini%2C+L">Leonardo Rigutini</a>, 
<a href="/search/cs?searchtype=author&query=Papini%2C+T">Tiziano Papini</a>, 
<a href="/search/cs?searchtype=author&query=Maggini%2C+M">Marco Maggini</a>, 
<a href="/search/cs?searchtype=author&query=Scarselli%2C+F">Franco Scarselli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 31st Annual International ACM SIGIR Conference (SIGIR 2008) - Workshop: Learning to Rank for Information Retrieval (LR4IR), Singapore, July 20-24 2008 - ISBN:978-16-05581-64-4
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of The 31st Annual International ACM SIGIR Conference
  (SIGIR 2008) - Workshop: Learning to Rank for Information Retrieval (LR4IR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Information Retrieval (cs.IR)

</div>
<p class="mathjax">The problem of relevance ranking consists of sorting a set of objects with
respect to a given criterion. Since users may prefer different relevance
criteria, the ranking algorithms should be adaptable to the user needs. Two
main approaches exist in literature for the task of learning to rank: 1) a
score function, learned by examples, which evaluates the properties of each
object yielding an absolute relevance value that can be used to order the
objects or 2) a pairwise approach, where a "preference function" is learned
using pairs of objects to define which one has to be ranked first. In this
paper, we present SortNet, an adaptive ranking algorithm which orders objects
using a neural network as a comparator. The neural network training set
provides examples of the desired ordering between pairs of items and it is
constructed by an iterative procedure which, at each iteration, adds the most
informative training examples. Moreover, the comparator adopts a connectionist
architecture that is particularly suited for implementing a preference
function. We also prove that such an architecture has the universal
approximation property and can implement a wide class of functions. Finally,
the proposed algorithm is evaluated on the LETOR dataset showing promising
performances in comparison with other state of the art algorithms.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01866" title="Abstract">arXiv:2311.01866</a> [<a href="/pdf/2311.01866" title="Download PDF">pdf</a>, <a href="/format/2311.01866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Concept-Aware Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shani%2C+C">Chen Shani</a>, 
<a href="/search/cs?searchtype=author&query=Vreeken%2C+J">Jilles Vreeken</a>, 
<a href="/search/cs?searchtype=author&query=Shahaf%2C+D">Dafna Shahaf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 findings long paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Concepts play a pivotal role in various human cognitive functions, including
learning, reasoning and communication. However, there is very little work on
endowing machines with the ability to form and reason with concepts. In
particular, state-of-the-art large language models (LLMs) work at the level of
tokens, not concepts.
<br />In this work, we analyze how well contemporary LLMs capture human concepts
and their structure. We then discuss ways to develop concept-aware LLMs, taking
place at different stages of the pipeline. We sketch a method for pretraining
LLMs using concepts, and also explore the simpler approach that uses the output
of existing LLMs. Despite its simplicity, our proof-of-concept is shown to
better match human intuition, as well as improve the robustness of predictions.
These preliminary results underscore the promise of concept-aware LLMs.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01870" title="Abstract">arXiv:2311.01870</a> [<a href="/pdf/2311.01870" title="Download PDF">pdf</a>, <a href="/format/2311.01870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-EuP: The Multilingual European Parliament Dataset for Analysis of  Bias in Information Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jinrui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Baldwin%2C+T">Timothy Baldwin</a>, 
<a href="/search/cs?searchtype=author&query=Cohn%2C+T">Trevor Cohn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at The 3rd Multilingual Representation Learning (MRL) Workshop (co-located with EMNLP 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">We present Multi-EuP, a new multilingual benchmark dataset, comprising 22K
multi-lingual documents collected from the European Parliament, spanning 24
languages. This dataset is designed to investigate fairness in a multilingual
information retrieval (IR) context to analyze both language and demographic
bias in a ranking context. It boasts an authentic multilingual corpus,
featuring topics translated into all 24 languages, as well as cross-lingual
relevance judgments. Furthermore, it offers rich demographic information
associated with its documents, facilitating the study of demographic bias. We
report the effectiveness of Multi-EuP for benchmarking both monolingual and
multilingual IR. We also conduct a preliminary experiment on language bias
caused by the choice of tokenization strategy.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01873" title="Abstract">arXiv:2311.01873</a> [<a href="/pdf/2311.01873" title="Download PDF">pdf</a>, <a href="/format/2311.01873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Black-Box Adversarial Attacks on Neural Text Detectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fishchuk%2C+V">Vitalii Fishchuk</a>, 
<a href="/search/cs?searchtype=author&query=Braun%2C+D">Daniel Braun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICNLSP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Neural text detectors are models trained to detect whether a given text was
generated by a language model or written by a human. In this paper, we
investigate three simple and resource-efficient strategies (parameter tweaking,
prompt engineering, and character-level mutations) to alter texts generated by
GPT-3.5 that are unsuspicious or unnoticeable for humans but cause
misclassification by neural text detectors. The results show that especially
parameter tweaking and character-level mutations are effective strategies.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01875" title="Abstract">arXiv:2311.01875</a> [<a href="/pdf/2311.01875" title="Download PDF">pdf</a>, <a href="/format/2311.01875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Functional Data Analysis with Sequential Neural Networks:  Advantages and Comparative Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">J. Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">J. Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">M. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jadhav%2C+S">S. Jadhav</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Functional Data Analysis (FDA) is a statistical domain developed to handle
functional data characterized by high dimensionality and complex data
structures. Sequential Neural Networks (SNNs) are specialized neural networks
capable of processing sequence data, a fundamental aspect of functional data.
Despite their great flexibility in modeling functional data, SNNs have been
inadequately employed in the FDA community. One notable advantage of SNNs is
the ease of implementation, making them accessible to a broad audience beyond
academia. Conversely, FDA-based methodologies present challenges, particularly
for practitioners outside the field, due to their intricate complexity. In
light of this, we propose utilizing SNNs in FDA applications and demonstrate
their effectiveness through comparative analyses against popular FDA regression
models based on numerical experiments and real-world data analysis. SNN
architectures allow us to surpass the limitations of traditional FDA methods,
offering scalability, flexibility, and improved analytical performance. Our
findings highlight the potential of SNN-based methodologies as powerful tools
for data applications involving functional data.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01876" title="Abstract">arXiv:2311.01876</a> [<a href="/pdf/2311.01876" title="Download PDF">pdf</a>, <a href="/format/2311.01876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sentiment Analysis through LLM Negotiations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaofei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoya Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shengyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guoyin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pre-print Version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">A standard paradigm for sentiment analysis is to rely on a singular LLM and
makes the decision in a single round under the framework of in-context
learning. This framework suffers the key disadvantage that the single-turn
output generated by a single LLM might not deliver the perfect decision, just
as humans sometimes need multiple attempts to get things right. This is
especially true for the task of sentiment analysis where deep reasoning is
required to address the complex linguistic phenomenon (e.g., clause
composition, irony, etc) in the input.
<br />To address this issue, this paper introduces a multi-LLM negotiation
framework for sentiment analysis. The framework consists of a reasoning-infused
generator to provide decision along with rationale, a explanation-deriving
discriminator to evaluate the credibility of the generator. The generator and
the discriminator iterate until a consensus is reached. The proposed framework
naturally addressed the aforementioned challenge, as we are able to take the
complementary abilities of two LLMs, have them use rationale to persuade each
other for correction.
<br />Experiments on a wide range of sentiment analysis benchmarks (SST-2, Movie
Review, Twitter, yelp, amazon, IMDB) demonstrate the effectiveness of proposed
approach: it consistently yields better performances than the ICL baseline
across all benchmarks, and even superior performances to supervised baselines
on the Twitter and movie review datasets.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01882" title="Abstract">arXiv:2311.01882</a> [<a href="/pdf/2311.01882" title="Download PDF">pdf</a>, <a href="/format/2311.01882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Indicative Summarization of Long Discussions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Syed%2C+S">Shahbaz Syed</a>, 
<a href="/search/cs?searchtype=author&query=Schwabe%2C+D">Dominik Schwabe</a>, 
<a href="/search/cs?searchtype=author&query=Al-Khatib%2C+K">Khalid Al-Khatib</a>, 
<a href="/search/cs?searchtype=author&query=Potthast%2C+M">Martin Potthast</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP 2023 Main Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Online forums encourage the exchange and discussion of different stances on
many topics. Not only do they provide an opportunity to present one's own
arguments, but may also gather a broad cross-section of others' arguments.
However, the resulting long discussions are difficult to overview. This paper
presents a novel unsupervised approach using large language models (LLMs) to
generating indicative summaries for long discussions that basically serve as
tables of contents. Our approach first clusters argument sentences, generates
cluster labels as abstractive summaries, and classifies the generated cluster
labels into argumentation frames resulting in a two-level summary. Based on an
extensively optimized prompt engineering approach, we evaluate 19~LLMs for
generative cluster labeling and frame classification. To evaluate the
usefulness of our indicative summaries, we conduct a purpose-driven user study
via a new visual interface called Discussion Explorer: It shows that our
proposed indicative summaries serve as a convenient navigation tool to explore
long discussions.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01885" title="Abstract">arXiv:2311.01885</a> [<a href="/pdf/2311.01885" title="Download PDF">pdf</a>, <a href="/format/2311.01885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Randomization via Entropy Maximization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tiboni%2C+G">Gabriele Tiboni</a>, 
<a href="/search/cs?searchtype=author&query=Klink%2C+P">Pascal Klink</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+J">Jan Peters</a>, 
<a href="/search/cs?searchtype=author&query=Tommasi%2C+T">Tatiana Tommasi</a>, 
<a href="/search/cs?searchtype=author&query=D%27Eramo%2C+C">Carlo D&#x27;Eramo</a>, 
<a href="/search/cs?searchtype=author&query=Chalvatzaki%2C+G">Georgia Chalvatzaki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website at <a href="https://gabrieletiboni.github.io/doraemon/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Varying dynamics parameters in simulation is a popular Domain Randomization
(DR) approach for overcoming the reality gap in Reinforcement Learning (RL).
Nevertheless, DR heavily hinges on the choice of the sampling distribution of
the dynamics parameters, since high variability is crucial to regularize the
agent's behavior but notoriously leads to overly conservative policies when
randomizing excessively. In this paper, we propose a novel approach to address
sim-to-real transfer, which automatically shapes dynamics distributions during
training in simulation without requiring real-world data. We introduce DOmain
RAndomization via Entropy MaximizatiON (DORAEMON), a constrained optimization
problem that directly maximizes the entropy of the training distribution while
retaining generalization capabilities. In achieving this, DORAEMON gradually
increases the diversity of sampled dynamics parameters as long as the
probability of success of the current policy is sufficiently high. We
empirically validate the consistent benefits of DORAEMON in obtaining highly
adaptive and generalizable policies, i.e. solving the task at hand across the
widest range of dynamics parameters, as opposed to representative baselines
from the DR literature. Notably, we also demonstrate the Sim2Real applicability
of DORAEMON through its successful zero-shot transfer in a robotic manipulation
setup under unknown real-world parameters.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01886" title="Abstract">arXiv:2311.01886</a> [<a href="/pdf/2311.01886" title="Download PDF">pdf</a>, <a href="/format/2311.01886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging the Gap between Multi-focus and Multi-modal: A Focused  Integration Framework for Multi-modal Image Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xilai Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaosong Li</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+T">Tao Ye</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xiaoqi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wuyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+H">Haishu Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multi-modal image fusion (MMIF) integrates valuable information from
different modality images into a fused one. However, the fusion of multiple
visible images with different focal regions and infrared images is a
unprecedented challenge in real MMIF applications. This is because of the
limited depth of the focus of visible optical lenses, which impedes the
simultaneous capture of the focal information within the same scene. To address
this issue, in this paper, we propose a MMIF framework for joint focused
integration and modalities information extraction. Specifically, a
semi-sparsity-based smoothing filter is introduced to decompose the images into
structure and texture components. Subsequently, a novel multi-scale operator is
proposed to fuse the texture components, capable of detecting significant
information by considering the pixel focus attributes and relevant data from
various modal images. Additionally, to achieve an effective capture of scene
luminance and reasonable contrast maintenance, we consider the distribution of
energy information in the structural components in terms of multi-directional
frequency variance and information entropy. Extensive experiments on existing
MMIF datasets, as well as the object detection and depth estimation tasks,
consistently demonstrate that the proposed algorithm can surpass the
state-of-the-art methods in visual perception and quantitative evaluation. The
code is available at https://github.com/ixilai/MFIF-MMIF.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01890" title="Abstract">arXiv:2311.01890</a> [<a href="/pdf/2311.01890" title="Download PDF">pdf</a>, <a href="/format/2311.01890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameterized algorithms for block-structured integer programs with  large entries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cslovjecsek%2C+J">Jana Cslovjecsek</a>, 
<a href="/search/cs?searchtype=author&query=Kouteck%C3%BD%2C+M">Martin Kouteck&#xfd;</a>, 
<a href="/search/cs?searchtype=author&query=Lassota%2C+A">Alexandra Lassota</a>, 
<a href="/search/cs?searchtype=author&query=Pilipczuk%2C+M">Micha&#x142; Pilipczuk</a>, 
<a href="/search/cs?searchtype=author&query=Polak%2C+A">Adam Polak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages. Extended abstract to appear in the proceedings of SODA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We study two classic variants of block-structured integer programming.
Two-stage stochastic programs are integer programs of the form $\{A_i
\mathbf{x} + D_i \mathbf{y}_i = \mathbf{b}_i\textrm{ for all }i=1,\ldots,n\}$,
where $A_i$ and $D_i$ are bounded-size matrices. On the other hand, $n$-fold
programs are integer programs of the form $\{{\sum_{i=1}^n
C_i\mathbf{y}_i=\mathbf{a}} \textrm{ and } D_i\mathbf{y}_i=\mathbf{b}_i\textrm{
for all }i=1,\ldots,n\}$, where again $C_i$ and $D_i$ are bounded-size
matrices. It is known that solving these kind of programs is fixed-parameter
tractable when parameterized by the maximum dimension among the relevant
matrices $A_i,C_i,D_i$ and the maximum absolute value of any entry appearing in
the constraint matrix.
<br />We show that the parameterized tractability results for two-stage stochastic
and $n$-fold programs persist even when one allows large entries in the global
part of the program. More precisely, we prove that:
<br />- The feasibility problem for two-stage stochastic programs is
fixed-parameter tractable when parameterized by the dimensions of matrices
$A_i,D_i$ and by the maximum absolute value of the entries of matrices $D_i$.
That is, we allow matrices $A_i$ to have arbitrarily large entries.
<br />- The linear optimization problem for $n$-fold integer programs that are
uniform -- all matrices $C_i$ are equal -- is fixed-parameter tractable when
parameterized by the dimensions of matrices $C_i$ and $D_i$ and by the maximum
absolute value of the entries of matrices $D_i$. That is, we require that
$C_i=C$ for all $i=1,\ldots,n$, but we allow $C$ to have arbitrarily large
entries.
<br />In the second result, the uniformity assumption is necessary; otherwise the
problem is $\mathsf{NP}$-hard already when the parameters take constant values.
Both our algorithms are weakly polynomial: the running time is measured in the
total bitsize of the input.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01895" title="Abstract">arXiv:2311.01895</a> [<a href="/pdf/2311.01895" title="Download PDF">pdf</a>, <a href="/ps/2311.01895" title="Download PostScript">ps</a>, <a href="/format/2311.01895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing search engine precision and user experience through  sentiment-based polysemy resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nkongolo%2C+M">Mike Nkongolo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This research article was accepted at the International Journal of Intelligent Systems (Hindawi), titled "News classification and categorization with smart function sentiment analysis". It underwent editing by Yaxin Bi and quality checking by Saranya Manokaran
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">With the proliferation of digital content and the need for efficient
information retrieval, this study's insights can be applied to various domains,
including news services, e-commerce, and digital marketing, to provide users
with more meaningful and tailored experiences. The study addresses the common
problem of polysemy in search engines, where the same keyword may have multiple
meanings. It proposes a solution to this issue by embedding a smart search
function into the search engine, which can differentiate between different
meanings based on sentiment. The study leverages sentiment analysis, a powerful
natural language processing (NLP) technique, to classify and categorize news
articles based on their emotional tone. This can provide more insightful and
nuanced search results. The article reports an impressive accuracy rate of 85%
for the proposed smart search function, which outperforms conventional search
engines. This indicates the effectiveness of the sentiment-based approach. The
research explores multiple sentiment analysis models, including Sentistrength
and Valence Aware Dictionary for Sentiment Reasoning (VADER), to determine the
best-performing approach. The findings can be applied to enhance search
engines, making them more capable of understanding the context and intent
behind users 'queries. This can lead to better search results that are more
aligned with what users are looking for. The proposed smart search function can
improve the user experience by reducing the need to sift through irrelevant
search results. This is particularly important in an age where information
overload is common.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01901" title="Abstract">arXiv:2311.01901</a> [<a href="/pdf/2311.01901" title="Download PDF">pdf</a>, <a href="/format/2311.01901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agent-based Modelling of Credit Card Promotions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamill%2C+C+B">Conor B. Hamill</a>, 
<a href="/search/cs?searchtype=author&query=Khraishi%2C+R">Raad Khraishi</a>, 
<a href="/search/cs?searchtype=author&query=Gherghel%2C+S">Simona Gherghel</a>, 
<a href="/search/cs?searchtype=author&query=Lawrence%2C+J">Jerrard Lawrence</a>, 
<a href="/search/cs?searchtype=author&query=Mercuri%2C+S">Salvatore Mercuri</a>, 
<a href="/search/cs?searchtype=author&query=Okhrati%2C+R">Ramin Okhrati</a>, 
<a href="/search/cs?searchtype=author&query=Cowan%2C+G+A">Greig A. Cowan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; General Economics (econ.GN)

</div>
<p class="mathjax">Interest-free promotions are a prevalent strategy employed by credit card
lenders to attract new customers, yet the research exploring their effects on
both consumers and lenders remains relatively sparse. The process of selecting
an optimal promotion strategy is intricate, involving the determination of an
interest-free period duration and promotion-availability window, all within the
context of competing offers, fluctuating market dynamics, and complex consumer
behaviour. In this paper, we introduce an agent-based model that facilitates
the exploration of various credit card promotions under diverse market
scenarios. Our approach, distinct from previous agent-based models,
concentrates on optimising promotion strategies and is calibrated using
benchmarks from the UK credit card market from 2019 to 2020, with agent
properties derived from historical distributions of the UK population from
roughly the same period. We validate our model against stylised facts and
time-series data, thereby demonstrating the value of this technique for
investigating pricing strategies and understanding credit card customer
behaviour. Our experiments reveal that, in the absence of competitor
promotions, lender profit is maximised by an interest-free duration of
approximately 12 months while market share is maximised by offering the longest
duration possible. When competitors do not offer promotions, extended promotion
availability windows yield maximum profit for lenders while also maximising
market share. In the context of concurrent interest-free promotions, we
identify that the optimal lender strategy entails offering a more competitive
interest-free period and a rapid response to competing promotional offers.
Notably, a delay of three months in responding to a rival promotion corresponds
to a 2.4% relative decline in income.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01902" title="Abstract">arXiv:2311.01902</a> [<a href="/pdf/2311.01902" title="Download PDF">pdf</a>, <a href="/format/2311.01902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High Precision Causal Model Evaluation with Conditional Randomization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cheng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Camera Ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
<p class="mathjax">The gold standard for causal model evaluation involves comparing model
predictions with true effects estimated from randomized controlled trials
(RCT). However, RCTs are not always feasible or ethical to perform. In
contrast, conditionally randomized experiments based on inverse probability
weighting (IPW) offer a more realistic approach but may suffer from high
estimation variance. To tackle this challenge and enhance causal model
evaluation in real-world conditional randomization settings, we introduce a
novel low-variance estimator for causal error, dubbed as the pairs estimator.
By applying the same IPW estimator to both the model and true experimental
effects, our estimator effectively cancels out the variance due to IPW and
achieves a smaller asymptotic variance. Empirical studies demonstrate the
improved of our estimator, highlighting its potential on achieving near-RCT
performance. Our method offers a simple yet powerful solution to evaluate
causal inference models in conditional randomization settings without
complicated modification of the IPW estimator itself, paving the way for more
robust and reliable model assessments.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01905" title="Abstract">arXiv:2311.01905</a> [<a href="/pdf/2311.01905" title="Download PDF">pdf</a>, <a href="/format/2311.01905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Chaos to Calibration: A Geometric Mutual Information Approach to  Target-Free Camera LiDAR Extrinsic Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borer%2C+J">Jack Borer</a>, 
<a href="/search/cs?searchtype=author&query=Tschirner%2C+J">Jeremy Tschirner</a>, 
<a href="/search/cs?searchtype=author&query=%C3%96lsner%2C+F">Florian &#xd6;lsner</a>, 
<a href="/search/cs?searchtype=author&query=Milz%2C+S">Stefan Milz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Sensor fusion is vital for the safe and robust operation of autonomous
vehicles. Accurate extrinsic sensor to sensor calibration is necessary to
accurately fuse multiple sensor's data in a common spatial reference frame. In
this paper, we propose a target free extrinsic calibration algorithm that
requires no ground truth training data, artificially constrained motion
trajectories, hand engineered features or offline optimization and that is
accurate, precise and extremely robust to initialization error.
<br />Most current research on online camera-LiDAR extrinsic calibration requires
ground truth training data which is impossible to capture at scale. We revisit
analytical mutual information based methods first proposed in 2012 and
demonstrate that geometric features provide a robust information metric for
camera-LiDAR extrinsic calibration. We demonstrate our proposed improvement
using the KITTI and KITTI-360 fisheye data set.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01906" title="Abstract">arXiv:2311.01906</a> [<a href="/pdf/2311.01906" title="Download PDF">pdf</a>, <a href="/format/2311.01906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simplifying Transformer Blocks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+B">Bobby He</a>, 
<a href="/search/cs?searchtype=author&query=Hofmann%2C+T">Thomas Hofmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">A simple design recipe for deep Transformers is to compose identical building
blocks. But standard transformer blocks are far from simple, interweaving
attention and MLP sub-blocks with skip connections &amp; normalisation layers in
precise arrangements. This complexity leads to brittle architectures, where
seemingly minor changes can significantly reduce training speed, or render
models untrainable.
<br />In this work, we ask to what extent the standard transformer block can be
simplified? Combining signal propagation theory and empirical observations, we
motivate modifications that allow many block components to be removed with no
loss of training speed, including skip connections, projection or value
parameters, sequential sub-blocks and normalisation layers. In experiments on
both autoregressive decoder-only and BERT encoder-only models, our simplified
transformers emulate the per-update training speed and performance of standard
transformers, while enjoying 15% faster training throughput, and using 15%
fewer parameters.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01907" title="Abstract">arXiv:2311.01907</a> [<a href="/pdf/2311.01907" title="Download PDF">pdf</a>, <a href="/format/2311.01907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BoschAI @ PLABA 2023: Leveraging Edit Operations in End-to-End Neural  Sentence Simplification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Knappich%2C+V">Valentin Knappich</a>, 
<a href="/search/cs?searchtype=author&query=Razniewski%2C+S">Simon Razniewski</a>, 
<a href="/search/cs?searchtype=author&query=Friedrich%2C+A">Annemarie Friedrich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Automatic simplification can help laypeople to comprehend complex scientific
text. Language models are frequently applied to this task by translating from
complex to simple language. In this paper, we describe our system based on
Llama 2, which ranked first in the PLABA shared task addressing the
simplification of biomedical text. We find that the large portion of shared
tokens between input and output leads to weak training signals and
conservatively editing models. To mitigate these issues, we propose
sentence-level and token-level loss weights. They give higher weight to
modified tokens, indicated by edit distance and edit operations, respectively.
We conduct an empirical evaluation on the PLABA dataset and find that both
approaches lead to simplifications closer to those created by human annotators
(+1.8% / +3.5% SARI), simpler language (-1 / -1.1 FKGL) and more edits (1.6x /
1.8x edit distance) compared to the same model fine-tuned with standard cross
entropy. We furthermore show that the hyperparameter $\lambda$ in token-level
loss weights can be used to control the edit distance and the simplicity level
(FKGL).
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01909" title="Abstract">arXiv:2311.01909</a> [<a href="/pdf/2311.01909" title="Download PDF">pdf</a>, <a href="/ps/2311.01909" title="Download PostScript">ps</a>, <a href="/format/2311.01909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Version Age-Optimal Cached Status Updates in a Gossiping Network with  Energy Harvesting Sensor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Delfani%2C+E">Erfan Delfani</a>, 
<a href="/search/cs?searchtype=author&query=Pappas%2C+N">Nikolaos Pappas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for journal publication. A shorter version has been presented at WiOpt 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">In this work, we consider a real-time IoT monitoring system in which an
energy harvesting sensor with a finite-size battery measures a physical process
and transmits the status updates to an aggregator. The aggregator, equipped
with caching capabilities, can serve the external requests of a destination
network with either a stored update or a fresh update from the sensor. We
assume the destination network acts as a gossiping network in which the update
packets are forwarded among the nodes in a randomized setting. We utilize the
Markov Decision Process framework to model and optimize the network's average
Version Age of Information (AoI) and obtain the optimal policy at the
aggregator. The structure of the optimal policy is analytically demonstrated
and numerically verified. Numerical results highlight the effect of the system
parameters on the average Version AoI. The simulations reveal the superior
performance of the optimal policy compared to a set of baseline policies.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01912" title="Abstract">arXiv:2311.01912</a> [<a href="/pdf/2311.01912" title="Download PDF">pdf</a>, <a href="/ps/2311.01912" title="Download PostScript">ps</a>, <a href="/format/2311.01912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-End assessment of AR-assisted neurosurgery systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bagheri%2C+M">Mahdi Bagheri</a>, 
<a href="/search/cs?searchtype=author&query=Piri%2C+F">Farhad Piri</a>, 
<a href="/search/cs?searchtype=author&query=Digale%2C+H">Hadi Digale</a>, 
<a href="/search/cs?searchtype=author&query=Sattarzadeh%2C+S">Saem Sattarzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Mohammadi%2C+M+R">Mohammad Reza Mohammadi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 8figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Augmented Reality (AR) has emerged as a significant advancement in surgical
procedures, offering a solution to the challenges posed by traditional
neuronavigation methods. These conventional techniques often necessitate
surgeons to split their focus between the surgical site and a separate monitor
that displays guiding images. Over the years, many systems have been developed
to register and track the hologram at the targeted locations, each employed its
own evaluation technique. On the other hand, hologram displacement measurement
is not a straightforward task because of various factors such as occlusion,
Vengence-Accomodation Conflict, and unstable holograms in space. In this study,
we explore and classify different techniques for assessing an AR-assisted
neurosurgery system and propose a new technique to systematize the assessment
procedure. Moreover, we conduct a deeper investigation to assess surgeon error
in the pre- and intra-operative phases of the surgery based on the respective
feedback given. We found that although the system can undergo registration and
tracking errors, physical feedback can significantly reduce the error caused by
hologram displacement. However, the lack of visual feedback on the hologram
does not have a significant effect on the user 3D perception.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01914" title="Abstract">arXiv:2311.01914</a> [<a href="/pdf/2311.01914" title="Download PDF">pdf</a>, <a href="/ps/2311.01914" title="Download PostScript">ps</a>, <a href="/format/2311.01914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Redundancy-aware Blockchain-based Partial Computation Offloading  for the Metaverse in In-network Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aliyu%2C+I">Ibrahim Aliyu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Cho-Rong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Um%2C+T">Tai-Won Um</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jinsul Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">The computing in the network (COIN) paradigm has emerged as a potential
solution for computation-intensive applications like the metaverse by utilizing
unused network resources. The blockchain (BC) guarantees task-offloading
privacy, but cost reduction, queueing delays, and redundancy elimination remain
open problems. This paper presents a redundancy-aware BC-based approach for the
metaverse's partial computation offloading (PCO). Specifically, we formulate a
joint BC redundancy factor (BRF) and PCO problem to minimize computation costs,
maximize incentives, and meet delay and BC offloading constraints. We proved
this problem is NP-hard and transformed it into two subproblems based on their
temporal correlation: real-time PCO and Markov decision process-based BRF. We
formulated the PCO problem as a multiuser game, proposed a decentralized
algorithm for Nash equilibrium under any BC redundancy state, and designed a
double deep Q-network-based algorithm for the optimal BRF policy. The BRF
strategy is updated periodically based on user computation demand and network
status to assist the PCO algorithm. The experimental results suggest that the
proposed approach outperforms existing schemes, resulting in a remarkable 47%
reduction in cost overhead, delivering approximately 64% higher rewards, and
achieving convergence in just a few training episodes.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01918" title="Abstract">arXiv:2311.01918</a> [<a href="/pdf/2311.01918" title="Download PDF">pdf</a>, <a href="/format/2311.01918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models Illuminate a Progressive Pathway to Artificial  Healthcare Assistant: A Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+M">Mingze Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+P">Peng Bao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jiajia Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yunhao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zifan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Li Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Lin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+B">Bin Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 1 figure, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">With the rapid development of artificial intelligence, large language models
(LLMs) have shown promising capabilities in mimicking human-level language
comprehension and reasoning. This has sparked significant interest in applying
LLMs to enhance various aspects of healthcare, ranging from medical education
to clinical decision support. However, medicine involves multifaceted data
modalities and nuanced reasoning skills, presenting challenges for integrating
LLMs. This paper provides a comprehensive review on the applications and
implications of LLMs in medicine. It begins by examining the fundamental
applications of general-purpose and specialized LLMs, demonstrating their
utilities in knowledge retrieval, research support, clinical workflow
automation, and diagnostic assistance. Recognizing the inherent multimodality
of medicine, the review then focuses on multimodal LLMs, investigating their
ability to process diverse data types like medical imaging and EHRs to augment
diagnostic accuracy. To address LLMs' limitations regarding personalization and
complex clinical reasoning, the paper explores the emerging development of
LLM-powered autonomous agents for healthcare. Furthermore, it summarizes the
evaluation methodologies for assessing LLMs' reliability and safety in medical
contexts. Overall, this review offers an extensive analysis on the
transformative potential of LLMs in modern medicine. It also highlights the
pivotal need for continuous optimizations and ethical oversight before these
models can be effectively integrated into clinical practice. Visit
https://github.com/mingze-yuan/Awesome-LLM-Healthcare for an accompanying
GitHub repository containing latest papers.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01920" title="Abstract">arXiv:2311.01920</a> [<a href="/pdf/2311.01920" title="Download PDF">pdf</a>, <a href="/format/2311.01920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChartGPT: Leveraging LLMs to Generate Charts from Abstract Natural  Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuan Tian</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+W">Weiwei Cui</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+D">Dazhen Deng</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+X">Xinjing Yi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yurun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haidong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yingcai Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">The use of natural language interfaces (NLIs) for the creation of charts is
becoming increasingly popular due to the intuitiveness of natural language
interactions. One key challenge in this approach is to accurately capture user
intents and transform them to proper chart specifications. This obstructs the
wide use of NLI in chart generation, as users' natural language inputs are
generally abstract (i.e., ambiguous or under-specified), without a clear
specification of visual encodings. Recently, pre-trained large language models
(LLMs) have exhibited superior performance in understanding and generating
natural language, demonstrating great potential for downstream tasks. Inspired
by this major trend, we propose ChartGPT, generating charts from abstract
natural language inputs. However, LLMs are struggling to address complex logic
problems. To enable the model to accurately specify the complex parameters and
perform operations in chart generation, we decompose the generation process
into a step-by-step reasoning pipeline, so that the model only needs to reason
a single and specific sub-task during each run. Moreover, LLMs are pre-trained
on general datasets, which might be biased for the task of chart generation. To
provide adequate visualization knowledge, we create a dataset consisting of
abstract utterances and charts and improve model performance through
fine-tuning. We further design an interactive interface for ChartGPT that
allows users to check and modify the intermediate outputs of each step. The
effectiveness of the proposed system is evaluated through quantitative
evaluations and a user study.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01924" title="Abstract">arXiv:2311.01924</a> [<a href="/pdf/2311.01924" title="Download PDF">pdf</a>, <a href="/ps/2311.01924" title="Download PostScript">ps</a>, <a href="/format/2311.01924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cascadic Tensor Multigrid Method and Economic Cascadic Tensor Multigrid  Method for Image Restoration Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yan%2C+Z">Ziqi Yan</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+C">Chenliang Li</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+Y">Yuhan Chen</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> American Journal of Numerical Analysis. 2023; 7(1):1-8
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">A cascadic tensor multigrid method and an economic cascadic tensor multigrid
method is presented for solving the image restoration models. The methods use
quadratic interpolation as prolongation operator to provide more accurate
initial values for the next fine grid level, and constructs a
preserving-edge-denoising operator to obtain better edges and remove noise. The
experimental results show that the new methods not only improves computational
efficiency but also achieve better restoration quality.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01927" title="Abstract">arXiv:2311.01927</a> [<a href="/pdf/2311.01927" title="Download PDF">pdf</a>, <a href="/format/2311.01927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GateLoop: Fully Data-Controlled Linear Recurrence for Sequence Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Katsch%2C+T">Tobias Katsch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 10 figures, ICLR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Linear Recurrence has proven to be a powerful tool for modeling long
sequences efficiently. In this work, we show that existing models fail to take
full advantage of its potential. Motivated by this finding, we develop
GateLoop, a foundational sequence model that generalizes linear recurrent
models such as S4, S5, LRU and RetNet, by employing data-controlled state
transitions. Utilizing this theoretical advance, GateLoop empirically
outperforms existing models for auto-regressive language modeling. Our method
comes with a low-cost $O(l)$ recurrent mode and an efficient $O(l \log_{2} l)$
parallel mode making use of highly optimized associative scan implementations.
Furthermore, we derive an $O(l^2)$ surrogate attention mode, revealing
remarkable implications for Transformer and recently proposed architectures.
Specifically, we prove that our approach can be interpreted as providing
data-controlled relative-positional information to Attention. While many
existing models solely rely on data-controlled cumulative sums for context
aggregation, our findings suggest that incorporating data-controlled complex
cumulative products may be a crucial step towards more powerful sequence
models.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01928" title="Abstract">arXiv:2311.01928</a> [<a href="/pdf/2311.01928" title="Download PDF">pdf</a>, <a href="/format/2311.01928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constructing Temporal Dynamic Knowledge Graphs from Interactive  Text-based Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+K+P">Keunwoo Peter Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In natural language processing, interactive text-based games serve as a test
bed for interactive AI systems. Prior work has proposed to play text-based
games by acting based on discrete knowledge graphs constructed by the Discrete
Graph Updater (DGU) to represent the game state from the natural language
description. While DGU has shown promising results with high interpretability,
it suffers from lower knowledge graph accuracy due to its lack of temporality
and limited generalizability to complex environments with objects with the same
label. In order to address DGU's weaknesses while preserving its high
interpretability, we propose the Temporal Discrete Graph Updater (TDGU), a
novel neural network model that represents dynamic knowledge graphs as a
sequence of timestamped graph events and models them using a temporal point
based graph neural network. Through experiments on the dataset collected from a
text-based game TextWorld, we show that TDGU outperforms the baseline DGU. We
further show the importance of temporal information for TDGU's performance
through an ablation study and demonstrate that TDGU has the ability to
generalize to more complex environments with objects with the same label. All
the relevant code can be found at
\url{https://github.com/yukw777/temporal-discrete-graph-updater}.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01929" title="Abstract">arXiv:2311.01929</a> [<a href="/pdf/2311.01929" title="Download PDF">pdf</a>, <a href="/format/2311.01929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProS: Facial Omni-Representation Learning via Prototype-based  Self-Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Di%2C+X">Xing Di</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yiyu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yu Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted in WACV2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents a novel approach, called Prototype-based
Self-Distillation (ProS), for unsupervised face representation learning. The
existing supervised methods heavily rely on a large amount of annotated
training facial data, which poses challenges in terms of data collection and
privacy concerns. To address these issues, we propose ProS, which leverages a
vast collection of unlabeled face images to learn a comprehensive facial
omni-representation. In particular, ProS consists of two vision-transformers
(teacher and student models) that are trained with different augmented images
(cropping, blurring, coloring, etc.). Besides, we build a face-aware retrieval
system along with augmentations to obtain the curated images comprising
predominantly facial areas. To enhance the discrimination of learned features,
we introduce a prototype-based matching loss that aligns the similarity
distributions between features (teacher or student) and a set of learnable
prototypes. After pre-training, the teacher vision transformer serves as a
backbone for downstream tasks, including attribute estimation, expression
recognition, and landmark alignment, achieved through simple fine-tuning with
additional layers. Extensive experiments demonstrate that our method achieves
state-of-the-art performance on various tasks, both in full and few-shot
settings. Furthermore, we investigate pre-training with synthetic face images,
and ProS exhibits promising performance in this scenario as well.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01933" title="Abstract">arXiv:2311.01933</a> [<a href="/pdf/2311.01933" title="Download PDF">pdf</a>, <a href="/format/2311.01933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ForecastPFN: Synthetically-Trained Zero-Shot Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dooley%2C+S">Samuel Dooley</a>, 
<a href="/search/cs?searchtype=author&query=Khurana%2C+G+S">Gurnoor Singh Khurana</a>, 
<a href="/search/cs?searchtype=author&query=Mohapatra%2C+C">Chirag Mohapatra</a>, 
<a href="/search/cs?searchtype=author&query=Naidu%2C+S">Siddartha Naidu</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+C">Colin White</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Thirty-seventh Conference on Neural Information Processing
  Systems, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The vast majority of time-series forecasting approaches require a substantial
training dataset. However, many real-life forecasting applications have very
little initial observations, sometimes just 40 or fewer. Thus, the
applicability of most forecasting methods is restricted in data-sparse
commercial applications. While there is recent work in the setting of very
limited initial data (so-called `zero-shot' forecasting), its performance is
inconsistent depending on the data used for pretraining. In this work, we take
a different approach and devise ForecastPFN, the first zero-shot forecasting
model trained purely on a novel synthetic data distribution. ForecastPFN is a
prior-data fitted network, trained to approximate Bayesian inference, which can
make predictions on a new time series dataset in a single forward pass. Through
extensive experiments, we show that zero-shot predictions made by ForecastPFN
are more accurate and faster compared to state-of-the-art forecasting methods,
even when the other methods are allowed to train on hundreds of additional
in-distribution data points.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01934" title="Abstract">arXiv:2311.01934</a> [<a href="/pdf/2311.01934" title="Download PDF">pdf</a>, <a href="/format/2311.01934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does Difficulty even Matter? Investigating Difficulty Adjustment and  Practice Behavior in an Open-Ended Learning Task
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sch%C3%BCtt%2C+A">Anan Sch&#xfc;tt</a>, 
<a href="/search/cs?searchtype=author&query=Huber%2C+T">Tobias Huber</a>, 
<a href="/search/cs?searchtype=author&query=Nasir%2C+J">Jauwairia Nasir</a>, 
<a href="/search/cs?searchtype=author&query=Conati%2C+C">Cristina Conati</a>, 
<a href="/search/cs?searchtype=author&query=Andr%C3%A9%2C+E">Elisabeth Andr&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Difficulty adjustment in practice exercises has been shown to be beneficial
for learning. However, previous research has mostly investigated close-ended
tasks, which do not offer the students multiple ways to reach a valid solution.
Contrary to this, in order to learn in an open-ended learning task, students
need to effectively explore the solution space as there are multiple ways to
reach a solution. For this reason, the effects of difficulty adjustment could
be different for open-ended tasks. To investigate this, as our first
contribution, we compare different methods of difficulty adjustment in a user
study conducted with 86 participants. Furthermore, as the practice behavior of
the students is expected to influence how well the students learn, we
additionally look at their practice behavior as a post-hoc analysis. Therefore,
as a second contribution, we identify different types of practice behavior and
how they link to students' learning outcomes and subjective evaluation measures
as well as explore the influence the difficulty adjustment methods have on the
practice behaviors. Our results suggest the usefulness of taking into account
the practice behavior in addition to only using the practice performance to
inform adaptive intervention and difficulty adjustment methods.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01937" title="Abstract">arXiv:2311.01937</a> [<a href="/pdf/2311.01937" title="Download PDF">pdf</a>, <a href="/format/2311.01937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Supermind Ideator: Exploring generative AI to support creative  problem-solving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rick%2C+S+R">Steven R. Rick</a>, 
<a href="/search/cs?searchtype=author&query=Giacomelli%2C+G">Gianni Giacomelli</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+H">Haoran Wen</a>, 
<a href="/search/cs?searchtype=author&query=Laubacher%2C+R+J">Robert J. Laubacher</a>, 
<a href="/search/cs?searchtype=author&query=Taubenslag%2C+N">Nancy Taubenslag</a>, 
<a href="/search/cs?searchtype=author&query=Heyman%2C+J+L">Jennifer L. Heyman</a>, 
<a href="/search/cs?searchtype=author&query=Knicker%2C+M+S">Max Sina Knicker</a>, 
<a href="/search/cs?searchtype=author&query=Jeddi%2C+Y">Younes Jeddi</a>, 
<a href="/search/cs?searchtype=author&query=Maier%2C+H">Hendrik Maier</a>, 
<a href="/search/cs?searchtype=author&query=Dwyer%2C+S">Stephen Dwyer</a>, 
<a href="/search/cs?searchtype=author&query=Ragupathy%2C+P">Pranav Ragupathy</a>, 
<a href="/search/cs?searchtype=author&query=Malone%2C+T+W">Thomas W. Malone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures, working paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Previous efforts to support creative problem-solving have included (a)
techniques (such as brainstorming and design thinking) to stimulate creative
ideas, and (b) software tools to record and share these ideas. Now, generative
AI technologies can suggest new ideas that might never have occurred to the
users, and users can then select from these ideas or use them to stimulate even
more ideas. Here, we describe such a system, Supermind Ideator. The system uses
a large language model (GPT 3.5) and adds prompting, fine tuning, and a user
interface specifically designed to help people use creative problem-solving
techniques. Some of these techniques can be applied to any problem; others are
specifically intended to help generate innovative ideas about how to design
groups of people and/or computers ("superminds"). We also describe our early
experiences with using this system and suggest ways it could be extended to
support additional techniques for other specific problem-solving domains.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01939" title="Abstract">arXiv:2311.01939</a> [<a href="/pdf/2311.01939" title="Download PDF">pdf</a>, <a href="/format/2311.01939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Quantitative Autonomy Quantification Framework for Fully Autonomous  Robotic Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gyagenda%2C+N">Nasser Gyagenda</a> (1), 
<a href="/search/cs?searchtype=author&query=Roth%2C+H">Hubert Roth</a> (1) ((1) University of Siegen)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures and 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Although autonomous functioning facilitates deployment of robotic systems in
domains that admit limited human oversight on our planet and beyond, finding
correspondence between task requirements and autonomous capability is still an
open challenge. Consequently, a number of methods for quantifying autonomy have
been proposed over the last three decades, but to our knowledge all these have
no discernment of sub-mode features of variation of autonomy and some are based
on metrics that violet the Goodhart's law. This paper focuses on the full
autonomous mode and proposes a task-requirements based autonomy assessment
framework. The framework starts by establishing robot task characteristics from
which three autonomy metrics, namely requisite capability, reliability and
responsiveness, and functions for determining autonomy as a two-part measure,
namely of level of autonomy and degree of autonomy are derived. These
characteristics are founded on the realization that robots ultimately replace
human skilled workers, to find a mapping between human job and robot task
characteristics. The distinction between level and degree of autonomy stemmed
from the acknowledgment that autonomy is not just a question of existence, but
also one of performance of requisite capability. When continuously monitored,
the proposed metrics provide a means of monitoring the integrity of a system.
The framework has been demonstrated on two case studies, namely autonomous
vehicle at an on-road dynamic driving task and the DARPA subT challenge rules
analysis. The framework provides not only a tool for quantifying autonomy, but
also a regulatory interface and common language for autonomous systems
developers and users.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01944" title="Abstract">arXiv:2311.01944</a> [<a href="/pdf/2311.01944" title="Download PDF">pdf</a>, <a href="/format/2311.01944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Swarm Performance Indicators: Metrics for Robustness, Fault Tolerance,  Scalability and Adaptability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Milner%2C+E">Emma Milner</a>, 
<a href="/search/cs?searchtype=author&query=Sooriyabandara%2C+M">Mahesh Sooriyabandara</a>, 
<a href="/search/cs?searchtype=author&query=Hauert%2C+S">Sabine Hauert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Swarms have distributed control and so are assumed to inherently have
superior robustness, scalability and adaptability compared to centralised
multi-agent systems. However, these features have generally only been defined
qualitatively and there is a lack of quantitative metrics and experimental
measures for the claimed parameters. Swarm Performance Indicators are defined
here as Key Performance Indicators for swarm features but can be applied to
multi-agent systems with centralised control as well. These swarm features are
Robustness, Fault Tolerance, Adaptability and Scalability. Swarm Performance
Indicators can be used to highlight the benefits of swarms beyond solely
considering task-based performance metrics (e.g. time taken)
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01949" title="Abstract">arXiv:2311.01949</a> [<a href="/pdf/2311.01949" title="Download PDF">pdf</a>, <a href="/format/2311.01949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hint-enhanced In-Context Learning wakes Large Language Models up for  knowledge-intensive tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qingyan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+X">Xinzhe Ni</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chufan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lemao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Haiyun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yujiu Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In-context learning (ICL) ability has emerged with the increasing scale of
large language models (LLMs), enabling them to learn input-label mappings from
demonstrations and perform well on downstream tasks. However, under the
standard ICL setting, LLMs may sometimes neglect query-related information in
demonstrations, leading to incorrect predictions. To address this limitation,
we propose a new paradigm called Hint-enhanced In-Context Learning (HICL) to
explore the power of ICL in open-domain question answering, an important form
in knowledge-intensive tasks. HICL leverages LLMs' reasoning ability to extract
query-related knowledge from demonstrations, then concatenates the knowledge to
prompt LLMs in a more explicit way. Furthermore, we track the source of this
knowledge to identify specific examples, and introduce a Hint-related Example
Retriever (HER) to select informative examples for enhanced demonstrations. We
evaluate HICL with HER on 3 open-domain QA benchmarks, and observe average
performance gains of 2.89 EM score and 2.52 F1 score on gpt-3.5-turbo, 7.62 EM
score and 7.27 F1 score on LLaMA-2-Chat-7B compared with standard setting.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01950" title="Abstract">arXiv:2311.01950</a> [<a href="/pdf/2311.01950" title="Download PDF">pdf</a>, <a href="/format/2311.01950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Lower Bound for the Max Entropy Algorithm for TSP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+B">Billy Jin</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+N">Nathan Klein</a>, 
<a href="/search/cs?searchtype=author&query=Williamson%2C+D+P">David P. Williamson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">One of the most famous conjectures in combinatorial optimization is the
four-thirds conjecture, which states that the integrality gap of the subtour LP
relaxation of the TSP is equal to $\frac43$. For 40 years, the best known upper
bound was 1.5, due to Wolsey (1980). Recently, Karlin, Klein, and Oveis Gharan
(2022) showed that the max entropy algorithm for the TSP gives an improved
bound of $1.5 - 10^{-36}$. In this paper, we show that the approximation ratio
of the max entropy algorithm is at least 1.375, even for graphic TSP. Thus the
max entropy algorithm does not appear to be the algorithm that will ultimately
resolve the four-thirds conjecture in the affirmative, should that be possible.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01953" title="Abstract">arXiv:2311.01953</a> [<a href="/pdf/2311.01953" title="Download PDF">pdf</a>, <a href="/format/2311.01953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimistic Multi-Agent Policy Gradient for Cooperative Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wenshuai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Kannala%2C+J">Juho Kannala</a>, 
<a href="/search/cs?searchtype=author&query=Pajarinen%2C+J">Joni Pajarinen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">\textit{Relative overgeneralization} (RO) occurs in cooperative multi-agent
learning tasks when agents converge towards a suboptimal joint policy due to
overfitting to suboptimal behavior of other agents. In early work, optimism has
been shown to mitigate the \textit{RO} problem when using tabular Q-learning.
However, with function approximation optimism can amplify overestimation and
thus fail on complex tasks. On the other hand, recent deep multi-agent policy
gradient (MAPG) methods have succeeded in many complex tasks but may fail with
severe \textit{RO}. We propose a general, yet simple, framework to enable
optimistic updates in MAPG methods and alleviate the RO problem. Specifically,
we employ a \textit{Leaky ReLU} function where a single hyperparameter selects
the degree of optimism to reshape the advantages when updating the policy.
Intuitively, our method remains optimistic toward individual actions with lower
returns which are potentially caused by other agents' sub-optimal behavior
during learning. The optimism prevents the individual agents from quickly
converging to a local optimum. We also provide a formal analysis from an
operator view to understand the proposed advantage transformation. In extensive
evaluations on diverse sets of tasks, including illustrative matrix games,
complex \textit{Multi-agent MuJoCo} and \textit{Overcooked} benchmarks, the
proposed method\footnote{Code can be found at
\url{https://github.com/wenshuaizhao/optimappo}.} outperforms strong baselines
on 13 out of 19 tested tasks and matches the performance on the rest.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01955" title="Abstract">arXiv:2311.01955</a> [<a href="/pdf/2311.01955" title="Download PDF">pdf</a>, <a href="/format/2311.01955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Too Much Information: Keeping Training Simple for BabyLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Edman%2C+L">Lukas Edman</a>, 
<a href="/search/cs?searchtype=author&query=Bylinina%2C+L">Lisa Bylinina</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper details the work of the University of Groningen for the BabyLM
Challenge. We follow the idea that, like babies, language models should be
introduced to simpler concepts first and build off of that knowledge to
understand more complex concepts. We examine this strategy of
simple-then-complex through a variety of lenses, namely context size,
vocabulary, and overall linguistic complexity of the data. We find that only
one, context size, is truly beneficial to training a language model. However
this simple change to context size gives us improvements of 2 points on average
on (Super)GLUE tasks, 1 point on MSGS tasks, and 12\% on average on BLiMP
tasks. Our context-limited model outperforms the baseline that was trained on
10$\times$ the amount of data.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01956" title="Abstract">arXiv:2311.01956</a> [<a href="/pdf/2311.01956" title="Download PDF">pdf</a>, <a href="/format/2311.01956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Architecture of Smart Certificates for Web3 Applications Against  Cyberthreats in Financial Industry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Behfar%2C+S+K">Stefan Kambiz Behfar</a>, 
<a href="/search/cs?searchtype=author&query=Crowcroft%2C+J">Jon Crowcroft</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This study addresses the security challenges associated with the current
internet transformations, specifically focusing on emerging technologies such
as blockchain and decentralized storage. It also investigates the role of Web3
applications in shaping the future of the internet. The primary objective is to
propose a novel design for 'smart certificates,' which are digital certificates
that can be programmatically enforced. Utilizing such certificates, an
enterprise can better protect itself from cyberattacks and ensure the security
of its data and systems. Web3 recent security solutions by companies and
projects like Certik, Forta, Slither, and Securify are the equivalent of code
scanning tool that were originally developed for Web1 and Web2 applications,
and definitely not like certificates to help enterprises feel safe against
cyberthreats. We aim to improve the resilience of enterprises' digital
infrastructure by building on top of Web3 application and put methodologies in
place for vulnerability analysis and attack correlation, focusing on
architecture of different layers, Wallet/Client, Application and Smart
Contract, where specific components are provided to identify and predict
threats and risks. Furthermore, Certificate Transparency is used for enhancing
the security, trustworthiness and decentralized management of the certificates,
and detecting misuses, compromises, and malfeasances.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01960" title="Abstract">arXiv:2311.01960</a> [<a href="/pdf/2311.01960" title="Download PDF">pdf</a>, <a href="/ps/2311.01960" title="Download PostScript">ps</a>, <a href="/format/2311.01960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hardness of Low Rank Approximation of Entrywise Transformed Matrix  Products
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarlos%2C+T">Tamas Sarlos</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xingyou Song</a>, 
<a href="/search/cs?searchtype=author&query=Woodruff%2C+D">David Woodruff</a>, 
<a href="/search/cs?searchtype=author&query=Qiuyi">Qiuyi</a> (Richard)
<a href="/search/cs?searchtype=author&query=Zhang">Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted and formatted in Neurips 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Inspired by fast algorithms in natural language processing, we study low rank
approximation in the entrywise transformed setting where we want to find a good
rank $k$ approximation to $f(U \cdot V)$, where $U, V^\top \in \mathbb{R}^{n
\times r}$ are given, $r = O(\log(n))$, and $f(x)$ is a general scalar
function. Previous work in sublinear low rank approximation has shown that if
both (1) $U = V^\top$ and (2) $f(x)$ is a PSD kernel function, then there is an
$O(nk^{\omega-1})$ time constant relative error approximation algorithm, where
$\omega \approx 2.376$ is the exponent of matrix multiplication. We give the
first conditional time hardness results for this problem, demonstrating that
both conditions (1) and (2) are in fact necessary for getting better than
$n^{2-o(1)}$ time for a relative error low rank approximation for a wide class
of functions. We give novel reductions from the Strong Exponential Time
Hypothesis (SETH) that rely on lower bounding the leverage scores of flat
sparse vectors and hold even when the rank of the transformed matrix $f(UV)$
and the target rank are $n^{o(1)}$, and when $U = V^\top$. Furthermore, even
when $f(x) = x^p$ is a simple polynomial, we give runtime lower bounds in the
case when $U \neq V^\top$ of the form $\Omega(\min(n^{2-o(1)}, \Omega(2^p)))$.
Lastly, we demonstrate that our lower bounds are tight by giving an $O(n \cdot
\text{poly}(k, 2^p, 1/\epsilon))$ time relative error approximation algorithm
and a fast $O(n \cdot \text{poly}(k, p, 1/\epsilon))$ additive error
approximation using fast tensor-based sketching. Additionally, since our low
rank algorithms rely on matrix-vector product subroutines, our lower bounds
extend to show that computing $f(UV)W$, for even a small matrix $W$, requires
$\Omega(n^{2-o(1)})$ time.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01961" title="Abstract">arXiv:2311.01961</a> [<a href="/pdf/2311.01961" title="Download PDF">pdf</a>, <a href="/format/2311.01961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing Fidelity in XAI post-hoc techniques: A Comparative Study with  Ground Truth Explanations Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mir%C3%B3-Nicolau%2C+M">M. Mir&#xf3;-Nicolau</a>, 
<a href="/search/cs?searchtype=author&query=Jaume-i-Cap%C3%B3%2C+A">A. Jaume-i-Cap&#xf3;</a>, 
<a href="/search/cs?searchtype=author&query=Moy%C3%A0-Alcover%2C+G">G. Moy&#xe0;-Alcover</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The evaluation of the fidelity of eXplainable Artificial Intelligence (XAI)
methods to their underlying models is a challenging task, primarily due to the
absence of a ground truth for explanations. However, assessing fidelity is a
necessary step for ensuring a correct XAI methodology. In this study, we
conduct a fair and objective comparison of the current state-of-the-art XAI
methods by introducing three novel image datasets with reliable ground truth
for explanations. The primary objective of this comparison is to identify
methods with low fidelity and eliminate them from further research, thereby
promoting the development of more trustworthy and effective XAI techniques. Our
results demonstrate that XAI methods based on the backpropagation of output
information to input yield higher accuracy and reliability compared to methods
relying on sensitivity analysis or Class Activation Maps (CAM). However, the
backpropagation method tends to generate more noisy saliency maps. These
findings have significant implications for the advancement of XAI methods,
enabling the elimination of erroneous explanations and fostering the
development of more robust and reliable XAI.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01964" title="Abstract">arXiv:2311.01964</a> [<a href="/pdf/2311.01964" title="Download PDF">pdf</a>, <a href="/format/2311.01964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Don&#x27;t Make Your LLM an Evaluation Benchmark Cheater
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yutao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhipeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wentong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W+X">Wayne Xin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yankai Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Ji-Rong Wen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jiawei Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models~(LLMs) have greatly advanced the frontiers of
artificial intelligence, attaining remarkable improvement in model capacity. To
assess the model performance, a typical approach is to construct evaluation
benchmarks for measuring the ability level of LLMs in different aspects.
Despite that a number of high-quality benchmarks have been released, the
concerns about the appropriate use of these benchmarks and the fair comparison
of different models are increasingly growing. Considering these concerns, in
this paper, we discuss the potential risk and impact of inappropriately using
evaluation benchmarks and misleadingly interpreting the evaluation results.
Specially, we focus on a special issue that would lead to inappropriate
evaluation, \ie \emph{benchmark leakage}, referring that the data related to
evaluation sets is occasionally used for model training. This phenomenon now
becomes more common since pre-training data is often prepared ahead of model
test. We conduct extensive experiments to study the effect of benchmark
leverage, and find that it can dramatically boost the evaluation results, which
would finally lead to an unreliable assessment of model performance. To improve
the use of existing evaluation benchmarks, we finally present several
guidelines for both LLM developers and benchmark maintainers. We hope this work
can draw attention to appropriate training and evaluation of LLMs.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01966" title="Abstract">arXiv:2311.01966</a> [<a href="/pdf/2311.01966" title="Download PDF">pdf</a>, <a href="/format/2311.01966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Depth-guided Free-space Segmentation for a Mobile Robot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sevastopoulos%2C+C">Christos Sevastopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Hussain%2C+J">Joey Hussain</a>, 
<a href="/search/cs?searchtype=author&query=Konstantopoulos%2C+S">Stasinos Konstantopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Karkaletsis%2C+V">Vangelis Karkaletsis</a>, 
<a href="/search/cs?searchtype=author&query=Makedon%2C+F">Fillia Makedon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Accurate indoor free-space segmentation is a challenging task due to the
complexity and the dynamic nature that indoor environments exhibit. We propose
an indoors free-space segmentation method that associates large depth values
with navigable regions. Our method leverages an unsupervised masking technique
that, using positive instances, generates segmentation labels based on textural
homogeneity and depth uniformity. Moreover, we generate superpixels
corresponding to areas of higher depth and align them with features extracted
from a Dense Prediction Transformer (DPT). Using the estimated free-space masks
and the DPT feature representation, a SegFormer model is fine-tuned on our
custom-collected indoor dataset. Our experiments demonstrate sufficient
performance in intricate scenarios characterized by cluttered obstacles and
challenging identification of free space.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01967" title="Abstract">arXiv:2311.01967</a> [<a href="/pdf/2311.01967" title="Download PDF">pdf</a>, <a href="/format/2311.01967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The language of prompting: What linguistic properties make a prompt  successful?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leidinger%2C+A">Alina Leidinger</a>, 
<a href="/search/cs?searchtype=author&query=van+Rooij%2C+R">Robert van Rooij</a>, 
<a href="/search/cs?searchtype=author&query=Shutova%2C+E">Ekaterina Shutova</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The latest generation of LLMs can be prompted to achieve impressive zero-shot
or few-shot performance in many NLP tasks. However, since performance is highly
sensitive to the choice of prompts, considerable effort has been devoted to
crowd-sourcing prompts or designing methods for prompt optimisation. Yet, we
still lack a systematic understanding of how linguistic properties of prompts
correlate with task performance. In this work, we investigate how LLMs of
different sizes, pre-trained and instruction-tuned, perform on prompts that are
semantically equivalent, but vary in linguistic structure. We investigate both
grammatical properties such as mood, tense, aspect and modality, as well as
lexico-semantic variation through the use of synonyms. Our findings contradict
the common assumption that LLMs achieve optimal performance on lower perplexity
prompts that reflect language use in pretraining or instruction-tuning data.
Prompts transfer poorly between datasets or models, and performance cannot
generally be explained by perplexity, word frequency, ambiguity or prompt
length. Based on our results, we put forward a proposal for a more robust and
comprehensive evaluation standard for prompting research.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01977" title="Abstract">arXiv:2311.01977</a> [<a href="/pdf/2311.01977" title="Download PDF">pdf</a>, <a href="/format/2311.01977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory  Sketches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jiayuan Gu</a>, 
<a href="/search/cs?searchtype=author&query=Kirmani%2C+S">Sean Kirmani</a>, 
<a href="/search/cs?searchtype=author&query=Wohlhart%2C+P">Paul Wohlhart</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Arenas%2C+M+G">Montserrat Gonzalez Arenas</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+K">Kanishka Rao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenhao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+C">Chuyuan Fu</a>, 
<a href="/search/cs?searchtype=author&query=Gopalakrishnan%2C+K">Keerthana Gopalakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhuo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Sundaresan%2C+P">Priya Sundaresan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+P">Peng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hao Su</a>, 
<a href="/search/cs?searchtype=author&query=Hausman%2C+K">Karol Hausman</a>, 
<a href="/search/cs?searchtype=author&query=Finn%2C+C">Chelsea Finn</a>, 
<a href="/search/cs?searchtype=author&query=Vuong%2C+Q">Quan Vuong</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+T">Ted Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Evaluation videos can be found at <a href="https://rt-trajectory.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generalization remains one of the most important desiderata for robust robot
learning systems. While recently proposed approaches show promise in
generalization to novel objects, semantic concepts, or visual distribution
shifts, generalization to new tasks remains challenging. For example, a
language-conditioned policy trained on pick-and-place tasks will not be able to
generalize to a folding task, even if the arm trajectory of folding is similar
to pick-and-place. Our key insight is that this kind of generalization becomes
feasible if we represent the task through rough trajectory sketches. We propose
a policy conditioning method using such rough trajectory sketches, which we
call RT-Trajectory, that is practical, easy to specify, and allows the policy
to effectively perform new tasks that would otherwise be challenging to
perform. We find that trajectory sketches strike a balance between being
detailed enough to express low-level motion-centric guidance while being coarse
enough to allow the learned policy to interpret the trajectory sketch in the
context of situational visual observations. In addition, we show how trajectory
sketches can provide a useful interface to communicate with robotic policies:
they can be specified through simple human inputs like drawings or videos, or
through automated methods such as modern image-generating or
waypoint-generating methods. We evaluate RT-Trajectory at scale on a variety of
real-world robotic tasks, and find that RT-Trajectory is able to perform a
wider range of tasks compared to language-conditioned and goal-conditioned
policies, when provided the same training data.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01981" title="Abstract">arXiv:2311.01981</a> [<a href="/pdf/2311.01981" title="Download PDF">pdf</a>, <a href="/format/2311.01981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProSG: Using Prompt Synthetic Gradients to Alleviate Prompt Forgetting  of RNN-like Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Haotian Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kunming Wu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+C">Cheng Dai</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+S">Sixian Ding</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinhao Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">RNN-like language models are getting renewed attention from NLP researchers
in recent years and several models have made significant progress, which
demonstrates performance comparable to traditional transformers. However, due
to the recurrent nature of RNNs, this kind of language model can only store
information in a set of fixed-length state vectors. As a consequence, they
still suffer from forgetfulness though after a lot of improvements and
optimizations, when given complex instructions or prompts. As the prompted
generation is the main and most concerned function of LMs, solving the problem
of forgetting in the process of generation is no wonder of vital importance. In
this paper, focusing on easing the prompt forgetting during generation, we
proposed an architecture to teach the model memorizing prompt during generation
by synthetic gradient. To force the model to memorize the prompt, we derive the
states that encode the prompt, then transform it into model parameter
modification using low-rank gradient approximation, which hard-codes the prompt
into model parameters temporarily. We construct a dataset for experiments, and
the results have demonstrated the effectiveness of our method in solving the
problem of forgetfulness in the process of prompted generation. We will release
all the code upon acceptance.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01984" title="Abstract">arXiv:2311.01984</a> [<a href="/pdf/2311.01984" title="Download PDF">pdf</a>, <a href="/format/2311.01984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Image Transport on Sparse Dictionaries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Junqing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haihui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Weiermann%2C+A">Andreas Weiermann</a>, 
<a href="/search/cs?searchtype=author&query=Ruzhansky%2C+M">Michael Ruzhansky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we derive a novel optimal image transport algorithm over
sparse dictionaries by taking advantage of Sparse Representation (SR) and
Optimal Transport (OT). Concisely, we design a unified optimization framework
in which the individual image features (color, textures, styles, etc.) are
encoded using sparse representation compactly, and an optimal transport plan is
then inferred between two learned dictionaries in accordance with the encoding
process. This paradigm gives rise to a simple but effective way for
simultaneous image representation and transformation, which is also empirically
solvable because of the moderate size of sparse coding and optimal transport
sub-problems. We demonstrate its versatility and many benefits to different
image-to-image translation tasks, in particular image color transform and
artistic style transfer, and show the plausible results for photo-realistic
transferred effects.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01989" title="Abstract">arXiv:2311.01989</a> [<a href="/pdf/2311.01989" title="Download PDF">pdf</a>, <a href="/format/2311.01989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Large-Scale Pretrained Vision Foundation Models for  Label-Efficient 3D Point Cloud Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+S">Shichao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fayao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Guosheng Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, large-scale pre-trained models such as Segment-Anything Model (SAM)
and Contrastive Language-Image Pre-training (CLIP) have demonstrated remarkable
success and revolutionized the field of computer vision. These foundation
vision models effectively capture knowledge from a large-scale broad data with
their vast model parameters, enabling them to perform zero-shot segmentation on
previously unseen data without additional training. While they showcase
competence in 2D tasks, their potential for enhancing 3D scene understanding
remains relatively unexplored. To this end, we present a novel framework that
adapts various foundational models for the 3D point cloud segmentation task.
Our approach involves making initial predictions of 2D semantic masks using
different large vision models. We then project these mask predictions from
various frames of RGB-D video sequences into 3D space. To generate robust 3D
semantic pseudo labels, we introduce a semantic label fusion strategy that
effectively combines all the results via voting. We examine diverse scenarios,
like zero-shot learning and limited guidance from sparse 2D point labels, to
assess the pros and cons of different vision foundation models. Our approach is
experimented on ScanNet dataset for 3D indoor scenes, and the results
demonstrate the effectiveness of adopting general 2D foundation models on
solving 3D point cloud segmentation tasks.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01990" title="Abstract">arXiv:2311.01990</a> [<a href="/pdf/2311.01990" title="Download PDF">pdf</a>, <a href="/ps/2311.01990" title="Download PostScript">ps</a>, <a href="/format/2311.01990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conditions on Preference Relations that Guarantee the Existence of  Optimal Policies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carr%2C+J+C">Jonathan Colaco Carr</a>, 
<a href="/search/cs?searchtype=author&query=Panangaden%2C+P">Prakash Panangaden</a>, 
<a href="/search/cs?searchtype=author&query=Precup%2C+D">Doina Precup</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, no figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Learning from Preferential Feedback (LfPF) plays an essential role in
training Large Language Models, as well as certain types of interactive
learning agents. However, a substantial gap exists between the theory and
application of LfPF algorithms. Current results guaranteeing the existence of
optimal policies in LfPF problems assume that both the preferences and
transition dynamics are determined by a Markov Decision Process. We introduce
the Direct Preference Process, a new framework for analyzing LfPF problems in
partially-observable, non-Markovian environments. Within this framework, we
establish conditions that guarantee the existence of optimal policies by
considering the ordinal structure of the preferences. Using the von
Neumann-Morgenstern Expected Utility Theorem, we show that the Direct
Preference Process generalizes the standard reinforcement learning problem. Our
findings narrow the gap between the empirical success and theoretical
understanding of LfPF algorithms and provide future practitioners with the
tools necessary for a more principled design of LfPF agents.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01993" title="Abstract">arXiv:2311.01993</a> [<a href="/pdf/2311.01993" title="Download PDF">pdf</a>, <a href="/format/2311.01993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Exploration in Iterative Gaussian Process Regression for  Uncertainty Modeling in Autonomous Racing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Benciolini%2C+T">Tommaso Benciolini</a>, 
<a href="/search/eess?searchtype=author&query=Tang%2C+C">Chen Tang</a>, 
<a href="/search/eess?searchtype=author&query=Leibold%2C+M">Marion Leibold</a>, 
<a href="/search/eess?searchtype=author&query=Weaver%2C+C">Catherine Weaver</a>, 
<a href="/search/eess?searchtype=author&query=Tomizuka%2C+M">Masayoshi Tomizuka</a>, 
<a href="/search/eess?searchtype=author&query=Zhan%2C+W">Wei Zhan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Autonomous racing creates challenging control problems, but Model Predictive
Control (MPC) has made promising steps toward solving both the minimum lap-time
problem and head-to-head racing. Yet, accurate models of the system are
necessary for model-based control, including models of vehicle dynamics and
opponent behavior. Both dynamics model error and opponent behavior can be
modeled with Gaussian Process (GP) regression. GP models can be updated
iteratively from data collected using the controller, but the strength of the
GP model depends on the diversity of the training data. We propose a novel
active exploration mechanism for iterative GP regression that purposefully
collects additional data at regions of higher uncertainty in the GP model. In
the exploration, a MPC collects diverse data by balancing the racing objectives
and the exploration criterion; then the GP is re-trained. The process is
repeated iteratively; in later iterations, the exploration is deactivated, and
only the racing objectives are optimized. Thus, the MPC can achieve better
performance by leveraging the improved GP model. We validate our approach in
the highly realistic racing simulation platform Gran Turismo Sport of Sony
Interactive Entertainment Inc for a minimum lap time challenge, and in
numerical simulation of head-to-head. Our active exploration mechanism yields a
significant improvement in the GP prediction accuracy compared to previous
approaches and, thus, an improved racing performance.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01995" title="Abstract">arXiv:2311.01995</a> [<a href="/pdf/2311.01995" title="Download PDF">pdf</a>, <a href="/format/2311.01995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Discrete to Continuous Best-Response Dynamics: Discrete  Fluctuations Do not Scale with the Population Size
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Aghaeeyan%2C+A">Azadeh Aghaeeyan</a>, 
<a href="/search/eess?searchtype=author&query=Ramazi%2C+P">Pouria Ramazi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In binary decision-makings, individuals often go for a common or rare action.
In the framework of evolutionary game theory, the best-response update rule can
be used to model this dichotomy. Those who prefer a common action are called
coordinators and those who prefer a rare one are called anticoordinators. A
finite mixed population of the two types may undergo perpetual fluctuations,
the characterization of which appears to be challenging. It is particularly
unknown, whether the fluctuations scale with the population size. To fill this
gap, we approximate the discrete finite population dynamics of coordinators and
anticoordinators with the associated mean dynamics in the form of
semicontinuous differential inclusions. We show that the family of the state
sequences of the discrete dynamics for increasing population sizes forms a
generalized stochastic approximation process for the differential inclusion. On
the other hand, we show that the differential inclusions always converge to an
equilibrium. This implies that the reported perpetual fluctuations in the
finite discrete dynamics of coordinators and anticoordinators do not scale as
the population size do. The results encourage to first analyze the often
simpler semicontinuous mean dynamics of the discrete population dynamics as the
semicontinuous dynamics partly reveal the asymptotic behaviour of the discrete
dynamics.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02007" title="Abstract">arXiv:2311.02007</a> [<a href="/pdf/2311.02007" title="Download PDF">pdf</a>, <a href="/format/2311.02007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Unsupervised Object Detection From LiDAR Point Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lunjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+A+J">Anqi Joyce Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yuwen Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Casas%2C+S">Sergio Casas</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+M">Mengye Ren</a>, 
<a href="/search/cs?searchtype=author&query=Urtasun%2C+R">Raquel Urtasun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">In this paper, we study the problem of unsupervised object detection from 3D
point clouds in self-driving scenes. We present a simple yet effective method
that exploits (i) point clustering in near-range areas where the point clouds
are dense, (ii) temporal consistency to filter out noisy unsupervised
detections, (iii) translation equivariance of CNNs to extend the auto-labels to
long range, and (iv) self-supervision for improving on its own. Our approach,
OYSTER (Object Discovery via Spatio-Temporal Refinement), does not impose
constraints on data collection (such as repeated traversals of the same
location), is able to detect objects in a zero-shot manner without supervised
finetuning (even in sparse, distant regions), and continues to self-improve
given more rounds of iterative self-training. To better measure model
performance in self-driving scenarios, we propose a new planning-centric
perception metric based on distance-to-collision. We demonstrate that our
unsupervised object detector significantly outperforms unsupervised baselines
on PandaSet and Argoverse 2 Sensor dataset, showing promise that
self-supervision combined with object priors can enable object discovery in the
wild. For more information, visit the project website:
https://waabi.ai/research/oyster
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02009" title="Abstract">arXiv:2311.02009</a> [<a href="/pdf/2311.02009" title="Download PDF">pdf</a>, <a href="/format/2311.02009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trust-Preserved Human-Robot Shared Autonomy enabled by Bayesian  Relational Event Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yingke Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fumin Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Shared autonomy functions as a flexible framework that empowers robots to
operate across a spectrum of autonomy levels, allowing for efficient task
execution with minimal human oversight. However, humans might be intimidated by
the autonomous decision-making capabilities of robots due to perceived risks
and a lack of trust. This paper proposed a trust-preserved shared autonomy
strategy that grants robots to seamlessly adjust their autonomy level, striving
to optimize team performance and enhance their acceptance among human
collaborators. By enhancing the Relational Event Modeling framework with
Bayesian learning techniques, this paper enables dynamic inference of human
trust based solely on time-stamped relational events within human-robot teams.
Adopting a longitudinal perspective on trust development and calibration in
human-robot teams, the proposed shared autonomy strategy warrants robots to
preserve human trust by not only passively adapting to it but also actively
participating in trust repair when violations occur. We validate the
effectiveness of the proposed approach through a user study on human-robot
collaborative search and rescue scenarios. The objective and subjective
evaluations demonstrate its merits over teleoperation on both task execution
and user acceptability.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02010" title="Abstract">arXiv:2311.02010</a> [<a href="/pdf/2311.02010" title="Download PDF">pdf</a>, <a href="/format/2311.02010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A cast of thousands: How the IDEAS Productivity project has advanced  software productivity and sustainability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McInnes%2C+L+C">Lois Curfman McInnes</a>, 
<a href="/search/cs?searchtype=author&query=Heroux%2C+M">Michael Heroux</a>, 
<a href="/search/cs?searchtype=author&query=Bernholdt%2C+D+E">David E. Bernholdt</a>, 
<a href="/search/cs?searchtype=author&query=Dubey%2C+A">Anshu Dubey</a>, 
<a href="/search/cs?searchtype=author&query=Gonsiorowski%2C+E">Elsa Gonsiorowski</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+R">Rinku Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Marques%2C+O">Osni Marques</a>, 
<a href="/search/cs?searchtype=author&query=Moulton%2C+J+D">J. David Moulton</a>, 
<a href="/search/cs?searchtype=author&query=Nam%2C+H+A">Hai Ah Nam</a>, 
<a href="/search/cs?searchtype=author&query=Norris%2C+B">Boyana Norris</a>, 
<a href="/search/cs?searchtype=author&query=Raybourn%2C+E+M">Elaine M. Raybourn</a>, 
<a href="/search/cs?searchtype=author&query=Willenbring%2C+J">Jim Willenbring</a>, 
<a href="/search/cs?searchtype=author&query=Almgren%2C+A">Ann Almgren</a>, 
<a href="/search/cs?searchtype=author&query=Bartlett%2C+R">Ross Bartlett</a>, 
<a href="/search/cs?searchtype=author&query=Cranfill%2C+K">Kita Cranfill</a>, 
<a href="/search/cs?searchtype=author&query=Fickas%2C+S">Stephen Fickas</a>, 
<a href="/search/cs?searchtype=author&query=Frederick%2C+D">Don Frederick</a>, 
<a href="/search/cs?searchtype=author&query=Godoy%2C+W">William Godoy</a>, 
<a href="/search/cs?searchtype=author&query=Grubel%2C+P">Patricia Grubel</a>, 
<a href="/search/cs?searchtype=author&query=Hartman-Baker%2C+R">Rebecca Hartman-Baker</a>, 
<a href="/search/cs?searchtype=author&query=Huebl%2C+A">Axel Huebl</a>, 
<a href="/search/cs?searchtype=author&query=Lynch%2C+R">Rose Lynch</a>, 
<a href="/search/cs?searchtype=author&query=Thakur%2C+A+M">Addi Malviya Thakur</a>, 
<a href="/search/cs?searchtype=author&query=Milewicz%2C+R">Reed Milewicz</a>, 
<a href="/search/cs?searchtype=author&query=Miller%2C+M+C">Mark C. Miller</a>, 
<a href="/search/cs?searchtype=author&query=Mundt%2C+M">Miranda Mundt</a>, 
<a href="/search/cs?searchtype=author&query=Palmer%2C+E">Erik Palmer</a>, 
<a href="/search/cs?searchtype=author&query=Parete-Koon%2C+S">Suzanne Parete-Koon</a>, 
<a href="/search/cs?searchtype=author&query=Phinney%2C+M">Megan Phinney</a>, 
<a href="/search/cs?searchtype=author&query=Riley%2C+K">Katherine Riley</a>, 
<a href="/search/cs?searchtype=author&query=Rogers%2C+D+M">David M. Rogers</a>, 
<a href="/search/cs?searchtype=author&query=Sims%2C+B">Ben Sims</a>, 
<a href="/search/cs?searchtype=author&query=Stevens%2C+D">Deborah Stevens</a>, 
<a href="/search/cs?searchtype=author&query=Watson%2C+G+R">Gregory R. Watson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Computational and data-enabled science and engineering are revolutionizing
advances throughout science and society, at all scales of computing. For
example, teams in the U.S. DOE Exascale Computing Project have been tackling
new frontiers in modeling, simulation, and analysis by exploiting unprecedented
exascale computing capabilities-building an advanced software ecosystem that
supports next-generation applications and addresses disruptive changes in
computer architectures. However, concerns are growing about the productivity of
the developers of scientific software, its sustainability, and the
trustworthiness of the results that it produces. Members of the IDEAS project
serve as catalysts to address these challenges through fostering software
communities, incubating and curating methodologies and resources, and
disseminating knowledge to advance developer productivity and software
sustainability. This paper discusses how these synergistic activities are
advancing scientific discovery-mitigating technical risks by building a firmer
foundation for reproducible, sustainable science at all scales of computing,
from laptops to clusters to exascale and beyond.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02013" title="Abstract">arXiv:2311.02013</a> [<a href="/pdf/2311.02013" title="Download PDF">pdf</a>, <a href="/format/2311.02013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Score Models for Offline Goal-Conditioned Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sikchi%2C+H">Harshit Sikchi</a>, 
<a href="/search/cs?searchtype=author&query=Chitnis%2C+R">Rohan Chitnis</a>, 
<a href="/search/cs?searchtype=author&query=Touati%2C+A">Ahmed Touati</a>, 
<a href="/search/cs?searchtype=author&query=Geramifard%2C+A">Alborz Geramifard</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Amy Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Niekum%2C+S">Scott Niekum</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Offline Goal-Conditioned Reinforcement Learning (GCRL) is tasked with
learning to achieve multiple goals in an environment purely from offline
datasets using sparse reward functions. Offline GCRL is pivotal for developing
generalist agents capable of leveraging pre-existing datasets to learn diverse
and reusable skills without hand-engineering reward functions. However,
contemporary approaches to GCRL based on supervised learning and contrastive
learning are often suboptimal in the offline setting. An alternative
perspective on GCRL optimizes for occupancy matching, but necessitates learning
a discriminator, which subsequently serves as a pseudo-reward for downstream
RL. Inaccuracies in the learned discriminator can cascade, negatively
influencing the resulting policy. We present a novel approach to GCRL under a
new lens of mixture-distribution matching, leading to our discriminator-free
method: SMORe. The key insight is combining the occupancy matching perspective
of GCRL with a convex dual formulation to derive a learning objective that can
better leverage suboptimal offline data. SMORe learns scores or unnormalized
densities representing the importance of taking an action at a state for
reaching a particular goal. SMORe is principled and our extensive experiments
on the fully offline GCRL benchmark composed of robot manipulation and
locomotion tasks, including high-dimensional observations, show that SMORe can
outperform state-of-the-art baselines by a significant margin.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02017" title="Abstract">arXiv:2311.02017</a> [<a href="/pdf/2311.02017" title="Download PDF">pdf</a>, <a href="/format/2311.02017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeliverAI: Reinforcement Learning Based Distributed Path-Sharing Network  for Food Deliveries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mehra%2C+A">Ashman Mehra</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+S">Snehanshu Saha</a>, 
<a href="/search/cs?searchtype=author&query=Raychoudhury%2C+V">Vaskar Raychoudhury</a>, 
<a href="/search/cs?searchtype=author&query=Mathur%2C+A">Archana Mathur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Delivery of items from the producer to the consumer has experienced
significant growth over the past decade and has been greatly fueled by the
recent pandemic. Amazon Fresh, Shopify, UberEats, InstaCart, and DoorDash are
rapidly growing and are sharing the same business model of consumer items or
food delivery. Existing food delivery methods are sub-optimal because each
delivery is individually optimized to go directly from the producer to the
consumer via the shortest time path. We observe a significant scope for
reducing the costs associated with completing deliveries under the current
model. We model our food delivery problem as a multi-objective optimization,
where consumer satisfaction and delivery costs, both, need to be optimized.
Taking inspiration from the success of ride-sharing in the taxi industry, we
propose DeliverAI - a reinforcement learning-based path-sharing algorithm.
Unlike previous attempts for path-sharing, DeliverAI can provide real-time,
time-efficient decision-making using a Reinforcement learning-enabled agent
system. Our novel agent interaction scheme leverages path-sharing among
deliveries to reduce the total distance traveled while keeping the delivery
completion time under check. We generate and test our methodology vigorously on
a simulation setup using real data from the city of Chicago. Our results show
that DeliverAI can reduce the delivery fleet size by 12\%, the distance
traveled by 13%, and achieve 50% higher fleet utilization compared to the
baselines.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02018" title="Abstract">arXiv:2311.02018</a> [<a href="/pdf/2311.02018" title="Download PDF">pdf</a>, <a href="/format/2311.02018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Reasoning in an Open-World Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Manjie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+G">Guangyuan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+W">Wei Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yixin Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Recent advances in vision-language learning have achieved notable success on
complete-information question-answering datasets through the integration of
extensive world knowledge. Yet, most models operate passively, responding to
questions based on pre-stored knowledge. In stark contrast, humans possess the
ability to actively explore, accumulate, and reason using both newfound and
existing information to tackle incomplete-information questions. In response to
this gap, we introduce $Conan$, an interactive open-world environment devised
for the assessment of active reasoning. $Conan$ facilitates active exploration
and promotes multi-round abductive inference, reminiscent of rich, open-world
settings like Minecraft. Diverging from previous works that lean primarily on
single-round deduction via instruction following, $Conan$ compels agents to
actively interact with their surroundings, amalgamating new evidence with prior
knowledge to elucidate events from incomplete observations. Our analysis on
$Conan$ underscores the shortcomings of contemporary state-of-the-art models in
active exploration and understanding complex scenarios. Additionally, we
explore Abduction from Deduction, where agents harness Bayesian rules to recast
the challenge of abduction as a deductive process. Through $Conan$, we aim to
galvanize advancements in active reasoning and set the stage for the next
generation of artificial intelligence agents adept at dynamically engaging in
environments.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02023" title="Abstract">arXiv:2311.02023</a> [<a href="/pdf/2311.02023" title="Download PDF">pdf</a>, <a href="/format/2311.02023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FiloBass: A Dataset and Corpus Based Study of Jazz Basslines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Riley%2C+X">Xavier Riley</a>, 
<a href="/search/cs?searchtype=author&query=Dixon%2C+S">Simon Dixon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ISMIR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We present FiloBass: a novel corpus of music scores and annotations which
focuses on the important but often overlooked role of the double bass in jazz
accompaniment. Inspired by recent work that sheds light on the role of the
soloist, we offer a collection of 48 manually verified transcriptions of
professional jazz bassists, comprising over 50,000 note events, which are based
on the backing tracks used in the FiloSax dataset. For each recording we
provide audio stems, scores, performance-aligned MIDI and associated metadata
for beats, downbeats, chord symbols and markers for musical form.
<br />We then use FiloBass to enrich our understanding of jazz bass lines, by
conducting a corpus-based musical analysis with a contrastive study of existing
instructional methods. Together with the original FiloSax dataset, our work
represents a significant step toward a fully annotated performance dataset for
a jazz quartet setting. By illuminating the critical role of the bass in jazz,
this work contributes to a more nuanced and comprehensive understanding of the
genre.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02025" title="Abstract">arXiv:2311.02025</a> [<a href="/pdf/2311.02025" title="Download PDF">pdf</a>, <a href="/format/2311.02025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vicinal Risk Minimization for Few-Shot Cross-lingual Transfer in Abusive  Language Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+la+Pe%C3%B1a+Sarrac%C3%A9n%2C+G+L">Gretel Liz De la Pe&#xf1;a Sarrac&#xe9;n</a>, 
<a href="/search/cs?searchtype=author&query=Rosso%2C+P">Paolo Rosso</a>, 
<a href="/search/cs?searchtype=author&query=Litschko%2C+R">Robert Litschko</a>, 
<a href="/search/cs?searchtype=author&query=Glava%C5%A1%2C+G">Goran Glava&#x161;</a>, 
<a href="/search/cs?searchtype=author&query=Ponzetto%2C+S+P">Simone Paolo Ponzetto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP 2023 (Main Conference)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Cross-lingual transfer learning from high-resource to medium and low-resource
languages has shown encouraging results. However, the scarcity of resources in
target languages remains a challenge. In this work, we resort to data
augmentation and continual pre-training for domain adaptation to improve
cross-lingual abusive language detection. For data augmentation, we analyze two
existing techniques based on vicinal risk minimization and propose MIXAG, a
novel data augmentation method which interpolates pairs of instances based on
the angle of their representations. Our experiments involve seven languages
typologically distinct from English and three different domains. The results
reveal that the data augmentation strategies can enhance few-shot cross-lingual
abusive language detection. Specifically, we observe that consistently in all
target languages, MIXAG improves significantly in multidomain and multilingual
environments. Finally, we show through an error analysis how the domain
adaptation can favour the class of abusive texts (reducing false negatives),
but at the same time, declines the precision of the abusive language detection
model.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02026" title="Abstract">arXiv:2311.02026</a> [<a href="/pdf/2311.02026" title="Download PDF">pdf</a>, <a href="/ps/2311.02026" title="Download PostScript">ps</a>, <a href="/format/2311.02026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> APRICOT: Acuity Prediction in Intensive Care Unit (ICU): Predicting  Stability, Transitions, and Life-Sustaining Therapies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Contreras%2C+M">Miguel Contreras</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+B">Brandon Silva</a>, 
<a href="/search/cs?searchtype=author&query=Shickel%2C+B">Benjamin Shickel</a>, 
<a href="/search/cs?searchtype=author&query=Baslanti%2C+T+O">Tezcan Ozrazgat Baslanti</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yuanfang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+Z">Ziyuan Guan</a>, 
<a href="/search/cs?searchtype=author&query=Bandyopadhyay%2C+S">Sabyasachi Bandyopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Khezeli%2C+K">Kia Khezeli</a>, 
<a href="/search/cs?searchtype=author&query=Bihorac%2C+A">Azra Bihorac</a>, 
<a href="/search/cs?searchtype=author&query=Rashidi%2C+P">Parisa Rashidi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The acuity state of patients in the intensive care unit (ICU) can quickly
change from stable to unstable, sometimes leading to life-threatening
conditions. Early detection of deteriorating conditions can result in providing
more timely interventions and improved survival rates. Current approaches rely
on manual daily assessments. Some data-driven approaches have been developed,
that use mortality as a proxy of acuity in the ICU. However, these methods do
not integrate acuity states to determine the stability of a patient or the need
for life-sustaining therapies. In this study, we propose APRICOT (Acuity
Prediction in Intensive Care Unit), a Transformer-based neural network to
predict acuity state in real-time in ICU patients. We develop and extensively
validate externally, temporally, and prospectively the APRICOT model on three
large datasets: University of Florida Health (UFH), eICU Collaborative Research
Database (eICU), and Medical Information Mart for Intensive Care (MIMIC)-IV.
The performance of APRICOT shows comparable results to state-of-the-art
mortality prediction models (external AUROC 0.93-0.93, temporal AUROC
0.96-0.98, and prospective AUROC 0.98) as well as acuity prediction models
(external AUROC 0.80-0.81, temporal AUROC 0.77-0.78, and prospective AUROC
0.87). Furthermore, APRICOT can make predictions for the need for
life-sustaining therapies, showing comparable results to state-of-the-art
ventilation prediction models (external AUROC 0.80-0.81, temporal AUROC
0.87-0.88, and prospective AUROC 0.85), and vasopressor prediction models
(external AUROC 0.82-0.83, temporal AUROC 0.73-0.75, prospective AUROC 0.87).
This tool allows for real-time acuity monitoring of a patient and can provide
helpful information to clinicians to make timely interventions. Furthermore,
the model can suggest life-sustaining therapies that the patient might need in
the next hours in the ICU.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02031" title="Abstract">arXiv:2311.02031</a> [<a href="/pdf/2311.02031" title="Download PDF">pdf</a>, <a href="/format/2311.02031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IRKA is a Riemannian Gradient Descent Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mlinari%C4%87%2C+P">Petar Mlinari&#x107;</a>, 
<a href="/search/math?searchtype=author&query=Beattie%2C+C">Christopher Beattie</a>, 
<a href="/search/math?searchtype=author&query=Drma%C4%8D%2C+Z">Zlatko Drma&#x10d;</a>, 
<a href="/search/math?searchtype=author&query=Gugercin%2C+S">Serkan Gugercin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
<p class="mathjax">The iterative rational Krylov algorithm (IRKA) is a commonly used fixed-point
iteration developed to minimize the $\mathcal{H}_2$ model order reduction
error. In this work, IRKA is recast as a Riemannian gradient descent method
with a fixed step size over the manifold of rational functions having fixed
degree. This interpretation motivates the development of a Riemannian gradient
descent method utilizing as a natural extension variable step size and line
search. Comparisons made between IRKA and this extension on a few examples
demonstrate significant benefits.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02035" title="Abstract">arXiv:2311.02035</a> [<a href="/pdf/2311.02035" title="Download PDF">pdf</a>, <a href="/format/2311.02035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Highly-Compact Direct-Injection Universal Power Flow and Quality  Control Circuit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lu%2C+M">Mowei Lu</a>, 
<a href="/search/eess?searchtype=author&query=Qin%2C+M">Mengjie Qin</a>, 
<a href="/search/eess?searchtype=author&query=Kacetl%2C+J">Jan Kacetl</a>, 
<a href="/search/eess?searchtype=author&query=Suresh%2C+E">Eeshta Suresh</a>, 
<a href="/search/eess?searchtype=author&query=Long%2C+T">Teng Long</a>, 
<a href="/search/eess?searchtype=author&query=Goetz%2C+S+M">Stefan M. Goetz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper presents a novel direct-injection modular universal power flow and
quality control topology exclusively using lower power components. In addition
to conventional high-voltage applications, it is particularly attractive for
the distribution and secondary grids, e.g., in soft open points, down to low
voltage as it can exploit the latest developments in low-voltage high-current
semiconductors. In contrast to other concepts that do not interface the grid
through transformers, it does not need to convert the entire line power but
only the injected or extracted power difference. The proposed power flow and
quality (f/q) controller comprises a shunt active front end, together with
high-frequency links serving as a power supply for a series floating module per
phase. Each of the floating modules is in series with one phase of the line,
floating with the electric potential of that particular phase, avoiding any
ground connection. Omitting bulky and dynamically limited line transformers of
conventional universal power flow controllers, the presented direct-injection
f/q controller enables exceptionally small size and volume, high power density,
high frequency content, and fast response. In contrast to direct-injection
concepts with full back-to-back converters, it only needs to handle a fraction
of the power. The circuit combines grid-voltage low-current electronics in the
shunt unit and low-voltage high-current modules in the floating series
injection units. Simulations and experiments demonstrate and validate the
concept.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02039" title="Abstract">arXiv:2311.02039</a> [<a href="/pdf/2311.02039" title="Download PDF">pdf</a>, <a href="/format/2311.02039" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HPC-based Solvers of Minimisation Problems for Signal Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cammarasana%2C+S">Simone Cammarasana</a>, 
<a href="/search/cs?searchtype=author&query=Patan%C3%A8%2C+G">Giuseppe Patan&#xe8;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Graphics (cs.GR); Signal Processing (eess.SP)

</div>
<p class="mathjax">Several physics and engineering applications involve the solution of a
minimisation problem to compute an approximation of the input signal. Modern
computing hardware and software apply high-performance computing to solve and
considerably reduce the execution time. We compare and analyse different
minimisation methods in terms of functional computation, convergence, execution
time, and scalability properties, for the solution of two minimisation problems
(i.e., approximation and denoising) with different constraints that involve
computationally expensive operations. These problems are attractive due to
their numerical and analytical properties, and our general analysis can be
extended to most signal-processing problems. We perform our tests on the Cineca
Marconi100 cluster, at the 26th position in the top500 list. Our experimental
results show that PRAXIS is the best optimiser in terms of minima computation:
the efficiency of the approximation is 38% with 256 processes, while the
denoising has 46% with 32 processes.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02044" title="Abstract">arXiv:2311.02044</a> [<a href="/pdf/2311.02044" title="Download PDF">pdf</a>, <a href="/format/2311.02044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Occlusion-Aware 2D and 3D Centerline Detection for Urban Driving via  Automatic Label Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paz%2C+D">David Paz</a>, 
<a href="/search/cs?searchtype=author&query=Ranganatha%2C+N+E">Narayanan E. Ranganatha</a>, 
<a href="/search/cs?searchtype=author&query=Srinivas%2C+S+K">Srinidhi K. Srinivas</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yunchao Yao</a>, 
<a href="/search/cs?searchtype=author&query=Christensen%2C+H+I">Henrik I. Christensen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures, 1 algorithm, 11 equations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This research work seeks to explore and identify strategies that can
determine road topology information in 2D and 3D under highly dynamic urban
driving scenarios. To facilitate this exploration, we introduce a substantial
dataset comprising nearly one million automatically labeled data frames. A key
contribution of our research lies in developing an automatic label-generation
process and an occlusion handling strategy. This strategy is designed to model
a wide range of occlusion scenarios, from mild disruptions to severe blockages.
Furthermore, we present a comprehensive ablation study wherein multiple
centerline detection methods are developed and evaluated. This analysis not
only benchmarks the performance of various approaches but also provides
valuable insights into the interpretability of these methods. Finally, we
demonstrate the practicality of our methods and assess their adaptability
across different sensor configurations, highlighting their versatility and
relevance in real-world scenarios. Our dataset and experimental models are
publicly available.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02049" title="Abstract">arXiv:2311.02049</a> [<a href="/pdf/2311.02049" title="Download PDF">pdf</a>, <a href="/format/2311.02049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Post Turing: Mapping the landscape of LLM Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tikhonov%2C+A">Alexey Tikhonov</a>, 
<a href="/search/cs?searchtype=author&query=Yamshchikov%2C+I+P">Ivan P. Yamshchikov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for GEM @ EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the rapidly evolving landscape of Large Language Models (LLMs),
introduction of well-defined and standardized evaluation methodologies remains
a crucial challenge. This paper traces the historical trajectory of LLM
evaluations, from the foundational questions posed by Alan Turing to the modern
era of AI research. We categorize the evolution of LLMs into distinct periods,
each characterized by its unique benchmarks and evaluation criteria. As LLMs
increasingly mimic human-like behaviors, traditional evaluation proxies, such
as the Turing test, have become less reliable. We emphasize the pressing need
for a unified evaluation system, given the broader societal implications of
these models. Through an analysis of common evaluation methodologies, we
advocate for a qualitative shift in assessment approaches, underscoring the
importance of standardization and objective criteria. This work serves as a
call for the AI community to collaboratively address the challenges of LLM
evaluation, ensuring their reliability, fairness, and societal benefit.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02050" title="Abstract">arXiv:2311.02050</a> [<a href="/pdf/2311.02050" title="Download PDF">pdf</a>, <a href="/format/2311.02050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Approximation Algorithms for Piercing Boxes by Points
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+P+K">Pankaj K. Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Har-Peled%2C+S">Sariel Har-Peled</a>, 
<a href="/search/cs?searchtype=author&query=Raychaudhury%2C+R">Rahul Raychaudhury</a>, 
<a href="/search/cs?searchtype=author&query=Sintos%2C+S">Stavros Sintos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in SODA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">$ \newcommand{\Re}{\mathbb{R}} \newcommand{\BX}{\mathcal{B}}
\newcommand{\bb}{\mathsf{b}} \newcommand{\eps}{\varepsilon}
\newcommand{\polylog}{\mathrm{polylog}} $
<br />Let $\BX=\{\bb_1, \ldots ,\bb_n\}$ be a set of $n$ axis-aligned boxes in
$\Re^d$ where $d\geq2$ is a constant. The piercing problem is to compute a
smallest set of points $N \subset \Re^d$ that hits every box in $\BX$, i.e.,
$N\cap \bb_i\neq \emptyset$, for $i=1,\ldots, n$. The problem is known to be
NP-Hard. Let $\psi:=\psi(\BX)$, the \emph{piercing number} be the minimum size
of a piercing set of $\BX$. We first present a randomized $O(\log\log
\psi)$-approximation algorithm with expected running time $O(n^{d/2}\polylog
(n))$. Next, we show that the expected running time can be improved to
near-linear using a sampling-based technique, if $\psi = O(n^{1/(d-1)})$.
Specifically, in the plane, the improved running time is $O(n \log \psi)$,
assuming $\psi &lt; n/\log^{\Omega(1)} n$. Finally, we study the dynamic version
of the piercing problem where boxes can be inserted or deleted. For boxes in
$\Re^2$, we obtain a randomized $O(\log\log\psi)$-approximation algorithm with
$O(n^{1/2}\polylog (n))$ amortized expected update time for insertion or
deletion of boxes. For squares in $\Re^2$, the update time can be improved to
$O(n^{1/3}\polylog (n))$.
<br />Our algorithms are based on the multiplicative weight-update (MWU) method and
require the construction of a weak $\eps$-net for a point set with respect to
boxes. A key idea of our work is to exploit the duality between the piercing
set and independent set (for boxes) to speed up our MWU. We also present a
simpler and slightly more efficient algorithm for constructing a weak
$\eps$-net than in [Ezr10], which is of independent interest. Our approach also
yields a simpler algorithm for constructing (regular) $\eps$-nets with respect
to boxes for $d=2,3$.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02055" title="Abstract">arXiv:2311.02055</a> [<a href="/pdf/2311.02055" title="Download PDF">pdf</a>, <a href="/ps/2311.02055" title="Download PostScript">ps</a>, <a href="/format/2311.02055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NSF Integrated Circuit Research, Education and Workforce Development  Workshop Final Report
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guthaus%2C+M">M. Guthaus</a>, 
<a href="/search/cs?searchtype=author&query=Batten%2C+C">C. Batten</a>, 
<a href="/search/cs?searchtype=author&query=Brunvand%2C+E">E. Brunvand</a>, 
<a href="/search/cs?searchtype=author&query=Gaillardon%2C+P+E">P.E. Gaillardon</a>, 
<a href="/search/cs?searchtype=author&query=harris%2C+D">D. harris</a>, 
<a href="/search/cs?searchtype=author&query=Manohar%2C+R">R. Manohar</a>, 
<a href="/search/cs?searchtype=author&query=Mazumder%2C+P">P. Mazumder</a>, 
<a href="/search/cs?searchtype=author&query=Pileggi%2C+L">L. Pileggi</a>, 
<a href="/search/cs?searchtype=author&query=Stine%2C+J">J. Stine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This material is based upon work supported by the NSF under Grant No. 2137629
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">As the pace of progress that has followed Moore's law continues to diminish,
it is critical that the US support Integrated Circuit (IC or chip) education
and research to maintain technological innovation. Furthermore, US economic
independence, security, and future international standing rely on having
on-shore IC design capabilities. New devices with disparate technologies,
improved design software toolchains and methodologies, and technologies to
integrate heterogeneous systems will be needed to advance IC design
capabilities. This will require rethinking both how we teach design to address
the new complexity and how we inspire student interest in a hardware systems
career path. The main recommendation of this workshop is that accessibility is
the key issue. To this end, a National Chip Design Center (NCDC) should be
established to further research and education by partnering academics and
industry to train our future workforce. This should not be limited to R1
universities, but should also include R2, community college, minority serving
institutions (MSI), and K-12 institutions to have the broadest effect. The NCDC
should support the access, development, and maintenance of open design tools,
tool flows, design kits, design components, and educational materials.
Open-source options should be emphasized wherever possible to maximize
accessibility. The NCDC should also provide access and support for chip
fabrication, packaging and testing for both research and educational purposes.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02058" title="Abstract">arXiv:2311.02058</a> [<a href="/pdf/2311.02058" title="Download PDF">pdf</a>, <a href="/format/2311.02058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LOTUS: Continual Imitation Learning for Robot Manipulation Through  Unsupervised Skill Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+W">Weikang Wan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yifeng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+R">Rutav Shah</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuke Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce LOTUS, a continual imitation learning algorithm that empowers a
physical robot to continuously and efficiently learn to solve new manipulation
tasks throughout its lifespan. The core idea behind LOTUS is constructing an
ever-growing skill library from a sequence of new tasks with a small number of
human demonstrations. LOTUS starts with a continual skill discovery process
using an open-vocabulary vision model, which extracts skills as recurring
patterns presented in unsegmented demonstrations. Continual skill discovery
updates existing skills to avoid catastrophic forgetting of previous tasks and
adds new skills to solve novel tasks. LOTUS trains a meta-controller that
flexibly composes various skills to tackle vision-based manipulation tasks in
the lifelong learning process. Our comprehensive experiments show that LOTUS
outperforms state-of-the-art baselines by over 11% in success rate, showing its
superior knowledge transfer ability compared to prior methods. More results and
videos can be found on the project website:
https://ut-austin-rpl.github.io/Lotus/.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02061" title="Abstract">arXiv:2311.02061</a> [<a href="/pdf/2311.02061" title="Download PDF">pdf</a>, <a href="/format/2311.02061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Learning-Based Species Range Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lange%2C+C">Christian Lange</a>, 
<a href="/search/cs?searchtype=author&query=Cole%2C+E">Elijah Cole</a>, 
<a href="/search/cs?searchtype=author&query=Van+Horn%2C+G">Grant Van Horn</a>, 
<a href="/search/cs?searchtype=author&query=Mac+Aodha%2C+O">Oisin Mac Aodha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We propose a new active learning approach for efficiently estimating the
geographic range of a species from a limited number of on the ground
observations. We model the range of an unmapped species of interest as the
weighted combination of estimated ranges obtained from a set of different
species. We show that it is possible to generate this candidate set of ranges
by using models that have been trained on large weakly supervised community
collected observation data. From this, we develop a new active querying
approach that sequentially selects geographic locations to visit that best
reduce our uncertainty over an unmapped species' range. We conduct a detailed
evaluation of our approach and compare it to existing active learning methods
using an evaluation dataset containing expert-derived ranges for one thousand
species. Our results demonstrate that our method outperforms alternative active
learning methods and approaches the performance of end-to-end trained models,
even when only using a fraction of the data. This highlights the utility of
active learning via transfer learned spatial representations for species range
estimation. It also emphasizes the value of leveraging emerging large-scale
crowdsourced datasets, not only for modeling a species' range, but also for
actively discovering them.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02062" title="Abstract">arXiv:2311.02062</a> [<a href="/pdf/2311.02062" title="Download PDF">pdf</a>, <a href="/format/2311.02062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GroomGen: A High-Quality Generative Hair Model Using Hierarchical Latent  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuxiao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+M">Menglei Chai</a>, 
<a href="/search/cs?searchtype=author&query=Pepe%2C+A">Alessandro Pepe</a>, 
<a href="/search/cs?searchtype=author&query=Gross%2C+M">Markus Gross</a>, 
<a href="/search/cs?searchtype=author&query=Beeler%2C+T">Thabo Beeler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SIGGRAPH Asia 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM Trans. Graph. 42, 6, Article 267 (December 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">Despite recent successes in hair acquisition that fits a high-dimensional
hair model to a specific input subject, generative hair models, which establish
general embedding spaces for encoding, editing, and sampling diverse
hairstyles, are way less explored. In this paper, we present GroomGen, the
first generative model designed for hair geometry composed of highly-detailed
dense strands. Our approach is motivated by two key ideas. First, we construct
hair latent spaces covering both individual strands and hairstyles. The latent
spaces are compact, expressive, and well-constrained for high-quality and
diverse sampling. Second, we adopt a hierarchical hair representation that
parameterizes a complete hair model to three levels: single strands, sparse
guide hairs, and complete dense hairs. This representation is critical to the
compactness of latent spaces, the robustness of training, and the efficiency of
inference. Based on this hierarchical latent representation, our proposed
pipeline consists of a strand-VAE and a hairstyle-VAE that encode an individual
strand and a set of guide hairs to their respective latent spaces, and a hybrid
densification step that populates sparse guide hairs to a dense hair model.
GroomGen not only enables novel hairstyle sampling and plausible hairstyle
interpolation, but also supports interactive editing of complex hairstyles, or
can serve as strong data-driven prior for hairstyle reconstruction from images.
We demonstrate the superiority of our approach with qualitative examples of
diverse sampled hairstyles and quantitative evaluation of generation quality
regarding every single component and the entire pipeline.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02067" title="Abstract">arXiv:2311.02067</a> [<a href="/pdf/2311.02067" title="Download PDF">pdf</a>, <a href="/format/2311.02067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Woeginger&#x27;s Hiking Problem: Wonderful Partitions in Anonymous  Hedonic Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Constantinescu%2C+A">Andrei Constantinescu</a>, 
<a href="/search/cs?searchtype=author&query=Lenzner%2C+P">Pascal Lenzner</a>, 
<a href="/search/cs?searchtype=author&query=Reiffenh%C3%A4user%2C+R">Rebecca Reiffenh&#xe4;user</a>, 
<a href="/search/cs?searchtype=author&query=Schmand%2C+D">Daniel Schmand</a>, 
<a href="/search/cs?searchtype=author&query=Varricchio%2C+G">Giovanna Varricchio</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Working paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">A decade ago, Gerhard Woeginger posed an open problem that became well-known
as "Gerhard's Hiking Problem": Consider a group of $n$ people that want to go
hiking; everyone expresses preferences over the size of their hiking group in
the form of an interval between $1$ and $n$. Is it possible to efficiently
assign the $n$ people to a set of hiking subgroups so that every person
approves the size of their assigned subgroup? The problem is also known as
efficiently deciding if an instance of an anonymous Hedonic Game with interval
approval preferences admits a wonderful partition.
<br />We resolve the open problem in the affirmative by presenting an $O(n^5)$ time
algorithm for Gerhard's Hiking Problem. Our solution is based on employing a
dynamic programming approach for a specific rectangle stabbing problem from
computational geometry. Moreover, we propose natural more demanding extensions
of the problem, e.g., maximizing the number of satisfied people, and show that
they are also efficiently solvable. Additionally, we precisely map the boundary
of tractability for the wonderful partition problem by proving that finding
such a partition becomes NP-hard if non-interval approval size sets of size two
are allowed. This closes a gap in the complexity landscape, since hardness was
only known for the case with non-interval approval size sets of size at most 3.
Last but not least, we employ our solution to efficiently compute a partition
that maximizes the egalitarian welfare for anonymous single-peaked Hedonic
Games.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02068" title="Abstract">arXiv:2311.02068</a> [<a href="/pdf/2311.02068" title="Download PDF">pdf</a>, <a href="/format/2311.02068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Closing the Gap to Quadratic Invariance: a Regret Minimization Approach  to Optimal Distributed Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Martinelli%2C+D">Daniele Martinelli</a>, 
<a href="/search/eess?searchtype=author&query=Martin%2C+A">Andrea Martin</a>, 
<a href="/search/eess?searchtype=author&query=Ferrari-Trecate%2C+G">Giancarlo Ferrari-Trecate</a>, 
<a href="/search/eess?searchtype=author&query=Furieri%2C+L">Luca Furieri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In optimal distributed control, state-of-the-art approaches design
controllers that comply with an information structure minimizing the $H_2$ or
$H_\infty$ norm, that is, the expected or worst-case cost in the presence of
stochastic or adversarial disturbances. However, performance against the
real-world disturbances affecting large-scale systems - which exhibit a complex
interplay of stochastic and deterministic elements due to diverse and unmodeled
disruptions spreading across the entire system's scale - remains poor. In this
paper, we propose improving performance for these scenarios by minimizing the
regret with respect to an ideal policy that complies with less stringent
sensor-information constraints. This endows our controller with the ability to
approach the improved behavior of a more informed policy, which would detect
and counteract heterogeneous and localized disturbances more promptly.
Specifically, we derive convex relaxations of the resulting regret minimization
problem that are compatible with any desired controller sparsity, while we
reveal a renewed role of the Quadratic Invariance (QI) condition in designing
informative benchmarks to measure regret. Last, we validate our proposed method
through numerical simulations on controlling a large-scale distributed system,
comparing its performance with traditional $H_2$ and $H_\infty$ policies.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02069" title="Abstract">arXiv:2311.02069</a> [<a href="/pdf/2311.02069" title="Download PDF">pdf</a>, <a href="/format/2311.02069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grounded Intuition of GPT-Vision&#x27;s Abilities with Scientific Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hwang%2C+A">Alyssa Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Head%2C+A">Andrew Head</a>, 
<a href="/search/cs?searchtype=author&query=Callison-Burch%2C+C">Chris Callison-Burch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">GPT-Vision has impressed us on a range of vision-language tasks, but it comes
with the familiar new challenge: we have little idea of its capabilities and
limitations. In our study, we formalize a process that many have instinctively
been trying already to develop "grounded intuition" of this new model. Inspired
by the recent movement away from benchmarking in favor of example-driven
qualitative evaluation, we draw upon grounded theory and thematic analysis in
social science and human-computer interaction to establish a rigorous framework
for qualitative evaluation in natural language processing. We use our technique
to examine alt text generation for scientific figures, finding that GPT-Vision
is particularly sensitive to prompting, counterfactual text in images, and
relative spatial relationships. Our method and analysis aim to help researchers
ramp up their own grounded intuitions of new models while exposing how
GPT-Vision can be applied to make information more accessible.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02072" title="Abstract">arXiv:2311.02072</a> [<a href="/pdf/2311.02072" title="Download PDF">pdf</a>, <a href="/format/2311.02072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Historical Status Prompt for Accurate and Robust Visual  Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+W">Wenrui Cai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qingjie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunhong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Most trackers perform template and search region similarity matching to find
the most similar object to the template during tracking. However, they struggle
to make prediction when the target appearance changes due to the limited
historical information introduced by roughly cropping the current search region
based on the predicted result of previous frame. In this paper, we identify
that the central impediment to improving the performance of existing trackers
is the incapacity to integrate abundant and effective historical information.
To address this issue, we propose a Historical Information Prompter (HIP) to
enhance the provision of historical information. We also build HIPTrack upon
HIP module. HIP is a plug-and-play module that make full use of search region
features to introduce historical appearance information. It also incorporates
historical position information by constructing refined mask of the target. HIP
is a lightweight module to generate historical information prompts. By
integrating historical information prompts, HIPTrack significantly enhances the
tracking performance without the need to retrain the backbone. Experimental
results demonstrate that our method outperforms all state-of-the-art approaches
on LaSOT, LaSOT ext, GOT10k and NfS. Futhermore, HIP module exhibits strong
generality and can be seamlessly integrated into trackers to improve tracking
performance. The source code and models will be released for further research.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02073" title="Abstract">arXiv:2311.02073</a> [<a href="/pdf/2311.02073" title="Download PDF">pdf</a>, <a href="/format/2311.02073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Streaming Algorithms for Weighted $k$-Disjoint Matchings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferdous%2C+S+M">S M Ferdous</a>, 
<a href="/search/cs?searchtype=author&query=Samineni%2C+B">Bhargav Samineni</a>, 
<a href="/search/cs?searchtype=author&query=Pothen%2C+A">Alex Pothen</a>, 
<a href="/search/cs?searchtype=author&query=Halappanavar%2C+M">Mahantesh Halappanavar</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamoorthy%2C+B">Bala Krishnamoorthy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We design and implement two single-pass semi-streaming algorithms for the
maximum weight $k$-disjoint matching ($k$-DM) problem. Given an integer $k$,
the $k$-DM problem is to find $k$ pairwise edge-disjoint matchings such that
the sum of the weights of the matchings is maximized. For $k \geq 2$, this
problem is NP-hard. Our first algorithm is based on the primal-dual framework
of a linear programming relaxation of the problem and is
$\frac{1}{3+\varepsilon}$-approximate. We also develop an approximation
preserving reduction from $k$-DM to the maximum weight $b$-matching problem.
Leveraging this reduction and an existing semi-streaming $b$-matching
algorithm, we design a $\frac{k}{(2+\varepsilon)(k+1)}$-approximate
semi-streaming algorithm for $k$-DM. For any constant $\varepsilon &gt; 0$, both
of these algorithms require $O(nk \log_{1+\varepsilon}^2 n)$ bits of space. To
the best of our knowledge, this is the first study of semi-streaming algorithms
for the $k$-DM problem.
<br />We compare our two algorithms to state-of-the-art offline algorithms on 82
real-world and synthetic test problems. On the smaller instances, our streaming
algorithms used significantly less memory (ranging from 6$\times$ to
114$\times$ less) and were faster in runtime than the offline algorithms. Our
solutions were often within 5\% of the best weights from the offline
algorithms. On a collection of six large graphs with a memory limit of 1 TB and
with $k=8$, the offline algorithms terminated only on one graph
(mycielskian20). The best offline algorithm on this instance required 640 GB of
memory and 20 minutes to complete. In contrast, our slowest streaming algorithm
for this instance took under four minutes and produced a matching that was 18\%
better in weight, using only 1.4 GB of memory.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02075" title="Abstract">arXiv:2311.02075</a> [<a href="/pdf/2311.02075" title="Download PDF">pdf</a>, <a href="/format/2311.02075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Envy-Free Cake-Cutting for Four Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hollender%2C+A">Alexandros Hollender</a>, 
<a href="/search/cs?searchtype=author&query=Rubinstein%2C+A">Aviad Rubinstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">In the envy-free cake-cutting problem we are given a resource, usually called
a cake and represented as the $[0,1]$ interval, and a set of $n$ agents with
heterogeneous preferences over pieces of the cake. The goal is to divide the
cake among the $n$ agents such that no agent is envious of any other agent.
Even under a very general preferences model, this fundamental fair division
problem is known to always admit an exact solution where each agent obtains a
connected piece of the cake; we study the complexity of finding an approximate
solution, i.e., a connected $\varepsilon$-envy-free allocation.
<br />For monotone valuations of cake pieces, Deng, Qi, and Saberi (2012) gave an
efficient ($\textsf{poly}(\log(1/\varepsilon))$ queries) algorithm for three
agents and posed the open problem of four (or more) monotone agents. Even for
the special case of additive valuations, Br\^anzei and Nisan (2022) conjectured
an $\Omega(1/\varepsilon)$ lower bound on the number of queries for four
agents. We provide the first efficient algorithm for finding a connected
$\varepsilon$-envy-free allocation with four monotone agents.
<br />We also prove that as soon as valuations are allowed to be non-monotone, the
problem becomes hard: it becomes PPAD-hard, requires
$\textsf{poly}(1/\varepsilon)$ queries in the black-box model, and even
$\textsf{poly}(1/\varepsilon)$ communication complexity. This constitutes, to
the best of our knowledge, the first intractability result for any version of
the cake-cutting problem in the communication complexity model.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02076" title="Abstract">arXiv:2311.02076</a> [<a href="/pdf/2311.02076" title="Download PDF">pdf</a>, <a href="/format/2311.02076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Sharpness Dynamics in Neural Network Training: Fixed Point  Analysis, Edge of Stability, and Route to Chaos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kalra%2C+D+S">Dayal Singh Kalra</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tianyu He</a>, 
<a href="/search/cs?searchtype=author&query=Barkeshli%2C+M">Maissam Barkeshli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9+21 pages, 8+20 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Chaotic Dynamics (nlin.CD); Machine Learning (stat.ML)

</div>
<p class="mathjax">In gradient descent dynamics of neural networks, the top eigenvalue of the
Hessian of the loss (sharpness) displays a variety of robust phenomena
throughout training. This includes early time regimes where the sharpness may
decrease during early periods of training (sharpness reduction), and later time
behavior such as progressive sharpening and edge of stability. We demonstrate
that a simple $2$-layer linear network (UV model) trained on a single training
example exhibits all of the essential sharpness phenomenology observed in
real-world scenarios. By analyzing the structure of dynamical fixed points in
function space and the vector field of function updates, we uncover the
underlying mechanisms behind these sharpness trends. Our analysis reveals (i)
the mechanism behind early sharpness reduction and progressive sharpening, (ii)
the required conditions for edge of stability, and (iii) a period-doubling
route to chaos on the edge of stability manifold as learning rate is increased.
Finally, we demonstrate that various predictions from this simplified model
generalize to real-world scenarios and discuss its limitations.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02077" title="Abstract">arXiv:2311.02077</a> [<a href="/pdf/2311.02077" title="Download PDF">pdf</a>, <a href="/format/2311.02077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EmerNeRF: Emergent Spatial-Temporal Scene Decomposition via  Self-Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiawei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ivanovic%2C+B">Boris Ivanovic</a>, 
<a href="/search/cs?searchtype=author&query=Litany%2C+O">Or Litany</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+X">Xinshuo Weng</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S+W">Seung Wook Kim</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Boyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Che%2C+T">Tong Che</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Danfei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Fidler%2C+S">Sanja Fidler</a>, 
<a href="/search/cs?searchtype=author&query=Pavone%2C+M">Marco Pavone</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yue Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> See the project page for code, data, and request pre-trained models: <a href="https://emernerf.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present EmerNeRF, a simple yet powerful approach for learning
spatial-temporal representations of dynamic driving scenes. Grounded in neural
fields, EmerNeRF simultaneously captures scene geometry, appearance, motion,
and semantics via self-bootstrapping. EmerNeRF hinges upon two core components:
First, it stratifies scenes into static and dynamic fields. This decomposition
emerges purely from self-supervision, enabling our model to learn from general,
in-the-wild data sources. Second, EmerNeRF parameterizes an induced flow field
from the dynamic field and uses this flow field to further aggregate
multi-frame features, amplifying the rendering precision of dynamic objects.
Coupling these three fields (static, dynamic, and flow) enables EmerNeRF to
represent highly-dynamic scenes self-sufficiently, without relying on ground
truth object annotations or pre-trained models for dynamic object segmentation
or optical flow estimation. Our method achieves state-of-the-art performance in
sensor simulation, significantly outperforming previous methods when
reconstructing static (+2.93 PSNR) and dynamic (+3.70 PSNR) scenes. In
addition, to bolster EmerNeRF's semantic generalization, we lift 2D visual
foundation model features into 4D space-time and address a general positional
bias in modern Transformers, significantly boosting 3D perception performance
(e.g., 37.50% relative improvement in occupancy prediction accuracy on
average). Finally, we construct a diverse and challenging 120-sequence dataset
to benchmark neural fields under extreme and highly-dynamic settings.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Mon,  6 Nov 23</h3>
<dl>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20333" title="Abstract">arXiv:2310.20333</a> (cross-list from math.OC) [<a href="/pdf/2310.20333" title="Download PDF">pdf</a>, <a href="/ps/2310.20333" title="Download PostScript">ps</a>, <a href="/format/2310.20333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semidefinite network games: multiplayer minimax and semidefinite  complementarity problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ickstadt%2C+C">Constantin Ickstadt</a>, 
<a href="/search/math?searchtype=author&query=Theobald%2C+T">Thorsten Theobald</a>, 
<a href="/search/math?searchtype=author&query=Tsigaridas%2C+E">Elias Tsigaridas</a>, 
<a href="/search/math?searchtype=author&query=Varvitsiotis%2C+A">Antonios Varvitsiotis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Network games are an important class of games that model agent interactions
in networked systems, where players are situated at the nodes of a graph and
their payoffs depend on the actions taken by their neighbors. We extend the
classical framework by considering a game model where the strategies are
positive semidefinite matrices having trace one. These (continuous) games can
serve as a simple model of quantum strategic interactions. We focus on the
zero-sum case, where the sum of all players' payoffs is equal to zero. We
establish that in this class of games, Nash equilibria can be characterized as
the projection of a spectrahedron, that is, the feasible region of a
semidefinite program. Furthermore, we demonstrate that determining whether a
game is a semidefinite network game is equivalent to deciding if the value of a
semidefinite program is zero. Beyond the zero-sum case, we characterize Nash
equilibria as the solutions of a semidefinite linear complementarity problem.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01471" title="Abstract">arXiv:2311.01471</a> (cross-list from physics.soc-ph) [<a href="/pdf/2311.01471" title="Download PDF">pdf</a>, <a href="/format/2311.01471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reverse Engineering the Reproduction Number: A Framework for Data-Driven  Counterfactual Analysis, Strategy Evaluation, and Feedback Control of  Epidemics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=She%2C+B">Baike She</a>, 
<a href="/search/physics?searchtype=author&query=Smith%2C+R+L">Rebecca Lee Smith</a>, 
<a href="/search/physics?searchtype=author&query=Pytlarz%2C+I">Ian Pytlarz</a>, 
<a href="/search/physics?searchtype=author&query=Sundaram%2C+S">Shreyas Sundaram</a>, 
<a href="/search/physics?searchtype=author&query=Par%C3%A9%2C+P+E">Philip E. Par&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">During the COVID-19 pandemic, different countries, regions, and communities
constructed various epidemic models to evaluate spreading behaviors and assist
in making mitigation policies. Model uncertainties, introduced by complex
transmission behaviors, contact-tracing networks, time-varying spreading
parameters, and human factors, as well as insufficient data, have posed arduous
challenges for model-based approaches. To address these challenges, we propose
a novel framework for data-driven counterfactual analysis, strategy evaluation,
and feedback control of epidemics, which leverages statistical information from
epidemic testing data instead of constructing a specific model. Through reverse
engineering the reproduction number by quantifying the impact of the
intervention strategy, this framework tackles three primary problems: 1) How
severe would an outbreak have been without the implemented intervention
strategies? 2) What impact would varying the intervention strength have had on
an outbreak? 3) How can we adjust the intervention intensity based on the
current state of an outbreak? Specifically, we consider the epidemic
intervention policies such as the testing-for-isolation strategy as an example,
which was successfully implemented by the University of Illinois
Urbana-Champaign (UIUC) and Purdue University (Purdue) during the COVID-19
pandemic. By leveraging data collected by UIUC and Purdue, we validate the
effectiveness of the proposed data-driven framework.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01476" title="Abstract">arXiv:2311.01476</a> (cross-list from stat.ML) [<a href="/pdf/2311.01476" title="Download PDF">pdf</a>, <a href="/ps/2311.01476" title="Download PostScript">ps</a>, <a href="/format/2311.01476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applications of the Theory of Aggregated Markov Processes in Stochastic  Learning Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Lin%2C+F">Fangyuan Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Probability (math.PR); Applications (stat.AP)

</div>
<p class="mathjax">A stochastic process that arises by composing a function with a Markov
process is called an aggregated Markov process (AMP). The purpose of composing
a Markov process with a function can be a reduction of dimensions, e.g., a
projection onto certain coordinates. The theory around AMP has been extensively
studied e.g. by Dynkin, Cameron, Rogers and Pitman, and Kelly, all of whom
provided sufficient conditions for an AMP to remain Markov. In another
direction, Larget provided a canonical representation for AMP, which can be
used to verify the equivalence of two AMPs. The purpose of this paper is to
describe how the theory of AMP can be applied to stochastic learning theory as
they learn a particular task.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01489" title="Abstract">arXiv:2311.01489</a> (cross-list from stat.ML) [<a href="/pdf/2311.01489" title="Download PDF">pdf</a>, <a href="/format/2311.01489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Invariant Causal Imitation Learning for Generalizable Policies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bica%2C+I">Ioana Bica</a>, 
<a href="/search/stat?searchtype=author&query=Jarrett%2C+D">Daniel Jarrett</a>, 
<a href="/search/stat?searchtype=author&query=van+der+Schaar%2C+M">Mihaela van der Schaar</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Proc. 35th International Conference on Neural Information
  Processing Systems (NeurIPS 2021)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Consider learning an imitation policy on the basis of demonstrated behavior
from multiple environments, with an eye towards deployment in an unseen
environment. Since the observable features from each setting may be different,
directly learning individual policies as mappings from features to actions is
prone to spurious correlations -- and may not generalize well. However, the
expert's policy is often a function of a shared latent structure underlying
those observable features that is invariant across settings. By leveraging data
from multiple environments, we propose Invariant Causal Imitation Learning
(ICIL), a novel technique in which we learn a feature representation that is
invariant across domains, on the basis of which we learn an imitation policy
that matches expert behavior. To cope with transition dynamics mismatch, ICIL
learns a shared representation of causal features (for all training
environments), that is disentangled from the specific representations of noise
variables (for each of those environments). Moreover, to ensure that the
learned policy matches the observation distribution of the expert's policy,
ICIL estimates the energy of the expert's observations and uses a
regularization term that minimizes the imitator policy's next state energy.
Experimentally, we compare our methods against several benchmarks in control
and healthcare tasks and show its effectiveness in learning imitation policies
capable of generalizing to unseen environments.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01491" title="Abstract">arXiv:2311.01491</a> (cross-list from physics.chem-ph) [<a href="/pdf/2311.01491" title="Download PDF">pdf</a>, <a href="/format/2311.01491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating the Behavior of Diffusion Models for Accelerating  Electronic Structure Calculations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Rothchild%2C+D">Daniel Rothchild</a>, 
<a href="/search/physics?searchtype=author&query=Rosen%2C+A+S">Andrew S. Rosen</a>, 
<a href="/search/physics?searchtype=author&query=Taw%2C+E">Eric Taw</a>, 
<a href="/search/physics?searchtype=author&query=Robinson%2C+C">Connie Robinson</a>, 
<a href="/search/physics?searchtype=author&query=Gonzalez%2C+J+E">Joseph E. Gonzalez</a>, 
<a href="/search/physics?searchtype=author&query=Krishnapriyan%2C+A+S">Aditi S. Krishnapriyan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Materials Science (cond-mat.mtrl-sci); Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">We present an investigation into diffusion models for molecular generation,
with the aim of better understanding how their predictions compare to the
results of physics-based calculations. The investigation into these models is
driven by their potential to significantly accelerate electronic structure
calculations using machine learning, without requiring expensive
first-principles datasets for training interatomic potentials. We find that the
inference process of a popular diffusion model for de novo molecular generation
is divided into an exploration phase, where the model chooses the atomic
species, and a relaxation phase, where it adjusts the atomic coordinates to
find a low-energy geometry. As training proceeds, we show that the model
initially learns about the first-order structure of the potential energy
surface, and then later learns about higher-order structure. We also find that
the relaxation phase of the diffusion model can be re-purposed to sample the
Boltzmann distribution over conformations and to carry out structure
relaxations. For structure relaxations, the model finds geometries with ~10x
lower energy than those produced by a classical force field for small organic
molecules. Initializing a density functional theory (DFT) relaxation at the
diffusion-produced structures yields a &gt;2x speedup to the DFT relaxation when
compared to initializing at structures relaxed with a classical force field.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01500" title="Abstract">arXiv:2311.01500</a> (cross-list from astro-ph.GA) [<a href="/pdf/2311.01500" title="Download PDF">pdf</a>, <a href="/format/2311.01500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> E(2) Equivariant Neural Networks for Robust Galaxy Morphology  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Pandya%2C+S">Sneh Pandya</a>, 
<a href="/search/astro-ph?searchtype=author&query=Patel%2C+P">Purvik Patel</a>, 
<a href="/search/astro-ph?searchtype=author&query=O%2C+F">Franc O</a>, 
<a href="/search/astro-ph?searchtype=author&query=Blazek%2C+J">Jonathan Blazek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures, 3 tables, Accepted to the Machine Learning and the Physical Sciences Workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Astrophysics of Galaxies (astro-ph.GA)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose the use of group convolutional neural network architectures
(GCNNs) equivariant to the 2D Euclidean group, $E(2)$, for the task of galaxy
morphology classification by utilizing symmetries of the data present in galaxy
images as an inductive bias in the architecture. We conduct robustness studies
by introducing artificial perturbations via Poisson noise insertion and
one-pixel adversarial attacks to simulate the effects of limited observational
capabilities. We train, validate, and test GCNNs equivariant to discrete
subgroups of $E(2)$ - the cyclic and dihedral groups of order $N$ - on the
Galaxy10 DECals dataset and find that GCNNs achieve higher classification
accuracy and are consistently more robust than their non-equivariant
counterparts, with an architecture equivariant to the group $D_{16}$ achieving
a $95.52 \pm 0.18\%$ test-set accuracy. We also find that the model loses
$&lt;6\%$ accuracy on a $50\%$-noise dataset and all GCNNs are less susceptible to
one-pixel perturbations than an identically constructed CNN. Our code is
publicly available at https://github.com/snehjp2/GCNNMorphology.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01519" title="Abstract">arXiv:2311.01519</a> (cross-list from physics.soc-ph) [<a href="/pdf/2311.01519" title="Download PDF">pdf</a>, <a href="/ps/2311.01519" title="Download PostScript">ps</a>, <a href="/format/2311.01519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discussion of the Effect of Inter-group Sub-groups Using a Consensus  Model Incorporating External Effective or Immobile Magnetic Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Kawahata%2C+Y">Yasuko Kawahata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Discussion Paper:Theory of opinion distribution in human relations where trust and distrust mixed(2020)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Individuals belong to certain social groups in search of a sense of
belonging, pride, stability, and significance. Perceiving the group to which
one belongs as an "in-group" and other groups as "out-groups" often leads to
harmful and discriminatory attitudes. In-group consciousness reinforces a sense
of unity within the group and promotes commitment to group goals and problem
solving. Identification with the in-group also shapes the social cognitive
framework (norms, values, and beliefs) that determine group behavior. In fact,
identification with an in-group often leads to prejudice, ethnocentrism,
stereotyping, and discrimination, even in the absence of physical conflict or
hostility. Social scientists have conducted thousands of empirical studies to
elucidate the mechanisms behind these prejudices and discriminations and the
social conflicts they generate. These studies are essential to understanding
the processes by which group membership and self-categorization create
prejudice and discrimination, which in turn lead to social conflict. However,
there remain many unanswered questions about howin-groups and out-groups
canmove beyond conflict to build harmony and avoid social conflict. According
to existing research, it is difficult to establish harmonious relationships
between in-groups and out-groups. This study proposes an approach using opinion
dynamics theory and social simulation to examine these issues. We examine the
possibility of simulating the movement of opinions between and within groups
and applying the considerations to cases of social conflict. The model analyzes
the severity of conflict within a society with two groups on the basis of
intragroup and intergroup trust.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01537" title="Abstract">arXiv:2311.01537</a> (cross-list from stat.ML) [<a href="/pdf/2311.01537" title="Download PDF">pdf</a>, <a href="/format/2311.01537" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variable Selection in Maximum Mean Discrepancy for Interpretable  Distribution Comparison
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Mitsuzawa%2C+K">Kensuke Mitsuzawa</a>, 
<a href="/search/stat?searchtype=author&query=Kanagawa%2C+M">Motonobu Kanagawa</a>, 
<a href="/search/stat?searchtype=author&query=Bortoli%2C+S">Stefano Bortoli</a>, 
<a href="/search/stat?searchtype=author&query=Grossi%2C+M">Margherita Grossi</a>, 
<a href="/search/stat?searchtype=author&query=Papotti%2C+P">Paolo Papotti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Two-sample testing decides whether two datasets are generated from the same
distribution. This paper studies variable selection for two-sample testing, the
task being to identify the variables (or dimensions) responsible for the
discrepancies between the two distributions. This task is relevant to many
problems of pattern analysis and machine learning, such as dataset shift
adaptation, causal inference and model validation. Our approach is based on a
two-sample test based on the Maximum Mean Discrepancy (MMD). We optimise the
Automatic Relevance Detection (ARD) weights defined for individual variables to
maximise the power of the MMD-based test. For this optimisation, we introduce
sparse regularisation and propose two methods for dealing with the issue of
selecting an appropriate regularisation parameter. One method determines the
regularisation parameter in a data-driven way, and the other aggregates the
results of different regularisation parameters. We confirm the validity of the
proposed methods by systematic comparisons with baseline methods, and
demonstrate their usefulness in exploratory analysis of high-dimensional
traffic simulation data. Preliminary theoretical analyses are also provided,
including a rigorous definition of variable selection for two-sample testing.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01574" title="Abstract">arXiv:2311.01574</a> (cross-list from eess.IV) [<a href="/pdf/2311.01574" title="Download PDF">pdf</a>, <a href="/ps/2311.01574" title="Download PostScript">ps</a>, <a href="/format/2311.01574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Lesion Segmentation in FDG-18 Whole-Body PET/CT scans using  Multilabel approach: AutoPET II challenge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Murugesan%2C+G+K">Gowtham Krishnan Murugesan</a>, 
<a href="/search/eess?searchtype=author&query=McCrumb%2C+D">Diana McCrumb</a>, 
<a href="/search/eess?searchtype=author&query=Brunner%2C+E">Eric Brunner</a>, 
<a href="/search/eess?searchtype=author&query=Kumar%2C+J">Jithendra Kumar</a>, 
<a href="/search/eess?searchtype=author&query=Soni%2C+R">Rahul Soni</a>, 
<a href="/search/eess?searchtype=author&query=Grigorash%2C+V">Vasily Grigorash</a>, 
<a href="/search/eess?searchtype=author&query=Moore%2C+S">Stephen Moore</a>, 
<a href="/search/eess?searchtype=author&query=Van+Oss%2C+J">Jeff Van Oss</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AutoPET II challenge paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Automatic segmentation of lesions in FDG-18 Whole Body (WB) PET/CT scans
using deep learning models is instrumental for determining treatment response,
optimizing dosimetry, and advancing theranostic applications in oncology.
However, the presence of organs with elevated radiotracer uptake, such as the
liver, spleen, brain, and bladder, often leads to challenges, as these regions
are often misidentified as lesions by deep learning models. To address this
issue, we propose a novel approach of segmenting both organs and lesions,
aiming to enhance the performance of automatic lesion segmentation methods. In
this study, we assessed the effectiveness of our proposed method using the
AutoPET II challenge dataset, which comprises 1014 subjects. We evaluated the
impact of inclusion of additional labels and data in the segmentation
performance of the model. In addition to the expert-annotated lesion labels, we
introduced eight additional labels for organs, including the liver, kidneys,
urinary bladder, spleen, lung, brain, heart, and stomach. These labels were
integrated into the dataset, and a 3D UNET model was trained within the nnUNet
framework. Our results demonstrate that our method achieved the top ranking in
the held-out test dataset, underscoring the potential of this approach to
significantly improve lesion segmentation accuracy in FDG-18 Whole-Body PET/CT
scans, ultimately benefiting cancer patients and advancing clinical practice.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01588" title="Abstract">arXiv:2311.01588</a> (cross-list from astro-ph.CO) [<a href="/pdf/2311.01588" title="Download PDF">pdf</a>, <a href="/format/2311.01588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Adaptive Graph Neural Networks for Constraining Cosmological  Parameters Across Multiple Data Sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Roncoli%2C+A">Andrea Roncoli</a>, 
<a href="/search/astro-ph?searchtype=author&query=%C4%86iprijanovi%C4%87%2C+A">Aleksandra &#x106;iprijanovi&#x107;</a>, 
<a href="/search/astro-ph?searchtype=author&query=Voetberg%2C+M">Maggie Voetberg</a>, 
<a href="/search/astro-ph?searchtype=author&query=Villaescusa-Navarro%2C+F">Francisco Villaescusa-Navarro</a>, 
<a href="/search/astro-ph?searchtype=author&query=Nord%2C+B">Brian Nord</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in Machine Learning and the Physical Sciences Workshop at NeurIPS 2023; 19 pages, 2 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cosmology and Nongalactic Astrophysics (astro-ph.CO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep learning models have been shown to outperform methods that rely on
summary statistics, like the power spectrum, in extracting information from
complex cosmological data sets. However, due to differences in the subgrid
physics implementation and numerical approximations across different simulation
suites, models trained on data from one cosmological simulation show a drop in
performance when tested on another. Similarly, models trained on any of the
simulations would also likely experience a drop in performance when applied to
observational data. Training on data from two different suites of the CAMELS
hydrodynamic cosmological simulations, we examine the generalization
capabilities of Domain Adaptive Graph Neural Networks (DA-GNNs). By utilizing
GNNs, we capitalize on their capacity to capture structured scale-free
cosmological information from galaxy distributions. Moreover, by including
unsupervised domain adaptation via Maximum Mean Discrepancy (MMD), we enable
our models to extract domain-invariant features. We demonstrate that DA-GNN
achieves higher accuracy and robustness on cross-dataset tasks (up to $28\%$
better relative error and up to almost an order of magnitude better $\chi^2$).
Using data visualizations, we show the effects of domain adaptation on proper
latent space data alignment. This shows that DA-GNNs are a promising method for
extracting domain-independent cosmological information, a vital step toward
robust deep learning for real cosmic survey data.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01614" title="Abstract">arXiv:2311.01614</a> (cross-list from math.OC) [<a href="/pdf/2311.01614" title="Download PDF">pdf</a>, <a href="/format/2311.01614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Alleviating the Curse of Dimensionality in Minkowski Sum Approximations  of Storage Flexibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=%C3%96zt%C3%BCrk%2C+E">Emrah &#xd6;zt&#xfc;rk</a>, 
<a href="/search/math?searchtype=author&query=Faulwasser%2C+T">Timm Faulwasser</a>, 
<a href="/search/math?searchtype=author&query=Worthmann%2C+K">Karl Worthmann</a>, 
<a href="/search/math?searchtype=author&query=Prei%C3%9Finger%2C+M">Markus Prei&#xdf;inger</a>, 
<a href="/search/math?searchtype=author&query=Rheinberger%2C+K">Klaus Rheinberger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Many real-world applications require the joint optimization of a large number
of flexible devices over some time horizon. The flexibility of multiple
batteries, thermostatically controlled loads, or electric vehicles, e.g., can
be used to support grid operations and to reduce operation costs. Using
piecewise constant power values, the flexibility of each device over $d$ time
periods can be described as a polytopic subset in power space. The aggregated
flexibility is given by the Minkowski sum of these polytopes. As the
computation of Minkowski sums is in general demanding, several approximations
have been proposed in the literature. Yet, their application potential is often
objective-dependent and limited by the curse of dimensionality. In this paper,
we show that up to $2^d$ vertices of each polytope can be computed efficiently
and that the convex hull of their sums provides a computationally efficient
inner approximation of the Minkowski sum. Via an extensive simulation study, we
illustrate that our approach outperforms ten state-of-the-art inner
approximations in terms of computational complexity and accuracy for different
objectives. Moreover, we propose an efficient disaggregation method applicable
to any vertex-based approximation. The proposed methods provide an efficient
means to aggregate and to disaggregate typical battery storages in
quarter-hourly periods over an entire day with reasonable accuracy for
aggregated cost and for peak power optimization.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01624" title="Abstract">arXiv:2311.01624</a> (cross-list from eess.IV) [<a href="/pdf/2311.01624" title="Download PDF">pdf</a>, <a href="/format/2311.01624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention based Dual-Branch Complex Feature Fusion Network for  Hyperspectral Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Alkhatib%2C+M+Q">Mohammed Q. Alkhatib</a>, 
<a href="/search/eess?searchtype=author&query=Al-Saad%2C+M">Mina Al-Saad</a>, 
<a href="/search/eess?searchtype=author&query=Aburaed%2C+N">Nour Aburaed</a>, 
<a href="/search/eess?searchtype=author&query=Zitouni%2C+M+S">M. Sami Zitouni</a>, 
<a href="/search/eess?searchtype=author&query=Ahmad%2C+H+A">Hussain Al Ahmad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This research work presents a novel dual-branch model for hyperspectral image
classification that combines two streams: one for processing standard
hyperspectral patches using Real-Valued Neural Network (RVNN) and the other for
processing their corresponding Fourier transforms using Complex-Valued Neural
Network (CVNN). The proposed model is evaluated on the Pavia University and
Salinas datasets. Results show that the proposed model outperforms
state-of-the-art methods in terms of overall accuracy, average accuracy, and
Kappa. Through the incorporation of Fourier transforms in the second stream,
the model is able to extract frequency information, which complements the
spatial information extracted by the first stream. The combination of these two
streams improves the overall performance of the model. Furthermore, to enhance
the model performance, the Squeeze and Excitation (SE) mechanism has been
utilized. Experimental evidence show that SE block improves the models overall
accuracy by almost 1\%.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01653" title="Abstract">arXiv:2311.01653</a> (cross-list from eess.IV) [<a href="/pdf/2311.01653" title="Download PDF">pdf</a>, <a href="/ps/2311.01653" title="Download PostScript">ps</a>, <a href="/format/2311.01653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> INeAT: Iterative Neural Adaptive Tomography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xiong%2C+B">Bo Xiong</a>, 
<a href="/search/eess?searchtype=author&query=Su%2C+C">Changqing Su</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+Z">Zihan Lin</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Y">You Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+Z">Zhaofei Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Computed Tomography (CT) with its remarkable capability for three-dimensional
imaging from multiple projections, enjoys a broad range of applications in
clinical diagnosis, scientific observation, and industrial detection. Neural
Adaptive Tomography (NeAT) is a recently proposed 3D rendering method based on
neural radiance field for CT, and it demonstrates superior performance compared
to traditional methods. However, it still faces challenges when dealing with
the substantial perturbations and pose shifts encountered in CT scanning
processes. Here, we propose a neural rendering method for CT reconstruction,
named Iterative Neural Adaptive Tomography (INeAT), which incorporates
iterative posture optimization to effectively counteract the influence of
posture perturbations in data, particularly in cases involving significant
posture variations. Through the implementation of a posture feedback
optimization strategy, INeAT iteratively refines the posture corresponding to
the input images based on the reconstructed 3D volume. We demonstrate that
INeAT achieves artifact-suppressed and resolution-enhanced reconstruction in
scenarios with significant pose disturbances. Furthermore, we show that our
INeAT maintains comparable reconstruction performance to stable-state
acquisitions even using data from unstable-state acquisitions, which
significantly reduces the time required for CT scanning and relaxes the
stringent requirements on imaging hardware systems, underscoring its immense
potential for applications in short-time and low-cost CT technology.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01664" title="Abstract">arXiv:2311.01664</a> (cross-list from physics.comp-ph) [<a href="/pdf/2311.01664" title="Download PDF">pdf</a>, <a href="/format/2311.01664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Theoretical Case Study of the Generalisation of Machine-learned  Potentials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Wang%2C+Y">Yangshuai Wang</a>, 
<a href="/search/physics?searchtype=author&query=Patel%2C+S">Shashwat Patel</a>, 
<a href="/search/physics?searchtype=author&query=Ortner%2C+C">Christoph Ortner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2209.05366">arXiv:2209.05366</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Machine-learned interatomic potentials (MLIPs) are typically trained on
datasets that encompass a restricted subset of possible input structures, which
presents a potential challenge for their generalization to a broader range of
systems outside the training set. Nevertheless, MLIPs have demonstrated
impressive accuracy in predicting forces and energies in simulations involving
intricate and complex structures. In this paper we aim to take steps towards
rigorously explaining the excellent observed generalisation properties of
MLIPs. Specifically, we offer a comprehensive theoretical and numerical
investigation of the generalization of MLIPs in the context of dislocation
simulations. We quantify precisely how the accuracy of such simulations is
directly determined by a few key factors: the size of the training structures,
the choice of training observations (e.g., energies, forces, virials), and the
level of accuracy achieved in the fitting process. Notably, our study reveals
the crucial role of fitting virials in ensuring the consistency of MLIPs for
dislocation simulations. Our series of careful numerical experiments
encompassing screw, edge, and mixed dislocations, supports existing best
practices in the MLIPs literature but also provides new insights into the
design of data sets and loss functions.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01681" title="Abstract">arXiv:2311.01681</a> (cross-list from stat.AP) [<a href="/pdf/2311.01681" title="Download PDF">pdf</a>, <a href="/format/2311.01681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The R.O.A.D. to precision medicine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bertsimas%2C+D">Dimitris Bertsimas</a>, 
<a href="/search/stat?searchtype=author&query=Koulouras%2C+A+G">Angelos G. Koulouras</a>, 
<a href="/search/stat?searchtype=author&query=Margonis%2C+G+A">Georgios Antonios Margonis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applications (stat.AP)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)

</div>
<p class="mathjax">We propose a prognostic stratum matching framework that addresses the
deficiencies of Randomized trial data subgroup analysis and transforms
ObservAtional Data to be used as if they were randomized, thus paving the road
for precision medicine. Our approach counters the effects of unobserved
confounding in observational data by correcting the estimated probabilities of
the outcome under a treatment through a novel two-step process. These
probabilities are then used to train Optimal Policy Trees (OPTs), which are
decision trees that optimally assign treatments to subgroups of patients based
on their characteristics. This facilitates the creation of clinically intuitive
treatment recommendations. We applied our framework to observational data of
patients with gastrointestinal stromal tumors (GIST) and validated the OPTs in
an external cohort using the sensitivity and specificity metrics. We show that
these recommendations outperformed those of experts in GIST. We further applied
the same framework to randomized clinical trial (RCT) data of patients with
extremity sarcomas. Remarkably, despite the initial trial results suggesting
that all patients should receive treatment, our framework, after addressing
imbalances in patient distribution due to the trial's small sample size,
identified through the OPTs a subset of patients with unique characteristics
who may not require treatment. Again, we successfully validated our
recommendations in an external cohort.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01683" title="Abstract">arXiv:2311.01683</a> (cross-list from physics.med-ph) [<a href="/pdf/2311.01683" title="Download PDF">pdf</a>, <a href="/ps/2311.01683" title="Download PostScript">ps</a>, <a href="/format/2311.01683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Amide Proton Transfer (APT) imaging in tumor with a machine learning  approach using partially synthetic data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Viswanathan%2C+M">Malvika Viswanathan</a>, 
<a href="/search/physics?searchtype=author&query=Yin%2C+L">Leqi Yin</a>, 
<a href="/search/physics?searchtype=author&query=Kurmi%2C+Y">Yashwant Kurmi</a>, 
<a href="/search/physics?searchtype=author&query=Zu%2C+Z">Zhongliang Zu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Machine learning (ML) has been increasingly used to quantify chemical
exchange saturation transfer (CEST) effect. ML models are typically trained
using either measured data or fully simulated data. However, training with
measured data often lacks sufficient training data, while training with fully
simulated data may introduce bias due to limited simulations pools. This study
introduces a new platform that combines simulated and measured components to
generate partially synthetic CEST data, and to evaluate its feasibility for
training ML models to predict amide proton transfer (APT) effect. Partially
synthetic CEST signals were created using an inverse summation of APT effects
from simulations and the other components from measurements. Training data were
generated by varying APT simulation parameters and applying scaling factors to
adjust the measured components, achieving a balance between simulation
flexibility and fidelity. First, tissue-mimicking CEST signals along with
ground truth information were created using multiple-pool model simulations to
validate this method. Second, an ML model was trained individually on partially
synthetic data, in vivo data, and fully simulated data, to predict APT effect
in rat brains bearing 9L tumors. Experiments on tissue-mimicking data suggest
that the ML method using the partially synthetic data is accurate in predicting
APT. In vivo experiments suggest that our method provides more accurate and
robust prediction than the training using in vivo data and fully synthetic
data. Partially synthetic CEST data can address the challenges in conventional
ML methods.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01702" title="Abstract">arXiv:2311.01702</a> (cross-list from eess.IV) [<a href="/pdf/2311.01702" title="Download PDF">pdf</a>, <a href="/ps/2311.01702" title="Download PostScript">ps</a>, <a href="/format/2311.01702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Medical Image Segmentation with Domain Adaptation: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yuemeng Li</a>, 
<a href="/search/eess?searchtype=author&query=Fan%2C+Y">Yong Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Survey
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Deep learning (DL) has shown remarkable success in various medical imaging
data analysis applications. However, it remains challenging for DL models to
achieve good generalization, especially when the training and testing datasets
are collected at sites with different scanners, due to domain shift caused by
differences in data distributions. Domain adaptation has emerged as an
effective means to address this challenge by mitigating domain gaps in medical
imaging applications. In this review, we specifically focus on domain
adaptation approaches for DL-based medical image segmentation. We first present
the motivation and background knowledge underlying domain adaptations, then
provide a comprehensive review of domain adaptation applications in medical
image segmentations, and finally discuss the challenges, limitations, and
future research trends in the field to promote the methodology development of
domain adaptation in the context of medical image segmentation. Our goal was to
provide researchers with up-to-date references on the applications of domain
adaptation in medical image segmentation studies.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01727" title="Abstract">arXiv:2311.01727</a> (cross-list from quant-ph) [<a href="/pdf/2311.01727" title="Download PDF">pdf</a>, <a href="/format/2311.01727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flexible Error Mitigation of Quantum Processes with Data Augmentation  Empowered Neural Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Liao%2C+M">Manwen Liao</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhu%2C+Y">Yan Zhu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chiribella%2C+G">Giulio Chiribella</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yang%2C+Y">Yuxiang Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures + appendix; comments are welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Neural networks have shown their effectiveness in various tasks in the realm
of quantum computing. However, their application in quantum error mitigation, a
crucial step towards realizing practical quantum advancements, has been
restricted by reliance on noise-free statistics. To tackle this critical
challenge, we propose a data augmentation empowered neural model for error
mitigation (DAEM). Our model does not require any prior knowledge about the
specific noise type and measurement settings and can estimate noise-free
statistics solely from the noisy measurement results of the target quantum
process, rendering it highly suitable for practical implementation. In
numerical experiments, we show the model's superior performance in mitigating
various types of noise, including Markovian noise and Non-Markovian noise,
compared with previous error mitigation methods. We further demonstrate its
versatility by employing the model to mitigate errors in diverse types of
quantum processes, including those involving large-scale quantum systems and
continuous-variable quantum states. This powerful data augmentation-empowered
neural model for error mitigation establishes a solid foundation for realizing
more reliable and robust quantum technologies in practical applications.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01731" title="Abstract">arXiv:2311.01731</a> (cross-list from eess.IV) [<a href="/pdf/2311.01731" title="Download PDF">pdf</a>, <a href="/format/2311.01731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Capturing Local and Global Features in Medical Images by Using Ensemble  CNN-Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kaleybar%2C+J+M">Javad Mirzapour Kaleybar</a>, 
<a href="/search/eess?searchtype=author&query=Saadat%2C+H">Hooman Saadat</a>, 
<a href="/search/eess?searchtype=author&query=Khaloo%2C+H">Hooman Khaloo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This paper introduces a groundbreaking classification model called the
Controllable Ensemble Transformer and CNN (CETC) for the analysis of medical
images. The CETC model combines the powerful capabilities of convolutional
neural networks (CNNs) and transformers to effectively capture both local and
global features present in medical images. The model architecture comprises
three main components: a convolutional encoder block (CEB), a
transposed-convolutional decoder block (TDB), and a transformer classification
block (TCB). The CEB is responsible for capturing multi-local features at
different scales and draws upon components from VGGNet, ResNet, and MobileNet
as backbones. By leveraging this combination, the CEB is able to effectively
detect and encode local features. The TDB, on the other hand, consists of
sub-decoders that decode and sum the captured features using ensemble
coefficients. This enables the model to efficiently integrate the information
from multiple scales. Finally, the TCB utilizes the SwT backbone and a
specially designed prediction head to capture global features, ensuring a
comprehensive understanding of the entire image. The paper provides detailed
information on the experimental setup and implementation, including the use of
transfer learning, data preprocessing techniques, and training settings. The
CETC model is trained and evaluated using two publicly available COVID-19
datasets. Remarkably, the model outperforms existing state-of-the-art models
across various evaluation metrics. The experimental results clearly demonstrate
the superiority of the CETC model, emphasizing its potential for accurately and
efficiently analyzing medical images.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01742" title="Abstract">arXiv:2311.01742</a> (cross-list from math.OC) [<a href="/pdf/2311.01742" title="Download PDF">pdf</a>, <a href="/format/2311.01742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Global Optimization: A Machine Learning Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bertsimas%2C+D">Dimitris Bertsimas</a>, 
<a href="/search/math?searchtype=author&query=Margaritis%2C+G">Georgios Margaritis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the Journal of Global Optimization. 35 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Many approaches for addressing Global Optimization problems typically rely on
relaxations of nonlinear constraints over specific mathematical primitives.
This is restricting in applications with constraints that are black-box,
implicit or consist of more general primitives. Trying to address such
limitations, Bertsimas and Ozturk (2023) proposed OCTHaGOn as a way of solving
black-box global optimization problems by approximating the nonlinear
constraints using hyperplane-based Decision-Trees and then using those trees to
construct a unified mixed integer optimization (MIO) approximation of the
original problem. We provide extensions to this approach, by (i) approximating
the original problem using other MIO-representable ML models besides Decision
Trees, such as Gradient Boosted Trees, Multi Layer Perceptrons and Suport
Vector Machines, (ii) proposing adaptive sampling procedures for more accurate
machine learning-based constraint approximations, (iii) utilizing robust
optimization to account for the uncertainty of the sample-dependent training of
the ML models, and (iv) leveraging a family of relaxations to address the
infeasibilities of the final MIO approximation. We then test the enhanced
framework in 81 Global Optimization instances. We show improvements in solution
feasibility and optimality in the majority of instances. We also compare
against BARON, showing improved optimality gaps or solution times in 11
instances.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01762" title="Abstract">arXiv:2311.01762</a> (cross-list from stat.ML) [<a href="/pdf/2311.01762" title="Download PDF">pdf</a>, <a href="/format/2311.01762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Kernel Ridge Regression with Gradient Descent for a Non-Constant  Kernel
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Allerbo%2C+O">Oskar Allerbo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Article <a href="/abs/2306.16838">arXiv:2306.16838v1</a> has been updated and split into two articles: this article and <a href="/abs/2306.16838">arXiv:2306.16838v2</a>. Thus, much of the content in this article is also a part of <a href="/abs/2306.16838">arXiv:2306.16838v1</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC); Methodology (stat.ME)

</div>
<p class="mathjax">Kernel ridge regression, KRR, is a generalization of linear ridge regression
that is non-linear in the data, but linear in the parameters. The solution can
be obtained either as a closed-form solution, which includes a matrix
inversion, or iteratively through gradient descent. Using the iterative
approach opens up for changing the kernel during training, something that is
investigated in this paper. We theoretically address the effects this has on
model complexity and generalization. Based on our findings, we propose an
update scheme for the bandwidth of translational-invariant kernels, where we
let the bandwidth decrease to zero during training, thus circumventing the need
for hyper-parameter selection. We demonstrate on real and synthetic data how
decreasing the bandwidth during training outperforms using a constant
bandwidth, selected by cross-validation and marginal likelihood maximization.
We also show theoretically and empirically that using a decreasing bandwidth,
we are able to achieve both zero training error in combination with good
generalization, and a double descent behavior, phenomena that do not occur for
KRR with constant bandwidth but are known to appear for neural networks.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01774" title="Abstract">arXiv:2311.01774</a> (cross-list from math-ph) [<a href="/pdf/2311.01774" title="Download PDF">pdf</a>, <a href="/format/2311.01774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Control with Obstacle Avoidance for Incompressible Ideal Flows  of an Inviscid Fluid
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math-ph?searchtype=author&query=Simoes%2C+A+A">Alexandre Anahory Simoes</a>, 
<a href="/search/math-ph?searchtype=author&query=Bloch%2C+A">Anthony Bloch</a>, 
<a href="/search/math-ph?searchtype=author&query=Colombo%2C+L">Leonardo Colombo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Physics (math-ph)</span>; Numerical Analysis (math.NA); Optimization and Control (math.OC)

</div>
<p class="mathjax">It has been shown in previous works that an optimal control formulation for
an incompressible ideal fluid flow yields Euler's fluid equations. In this
paper we consider the modified Euler's equations by adding a potential function
playing the role of a barrier function in the corresponding optimal control
problem with the motivation of studying obstacle avoidance in the motion of
fluid particles for incompressible ideal flows of an inviscid fluid From the
physical point of view, imposing an artificial potential in the fluid context
is equivalent to generating a desired pressure. Simulation results for the
obstacle avoidance task are provided.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01777" title="Abstract">arXiv:2311.01777</a> (cross-list from eess.IV) [<a href="/pdf/2311.01777" title="Download PDF">pdf</a>, <a href="/format/2311.01777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CheX-Nomaly: Segmenting Lung Abnormalities from Chest Radiographs using  Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Singh%2C+S">Sanskriti Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages; 13 figures; 3 appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">The global challenge in chest radiograph X-ray (CXR) abnormalities often
being misdiagnosed is primarily associated with perceptual errors, where
healthcare providers struggle to accurately identify the location of
abnormalities, rather than misclassification errors. We currently address this
problem through disease-specific segmentation models. Unfortunately, these
models cannot be released in the field due to their lack of generalizability
across all thoracic diseases. A binary model tends to perform poorly when it
encounters a disease that isn't represented in the dataset. We present
CheX-nomaly: a binary localization U-net model that leverages transfer learning
techniques with the incorporation of an innovative contrastive learning
approach. Trained on the VinDr-CXR dataset, which encompasses 14 distinct
diseases in addition to 'no finding' cases, my model achieves generalizability
across these 14 diseases and others it has not seen before. We show that we can
significantly improve the generalizability of an abnormality localization model
by incorporating a contrastive learning method and dissociating the bounding
boxes with its disease class. We also introduce a new loss technique to apply
to enhance the U-nets performance on bounding box segmentation. By introducing
CheX-nomaly, we offer a promising solution to enhance the precision of chest
disease diagnosis, with a specific focus on reducing the significant number of
perceptual errors in healthcare.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01806" title="Abstract">arXiv:2311.01806</a> (cross-list from math.OC) [<a href="/pdf/2311.01806" title="Download PDF">pdf</a>, <a href="/format/2311.01806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sketching for Convex and Nonconvex Regularized Least Squares with Sharp  Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yang%2C+Y">Yingzhen Yang</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+P">Ping Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
<p class="mathjax">Randomized algorithms are important for solving large-scale optimization
problems. In this paper, we propose a fast sketching algorithm for least square
problems regularized by convex or nonconvex regularization functions, Sketching
for Regularized Optimization (SRO). Our SRO algorithm first generates a sketch
of the original data matrix, then solves the sketched problem. Different from
existing randomized algorithms, our algorithm handles general Frechet
subdifferentiable regularization functions in an unified framework. We present
general theoretical result for the approximation error between the optimization
results of the original problem and the sketched problem for regularized least
square problems which can be convex or nonconvex. For arbitrary convex
regularizer, relative-error bound is proved for the approximation error.
Importantly, minimax rates for sparse signal estimation by solving the sketched
sparse convex or nonconvex learning problems are also obtained using our
general theoretical result under mild conditions. To the best of our knowledge,
our results are among the first to demonstrate minimax rates for convex or
nonconvex sparse learning problem by sketching under a unified theoretical
framework. We further propose an iterative sketching algorithm which reduces
the approximation error exponentially by iteratively invoking the sketching
algorithm. Experimental results demonstrate the effectiveness of the proposed
SRO and Iterative SRO algorithms.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01852" title="Abstract">arXiv:2311.01852</a> (cross-list from quant-ph) [<a href="/pdf/2311.01852" title="Download PDF">pdf</a>, <a href="/format/2311.01852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimisation of Active Space Debris Removal Missions With Multiple  Targets Using Quantum Annealing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Swain%2C+T">Thomas Swain</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">A strategy for the analysis of active debris removal missions targeting
multiple objects from a set of objects in near-circular orbit with similar
inclination is presented. Algebraic techniques successfully reduce the orbital
mechanics regarding specific inter-debris transfer and disposal methods to
simple computations, which can be used as the coefficients of a quadratic
unconstrained binary optimisation (QUBO) problem formulation which minimises
the total propellant used in the mission whilst allowing for servicing time and
meeting the mission deadline. The QUBO is validated by solving artificial small
problems (from 2 to 11 debris) using classical computational methods and the
weaknesses in using these methods are examined prior to solution using quantum
annealing hardware. The quantum processing unit (QPU) and quantum-classical
hybrid solvers provided by D-Wave are then used to solve the same small
problems, with attention paid to evident strengths and weaknesses of each
approach. Hybrid solvers are found to be significantly more effective at
solving larger problems. Finally, the hybrid method is used to solve a large
problem using a real dataset. From a set of 79 debris objects resulting from
the destruction of the Kosmos-1408 satellite, an active debris removal mission
starting on 30 September 2023 targeting 5 debris objects for disposal within a
year with 20 days servicing time per object is successfully planned. This plan
calculates the total propellant cost of transfer and disposal to be 0.87km/s
and would be complete well within the deadline at 241 days from the start date.
This problem uses 6,478 binary variables in total and is solved using around
25s of QPU access time.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01854" title="Abstract">arXiv:2311.01854</a> (cross-list from eess.IV) [<a href="/pdf/2311.01854" title="Download PDF">pdf</a>, <a href="/format/2311.01854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Ensemble Machine Learning Approach for Screening Covid-19 based on  Urine Parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Moayedi%2C+B">Behzad Moayedi</a>, 
<a href="/search/eess?searchtype=author&query=Keramatfar%2C+A">Abdalsamad Keramatfar</a>, 
<a href="/search/eess?searchtype=author&query=Goldani%2C+M+H">Mohammad Hadi Goldani</a>, 
<a href="/search/eess?searchtype=author&query=Fallahi%2C+M+J">Mohammad Javad Fallahi</a>, 
<a href="/search/eess?searchtype=author&query=Jahangirisisakht%2C+A">Alborz Jahangirisisakht</a>, 
<a href="/search/eess?searchtype=author&query=Saboori%2C+M">Mohammad Saboori</a>, 
<a href="/search/eess?searchtype=author&query=badiei%2C+L">Leyla badiei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">The rapid spread of COVID-19 and the emergence of new variants underscore the
importance of effective screening measures. Rapid diagnosis and subsequent
quarantine of infected individuals can prevent further spread of the virus in
society. While PCR tests are the gold standard for COVID-19 diagnosis, they are
costly and time-consuming. In contrast, urine test strips are an inexpensive,
non-invasive, and rapidly obtainable screening method that can provide
important information about a patient's health status. In this study, we
collected a new dataset and used the RGB (Red Green Blue) color space of urine
test strips parameters to detect the health status of individuals. To improve
the accuracy of our model, we converted the RGB space to 10 additional color
spaces. After evaluating four different machine learning models, we proposed a
new ensemble model based on a multi-layer perceptron neural network. Although
the initial results were not strong, we were able to improve the model's
screening performance for COVID-19 by removing uncertain regions of the model
space. Ultimately, our model achieved a screening accuracy of 80% based on
urine parameters. Our results suggest that urine test strips can be a useful
tool for COVID-19 screening, particularly in resource-constrained settings
where PCR testing may not be feasible. Further research is needed to validate
our findings and explore the potential role of urine test strips in COVID-19
diagnosis and management.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01888" title="Abstract">arXiv:2311.01888</a> (cross-list from stat.ML) [<a href="/pdf/2311.01888" title="Download PDF">pdf</a>, <a href="/format/2311.01888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Sparse Codes with Entropy-Based ELBOs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Velychko%2C+D">Dmytro Velychko</a>, 
<a href="/search/stat?searchtype=author&query=Damm%2C+S">Simon Damm</a>, 
<a href="/search/stat?searchtype=author&query=Fischer%2C+A">Asja Fischer</a>, 
<a href="/search/stat?searchtype=author&query=L%C3%BCcke%2C+J">J&#xf6;rg L&#xfc;cke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Standard probabilistic sparse coding assumes a Laplace prior, a linear
mapping from latents to observables, and Gaussian observable distributions. We
here derive a solely entropy-based learning objective for the parameters of
standard sparse coding. The novel variational objective has the following
features: (A) unlike MAP approximations, it uses non-trivial posterior
approximations for probabilistic inference; (B) unlike for previous non-trivial
approximations, the novel objective is fully analytical; and (C) the objective
allows for a novel principled form of annealing. The objective is derived by
first showing that the standard ELBO objective converges to a sum of entropies,
which matches similar recent results for generative models with Gaussian
priors. The conditions under which the ELBO becomes equal to entropies are then
shown to have analytical solutions, which leads to the fully analytical
objective. Numerical experiments are used to demonstrate the feasibility of
learning with such entropy-based ELBOs. We investigate different posterior
approximations including Gaussians with correlated latents and deep amortized
approximations. Furthermore, we numerically investigate entropy-based annealing
which results in improved learning. Our main contributions are theoretical,
however, and they are twofold: (1) for non-trivial posterior approximations, we
provide the (to the knowledge of the authors) first analytical ELBO objective
for standard probabilistic sparse coding; and (2) we provide the first
demonstration on how a recently shown convergence of the ELBO to entropy sums
can be used for learning.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01894" title="Abstract">arXiv:2311.01894</a> (cross-list from eess.IV) [<a href="/pdf/2311.01894" title="Download PDF">pdf</a>, <a href="/ps/2311.01894" title="Download PostScript">ps</a>, <a href="/format/2311.01894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simulation of acquisition shifts in T2 Flair MR images to stress test AI  segmentation networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Posselt%2C+C">Christiane Posselt</a> (1), 
<a href="/search/eess?searchtype=author&query=Avci%2C+M+Y">Mehmet Yigit Avci</a> (2), 
<a href="/search/eess?searchtype=author&query=Yigitsoy%2C+M">Mehmet Yigitsoy</a> (2), 
<a href="/search/eess?searchtype=author&query=Sch%C3%BCnke%2C+P">Patrick Sch&#xfc;nke</a> (3), 
<a href="/search/eess?searchtype=author&query=Kolbitsch%2C+C">Christoph Kolbitsch</a> (3), 
<a href="/search/eess?searchtype=author&query=Sch%C3%A4ffter%2C+T">Tobias Sch&#xe4;ffter</a> (3 and 4), 
<a href="/search/eess?searchtype=author&query=Remmele%2C+S">Stefanie Remmele</a> (1) ((1) University of Applied Sciences, Faculty of Electrical and Industrial Engineering, Am Lurzenhof 1, Landshut, Germany, (2) deepc GmbH, Blumenstrasse 28, 80331 Munich, Germany, (3) Physikalisch Technische Bundesanstalt, Abbestrasse 2-12, 10587 Berlin, Germany, (4) Technical University of Berlin, Department of Medical Engineering, Dovestrasse 6, Berlin, Germany)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 10 figures The paper was submitted to SPIE Journal of Medical Imaging
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Purpose: To provide a simulation framework for routine neuroimaging test
data, which allows for "stress testing" of deep segmentation networks against
acquisition shifts that commonly occur in clinical practice for T2 weighted
(T2w) fluid attenuated inversion recovery (FLAIR) Magnetic Resonance Imaging
(MRI) protocols.
<br />Approach: The approach simulates "acquisition shift derivatives" of MR images
based on MR signal equations. Experiments comprise the validation of the
simulated images by real MR scans and example stress tests on state-of-the-art
MS lesion segmentation networks to explore a generic model function to describe
the F1 score in dependence of the contrast-affecting sequence parameters echo
time (TE) and inversion time (TI).
<br />Results: The differences between real and simulated images range up to 19 %
in gray and white matter for extreme parameter settings. For the segmentation
networks under test the F1 score dependency on TE and TI can be well described
by quadratic model functions (R^2 &gt; 0.9). The coefficients of the model
functions indicate that changes of TE have more influence on the model
performance than TI.
<br />Conclusions: We show that these deviations are in the range of values as may
be caused by erroneous or individual differences of relaxation times as
described by literature. The coefficients of the F1 model function allow for
quantitative comparison of the influences of TE and TI. Limitations arise
mainly from tissues with the low baseline signal (like CSF) and when the
protocol contains contrast-affecting measures that cannot be modelled due to
missing information in the DICOM header.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01900" title="Abstract">arXiv:2311.01900</a> (cross-list from stat.ML) [<a href="/pdf/2311.01900" title="Download PDF">pdf</a>, <a href="/format/2311.01900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online non-parametric likelihood-ratio estimation by Pearson-divergence  functional minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=de+la+Concha%2C+A">Alejandro de la Concha</a>, 
<a href="/search/stat?searchtype=author&query=Vayatis%2C+N">Nicolas Vayatis</a>, 
<a href="/search/stat?searchtype=author&query=Kalogeratos%2C+A">Argyris Kalogeratos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Quantifying the difference between two probability density functions, $p$ and
$q$, using available data, is a fundamental problem in Statistics and Machine
Learning. A usual approach for addressing this problem is the likelihood-ratio
estimation (LRE) between $p$ and $q$, which -- to our best knowledge -- has
been investigated mainly for the offline case. This paper contributes by
introducing a new framework for online non-parametric LRE (OLRE) for the
setting where pairs of iid observations $(x_t \sim p, x'_t \sim q)$ are
observed over time. The non-parametric nature of our approach has the advantage
of being agnostic to the forms of $p$ and $q$. Moreover, we capitalize on the
recent advances in Kernel Methods and functional minimization to develop an
estimator that can be efficiently updated online. We provide theoretical
guarantees for the performance of the OLRE method along with empirical
validation in synthetic experiments.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01908" title="Abstract">arXiv:2311.01908</a> (cross-list from eess.IV) [<a href="/pdf/2311.01908" title="Download PDF">pdf</a>, <a href="/format/2311.01908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM-driven Multimodal Target Volume Contouring in Radiation Oncology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Oh%2C+Y">Yujin Oh</a>, 
<a href="/search/eess?searchtype=author&query=Park%2C+S">Sangjoon Park</a>, 
<a href="/search/eess?searchtype=author&query=Byun%2C+H+K">Hwa Kyung Byun</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+J+S">Jin Sung Kim</a>, 
<a href="/search/eess?searchtype=author&query=Ye%2C+J+C">Jong Chul Ye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Target volume contouring for radiation therapy is considered significantly
more challenging than the normal organ segmentation tasks as it necessitates
the utilization of both image and text-based clinical information. Inspired by
the recent advancement of large language models (LLMs) that can facilitate the
integration of the textural information and images, here we present a novel
LLM-driven multi-modal AI that utilizes the clinical text information and is
applicable to the challenging task of target volume contouring for radiation
therapy, and validate it within the context of breast cancer radiation therapy
target volume contouring. Using external validation and data-insufficient
environments, which attributes highly conducive to real-world applications, we
demonstrate that the proposed model exhibits markedly improved performance
compared to conventional vision-only AI models, particularly exhibiting robust
generalization performance and data-efficiency. To our best knowledge, this is
the first LLM-driven multimodal AI model that integrates the clinical text
information into target volume delineation for radiation oncology.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01916" title="Abstract">arXiv:2311.01916</a> (cross-list from eess.IV) [<a href="/pdf/2311.01916" title="Download PDF">pdf</a>, <a href="/format/2311.01916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrast-Agnostic Groupwise Registration by Robust PCA for Quantitative  Cardiac MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xinqi Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+Y">Yidong Zhao</a>, 
<a href="/search/eess?searchtype=author&query=van+Gemert%2C+J">Jan van Gemert</a>, 
<a href="/search/eess?searchtype=author&query=Tao%2C+Q">Qian Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Quantitative cardiac magnetic resonance imaging (MRI) is an increasingly
important diagnostic tool for cardiovascular diseases. Yet, co-registration of
all baseline images within the quantitative MRI sequence is essential for the
accuracy and precision of quantitative maps. However, co-registering all
baseline images from a quantitative cardiac MRI sequence remains a nontrivial
task because of the simultaneous changes in intensity and contrast, in
combination with cardiac and respiratory motion. To address the challenge, we
propose a novel motion correction framework based on robust principle component
analysis (rPCA) that decomposes quantitative cardiac MRI into low-rank and
sparse components, and we integrate the groupwise CNN-based registration
backbone within the rPCA framework. The low-rank component of rPCA corresponds
to the quantitative mapping (i.e. limited degree of freedom in variation),
while the sparse component corresponds to the residual motion, making it easier
to formulate and solve the groupwise registration problem. We evaluated our
proposed method on cardiac T1 mapping by the modified Look-Locker inversion
recovery (MOLLI) sequence, both before and after the Gadolinium contrast agent
administration. Our experiments showed that our method effectively improved
registration performance over baseline methods without introducing rPCA, and
reduced quantitative mapping error in both in-domain (pre-contrast MOLLI) and
out-of-domain (post-contrast MOLLI) inference. The proposed rPCA framework is
generic and can be integrated with other registration backbones.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01940" title="Abstract">arXiv:2311.01940</a> (cross-list from math.CO) [<a href="/pdf/2311.01940" title="Download PDF">pdf</a>, <a href="/format/2311.01940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Balanced independent sets and colorings of hypergraphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dhawan%2C+A">Abhishek Dhawan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">A $k$-uniform hypergraph $H = (V, E)$ is $k$-partite if $V$ can be
partitioned into $k$ sets $V_1, \ldots, V_k$ such that every edge in $E$
contains precisely one vertex from each $V_i$. We call such a graph
$n$-balanced if $|V_i| = n$ for each $i$. An independent set $I$ in $H$ is
balanced if $|I\cap V_i| = |I|/k$ for each $i$, and a coloring is balanced if
each color class induces a balanced independent set in $H$. In this paper, we
provide a lower bound on the balanced independence number $\alpha_b(H)$ in
terms of the average degree $D = |E|/n$, and an upper bound on the balanced
chromatic number $\chi_b(H)$ in terms of the maximum degree $\Delta$. Our
results match those of recent work of Chakraborti for $k = 2$.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01945" title="Abstract">arXiv:2311.01945</a> (cross-list from math.CO) [<a href="/pdf/2311.01945" title="Download PDF">pdf</a>, <a href="/ps/2311.01945" title="Download PostScript">ps</a>, <a href="/format/2311.01945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Closure property of contraction-depth of matroids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Brianski%2C+M">Marcin Brianski</a>, 
<a href="/search/math?searchtype=author&query=Kral%2C+D">Daniel Kral</a>, 
<a href="/search/math?searchtype=author&query=Lamaison%2C+A">Ander Lamaison</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">The contraction$^*$-depth is the matroid depth parameter analogous to
tree-depth of graphs. We establish the matroid analogue of the classical graph
theory result asserting that the tree-depth of a graph $G$ is the minimum
height of a rooted forest whose closure contains $G$ by proving the following
for every matroid $M$ (except the trivial case when $M$ consists of loops and
bridges only): the contraction$^*$-depth of $M$ plus one is equal to the
minimum contraction-depth of a matroid containing $M$ as a restriction.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01947" title="Abstract">arXiv:2311.01947</a> (cross-list from math.CO) [<a href="/pdf/2311.01947" title="Download PDF">pdf</a>, <a href="/format/2311.01947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lengths of divisible codes -- the missing cases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kurz%2C+S">Sascha Kurz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">A linear code $C$ over $\mathbb{F}_q$ is called $\Delta$-divisible if the
Hamming weights $\operatorname{wt}(c)$ of all codewords $c \in C$ are divisible
by $\Delta$. The possible effective lengths of $q^r$-divisible codes have been
completely characterized for each prime power $q$ and each non-negative integer
$r$. The study of $\Delta$ divisible codes was initiated by Harold Ward. If $c$
divides $\Delta$ but is coprime to $q$, then each $\Delta$-divisible code $C$
over $\F_q$ is the $c$-fold repetition of a $\Delta/c$-divisible code. Here we
determine the possible effective lengths of $p^r$-divisible codes over finite
fields of characteristic $p$, where $p\in\mathbb{N}$ but $p^r$ is not a power
of the field size, i.e., the missing cases.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01957" title="Abstract">arXiv:2311.01957</a> (cross-list from math.OC) [<a href="/pdf/2311.01957" title="Download PDF">pdf</a>, <a href="/ps/2311.01957" title="Download PostScript">ps</a>, <a href="/format/2311.01957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Regret and Cumulative Constraint Violation Analysis for  Distributed Online Constrained Convex Optimization with Event-Triggered  Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+K">Kunpeng Zhang</a>, 
<a href="/search/math?searchtype=author&query=Yi%2C+X">Xinlei Yi</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+Y">Yuzhe Li</a>, 
<a href="/search/math?searchtype=author&query=Cao%2C+M">Ming Cao</a>, 
<a href="/search/math?searchtype=author&query=Chai%2C+T">Tianyou Chai</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+T">Tao Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">This paper focuses on the distributed online convex optimization problem with
time-varying inequality constraints over a network of agents, where each agent
collaborates with its neighboring agents to minimize the cumulative
network-wide loss over time. To reduce communication overhead between the
agents, we propose a distributed event-triggered online primal-dual algorithm
over a time-varying directed graph. Dynamic network regret and network
cumulative constraint violation are leveraged to measure the performance of the
algorithm. Based on the natural decreasing parameter sequences, we establish
sublinear dynamic network regret and network cumulative constraint violation
bounds. The theoretical results broaden the applicability of event-triggered
online convex optimization to the regime with inequality constraints. Finally,
a numerical simulation example is provided to verify the theoretical results.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01959" title="Abstract">arXiv:2311.01959</a> (cross-list from math.OC) [<a href="/pdf/2311.01959" title="Download PDF">pdf</a>, <a href="/ps/2311.01959" title="Download PostScript">ps</a>, <a href="/format/2311.01959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A First Order Method for Linear Programming Parameterized by Circuit  Imbalance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cole%2C+R">Richard Cole</a>, 
<a href="/search/math?searchtype=author&query=Hertrich%2C+C">Christoph Hertrich</a>, 
<a href="/search/math?searchtype=author&query=Tao%2C+Y">Yixin Tao</a>, 
<a href="/search/math?searchtype=author&query=V%C3%A9gh%2C+L+A">L&#xe1;szl&#xf3; A. V&#xe9;gh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Various first order approaches have been proposed in the literature to solve
Linear Programming (LP) problems, recently leading to practically efficient
solvers for large-scale LPs. From a theoretical perspective, linear convergence
rates have been established for first order LP algorithms, despite the fact
that the underlying formulations are not strongly convex. However, the
convergence rate typically depends on the Hoffman constant of a large matrix
that contains the constraint matrix, as well as the right hand side, cost, and
capacity vectors.
<br />We introduce a first order approach for LP optimization with a convergence
rate depending polynomially on the circuit imbalance measure, which is a
geometric parameter of the constraint matrix, and depending logarithmically on
the right hand side, capacity, and cost vectors. This provides much stronger
convergence guarantees. For example, if the constraint matrix is totally
unimodular, we obtain polynomial-time algorithms, whereas the convergence
guarantees for approaches based on primal-dual formulations may have
arbitrarily slow convergence rates for this class. Our approach is based on a
fast gradient method due to Necoara, Nesterov, and Glineur (Math. Prog. 2019);
this algorithm is called repeatedly in a framework that gradually fixes
variables to the boundary. This technique is based on a new approximate version
of Tardos's method, that was used to obtain a strongly polynomial algorithm for
combinatorial LPs (Oper. Res. 1986).
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01968" title="Abstract">arXiv:2311.01968</a> (cross-list from physics.geo-ph) [<a href="/pdf/2311.01968" title="Download PDF">pdf</a>, <a href="/format/2311.01968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Diffusion Model for Conditional Reservoir Facies Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Lee%2C+D">Daesoo Lee</a>, 
<a href="/search/physics?searchtype=author&query=Ovanger%2C+O">Oscar Ovanger</a>, 
<a href="/search/physics?searchtype=author&query=Eidsvik%2C+J">Jo Eidsvik</a>, 
<a href="/search/physics?searchtype=author&query=Aune%2C+E">Erlend Aune</a>, 
<a href="/search/physics?searchtype=author&query=Skauvold%2C+J">Jacob Skauvold</a>, 
<a href="/search/physics?searchtype=author&query=Hauge%2C+R">Ragnar Hauge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geophysics (physics.geo-ph)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Creating accurate and geologically realistic reservoir facies based on
limited measurements is crucial for field development and reservoir management,
especially in the oil and gas sector. Traditional two-point geostatistics,
while foundational, often struggle to capture complex geological patterns.
Multi-point statistics offers more flexibility, but comes with its own
challenges. With the rise of Generative Adversarial Networks (GANs) and their
success in various fields, there has been a shift towards using them for facies
generation. However, recent advances in the computer vision domain have shown
the superiority of diffusion models over GANs. Motivated by this, a novel
Latent Diffusion Model is proposed, which is specifically designed for
conditional generation of reservoir facies. The proposed model produces
high-fidelity facies realizations that rigorously preserve conditioning data.
It significantly outperforms a GAN-based alternative.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01994" title="Abstract">arXiv:2311.01994</a> (cross-list from stat.ML) [<a href="/pdf/2311.01994" title="Download PDF">pdf</a>, <a href="/format/2311.01994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Obtaining Explainable Classification Models using Distributionally  Robust Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Dash%2C+S">Sanjeeb Dash</a>, 
<a href="/search/stat?searchtype=author&query=Ghosh%2C+S">Soumyadip Ghosh</a>, 
<a href="/search/stat?searchtype=author&query=Goncalves%2C+J">Joao Goncalves</a>, 
<a href="/search/stat?searchtype=author&query=Squillante%2C+M+S">Mark S. Squillante</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">Model explainability is crucial for human users to be able to interpret how a
proposed classifier assigns labels to data based on its feature values. We
study generalized linear models constructed using sets of feature value rules,
which can capture nonlinear dependencies and interactions. An inherent
trade-off exists between rule set sparsity and its prediction accuracy. It is
computationally expensive to find the right choice of sparsity -- e.g., via
cross-validation -- with existing methods. We propose a new formulation to
learn an ensemble of rule sets that simultaneously addresses these competing
factors. Good generalization is ensured while keeping computational costs low
by utilizing distributionally robust optimization. The formulation utilizes
column generation to efficiently search the space of rule sets and constructs a
sparse ensemble of rule sets, in contrast with techniques like random forests
or boosting and their variants. We present theoretical results that motivate
and justify the use of our distributionally robust formulation. Extensive
numerical experiments establish that our method improves over competing methods
-- on a large set of publicly available binary classification problem instances
-- with respect to one or more of the following metrics: generalization
quality, computational cost, and explainability.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01996" title="Abstract">arXiv:2311.01996</a> (cross-list from eess.IV) [<a href="/pdf/2311.01996" title="Download PDF">pdf</a>, <a href="/ps/2311.01996" title="Download PostScript">ps</a>, <a href="/format/2311.01996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detection of keratoconus Diseases using deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Haque%2C+A+E">AKM Enzam-Ul Haque</a>, 
<a href="/search/eess?searchtype=author&query=Rabbany%2C+G">Golam Rabbany</a>, 
<a href="/search/eess?searchtype=author&query=Siam%2C+M">Md. Siam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">One of the most serious corneal disorders, keratoconus is difficult to
diagnose in its early stages and can result in blindness. This illness, which
often appears in the second decade of life, affects people of all sexes and
races. Convolutional neural networks (CNNs), one of the deep learning
approaches, have recently come to light as particularly promising tools for the
accurate and timely diagnosis of keratoconus. The purpose of this study was to
evaluate how well different D-CNN models identified keratoconus-related
diseases. To be more precise, we compared five different CNN-based deep
learning architectures (DenseNet201, InceptionV3, MobileNetV2, VGG19,
Xception). In our comprehensive experimental analysis, the DenseNet201-based
model performed very well in keratoconus disease identification in our
extensive experimental research. This model outperformed its D-CNN equivalents,
with an astounding accuracy rate of 89.14% in three crucial classes:
Keratoconus, Normal, and Suspect. The results demonstrate not only the
stability and robustness of the model but also its practical usefulness in
real-world applications for accurate and dependable keratoconus identification.
In addition, D-CNN DenseNet201 performs extraordinarily well in terms of
precision, recall rates, and F1 scores in addition to accuracy. These measures
validate the model's usefulness as an effective diagnostic tool by highlighting
its capacity to reliably detect instances of keratoconus and to reduce false
positives and negatives.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02000" title="Abstract">arXiv:2311.02000</a> (cross-list from math.OC) [<a href="/pdf/2311.02000" title="Download PDF">pdf</a>, <a href="/ps/2311.02000" title="Download PostScript">ps</a>, <a href="/format/2311.02000" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High Probability Convergence of Adam Under Unbounded Gradients and  Affine Variance Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hong%2C+Y">Yusu Hong</a>, 
<a href="/search/math?searchtype=author&query=Lin%2C+J">Junhong Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">In this paper, we study the convergence of the Adaptive Moment Estimation
(Adam) algorithm under unconstrained non-convex smooth stochastic
optimizations. Despite the widespread usage in machine learning areas, its
theoretical properties remain limited. Prior researches primarily investigated
Adam's convergence from an expectation view, often necessitating strong
assumptions like uniformly stochastic bounded gradients or problem-dependent
knowledge in prior. As a result, the applicability of these findings in
practical real-world scenarios has been constrained. To overcome these
limitations, we provide a deep analysis and show that Adam could converge to
the stationary point in high probability with a rate of $\mathcal{O}\left({\rm
poly}(\log T)/\sqrt{T}\right)$ under coordinate-wise "affine" variance noise,
not requiring any bounded gradient assumption and any problem-dependent
knowledge in prior to tune hyper-parameters. Additionally, it is revealed that
Adam confines its gradients' magnitudes within an order of
$\mathcal{O}\left({\rm poly}(\log T)\right)$. Finally, we also investigate a
simplified version of Adam without one of the corrective terms and obtain a
convergence rate that is adaptive to the noise level.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02002" title="Abstract">arXiv:2311.02002</a> (cross-list from math.OC) [<a href="/pdf/2311.02002" title="Download PDF">pdf</a>, <a href="/ps/2311.02002" title="Download PostScript">ps</a>, <a href="/format/2311.02002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Variational Perspective on High-Resolution ODEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Maskan%2C+H">Hoomaan Maskan</a>, 
<a href="/search/math?searchtype=author&query=Zygalakis%2C+K+C">Konstantinos C. Zygalakis</a>, 
<a href="/search/math?searchtype=author&query=Yurtsever%2C+A">Alp Yurtsever</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37th Annual Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
<p class="mathjax">We consider unconstrained minimization of smooth convex functions. We propose
a novel variational perspective using forced Euler-Lagrange equation that
allows for studying high-resolution ODEs. Through this, we obtain a faster
convergence rate for gradient norm minimization using Nesterov's accelerated
gradient method. Additionally, we show that Nesterov's method can be
interpreted as a rate-matching discretization of an appropriately chosen
high-resolution ODE. Finally, using the results from the new variational
perspective, we propose a stochastic method for noisy gradients. Several
numerical experiments compare and illustrate our stochastic algorithm with
state of the art methods.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02003" title="Abstract">arXiv:2311.02003</a> (cross-list from eess.IV) [<a href="/pdf/2311.02003" title="Download PDF">pdf</a>, <a href="/format/2311.02003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Structured Pruning Algorithm for Model-based Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Park%2C+C">Chicago Park</a>, 
<a href="/search/eess?searchtype=author&query=Gan%2C+W">Weijie Gan</a>, 
<a href="/search/eess?searchtype=author&query=Zou%2C+Z">Zihao Zou</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+Y">Yuyang Hu</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+Z">Zhixin Sun</a>, 
<a href="/search/eess?searchtype=author&query=Kamilov%2C+U+S">Ulugbek S. Kamilov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">There is a growing interest in model-based deep learning (MBDL) for solving
imaging inverse problems. MBDL networks can be seen as iterative algorithms
that estimate the desired image using a physical measurement model and a
learned image prior specified using a convolutional neural net (CNNs). The
iterative nature of MBDL networks increases the test-time computational
complexity, which limits their applicability in certain large-scale
applications. We address this issue by presenting structured pruning algorithm
for model-based deep learning (SPADE) as the first structured pruning algorithm
for MBDL networks. SPADE reduces the computational complexity of CNNs used
within MBDL networks by pruning its non-essential weights. We propose three
distinct strategies to fine-tune the pruned MBDL networks to minimize the
performance loss. Each fine-tuning strategy has a unique benefit that depends
on the presence of a pre-trained model and a high-quality ground truth. We
validate SPADE on two distinct inverse problems, namely compressed sensing MRI
and image super-resolution. Our results highlight that MBDL models pruned by
SPADE can achieve substantial speed up in testing time while maintaining
competitive performance.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02019" title="Abstract">arXiv:2311.02019</a> (cross-list from stat.ME) [<a href="/pdf/2311.02019" title="Download PDF">pdf</a>, <a href="/format/2311.02019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reproducible Parameter Inference Using Bagged Posteriors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Huggins%2C+J+H">Jonathan H. Huggins</a>, 
<a href="/search/stat?searchtype=author&query=Miller%2C+J+W">Jeffrey W. Miller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/1912.07104">arXiv:1912.07104</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
<p class="mathjax">Under model misspecification, it is known that Bayesian posteriors often do
not properly quantify uncertainty about true or pseudo-true parameters. Even
more fundamentally, misspecification leads to a lack of reproducibility in the
sense that the same model will yield contradictory posteriors on independent
data sets from the true distribution. To define a criterion for reproducible
uncertainty quantification under misspecification, we consider the probability
that two confidence sets constructed from independent data sets have nonempty
overlap, and we establish a lower bound on this overlap probability that holds
for any valid confidence sets. We prove that credible sets from the standard
posterior can strongly violate this bound, particularly in high-dimensional
settings (i.e., with dimension increasing with sample size), indicating that it
is not internally coherent under misspecification. To improve reproducibility
in an easy-to-use and widely applicable way, we propose to apply bagging to the
Bayesian posterior ("BayesBag"'); that is, to use the average of posterior
distributions conditioned on bootstrapped datasets. We motivate BayesBag from
first principles based on Jeffrey conditionalization and show that the bagged
posterior typically satisfies the overlap lower bound. Further, we prove a
Bernstein--Von Mises theorem for the bagged posterior, establishing its
asymptotic normal distribution. We demonstrate the benefits of BayesBag via
simulation experiments and an application to crime rate prediction.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02029" title="Abstract">arXiv:2311.02029</a> (cross-list from q-bio.GN) [<a href="/pdf/2311.02029" title="Download PDF">pdf</a>, <a href="/ps/2311.02029" title="Download PostScript">ps</a>, <a href="/format/2311.02029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MetaFast: Enabling Fast Metagenomic Classification via Seed Counting and  Edit Distance Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Gollwitzer%2C+A+E">Arvid E. Gollwitzer</a>, 
<a href="/search/q-bio?searchtype=author&query=Alser%2C+M">Mohammed Alser</a>, 
<a href="/search/q-bio?searchtype=author&query=Bergtholdt%2C+J">Joel Bergtholdt</a>, 
<a href="/search/q-bio?searchtype=author&query=Lindegger%2C+J">Joel Lindegger</a>, 
<a href="/search/q-bio?searchtype=author&query=Rumpf%2C+M">Maximilian-David Rumpf</a>, 
<a href="/search/q-bio?searchtype=author&query=Firtina%2C+C">Can Firtina</a>, 
<a href="/search/q-bio?searchtype=author&query=Mangul%2C+S">Serghei Mangul</a>, 
<a href="/search/q-bio?searchtype=author&query=Mutlu%2C+O">Onur Mutlu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Hardware Architecture (cs.AR); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Metagenomics, the study of genome sequences of diverse organisms cohabiting
in a shared environment, has experienced significant advancements across
various medical and biological fields. Metagenomic analysis is crucial, for
instance, in clinical applications such as infectious disease screening and the
diagnosis and early detection of diseases such as cancer. A key task in
metagenomics is to determine the species present in a sample and their relative
abundances. Currently, the field is dominated by either alignment-based tools,
which offer high accuracy but are computationally expensive, or alignment-free
tools, which are fast but lack the needed accuracy for many applications. In
response to this dichotomy, we introduce MetaFast, a tool based on heuristics,
to achieve a fundamental improvement in accuracy-runtime tradeoff over existing
methods. MetaFast delivers accuracy comparable to the alignment-based and
highly accurate tool Metalign but with significantly enhanced efficiency. In
MetaFast, we accelerate memory-frugal reference database indexing and
filtering. We further employ heuristics to accelerate read mapping. Our
evaluation demonstrates that MetaFast achieves a 4x speedup over Metalign
without compromising accuracy. MetaFast is publicly available on:
https://github.com/CMU-SAFARI/MetaFast.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02037" title="Abstract">arXiv:2311.02037</a> (cross-list from math.OC) [<a href="/pdf/2311.02037" title="Download PDF">pdf</a>, <a href="/format/2311.02037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Efficient Framework for Global Non-Convex Polynomial Optimization  with Nonlinear Polynomial Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Harris%2C+M+T">Mitchell Tong Harris</a>, 
<a href="/search/math?searchtype=author&query=Letourneau%2C+P">Pierre-David Letourneau</a>, 
<a href="/search/math?searchtype=author&query=Jones%2C+D">Dalton Jones</a>, 
<a href="/search/math?searchtype=author&query=Langston%2C+M+H">M. Harper Langston</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Mathematical Software (cs.MS); Numerical Analysis (math.NA)

</div>
<p class="mathjax">We present an efficient framework for solving constrained global non-convex
polynomial optimization problems. We prove the existence of an equivalent
nonlinear reformulation of such problems that possesses essentially no spurious
local minima. We show through numerical experiments that polynomial scaling in
dimension and degree is achievable for computing the optimal value and location
of previously intractable global constrained polynomial optimization problems
in high dimension.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02041" title="Abstract">arXiv:2311.02041</a> (cross-list from quant-ph) [<a href="/pdf/2311.02041" title="Download PDF">pdf</a>, <a href="/format/2311.02041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum circuit synthesis with diffusion models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=F%C3%BCrrutter%2C+F">Florian F&#xfc;rrutter</a>, 
<a href="/search/quant-ph?searchtype=author&query=Mu%C3%B1oz-Gil%2C+G">Gorka Mu&#xf1;oz-Gil</a>, 
<a href="/search/quant-ph?searchtype=author&query=Briegel%2C+H+J">Hans J. Briegel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Main Text: 6 pages and 4 figures; Appendix: 6 pages, 4 figures and 3 tables. Code available at: <a href="https://github.com/FlorianFuerrutter/genQC">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Quantum computing has recently emerged as a transformative technology. Yet,
its promised advantages rely on efficiently translating quantum operations into
viable physical realizations. In this work, we use generative machine learning
models, specifically denoising diffusion models (DMs), to facilitate this
transformation. Leveraging text-conditioning, we steer the model to produce
desired quantum operations within gate-based quantum circuits. Notably, DMs
allow to sidestep during training the exponential overhead inherent in the
classical simulation of quantum dynamics -- a consistent bottleneck in
preceding ML techniques. We demonstrate the model's capabilities across two
tasks: entanglement generation and unitary compilation. The model excels at
generating new circuits and supports typical DM extensions such as masking and
editing to, for instance, align the circuit generation to the constraints of
the targeted quantum device. Given their flexibility and generalization
abilities, we envision DMs as pivotal in quantum circuit synthesis, enhancing
both practical applications but also insights into theoretical quantum
computation.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Mon,  6 Nov 23</h3>
<dl>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1807.00404" title="Abstract">arXiv:1807.00404</a> (replaced) [<a href="/pdf/1807.00404" title="Download PDF">pdf</a>, <a href="/format/1807.00404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Worst-case iteration bounds for log barrier methods on problems with  nonconvex constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hinder%2C+O">Oliver Hinder</a>, 
<a href="/search/math?searchtype=author&query=Ye%2C+Y">Yinyu Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in Mathematics of Operations Research. Note that several results were removed from the previous version most notably the results on convex case. These results were removed due to reviewer suggestions to focus the paper on the most significant contributions. These results still appear in the first author's PhD thesis (Principled Algorithms for Finding Local Minima)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2007.04750" title="Abstract">arXiv:2007.04750</a> (replaced) [<a href="/pdf/2007.04750" title="Download PDF">pdf</a>, <a href="/format/2007.04750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recurrent Neural-Linear Posterior Sampling for Nonstationary Contextual  Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramesh%2C+A">Aditya Ramesh</a>, 
<a href="/search/cs?searchtype=author&query=Rauber%2C+P">Paulo Rauber</a>, 
<a href="/search/cs?searchtype=author&query=Conserva%2C+M">Michelangelo Conserva</a>, 
<a href="/search/cs?searchtype=author&query=Schmidhuber%2C+J">J&#xfc;rgen Schmidhuber</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Neural Computation. 2022 Oct 7;34(11):2232-72
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2007.10629" title="Abstract">arXiv:2007.10629</a> (replaced) [<a href="/pdf/2007.10629" title="Download PDF">pdf</a>, <a href="/ps/2007.10629" title="Download PostScript">ps</a>, <a href="/format/2007.10629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CSLNSpeech: solving extended speech separation problem with the help of  Chinese sign language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wu%2C+J">Jiasong Wu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xuan Li</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+T">Taotao Li</a>, 
<a href="/search/eess?searchtype=author&query=Meng%2C+F">Fanman Meng</a>, 
<a href="/search/eess?searchtype=author&query=Kong%2C+Y">Youyong Kong</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+G">Guanyu Yang</a>, 
<a href="/search/eess?searchtype=author&query=Senhadji%2C+L">Lotfi Senhadji</a>, 
<a href="/search/eess?searchtype=author&query=Shu%2C+H">Huazhong Shu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computer Vision and Pattern Recognition (cs.CV); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2010.08627" title="Abstract">arXiv:2010.08627</a> (replaced) [<a href="/pdf/2010.08627" title="Download PDF">pdf</a>, <a href="/format/2010.08627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimax Quasi-Bayesian estimation in sparse canonical correlation  analysis via a Rayleigh quotient function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhu%2C+Q">Qiuyun Zhu</a>, 
<a href="/search/stat?searchtype=author&query=Atchade%2C+Y">Yves Atchade</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Computation (stat.CO); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2010.09858" title="Abstract">arXiv:2010.09858</a> (replaced) [<a href="/pdf/2010.09858" title="Download PDF">pdf</a>, <a href="/format/2010.09858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vehicular Visible Light Positioning for Collision Avoidance and  Platooning: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Soner%2C+B">Burak Soner</a>, 
<a href="/search/eess?searchtype=author&query=Karakas%2C+M">Merve Karakas</a>, 
<a href="/search/eess?searchtype=author&query=Noyan%2C+U">Utku Noyan</a>, 
<a href="/search/eess?searchtype=author&query=Sahbaz%2C+F">Furkan Sahbaz</a>, 
<a href="/search/eess?searchtype=author&query=Coleri%2C+S">Sinem Coleri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.12915" title="Abstract">arXiv:2106.12915</a> (replaced) [<a href="/pdf/2106.12915" title="Download PDF">pdf</a>, <a href="/format/2106.12915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical influence of ReLU&#x27;(0) on backpropagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bertoin%2C+D">David Bertoin</a> (ISAE-SUPAERO), 
<a href="/search/cs?searchtype=author&query=Bolte%2C+J">J&#xe9;r&#xf4;me Bolte</a> (TSE-R), 
<a href="/search/cs?searchtype=author&query=Gerchinovitz%2C+S">S&#xe9;bastien Gerchinovitz</a> (IMT), 
<a href="/search/cs?searchtype=author&query=Pauwels%2C+E">Edouard Pauwels</a> (IRIT-ADRIA)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Advances in Neural Information Processing Systems, Dec 2021,
  Paris, France
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.08452" title="Abstract">arXiv:2111.08452</a> (replaced) [<a href="/pdf/2111.08452" title="Download PDF">pdf</a>, <a href="/format/2111.08452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On minimizers and convolutional filters: theoretical connections and  applications to genome analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y+W">Yun William Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures, submitted to a conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Genomics (q-bio.GN)

</div>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.08369" title="Abstract">arXiv:2112.08369</a> (replaced) [<a href="/pdf/2112.08369" title="Download PDF">pdf</a>, <a href="/format/2112.08369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature-Attending Recurrent Modules for Generalization in Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carvalho%2C+W">Wilka Carvalho</a>, 
<a href="/search/cs?searchtype=author&query=Lampinen%2C+A">Andrew Lampinen</a>, 
<a href="/search/cs?searchtype=author&query=Nikiforou%2C+K">Kyriacos Nikiforou</a>, 
<a href="/search/cs?searchtype=author&query=Hill%2C+F">Felix Hill</a>, 
<a href="/search/cs?searchtype=author&query=Shanahan%2C+M">Murray Shanahan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> TMLR, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.09698" title="Abstract">arXiv:2201.09698</a> (replaced) [<a href="/pdf/2201.09698" title="Download PDF">pdf</a>, <a href="/format/2201.09698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Neural Diffusion Networks for Semi-supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+W">Wei Ye</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zexi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+Y">Yunqi Hong</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Ambuj Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.00282" title="Abstract">arXiv:2202.00282</a> (replaced) [<a href="/pdf/2202.00282" title="Download PDF">pdf</a>, <a href="/format/2202.00282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stabilizing the LIF Neuron Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Herranz-Celotti%2C+L">Luca Herranz-Celotti</a>, 
<a href="/search/cs?searchtype=author&query=Rouat%2C+J">Jean Rouat</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.16748" title="Abstract">arXiv:2203.16748</a> (replaced) [<a href="/pdf/2203.16748" title="Download PDF">pdf</a>, <a href="/format/2203.16748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topological Optimization with Big Steps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nigmetov%2C+A">Arnur Nigmetov</a>, 
<a href="/search/cs?searchtype=author&query=Morozov%2C+D">Dmitriy Morozov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 29 figures. Updated version (section on consistency of critical sets, more experiments) accepted to DCG
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Algebraic Topology (math.AT); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.00763" title="Abstract">arXiv:2204.00763</a> (replaced) [<a href="/pdf/2204.00763" title="Download PDF">pdf</a>, <a href="/format/2204.00763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Metaphorical User Simulators for Evaluating Task-oriented Dialogue  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weiwei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Shuyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+P">Pengjie Ren</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhumin Chen</a>, 
<a href="/search/cs?searchtype=author&query=de+Rijke%2C+M">Maarten de Rijke</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zhaochun Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.03148" title="Abstract">arXiv:2205.03148</a> (replaced) [<a href="/pdf/2205.03148" title="Download PDF">pdf</a>, <a href="/format/2205.03148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A relativistic discrete spacetime formulation of 3+1 QED
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Eon%2C+N">Nathana&#xeb;l Eon</a>, 
<a href="/search/quant-ph?searchtype=author&query=Di+Molfetta%2C+G">Giuseppe Di Molfetta</a>, 
<a href="/search/quant-ph?searchtype=author&query=Magnifico%2C+G">Giuseppe Magnifico</a>, 
<a href="/search/quant-ph?searchtype=author&query=Arrighi%2C+P">Pablo Arrighi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 8 figures. V2: typos corrected, precisions added. V3: changed license, added ref doi
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Formal Languages and Automata Theory (cs.FL); Cellular Automata and Lattice Gases (nlin.CG)

</div>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.01466" title="Abstract">arXiv:2206.01466</a> (replaced) [<a href="/pdf/2206.01466" title="Download PDF">pdf</a>, <a href="/format/2206.01466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recognition of Unseen Bird Species by Learning from Field Guides
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rodr%C3%ADguez%2C+A+C">Andr&#xe9;s C. Rodr&#xed;guez</a>, 
<a href="/search/cs?searchtype=author&query=D%27Aronco%2C+S">Stefano D&#x27;Aronco</a>, 
<a href="/search/cs?searchtype=author&query=Daudt%2C+R+C">Rodrigo Caye Daudt</a>, 
<a href="/search/cs?searchtype=author&query=Wegner%2C+J+D">Jan D. Wegner</a>, 
<a href="/search/cs?searchtype=author&query=Schindler%2C+K">Konrad Schindler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WACV2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.09090" title="Abstract">arXiv:2206.09090</a> (replaced) [<a href="/pdf/2206.09090" title="Download PDF">pdf</a>, <a href="/ps/2206.09090" title="Download PostScript">ps</a>, <a href="/format/2206.09090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Understanding Genetic Drift to a Smart-Restart Mechanism for  Estimation-of-Distribution Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Weijie Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Doerr%2C+B">Benjamin Doerr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of our GECCO 2020 paper. This article supersedes <a href="/abs/2004.07141">arXiv:2004.07141</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Machine Learning Research 24 (2023) 1-40
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.14360" title="Abstract">arXiv:2206.14360</a> (replaced) [<a href="/pdf/2206.14360" title="Download PDF">pdf</a>, <a href="/ps/2206.14360" title="Download PostScript">ps</a>, <a href="/format/2206.14360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stability Analysis for Stochastic Hybrid Inclusions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+D">Dandan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Su%2C+H">Hongye Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 3 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.02205" title="Abstract">arXiv:2207.02205</a> (replaced) [<a href="/pdf/2207.02205" title="Download PDF">pdf</a>, <a href="/format/2207.02205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clustered Saliency Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sherkati%2C+R">Rezvan Sherkati</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+J+J">James J. Clark</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, BMVC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.03028" title="Abstract">arXiv:2209.03028</a> (replaced) [<a href="/pdf/2209.03028" title="Download PDF">pdf</a>, <a href="/format/2209.03028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian learning of feature spaces for multitasks problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Sevilla-Salcedo%2C+C">Carlos Sevilla-Salcedo</a>, 
<a href="/search/stat?searchtype=author&query=Gallardo-Antol%C3%ADn%2C+A">Ascensi&#xf3;n Gallardo-Antol&#xed;n</a>, 
<a href="/search/stat?searchtype=author&query=G%C3%B3mez-Verdejo%2C+V">Vanessa G&#xf3;mez-Verdejo</a>, 
<a href="/search/stat?searchtype=author&query=Parrado-Hern%C3%A1ndez%2C+E">Emilio Parrado-Hern&#xe1;ndez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.06177" title="Abstract">arXiv:2209.06177</a> (replaced) [<a href="/pdf/2209.06177" title="Download PDF">pdf</a>, <a href="/format/2209.06177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizing Graph Datasets for Node Classification:  Homophily-Heterophily Dichotomy and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Platonov%2C+O">Oleg Platonov</a>, 
<a href="/search/cs?searchtype=author&query=Kuznedelev%2C+D">Denis Kuznedelev</a>, 
<a href="/search/cs?searchtype=author&query=Babenko%2C+A">Artem Babenko</a>, 
<a href="/search/cs?searchtype=author&query=Prokhorenkova%2C+L">Liudmila Prokhorenkova</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Discrete Mathematics (cs.DM); Machine Learning (cs.LG); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.07550" title="Abstract">arXiv:2210.07550</a> (replaced) [<a href="/pdf/2210.07550" title="Download PDF">pdf</a>, <a href="/ps/2210.07550" title="Download PostScript">ps</a>, <a href="/format/2210.07550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Codes on Subgroups of Weighted Projective Tori
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=%C5%9Eahin%2C+M">Mesut &#x15e;ahin</a>, 
<a href="/search/math?searchtype=author&query=Yayla%2C+O">O&#x11f;uz Yayla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> supported by TUBITAK Project No:119F177
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Geometry (math.AG)</span>; Information Theory (cs.IT); Commutative Algebra (math.AC); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.16106" title="Abstract">arXiv:2210.16106</a> (replaced) [<a href="/pdf/2210.16106" title="Download PDF">pdf</a>, <a href="/format/2210.16106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motion Planning using Reactive Circular Fields: A 2D Analysis of  Collision Avoidance and Goal Convergence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Becker%2C+M">Marvin Becker</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6hler%2C+J">Johannes K&#xf6;hler</a>, 
<a href="/search/cs?searchtype=author&query=Haddadin%2C+S">Sami Haddadin</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+M+A">Matthias A. M&#xfc;ller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in IEEE Transactions on Automatic Control (Early Access)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.17514" title="Abstract">arXiv:2210.17514</a> (replaced) [<a href="/pdf/2210.17514" title="Download PDF">pdf</a>, <a href="/format/2210.17514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cost-aware Generalized $&#x3b1;$-investing for Multiple Hypothesis  Testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cook%2C+T">Thomas Cook</a>, 
<a href="/search/cs?searchtype=author&query=Dubey%2C+H+V">Harsh Vardhan Dubey</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+A">Ji Ah Lee</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+G">Guangyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tingting Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Flaherty%2C+P">Patrick Flaherty</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 5 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.04399" title="Abstract">arXiv:2211.04399</a> (replaced) [<a href="/pdf/2211.04399" title="Download PDF">pdf</a>, <a href="/format/2211.04399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stability estimates for the expected utility in Bayesian optimal  experimental design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Duong%2C+D">Duc-Lam Duong</a>, 
<a href="/search/math?searchtype=author&query=Helin%2C+T">Tapio Helin</a>, 
<a href="/search/math?searchtype=author&query=Rojo-Garcia%2C+J+R">Jose Rodrigo Rojo-Garcia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages; 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.06319" title="Abstract">arXiv:2211.06319</a> (replaced) [<a href="/pdf/2211.06319" title="Download PDF">pdf</a>, <a href="/ps/2211.06319" title="Download PostScript">ps</a>, <a href="/format/2211.06319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Young and the Old, the Fast and the Slow: A Large-Scale Study of  Productivity Classes and Rank Advancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kwiek%2C+M">Marek Kwiek</a>, 
<a href="/search/cs?searchtype=author&query=Roszka%2C+W">Wojciech Roszka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 13 tables, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Digital Libraries (cs.DL)

</div>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.07596" title="Abstract">arXiv:2211.07596</a> (replaced) [<a href="/pdf/2211.07596" title="Download PDF">pdf</a>, <a href="/format/2211.07596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Abstractive Timeline Summarisation using Preference-based  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yuxuan Ye</a>, 
<a href="/search/cs?searchtype=author&query=Simpson%2C+E">Edwin Simpson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ECAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08761" title="Abstract">arXiv:2211.08761</a> (replaced) [<a href="/pdf/2211.08761" title="Download PDF">pdf</a>, <a href="/format/2211.08761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Separable PINN: Mitigating the Curse of Dimensionality in  Physics-Informed Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cho%2C+J">Junwoo Cho</a>, 
<a href="/search/cs?searchtype=author&query=Nam%2C+S">Seungtae Nam</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hyunmo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+S">Seok-Bae Yun</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+Y">Youngjoon Hong</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+E">Eunbyung Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in NeurIPS 2022 Workshop on The Symbiosis of Deep Learning and Differential Equations (DLDE) - II, 12 pages, 5 figures, full paper: <a href="/abs/2306.15969">arXiv:2306.15969</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.09580" title="Abstract">arXiv:2211.09580</a> (replaced) [<a href="/pdf/2211.09580" title="Download PDF">pdf</a>, <a href="/format/2211.09580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quadrupole Magnet Design based on Genetic Multi-Objective Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Diehl%2C+E">Eric Diehl</a>, 
<a href="/search/physics?searchtype=author&query=von+Tresckow%2C+M">Moritz von Tresckow</a>, 
<a href="/search/physics?searchtype=author&query=Scholtissek%2C+L">Lou Scholtissek</a>, 
<a href="/search/physics?searchtype=author&query=Loukrezis%2C+D">Dimitrios Loukrezis</a>, 
<a href="/search/physics?searchtype=author&query=Marsic%2C+N">Nicolas Marsic</a>, 
<a href="/search/physics?searchtype=author&query=M%C3%BCller%2C+W+F+O">Wolfgang F. O. M&#xfc;ller</a>, 
<a href="/search/physics?searchtype=author&query=De+Gersem%2C+H">Herbert De Gersem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Accelerator Physics (physics.acc-ph)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.11130" title="Abstract">arXiv:2211.11130</a> (replaced) [<a href="/pdf/2211.11130" title="Download PDF">pdf</a>, <a href="/ps/2211.11130" title="Download PostScript">ps</a>, <a href="/format/2211.11130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Stabilization for Stochastic Time-Delay Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pan%2C+Z">Zhuo-Rui Pan</a>, 
<a href="/search/eess?searchtype=author&query=Ren%2C+W">Wei Ren</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+X">Xi-Ming Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures. Accepted by IEEE TAC as a Technical Note. arXiv admin note: text overlap with <a href="/abs/2204.12106">arXiv:2204.12106</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.11961" title="Abstract">arXiv:2211.11961</a> (replaced) [<a href="/pdf/2211.11961" title="Download PDF">pdf</a>, <a href="/ps/2211.11961" title="Download PostScript">ps</a>, <a href="/format/2211.11961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online facility location with weights and congestion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+A">Arghya Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Vaze%2C+R">Rahul Vaze</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.04873" title="Abstract">arXiv:2212.04873</a> (replaced) [<a href="/pdf/2212.04873" title="Download PDF">pdf</a>, <a href="/format/2212.04873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Prototype-Enhanced Network for Few-Shot Action Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ni%2C+X">Xinzhe Ni</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+H">Hao Wen</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Y">Yatai Ji</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jing Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yujiu Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.07738" title="Abstract">arXiv:2212.07738</a> (replaced) [<a href="/pdf/2212.07738" title="Download PDF">pdf</a>, <a href="/ps/2212.07738" title="Download PostScript">ps</a>, <a href="/format/2212.07738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A large-scale and PCR-referenced vocal audio dataset for COVID-19
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Budd%2C+J">Jobie Budd</a>, 
<a href="/search/cs?searchtype=author&query=Baker%2C+K">Kieran Baker</a>, 
<a href="/search/cs?searchtype=author&query=Karoune%2C+E">Emma Karoune</a>, 
<a href="/search/cs?searchtype=author&query=Coppock%2C+H">Harry Coppock</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+S">Selina Patel</a>, 
<a href="/search/cs?searchtype=author&query=Ca%C3%B1adas%2C+A+T">Ana Tendero Ca&#xf1;adas</a>, 
<a href="/search/cs?searchtype=author&query=Titcomb%2C+A">Alexander Titcomb</a>, 
<a href="/search/cs?searchtype=author&query=Payne%2C+R">Richard Payne</a>, 
<a href="/search/cs?searchtype=author&query=Hurley%2C+D">David Hurley</a>, 
<a href="/search/cs?searchtype=author&query=Egglestone%2C+S">Sabrina Egglestone</a>, 
<a href="/search/cs?searchtype=author&query=Butler%2C+L">Lorraine Butler</a>, 
<a href="/search/cs?searchtype=author&query=Mellor%2C+J">Jonathon Mellor</a>, 
<a href="/search/cs?searchtype=author&query=Nicholson%2C+G">George Nicholson</a>, 
<a href="/search/cs?searchtype=author&query=Kiskin%2C+I">Ivan Kiskin</a>, 
<a href="/search/cs?searchtype=author&query=Koutra%2C+V">Vasiliki Koutra</a>, 
<a href="/search/cs?searchtype=author&query=Jersakova%2C+R">Radka Jersakova</a>, 
<a href="/search/cs?searchtype=author&query=McKendry%2C+R+A">Rachel A. McKendry</a>, 
<a href="/search/cs?searchtype=author&query=Diggle%2C+P">Peter Diggle</a>, 
<a href="/search/cs?searchtype=author&query=Richardson%2C+S">Sylvia Richardson</a>, 
<a href="/search/cs?searchtype=author&query=Schuller%2C+B+W">Bj&#xf6;rn W. Schuller</a>, 
<a href="/search/cs?searchtype=author&query=Gilmour%2C+S">Steven Gilmour</a>, 
<a href="/search/cs?searchtype=author&query=Pigoli%2C+D">Davide Pigoli</a>, 
<a href="/search/cs?searchtype=author&query=Roberts%2C+S">Stephen Roberts</a>, 
<a href="/search/cs?searchtype=author&query=Packham%2C+J">Josef Packham</a>, 
<a href="/search/cs?searchtype=author&query=Thornley%2C+T">Tracey Thornley</a>, 
<a href="/search/cs?searchtype=author&query=Holmes%2C+C">Chris Holmes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.09146" title="Abstract">arXiv:2212.09146</a> (replaced) [<a href="/pdf/2212.09146" title="Download PDF">pdf</a>, <a href="/format/2212.09146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Retriever-Augmented Language Models Reason? The Blame Game Between  the Retriever and the Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=BehnamGhader%2C+P">Parishad BehnamGhader</a>, 
<a href="/search/cs?searchtype=author&query=Miret%2C+S">Santiago Miret</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+S">Siva Reddy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in EMNLP2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.00823" title="Abstract">arXiv:2301.00823</a> (replaced) [<a href="/pdf/2301.00823" title="Download PDF">pdf</a>, <a href="/format/2301.00823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bringing data minimization to digital wallets at scale with  general-purpose zero-knowledge proofs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Babel%2C+M">Matthias Babel</a>, 
<a href="/search/cs?searchtype=author&query=Sedlmeir%2C+J">Johannes Sedlmeir</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.01182" title="Abstract">arXiv:2301.01182</a> (replaced) [<a href="/pdf/2301.01182" title="Download PDF">pdf</a>, <a href="/format/2301.01182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PMT-IQA: Progressive Multi-task Learning for Blind Image Quality  Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pan%2C+Q">Qingyi Pan</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+N">Ning Guo</a>, 
<a href="/search/eess?searchtype=author&query=Qingge%2C+L">Letu Qingge</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jingyi Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+P">Pei Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.05062" title="Abstract">arXiv:2301.05062</a> (replaced) [<a href="/pdf/2301.05062" title="Download PDF">pdf</a>, <a href="/format/2301.05062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tracr: Compiled Transformers as a Laboratory for Interpretability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lindner%2C+D">David Lindner</a>, 
<a href="/search/cs?searchtype=author&query=Kram%C3%A1r%2C+J">J&#xe1;nos Kram&#xe1;r</a>, 
<a href="/search/cs?searchtype=author&query=Farquhar%2C+S">Sebastian Farquhar</a>, 
<a href="/search/cs?searchtype=author&query=Rahtz%2C+M">Matthew Rahtz</a>, 
<a href="/search/cs?searchtype=author&query=McGrath%2C+T">Thomas McGrath</a>, 
<a href="/search/cs?searchtype=author&query=Mikulik%2C+V">Vladimir Mikulik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at NeurIPS 2023 (Spotlight)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.08880" title="Abstract">arXiv:2301.08880</a> (replaced) [<a href="/pdf/2301.08880" title="Download PDF">pdf</a>, <a href="/format/2301.08880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Large-scale Film Style Dataset for Learning Multi-frequency Driven  Film Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zinuo Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuhang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pun%2C+C">Chi-Man Pun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by International Joint Conference on Artificial Intelligence (IJCAI 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10097" title="Abstract">arXiv:2301.10097</a> (replaced) [<a href="/pdf/2301.10097" title="Download PDF">pdf</a>, <a href="/format/2301.10097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Canonical momentum based numerical schemes for hybrid plasma models with  kinetic ions and massless electrons
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+Y">Yingzhe Li</a>, 
<a href="/search/math?searchtype=author&query=Holderied%2C+F">Florian Holderied</a>, 
<a href="/search/math?searchtype=author&query=Possanner%2C+S">Stefan Possanner</a>, 
<a href="/search/math?searchtype=author&query=Sonnendr%C3%BCcker%2C+E">Eric Sonnendr&#xfc;cker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Plasma Physics (physics.plasm-ph)

</div>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10625" title="Abstract">arXiv:2301.10625</a> (replaced) [<a href="/pdf/2301.10625" title="Download PDF">pdf</a>, <a href="/format/2301.10625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigating the Pitfalls of Active Learning Evaluation: A Systematic  Framework for Meaningful Performance Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=L%C3%BCth%2C+C+T">Carsten T. L&#xfc;th</a>, 
<a href="/search/cs?searchtype=author&query=Bungert%2C+T+J">Till J. Bungert</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+L">Lukas Klein</a>, 
<a href="/search/cs?searchtype=author&query=Jaeger%2C+P+F">Paul F. Jaeger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11657" title="Abstract">arXiv:2301.11657</a> (replaced) [<a href="/pdf/2301.11657" title="Download PDF">pdf</a>, <a href="/ps/2301.11657" title="Download PostScript">ps</a>, <a href="/format/2301.11657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multilayer hypergraph clustering using the aggregate similarity matrix
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Alaluusua%2C+K">Kalle Alaluusua</a>, 
<a href="/search/math?searchtype=author&query=Avrachenkov%2C+K">Konstantin Avrachenkov</a>, 
<a href="/search/math?searchtype=author&query=Kumar%2C+B+R+V">B. R. Vinay Kumar</a>, 
<a href="/search/math?searchtype=author&query=Leskel%C3%A4%2C+L">Lasse Leskel&#xe4;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 3 tables. Reason for replacement on 3 Nov 2023: incorporating the possibility of non-uniform layers. Reason for replacement on 18 May 2023: improving clarity of the presentation and clarifying the contribution/novelty of the paper
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In: Dewar, M., Pra{\l}at, P., Szufel, P., Th\'eberge, F., Wrzosek,
  M. (eds) Algorithms and Models for the Web Graph. WAW 2023. Lecture Notes in
  Computer Science, vol 13894. Springer, Cham. pp. 83-98
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Information Theory (cs.IT); Probability (math.PR); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12247" title="Abstract">arXiv:2301.12247</a> (replaced) [<a href="/pdf/2301.12247" title="Download PDF">pdf</a>, <a href="/format/2301.12247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SEGA: Instructing Text-to-Image Models using Semantic Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brack%2C+M">Manuel Brack</a>, 
<a href="/search/cs?searchtype=author&query=Friedrich%2C+F">Felix Friedrich</a>, 
<a href="/search/cs?searchtype=author&query=Hintersdorf%2C+D">Dominik Hintersdorf</a>, 
<a href="/search/cs?searchtype=author&query=Struppek%2C+L">Lukas Struppek</a>, 
<a href="/search/cs?searchtype=author&query=Schramowski%2C+P">Patrick Schramowski</a>, 
<a href="/search/cs?searchtype=author&query=Kersting%2C+K">Kristian Kersting</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2212.06013">arXiv:2212.06013</a> Proceedings of the Advances in Neural Information Processing Systems: Annual Conference on Neural Information Processing Systems (NeurIPS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01135" title="Abstract">arXiv:2302.01135</a> (replaced) [<a href="/pdf/2302.01135" title="Download PDF">pdf</a>, <a href="/format/2302.01135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provably Robust Semi-Infinite Program Under Collision Constraints via  Subdivision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Duo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+C">Chen Liang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xifeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kui Wu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zherong Pan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05535" title="Abstract">arXiv:2302.05535</a> (replaced) [<a href="/pdf/2302.05535" title="Download PDF">pdf</a>, <a href="/ps/2302.05535" title="Download PostScript">ps</a>, <a href="/format/2302.05535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> K-Spectral Sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Greenbaum%2C+A">Anne Greenbaum</a>, 
<a href="/search/math?searchtype=author&query=Wellen%2C+N">Natalie Wellen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 10 figures. For relevant code, see <a href="https://github.com/tygris/k-spectral-sets.">this https URL</a> Abstract refers to <a href="/abs/1803.10904">arXiv:1803.10904</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.07317" title="Abstract">arXiv:2302.07317</a> (replaced) [<a href="/pdf/2302.07317" title="Download PDF">pdf</a>, <a href="/format/2302.07317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithm Selection for Deep Active Learning with Imbalanced Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+S">Shuai Shao</a>, 
<a href="/search/cs?searchtype=author&query=Verma%2C+S">Saurabh Verma</a>, 
<a href="/search/cs?searchtype=author&query=Nowak%2C+R">Robert Nowak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14082" title="Abstract">arXiv:2302.14082</a> (replaced) [<a href="/pdf/2302.14082" title="Download PDF">pdf</a>, <a href="/format/2302.14082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting and Mitigating Mode-Collapse for Flow-based Sampling of  Lattice Field Theories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-lat?searchtype=author&query=Nicoli%2C+K+A">Kim A. Nicoli</a>, 
<a href="/search/hep-lat?searchtype=author&query=Anders%2C+C+J">Christopher J. Anders</a>, 
<a href="/search/hep-lat?searchtype=author&query=Hartung%2C+T">Tobias Hartung</a>, 
<a href="/search/hep-lat?searchtype=author&query=Jansen%2C+K">Karl Jansen</a>, 
<a href="/search/hep-lat?searchtype=author&query=Kessel%2C+P">Pan Kessel</a>, 
<a href="/search/hep-lat?searchtype=author&query=Nakajima%2C+S">Shinichi Nakajima</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures, 6 pages of supplement material
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Lattice (hep-lat)</span>; Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14201" title="Abstract">arXiv:2302.14201</a> (replaced) [<a href="/pdf/2302.14201" title="Download PDF">pdf</a>, <a href="/format/2302.14201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nautilus: A Framework for Cross-Layer Cartography of Submarine Cables  and IP Links
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramanathan%2C+A">Alagappan Ramanathan</a>, 
<a href="/search/cs?searchtype=author&query=Jyothi%2C+S+A">Sangeetha Abdu Jyothi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03374" title="Abstract">arXiv:2303.03374</a> (replaced) [<a href="/pdf/2303.03374" title="Download PDF">pdf</a>, <a href="/format/2303.03374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> To Stay or Not to Stay in the Pre-train Basin: Insights on Ensembling in  Transfer Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sadrtdinov%2C+I">Ildus Sadrtdinov</a>, 
<a href="/search/cs?searchtype=author&query=Pozdeev%2C+D">Dmitrii Pozdeev</a>, 
<a href="/search/cs?searchtype=author&query=Vetrov%2C+D">Dmitry Vetrov</a>, 
<a href="/search/cs?searchtype=author&query=Lobacheva%2C+E">Ekaterina Lobacheva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in NeurIPS 2023. First two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.07104" title="Abstract">arXiv:2303.07104</a> (replaced) [<a href="/pdf/2303.07104" title="Download PDF">pdf</a>, <a href="/format/2303.07104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> xASTNN: Improved Code Representations for Industrial Practice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Min Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xibin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongyu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ESEC/FSE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09448" title="Abstract">arXiv:2303.09448</a> (replaced) [<a href="/pdf/2303.09448" title="Download PDF">pdf</a>, <a href="/format/2303.09448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topology optimization of flexoelectric metamaterials with apparent  piezoelectricity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Greco%2C+F">Francesco Greco</a>, 
<a href="/search/physics?searchtype=author&query=Codony%2C+D">David Codony</a>, 
<a href="/search/physics?searchtype=author&query=Mohammadi%2C+H">Hossein Mohammadi</a>, 
<a href="/search/physics?searchtype=author&query=Fernandez-Mendez%2C+S">Sonia Fernandez-Mendez</a>, 
<a href="/search/physics?searchtype=author&query=Arias%2C+I">Irene Arias</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applied Physics (physics.app-ph)</span>; Numerical Analysis (math.NA); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10834" title="Abstract">arXiv:2303.10834</a> (replaced) [<a href="/pdf/2303.10834" title="Download PDF">pdf</a>, <a href="/format/2303.10834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Object-Centric Slot Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jindong Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+F">Fei Deng</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+G">Gautam Singh</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+S">Sungjin Ahn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023 as a Spotlight paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11143" title="Abstract">arXiv:2303.11143</a> (replaced) [<a href="/pdf/2303.11143" title="Download PDF">pdf</a>, <a href="/format/2303.11143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Attacks against Binary Similarity Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Capozzi%2C+G">Gianluca Capozzi</a>, 
<a href="/search/cs?searchtype=author&query=D%27Elia%2C+D+C">Daniele Cono D&#x27;Elia</a>, 
<a href="/search/cs?searchtype=author&query=Di+Luna%2C+G+A">Giuseppe Antonio Di Luna</a>, 
<a href="/search/cs?searchtype=author&query=Querzoni%2C+L">Leonardo Querzoni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12040" title="Abstract">arXiv:2303.12040</a> (replaced) [<a href="/pdf/2303.12040" title="Download PDF">pdf</a>, <a href="/ps/2303.12040" title="Download PostScript">ps</a>, <a href="/format/2303.12040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Roots and Requirements for Collaborative AIs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stefik%2C+M">Mark Stefik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17172" title="Abstract">arXiv:2303.17172</a> (replaced) [<a href="/pdf/2303.17172" title="Download PDF">pdf</a>, <a href="/format/2303.17172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lengths of divisible codes with restricted column multiplicities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=K%C3%B6rner%2C+T">Theresa K&#xf6;rner</a>, 
<a href="/search/math?searchtype=author&query=Kurz%2C+S">Sascha Kurz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03183" title="Abstract">arXiv:2304.03183</a> (replaced) [<a href="/pdf/2304.03183" title="Download PDF">pdf</a>, <a href="/format/2304.03183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> History-deterministic Timed Automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bose%2C+S">Sougata Bose</a>, 
<a href="/search/cs?searchtype=author&query=Henzinger%2C+T+A">Thomas A. Henzinger</a>, 
<a href="/search/cs?searchtype=author&query=Lehtinen%2C+K">Karoliina Lehtinen</a>, 
<a href="/search/cs?searchtype=author&query=Schewe%2C+S">Sven Schewe</a>, 
<a href="/search/cs?searchtype=author&query=Totzke%2C+P">Patrick Totzke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03843" title="Abstract">arXiv:2304.03843</a> (replaced) [<a href="/pdf/2304.03843" title="Download PDF">pdf</a>, <a href="/format/2304.03843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Why think step by step? Reasoning emerges from the locality of  experience
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prystawski%2C+B">Ben Prystawski</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M+Y">Michael Y. Li</a>, 
<a href="/search/cs?searchtype=author&query=Goodman%2C+N+D">Noah D. Goodman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11015" title="Abstract">arXiv:2304.11015</a> (replaced) [<a href="/pdf/2304.11015" title="Download PDF">pdf</a>, <a href="/format/2304.11015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DIN-SQL: Decomposed In-Context Learning of Text-to-SQL with  Self-Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pourreza%2C+M">Mohammadreza Pourreza</a>, 
<a href="/search/cs?searchtype=author&query=Rafiei%2C+D">Davood Rafiei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Databases (cs.DB); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03515" title="Abstract">arXiv:2305.03515</a> (replaced) [<a href="/pdf/2305.03515" title="Download PDF">pdf</a>, <a href="/format/2305.03515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GradTree: Learning Axis-Aligned Decision Trees with Gradient Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marton%2C+S">Sascha Marton</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%BCdtke%2C+S">Stefan L&#xfc;dtke</a>, 
<a href="/search/cs?searchtype=author&query=Bartelt%2C+C">Christian Bartelt</a>, 
<a href="/search/cs?searchtype=author&query=Stuckenschmidt%2C+H">Heiner Stuckenschmidt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03609" title="Abstract">arXiv:2305.03609</a> (replaced) [<a href="/pdf/2305.03609" title="Download PDF">pdf</a>, <a href="/format/2305.03609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially Private Topological Data Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Kang%2C+T">Taegyu Kang</a>, 
<a href="/search/stat?searchtype=author&query=Kim%2C+S">Sehwan Kim</a>, 
<a href="/search/stat?searchtype=author&query=Sohn%2C+J">Jinwon Sohn</a>, 
<a href="/search/stat?searchtype=author&query=Awan%2C+J">Jordan Awan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages before references and appendices, 42 pages total, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Computational Geometry (cs.CG); Cryptography and Security (cs.CR); Machine Learning (cs.LG); Algebraic Topology (math.AT)

</div>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03689" title="Abstract">arXiv:2305.03689</a> (replaced) [<a href="/pdf/2305.03689" title="Download PDF">pdf</a>, <a href="/format/2305.03689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COLA: A Benchmark for Compositional Text-to-image Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ray%2C+A">Arijit Ray</a>, 
<a href="/search/cs?searchtype=author&query=Radenovic%2C+F">Filip Radenovic</a>, 
<a href="/search/cs?searchtype=author&query=Dubey%2C+A">Abhimanyu Dubey</a>, 
<a href="/search/cs?searchtype=author&query=Plummer%2C+B+A">Bryan A. Plummer</a>, 
<a href="/search/cs?searchtype=author&query=Krishna%2C+R">Ranjay Krishna</a>, 
<a href="/search/cs?searchtype=author&query=Saenko%2C+K">Kate Saenko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023. Webpage: <a href="https://cs-people.bu.edu/array/research/cola/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07797" title="Abstract">arXiv:2305.07797</a> (replaced) [<a href="/pdf/2305.07797" title="Download PDF">pdf</a>, <a href="/format/2305.07797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ACCENT: An Automatic Event Commonsense Evaluation Metric for Open-Domain  Dialogue Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghazarian%2C+S">Sarik Ghazarian</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Y">Yijia Shao</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+R">Rujun Han</a>, 
<a href="/search/cs?searchtype=author&query=Galstyan%2C+A">Aram Galstyan</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+N">Nanyun Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08051" title="Abstract">arXiv:2305.08051</a> (replaced) [<a href="/pdf/2305.08051" title="Download PDF">pdf</a>, <a href="/format/2305.08051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prox-DBRO-VR: A Unified Analysis on Decentralized Byzantine-Resilient  Composite Stochastic Optimization with Variance Reduction and Non-Asymptotic  Convergence Rates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hu%2C+J">Jinhui Hu</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+G">Guo Chen</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+H">Huaqing Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 0 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08946" title="Abstract">arXiv:2305.08946</a> (replaced) [<a href="/pdf/2305.08946" title="Download PDF">pdf</a>, <a href="/format/2305.08946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Matching by Bare Homography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bellavia%2C+F">Fabio Bellavia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> major revision update
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09123" title="Abstract">arXiv:2305.09123</a> (replaced) [<a href="/pdf/2305.09123" title="Download PDF">pdf</a>, <a href="/format/2305.09123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Raft-Forensics: High Performance CFT Consensus with Accountability for  Byzantine Faults
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+W">Weizhao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+P">Peiyao Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+P">Pronoy Roy</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuechao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fanti%2C+G">Giulia Fanti</a>, 
<a href="/search/cs?searchtype=author&query=Viswanath%2C+P">Pramod Viswanath</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10050" title="Abstract">arXiv:2305.10050</a> (replaced) [<a href="/pdf/2305.10050" title="Download PDF">pdf</a>, <a href="/format/2305.10050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impact of Missing Data on Causal Discovery: A Multicentric Clinical  Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zanga%2C+A">Alessio Zanga</a>, 
<a href="/search/stat?searchtype=author&query=Bernasconi%2C+A">Alice Bernasconi</a>, 
<a href="/search/stat?searchtype=author&query=Lucas%2C+P+J+F">Peter J.F. Lucas</a>, 
<a href="/search/stat?searchtype=author&query=Pijnenborg%2C+H">Hanny Pijnenborg</a>, 
<a href="/search/stat?searchtype=author&query=Reijnen%2C+C">Casper Reijnen</a>, 
<a href="/search/stat?searchtype=author&query=Scutari%2C+M">Marco Scutari</a>, 
<a href="/search/stat?searchtype=author&query=Stella%2C+F">Fabio Stella</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11092" title="Abstract">arXiv:2305.11092</a> (replaced) [<a href="/pdf/2305.11092" title="Download PDF">pdf</a>, <a href="/format/2305.11092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Domain Adaptation from Foundation Models: A Baseline Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+B">Bin Deng</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+K">Kui Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13112" title="Abstract">arXiv:2305.13112</a> (replaced) [<a href="/pdf/2305.13112" title="Download PDF">pdf</a>, <a href="/format/2305.13112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking the Evaluation for Conversational Recommendation in the Era  of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaolei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xinyu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W+X">Wayne Xin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Ji-Rong Wen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13484" title="Abstract">arXiv:2305.13484</a> (replaced) [<a href="/pdf/2305.13484" title="Download PDF">pdf</a>, <a href="/format/2305.13484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flover: A Temporal Fusion Framework for Efficient Autoregressive Model  Parallel Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jinghan Yao</a>, 
<a href="/search/cs?searchtype=author&query=Alnaasan%2C+N">Nawras Alnaasan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shafi%2C+A">Aamir Shafi</a>, 
<a href="/search/cs?searchtype=author&query=Subramoni%2C+H">Hari Subramoni</a>, 
<a href="/search/cs?searchtype=author&query=K.%2C+D">Dhabaleswar K.</a> (DK)
<a href="/search/cs?searchtype=author&query=Panda">Panda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceeding of 30th IEEE International Conference on High Performance Computing, Data, and Analytics (HiPC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13669" title="Abstract">arXiv:2305.13669</a> (replaced) [<a href="/pdf/2305.13669" title="Download PDF">pdf</a>, <a href="/format/2305.13669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Knowledge Alignment Problem: Bridging Human and External Knowledge  for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Liangming Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Junzhou Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W+Y">William Yang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14022" title="Abstract">arXiv:2305.14022</a> (replaced) [<a href="/pdf/2305.14022" title="Download PDF">pdf</a>, <a href="/format/2305.14022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Realistic Noise Synthesis with Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+M">Mingyan Han</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+T">Ting Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Haoqiang Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+B">Bing Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuaicheng Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14637" title="Abstract">arXiv:2305.14637</a> (replaced) [<a href="/pdf/2305.14637" title="Download PDF">pdf</a>, <a href="/format/2305.14637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning UI-to-Code Reverse Generator Using Visual Critic Without  Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soselia%2C+D">Davit Soselia</a>, 
<a href="/search/cs?searchtype=author&query=Saifullah%2C+K">Khalid Saifullah</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianyi Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14711" title="Abstract">arXiv:2305.14711</a> (replaced) [<a href="/pdf/2305.14711" title="Download PDF">pdf</a>, <a href="/format/2305.14711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gender Biases in Automatic Evaluation Metrics for Image Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+H">Haoyi Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Z">Zi-Yi Dou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianlu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Celikyilmaz%2C+A">Asli Celikyilmaz</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+N">Nanyun Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15004" title="Abstract">arXiv:2305.15004</a> (replaced) [<a href="/pdf/2305.15004" title="Download PDF">pdf</a>, <a href="/format/2305.15004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMDet: A Third Party Large Language Models Generated Text Detection  Tool
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kangxi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+L">Liang Pang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Huawei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xueqi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16397" title="Abstract">arXiv:2305.16397</a> (replaced) [<a href="/pdf/2305.16397" title="Download PDF">pdf</a>, <a href="/format/2305.16397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are Diffusion Models Vision-And-Language Reasoners?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krojer%2C+B">Benno Krojer</a>, 
<a href="/search/cs?searchtype=author&query=Poole-Dayan%2C+E">Elinor Poole-Dayan</a>, 
<a href="/search/cs?searchtype=author&query=Voleti%2C+V">Vikram Voleti</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+C">Christopher Pal</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+S">Siva Reddy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16671" title="Abstract">arXiv:2305.16671</a> (replaced) [<a href="/pdf/2305.16671" title="Download PDF">pdf</a>, <a href="/ps/2305.16671" title="Download PostScript">ps</a>, <a href="/format/2305.16671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Approach for Maximizing Continuous DR-submodular Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pedramfar%2C+M">Mohammad Pedramfar</a>, 
<a href="/search/cs?searchtype=author&query=Quinn%2C+C+J">Christopher John Quinn</a>, 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+V">Vaneet Aggarwal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17560" title="Abstract">arXiv:2305.17560</a> (replaced) [<a href="/pdf/2305.17560" title="Download PDF">pdf</a>, <a href="/format/2305.17560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Transformer for PDE Surrogate Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zijie Li</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+D">Dule Shu</a>, 
<a href="/search/cs?searchtype=author&query=Farimani%2C+A+B">Amir Barati Farimani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18381" title="Abstract">arXiv:2305.18381</a> (replaced) [<a href="/pdf/2305.18381" title="Download PDF">pdf</a>, <a href="/format/2305.18381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distill Gold from Massive Ores: Efficient Dataset Distillation via  Critical Samples Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yue Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong-Lu Li</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+K">Kaitong Cui</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cewu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Tai%2C+Y">Yu-Wing Tai</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chi-Keung Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19234" title="Abstract">arXiv:2305.19234</a> (replaced) [<a href="/pdf/2305.19234" title="Download PDF">pdf</a>, <a href="/ps/2305.19234" title="Download PostScript">ps</a>, <a href="/format/2305.19234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grammar Prompting for Domain-Specific Language Generation with Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bailin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuezhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yuan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Saurous%2C+R+A">Rif A. Saurous</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yoon Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> camera-ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00265" title="Abstract">arXiv:2306.00265</a> (replaced) [<a href="/pdf/2306.00265" title="Download PDF">pdf</a>, <a href="/format/2306.00265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Doubly Robust Self-Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Banghua Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Mingyu Ding</a>, 
<a href="/search/cs?searchtype=author&query=Jacobson%2C+P">Philip Jacobson</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Ming Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+W">Wei Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Jordan%2C+M">Michael Jordan</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+J">Jiantao Jiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01264" title="Abstract">arXiv:2306.01264</a> (replaced) [<a href="/pdf/2306.01264" title="Download PDF">pdf</a>, <a href="/ps/2306.01264" title="Download PostScript">ps</a>, <a href="/format/2306.01264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convex and Non-convex Optimization Under Generalized Smoothness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+H">Haochuan Li</a>, 
<a href="/search/math?searchtype=author&query=Qian%2C+J">Jian Qian</a>, 
<a href="/search/math?searchtype=author&query=Tian%2C+Y">Yi Tian</a>, 
<a href="/search/math?searchtype=author&query=Rakhlin%2C+A">Alexander Rakhlin</a>, 
<a href="/search/math?searchtype=author&query=Jadbabaie%2C+A">Ali Jadbabaie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02231" title="Abstract">arXiv:2306.02231</a> (replaced) [<a href="/pdf/2306.02231" title="Download PDF">pdf</a>, <a href="/format/2306.02231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-Tuning Language Models with Advantage-Induced Policy Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Banghua Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+H">Hiteshi Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Frujeri%2C+F+V">Felipe Vieira Frujeri</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+S">Shi Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chenguang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Jordan%2C+M+I">Michael I. Jordan</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+J">Jiantao Jiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02899" title="Abstract">arXiv:2306.02899</a> (replaced) [<a href="/pdf/2306.02899" title="Download PDF">pdf</a>, <a href="/format/2306.02899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning nonparametric latent causal graphs with unknown interventions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Jiang%2C+Y">Yibo Jiang</a>, 
<a href="/search/stat?searchtype=author&query=Aragam%2C+B">Bryon Aragam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05930" title="Abstract">arXiv:2306.05930</a> (replaced) [<a href="/pdf/2306.05930" title="Download PDF">pdf</a>, <a href="/format/2306.05930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Positivity certificates for linear recurrences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ibrahim%2C+A">Alaa Ibrahim</a>, 
<a href="/search/cs?searchtype=author&query=Salvy%2C+B">Bruno Salvy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages. To appear in Proceedings SODA'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09136" title="Abstract">arXiv:2306.09136</a> (replaced) [<a href="/pdf/2306.09136" title="Download PDF">pdf</a>, <a href="/format/2306.09136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finite-Time Logarithmic Bayes Regret Upper Bounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Atsidakou%2C+A">Alexia Atsidakou</a>, 
<a href="/search/cs?searchtype=author&query=Kveton%2C+B">Branislav Kveton</a>, 
<a href="/search/cs?searchtype=author&query=Katariya%2C+S">Sumeet Katariya</a>, 
<a href="/search/cs?searchtype=author&query=Caramanis%2C+C">Constantine Caramanis</a>, 
<a href="/search/cs?searchtype=author&query=Sanghavi%2C+S">Sujay Sanghavi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10763" title="Abstract">arXiv:2306.10763</a> (replaced) [<a href="/pdf/2306.10763" title="Download PDF">pdf</a>, <a href="/format/2306.10763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guiding Language Models of Code with Global Context using Monitors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+L+A">Lakshya A Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Kanade%2C+A">Aditya Kanade</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+N">Navin Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Lahiri%2C+S+K">Shuvendu K. Lahiri</a>, 
<a href="/search/cs?searchtype=author&query=Rajamani%2C+S+K">Sriram K. Rajamani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023 and to appear as "Monitor-Guided Decoding of Code LMs with Static Analysis of Repository Context" at <a href="https://neurips.cc/virtual/2023/poster/70362">this https URL</a> . Contents: 11 pages, 15 additional pages of appendix, 13 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Programming Languages (cs.PL); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11845" title="Abstract">arXiv:2306.11845</a> (replaced) [<a href="/pdf/2306.11845" title="Download PDF">pdf</a>, <a href="/format/2306.11845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-Optimal Path Planning in a Constant Wind for Uncrewed Aerial  Vehicles using Dubins Set Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moon%2C+B">Brady Moon</a>, 
<a href="/search/cs?searchtype=author&query=Sachdev%2C+S">Sagar Sachdev</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Junbin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Scherer%2C+S">Sebastian Scherer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE Robotics and Automation Letters (RA-L) and ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15136" title="Abstract">arXiv:2306.15136</a> (replaced) [<a href="/pdf/2306.15136" title="Download PDF">pdf</a>, <a href="/format/2306.15136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Truly Matters in Trajectory Prediction for Autonomous Driving?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tran%2C+P">Phong Tran</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haoran Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Cunjun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+P">Panpan Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Sifa Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+D">David Hsu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16042" title="Abstract">arXiv:2306.16042</a> (replaced) [<a href="/pdf/2306.16042" title="Download PDF">pdf</a>, <a href="/format/2306.16042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guarantees for data-driven control of nonlinear systems using  semidefinite programming: A survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Martin%2C+T">Tim Martin</a>, 
<a href="/search/math?searchtype=author&query=Sch%C3%B6n%2C+T+B">Thomas B. Sch&#xf6;n</a>, 
<a href="/search/math?searchtype=author&query=Allg%C3%B6wer%2C+F">Frank Allg&#xf6;wer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16578" title="Abstract">arXiv:2306.16578</a> (replaced) [<a href="/pdf/2306.16578" title="Download PDF">pdf</a>, <a href="/format/2306.16578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Allocating Divisible Resources on Arms with Unknown and Random Rewards
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+N">Ningyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenhao Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16898" title="Abstract">arXiv:2306.16898</a> (replaced) [<a href="/pdf/2306.16898" title="Download PDF">pdf</a>, <a href="/format/2306.16898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Whole-Body Ergodic Exploration with a Manipulator Using Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bilaloglu%2C+C">Cem Bilaloglu</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B6w%2C+T">Tobias L&#xf6;w</a>, 
<a href="/search/cs?searchtype=author&query=Calinon%2C+S">Sylvain Calinon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00424" title="Abstract">arXiv:2307.00424</a> (replaced) [<a href="/pdf/2307.00424" title="Download PDF">pdf</a>, <a href="/format/2307.00424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Algorithms for Relaxed Pareto Set Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Kone%2C+C">Cyrille Kone</a>, 
<a href="/search/stat?searchtype=author&query=Kaufmann%2C+E">Emilie Kaufmann</a>, 
<a href="/search/stat?searchtype=author&query=Richert%2C+L">Laura Richert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01050" title="Abstract">arXiv:2307.01050</a> (replaced) [<a href="/pdf/2307.01050" title="Download PDF">pdf</a>, <a href="/format/2307.01050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transport, Variational Inference and Diffusions: with Applications to  Annealed Flows and Schr&#xf6;dinger Bridges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Vargas%2C+F">Francisco Vargas</a>, 
<a href="/search/stat?searchtype=author&query=N%C3%BCsken%2C+N">Nikolas N&#xfc;sken</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Workshop on New Frontiers in Learning, Control, and Dynamical Systems at the International Conference on Machine Learning (ICML), Honolulu, Hawaii, USA, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01827" title="Abstract">arXiv:2307.01827</a> (replaced) [<a href="/pdf/2307.01827" title="Download PDF">pdf</a>, <a href="/format/2307.01827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deconstructing Data Reconstruction: Multiclass, Weight Decay and General  Losses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Buzaglo%2C+G">Gon Buzaglo</a>, 
<a href="/search/cs?searchtype=author&query=Haim%2C+N">Niv Haim</a>, 
<a href="/search/cs?searchtype=author&query=Yehudai%2C+G">Gilad Yehudai</a>, 
<a href="/search/cs?searchtype=author&query=Vardi%2C+G">Gal Vardi</a>, 
<a href="/search/cs?searchtype=author&query=Oz%2C+Y">Yakir Oz</a>, 
<a href="/search/cs?searchtype=author&query=Nikankin%2C+Y">Yaniv Nikankin</a>, 
<a href="/search/cs?searchtype=author&query=Irani%2C+M">Michal Irani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code: <a href="https://github.com/gonbuzaglo/decoreco.">this https URL</a> arXiv admin note: text overlap with <a href="/abs/2305.03350">arXiv:2305.03350</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02108" title="Abstract">arXiv:2307.02108</a> (replaced) [<a href="/pdf/2307.02108" title="Download PDF">pdf</a>, <a href="/format/2307.02108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proportional Response: Contextual Bandits for Simple and Cumulative  Regret Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krishnamurthy%2C+S+K">Sanath Kumar Krishnamurthy</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+R">Ruohan Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Athey%2C+S">Susan Athey</a>, 
<a href="/search/cs?searchtype=author&query=Brunskill%2C+E">Emma Brunskill</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02345" title="Abstract">arXiv:2307.02345</a> (replaced) [<a href="/pdf/2307.02345" title="Download PDF">pdf</a>, <a href="/format/2307.02345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLQL: Logistic Likelihood Q-Learning for Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lv%2C+O">Outongyi Lv</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bingxin Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03449" title="Abstract">arXiv:2307.03449</a> (replaced) [<a href="/pdf/2307.03449" title="Download PDF">pdf</a>, <a href="/format/2307.03449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Semi-supervised Model Adaptation via Collaborative Consistency  Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zizheng Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yushuang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yipeng Qin</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiaoguang Han</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Shuguang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanbin Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03864" title="Abstract">arXiv:2307.03864</a> (replaced) [<a href="/pdf/2307.03864" title="Download PDF">pdf</a>, <a href="/format/2307.03864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Do Transformers Shine in RL? Decoupling Memory from Credit  Assignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ni%2C+T">Tianwei Ni</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+M">Michel Ma</a>, 
<a href="/search/cs?searchtype=author&query=Eysenbach%2C+B">Benjamin Eysenbach</a>, 
<a href="/search/cs?searchtype=author&query=Bacon%2C+P">Pierre-Luc Bacon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05374" title="Abstract">arXiv:2307.05374</a> (replaced) [<a href="/pdf/2307.05374" title="Download PDF">pdf</a>, <a href="/format/2307.05374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Task Learning to Enhance Generalizability of Neural Network  Equalizers in Coherent Optical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Srivallapanondh%2C+S">Sasipim Srivallapanondh</a>, 
<a href="/search/eess?searchtype=author&query=Freire%2C+P+J">Pedro J. Freire</a>, 
<a href="/search/eess?searchtype=author&query=Alam%2C+A">Ashraful Alam</a>, 
<a href="/search/eess?searchtype=author&query=Costa%2C+N">Nelson Costa</a>, 
<a href="/search/eess?searchtype=author&query=Spinnler%2C+B">Bernhard Spinnler</a>, 
<a href="/search/eess?searchtype=author&query=Napoli%2C+A">Antonio Napoli</a>, 
<a href="/search/eess?searchtype=author&query=Sedov%2C+E">Egor Sedov</a>, 
<a href="/search/eess?searchtype=author&query=Turitsyn%2C+S+K">Sergei K. Turitsyn</a>, 
<a href="/search/eess?searchtype=author&query=Prilepsky%2C+J+E">Jaroslaw E. Prilepsky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, European Conference on Optical Communication (ECOC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08873" title="Abstract">arXiv:2307.08873</a> (replaced) [<a href="/pdf/2307.08873" title="Download PDF">pdf</a>, <a href="/format/2307.08873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Alternative to Variance: Gini Deviation for Risk-averse Policy  Gradient
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yudong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guiliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Poupart%2C+P">Pascal Poupart</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yangchen Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08964" title="Abstract">arXiv:2307.08964</a> (replaced) [<a href="/pdf/2307.08964" title="Download PDF">pdf</a>, <a href="/format/2307.08964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Landscape Surrogate: Learning Decision Losses for Mathematical  Optimization Under Partial Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zharmagambetov%2C+A">Arman Zharmagambetov</a>, 
<a href="/search/cs?searchtype=author&query=Amos%2C+B">Brandon Amos</a>, 
<a href="/search/cs?searchtype=author&query=Ferber%2C+A">Aaron Ferber</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Taoan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Dilkina%2C+B">Bistra Dilkina</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuandong Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10683" title="Abstract">arXiv:2307.10683</a> (replaced) [<a href="/pdf/2307.10683" title="Download PDF">pdf</a>, <a href="/format/2307.10683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fractional Denoising for 3D Molecular Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Feng%2C+S">Shikun Feng</a>, 
<a href="/search/q-bio?searchtype=author&query=Ni%2C+Y">Yuyan Ni</a>, 
<a href="/search/q-bio?searchtype=author&query=Lan%2C+Y">Yanyan Lan</a>, 
<a href="/search/q-bio?searchtype=author&query=Ma%2C+Z">Zhi-Ming Ma</a>, 
<a href="/search/q-bio?searchtype=author&query=Ma%2C+W">Wei-Ying Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG); Chemical Physics (physics.chem-ph)

</div>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11957" title="Abstract">arXiv:2307.11957</a> (replaced) [<a href="/pdf/2307.11957" title="Download PDF">pdf</a>, <a href="/format/2307.11957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-performance real-world optical computing trained by in situ  model-free optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Zhao%2C+G">Guangyuan Zhao</a>, 
<a href="/search/physics?searchtype=author&query=Shu%2C+X">Xin Shu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Computer Vision and Pattern Recognition (cs.CV); Emerging Technologies (cs.ET); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12936" title="Abstract">arXiv:2307.12936</a> (replaced) [<a href="/pdf/2307.12936" title="Download PDF">pdf</a>, <a href="/ps/2307.12936" title="Download PostScript">ps</a>, <a href="/format/2307.12936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Timely Target Tracking: Distributed Updating in Cognitive Radar Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Howard%2C+W+W">William W. Howard</a>, 
<a href="/search/eess?searchtype=author&query=Martone%2C+A+F">Anthony F. Martone</a>, 
<a href="/search/eess?searchtype=author&query=Buehrer%2C+R+M">R. Michael Buehrer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, double column, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14283" title="Abstract">arXiv:2307.14283</a> (replaced) [<a href="/pdf/2307.14283" title="Download PDF">pdf</a>, <a href="/format/2307.14283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> General Purpose Artificial Intelligence Systems (GPAIS): Properties,  Definition, Taxonomy, Societal Implications and Responsible Governance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Triguero%2C+I">Isaac Triguero</a>, 
<a href="/search/cs?searchtype=author&query=Molina%2C+D">Daniel Molina</a>, 
<a href="/search/cs?searchtype=author&query=Poyatos%2C+J">Javier Poyatos</a>, 
<a href="/search/cs?searchtype=author&query=Del+Ser%2C+J">Javier Del Ser</a>, 
<a href="/search/cs?searchtype=author&query=Herrera%2C+F">Francisco Herrera</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00180" title="Abstract">arXiv:2308.00180</a> (replaced) [<a href="/pdf/2308.00180" title="Download PDF">pdf</a>, <a href="/format/2308.00180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> General Anomaly Detection of Underwater Gliders Validated by Large-scale  Deployment Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Ruochu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lembke%2C+C">Chad Lembke</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fumin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Edwards%2C+C">Catherine Edwards</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in IEEE/MTS OCEANS Gulf Coast 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01923" title="Abstract">arXiv:2308.01923</a> (replaced) [<a href="/pdf/2308.01923" title="Download PDF">pdf</a>, <a href="/format/2308.01923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fairness Improvement with Multiple Protected Attributes: How Far Are We?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenpeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J+M">Jie M. Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sarro%2C+F">Federica Sarro</a>, 
<a href="/search/cs?searchtype=author&query=Harman%2C+M">Mark Harman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 46th International Conference on Software Engineering (ICSE 2024). Please include ICSE in any citations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02618" title="Abstract">arXiv:2308.02618</a> (replaced) [<a href="/pdf/2308.02618" title="Download PDF">pdf</a>, <a href="/format/2308.02618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatGPT for GTFS: Benchmarking LLMs on GTFS Understanding and Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Devunuri%2C+S">Saipraneeth Devunuri</a>, 
<a href="/search/cs?searchtype=author&query=Qiam%2C+S">Shirin Qiam</a>, 
<a href="/search/cs?searchtype=author&query=Lehe%2C+L">Lewis Lehe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 8 figures, 1 table, Public Transport
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05993" title="Abstract">arXiv:2308.05993</a> (replaced) [<a href="/pdf/2308.05993" title="Download PDF">pdf</a>, <a href="/format/2308.05993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image-based Geolocalization by Ground-to-2.5D Map Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Mengjie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Liu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yiran Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Calway%2C+A">Andrew Calway</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10685" title="Abstract">arXiv:2308.10685</a> (replaced) [<a href="/pdf/2308.10685" title="Download PDF">pdf</a>, <a href="/format/2308.10685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Graph Prompt-tuning for Cross-domain Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+Z">Zixuan Yi</a>, 
<a href="/search/cs?searchtype=author&query=Ounis%2C+I">Iadh Ounis</a>, 
<a href="/search/cs?searchtype=author&query=Macdonald%2C+C">Craig Macdonald</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13612" title="Abstract">arXiv:2308.13612</a> (replaced) [<a href="/e-print/2308.13612" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is Deep Learning Network Necessary for Image Generation?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chenqiu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+G">Guanfang Dong</a>, 
<a href="/search/cs?searchtype=author&query=Basu%2C+A">Anup Basu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been reject. I am planning to combine this paper with my another paper to make one strong paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15457" title="Abstract">arXiv:2308.15457</a> (replaced) [<a href="/pdf/2308.15457" title="Download PDF">pdf</a>, <a href="/format/2308.15457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From SMOTE to Mixup for Deep Imbalanced Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+W">Wei-Chao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Mai%2C+T">Tan-Ha Mai</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hsuan-Tien Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 3 figures. The paper is accepted by TAAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16150" title="Abstract">arXiv:2308.16150</a> (replaced) [<a href="/pdf/2308.16150" title="Download PDF">pdf</a>, <a href="/format/2308.16150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modality Cycles with Masked Conditional Diffusion for Unsupervised  Anomaly Segmentation in MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liang%2C+Z">Ziyun Liang</a>, 
<a href="/search/eess?searchtype=author&query=Anthony%2C+H">Harry Anthony</a>, 
<a href="/search/eess?searchtype=author&query=Wagner%2C+F">Felix Wagner</a>, 
<a href="/search/eess?searchtype=author&query=Kamnitsas%2C+K">Konstantinos Kamnitsas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in Multiscale Multimodal Medical Imaging workshop in MICCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16708" title="Abstract">arXiv:2308.16708</a> (replaced) [<a href="/pdf/2308.16708" title="Download PDF">pdf</a>, <a href="/format/2308.16708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concentrating on the Impact: Consequence-based Explanations in  Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lubos%2C+S">Sebastian Lubos</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+T+N+T">Thi Ngoc Trang Tran</a>, 
<a href="/search/cs?searchtype=author&query=Erdeniz%2C+S+P">Seda Polat Erdeniz</a>, 
<a href="/search/cs?searchtype=author&query=Mansi%2C+M+E">Merfat El Mansi</a>, 
<a href="/search/cs?searchtype=author&query=Felfernig%2C+A">Alexander Felfernig</a>, 
<a href="/search/cs?searchtype=author&query=Wundara%2C+M">Manfred Wundara</a>, 
<a href="/search/cs?searchtype=author&query=Leitner%2C+G">Gerhard Leitner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper was presented at IntRS'23: Joint Workshop on Interfaces and Human Decision Making for Recommender Systems, September 18, 2023, Singapore. and is published in the workshop proceedings: <a href="https://ceur-ws.org/Vol-3534/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01814" title="Abstract">arXiv:2309.01814</a> (replaced) [<a href="/pdf/2309.01814" title="Download PDF">pdf</a>, <a href="/ps/2309.01814" title="Download PostScript">ps</a>, <a href="/format/2309.01814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Computation of Robust Invariant Sets and Gain-Scheduled  Controllers for Linear Parameter-Varying Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mejari%2C+M">Manas Mejari</a>, 
<a href="/search/eess?searchtype=author&query=Gupta%2C+A">Ankit Gupta</a>, 
<a href="/search/eess?searchtype=author&query=Piga%2C+D">Dario Piga</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures. Accepted for publication, IEEE Control System Letters (LCSS) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01865" title="Abstract">arXiv:2309.01865</a> (replaced) [<a href="/pdf/2309.01865" title="Download PDF">pdf</a>, <a href="/format/2309.01865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BigFUSE: Global Context-Aware Image Fusion in Dual-View Light-Sheet  Fluorescence Microscopy with Image Formation Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yu Liu</a>, 
<a href="/search/eess?searchtype=author&query=Muller%2C+G">Gesine Muller</a>, 
<a href="/search/eess?searchtype=author&query=Navab%2C+N">Nassir Navab</a>, 
<a href="/search/eess?searchtype=author&query=Marr%2C+C">Carsten Marr</a>, 
<a href="/search/eess?searchtype=author&query=Huisken%2C+J">Jan Huisken</a>, 
<a href="/search/eess?searchtype=author&query=Peng%2C+T">Tingying Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> paper in MICCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02553" title="Abstract">arXiv:2309.02553</a> (replaced) [<a href="/pdf/2309.02553" title="Download PDF">pdf</a>, <a href="/format/2309.02553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automating Behavioral Testing in Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferrando%2C+J">Javier Ferrando</a>, 
<a href="/search/cs?searchtype=author&query=Sperber%2C+M">Matthias Sperber</a>, 
<a href="/search/cs?searchtype=author&query=Setiawan%2C+H">Hendra Setiawan</a>, 
<a href="/search/cs?searchtype=author&query=Telaar%2C+D">Dominic Telaar</a>, 
<a href="/search/cs?searchtype=author&query=Hasan%2C+S">Sa&#x161;a Hasan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04579" title="Abstract">arXiv:2309.04579</a> (replaced) [<a href="/pdf/2309.04579" title="Download PDF">pdf</a>, <a href="/format/2309.04579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EGOFALLS: A visual-audio dataset and benchmark for fall detection using  egocentric cameras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xueyi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06884" title="Abstract">arXiv:2309.06884</a> (replaced) [<a href="/pdf/2309.06884" title="Download PDF">pdf</a>, <a href="/format/2309.06884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autoencoder-Based Visual Anomaly Localization for Manufacturing Quality  Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mehta%2C+D">Devang Mehta</a>, 
<a href="/search/cs?searchtype=author&query=Klarmann%2C+N">Noah Klarmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08473" title="Abstract">arXiv:2309.08473</a> (replaced) [<a href="/pdf/2309.08473" title="Download PDF">pdf</a>, <a href="/ps/2309.08473" title="Download PostScript">ps</a>, <a href="/format/2309.08473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On some limitations of data-driven weather forecasting models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bonavita%2C+M">Massimo Bonavita</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Expanded and revised version of original submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09556" title="Abstract">arXiv:2309.09556</a> (replaced) [<a href="/pdf/2309.09556" title="Download PDF">pdf</a>, <a href="/format/2309.09556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Affordance-Driven Next-Best-View Planning for Robotic Grasping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuechao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Sun Han</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weichuang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhigang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+X">Xiaoming Duan</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Chongrong Fang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuelong Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jianping He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference on Robot Learning (CoRL) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09599" title="Abstract">arXiv:2309.09599</a> (replaced) [<a href="/pdf/2309.09599" title="Download PDF">pdf</a>, <a href="/format/2309.09599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MEDL-U: Uncertainty-aware 3D Automatic Annotation based on Evidential  Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paat%2C+H">Helbert Paat</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+Q">Qing Lian</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+W">Weilong Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages Main, 1 page Reference, 5 pages Appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10609" title="Abstract">arXiv:2309.10609</a> (replaced) [<a href="/pdf/2309.10609" title="Download PDF">pdf</a>, <a href="/ps/2309.10609" title="Download PostScript">ps</a>, <a href="/format/2309.10609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Game Connectivity and Adaptive Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Johnston%2C+T">Tom Johnston</a>, 
<a href="/search/econ?searchtype=author&query=Savery%2C+M">Michael Savery</a>, 
<a href="/search/econ?searchtype=author&query=Scott%2C+A">Alex Scott</a>, 
<a href="/search/econ?searchtype=author&query=Tarbush%2C+B">Bassel Tarbush</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages; v3: improved the introduction and added more discussion of our results. Other minor changes
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Computer Science and Game Theory (cs.GT); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14072" title="Abstract">arXiv:2309.14072</a> (replaced) [<a href="/pdf/2309.14072" title="Download PDF">pdf</a>, <a href="/format/2309.14072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BoIR: Box-Supervised Instance Representation for Multi-Person Pose  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeong%2C+U">Uyoung Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Baek%2C+S">Seungryul Baek</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+H+J">Hyung Jin Chang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K+I">Kwang In Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to BMVC 2023, 19 pages including the appendix, 6 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15411" title="Abstract">arXiv:2309.15411</a> (replaced) [<a href="/pdf/2309.15411" title="Download PDF">pdf</a>, <a href="/format/2309.15411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Multiple Object Tracking on Autonomous Driving: A Literature Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Liang He</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xin Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 6 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15770" title="Abstract">arXiv:2309.15770</a> (replaced) [<a href="/pdf/2309.15770" title="Download PDF">pdf</a>, <a href="/format/2309.15770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Transferable Adversarial Simulation Scenarios for  Self-Driving via Neural Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abeysirigoonawardena%2C+Y">Yasasa Abeysirigoonawardena</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+K">Kevin Xie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chuhan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hosseini%2C+S">Salar Hosseini</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruiting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shkurti%2C+F">Florian Shkurti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference paper submitted to CoRL 23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17130" title="Abstract">arXiv:2309.17130</a> (replaced) [<a href="/pdf/2309.17130" title="Download PDF">pdf</a>, <a href="/format/2309.17130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GRANDE: Gradient-Based Decision Tree Ensembles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marton%2C+S">Sascha Marton</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%BCdtke%2C+S">Stefan L&#xfc;dtke</a>, 
<a href="/search/cs?searchtype=author&query=Bartelt%2C+C">Christian Bartelt</a>, 
<a href="/search/cs?searchtype=author&query=Stuckenschmidt%2C+H">Heiner Stuckenschmidt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01682" title="Abstract">arXiv:2310.01682</a> (replaced) [<a href="/pdf/2310.01682" title="Download PDF">pdf</a>, <a href="/format/2310.01682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Two-Player General-Sum Games Between Swarms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghimire%2C+M">Mukesh Ghimire</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenlong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yi Ren</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhe Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ACC 2024. Revised Version, fixed typo in algorithm (DQN instead of DDQN)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Computer Science and Game Theory (cs.GT); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03510" title="Abstract">arXiv:2310.03510</a> (replaced) [<a href="/pdf/2310.03510" title="Download PDF">pdf</a>, <a href="/format/2310.03510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Supervising Smart Home Device Interactions: A Profile-Based Firewall  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Keersmaeker%2C+F">Fran&#xe7;ois De Keersmaeker</a>, 
<a href="/search/cs?searchtype=author&query=Sadre%2C+R">Ramin Sadre</a>, 
<a href="/search/cs?searchtype=author&query=Pelsser%2C+C">Cristel Pelsser</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages of body text, 15 pages total
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03940" title="Abstract">arXiv:2310.03940</a> (replaced) [<a href="/pdf/2310.03940" title="Download PDF">pdf</a>, <a href="/format/2310.03940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hard View Selection for Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferreira%2C+F">Fabio Ferreira</a>, 
<a href="/search/cs?searchtype=author&query=Rapant%2C+I">Ivo Rapant</a>, 
<a href="/search/cs?searchtype=author&query=Hutter%2C+F">Frank Hutter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05058" title="Abstract">arXiv:2310.05058</a> (replaced) [<a href="/pdf/2310.05058" title="Download PDF">pdf</a>, <a href="/format/2310.05058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Separable Hidden Unit Contributions for Speaker-Adaptive  Lip-Reading
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Songtao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+S">Shiguang Shan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xilin Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to BMVC 2023 20pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05280" title="Abstract">arXiv:2310.05280</a> (replaced) [<a href="/pdf/2310.05280" title="Download PDF">pdf</a>, <a href="/format/2310.05280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are Personalized Stochastic Parrots More Dangerous? Evaluating Persona  Biases in Dialogue Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+Y">Yixin Wan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jieyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chadha%2C+A">Aman Chadha</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+N">Nanyun Peng</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K">Kai-Wei Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05619" title="Abstract">arXiv:2310.05619</a> (replaced) [<a href="/pdf/2310.05619" title="Download PDF">pdf</a>, <a href="/format/2310.05619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Top-k Estimation Consolidates Disagreement between Feature  Attribution Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kamp%2C+J">Jonathan Kamp</a>, 
<a href="/search/cs?searchtype=author&query=Beinborn%2C+L">Lisa Beinborn</a>, 
<a href="/search/cs?searchtype=author&query=Fokkens%2C+A">Antske Fokkens</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Short paper accepted to EMNLP 2023 main conference. Please cite the EMNLP version when available
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05628" title="Abstract">arXiv:2310.05628</a> (replaced) [<a href="/pdf/2310.05628" title="Download PDF">pdf</a>, <a href="/format/2310.05628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Glitter or Gold? Deriving Structured Insights from Sustainability  Reports via Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bronzini%2C+M">Marco Bronzini</a>, 
<a href="/search/cs?searchtype=author&query=Nicolini%2C+C">Carlo Nicolini</a>, 
<a href="/search/cs?searchtype=author&query=Lepri%2C+B">Bruno Lepri</a>, 
<a href="/search/cs?searchtype=author&query=Passerini%2C+A">Andrea Passerini</a>, 
<a href="/search/cs?searchtype=author&query=Staiano%2C+J">Jacopo Staiano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computational Engineering, Finance, and Science (cs.CE); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05812" title="Abstract">arXiv:2310.05812</a> (replaced) [<a href="/pdf/2310.05812" title="Download PDF">pdf</a>, <a href="/format/2310.05812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provably Convergent Data-Driven Convex-Nonconvex Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shumaylov%2C+Z">Zakhar Shumaylov</a>, 
<a href="/search/cs?searchtype=author&query=Budd%2C+J">Jeremy Budd</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+S">Subhadip Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6nlieb%2C+C">Carola-Bibiane Sch&#xf6;nlieb</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023 Workshop on Deep Learning and Inverse Problems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07223" title="Abstract">arXiv:2310.07223</a> (replaced) [<a href="/pdf/2310.07223" title="Download PDF">pdf</a>, <a href="/format/2310.07223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning for blind spectral unmixing of LULC classes with MODIS  multispectral time series and ancillary data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rodr%C3%ADguez-Ortega%2C+J">Jos&#xe9; Rodr&#xed;guez-Ortega</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Khaldi%2C+R">Rohaifa Khaldi</a> (2), 
<a href="/search/cs?searchtype=author&query=Alcaraz-Segura%2C+D">Domingo Alcaraz-Segura</a> (3), 
<a href="/search/cs?searchtype=author&query=Tabik%2C+S">Siham Tabik</a> (1) ((1) Department of Computer Science and Artificial Intelligence, DaSCI, University of Granada, Granada, Spain, (2) LifeWatch-ERIC ICT Core, Seville, Spain, (3) Department of Botany, Faculty of Science, University of Granada, Granada, Spain)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07736" title="Abstract">arXiv:2310.07736</a> (replaced) [<a href="/pdf/2310.07736" title="Download PDF">pdf</a>, <a href="/ps/2310.07736" title="Download PostScript">ps</a>, <a href="/format/2310.07736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Observatory: Characterizing Embeddings of Relational Tables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cong%2C+T">Tianji Cong</a>, 
<a href="/search/cs?searchtype=author&query=Hulsebos%2C+M">Madelon Hulsebos</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhenjie Sun</a>, 
<a href="/search/cs?searchtype=author&query=Groth%2C+P">Paul Groth</a>, 
<a href="/search/cs?searchtype=author&query=Jagadish%2C+H+V">H. V. Jagadish</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Revised version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08372" title="Abstract">arXiv:2310.08372</a> (replaced) [<a href="/pdf/2310.08372" title="Download PDF">pdf</a>, <a href="/format/2310.08372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Factual Consistency for Knowledge-Grounded Dialogue Systems  via Knowledge Enhancement and Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+B">Boyang Xue</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weichao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongru Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+F">Fei Mi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yasheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+L">Lifeng Shang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K">Kam-Fai Wong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08571" title="Abstract">arXiv:2310.08571</a> (replaced) [<a href="/pdf/2310.08571" title="Download PDF">pdf</a>, <a href="/format/2310.08571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bucks for Buckets (B4B): Active Defenses Against Stealing Encoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dubi%C5%84ski%2C+J">Jan Dubi&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Pawlak%2C+S">Stanis&#x142;aw Pawlak</a>, 
<a href="/search/cs?searchtype=author&query=Boenisch%2C+F">Franziska Boenisch</a>, 
<a href="/search/cs?searchtype=author&query=Trzci%C5%84ski%2C+T">Tomasz Trzci&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Dziedzic%2C+A">Adam Dziedzic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08701" title="Abstract">arXiv:2310.08701</a> (replaced) [<a href="/pdf/2310.08701" title="Download PDF">pdf</a>, <a href="/format/2310.08701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Biased news sharing and partisan polarization on social media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=del+Pozo%2C+S+M">Sof&#xed;a M del Pozo</a>, 
<a href="/search/cs?searchtype=author&query=Pinto%2C+S">Sebasti&#xe1;n Pinto</a>, 
<a href="/search/cs?searchtype=author&query=Serafino%2C+M">Matteo Serafino</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+L">Lucio Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Makse%2C+H+A">Hern&#xe1;n A Makse</a>, 
<a href="/search/cs?searchtype=author&query=Balenzuela%2C+P">Pablo Balenzuela</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08854" title="Abstract">arXiv:2310.08854</a> (replaced) [<a href="/pdf/2310.08854" title="Download PDF">pdf</a>, <a href="/format/2310.08854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rank-DETR for High Quality Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pu%2C+Y">Yifan Pu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+W">Weicong Liang</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Y">Yiduo Hao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yuhui Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yukang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Han Hu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Gao Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09219" title="Abstract">arXiv:2310.09219</a> (replaced) [<a href="/pdf/2310.09219" title="Download PDF">pdf</a>, <a href="/format/2310.09219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Kelly is a Warm Person, Joseph is a Role Model&quot;: Gender Biases in  LLM-Generated Reference Letters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+Y">Yixin Wan</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+G">George Pu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Garimella%2C+A">Aparna Garimella</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K">Kai-Wei Chang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+N">Nanyun Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12560" title="Abstract">arXiv:2310.12560</a> (replaced) [<a href="/pdf/2310.12560" title="Download PDF">pdf</a>, <a href="/format/2310.12560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Model Debias with Machine Unlearning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruizhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianfei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Huimin Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jianhong Bai</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+T">Tianxiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+J">Jin Hao</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J+T">Joey Tianyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zuozhu Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12612" title="Abstract">arXiv:2310.12612</a> (replaced) [<a href="/pdf/2310.12612" title="Download PDF">pdf</a>, <a href="/format/2310.12612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How a student becomes a teacher: learning and forgetting through  Spectral methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Giambagli%2C+L">Lorenzo Giambagli</a>, 
<a href="/search/cs?searchtype=author&query=Buffoni%2C+L">Lorenzo Buffoni</a>, 
<a href="/search/cs?searchtype=author&query=Chicchi%2C+L">Lorenzo Chicchi</a>, 
<a href="/search/cs?searchtype=author&query=Fanelli%2C+D">Duccio Fanelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages + references + supplemental material. Poster presentation at NeurIPS 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12701" title="Abstract">arXiv:2310.12701</a> (replaced) [<a href="/pdf/2310.12701" title="Download PDF">pdf</a>, <a href="/ps/2310.12701" title="Download PostScript">ps</a>, <a href="/format/2310.12701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parity Games on Temporal Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Austin%2C+P">Pete Austin</a>, 
<a href="/search/cs?searchtype=author&query=Bose%2C+S">Sougata Bose</a>, 
<a href="/search/cs?searchtype=author&query=Totzke%2C+P">Patrick Totzke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13139" title="Abstract">arXiv:2310.13139</a> (replaced) [<a href="/pdf/2310.13139" title="Download PDF">pdf</a>, <a href="/ps/2310.13139" title="Download PostScript">ps</a>, <a href="/format/2310.13139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Neural Networks with polynomial activations have limited  expressivity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khalife%2C+S">Sammy Khalife</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14201" title="Abstract">arXiv:2310.14201</a> (replaced) [<a href="/pdf/2310.14201" title="Download PDF">pdf</a>, <a href="/format/2310.14201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt Engineering Through the Lens of Optimal Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yifan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yiming Tang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chengfeng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhennan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+B">Bin Dong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14880" title="Abstract">arXiv:2310.14880</a> (replaced) [<a href="/pdf/2310.14880" title="Download PDF">pdf</a>, <a href="/ps/2310.14880" title="Download PostScript">ps</a>, <a href="/format/2310.14880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can ChatGPT Perform Reasoning Using the IRAC Method in Analyzing Legal  Scenarios Like a Lawyer?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+X">Xiaoxi Kang</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+L">Lizhen Qu</a>, 
<a href="/search/cs?searchtype=author&query=Soon%2C+L">Lay-Ki Soon</a>, 
<a href="/search/cs?searchtype=author&query=Trakic%2C+A">Adnan Trakic</a>, 
<a href="/search/cs?searchtype=author&query=Zhuo%2C+T+Y">Terry Yue Zhuo</a>, 
<a href="/search/cs?searchtype=author&query=Emerton%2C+P+C">Patrick Charles Emerton</a>, 
<a href="/search/cs?searchtype=author&query=Grant%2C+G">Genevieve Grant</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15958" title="Abstract">arXiv:2310.15958</a> (replaced) [<a href="/pdf/2310.15958" title="Download PDF">pdf</a>, <a href="/format/2310.15958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparison of Unscented Kalman Filter Design for Agricultural Anaerobic  Digestion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hellmann%2C+S">Simon Hellmann</a>, 
<a href="/search/eess?searchtype=author&query=Wilms%2C+T">Terrance Wilms</a>, 
<a href="/search/eess?searchtype=author&query=Streif%2C+S">Stefan Streif</a>, 
<a href="/search/eess?searchtype=author&query=Weinrich%2C+S">S&#xf6;ren Weinrich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fixed typo in model parameters in appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16717" title="Abstract">arXiv:2310.16717</a> (replaced) [<a href="/e-print/2310.16717" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rebuild City Buildings from Off-Nadir Aerial Images with Offset-Building  Model (OBM)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kai Li</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yupeng Deng</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+Y">Yunlong Kong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Diyou Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingbo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+Y">Yu Meng</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Junxian Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> this paper will be rewritten in an entirely different direction in a more detailed and understandable way. Another edition will first send to a conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16789" title="Abstract">arXiv:2310.16789</a> (replaced) [<a href="/pdf/2310.16789" title="Download PDF">pdf</a>, <a href="/format/2310.16789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Pretraining Data from Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Weijia Shi</a>, 
<a href="/search/cs?searchtype=author&query=Ajith%2C+A">Anirudh Ajith</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+M">Mengzhou Xia</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yangsibo Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Daogao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Blevins%2C+T">Terra Blevins</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Danqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zettlemoyer%2C+L">Luke Zettlemoyer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16804" title="Abstract">arXiv:2310.16804</a> (replaced) [<a href="/pdf/2310.16804" title="Download PDF">pdf</a>, <a href="/format/2310.16804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning COVID-19 Regional Transmission Using Universal Differential  Equations in a SIR model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rojas-Campos%2C+A">Adrian Rojas-Campos</a>, 
<a href="/search/cs?searchtype=author&query=Stelz%2C+L">Lukas Stelz</a>, 
<a href="/search/cs?searchtype=author&query=Nieters%2C+P">Pascal Nieters</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, corrected authorship
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16945" title="Abstract">arXiv:2310.16945</a> (replaced) [<a href="/pdf/2310.16945" title="Download PDF">pdf</a>, <a href="/format/2310.16945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Q-Aggregation for CATE Model Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Lan%2C+H">Hui Lan</a>, 
<a href="/search/stat?searchtype=author&query=Syrgkanis%2C+V">Vasilis Syrgkanis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The main text is 10 pages, and we include the Appendix at the end (totaling 52 pages)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Econometrics (econ.EM); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17274" title="Abstract">arXiv:2310.17274</a> (replaced) [<a href="/pdf/2310.17274" title="Download PDF">pdf</a>, <a href="/format/2310.17274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> cuRobo: Parallelized Collision-Free Minimum-Jerk Robot Motion Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sundaralingam%2C+B">Balakumar Sundaralingam</a>, 
<a href="/search/cs?searchtype=author&query=Hari%2C+S+K+S">Siva Kumar Sastry Hari</a>, 
<a href="/search/cs?searchtype=author&query=Fishman%2C+A">Adam Fishman</a>, 
<a href="/search/cs?searchtype=author&query=Garrett%2C+C">Caelan Garrett</a>, 
<a href="/search/cs?searchtype=author&query=Van+Wyk%2C+K">Karl Van Wyk</a>, 
<a href="/search/cs?searchtype=author&query=Blukis%2C+V">Valts Blukis</a>, 
<a href="/search/cs?searchtype=author&query=Millane%2C+A">Alexander Millane</a>, 
<a href="/search/cs?searchtype=author&query=Oleynikova%2C+H">Helen Oleynikova</a>, 
<a href="/search/cs?searchtype=author&query=Handa%2C+A">Ankur Handa</a>, 
<a href="/search/cs?searchtype=author&query=Ramos%2C+F">Fabio Ramos</a>, 
<a href="/search/cs?searchtype=author&query=Ratliff%2C+N">Nathan Ratliff</a>, 
<a href="/search/cs?searchtype=author&query=Fox%2C+D">Dieter Fox</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> revised technical report, 62 pages, Website: <a href="https://curobo.org">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Hardware Architecture (cs.AR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17419" title="Abstract">arXiv:2310.17419</a> (replaced) [<a href="/pdf/2310.17419" title="Download PDF">pdf</a>, <a href="/format/2310.17419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AntifakePrompt: Prompt-Tuned Vision-Language Models are Fake Image  Detectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">You-Ming Chang</a>, 
<a href="/search/cs?searchtype=author&query=Yeh%2C+C">Chen Yeh</a>, 
<a href="/search/cs?searchtype=author&query=Chiu%2C+W">Wei-Chen Chiu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+N">Ning Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17584" title="Abstract">arXiv:2310.17584</a> (replaced) [<a href="/pdf/2310.17584" title="Download PDF">pdf</a>, <a href="/format/2310.17584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A minimax optimal control approach for robust neural ODEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cipriani%2C+C">Cristina Cipriani</a>, 
<a href="/search/math?searchtype=author&query=Scagliotti%2C+A">Alessandro Scagliotti</a>, 
<a href="/search/math?searchtype=author&query=W%C3%B6hrer%2C+T">Tobias W&#xf6;hrer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 2 figures and 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17785" title="Abstract">arXiv:2310.17785</a> (replaced) [<a href="/pdf/2310.17785" title="Download PDF">pdf</a>, <a href="/format/2310.17785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Extrinsic Dexterity with Parameterized Manipulation Primitives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shih-Min Yang</a>, 
<a href="/search/cs?searchtype=author&query=Magnusson%2C+M">Martin Magnusson</a>, 
<a href="/search/cs?searchtype=author&query=Stork%2C+J+A">Johannes A. Stork</a>, 
<a href="/search/cs?searchtype=author&query=Stoyanov%2C+T">Todor Stoyanov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18144" title="Abstract">arXiv:2310.18144</a> (replaced) [<a href="/pdf/2310.18144" title="Download PDF">pdf</a>, <a href="/format/2310.18144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Intrinsic Exploration by Creating Stationary Objectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Castanyer%2C+R+C">Roger Creus Castanyer</a>, 
<a href="/search/cs?searchtype=author&query=Romoff%2C+J">Joshua Romoff</a>, 
<a href="/search/cs?searchtype=author&query=Berseth%2C+G">Glen Berseth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18860" title="Abstract">arXiv:2310.18860</a> (replaced) [<a href="/pdf/2310.18860" title="Download PDF">pdf</a>, <a href="/format/2310.18860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayes beats Cross Validation: Efficient and Accurate Ridge Regression  via Expectation Maximization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Tew%2C+S+Y">Shu Yu Tew</a>, 
<a href="/search/stat?searchtype=author&query=Boley%2C+M">Mario Boley</a>, 
<a href="/search/stat?searchtype=author&query=Schmidt%2C+D+F">Daniel F. Schmidt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18961" title="Abstract">arXiv:2310.18961</a> (replaced) [<a href="/pdf/2310.18961" title="Download PDF">pdf</a>, <a href="/format/2310.18961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qihang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+G">Guansong Pang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yu Tian</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+S">Shibo He</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiming Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19049" title="Abstract">arXiv:2310.19049</a> (replaced) [<a href="/pdf/2310.19049" title="Download PDF">pdf</a>, <a href="/format/2310.19049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimation of Semiconductor Power Losses Through Automatic Thermal  Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sanz-Alcaine%2C+J+M">Jose Miguel Sanz-Alcaine</a>, 
<a href="/search/eess?searchtype=author&query=Sebastian%2C+E">Eduardo Sebastian</a>, 
<a href="/search/eess?searchtype=author&query=Perez-Cebolla%2C+F+J">Francisco Jose Perez-Cebolla</a>, 
<a href="/search/eess?searchtype=author&query=Arruti%2C+A">Asier Arruti</a>, 
<a href="/search/eess?searchtype=author&query=Bernal-Ruiz%2C+C">Carlos Bernal-Ruiz</a>, 
<a href="/search/eess?searchtype=author&query=Aizpuru%2C+I">Iosu Aizpuru</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19180" title="Abstract">arXiv:2310.19180</a> (replaced) [<a href="/pdf/2310.19180" title="Download PDF">pdf</a>, <a href="/format/2310.19180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JEN-1 Composer: A Unified Framework for High-Fidelity Multi-Track Music  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yao Yao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peike Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Boyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Alex Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprints
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19311" title="Abstract">arXiv:2310.19311</a> (replaced) [<a href="/pdf/2310.19311" title="Download PDF">pdf</a>, <a href="/format/2310.19311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relation-driven Query of Multiple Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuhan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuan Tian</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zikun Deng</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+W">Weiwei Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haidong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+D">Di Weng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yingcai Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19367" title="Abstract">arXiv:2310.19367</a> (replaced) [<a href="/pdf/2310.19367" title="Download PDF">pdf</a>, <a href="/ps/2310.19367" title="Download PostScript">ps</a>, <a href="/format/2310.19367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimized Pseudo-Linearization-Based Model Predictive Controller Design:  Direct Data-Driven Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sekine%2C+M">Mikiya Sekine</a>, 
<a href="/search/eess?searchtype=author&query=Tsuruhara%2C+S">Satoshi Tsuruhara</a>, 
<a href="/search/eess?searchtype=author&query=Ito%2C+K">Kazuhisa Ito</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 16 figures, 4 tables, To be submitted to IEEE Transactions on Control Systems Technology (TCST)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19459" title="Abstract">arXiv:2310.19459</a> (replaced) [<a href="/pdf/2310.19459" title="Download PDF">pdf</a>, <a href="/format/2310.19459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Security Challenges for Cloud or Fog Computing-Based AI Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pakmehr%2C+A">Amir Pakmehr</a>, 
<a href="/search/cs?searchtype=author&query=A%C3%9Fmuth%2C+A">Andreas A&#xdf;muth</a>, 
<a href="/search/cs?searchtype=author&query=Neumann%2C+C+P">Christoph P. Neumann</a>, 
<a href="/search/cs?searchtype=author&query=Pirkl%2C+G">Gerald Pirkl</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proc of the 14th IARIA International Conference on Cloud
  Computing, GRIDs, and Virtualization (Cloud Computing 2023), Nice, France,
  June 2023, pp. 21-29, ISSN 2308-4294
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19461" title="Abstract">arXiv:2310.19461</a> (replaced) [<a href="/pdf/2310.19461" title="Download PDF">pdf</a>, <a href="/format/2310.19461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FoodFresh: Multi-Chain Design for an Inter-Institutional Food Supply  Chain Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stangl%2C+P">Philipp Stangl</a>, 
<a href="/search/cs?searchtype=author&query=Neumann%2C+C+P">Christoph P. Neumann</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proc of the 14th IARIA International Conference on Cloud
  Computing, GRIDs, and Virtualization (Cloud Computing 2023), Nice, France,
  June 2023, pp. 41-46, ISSN 2308-4294
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19571" title="Abstract">arXiv:2310.19571</a> (replaced) [<a href="/pdf/2310.19571" title="Download PDF">pdf</a>, <a href="/format/2310.19571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A numerical study of the Dirichlet-to-Neumann operator in planar domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chaigneau%2C+A">Adrien Chaigneau</a>, 
<a href="/search/math?searchtype=author&query=Grebenkov%2C+D+S">Denis S. Grebenkov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19589" title="Abstract">arXiv:2310.19589</a> (replaced) [<a href="/pdf/2310.19589" title="Download PDF">pdf</a>, <a href="/format/2310.19589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Dynamics over Meshes with Gauge Equivariant Nonlinear Message  Passing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+J+Y">Jung Yeon Park</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+L+L+S">Lawson L.S. Wong</a>, 
<a href="/search/cs?searchtype=author&query=Walters%2C+R">Robin Walters</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19951" title="Abstract">arXiv:2310.19951</a> (replaced) [<a href="/pdf/2310.19951" title="Download PDF">pdf</a>, <a href="/format/2310.19951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measuring Behavior Change with Observational Studies: a Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pera%2C+A">Arianna Pera</a>, 
<a href="/search/cs?searchtype=author&query=de+Francisci+Morales%2C+G">Gianmarco de Francisci Morales</a>, 
<a href="/search/cs?searchtype=author&query=Aiello%2C+L+M">Luca Maria Aiello</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Social and Information Networks (cs.SI); Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20033" title="Abstract">arXiv:2310.20033</a> (replaced) [<a href="/pdf/2310.20033" title="Download PDF">pdf</a>, <a href="/format/2310.20033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthetic Imitation Edit Feedback for Factual Alignment in Clinical  Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mishra%2C+P">Prakamya Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Z">Zonghai Yao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shuwei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Beining Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mittal%2C+R">Rohan Mittal</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hong Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in NeurIPS 2023 Workshop SyntheticData4ML
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20243" title="Abstract">arXiv:2310.20243</a> (replaced) [<a href="/pdf/2310.20243" title="Download PDF">pdf</a>, <a href="/ps/2310.20243" title="Download PostScript">ps</a>, <a href="/format/2310.20243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrast-agent-induced deterministic component of CT-density in the  abdominal aorta during routine angiography: proof of concept study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kodenko%2C+M+R">Maria R. Kodenko</a>, 
<a href="/search/cs?searchtype=author&query=Vasilev%2C+Y+A">Yuriy A. Vasilev</a>, 
<a href="/search/cs?searchtype=author&query=Kulberg%2C+N+S">Nicholas S. Kulberg</a>, 
<a href="/search/cs?searchtype=author&query=Samorodov%2C+A+V">Andrey V. Samorodov</a>, 
<a href="/search/cs?searchtype=author&query=Vladzimirskyy%2C+A+V">Anton V. Vladzimirskyy</a>, 
<a href="/search/cs?searchtype=author&query=Omelyanskaya%2C+O+V">Olga V. Omelyanskaya</a>, 
<a href="/search/cs?searchtype=author&query=Reshetnikov%2C+R+V">Roman V. Reshetnikov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20258" title="Abstract">arXiv:2310.20258</a> (replaced) [<a href="/pdf/2310.20258" title="Download PDF">pdf</a>, <a href="/format/2310.20258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Bayesian Optimization via Learning Correlated Latent Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seunghun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+J">Jaewon Chu</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sihyeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ko%2C+J">Juyeon Ko</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H+J">Hyunwoo J. Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20271" title="Abstract">arXiv:2310.20271</a> (replaced) [<a href="/pdf/2310.20271" title="Download PDF">pdf</a>, <a href="/format/2310.20271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Denoising Training to Test-Time Adaptation: Enhancing Domain  Generalization for Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+R">Ruxue Wen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Hangjie Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+D">Dong Ni</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+W">Wenbo Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yaoyao Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20343" title="Abstract">arXiv:2310.20343</a> (replaced) [<a href="/pdf/2310.20343" title="Download PDF">pdf</a>, <a href="/format/2310.20343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Multi-modal Encoders for Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+Z">Zixuan Yi</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+Z">Zijun Long</a>, 
<a href="/search/cs?searchtype=author&query=Ounis%2C+I">Iadh Ounis</a>, 
<a href="/search/cs?searchtype=author&query=Macdonald%2C+C">Craig Macdonald</a>, 
<a href="/search/cs?searchtype=author&query=Mccreadie%2C+R">Richard Mccreadie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20380" title="Abstract">arXiv:2310.20380</a> (replaced) [<a href="/pdf/2310.20380" title="Download PDF">pdf</a>, <a href="/format/2310.20380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dropout Strategy in Reinforcement Learning: Limiting the Surrogate  Objective Variance in Policy Optimization Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhengpeng Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Changdong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+W">Weizheng Qiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20381" title="Abstract">arXiv:2310.20381</a> (replaced) [<a href="/pdf/2310.20381" title="Download PDF">pdf</a>, <a href="/format/2310.20381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Study of GPT-4V&#x27;s Multimodal Capabilities in Medical  Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yingshu Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yunyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhanyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xinyu Liang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingqiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+L">Leyang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhaopeng Tu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Longyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Luping Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20414" title="Abstract">arXiv:2310.20414</a> (replaced) [<a href="/pdf/2310.20414" title="Download PDF">pdf</a>, <a href="/ps/2310.20414" title="Download PostScript">ps</a>, <a href="/format/2310.20414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta Learning for Multi-View Visuomotor Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alwis%2C+B">Benji Alwis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Change of authors since further experiments based on second and third authors comments will be added to a future version of this paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20550" title="Abstract">arXiv:2310.20550</a> (replaced) [<a href="/pdf/2310.20550" title="Download PDF">pdf</a>, <a href="/format/2310.20550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CapsFusion: Rethinking Image-Text Data at Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qiying Yu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Quan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaosong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Y">Yufeng Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yue Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinlong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingjing Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code &amp; Dataset: <a href="https://github.com/baaivision/CapsFusion">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00060" title="Abstract">arXiv:2311.00060</a> (replaced) [<a href="/pdf/2311.00060" title="Download PDF">pdf</a>, <a href="/format/2311.00060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ensemble models outperform single model uncertainties and predictions  for operator-learning of hypersonic flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Leon%2C+V+J">Victor J. Leon</a>, 
<a href="/search/physics?searchtype=author&query=Ford%2C+N">Noah Ford</a>, 
<a href="/search/physics?searchtype=author&query=Mrema%2C+H">Honest Mrema</a>, 
<a href="/search/physics?searchtype=author&query=Gilbert%2C+J">Jeffrey Gilbert</a>, 
<a href="/search/physics?searchtype=author&query=New%2C+A">Alexander New</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work was accepted after peer-review and presented at the 2023 NeurIPS Machine Learning and the Physical Sciences workshop. <a href="https://ml4physicalsciences.github.io/2023/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00128" title="Abstract">arXiv:2311.00128</a> (replaced) [<a href="/pdf/2311.00128" title="Download PDF">pdf</a>, <a href="/format/2311.00128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the effect of curriculum learning with developmental data for grammar  acquisition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Opper%2C+M">Mattia Opper</a>, 
<a href="/search/cs?searchtype=author&query=Morrison%2C+J">J. Morrison</a>, 
<a href="/search/cs?searchtype=author&query=Siddharth%2C+N">N. Siddharth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CoNLL-CMCL Shared Task BabyLM Challenge 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00687" title="Abstract">arXiv:2311.00687</a> (replaced) [<a href="/pdf/2311.00687" title="Download PDF">pdf</a>, <a href="/format/2311.00687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Interpersonal Communication by Simulating Audiences with  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ryan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yen%2C+H">Howard Yen</a>, 
<a href="/search/cs?searchtype=author&query=Marjieh%2C+R">Raja Marjieh</a>, 
<a href="/search/cs?searchtype=author&query=Griffiths%2C+T+L">Thomas L. Griffiths</a>, 
<a href="/search/cs?searchtype=author&query=Krishna%2C+R">Ranjay Krishna</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages (main paper), 7 tables and figures (main)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01057" title="Abstract">arXiv:2311.01057</a> (replaced) [<a href="/pdf/2311.01057" title="Download PDF">pdf</a>, <a href="/ps/2311.01057" title="Download PostScript">ps</a>, <a href="/format/2311.01057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ultra-Efficient On-Device Object Detection on AI-Integrated Smart  Glasses with TinyissimoYOLO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moosmann%2C+J">Julian Moosmann</a>, 
<a href="/search/cs?searchtype=author&query=Bonazzi%2C+P">Pietro Bonazzi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yawei Li</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+S">Sizhen Bian</a>, 
<a href="/search/cs?searchtype=author&query=Mayer%2C+P">Philipp Mayer</a>, 
<a href="/search/cs?searchtype=author&query=Benini%2C+L">Luca Benini</a>, 
<a href="/search/cs?searchtype=author&query=Magno%2C+M">Michele Magno</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01240" title="Abstract">arXiv:2311.01240</a> (replaced) [<a href="/pdf/2311.01240" title="Download PDF">pdf</a>, <a href="/format/2311.01240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FacadeNet: Conditional Facade Synthesis via Selective Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Georgiou%2C+Y">Yiangos Georgiou</a>, 
<a href="/search/cs?searchtype=author&query=Loizou%2C+M">Marios Loizou</a>, 
<a href="/search/cs?searchtype=author&query=Kelly%2C+T">Tom Kelly</a>, 
<a href="/search/cs?searchtype=author&query=Averkiou%2C+M">Melinos Averkiou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01282" title="Abstract">arXiv:2311.01282</a> (replaced) [<a href="/pdf/2311.01282" title="Download PDF">pdf</a>, <a href="/format/2311.01282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlashDecoding++: Faster Large Language Model Inference on GPUs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+K">Ke Hong</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+G">Guohao Dai</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiaming Xu</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Q">Qiuli Mao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiuhong Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kangdi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hanyu Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01315" title="Abstract">arXiv:2311.01315</a> (replaced) [<a href="/pdf/2311.01315" title="Download PDF">pdf</a>, <a href="/ps/2311.01315" title="Download PostScript">ps</a>, <a href="/format/2311.01315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generic Model Checking for Modal Fixpoint Logics in COOL-MC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hausmann%2C+D">Daniel Hausmann</a>, 
<a href="/search/cs?searchtype=author&query=Humml%2C+M">Merlin Humml</a>, 
<a href="/search/cs?searchtype=author&query=Prucker%2C+S">Simon Prucker</a>, 
<a href="/search/cs?searchtype=author&query=Schr%C3%B6der%2C+L">Lutz Schr&#xf6;der</a>, 
<a href="/search/cs?searchtype=author&query=Strahlberger%2C+A">Aaron Strahlberger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full Version of VMCAI 2024 publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01414" title="Abstract">arXiv:2311.01414</a> (replaced) [<a href="/pdf/2311.01414" title="Download PDF">pdf</a>, <a href="/ps/2311.01414" title="Download PostScript">ps</a>, <a href="/format/2311.01414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Dynamic Temporal Logic for Quality of Service in Choreographic Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pombo%2C+C+G+L">Carlos G. Lopez Pombo</a>, 
<a href="/search/cs?searchtype=author&query=Su%C3%B1%C3%A9%2C+A+E+M">Agust&#xed;n E. Martinez Su&#xf1;&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Tuosto%2C+E">Emilio Tuosto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, Accepted for publication at International Conference on Theoretical Aspects of Computing 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item228">Cross-lists</a></li>
<li><a href="#item274">Replacements</a></li>
</ul>
<small>[ total of 456 entries:  <b>1-456</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2311">2311</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
