<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Tue 21 Nov 23  to  Wed 22 Nov 23, announced Thu, 23 Nov 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item333">Cross-lists</a></li>
<li><a href="#item393">Replacements</a></li>
</ul>
<small>[ total of 567 entries:  <b>1-567</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Thu, 23 Nov 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12798" title="Abstract">arXiv:2311.12798</a> [<a href="/pdf/2311.12798" title="Download PDF">pdf</a>, <a href="/format/2311.12798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frequency Analysis with Multiple Kernels and Complete Dictionary
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Cuiyun Lin</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+T">Tao Qian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In signal analysis, among the effort of seeking for efficient representations
of a signal into the basic ones of meaningful frequencies, to extract principal
frequency components, consecutively one after another or $n$ at one time, is a
fundamental strategy. For this goal, we define the concept of mean-frequency
and develop the related frequency decomposition with the complete Szeg\"o
kernel dictionary, the latter consisting of the multiple kernels, being defined
as the parameter-derivatives of the Szeg\"o kernels. Several major energy
matching pursuit type sparse representations, including greedy algorithm (GA),
orthogonal greedy algorithm (OGA), adaptive Fourier decomposition (AFD),
pre-orthogonal adaptive Fourier decomposition (POAFD), $n$-Best approximation
and unwinding Blaschke expansion, are analyzed and compared. Of which an order
in re-construction efficiency between the mentioned algorithms is given based
on detailed study of their respective remainders. The study spells out the
natural connections between the multiple kernels and the related Laguerre
system, and in particular shows that both, like the Fourier series, extract out
the $O(n^{-\sigma})$ order convergence rate from the functions in the
Hardy-Sobolev space of order $\sigma &gt;0.$ Existence of the $n$-Best
approximation with the complete Szeg\"o dictionary is proved and the related
algorithm aspects are discussed. The included experiments form a significant
integration part of the study, for they not only illustrate the theoretical
results, but also provide cross comparison between various ways of combination
between the matching pursuit algorithms and the dictionaries in use.
Experiments show that the complete dictionary remarkably improves approximation
efficiency.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12799" title="Abstract">arXiv:2311.12799</a> [<a href="/pdf/2311.12799" title="Download PDF">pdf</a>, <a href="/format/2311.12799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Fine-Grained Image Description Generation Method Based on Joint  Objectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chunzhen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+D">Donglin Cao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dazhen Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The goal of fine-grained image description generation techniques is to learn
detailed information from images and simulate human-like descriptions that
provide coherent and comprehensive textual details about the image content.
Currently, most of these methods face two main challenges: description
repetition and omission. Moreover, the existing evaluation metrics cannot
clearly reflect the performance of models on these two issues. To address these
challenges, we propose an innovative Fine-grained Image Description Generation
model based on Joint Objectives. Furthermore, we introduce new object-based
evaluation metrics to more intuitively assess the model's performance in
handling description repetition and omission. This novel approach combines
visual features at both the image level and object level to maximize their
advantages and incorporates an object penalty mechanism to reduce description
repetition. Experimental results demonstrate that our proposed method
significantly improves the CIDEr evaluation metric, indicating its excellent
performance in addressing description repetition and omission issues.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12800" title="Abstract">arXiv:2311.12800</a> [<a href="/pdf/2311.12800" title="Download PDF">pdf</a>, <a href="/format/2311.12800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Data Augmentation from a Robustness Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhendong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Q">Qiangqiang He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chongjun Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Not published yet. arXiv admin note: text overlap with <a href="/abs/2212.04059">arXiv:2212.04059</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the realm of visual recognition, data augmentation stands out as a pivotal
technique to amplify model robustness. Yet, a considerable number of existing
methodologies lean heavily on heuristic foundations, rendering their intrinsic
mechanisms ambiguous. This manuscript takes both a theoretical and empirical
approach to understanding the phenomenon. Theoretically, we frame the discourse
around data augmentation within game theory's constructs. Venturing deeper, our
empirical evaluations dissect the intricate mechanisms of emblematic data
augmentation strategies, illuminating that these techniques primarily stimulate
mid- and high-order game interactions. Beyond the foundational exploration, our
experiments span multiple datasets and diverse augmentation techniques,
underscoring the universal applicability of our findings. Recognizing the vast
array of robustness metrics with intricate correlations, we unveil a
streamlined proxy. This proxy not only simplifies robustness assessment but
also offers invaluable insights, shedding light on the inherent dynamics of
model game interactions and their relation to overarching system robustness.
These insights provide a novel lens through which we can re-evaluate model
safety and robustness in visual recognition tasks.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12801" title="Abstract">arXiv:2311.12801</a> [<a href="/pdf/2311.12801" title="Download PDF">pdf</a>, <a href="/ps/2311.12801" title="Download PostScript">ps</a>, <a href="/format/2311.12801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-end Phase Field Model Discovery Combining Experimentation,  Crowdsourcing, Simulation and Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nasim%2C+M">Md Nasim</a>, 
<a href="/search/cs?searchtype=author&query=El-Azab%2C+A">Anter El-Azab</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinghang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Y">Yexiang Xue</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The availability of tera-byte scale experiment data calls for AI driven
approaches which automatically discover scientific models from data.
Nonetheless, significant challenges present in AI-driven scientific discovery:
(i) The annotation of large scale datasets requires fundamental re-thinking in
developing scalable crowdsourcing tools. (ii) The learning of scientific models
from data calls for innovations beyond black-box neural nets. (iii) Novel
visualization and diagnosis tools are needed for the collaboration of
experimental and theoretical physicists, and computer scientists. We present
Phase-Field-Lab platform for end-to-end phase field model discovery, which
automatically discovers phase field physics models from experiment data,
integrating experimentation, crowdsourcing, simulation and learning.
Phase-Field-Lab combines (i) a streamlined annotation tool which reduces the
annotation time (by ~50-75%), while increasing annotation accuracy compared to
baseline; (ii) an end-to-end neural model which automatically learns phase
field models from data by embedding phase field simulation and existing domain
knowledge into learning; and (iii) novel interfaces and visualizations to
integrate our platform into the scientific discovery cycle of domain
scientists. Our platform is deployed in the analysis of nano-structure
evolution in materials under extreme conditions (high temperature and
irradiation). Our approach reveals new properties of nano-void defects, which
otherwise cannot be detected via manual analysis.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12802" title="Abstract">arXiv:2311.12802</a> [<a href="/pdf/2311.12802" title="Download PDF">pdf</a>, <a href="/ps/2311.12802" title="Download PostScript">ps</a>, <a href="/format/2311.12802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A general Framework for Utilizing Metaheuristic Optimization for  Sustainable Unrelated Parallel Machine Scheduling: A concise overview
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ezugwu%2C+A+E">Absalom E. Ezugwu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Sustainable development has emerged as a global priority, and industries are
increasingly striving to align their operations with sustainable practices.
Parallel machine scheduling (PMS) is a critical aspect of production planning
that directly impacts resource utilization and operational efficiency. In this
paper, we investigate the application of metaheuristic optimization algorithms
to address the unrelated parallel machine scheduling problem (UPMSP) through
the lens of sustainable development goals (SDGs). The primary objective of this
study is to explore how metaheuristic optimization algorithms can contribute to
achieving sustainable development goals in the context of UPMSP. We examine a
range of metaheuristic algorithms, including genetic algorithms, particle swarm
optimization, ant colony optimization, and more, and assess their effectiveness
in optimizing the scheduling problem. The algorithms are evaluated based on
their ability to improve resource utilization, minimize energy consumption,
reduce environmental impact, and promote socially responsible production
practices. To conduct a comprehensive analysis, we consider UPMSP instances
that incorporate sustainability-related constraints and objectives.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12803" title="Abstract">arXiv:2311.12803</a> [<a href="/pdf/2311.12803" title="Download PDF">pdf</a>, <a href="/format/2311.12803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating Copyright Issues of Diffusion Models under Practical  Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tzun%2C+T+T">Teoh Tze Tzun</a>, 
<a href="/search/cs?searchtype=author&query=Hern%2C+L+W">Lim Wei Hern</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haonan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kawaguchi%2C+K">Kenji Kawaguchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 18 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">The issue of copyright in generative models, particularly diffusion models,
has become a prominent concern in recent years. Previous studies have
predominantly focused on copyright violation at the image level, where
generative models replicate copyrighted images entirely. Furthermore, these
earlier studies have examined copyright infringements mainly using prompts that
are semantically similar to target topics. However, copyright infringement can
be more nuanced than mere replication of whole images and can be triggered with
prompts that are less directly related to copyright topics. In our work, we
tackle the limitations of previous studies by delving into partial copyright
infringement, which treats parts of images as copyrighted content, using
prompts that are considerably different from copyrighted topics. We develop a
data generation pipeline that facilitates the creation of datasets for
copyright research in diffusion models. Using our pipeline, we create datasets
containing copyright infringement samples for different diffusion models. We
conduct evaluations on generated data under various criteria. Our results show
the prevalence of generating copyright-infringing content across a range of
diffusion models, including the latest Stable Diffusion XL.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12804" title="Abstract">arXiv:2311.12804</a> [<a href="/pdf/2311.12804" title="Download PDF">pdf</a>, <a href="/format/2311.12804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards the generation of synchronized and believable non-verbal facial  behaviors of a talking virtual agent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Delbosc%2C+A">Alice Delbosc</a> (TALEP, LIS, AMU), 
<a href="/search/cs?searchtype=author&query=Ochs%2C+M">Magalie Ochs</a> (LIS, AMU, TALEP), 
<a href="/search/cs?searchtype=author&query=Sabouret%2C+N">Nicolas Sabouret</a> (LISN), 
<a href="/search/cs?searchtype=author&query=Ravenet%2C+B">Brian Ravenet</a> (LISN), 
<a href="/search/cs?searchtype=author&query=Ayache%2C+S">St&#xe9;phane Ayache</a> (AMU, LIS, QARMA)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION (ICMI '23
  Companion), Oct 2023, Paris, France
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">This paper introduces a new model to generate rhythmically relevant
non-verbal facial behaviors for virtual agents while they speak. The model
demonstrates perceived performance comparable to behaviors directly extracted
from the data and replayed on a virtual agent, in terms of synchronization with
speech and believability. Interestingly, we found that training the model with
two different sets of data, instead of one, did not necessarily improve its
performance. The expressiveness of the people in the dataset and the shooting
conditions are key elements. We also show that employing an adversarial model,
in which fabricated fake examples are introduced during the training phase,
increases the perception of synchronization with speech. A collection of videos
demonstrating the results and code can be accessed at:
https://github.com/aldelb/non_verbal_facial_animation.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12805" title="Abstract">arXiv:2311.12805</a> [<a href="/pdf/2311.12805" title="Download PDF">pdf</a>, <a href="/format/2311.12805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepCompass: AI-driven Location-Orientation Synchronization for  Navigating Platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jihun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+S">SP Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+B">Bumsoo Kang</a>, 
<a href="/search/cs?searchtype=author&query=Seok%2C+H">Hyekyoung Seok</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+H">Hyoungseok Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+S">Sanghee Jung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7page with 3 supplemental pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In current navigating platforms, the user's orientation is typically
estimated based on the difference between two consecutive locations. In other
words, the orientation cannot be identified until the second location is taken.
This asynchronous location-orientation identification often leads to our
real-life question: Why does my navigator tell the wrong direction of my car at
the beginning? We propose DeepCompass to identify the user's orientation by
bridging the gap between the street-view and the user-view images. First, we
explore suitable model architectures and design corresponding input
configuration. Second, we demonstrate artificial transformation techniques
(e.g., style transfer and road segmentation) to minimize the disparity between
the street-view and the user's real-time experience. We evaluate DeepCompass
with extensive evaluation in various driving conditions. DeepCompass does not
require additional hardware and is also not susceptible to external
interference, in contrast to magnetometer-based navigator. This highlights the
potential of DeepCompass as an add-on to existing sensor-based orientation
detection methods.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12806" title="Abstract">arXiv:2311.12806</a> [<a href="/pdf/2311.12806" title="Download PDF">pdf</a>, <a href="/ps/2311.12806" title="Download PostScript">ps</a>, <a href="/format/2311.12806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MatGD: Materials Graph Digitizer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaewoong Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+W">Wonseok Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jihan Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Digital Libraries (cs.DL); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">We have developed MatGD (Material Graph Digitizer), which is a tool for
digitizing a data line from scientific graphs. The algorithm behind the tool
consists of four steps: (1) identifying graphs within subfigures, (2)
separating axes and data sections, (3) discerning the data lines by eliminating
irrelevant graph objects and matching with the legend, and (4) data extraction
and saving. From the 62,534 papers in the areas of batteries, catalysis, and
MOFs, 501,045 figures were mined. Remarkably, our tool showcased performance
with over 99% accuracy in legend marker and text detection. Moreover, its
capability for data line separation stood at 66%, which is much higher compared
to other existing figure mining tools. We believe that this tool will be
integral to collecting both past and future data from publications, and these
data can be used to train various machine learning models that can enhance
material predictions and new materials discovery.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12807" title="Abstract">arXiv:2311.12807</a> [<a href="/pdf/2311.12807" title="Download PDF">pdf</a>, <a href="/format/2311.12807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reducing the Environmental Impact of Wireless Communication via  Probabilistic Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koblitz%2C+A+R">A. Ryo Koblitz</a>, 
<a href="/search/cs?searchtype=author&query=Maggi%2C+L">Lorenzo Maggi</a>, 
<a href="/search/cs?searchtype=author&query=Andrews%2C+M">Matthew Andrews</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Machine learning methods are increasingly adopted in communications problems,
particularly those arising in next generation wireless settings. Though seen as
a key climate mitigation and societal adaptation enabler, communications
related energy consumption is high and is expected to grow in future networks
in spite of anticipated efficiency gains in 6G due to exponential
communications traffic growth. To make meaningful climate mitigation impact in
the communications sector, a mindset shift away from maximizing throughput at
all cost and towards prioritizing energy efficiency is needed. Moreover, this
must be adopted in both existing (without incurring further embodied carbon
costs through equipment replacement) and future network infrastructure, given
the long development time of mobile generations. To that end, we present
summaries of two such problems, from both current and next generation network
specifications, where probabilistic inference methods were used to great
effect: using Bayesian parameter tuning we are able to safely reduce the energy
consumption of existing hardware on a live communications network by $11\%$
whilst maintaining operator specified performance envelopes; through
spatiotemporal Gaussian process surrogate modeling we reduce the overhead in a
next generation hybrid beamforming system by over $60\%$, greatly improving the
networks' ability to target highly mobile users such as autonomous vehicles.
The Bayesian paradigm is itself helpful in terms of energy usage, since
training a Bayesian optimization model can require much less computation than,
say, training a deep neural network.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12808" title="Abstract">arXiv:2311.12808</a> [<a href="/pdf/2311.12808" title="Download PDF">pdf</a>, <a href="/ps/2311.12808" title="Download PostScript">ps</a>, <a href="/format/2311.12808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved vectorization of OpenCV algorithms for RISC-V CPUs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Volokitin%2C+V+D">V. D. Volokitin</a>, 
<a href="/search/cs?searchtype=author&query=Vasiliev%2C+E+P">E. P. Vasiliev</a>, 
<a href="/search/cs?searchtype=author&query=Kozinov%2C+E+A">E. A. Kozinov</a>, 
<a href="/search/cs?searchtype=author&query=Kustikova%2C+V+D">V. D. Kustikova</a>, 
<a href="/search/cs?searchtype=author&query=Liniov%2C+A+V">A. V. Liniov</a>, 
<a href="/search/cs?searchtype=author&query=Rodimkov%2C+Y+A">Y. A. Rodimkov</a>, 
<a href="/search/cs?searchtype=author&query=Sysoyev%2C+A+V">A. V. Sysoyev</a>, 
<a href="/search/cs?searchtype=author&query=Meyerov%2C+I+B">I. B. Meyerov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Computer Vision and Pattern Recognition (cs.CV); Performance (cs.PF)

</div>
<p class="mathjax">The development of an open and free RISC-V architecture is of great interest
for a wide range of areas, including high-performance computing and numerical
simulation in mathematics, physics, chemistry and other problem domains. In
this paper, we discuss the possibilities of accelerating computations on
available RISC-V processors by improving the vectorization of several computer
vision and machine learning algorithms in the widely used OpenCV library. It is
shown that improved vectorization speeds up computations on existing prototypes
of RISC-V devices by tens of percent.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12809" title="Abstract">arXiv:2311.12809</a> [<a href="/pdf/2311.12809" title="Download PDF">pdf</a>, <a href="/format/2311.12809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Power and Safe RF Wireless Charging: Cautious Deployment and  Operation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez%2C+O+L+A">Onel L. A. L&#xf3;pez</a>, 
<a href="/search/cs?searchtype=author&query=Rosabal%2C+O+M">Osmel M. Rosabal</a>, 
<a href="/search/cs?searchtype=author&query=Azarbahram%2C+A">Amirhossein Azarbahram</a>, 
<a href="/search/cs?searchtype=author&query=Khattak%2C+A+B">A. Basit Khattak</a>, 
<a href="/search/cs?searchtype=author&query=Monemi%2C+M">Mehdi Monemi</a>, 
<a href="/search/cs?searchtype=author&query=Souza%2C+R+D">Richard D. Souza</a>, 
<a href="/search/cs?searchtype=author&query=Popovski%2C+P">Petar Popovski</a>, 
<a href="/search/cs?searchtype=author&query=Latva-aho%2C+M">Matti Latva-aho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Emerging Technologies (cs.ET); Signal Processing (eess.SP)

</div>
<p class="mathjax">The wired charging and the need for battery replacements are critical
barriers to unlimited, scalable, and sustainable mobile connectivity,
motivating the interest in radio frequency (RF) wireless power transfer (WPT)
technology. However, the inherently low end-to-end power transfer efficiency
(PTE) and health/safety-related apprehensions about the technology are critical
obstacles. Indeed, RF-WPT implementation and operation require efficient and
cautious strategies and protocols, especially when targeting high-power
charging, which constitutes the scope of this work. Herein, we overview the
main factors affecting the end-to-end PTE of RF-WPT systems and their
multiplicative effect and interdependencies. Moreover, we discuss key
electromagnetic field (EMF) exposure metrics, safety limits, and approaches for
efficient and EMF-aware deployment and operation. Quantitatively, we show that
near-field RF charging may significantly reduce EMF exposure, and thus must be
promoted. We also present our vision of a cyber-physical system for efficient
and safe wireless charging, specify key components and their interrelation, and
illustrate numerically the PTE attained by two modern low-power multi-antenna
architectures in a simple setup. Throughout the paper, we highlight the need
for high end-to-end PTE architectures and charging protocols transparently
complying with EMF exposure regulations and outline relevant challenges and
research directions. This work expands the vision and understanding of modern
RF-WPT technology and constitutes a step towards making the technology
attractive for worldwide commercial exploitation.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12810" title="Abstract">arXiv:2311.12810</a> [<a href="/pdf/2311.12810" title="Download PDF">pdf</a>, <a href="/ps/2311.12810" title="Download PostScript">ps</a>, <a href="/format/2311.12810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combining low-dose CT-based radiomics and metabolomics for early lung  cancer screening support
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zyla%2C+J">Joanna Zyla</a>, 
<a href="/search/cs?searchtype=author&query=Marczyk%2C+M">Michal Marczyk</a>, 
<a href="/search/cs?searchtype=author&query=Prazuch%2C+W">Wojciech Prazuch</a>, 
<a href="/search/cs?searchtype=author&query=Socha%2C+M">Marek Socha</a>, 
<a href="/search/cs?searchtype=author&query=Suwalska%2C+A">Aleksandra Suwalska</a>, 
<a href="/search/cs?searchtype=author&query=Durawa%2C+A">Agata Durawa</a>, 
<a href="/search/cs?searchtype=author&query=Jelitto-Gorska%2C+M">Malgorzata Jelitto-Gorska</a>, 
<a href="/search/cs?searchtype=author&query=Dziadziuszko%2C+K">Katarzyna Dziadziuszko</a>, 
<a href="/search/cs?searchtype=author&query=Szurowska%2C+E">Edyta Szurowska</a>, 
<a href="/search/cs?searchtype=author&query=Rzyman%2C+W">Witold Rzyman</a>, 
<a href="/search/cs?searchtype=author&query=Widlak%2C+P">Piotr Widlak</a>, 
<a href="/search/cs?searchtype=author&query=Polanska%2C+J">Joanna Polanska</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Applications (stat.AP)

</div>
<p class="mathjax">Due to its predominantly asymptomatic or mildly symptomatic progression, lung
cancer is often diagnosed in advanced stages, resulting in poorer survival
rates for patients. As with other cancers, early detection significantly
improves the chances of successful treatment. Early diagnosis can be
facilitated through screening programs designed to detect lung tissue tumors
when they are still small, typically around 3mm in size. However, the analysis
of extensive screening program data is hampered by limited access to medical
experts. In this study, we developed a procedure for identifying potential
malignant neoplastic lesions within lung parenchyma. The system leverages
machine learning (ML) techniques applied to two types of measurements: low-dose
Computed Tomography-based radiomics and metabolomics. Using data from two
Polish screening programs, two ML algorithms were tested, along with various
integration methods, to create a final model that combines both modalities to
support lung cancer screening.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12812" title="Abstract">arXiv:2311.12812</a> [<a href="/pdf/2311.12812" title="Download PDF">pdf</a>, <a href="/ps/2311.12812" title="Download PostScript">ps</a>, <a href="/format/2311.12812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personalization of Affective Models to Enable Neuropsychiatric Digital  Precision Health Interventions: A Feasibility Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kargarandehkordi%2C+A">Ali Kargarandehkordi</a>, 
<a href="/search/cs?searchtype=author&query=Kaisti%2C+M">Matti Kaisti</a>, 
<a href="/search/cs?searchtype=author&query=Washington%2C+P">Peter Washington</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Mobile digital therapeutics for autism spectrum disorder (ASD) often target
emotion recognition and evocation, which is a challenge for children with ASD.
While such mobile applications often use computer vision machine learning (ML)
models to guide the adaptive nature of the digital intervention, a single model
is usually deployed and applied to all children. Here, we explore the potential
of model personalization, or training a single emotion recognition model per
person, to improve the performance of these underlying emotion recognition
models used to guide digital health therapies for children with ASD. We
conducted experiments on the Emognition dataset, a video dataset of human
subjects evoking a series of emotions. For a subset of 10 individuals in the
dataset with a sufficient representation of at least two ground truth emotion
labels, we trained a personalized version of three classical ML models on a set
of 51 features extracted from each video frame. We measured the importance of
each facial feature for all personalized models and observed differing ranked
lists of top features across subjects, motivating the need for model
personalization. We then compared the personalized models against a generalized
model trained using data from all 10 participants. The mean F1-scores achieved
by the personalized models were 90.48%, 92.66%, and 86.40%, respectively. By
contrast, the mean F1-scores reached by non-personalized models trained on
different human subjects and evaluated using the same test set were 88.55%,
91.78%, and 80.42%, respectively. The personalized models outperformed the
generalized models for 7 out of 10 participants. PCA analyses on the remaining
3 participants revealed relatively facial configuration differences between
emotion labels within each subject, suggesting that personalized ML will fail
when the variation among data points within a subjects data is too low.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12813" title="Abstract">arXiv:2311.12813</a> [<a href="/pdf/2311.12813" title="Download PDF">pdf</a>, <a href="/format/2311.12813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Targeted Activation Penalties Help CNNs Ignore Spurious Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dekai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+M">Matthew Williams</a>, 
<a href="/search/cs?searchtype=author&query=Toni%2C+F">Francesca Toni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages including appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Neural networks (NNs) can learn to rely on spurious signals in the training
data, leading to poor generalisation. Recent methods tackle this problem by
training NNs with additional ground-truth annotations of such signals. These
methods may, however, let spurious signals re-emerge in deep convolutional NNs
(CNNs). We propose Targeted Activation Penalty (TAP), a new method tackling the
same problem by penalising activations to control the re-emergence of spurious
signals in deep CNNs, while also lowering training times and memory usage. In
addition, ground-truth annotations can be expensive to obtain. We show that TAP
still works well with annotations generated by pre-trained models as effective
substitutes of ground-truth annotations. We demonstrate the power of TAP
against two state-of-the-art baselines on the MNIST benchmark and on two
clinical image datasets, using four different CNN architectures.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12815" title="Abstract">arXiv:2311.12815</a> [<a href="/pdf/2311.12815" title="Download PDF">pdf</a>, <a href="/format/2311.12815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proposing an intelligent mesh smoothing method with graph neural  networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhichao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinhai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junjun Yan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jie Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In CFD, mesh smoothing methods are commonly utilized to refine the mesh
quality to achieve high-precision numerical simulations. Specifically,
optimization-based smoothing is used for high-quality mesh smoothing, but it
incurs significant computational overhead. Pioneer works improve its smoothing
efficiency by adopting supervised learning to learn smoothing methods from
high-quality meshes. However, they pose difficulty in smoothing the mesh nodes
with varying degrees and also need data augmentation to address the node input
sequence problem. Additionally, the required labeled high-quality meshes
further limit the applicability of the proposed method. In this paper, we
present GMSNet, a lightweight neural network model for intelligent mesh
smoothing. GMSNet adopts graph neural networks to extract features of the
node's neighbors and output the optimal node position. During smoothing, we
also introduce a fault-tolerance mechanism to prevent GMSNet from generating
negative volume elements. With a lightweight model, GMSNet can effectively
smoothing mesh nodes with varying degrees and remain unaffected by the order of
input data. A novel loss function, MetricLoss, is also developed to eliminate
the need for high-quality meshes, which provides a stable and rapid convergence
during training. We compare GMSNet with commonly used mesh smoothing methods on
two-dimensional triangle meshes. The experimental results show that GMSNet
achieves outstanding mesh smoothing performances with 5% model parameters of
the previous model, and attains 8.62 times faster than optimization-based
smoothing.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12816" title="Abstract">arXiv:2311.12816</a> [<a href="/pdf/2311.12816" title="Download PDF">pdf</a>, <a href="/ps/2311.12816" title="Download PostScript">ps</a>, <a href="/format/2311.12816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evolution of Convolutional Neural Network (CNN): Compute vs Memory  bandwidth for Edge AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chenna%2C+D">Dwith Chenna</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Convolutional Neural Networks (CNNs) have greatly influenced the field of
Embedded Vision and Edge Artificial Intelligence (AI), enabling powerful
machine learning capabilities on resource-constrained devices. This article
explores the relationship between CNN compute requirements and memory bandwidth
in the context of Edge AI. We delve into the historical progression of CNN
architectures, from the early pioneering models to the current state-of-the-art
designs, highlighting the advancements in compute-intensive operations. We
examine the impact of increasing model complexity on both computational
requirements and memory access patterns. The paper presents a comparison
analysis of the evolving trade-off between compute demands and memory bandwidth
requirements in CNNs. This analysis provides insights into designing efficient
architectures and potential hardware accelerators in enhancing CNN performance
on edge devices.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12817" title="Abstract">arXiv:2311.12817</a> [<a href="/pdf/2311.12817" title="Download PDF">pdf</a>, <a href="/format/2311.12817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Face Compression for Metaverse: A Compact 3D Descriptor Based  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Binzhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bolin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yan Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this letter, we envision a new metaverse communication paradigm for
virtual avatar faces, and develop the semantic face compression with compact 3D
facial descriptors. The fundamental principle is that the communication of
virtual avatar faces primarily emphasizes the conveyance of semantic
information. In light of this, the proposed scheme offers the advantages of
being highly flexible, efficient and semantically meaningful. The semantic face
compression, which allows the communication of the descriptors for artificial
intelligence based understanding, could facilitate numerous applications
without the involvement of humans in metaverse. The promise of the proposed
paradigm is also demonstrated by performance comparisons with the
state-of-the-art video coding standard, Versatile Video Coding. A significant
improvement in terms of rate-accuracy performance has been achieved. The
proposed scheme is expected to enable numerous applications, such as digital
human communication based on machine analysis, and to form the cornerstone of
interaction and communication in the metaverse.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12818" title="Abstract">arXiv:2311.12818</a> [<a href="/pdf/2311.12818" title="Download PDF">pdf</a>, <a href="/format/2311.12818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Manifold Path Guiding for Importance Sampling Specular Chains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zhimin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+P">Pengpei Hong</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jie Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+C">Changqing Zou</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yanwen Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+L">Ling-Qi Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Complex visual effects such as caustics are often produced by light paths
containing multiple consecutive specular vertices (dubbed specular chains),
which pose a challenge to unbiased estimation in Monte Carlo rendering. In this
work, we study the light transport behavior within a sub-path that is comprised
of a specular chain and two non-specular separators. We show that the specular
manifolds formed by all the sub-paths could be exploited to provide coherence
among sub-paths. By reconstructing continuous energy distributions from
historical and coherent sub-paths, seed chains can be generated in the context
of importance sampling and converge to admissible chains through manifold
walks. We verify that importance sampling the seed chain in the continuous
space reaches the goal of importance sampling the discrete admissible specular
chain. Based on these observations and theoretical analyses, a progressive
pipeline, manifold path guiding, is designed and implemented to importance
sample challenging paths featuring long specular chains. To our best knowledge,
this is the first general framework for importance sampling discrete specular
chains in regular Monte Carlo rendering. Extensive experiments demonstrate that
our method outperforms state-of-the-art unbiased solutions with up to 40x
variance reduction, especially in typical scenes containing long specular
chains and complex visibility.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12819" title="Abstract">arXiv:2311.12819</a> [<a href="/pdf/2311.12819" title="Download PDF">pdf</a>, <a href="/format/2311.12819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fixing the problems of deep neural networks will require better training  data and learning algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Linsley%2C+D">Drew Linsley</a>, 
<a href="/search/cs?searchtype=author&query=Serre%2C+T">Thomas Serre</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a commentary in Behavioral and Brain Sciences
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Bowers and colleagues argue that DNNs are poor models of biological vision
because they often learn to rival human accuracy by relying on strategies that
differ markedly from those of humans. We show that this problem is worsening as
DNNs are becoming larger-scale and increasingly more accurate, and prescribe
methods for building DNNs that can reliably model biological vision.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12820" title="Abstract">arXiv:2311.12820</a> [<a href="/pdf/2311.12820" title="Download PDF">pdf</a>, <a href="/format/2311.12820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MSG-BART: Multi-granularity Scene Graph-Enhanced Encoder-Decoder  Language Model for Video-grounded Dialogue Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongcheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hui Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pingjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages,3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Generating dialogue grounded in videos requires a high level of understanding
and reasoning about the visual scenes in the videos. However, existing large
visual-language models are not effective due to their latent features and
decoder-only structure, especially with respect to spatio-temporal relationship
reasoning. In this paper, we propose a novel approach named MSG-BART, which
enhances the integration of video information by incorporating a
multi-granularity spatio-temporal scene graph into an encoder-decoder
pre-trained language model. Specifically, we integrate the global and local
scene graph into the encoder and decoder, respectively, to improve both overall
perception and target reasoning capability. To further improve the information
selection capability, we propose a multi-pointer network to facilitate
selection between text and video. Extensive experiments are conducted on three
video-grounded dialogue benchmarks, which show the significant superiority of
the proposed MSG-BART compared to a range of state-of-the-art approaches.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12821" title="Abstract">arXiv:2311.12821</a> [<a href="/pdf/2311.12821" title="Download PDF">pdf</a>, <a href="/format/2311.12821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing The Rate-Distortion-Computation Frontier For Neural Image  Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Minnen%2C+D">David Minnen</a>, 
<a href="/search/cs?searchtype=author&query=Johnston%2C+N">Nick Johnston</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in 2023 IEEE International Conference on Image Processing (ICIP)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">The rate-distortion performance of neural image compression models has
exceeded the state-of-the-art for non-learned codecs, but neural codecs are
still far from widespread deployment and adoption. The largest obstacle is
having efficient models that are feasible on a wide variety of consumer
hardware. Comparative research and evaluation is difficult due to the lack of
standard benchmarking platforms and due to variations in hardware architectures
and test environments. Through our rate-distortion-computation (RDC) study we
demonstrate that neither floating-point operations (FLOPs) nor runtime are
sufficient on their own to accurately rank neural compression methods. We also
explore the RDC frontier, which leads to a family of model architectures with
the best empirical trade-off between computational requirements and RD
performance. Finally, we identify a novel neural compression architecture that
yields state-of-the-art RD performance with rate savings of 23.1% over BPG
(7.0% over VTM and 3.0% over ELIC) without requiring significantly more FLOPs
than other learning-based codecs.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12822" title="Abstract">arXiv:2311.12822</a> [<a href="/pdf/2311.12822" title="Download PDF">pdf</a>, <a href="/format/2311.12822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Note on Ribbon-based Biharmonic Surface Patches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Vaitkus%2C+M">M&#xe1;rton Vaitkus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">In this short note we describe a simple adaptation of biharmonic surfaces to
interpolate boundary cross-derivatives given in ribbon form, and compare with
the recently proposed Generalized B-spline patches.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12823" title="Abstract">arXiv:2311.12823</a> [<a href="/pdf/2311.12823" title="Download PDF">pdf</a>, <a href="/format/2311.12823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EWasteNet: A Two-Stream Data Efficient Image Transformer Approach for  E-Waste Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Islam%2C+N">Niful Islam</a>, 
<a href="/search/cs?searchtype=author&query=Jony%2C+M+M+H">Md. Mehedi Hasan Jony</a>, 
<a href="/search/cs?searchtype=author&query=Hasan%2C+E">Emam Hasan</a>, 
<a href="/search/cs?searchtype=author&query=Sutradhar%2C+S">Sunny Sutradhar</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+A">Atikur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+M">Md. Motaharul Islam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE 8th International Conference On Software Engineering and
  Computer Systems (ICSECS), Penang, Malaysia, 2023, pp. 435-440
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Improper disposal of e-waste poses global environmental and health risks,
raising serious concerns. The accurate classification of e-waste images is
critical for efficient management and recycling. In this paper, we have
presented a comprehensive dataset comprised of eight different classes of
images of electronic devices named the E-Waste Vision Dataset. We have also
presented EWasteNet, a novel two-stream approach for precise e-waste image
classification based on a data-efficient image transformer (DeiT). The first
stream of EWasteNet passes through a sobel operator that detects the edges
while the second stream is directed through an Atrous Spatial Pyramid Pooling
and attention block where multi-scale contextual information is captured. We
train both of the streams simultaneously and their features are merged at the
decision level. The DeiT is used as the backbone of both streams. Extensive
analysis of the e-waste dataset indicates the usefulness of our method,
providing 96% accuracy in e-waste classification. The proposed approach
demonstrates significant usefulness in addressing the global concern of e-waste
management. It facilitates efficient waste management and recycling by
accurately classifying e-waste images, reducing health and safety hazards
associated with improper disposal.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12824" title="Abstract">arXiv:2311.12824</a> [<a href="/pdf/2311.12824" title="Download PDF">pdf</a>, <a href="/ps/2311.12824" title="Download PostScript">ps</a>, <a href="/format/2311.12824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative Analysis of Shear Strength Prediction Models for Reinforced  Concrete Slab-Column Connections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wahab%2C+S">Sarmed Wahab</a>, 
<a href="/search/cs?searchtype=author&query=Mahmoudabadi%2C+N+S">Nasim Shakouri Mahmoudabadi</a>, 
<a href="/search/cs?searchtype=author&query=Waqas%2C+S">Sarmad Waqas</a>, 
<a href="/search/cs?searchtype=author&query=Herl%2C+N">Nouman Herl</a>, 
<a href="/search/cs?searchtype=author&query=Iqbal%2C+M">Muhammad Iqbal</a>, 
<a href="/search/cs?searchtype=author&query=Alam%2C+K">Khurshid Alam</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+A">Afaq Ahmad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 Pages,25 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This research aims at comparative analysis of shear strength prediction at
slab-column connection, unifying machine learning, design codes and Finite
Element Analysis. Current design codes (CDCs) of ACI 318-19 (ACI), Eurocode 2
(EC2), Compressive Force Path (CFP) method, Feed Forward Neural Network (FNN)
based Artificial Neural Network (ANN), PSO-based FNN (PSOFNN), and BAT
algorithm-based BATFNN are used. The study is complemented with FEA of slab for
validating the experimental results and machine learning predictions.In the
case of hybrid models of PSOFNN and BATFNN, mean square error is used as an
objective function to obtain the optimized values of the weights, that are used
by Feed Forward Neural Network to perform predictions on the slab data. Seven
different models of PSOFNN, BATFNN, and FNN are trained on this data and the
results exhibited that PSOFNN is the best model overall. PSOFNN has the best
results for SCS=1 with highest value of R as 99.37% and lowest of MSE, and MAE
values of 0.0275%, and 1.214% respectively which are better than the best FNN
model for SCS=4 having the values of R, MSE, and MAE as 97.464%, 0.0492%, and
1.43%, respectively.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12825" title="Abstract">arXiv:2311.12825</a> [<a href="/pdf/2311.12825" title="Download PDF">pdf</a>, <a href="/ps/2311.12825" title="Download PostScript">ps</a>, <a href="/format/2311.12825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A PSO Based Method to Generate Actionable Counterfactuals for High  Dimensional Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shekhar%2C+S">Shashank Shekhar</a>, 
<a href="/search/cs?searchtype=author&query=Salim%2C+A">Asif Salim</a>, 
<a href="/search/cs?searchtype=author&query=Bansode%2C+A">Adesh Bansode</a>, 
<a href="/search/cs?searchtype=author&query=Jinturkar%2C+V">Vivaswan Jinturkar</a>, 
<a href="/search/cs?searchtype=author&query=Nayak%2C+A">Anirudha Nayak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted in IEEE CSDE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">Counterfactual explanations (CFE) are methods that explain a machine learning
model by giving an alternate class prediction of a data point with some minimal
changes in its features. It helps the users to identify their data attributes
that caused an undesirable prediction like a loan or credit card rejection. We
describe an efficient and an actionable counterfactual (CF) generation method
based on particle swarm optimization (PSO). We propose a simple objective
function for the optimization of the instance-centric CF generation problem.
The PSO brings in a lot of flexibility in terms of carrying out multi-objective
optimization in large dimensions, capability for multiple CF generation, and
setting box constraints or immutability of data attributes. An algorithm is
proposed that incorporates these features and it enables greater control over
the proximity and sparsity properties over the generated CFs. The proposed
algorithm is evaluated with a set of action-ability metrics in real-world
datasets, and the results were superior compared to that of the
state-of-the-arts.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12826" title="Abstract">arXiv:2311.12826</a> [<a href="/pdf/2311.12826" title="Download PDF">pdf</a>, <a href="/format/2311.12826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LiveChat: Video Comment Generation from Audio-Visual Multimodal Contexts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lalanne%2C+J">Julien Lalanne</a>, 
<a href="/search/cs?searchtype=author&query=Bournet%2C+R">Raphael Bournet</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yi Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Live commenting on video, a popular feature of live streaming platforms,
enables viewers to engage with the content and share their comments, reactions,
opinions, or questions with the streamer or other viewers while watching the
video or live stream. It presents a challenging testbed for AI agents, which
involves the simultaneous understanding of audio-visual multimodal contexts
from live streams and the ability to interact with human viewers through
dialogue. As existing live streaming-based comments datasets contain limited
categories and lack a diversity, we create a large-scale audio-visual
multimodal dialogue dataset to facilitate the development of live commenting
technologies. The data is collected from Twitch, with 11 different categories
and 575 streamers for a total of 438 hours of video and 3.2 million comments.
Moreover, we propose a novel multimodal generation model capable of generating
live comments that align with the temporal and spatial events within the video,
as well as with the ongoing multimodal dialogue context. Our initial results
have demonstrated the effectiveness of the proposed model, providing a robust
foundation for further research and practical applications in the field of live
video interaction.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12827" title="Abstract">arXiv:2311.12827</a> [<a href="/pdf/2311.12827" title="Download PDF">pdf</a>, <a href="/format/2311.12827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personalized Guidelines for Design, Implementation and Evaluation of  Anti-phishing Interventions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarker%2C+O">Orvila Sarker</a>, 
<a href="/search/cs?searchtype=author&query=Haggag%2C+S">Sherif Haggag</a>, 
<a href="/search/cs?searchtype=author&query=Jayatilaka%2C+A">Asangi Jayatilaka</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chelsea Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article is accepted for publication at the IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Background: Current anti-phishing interventions, which typically involve
one-size-fits-all solutions, suffer from limitations such as inadequate
usability and poor implementation. Human-centric challenges in anti-phishing
technologies remain little understood. Research shows a deficiency in the
comprehension of end-user preferences, mental states, and cognitive
requirements by developers and practitioners involved in the design,
implementation, and evaluation of anti-phishing interventions. Aims: This study
addresses the current lack of resources and guidelines for the design,
implementation and evaluation of anti-phishing interventions, by presenting
personalized guidelines to the developers and practitioners. Method: Through an
analysis of 53 academic studies and 16 items of grey literature studies, we
systematically identified the challenges and recommendations within the
anti-phishing interventions, across different practitioner groups and
intervention types. Results: We identified 22 dominant factors at the
individual, technical, and organizational levels, that affected the
effectiveness of anti-phishing interventions and, accordingly, reported 41
guidelines based on the suggestions and recommendations provided in the studies
to improve the outcome of anti-phishing interventions. Conclusions: Our
dominant factors can help developers and practitioners enhance their
understanding of human-centric, technical and organizational issues in
anti-phishing interventions. Our customized guidelines can empower developers
and practitioners to counteract phishing attacks.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12829" title="Abstract">arXiv:2311.12829</a> [<a href="/pdf/2311.12829" title="Download PDF">pdf</a>, <a href="/format/2311.12829" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intelligent Knee Sleeves: A Real-time Multimodal Dataset for 3D Lower  Body Motion Estimation Using Smart Textile
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tashakori%2C+A">Arvin Tashakori</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zenan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Servati%2C+A">Amir Servati</a>, 
<a href="/search/cs?searchtype=author&query=Narayana%2C+H">Harishkumar Narayana</a>, 
<a href="/search/cs?searchtype=author&query=Soltanian%2C+S">Saeid Soltanian</a>, 
<a href="/search/cs?searchtype=author&query=Yeap%2C+R+Y">Rou Yi Yeap</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+M+H">Meng Han Ma</a>, 
<a href="/search/cs?searchtype=author&query=Toy%2C+L">Lauren Toy</a>, 
<a href="/search/cs?searchtype=author&query=Servati%2C+P">Peyman Servati</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Thirty-seventh Conference on Neural Information Processing Systems (Neurips) D&amp;B Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The kinematics of human movements and locomotion are closely linked to the
activation and contractions of muscles. To investigate this, we present a
multimodal dataset with benchmarks collected using a novel pair of Intelligent
Knee Sleeves (Texavie MarsWear Knee Sleeves) for human pose estimation. Our
system utilizes synchronized datasets that comprise time-series data from the
Knee Sleeves and the corresponding ground truth labels from the visualized
motion capture camera system. We employ these to generate 3D human models
solely based on the wearable data of individuals performing different
activities. We demonstrate the effectiveness of this camera-free system and
machine learning algorithms in the assessment of various movements and
exercises, including extension to unseen exercises and individuals. The results
show an average error of 7.21 degrees across all eight lower body joints when
compared to the ground truth, indicating the effectiveness and reliability of
the Knee Sleeve system for the prediction of different lower body joints beyond
the knees. The results enable human pose estimation in a seamless manner
without being limited by visual occlusion or the field of view of cameras. Our
results show the potential of multimodal wearable sensing in a variety of
applications from home fitness to sports, healthcare, and physical
rehabilitation focusing on pose and movement estimation.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12830" title="Abstract">arXiv:2311.12830</a> [<a href="/pdf/2311.12830" title="Download PDF">pdf</a>, <a href="/format/2311.12830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nature Inspired Evolutionary Swarm Optimizers for Biomedical Image and  Signal Processing -- A Systematic Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adhikary%2C+S">Subhrangshu Adhikary</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The challenge of finding a global optimum in a solution search space with
limited resources and higher accuracy has given rise to several optimization
algorithms. Generally, the gradient-based optimizers converge to the global
solution very accurately, but they often require a large number of iterations
to find the solution. Researchers took inspiration from different natural
phenomena and behaviours of many living organisms to develop algorithms that
can solve optimization problems much quicker with high accuracy. These
algorithms are called nature-inspired meta-heuristic optimization algorithms.
These can be used for denoising signals, updating weights in a deep neural
network, and many other cases. In the state-of-the-art, there are no systematic
reviews available that have discussed the applications of nature-inspired
algorithms on biomedical signal processing. The paper solves that gap by
discussing the applications of such algorithms in biomedical signal processing
and also provides an updated survey of the application of these algorithms in
biomedical image processing. The paper reviews 28 latest peer-reviewed relevant
articles and 26 nature-inspired algorithms and segregates them into thoroughly
explored, lesser explored and unexplored categories intending to help readers
understand the reliability and exploration stage of each of these algorithms.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12831" title="Abstract">arXiv:2311.12831</a> [<a href="/pdf/2311.12831" title="Download PDF">pdf</a>, <a href="/format/2311.12831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ECNR: Efficient Compressive Neural Representation of Time-Varying  Volumetric Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+K">Kaiyuan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chaoli Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Due to its conceptual simplicity and generality, compressive neural
representation has emerged as a promising alternative to traditional
compression methods for managing massive volumetric datasets. The
state-of-the-art neural compression solution, neurcomp, however, utilizes a
single large multilayer perceptron (MLP) to encode the global volume, incurring
slow training and inference. This paper presents an efficient compressive
neural representation (ECNR) solution that improves upon neurcomp to handle
large-scale time-varying datasets. At the heart of our approach is a multiscale
structure that uses the Laplacian pyramid for adaptive signal fitting via
implicit neural representation. We leverage multiple small MLPs at each scale
for fitting local content or residual blocks. By assigning similar blocks to
the same MLP via size uniformization, we enable balanced parallelization among
MLPs to significantly speed up training and inference. A deep compression
strategy is then employed to compact the resulting model. We demonstrate the
effectiveness of ECNR with multiple datasets and compare it with neurcomp and
two state-of-the-art conventional compression methods (SZ3 and TTHRESH). Our
results position ECNR as a promising alternative to neurcomp for scientific
data compression.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12832" title="Abstract">arXiv:2311.12832</a> [<a href="/pdf/2311.12832" title="Download PDF">pdf</a>, <a href="/format/2311.12832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward effective protection against diffusion based mimicry through  score distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+H">Haotian Xue</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+C">Chumeng Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaoyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yongxin Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> code is available in <a href="https://github.com/xavihart/Diff-Protect">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">While generative diffusion models excel in producing high-quality images,
they can also be misused to mimic authorized images, posing a significant
threat to AI systems. Efforts have been made to add calibrated perturbations to
protect images from diffusion-based mimicry pipelines. However, most of the
existing methods are too ineffective and even impractical to be used by
individual users due to their high computation and memory requirements. In this
work, we present novel findings on attacking latent diffusion models (LDM) and
propose new plug-and-play strategies for more effective protection. In
particular, we explore the bottleneck in attacking an LDM, discovering that the
encoder module rather than the denoiser module is the vulnerable point. Based
on this insight, we present our strategy using Score Distillation Sampling
(SDS) to double the speed of protection and reduce memory occupation by half
without compromising its strength. Additionally, we provide a robust protection
strategy by counterintuitively minimizing the semantic loss, which can assist
in generating more natural perturbations. Finally, we conduct extensive
experiments to substantiate our findings and comprehensively evaluate our newly
proposed strategies. We hope our insights and protective measures can
contribute to better defense against malicious diffusion-based mimicry,
advancing the development of secure AI systems. The code is available in
https://github.com/xavihart/Diff-Protect
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12833" title="Abstract">arXiv:2311.12833</a> [<a href="/pdf/2311.12833" title="Download PDF">pdf</a>, <a href="/format/2311.12833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HPC-GPT: Integrating Large Language Model for High-Performance Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+X">Xianzhong Ding</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Le Chen</a>, 
<a href="/search/cs?searchtype=author&query=Emani%2C+M">Murali Emani</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+C">Chunhua Liao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+P">Pei-Hung Lin</a>, 
<a href="/search/cs?searchtype=author&query=Vanderbruggen%2C+T">Tristan Vanderbruggen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhen Xie</a>, 
<a href="/search/cs?searchtype=author&query=Cerpa%2C+A+E">Alberto E. Cerpa</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+W">Wan Du</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Large Language Models (LLMs), including the LLaMA model, have exhibited their
efficacy across various general-domain natural language processing (NLP) tasks.
However, their performance in high-performance computing (HPC) domain tasks has
been less than optimal due to the specialized expertise required to interpret
the model responses. In response to this challenge, we propose HPC-GPT, a novel
LLaMA-based model that has been supervised fine-tuning using generated QA
(Question-Answer) instances for the HPC domain. To evaluate its effectiveness,
we concentrate on two HPC tasks: managing AI models and datasets for HPC, and
data race detection. By employing HPC-GPT, we demonstrate comparable
performance with existing methods on both tasks, exemplifying its excellence in
HPC-related scenarios. Our experiments on open-source benchmarks yield
extensive results, underscoring HPC-GPT's potential to bridge the performance
gap between LLMs and HPC-specific tasks. With HPC-GPT, we aim to pave the way
for LLMs to excel in HPC domains, simplifying the utilization of language
models in complex computing applications.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12835" title="Abstract">arXiv:2311.12835</a> [<a href="/pdf/2311.12835" title="Download PDF">pdf</a>, <a href="/ps/2311.12835" title="Download PostScript">ps</a>, <a href="/format/2311.12835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faedo-Galerkin approximation technique to non-instantaneous impulsive  abstract functional differential equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ansari%2C+S">Shahin Ansari</a>, 
<a href="/search/math?searchtype=author&query=Malik%2C+M">Muslim Malik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This manuscript is devoted to the study of a class of nonlinear
non-instantaneous impulsive first order abstract retarded type functional
differential equations in an arbitrary separable Hilbert space H. A new set of
sufficient conditions are derived to ensure the existence of approximate
solutions. Finite dimensional approximations are derived using the projection
operator. Through the utilization of analytic semigroup theory, fixed point
theorem and Gronwall inequality, we establish the uniqueness and convergence of
approximate solutions. Additionally, we study the Faedo-Galerkin approximate
solutions and establish some convergence results. Finally, an illustrative
instance demonstrating the applications of obtained results to partial
differential equations is provided.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12836" title="Abstract">arXiv:2311.12836</a> [<a href="/pdf/2311.12836" title="Download PDF">pdf</a>, <a href="/ps/2311.12836" title="Download PostScript">ps</a>, <a href="/format/2311.12836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-based association analysis for medical imaging using latent-space  geometric confounder correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xianjing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Vernooij%2C+M+W">Meike W. Vernooij</a>, 
<a href="/search/cs?searchtype=author&query=Wolvius%2C+E+B">Eppo B. Wolvius</a>, 
<a href="/search/cs?searchtype=author&query=Roshchupkin%2C+G+V">Gennady V. Roshchupkin</a>, 
<a href="/search/cs?searchtype=author&query=Bron%2C+E+E">Esther E. Bron</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages; 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">AI has greatly enhanced medical image analysis, yet its use in
epidemiological population imaging studies remains limited due to visualization
challenges in non-linear models and lack of confounder control. Addressing
this, we introduce an AI method emphasizing semantic feature interpretation and
resilience against multiple confounders. Our approach's merits are tested in
three scenarios: extracting confounder-free features from a 2D synthetic
dataset; examining the association between prenatal alcohol exposure and
children's facial shapes using 3D mesh data; exploring the relationship between
global cognition and brain images with a 3D MRI dataset. Results confirm our
method effectively reduces confounder influences, establishing less confounded
associations. Additionally, it provides a unique visual representation,
highlighting specific image alterations due to identified correlations.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12838" title="Abstract">arXiv:2311.12838</a> [<a href="/pdf/2311.12838" title="Download PDF">pdf</a>, <a href="/ps/2311.12838" title="Download PostScript">ps</a>, <a href="/format/2311.12838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards parallel intelligence: an interdisciplinary solution for complex  systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhengqiu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+S">Sihang Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jincai Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xin Lu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Weiyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+C">Chuan Ai</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kuihua Huang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Cheng He</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yucheng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fei-Yue Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">The growing complexity of real-world systems necessitates interdisciplinary
solutions to confront myriad challenges in modeling, analysis, management, and
control. To meet these demands, the parallel systems method rooted in
Artificial systems, Computational experiments, and Parallel execution (ACP)
approach has been developed. The method cultivates a cycle, termed parallel
intelligence, which iteratively creates data, acquires knowledge, and refines
the actual system. Over the past two decades, the parallel systems method has
continuously woven advanced knowledge and technologies from various
disciplines, offering versatile interdisciplinary solutions for complex systems
across diverse fields. This review explores the origins and fundamental
concepts of the parallel systems method, showcasing its accomplishments as a
diverse array of parallel technologies and applications, while also
prognosticating potential challenges. We posit that this method will
considerably augment sustainable development while enhancing interdisciplinary
communication and cooperation.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12839" title="Abstract">arXiv:2311.12839</a> [<a href="/pdf/2311.12839" title="Download PDF">pdf</a>, <a href="/format/2311.12839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Review of Deep Reinforcement Learning in Serverless Computing:  Function Scheduling and Resource Auto-Scaling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Majid%2C+A+Y">Amjad Yousef Majid</a>, 
<a href="/search/cs?searchtype=author&query=Marin%2C+E">Eduard Marin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In the rapidly evolving field of serverless computing, efficient function
scheduling and resource scaling are critical for optimizing performance and
cost. This paper presents a comprehensive review of the application of Deep
Reinforcement Learning (DRL) techniques in these areas. We begin by providing
an overview of serverless computing, highlighting its benefits and challenges,
with a particular focus on function scheduling and resource scaling. We then
delve into the principles of deep reinforcement learning (DRL) and its
potential for addressing these challenges. A systematic review of recent
studies applying DRL to serverless computing is presented, covering various
algorithms, models, and performances. Our analysis reveals that DRL, with its
ability to learn and adapt from an environment, shows promising results in
improving the efficiency of function scheduling and resource scaling in
serverless computing. However, several challenges remain, including the need
for more realistic simulation environments, handling of cold starts, and the
trade-off between learning time and scheduling performance. We conclude by
discussing potential future directions for this research area, emphasizing the
need for more robust DRL models, better benchmarking methods, and the
exploration of multi-agent reinforcement learning for more complex serverless
architectures. This review serves as a valuable resource for researchers and
practitioners aiming to understand and advance the application of DRL in
serverless computing.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12840" title="Abstract">arXiv:2311.12840</a> [<a href="/pdf/2311.12840" title="Download PDF">pdf</a>, <a href="/format/2311.12840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wafer Map Defect Patterns Semi-Supervised Classification Using Latent  Vector Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Q">Qiyu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiaoyan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zeng Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 2 figures, CIS confernece
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">As the globalization of semiconductor design and manufacturing processes
continues, the demand for defect detection during integrated circuit
fabrication stages is becoming increasingly critical, playing a significant
role in enhancing the yield of semiconductor products. Traditional wafer map
defect pattern detection methods involve manual inspection using electron
microscopes to collect sample images, which are then assessed by experts for
defects. This approach is labor-intensive and inefficient. Consequently, there
is a pressing need to develop a model capable of automatically detecting
defects as an alternative to manual operations. In this paper, we propose a
method that initially employs a pre-trained VAE model to obtain the fault
distribution information of the wafer map. This information serves as guidance,
combined with the original image set for semi-supervised model training. During
the semi-supervised training, we utilize a teacher-student network for
iterative learning. The model presented in this paper is validated on the
benchmark dataset WM-811K wafer dataset. The experimental results demonstrate
superior classification accuracy and detection performance compared to
state-of-the-art models, fulfilling the requirements for industrial
applications. Compared to the original architecture, we have achieved
significant performance improvement.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12841" title="Abstract">arXiv:2311.12841</a> [<a href="/pdf/2311.12841" title="Download PDF">pdf</a>, <a href="/format/2311.12841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tool Wear Segmentation in Blanking Processes with Fully Convolutional  Networks based Digital Image Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schlegel%2C+C">Clemens Schlegel</a>, 
<a href="/search/cs?searchtype=author&query=Molitor%2C+D+A">Dirk Alexander Molitor</a>, 
<a href="/search/cs?searchtype=author&query=Kubik%2C+C">Christian Kubik</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+D+M">Daniel Michael Martin</a>, 
<a href="/search/cs?searchtype=author&query=Groche%2C+P">Peter Groche</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">The extend of tool wear significantly affects blanking processes and has a
decisive impact on product quality and productivity. For this reason, numerous
scientists have addressed their research to wear monitoring systems in order to
identify or even predict critical wear at an early stage. Existing approaches
are mainly based on indirect monitoring using time series, which are used to
detect critical wear states via thresholds or machine learning models.
Nevertheless, differentiation between types of wear phenomena affecting the
tool during blanking as well as quantification of worn surfaces is still
limited in practice. While time series data provides partial insights into wear
occurrence and evolution, direct monitoring techniques utilizing image data
offer a more comprehensive perspective and increased robustness when dealing
with varying process parameters. However, acquiring and processing this data in
real-time is challenging. In particular, high dynamics combined with increasing
strokes rates as well as the high dimensionality of image data have so far
prevented the development of direct image-based monitoring systems. For this
reason, this paper demonstrates how high-resolution images of tools at 600 spm
can be captured and subsequently processed using semantic segmentation deep
learning algorithms, more precisely Fully Convolutional Networks (FCN). 125,000
images of the tool are taken from successive strokes, and microscope images are
captured to investigate the worn surfaces. Based on findings from the
microscope images, selected images are labeled pixel by pixel according to
their wear condition and used to train a FCN (U-Net).
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12845" title="Abstract">arXiv:2311.12845</a> [<a href="/pdf/2311.12845" title="Download PDF">pdf</a>, <a href="/ps/2311.12845" title="Download PostScript">ps</a>, <a href="/format/2311.12845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Defocus-Blur Region Detection Approach Based on DCT Feature and  PCNN Structure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Basar%2C+S">Sadia Basar</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+M">Mushtaq Ali</a>, 
<a href="/search/cs?searchtype=author&query=Waheed%2C+A">Abdul Waheed</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+M">Muneer Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Miraz%2C+M+H">Mahdi H. Miraz</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Access, 29 August 2023, Vol. 7, Electronic ISSN: 2169-3536,
  pp. 94945-94961, https://ieeexplore.ieee.org/document/10233857
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The motion or out-of-focus effect in digital images is the main reason for
the blurred regions in defocused-blurred images. It may adversely affect
various image features such as texture, pixel, and region. Therefore, it is
important to detect in-focused objects in defocused-blurred images after the
segmentation of blurred and non-blurred regions. The state-of-the-art
techniques are prone to noisy pixels, and their local descriptors for
developing segmentation metrics are also complex. To address these issues, this
research, therefore, proposed a novel and hybrid-focused detection approach
based on Discrete Cosine Transform (DCT) coefficients and PC Neural Net (PCNN)
structure. The proposed approach partially resolves the limitations of the
existing contrast schemes to detect in-focused smooth objects from the
out-of-focused smooth regions in the defocus dataset. The visual and
quantitative evaluation illustrates that the proposed approach outperformed in
terms of accuracy and efficiency to referenced algorithms. The highest F-score
of the proposed approach on Zhao's dataset is 0.7940 whereas on Shi's dataset
is 0.9178.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12847" title="Abstract">arXiv:2311.12847</a> [<a href="/pdf/2311.12847" title="Download PDF">pdf</a>, <a href="/format/2311.12847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CopyScope: Model-level Copyright Infringement Quantification in the  Diffusion Workflow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Junlei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jiashi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xuetao Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Web-based AI image generation has become an innovative art form that can
generate novel artworks with the rapid development of the diffusion model.
However, this new technique brings potential copyright infringement risks as it
may incorporate the existing artworks without the owners' consent. Copyright
infringement quantification is the primary and challenging step towards
AI-generated image copyright traceability. Previous work only focused on data
attribution from the training data perspective, which is unsuitable for tracing
and quantifying copyright infringement in practice because of the following
reasons: (1) the training datasets are not always available in public; (2) the
model provider is the responsible party, not the image. Motivated by this, in
this paper, we propose CopyScope, a new framework to quantify the infringement
of AI-generated images from the model level. We first rigorously identify
pivotal components within the AI image generation pipeline. Then, we propose to
take advantage of Fr\'echet Inception Distance (FID) to effectively capture the
image similarity that fits human perception naturally. We further propose the
FID-based Shapley algorithm to evaluate the infringement contribution among
models. Extensive experiments demonstrate that our work not only reveals the
intricacies of infringement quantification but also effectively depicts the
infringing models quantitatively, thus promoting accountability in AI
image-generation tasks.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12848" title="Abstract">arXiv:2311.12848</a> [<a href="/pdf/2311.12848" title="Download PDF">pdf</a>, <a href="/format/2311.12848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lightweight Knowledge Representations for Automating Data Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sterbentz%2C+M">Marko Sterbentz</a>, 
<a href="/search/cs?searchtype=author&query=Barrie%2C+C">Cameron Barrie</a>, 
<a href="/search/cs?searchtype=author&query=Hooshmand%2C+D">Donna Hooshmand</a>, 
<a href="/search/cs?searchtype=author&query=Shahi%2C+S">Shubham Shahi</a>, 
<a href="/search/cs?searchtype=author&query=Dutta%2C+A">Abhratanu Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Pack%2C+H">Harper Pack</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+A+L">Andong Li Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Paley%2C+A">Andrew Paley</a>, 
<a href="/search/cs?searchtype=author&query=Einarsson%2C+A">Alexander Einarsson</a>, 
<a href="/search/cs?searchtype=author&query=Hammond%2C+K">Kristian Hammond</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The principal goal of data science is to derive meaningful information from
data. To do this, data scientists develop a space of analytic possibilities and
from it reach their information goals by using their knowledge of the domain,
the available data, the operations that can be performed on those data, the
algorithms/models that are fed the data, and how all of these facets
interweave. In this work, we take the first steps towards automating a key
aspect of the data science pipeline: data analysis. We present an extensible
taxonomy of data analytic operations that scopes across domains and data, as
well as a method for codifying domain-specific knowledge that links this
analytics taxonomy to actual data. We validate the functionality of our
analytics taxonomy by implementing a system that leverages it, alongside domain
labelings for 8 distinct domains, to automatically generate a space of
answerable questions and associated analytic plans. In this way, we produce
information spaces over data that enable complex analyses and search over this
data and pave the way for fully automated data analysis.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12849" title="Abstract">arXiv:2311.12849</a> [<a href="/pdf/2311.12849" title="Download PDF">pdf</a>, <a href="/format/2311.12849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reliability Analysis of Fault Tolerant Memory Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yigit%2C+Y">Yagmur Yigit</a>, 
<a href="/search/cs?searchtype=author&query=Maglaras%2C+L">Leandros Maglaras</a>, 
<a href="/search/cs?searchtype=author&query=Ferrag%2C+M+A">Mohamed Amine Ferrag</a>, 
<a href="/search/cs?searchtype=author&query=Moradpoor%2C+N">Naghmeh Moradpoor</a>, 
<a href="/search/cs?searchtype=author&query=Lambropoulos%2C+G">Georgios Lambropoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">This paper delves into a range of recovery techniques employed in
fault-tolerant memory systems, primarily designed to address transient errors.
These techniques are modelled using Markov chains. The memory systems under
examination in this study make use of scrubbing methods in conjunction with
Single-Error Correction and Double-Error Detection (SEC-DED) codes. The
analysis encompasses three key models: 1) Exponentially distributed scrubbing,
involving the periodic checking of a memory word within an exponentially
distributed time frame; 2) Deterministic scrubbing, featuring regular periodic
checks of the memory word; and 3) Mixed scrubbing, which combines both
exponentially distributed and deterministic scrubbing approaches. The study
involves the estimation of reliability and Mean Time to Failure (MTTF) values
for each of these models. The results reveal that mixed scrubbing outperforms
simple scrubbing methods (whether probabilistic or deterministic) in terms of
both reliability and MTTF.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12850" title="Abstract">arXiv:2311.12850</a> [<a href="/pdf/2311.12850" title="Download PDF">pdf</a>, <a href="/format/2311.12850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meticulously Selecting 1% of the Dataset for Pre-training! Generating  Differentially Private Images Data with Semantics Query
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kecen Li</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+C">Chen Gong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhixiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yuzhong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+X">Xinwen Hou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianhao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Differential Privacy (DP) image data synthesis, which leverages the DP
technique to generate synthetic data to replace the sensitive data, allowing
organizations to share and utilize synthetic images without privacy concerns.
Previous methods incorporate the advanced techniques of generative models and
pre-training on a public dataset to produce exceptional DP image data, but
suffer from problems of unstable training and massive computational resource
demands. This paper proposes a novel DP image synthesis method, termed
PRIVIMAGE, which meticulously selects pre-training data, promoting the
efficient creation of DP datasets with high fidelity and utility. PRIVIMAGE
first establishes a semantic query function using a public dataset. Then, this
function assists in querying the semantic distribution of the sensitive
dataset, facilitating the selection of data from the public dataset with
analogous semantics for pre-training. Finally, we pre-train an image generative
model using the selected data and then fine-tune this model on the sensitive
dataset using Differentially Private Stochastic Gradient Descent (DP-SGD).
PRIVIMAGE allows us to train a lightly parameterized generative model, reducing
the noise in the gradient during DP-SGD training and enhancing training
stability. Extensive experiments demonstrate that PRIVIMAGE uses only 1% of the
public dataset for pre-training and 7.6% of the parameters in the generative
model compared to the state-of-the-art method, whereas achieves superior
synthetic performance and conserves more computational resources. On average,
PRIVIMAGE achieves 30.1% lower FID and 12.6% higher Classification Accuracy
than the state-of-the-art method. The replication package and datasets can be
accessed online.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12852" title="Abstract">arXiv:2311.12852</a> [<a href="/pdf/2311.12852" title="Download PDF">pdf</a>, <a href="/ps/2311.12852" title="Download PostScript">ps</a>, <a href="/format/2311.12852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cell-free Terahertz Networks: A Spatial-spectral Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zesheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lifeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+B">Bo Tan</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Shi Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Cell-free network architecture plays a promising role in the terahertz (THz)
networks since it provides better link reliability and uniformly good services
for all the users compared to the co-located massive MIMO counterpart, and the
spatial-spectral THz link has the advantages of lower initial access latency
and fast beam operations. To this end, this work studies cell-free
spatial-spectral THz networks with leaky-wave antennas, to exploit the benefits
of leveraging both cell-free and spatial-spectral THz technologies. By
addressing the coupling effects between propagation angles and frequencies, we
propose novel frequency-dependent THz transmit antenna selection schemes to
maximize the transmission rate. Numerical results confirm that the proposed
antenna selection schemes can achieve much larger transmission rate than the
maximal ratio transmission of using all the transmit antennas with equal
subchannel bandwidth allocation in higher THz frequencies.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12854" title="Abstract">arXiv:2311.12854</a> [<a href="/pdf/2311.12854" title="Download PDF">pdf</a>, <a href="/format/2311.12854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Robotic Manipulation: Harnessing the Power of Multi-Task  Reinforcement Learning and Single Life Reinforcement Learning in Meta-World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nehme%2C+G">Ghadi Nehme</a>, 
<a href="/search/cs?searchtype=author&query=Sabane%2C+I">Ishan Sabane</a>, 
<a href="/search/cs?searchtype=author&query=Deo%2C+T+Y">Tejas Y. Deo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">At present, robots typically require extensive training to successfully
accomplish a single task. However, to truly enhance their usefulness in
real-world scenarios, robots should possess the capability to perform multiple
tasks effectively. To address this need, various multi-task reinforcement
learning (RL) algorithms have been developed, including multi-task proximal
policy optimization (PPO), multi-task trust region policy optimization (TRPO),
and multi-task soft-actor critic (SAC). Nevertheless, these algorithms
demonstrate optimal performance only when operating within an environment or
observation space that exhibits a similar distribution. In reality, such
conditions are often not the norm, as robots may encounter scenarios or
observations that differ from those on which they were trained. Addressing this
challenge, algorithms like Q-Weighted Adversarial Learning (QWALE) attempt to
tackle the issue by training the base algorithm (generating prior data) solely
for a particular task, rendering it unsuitable for generalization across tasks.
So, the aim of this research project is to enable a robotic arm to successfully
execute seven distinct tasks within the Meta World environment. To achieve
this, a multi-task soft actor-critic (MT-SAC) is employed to train the robotic
arm. Subsequently, the trained model will serve as a source of prior data for
the single-life RL algorithm. The effectiveness of this MT-QWALE algorithm will
be assessed by conducting tests on various target positions (novel positions).
In the end, a comparison is provided between the trained MT-SAC and the
MT-QWALE algorithm where the MT-QWALE performs better. An ablation study
demonstrates that MT-QWALE successfully completes tasks with a slightly larger
number of steps even after hiding the final goal position.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12855" title="Abstract">arXiv:2311.12855</a> [<a href="/pdf/2311.12855" title="Download PDF">pdf</a>, <a href="/format/2311.12855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contextualised Out-of-Distribution Detection using Pattern Identication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu-Darme%2C+R">Romain Xu-Darme</a> (LSL, LIG), 
<a href="/search/cs?searchtype=author&query=Girard-Satabin%2C+J">Julien Girard-Satabin</a> (LSL), 
<a href="/search/cs?searchtype=author&query=Hond%2C+D">Darryl Hond</a> (TRT UK), 
<a href="/search/cs?searchtype=author&query=Incorvaia%2C+G">Gabriele Incorvaia</a> (TRT UK), 
<a href="/search/cs?searchtype=author&query=Chihani%2C+Z">Zakaria Chihani</a> (LSL)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2302.10303">arXiv:2302.10303</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computer Safety, Reliability, and Security. SAFECOMP 2023
  Workshops, Sep 2023, Toulouse, France
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this work, we propose CODE, an extension of existing work from the field
of explainable AI that identifies class-specific recurring patterns to build a
robust Out-of-Distribution (OoD) detection method for visual classifiers. CODE
does not require any classifier retraining and is OoD-agnostic, i.e., tuned
directly to the training dataset. Crucially, pattern identification allows us
to provide images from the In-Distribution (ID) dataset as reference data to
provide additional context to the confidence scores. In addition, we introduce
a new benchmark based on perturbations of the ID dataset that provides a known
and quantifiable measure of the discrepancy between the ID and OoD datasets
serving as a reference value for the comparison between OoD detection methods.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12857" title="Abstract">arXiv:2311.12857</a> [<a href="/pdf/2311.12857" title="Download PDF">pdf</a>, <a href="/format/2311.12857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial sample generation and training using geometric masks for  accurate and resilient license plate character recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shrestha%2C+B">Bishal Shrestha</a>, 
<a href="/search/cs?searchtype=author&query=Khakurel%2C+G">Griwan Khakurel</a>, 
<a href="/search/cs?searchtype=author&query=Simkhada%2C+K">Kritika Simkhada</a>, 
<a href="/search/cs?searchtype=author&query=Adhikari%2C+B">Badri Adhikari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Reading dirty license plates accurately in moving vehicles is challenging for
automatic license plate recognition systems. Moreover, license plates are often
intentionally tampered with a malicious intent to avoid police apprehension.
Usually, such groups and individuals know how to fool the existing recognition
systems by making minor unnoticeable plate changes. Designing and developing
deep learning methods resilient to such real-world 'attack' practices remains
an active research problem. As a solution, this work develops a resilient
method to recognize license plate characters. Extracting 1057 character images
from 160 Nepalese vehicles, as the first step, we trained several standard deep
convolutional neural networks to obtain 99.5% character classification
accuracy. On adversarial images generated to simulate malicious tampering,
however, our model's accuracy dropped to 25%. Next, we enriched our dataset by
generating and adding geometrically masked images, retrained our models, and
investigated the models' predictions. The proposed approach of training with
generated adversarial images helped our adversarial attack-aware license plate
character recognition (AA-LPCR) model achieves an accuracy of 99.7%. This
near-perfect accuracy demonstrates that the proposed idea of random geometric
masking is highly effective for improving the accuracy of license plate
recognition models. Furthermore, by performing interpretability studies to
understand why our models work, we identify and highlight attack-prone regions
in the input character images. In sum, although Nepal's embossed license plate
detection systems are vulnerable to malicious attacks, our findings suggest
that these systems can be upgraded to close to 100% resilience.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12858" title="Abstract">arXiv:2311.12858</a> [<a href="/pdf/2311.12858" title="Download PDF">pdf</a>, <a href="/format/2311.12858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RAEDiff: Denoising Diffusion Probabilistic Models Based Reversible  Adversarial Examples Self-Generation and Self-Recovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xing%2C+F">Fan Xing</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaoyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xuefeng Fan</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zhuo Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yan Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Collected and annotated datasets, which are obtained through extensive
efforts, are effective for training Deep Neural Network (DNN) models. However,
these datasets are susceptible to be misused by unauthorized users, resulting
in infringement of Intellectual Property (IP) rights owned by the dataset
creators. Reversible Adversarial Exsamples (RAE) can help to solve the issues
of IP protection for datasets. RAEs are adversarial perturbed images that can
be restored to the original. As a cutting-edge approach, RAE scheme can serve
the purposes of preventing unauthorized users from engaging in malicious model
training, as well as ensuring the legitimate usage of authorized users.
Nevertheless, in the existing work, RAEs still rely on the embedded auxiliary
information for restoration, which may compromise their adversarial abilities.
In this paper, a novel self-generation and self-recovery method, named as
RAEDiff, is introduced for generating RAEs based on a Denoising Diffusion
Probabilistic Models (DDPM). It diffuses datasets into a Biased Gaussian
Distribution (BGD) and utilizes the prior knowledge of the DDPM for generating
and recovering RAEs. The experimental results demonstrate that RAEDiff
effectively self-generates adversarial perturbations for DNN models, including
Artificial Intelligence Generated Content (AIGC) models, while also exhibiting
significant self-recovery capabilities.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12859" title="Abstract">arXiv:2311.12859</a> [<a href="/pdf/2311.12859" title="Download PDF">pdf</a>, <a href="/format/2311.12859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Multi-View Collaborative Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khalafaoui%2C+Y">Yasser Khalafaoui</a> (Alteca, ETIS), 
<a href="/search/cs?searchtype=author&query=Matei%2C+B">Basarab Matei</a> (LIPN), 
<a href="/search/cs?searchtype=author&query=Grozavu%2C+N">Nistor Grozavu</a> (ETIS), 
<a href="/search/cs?searchtype=author&query=Lovisetto%2C+M">Martino Lovisetto</a> (Alteca)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 International Joint Conference on Neural Networks (IJCNN), Jun 2023, Gold Coast, Australia
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Data is increasingly being collected from multiple sources and described by
multiple views. These multi-view data provide richer information than
traditional single-view data. Fusing the former for specific tasks is an
essential component of multi-view clustering. Since the goal of multi-view
clustering algorithms is to discover the common latent structure shared by
multiple views, the majority of proposed solutions overlook the advantages of
incorporating knowledge derived from horizontal collaboration between
multi-view data and the final consensus. To fill this gap, we propose the Joint
Multi-View Collaborative Clustering (JMVCC) solution, which involves the
generation of basic partitions using Non-negative Matrix Factorization (NMF)
and the horizontal collaboration principle, followed by the fusion of these
local partitions using ensemble clustering. Furthermore, we propose a weighting
method to reduce the risk of negative collaboration (i.e., views with low
quality) during the generation and fusion of local partitions. The experimental
results, which were obtained using a variety of data sets, demonstrate that
JMVCC outperforms other multi-view clustering algorithms and is robust to noisy
views.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12860" title="Abstract">arXiv:2311.12860</a> [<a href="/pdf/2311.12860" title="Download PDF">pdf</a>, <a href="/format/2311.12860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the stability, correctness and plausibility of visual explanation  methods based on feature importance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu-Darme%2C+R">Romain Xu-Darme</a> (LSL, LIG), 
<a href="/search/cs?searchtype=author&query=Benois-Pineau%2C+J">Jenny Benois-Pineau</a> (LaBRI), 
<a href="/search/cs?searchtype=author&query=Giot%2C+R">Romain Giot</a> (LaBRI), 
<a href="/search/cs?searchtype=author&query=Qu%C3%A9not%2C+G">Georges Qu&#xe9;not</a> (LIG), 
<a href="/search/cs?searchtype=author&query=Chihani%2C+Z">Zakaria Chihani</a> (LSL), 
<a href="/search/cs?searchtype=author&query=Rousset%2C+M">Marie-Christine Rousset</a> (LIG), 
<a href="/search/cs?searchtype=author&query=Zhukov%2C+A">Alexey Zhukov</a> (LaBRI)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In the field of Explainable AI, multiples evaluation metrics have been
proposed in order to assess the quality of explanation methods w.r.t. a set of
desired properties. In this work, we study the articulation between the
stability, correctness and plausibility of explanations based on feature
importance for image classifiers. We show that the existing metrics for
evaluating these properties do not always agree, raising the issue of what
constitutes a good evaluation metric for explanations. Finally, in the
particular case of stability and correctness, we show the possible limitations
of some evaluation metrics and propose new ones that take into account the
local behaviour of the model under test.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12861" title="Abstract">arXiv:2311.12861</a> [<a href="/pdf/2311.12861" title="Download PDF">pdf</a>, <a href="/ps/2311.12861" title="Download PostScript">ps</a>, <a href="/format/2311.12861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A versatile circuit for emulating active biological dendrites applied to  sound localisation and neuron imitation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mannion%2C+D+J">Daniel John Mannion</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages. 6 Figues in main text, 1 figure in supplementary materials
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Sophisticated machine learning struggles to transition onto battery-operated
devices due to the high-power consumption of neural networks. Researchers have
turned to neuromorphic engineering, inspired by biological neural networks, for
more efficient solutions. While previous research focused on artificial neurons
and synapses, an essential component has been overlooked: dendrites. Dendrites
transmit inputs from synapses to the neuron's soma, applying both passive and
active transformations. However, neuromorphic circuits replace these
sophisticated computational channels with metallic interconnects. In this
study, we introduce a versatile circuit that emulates a segment of a dendrite
which exhibits gain, introduces delays, and performs integration. We show how
sound localisation - a biological example of dendritic computation - is not
possible with the existing passive dendrite circuits but can be achieved using
this proposed circuit. We also find that dendrites can form bursting neurons.
This significant discovery suggests the potential to fabricate neural networks
solely comprised of dendrite circuits.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12862" title="Abstract">arXiv:2311.12862</a> [<a href="/pdf/2311.12862" title="Download PDF">pdf</a>, <a href="/format/2311.12862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TorchSparse++: Efficient Training and Inference Framework for Sparse  Convolution on GPUs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Haotian Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhijian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+K">Ke Hong</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhongming Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiuyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+G">Guohao Dai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Song Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MICRO 2023; Haotian Tang and Shang Yang contributed equally to this project
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Performance (cs.PF)

</div>
<p class="mathjax">Sparse convolution plays a pivotal role in emerging workloads, including
point cloud processing in AR/VR, autonomous driving, and graph understanding in
recommendation systems. Since the computation pattern is sparse and irregular,
specialized high-performance kernels are required. Existing GPU libraries offer
two dataflow types for sparse convolution. The gather-GEMM-scatter dataflow is
easy to implement but not optimal in performance, while the dataflows with
overlapped computation and memory access (e.g.implicit GEMM) are highly
performant but have very high engineering costs. In this paper, we introduce
TorchSparse++, a new GPU library that achieves the best of both worlds. We
create a highly efficient Sparse Kernel Generator that generates performant
sparse convolution kernels at less than one-tenth of the engineering cost of
the current state-of-the-art system. On top of this, we design the Sparse
Autotuner, which extends the design space of existing sparse convolution
libraries and searches for the best dataflow configurations for training and
inference workloads. Consequently, TorchSparse++ achieves 2.9x, 3.3x, 2.2x and
1.7x measured end-to-end speedup on an NVIDIA A100 GPU over state-of-the-art
MinkowskiEngine, SpConv 1.2, TorchSparse and SpConv v2 in inference; and is
1.2-1.3x faster than SpConv v2 in mixed precision training across seven
representative autonomous driving benchmarks. It also seamlessly supports graph
convolutions, achieving 2.6-7.6x faster inference speed compared with
state-of-the-art graph deep learning libraries.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12866" title="Abstract">arXiv:2311.12866</a> [<a href="/pdf/2311.12866" title="Download PDF">pdf</a>, <a href="/format/2311.12866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modular Blended Attention Network for Video Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Mingjie Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> I will not add others' names since this work has not been published
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">In multimodal machine learning tasks, it is due to the complexity of the
assignments that the network structure, in most cases, is assembled in a
sophisticated way. The holistic architecture can be separated into several
logical parts according to the respective ends that the modules are devised to
achieve. As the number of modalities of information representation increases,
constructing ad hoc subnetworks for processing the data from divergent
modalities while mediating the fusion of different information types has become
a cumbersome and expensive problem. In this paper, we present an approach to
facilitate the question with a reusable and composable neural unit; by
connecting the units in series or parallel, the arduous network constructing of
multimodal machine learning tasks will be accomplished in a much
straightforward way. Additionally, through parameter sharing (weights
replication) among the units, the space complexity will be significantly
reduced. We have conducted experiments on three commonly used datasets; our
method achieves impressive performance compared to several video QA baselines.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12869" title="Abstract">arXiv:2311.12869</a> [<a href="/pdf/2311.12869" title="Download PDF">pdf</a>, <a href="/ps/2311.12869" title="Download PostScript">ps</a>, <a href="/format/2311.12869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Progression and Challenges of IoT in Healthcare: A Short Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahman%2C+S+M+A">S M Atikur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Ibtisum%2C+S">Sifat Ibtisum</a>, 
<a href="/search/cs?searchtype=author&query=Podder%2C+P">Priya Podder</a>, 
<a href="/search/cs?searchtype=author&query=Hossain%2C+S+M+S">S. M. Saokat Hossain</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Computer Applications, Vol. 185, No. 37,
  pp. 9-15, October 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Smart healthcare, an integral element of connected living, plays a pivotal
role in fulfilling a fundamental human need. The burgeoning field of smart
healthcare is poised to generate substantial revenue in the foreseeable future.
Its multifaceted framework encompasses vital components such as the Internet of
Things (IoT), medical sensors, artificial intelligence (AI), edge and cloud
computing, as well as next-generation wireless communication technologies. Many
research papers discuss smart healthcare and healthcare more broadly. Numerous
nations have strategically deployed the Internet of Medical Things (IoMT)
alongside other measures to combat the propagation of COVID-19. This combined
effort has not only enhanced the safety of frontline healthcare workers but has
also augmented the overall efficacy in managing the pandemic, subsequently
reducing its impact on human lives and mortality rates. Remarkable strides have
been made in both applications and technology within the IoMT domain. However,
it is imperative to acknowledge that this technological advancement has
introduced certain challenges, particularly in the realm of security. The rapid
and extensive adoption of IoMT worldwide has magnified issues related to
security and privacy. These encompass a spectrum of concerns, ranging from
replay attacks, man-in-the-middle attacks, impersonation, privileged insider
threats, remote hijacking, password guessing, and denial of service (DoS)
attacks, to malware incursions. In this comprehensive review, we undertake a
comparative analysis of existing strategies designed for the detection and
prevention of malware in IoT environments.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12871" title="Abstract">arXiv:2311.12871</a> [<a href="/pdf/2311.12871" title="Download PDF">pdf</a>, <a href="/format/2311.12871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Embodied Generalist Agent in 3D World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiangyong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yong%2C+S">Silong Yong</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaojian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Linghu%2C+X">Xiongkun Linghu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Puhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qing Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Song-Chun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+B">Baoxiong Jia</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Siyuan Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first four authors contribute equally. Project page: <a href="https://embodied-generalist.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Leveraging massive knowledge and learning schemes from large language models
(LLMs), recent machine learning models show notable successes in building
generalist agents that exhibit the capability of general-purpose task solving
in diverse domains, including natural language processing, computer vision, and
robotics. However, a significant challenge remains as these models exhibit
limited ability in understanding and interacting with the 3D world. We argue
this limitation significantly hinders the current models from performing
real-world tasks and further achieving general intelligence. To this end, we
introduce an embodied multi-modal and multi-task generalist agent that excels
in perceiving, grounding, reasoning, planning, and acting in the 3D world. Our
proposed agent, referred to as LEO, is trained with shared LLM-based model
architectures, objectives, and weights in two stages: (i) 3D vision-language
alignment and (ii) 3D vision-language-action instruction tuning. To facilitate
the training, we meticulously curate and generate an extensive dataset
comprising object-level and scene-level multi-modal tasks with exceeding scale
and complexity, necessitating a deep understanding of and interaction with the
3D world. Through rigorous experiments, we demonstrate LEO's remarkable
proficiency across a wide spectrum of tasks, including 3D captioning, question
answering, embodied reasoning, embodied navigation, and robotic manipulation.
Our ablation results further provide valuable insights for the development of
future embodied generalist agents.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12872" title="Abstract">arXiv:2311.12872</a> [<a href="/pdf/2311.12872" title="Download PDF">pdf</a>, <a href="/ps/2311.12872" title="Download PostScript">ps</a>, <a href="/format/2311.12872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Case for Universal Basic Computing Power
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yue Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">The Universal Basic Computing Power (UBCP) initiative ensures global, free
access to a set amount of computing power specifically for AI research and
development (R&amp;D). This initiative comprises three key elements. First, UBCP
must be cost free, with its usage limited to AI R&amp;D and minimal additional
conditions. Second, UBCP should continually incorporate the state of the art AI
advancements, including efficiently distilled, compressed, and deployed
training data, foundational models, benchmarks, and governance tools. Lastly,
it's essential for UBCP to be universally accessible, ensuring convenience for
all users. We urge major stakeholders in AI development large platforms, open
source contributors, and policymakers to prioritize the UBCP initiative.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12880" title="Abstract">arXiv:2311.12880</a> [<a href="/pdf/2311.12880" title="Download PDF">pdf</a>, <a href="/format/2311.12880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weak-Form Latent Space Dynamics Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tran%2C+A">April Tran</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+X">Xiaolong He</a>, 
<a href="/search/eess?searchtype=author&query=Messenger%2C+D+A">Daniel A. Messenger</a>, 
<a href="/search/eess?searchtype=author&query=Choi%2C+Y">Youngsoo Choi</a>, 
<a href="/search/eess?searchtype=author&query=Bortz%2C+D+M">David M. Bortz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Recent work in data-driven modeling has demonstrated that a weak formulation
of model equations enhances the noise robustness of a wide range of
computational methods. In this paper, we demonstrate the power of the weak form
to enhance the LaSDI (Latent Space Dynamics Identification) algorithm, a
recently developed data-driven reduced order modeling technique.
<br />We introduce a weak form-based version WLaSDI (Weak-form Latent Space
Dynamics Identification). WLaSDI first compresses data, then projects onto the
test functions and learns the local latent space models. Notably, WLaSDI
demonstrates significantly enhanced robustness to noise. With WLaSDI, the local
latent space is obtained using weak-form equation learning techniques. Compared
to the standard sparse identification of nonlinear dynamics (SINDy) used in
LaSDI, the variance reduction of the weak form guarantees a robust and precise
latent space recovery, hence allowing for a fast, robust, and accurate
simulation. We demonstrate the efficacy of WLaSDI vs. LaSDI on several common
benchmark examples including viscid and inviscid Burgers', radial advection,
and heat conduction. For instance, in the case of 1D inviscid Burgers'
simulations with the addition of up to 100% Gaussian white noise, the relative
error remains consistently below 6% for WLaSDI, while it can exceed 10,000% for
LaSDI. Similarly, for radial advection simulations, the relative errors stay
below 15% for WLaSDI, in stark contrast to the potential errors of up to
10,000% with LaSDI. Moreover, speedups of several orders of magnitude can be
obtained with WLaSDI. For example applying WLaSDI to 1D Burgers' yields a 140X
speedup compared to the corresponding full order model.
<br />Python code to reproduce the results in this work is available at
(https://github.com/MathBioCU/PyWSINDy_ODE) and
(https://github.com/MathBioCU/PyWLaSDI).
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12882" title="Abstract">arXiv:2311.12882</a> [<a href="/pdf/2311.12882" title="Download PDF">pdf</a>, <a href="/ps/2311.12882" title="Download PostScript">ps</a>, <a href="/format/2311.12882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Overview of Current Applications of Large Language Models in Various  Medical Specialities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mumtaz%2C+U">Ummara Mumtaz</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+A">Awais Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Mumtaz%2C+S">Summaya Mumtaz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages and one figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper gives an overview of the latest applications of Large Language
Models (LLMs) in the healthcare sector, highlighting their transformative role
in enhancing medical care quality. By processing vast amounts of data from
diverse medical domains, LLMs have become pivotal in assisting doctors,
healthcare providers, and patients. We explore their utilization in various
medical specialties, such as cancer diagnostics, dentistry, nephrology,
dermatology, etc. The paper includes the LLM methodologies applied in various
medical specialties, different data types in the medical domains and the
relevant input formatting for LLMs, along with practical use-cases of LLMs in
the healthcare domain.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12883" title="Abstract">arXiv:2311.12883</a> [<a href="/pdf/2311.12883" title="Download PDF">pdf</a>, <a href="/format/2311.12883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLVM Static Analysis for Program Characterization and Memory Reuse  Profile Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barai%2C+A">Atanu Barai</a>, 
<a href="/search/cs?searchtype=author&query=Santhi%2C+N">Nandakishore Santhi</a>, 
<a href="/search/cs?searchtype=author&query=Razzak%2C+A">Abdur Razzak</a>, 
<a href="/search/cs?searchtype=author&query=Eidenbenz%2C+S">Stephan Eidenbenz</a>, 
<a href="/search/cs?searchtype=author&query=Badawy%2C+A+A">Abdel-Hameed A. Badawy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was accepted at the MEMSYS '23 conference, The International Symposium on Memory Systems, October 02, 2023 - October 05, 2023, Alexandria, VA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Performance (cs.PF)

</div>
<p class="mathjax">Profiling various application characteristics, including the number of
different arithmetic operations performed, memory footprint, etc., dynamically
is time- and space-consuming. On the other hand, static analysis methods,
although fast, can be less accurate. This paper presents an LLVM-based
probabilistic static analysis method that accurately predicts different program
characteristics and estimates the reuse distance profile of a program by
analyzing the LLVM IR file in constant time, regardless of program input size.
We generate the basic-block-level control flow graph of the target application
kernel and determine basic-block execution counts by solving the linear balance
equation involving the adjacent basic blocks' transition probabilities.
Finally, we represent the kernel memory accesses in a bracketed format and
employ a recursive algorithm to calculate the reuse distance profile. The
results show that our approach can predict application characteristics
accurately compared to another LLVM-based dynamic code analysis tool, Byfl.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12885" title="Abstract">arXiv:2311.12885</a> [<a href="/pdf/2311.12885" title="Download PDF">pdf</a>, <a href="/format/2311.12885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Long-MIL: Scaling Long Contextual Multiple Instance Learning for  Histopathology Whole Slide Image Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Honglin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yunlong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chenglu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+J">Jiatong Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Sunyi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lin Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Histopathology image analysis is the golden standard of clinical diagnosis
for Cancers. In doctors daily routine and computer-aided diagnosis, the Whole
Slide Image (WSI) of histopathology tissue is used for analysis. Because of the
extremely large scale of resolution, previous methods generally divide the WSI
into a large number of patches, then aggregate all patches within a WSI by
Multi-Instance Learning (MIL) to make the slide-level prediction when
developing computer-aided diagnosis tools. However, most previous WSI-MIL
models using global-attention without pairwise interaction and any positional
information, or self-attention with absolute position embedding can not well
handle shape varying large WSIs, e.g. testing WSIs after model deployment may
be larger than training WSIs, since the model development set is always limited
due to the difficulty of histopathology WSIs collection. To deal with the
problem, in this paper, we propose to amend position embedding for shape
varying long-contextual WSI by introducing Linear Bias into Attention, and
adapt it from 1-d long sequence into 2-d long-contextual WSI which helps model
extrapolate position embedding to unseen or under-fitted positions. We further
utilize Flash-Attention module to tackle the computational complexity of
Transformer, which also keep full self-attention performance compared to
previous attention approximation work. Our method, Long-contextual MIL
(Long-MIL) are evaluated on extensive experiments including 4 dataset including
WSI classification and survival prediction tasks to validate the superiority on
shape varying WSIs. The source code will be open-accessed soon.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12886" title="Abstract">arXiv:2311.12886</a> [<a href="/pdf/2311.12886" title="Download PDF">pdf</a>, <a href="/format/2311.12886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-Grained Open Domain Image Animation with Motion Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+Z">Zuozhuo Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenghao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yao Yao</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+B">Bingxue Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Siyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+L">Long Qin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weizhi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image animation is a key task in computer vision which aims to generate
dynamic visual content from static image. Recent image animation methods employ
neural based rendering technique to generate realistic animations. Despite
these advancements, achieving fine-grained and controllable image animation
guided by text remains challenging, particularly for open-domain images
captured in diverse real environments. In this paper, we introduce an open
domain image animation method that leverages the motion prior of video
diffusion model. Our approach introduces targeted motion area guidance and
motion strength guidance, enabling precise control the movable area and its
motion speed. This results in enhanced alignment between the animated visual
elements and the prompting text, thereby facilitating a fine-grained and
interactive animation generation process for intricate motion sequences. We
validate the effectiveness of our method through rigorous experiments on an
open-domain dataset, with the results showcasing its superior performance. The
source code and model will be made publicly available upon publication.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12889" title="Abstract">arXiv:2311.12889</a> [<a href="/pdf/2311.12889" title="Download PDF">pdf</a>, <a href="/format/2311.12889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Scene Graph Generation with Hierarchical Relationships and  Commonsense Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Bowen Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Z">Zhijun Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Taylor%2C+C+J">Camillo Jose Taylor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This work presents an enhanced approach to generating scene graphs by
incorporating a relationship hierarchy and commonsense knowledge. Specifically,
we propose a Bayesian classification head that exploits an informative
hierarchical structure. It jointly predicts the super-category or type of
relationship between the two objects, along with the detailed relationship
under each super-category. We design a commonsense validation pipeline that
uses a large language model to critique the results from the scene graph
prediction system and then use that feedback to enhance the model performance.
The system requires no external large language model assistance at test time,
making it more convenient for practical applications. Experiments on the Visual
Genome and the OpenImage V6 datasets demonstrate that harnessing hierarchical
relationships enhances the model performance by a large margin. The proposed
Bayesian head can also be incorporated as a portable module in existing scene
graph generation algorithms to improve their results. In addition, the
commonsense validation enables the model to generate an extensive set of
reasonable predictions beyond dataset annotations.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12890" title="Abstract">arXiv:2311.12890</a> [<a href="/pdf/2311.12890" title="Download PDF">pdf</a>, <a href="/format/2311.12890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> De-fine: Decomposing and Refining Visual Programs with Auto-Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+M">Minghe Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Juncheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Fei%2C+H">Hao Fei</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+W">Wei Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guoming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenqiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Siliang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Y">Yueting Zhuang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Visual programming, a modular and generalizable paradigm, integrates
different modules and Python operators to solve various vision-language tasks.
Unlike end-to-end models that need task-specific data, it advances in
performing visual processing and reasoning in an unsupervised manner. Current
visual programming methods generate programs in a single pass for each task
where the ability to evaluate and optimize based on feedback, unfortunately, is
lacking, which consequentially limits their effectiveness for complex,
multi-step problems. Drawing inspiration from benders decomposition, we
introduce De-fine, a general framework that automatically decomposes complex
tasks into simpler subtasks and refines programs through auto-feedback. This
model-agnostic approach can improve logical reasoning performance by
integrating the strengths of multiple models. Our experiments across various
visual tasks show that De-fine creates more accurate and robust programs,
setting new benchmarks in the field.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12891" title="Abstract">arXiv:2311.12891</a> [<a href="/pdf/2311.12891" title="Download PDF">pdf</a>, <a href="/format/2311.12891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text-Guided Texturing by Synchronized Multi-View Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuxin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+M">Minshan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hanyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+T">Tien-Tsin Wong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper introduces a novel approach to synthesize texture to dress up a
given 3D object, given a text prompt. Based on the pretrained text-to-image
(T2I) diffusion model, existing methods usually employ a project-and-inpaint
approach, in which a view of the given object is first generated and warped to
another view for inpainting. But it tends to generate inconsistent texture due
to the asynchronous diffusion of multiple views. We believe such asynchronous
diffusion and insufficient information sharing among views are the root causes
of the inconsistent artifact. In this paper, we propose a synchronized
multi-view diffusion approach that allows the diffusion processes from
different views to reach a consensus of the generated content early in the
process, and hence ensures the texture consistency. To synchronize the
diffusion, we share the denoised content among different views in each
denoising step, specifically blending the latent content in the texture domain
from views with overlap. Our method demonstrates superior performance in
generating consistent, seamless, highly detailed textures, comparing to
state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12893" title="Abstract">arXiv:2311.12893</a> [<a href="/pdf/2311.12893" title="Download PDF">pdf</a>, <a href="/format/2311.12893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Safer Vision-based Autonomous Planning System for Quadrotor UAVs with  Dynamic Obstacle Trajectory Prediction and Its Application with LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+J">Jiageng Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Ming Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yinliang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zihang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Haoran Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">For intelligent quadcopter UAVs, a robust and reliable autonomous planning
system is crucial. Most current trajectory planning methods for UAVs are
suitable for static environments but struggle to handle dynamic obstacles,
which can pose challenges and even dangers to flight. To address this issue,
this paper proposes a vision-based planning system that combines tracking and
trajectory prediction of dynamic obstacles to achieve efficient and reliable
autonomous flight. We use a lightweight object detection algorithm to identify
dynamic obstacles and then use Kalman Filtering to track and estimate their
motion states. During the planning phase, we not only consider static obstacles
but also account for the potential movements of dynamic obstacles. For
trajectory generation, we use a B-spline-based trajectory search algorithm,
which is further optimized with various constraints to enhance safety and
alignment with the UAV's motion characteristics. We conduct experiments in both
simulation and real-world environments, and the results indicate that our
approach can successfully detect and avoid obstacles in dynamic environments in
real-time, offering greater reliability compared to existing approaches.
Furthermore, with the advancements in Natural Language Processing (NLP)
technology demonstrating exceptional zero-shot generalization capabilities,
more user-friendly human-machine interactions have become feasible, and this
study also explores the integration of autonomous planning systems with Large
Language Models (LLMs).
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12894" title="Abstract">arXiv:2311.12894</a> [<a href="/pdf/2311.12894" title="Download PDF">pdf</a>, <a href="/format/2311.12894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attribute-Aware Deep Hashing with Self-Consistency for Large-Scale  Fine-Grained Image Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xiu-Shen Wei</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xuhao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yuxin Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE TPAMI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">Our work focuses on tackling large-scale fine-grained image retrieval as
ranking the images depicting the concept of interests (i.e., the same
sub-category labels) highest based on the fine-grained details in the query. It
is desirable to alleviate the challenges of both fine-grained nature of small
inter-class variations with large intra-class variations and explosive growth
of fine-grained data for such a practical task. In this paper, we propose
attribute-aware hashing networks with self-consistency for generating
attribute-aware hash codes to not only make the retrieval process efficient,
but also establish explicit correspondences between hash codes and visual
attributes. Specifically, based on the captured visual representations by
attention, we develop an encoder-decoder structure network of a reconstruction
task to unsupervisedly distill high-level attribute-specific vectors from the
appearance-specific visual representations without attribute annotations. Our
models are also equipped with a feature decorrelation constraint upon these
attribute vectors to strengthen their representative abilities. Then, driven by
preserving original entities' similarity, the required hash codes can be
generated from these attribute-specific vectors and thus become
attribute-aware. Furthermore, to combat simplicity bias in deep hashing, we
consider the model design from the perspective of the self-consistency
principle and propose to further enhance models' self-consistency by equipping
an additional image reconstruction path. Comprehensive quantitative experiments
under diverse empirical settings on six fine-grained retrieval datasets and two
generic retrieval datasets show the superiority of our models over competing
methods.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12897" title="Abstract">arXiv:2311.12897</a> [<a href="/pdf/2311.12897" title="Download PDF">pdf</a>, <a href="/format/2311.12897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Efficient 3D Gaussian Representation for Monocular/Multi-view Dynamic  Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Katsumata%2C+K">Kai Katsumata</a>, 
<a href="/search/cs?searchtype=author&query=Vo%2C+D+M">Duc Minh Vo</a>, 
<a href="/search/cs?searchtype=author&query=Nakayama%2C+H">Hideki Nakayama</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">In novel view synthesis of scenes from multiple input views, 3D Gaussian
splatting emerges as a viable alternative to existing radiance field
approaches, delivering great visual quality and real-time rendering. While
successful in static scenes, the present advancement of 3D Gaussian
representation, however, faces challenges in dynamic scenes in terms of memory
consumption and the need for numerous observations per time step, due to the
onus of storing 3D Gaussian parameters per time step. In this study, we present
an efficient 3D Gaussian representation tailored for dynamic scenes in which we
define positions and rotations as functions of time while leaving other
time-invariant properties of the static 3D Gaussian unchanged. Notably, our
representation reduces memory usage, which is consistent regardless of the
input sequence length. Additionally, it mitigates the risk of overfitting
observed frames by accounting for temporal changes. The optimization of our
Gaussian representation based on image and flow reconstruction results in a
powerful framework for dynamic scene view synthesis in both monocular and
multi-view cases. We obtain the highest rendering speed of $118$ frames per
second (FPS) at a resolution of $1352 \times 1014$ with a single GPU, showing
the practical usability and effectiveness of our proposed method in dynamic
scene rendering scenarios.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12900" title="Abstract">arXiv:2311.12900</a> [<a href="/pdf/2311.12900" title="Download PDF">pdf</a>, <a href="/ps/2311.12900" title="Download PostScript">ps</a>, <a href="/format/2311.12900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visually impaired citizens&#x27; acceptance of autonomous vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kacperski%2C+C">Celina Kacperski</a>, 
<a href="/search/cs?searchtype=author&query=Kutzner%2C+F">Florian Kutzner</a>, 
<a href="/search/cs?searchtype=author&query=Vogel%2C+T">Tobias Vogel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">The question how individuals with visual impairments expect connected and
autonomous vehicles (CAVs) to affect their lives and the world around them has
not so far received much attention. The present research reports results based
on survey responses from 114 visually impaired participants and 117 panel
recruited participants without visual impairments from Germany. Their attitudes
towards autonomous vehicles and their expectations for consequences of
wide-spread adoption of CAVs are assessed. A confirmatory factor analysis
establishes privacy, safety, sustainability, and efficiency, as well as
independence to be important factors for acceptance. Results indicate
significantly more positive CAV attitudes in participants with visual
impairments (compared to those without visual impairments). Mediation analyses
indicate that more positive CAV attitudes are largely explained by higher hopes
for independence, and more optimistic expectations regarding safety and
sustainability. Policy makers should ensure accessibility without sacrificing
goals for higher safety and lower ecological impact to make CAVs an acceptable
inclusive mobility solution.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12902" title="Abstract">arXiv:2311.12902</a> [<a href="/pdf/2311.12902" title="Download PDF">pdf</a>, <a href="/format/2311.12902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local Convolution Enhanced Global Fourier Neural Operator For Multiscale  Dynamic Spaces Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xuanle Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yue Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tielin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Bo Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Dynamical Systems (math.DS); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Neural operators extend the capabilities of traditional neural networks by
allowing them to handle mappings between function spaces for the purpose of
solving partial differential equations (PDEs). One of the most notable methods
is the Fourier Neural Operator (FNO), which is inspired by Green's function
method and approximate operator kernel directly in the frequency domain. In
this work, we focus on predicting multiscale dynamic spaces, which is
equivalent to solving multiscale PDEs. Multiscale PDEs are characterized by
rapid coefficient changes and solution space oscillations, which are crucial
for modeling atmospheric convection and ocean circulation. To solve this
problem, models should have the ability to capture rapid changes and process
them at various scales. However, the FNO only approximates kernels in the
low-frequency domain, which is insufficient when solving multiscale PDEs. To
address this challenge, we propose a novel hierarchical neural operator that
integrates improved Fourier layers with attention mechanisms, aiming to capture
all details and handle them at various scales. These mechanisms complement each
other in the frequency domain and encourage the model to solve multiscale
problems. We perform experiments on dynamic spaces governed by forward and
reverse problems of multiscale elliptic equations, Navier-Stokes equations and
some other physical scenarios, and reach superior performance in existing PDE
benchmarks, especially equations characterized by rapid coefficient variations.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12905" title="Abstract">arXiv:2311.12905</a> [<a href="/pdf/2311.12905" title="Download PDF">pdf</a>, <a href="/format/2311.12905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting the Domain Shift and Sample Uncertainty in Multi-source  Active Domain Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenqiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+Z">Zheqi Lv</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jia-Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Juncheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mengze Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Siliang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Y">Yueting Zhuang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2302.13824">arXiv:2302.13824</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Active Domain Adaptation (ADA) aims to maximally boost model adaptation in a
new target domain by actively selecting a limited number of target data to
annotate.This setting neglects the more practical scenario where training data
are collected from multiple sources. This motivates us to target a new and
challenging setting of knowledge transfer that extends ADA from a single source
domain to multiple source domains, termed Multi-source Active Domain Adaptation
(MADA). Not surprisingly, we find that most traditional ADA methods cannot work
directly in such a setting, mainly due to the excessive domain gap introduced
by all the source domains and thus their uncertainty-aware sample selection can
easily become miscalibrated under the multi-domain shifts. Considering this, we
propose a Dynamic integrated uncertainty valuation framework(Detective) that
comprehensively consider the domain shift between multi-source domains and
target domain to detect the informative target samples. Specifically, the
leverages a dynamic Domain Adaptation(DA) model that learns how to adapt the
model's parameters to fit the union of multi-source domains. This enables an
approximate single-source domain modeling by the dynamic model. We then
comprehensively measure both domain uncertainty and predictive uncertainty in
the target domain to detect informative target samples using evidential deep
learning, thereby mitigating uncertainty miscalibration. Furthermore, we
introduce a contextual diversity-aware calculator to enhance the diversity of
the selected samples. Experiments demonstrate that our solution outperforms
existing methods by a considerable margin on three domain adaptation
benchmarks.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12906" title="Abstract">arXiv:2311.12906</a> [<a href="/pdf/2311.12906" title="Download PDF">pdf</a>, <a href="/ps/2311.12906" title="Download PostScript">ps</a>, <a href="/format/2311.12906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear System Identification of Swarm of UAVs Using Deep Learning  Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yazdannik%2C+S">Saman Yazdannik</a>, 
<a href="/search/cs?searchtype=author&query=Tayefi%2C+M">Morteza Tayefi</a>, 
<a href="/search/cs?searchtype=author&query=Farrokh%2C+M">Mojtaba Farrokh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This study designs and evaluates multiple nonlinear system identification
techniques for modeling the UAV swarm system in planar space. learning methods
such as RNNs, CNNs, and Neural ODE are explored and compared. The objective is
to forecast future swarm trajectories by accurately approximating the nonlinear
dynamics of the swarm model. The modeling process is performed using both
transient and steady-state data from swarm simulations. Results show that the
combination of Neural ODE with a well-trained model using transient data is
robust for varying initial conditions and outperforms other learning methods in
accurately predicting swarm stability.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12908" title="Abstract">arXiv:2311.12908</a> [<a href="/pdf/2311.12908" title="Download PDF">pdf</a>, <a href="/format/2311.12908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Model Alignment Using Direct Preference Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wallace%2C+B">Bram Wallace</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+M">Meihua Dang</a>, 
<a href="/search/cs?searchtype=author&query=Rafailov%2C+R">Rafael Rafailov</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Linqi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+A">Aaron Lou</a>, 
<a href="/search/cs?searchtype=author&query=Purushwalkam%2C+S">Senthil Purushwalkam</a>, 
<a href="/search/cs?searchtype=author&query=Ermon%2C+S">Stefano Ermon</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+C">Caiming Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Joty%2C+S">Shafiq Joty</a>, 
<a href="/search/cs?searchtype=author&query=Naik%2C+N">Nikhil Naik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) are fine-tuned using human comparison data with
Reinforcement Learning from Human Feedback (RLHF) methods to make them better
aligned with users' preferences. In contrast to LLMs, human preference learning
has not been widely explored in text-to-image diffusion models; the best
existing approach is to fine-tune a pretrained model using carefully curated
high quality images and captions to improve visual appeal and text alignment.
We propose Diffusion-DPO, a method to align diffusion models to human
preferences by directly optimizing on human comparison data. Diffusion-DPO is
adapted from the recently developed Direct Preference Optimization (DPO), a
simpler alternative to RLHF which directly optimizes a policy that best
satisfies human preferences under a classification objective. We re-formulate
DPO to account for a diffusion model notion of likelihood, utilizing the
evidence lower bound to derive a differentiable objective. Using the Pick-a-Pic
dataset of 851K crowdsourced pairwise preferences, we fine-tune the base model
of the state-of-the-art Stable Diffusion XL (SDXL)-1.0 model with
Diffusion-DPO. Our fine-tuned base model significantly outperforms both base
SDXL-1.0 and the larger SDXL-1.0 model consisting of an additional refinement
model in human evaluation, improving visual appeal and prompt alignment. We
also develop a variant that uses AI feedback and has comparable performance to
training on human preferences, opening the door for scaling of diffusion model
alignment methods.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12912" title="Abstract">arXiv:2311.12912</a> [<a href="/pdf/2311.12912" title="Download PDF">pdf</a>, <a href="/format/2311.12912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Q-Seg: Quantum Annealing-based Unsupervised Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Venkatesh%2C+S+M">Supreeth Mysore Venkatesh</a>, 
<a href="/search/cs?searchtype=author&query=Macaluso%2C+A">Antonio Macaluso</a>, 
<a href="/search/cs?searchtype=author&query=Nuske%2C+M">Marlon Nuske</a>, 
<a href="/search/cs?searchtype=author&query=Klusch%2C+M">Matthias Klusch</a>, 
<a href="/search/cs?searchtype=author&query=Dengel%2C+A">Andreas Dengel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 9 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">In this study, we present Q-Seg, a novel unsupervised image segmentation
method based on quantum annealing, tailored for existing quantum hardware. We
formulate the pixel-wise segmentation problem, which assimilates spectral and
spatial information of the image, as a graph-cut optimization task. Our method
efficiently leverages the interconnected qubit topology of the D-Wave Advantage
device, offering superior scalability over existing quantum approaches and
outperforming state-of-the-art classical methods. Our empirical evaluations on
synthetic datasets reveal that Q-Seg offers better runtime performance against
the classical optimizer Gurobi. Furthermore, we evaluate our method on
segmentation of Earth Observation images, an area of application where the
amount of labeled data is usually very limited. In this case, Q-Seg
demonstrates near-optimal results in flood mapping detection with respect to
classical supervised state-of-the-art machine learning methods. Also, Q-Seg
provides enhanced segmentation for forest coverage compared to existing
annotated masks. Thus, Q-Seg emerges as a viable alternative for real-world
applications using available quantum hardware, particularly in scenarios where
the lack of labeled data and computational runtime are critical.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12914" title="Abstract">arXiv:2311.12914</a> [<a href="/pdf/2311.12914" title="Download PDF">pdf</a>, <a href="/format/2311.12914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention Deficit is Ordered! Fooling Deformable Vision Transformers  with Collaborative Adversarial Patches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alam%2C+Q+M">Quazi Mishkatul Alam</a>, 
<a href="/search/cs?searchtype=author&query=Tarchoun%2C+B">Bilel Tarchoun</a>, 
<a href="/search/cs?searchtype=author&query=Alouani%2C+I">Ihsen Alouani</a>, 
<a href="/search/cs?searchtype=author&query=Abu-Ghazaleh%2C+N">Nael Abu-Ghazaleh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The latest generation of transformer-based vision models have proven to be
superior to Convolutional Neural Network (CNN)-based models across several
vision tasks, largely attributed to their remarkable prowess in relation
modeling. Deformable vision transformers significantly reduce the quadratic
complexity of modeling attention by using sparse attention structures, enabling
them to be used in larger scale applications such as multi-view vision systems.
Recent work demonstrated adversarial attacks against transformers; we show that
these attacks do not transfer to deformable transformers due to their sparse
attention structure. Specifically, attention in deformable transformers is
modeled using pointers to the most relevant other tokens. In this work, we
contribute for the first time adversarial attacks that manipulate the attention
of deformable transformers, distracting them to focus on irrelevant parts of
the image. We also develop new collaborative attacks where a source patch
manipulates attention to point to a target patch that adversarially attacks the
system. In our experiments, we find that only 1% patched area of the input
field can lead to 0% AP. We also show that the attacks provide substantial
versatility to support different attacker scenarios because of their ability to
redirect attention under the attacker control.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12915" title="Abstract">arXiv:2311.12915</a> [<a href="/pdf/2311.12915" title="Download PDF">pdf</a>, <a href="/format/2311.12915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural-Integrated Meshfree (NIM) Method: A differentiable  programming-based hybrid solver for computational mechanics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Honghui Du</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Q">QiZhi He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">We present the neural-integrated meshfree (NIM) method, a differentiable
programming-based hybrid meshfree approach within the field of computational
mechanics. NIM seamlessly integrates traditional physics-based meshfree
discretization techniques with deep learning architectures. It employs a hybrid
approximation scheme, NeuroPU, to effectively represent the solution by
combining continuous DNN representations with partition of unity (PU) basis
functions associated with the underlying spatial discretization. This
neural-numerical hybridization not only enhances the solution representation
through functional space decomposition but also reduces both the size of DNN
model and the need for spatial gradient computations based on automatic
differentiation, leading to a significant improvement in training efficiency.
Under the NIM framework, we propose two truly meshfree solvers: the strong
form-based NIM (S-NIM) and the local variational form-based NIM (V-NIM). In the
S-NIM solver, the strong-form governing equation is directly considered in the
loss function, while the V-NIM solver employs a local Petrov-Galerkin approach
that allows the construction of variational residuals based on arbitrary
overlapping subdomains. This ensures both the satisfaction of underlying
physics and the preservation of meshfree property. We perform extensive
numerical experiments on both stationary and transient benchmark problems to
assess the effectiveness of the proposed NIM methods in terms of accuracy,
scalability, generalizability, and convergence properties. Moreover,
comparative analysis with other physics-informed machine learning methods
demonstrates that NIM, especially V-NIM, significantly enhances both accuracy
and efficiency in end-to-end predictive capabilities.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12919" title="Abstract">arXiv:2311.12919</a> [<a href="/pdf/2311.12919" title="Download PDF">pdf</a>, <a href="/format/2311.12919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPOT! Revisiting Video-Language Models for Event Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Gengyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+J">Jinhe Bi</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jindong Gu</a>, 
<a href="/search/cs?searchtype=author&query=Tresp%2C+V">Volker Tresp</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Understanding videos is an important research topic for multimodal learning.
Leveraging large-scale datasets of web-crawled video-text pairs as weak
supervision has become a pre-training paradigm for learning joint
representations and showcased remarkable potential in video understanding
tasks. However, videos can be multi-event and multi-grained, while these
video-text pairs usually contain only broad-level video captions. This raises a
question: with such weak supervision, can video representation in
video-language models gain the ability to distinguish even factual
discrepancies in textual description and understand fine-grained events? To
address this, we introduce SPOT Prober, to benchmark existing video-language
models's capacities of distinguishing event-level discrepancies as an indicator
of models' event understanding ability. Our approach involves extracting events
as tuples (&lt;Subject, Predicate, Object, Attribute, Timestamps&gt;) from videos and
generating false event tuples by manipulating tuple components systematically.
We reevaluate the existing video-language models with these positive and
negative captions and find they fail to distinguish most of the manipulated
events. Based on our findings, we propose to plug in these manipulated event
captions as hard negative samples and find them effective in enhancing models
for event understanding.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12943" title="Abstract">arXiv:2311.12943</a> [<a href="/pdf/2311.12943" title="Download PDF">pdf</a>, <a href="/format/2311.12943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InteRACT: Transformer Models for Human Intent Prediction Conditioned on  Robot Actions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kedia%2C+K">Kushal Kedia</a>, 
<a href="/search/cs?searchtype=author&query=Bhardwaj%2C+A">Atiksh Bhardwaj</a>, 
<a href="/search/cs?searchtype=author&query=Dan%2C+P">Prithwish Dan</a>, 
<a href="/search/cs?searchtype=author&query=Choudhury%2C+S">Sanjiban Choudhury</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">In collaborative human-robot manipulation, a robot must predict human intents
and adapt its actions accordingly to smoothly execute tasks. However, the
human's intent in turn depends on actions the robot takes, creating a
chicken-or-egg problem. Prior methods ignore such inter-dependency and instead
train marginal intent prediction models independent of robot actions. This is
because training conditional models is hard given a lack of paired human-robot
interaction datasets.
<br />Can we instead leverage large-scale human-human interaction data that is more
easily accessible? Our key insight is to exploit a correspondence between human
and robot actions that enables transfer learning from human-human to
human-robot data. We propose a novel architecture, InteRACT, that pre-trains a
conditional intent prediction model on large human-human datasets and
fine-tunes on a small human-robot dataset. We evaluate on a set of real-world
collaborative human-robot manipulation tasks and show that our conditional
model improves over various marginal baselines. We also introduce new
techniques to tele-operate a 7-DoF robot arm and collect a diverse range of
human-robot collaborative manipulation data, which we open-source.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12944" title="Abstract">arXiv:2311.12944</a> [<a href="/pdf/2311.12944" title="Download PDF">pdf</a>, <a href="/format/2311.12944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DroneOptiNet: A Framework for Optimal Drone-based Load Redistribution  Mechanism for 5G and Beyond Solar Small Cell Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dave%2C+D">Daksh Dave</a>, 
<a href="/search/cs?searchtype=author&query=Chamola%2C+V">Vinay Chamola</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+S">Sandeep Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Zeadally%2C+S">Sherali Zeadally</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">The power requirements posed by the fifth-generation and beyond cellular
networks are an important constraint in network deployment and require
energy-efficient solutions. In this work, we propose a novel user load transfer
approach using airborne base stations (BS), mounted on drones, for reliable and
secure power redistribution across the micro-grid network comprising green
small cell BSs. Depending on the user density and the availability of an aerial
BS, the energy requirement of a cell with an energy deficit is accommodated by
migrating the aerial BS from a high-energy to a low-energy cell. The proposed
hybrid drone-based framework integrates long short-term memory with unique cost
functions using an evolutionary neural network for drones and BSs, and
efficiently manages energy and load redistribution. The proposed algorithm
reduces power outages at BSs and maintains consistent throughput stability,
thereby demonstrating its capability to boost the reliability and robustness of
wireless communication systems.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12945" title="Abstract">arXiv:2311.12945</a> [<a href="/pdf/2311.12945" title="Download PDF">pdf</a>, <a href="/ps/2311.12945" title="Download PostScript">ps</a>, <a href="/format/2311.12945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalization of Trigonometric B-splines and Kernels of Interpolating  Trigonometric Splines with Riemann Convergence Multipliers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Denysiuk%2C+V">Volodymyr Denysiuk</a>, 
<a href="/search/math?searchtype=author&query=Hryshko%2C+O">Olena Hryshko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper explores the generalization of the method for extracting Riemann
trigonometric B-splines and Riemann kernels of trigonometric interpolation
splines of arbitrary order on different grids of stitching and interpolation.
It is demonstrated that for various combinations of stitching and interpolation
grids, distinct trigonometric B-splines exist. The theoretical principles are
illustrated through a numerical example. The obtained results can have various
practical applications.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12947" title="Abstract">arXiv:2311.12947</a> [<a href="/pdf/2311.12947" title="Download PDF">pdf</a>, <a href="/format/2311.12947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PINNs-Based Uncertainty Quantification for Transient Stability Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ren Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+M">Ming Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kaidi Xu</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez-Cort%C3%A9s%2C+L+G">Lola Gir&#xe1;ldez S&#xe1;nchez-Cort&#xe9;s</a>, 
<a href="/search/cs?searchtype=author&query=de+Cominges+Guerra%2C+I">Ignacio de Cominges Guerra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper addresses the challenge of transient stability in power systems
with missing parameters and uncertainty propagation in swing equations. We
introduce a novel application of Physics-Informed Neural Networks (PINNs),
specifically an Ensemble of PINNs (E-PINNs), to estimate critical parameters
like rotor angle and inertia coefficient with enhanced accuracy and reduced
computational load. E-PINNs capitalize on the underlying physical principles of
swing equations to provide a robust solution. Our approach not only facilitates
efficient parameter estimation but also quantifies uncertainties, delivering
probabilistic insights into the system behavior. The efficacy of E-PINNs is
demonstrated through the analysis of $1$-bus and $2$-bus systems, highlighting
the model's ability to handle parameter variability and data scarcity. The
study advances the application of machine learning in power system stability,
paving the way for reliable and computationally efficient transient stability
analysis.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12948" title="Abstract">arXiv:2311.12948</a> [<a href="/pdf/2311.12948" title="Download PDF">pdf</a>, <a href="/format/2311.12948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A web-based gamification of upper extremity robotic rehabilitation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharafianardakani%2C+P">Payman Sharafianardakani</a>, 
<a href="/search/cs?searchtype=author&query=Moradi%2C+H">Hadi Moradi</a>, 
<a href="/search/cs?searchtype=author&query=Bahrami%2C+F">Fariba Bahrami</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2021 International Serious Games Symposium (ISGS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In recent years, gamification has become very popular for rehabilitating
different cognitive and motor problems. It has been shown that rehabilitation
is effective when it starts early enough and it is intensive and repetitive.
However, the success of rehabilitation depends also on the motivation and
perseverance of patients during treatment. Adding serious games to the
rehabilitation procedure will help the patients to overcome the monotonicity of
the treatment procedure. On the other hand, if a variety of games can be used
with a robotic rehabilitation system, it will help to define tasks with
different levels of difficulty with greater variety. In this paper we introduce
a procedure for connecting a rehabilitation robot to several web-based games.
In other words, an interface is designed that connects the robot to a computer
through a USB port. To validate the usefulness of the proposed approach, a
researcher designed survey was used to get feedback from several users. The
results demonstrate that having several games besides rehabilitation makes the
procedure of rehabilitation entertaining.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12952" title="Abstract">arXiv:2311.12952</a> [<a href="/pdf/2311.12952" title="Download PDF">pdf</a>, <a href="/format/2311.12952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards new challenges of modern Pentest
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bertoglio%2C+D+D">Daniel Dalalana Bertoglio</a>, 
<a href="/search/cs?searchtype=author&query=Gil%2C+A">Arthur Gil</a>, 
<a href="/search/cs?searchtype=author&query=Acosta%2C+J">Juan Acosta</a>, 
<a href="/search/cs?searchtype=author&query=Godoy%2C+J">Julia Godoy</a>, 
<a href="/search/cs?searchtype=author&query=Lunardi%2C+R+C">Roben Castagna Lunardi</a>, 
<a href="/search/cs?searchtype=author&query=Zorzo%2C+A+F">Avelino Francisco Zorzo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 2 figures. Paper presented at World Conference on Smart Trends in Systems, Security, and Sustainability (WorldS4 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">With the increasing number of internet-based resources and applications, the
amount of attacks faced by companies has increased significantly in the past
years. Likewise, the techniques to test security and emulate attacks need to be
constantly improved and, as a consequence, help to mitigate attacks. Among
these techniques, penetration test (Pentest) provides methods to assess the
security posture of assets, using different tools and methodologies applied in
specific scenarios. Therefore, this study aims to present current
methodologies, tools, and potential challenges applied to Pentest from an
updated systematic literature review. As a result, this work provides a new
perspective on the scenarios where penetration tests are performed. Also, it
presents new challenges such as automation of techniques, management of costs
associated with offensive security, and the difficulty in hiring qualified
professionals to perform Pentest.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12955" title="Abstract">arXiv:2311.12955</a> [<a href="/pdf/2311.12955" title="Download PDF">pdf</a>, <a href="/format/2311.12955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Don&#x27;t forget private retrieval: distributed private similarity search  for large language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zyskind%2C+G">Guy Zyskind</a>, 
<a href="/search/cs?searchtype=author&query=South%2C+T">Tobin South</a>, 
<a href="/search/cs?searchtype=author&query=Pentland%2C+A">Alex Pentland</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">While the flexible capabilities of large language models (LLMs) allow them to
answer a range of queries based on existing learned knowledge, information
retrieval to augment generation is an important tool to allow LLMs to answer
questions on information not included in pre-training data. Such private
information is increasingly being generated in a wide array of distributed
contexts by organizations and individuals. Performing such information
retrieval using neural embeddings of queries and documents always leaked
information about queries and database content unless both were stored locally.
We present Private Retrieval Augmented Generation (PRAG), an approach that uses
multi-party computation (MPC) to securely transmit queries to a distributed set
of servers containing a privately constructed database to return top-k and
approximate top-k documents. This is a first-of-its-kind approach to dense
information retrieval that ensures no server observes a client's query or can
see the database content. The approach introduces a novel MPC friendly protocol
for inverted file approximate search (IVF) that allows for fast document search
over distributed and private data in sublinear communication complexity. This
work presents new avenues through which data for use in LLMs can be accessed
and used without needing to centralize or forgo privacy.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12956" title="Abstract">arXiv:2311.12956</a> [<a href="/pdf/2311.12956" title="Download PDF">pdf</a>, <a href="/format/2311.12956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Innovative Horizons in Aerial Imagery: LSKNet Meets DiffusionDet for  Advanced Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharshar%2C+A">Ahmed Sharshar</a>, 
<a href="/search/cs?searchtype=author&query=Matsun%2C+A">Aleksandr Matsun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In the realm of aerial image analysis, object detection plays a pivotal role,
with significant implications for areas such as remote sensing, urban planning,
and disaster management. This study addresses the inherent challenges in this
domain, notably the detection of small objects, managing densely packed
elements, and accounting for diverse orientations. We present an in-depth
evaluation of an object detection model that integrates the Large Selective
Kernel Network (LSKNet)as its backbone with the DiffusionDet head, utilizing
the iSAID dataset for empirical analysis. Our approach encompasses the
introduction of novel methodologies and extensive ablation studies. These
studies critically assess various aspects such as loss functions, box
regression techniques, and classification strategies to refine the model's
precision in object detection. The paper details the experimental application
of the LSKNet backbone in synergy with the DiffusionDet heads, a combination
tailored to meet the specific challenges in aerial image object detection. The
findings of this research indicate a substantial enhancement in the model's
performance, especially in the accuracy-time tradeoff. The proposed model
achieves a mean average precision (MAP) of approximately 45.7%, which is a
significant improvement, outperforming the RCNN model by 4.7% on the same
dataset. This advancement underscores the effectiveness of the proposed
modifications and sets a new benchmark in aerial image analysis, paving the way
for more accurate and efficient object detection methodologies. The code is
publicly available at https://github.com/SashaMatsun/LSKDiffDet
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12961" title="Abstract">arXiv:2311.12961</a> [<a href="/pdf/2311.12961" title="Download PDF">pdf</a>, <a href="/format/2311.12961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demystifying the buzzword behind Digital Twin: a novel generic  evaluation model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Araghi%2C+S+N">Sina Namaki Araghi</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+A">Arkopaul Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Karray%2C+M+H">Mohamed Hedi Karray</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a draft of the article that subject to future change and correction
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Despite the growing popularity of digital twin (DT) developments, there is a
lack of common understanding and definition for important concepts of DT. It is
needed to address this gap by building a shared understanding of DT before it
becomes an obstacle for future work. With this challenge in view, the objective
of our study is to assess the existing DT from various domains on a common
basis and to unify the knowledge and understanding of DT developers and
stakeholders before practice. To achieve this goal, we conducted a systematic
literature review and analyzed 25 selected papers to identify and discuss the
characteristics of existing DT's. The review shows an inconsistency and
case-specific choices of dimensions in assessing DT. Therefore, this article
proposes a four-dimensional evaluation framework to assess the maturity of
digital twins across different domains, focusing on the characteristics of
digital models. The four identified dimensions in this model are Capability,
Cooperability, Coverage, and Lifecycle. Additionally, a weight mechanism is
implemented inside the model to adapt the importance of each dimension for
different application requirements. Several case studies are devised to
validate the proposed model in general, industrial and scientific cases.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12965" title="Abstract">arXiv:2311.12965</a> [<a href="/pdf/2311.12965" title="Download PDF">pdf</a>, <a href="/format/2311.12965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Terrestrial-Satellite Spectrum Sharing in the Upper Mid-Band with  Interference Nulling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kang%2C+S">Seongjoon Kang</a>, 
<a href="/search/eess?searchtype=author&query=Geraci%2C+G">Giovanni Geraci</a>, 
<a href="/search/eess?searchtype=author&query=Mezzavilla%2C+M">Marco Mezzavilla</a>, 
<a href="/search/eess?searchtype=author&query=Rangan%2C+S">Sundeep Rangan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The growing demand for broader bandwidth in cellular networks has turned the
upper mid-band (7-24 GHz) into a focal point for expansion. However, the
integration of terrestrial cellular and incumbent satellite services,
particularly in the 12 GHz band, poses significant interference challenges.
This paper investigates the interference dynamics in terrestrial-satellite
coexistence scenarios and introduces a novel beamforming approach that
leverages available ephemeris data for dynamic interference mitigation. By
establishing spatial radiation nulls directed towards visible satellites, our
technique ensures the protection of satellite uplink communications without
markedly compromising terrestrial downlink quality. Through a practical case
study, we demonstrate that our approach maintains the satellite uplink
signal-to-noise ratio (SNR) degradation under 1 dB and incurs a median SNR
penalty of only 0.1 dB for the terrestrial downlink. Our findings offer a
promising pathway for efficient spectrum sharing in the upper mid-band,
fostering a concurrent enhancement in both terrestrial and satellite network
capacity.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12967" title="Abstract">arXiv:2311.12967</a> [<a href="/pdf/2311.12967" title="Download PDF">pdf</a>, <a href="/format/2311.12967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robustifying Generalizable Implicit Shape Networks with a Tunable  Non-Parametric Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ouasfi%2C+A">Amine Ouasfi</a>, 
<a href="/search/cs?searchtype=author&query=Boukhayma%2C+A">Adnane Boukhayma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Feedforward generalizable models for implicit shape reconstruction from
unoriented point cloud present multiple advantages, including high performance
and inference speed. However, they still suffer from generalization issues,
ranging from underfitting the input point cloud, to misrepresenting samples
outside of the training data distribution, or with toplogies unseen at
training. We propose here an efficient mechanism to remedy some of these
limitations at test time. We combine the inter-shape data prior of the network
with an intra-shape regularization prior of a Nystr\"om Kernel Ridge
Regression, that we further adapt by fitting its hyperprameters to the current
shape. The resulting shape function defined in a shape specific Reproducing
Kernel Hilbert Space benefits from desirable stability and efficiency
properties and grants a shape adaptive expressiveness-robustness trade-off. We
demonstrate the improvement obtained through our method with respect to
baselines and the state-of-the-art using synthetic and real data.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12968" title="Abstract">arXiv:2311.12968</a> [<a href="/pdf/2311.12968" title="Download PDF">pdf</a>, <a href="/ps/2311.12968" title="Download PostScript">ps</a>, <a href="/format/2311.12968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bit Error Rate Performance and Diversity Analysis for Mediumband  Wireless Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Basnayaka%2C+D+A">Dushyantha A Basnayaka</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jiabin Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures, Accepted for Publication in the Proceedings of IEEE VCC 2023, 28-30 Nov. 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of IEEE VCC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Mediumband wireless communication refers to wireless communication through a
class of channels known as mediumband that exists on the TmTs-plane. This
paper, through statistical analysis and computer simulations, studies the
performance limits of this class of channels in terms of uncoded bit error rate
(BER) and diversity order. We show that, owing mainly to the effect of the deep
fading avoidance, which is unique to the channels in the mediumband region,
mediumband wireless systems, if designed judiciously, have the potential to
achieve significantly superior error rate and higher order diversity even in
non-line-of-sight (NLoS) propagation environments where the achievable
diversity order is otherwise low.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12970" title="Abstract">arXiv:2311.12970</a> [<a href="/pdf/2311.12970" title="Download PDF">pdf</a>, <a href="/format/2311.12970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clustered Policy Decision Ranking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Levin%2C+M">Mark Levin</a>, 
<a href="/search/cs?searchtype=author&query=Chockler%2C+H">Hana Chockler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 4 figures. arXiv admin note: text overlap with <a href="/abs/2111.08415">arXiv:2111.08415</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Policies trained via reinforcement learning (RL) are often very complex even
for simple tasks. In an episode with n time steps, a policy will make n
decisions on actions to take, many of which may appear non-intuitive to the
observer. Moreover, it is not clear which of these decisions directly
contribute towards achieving the reward and how significant their contribution
is. Given a trained policy, we propose a black-box method based on statistical
covariance estimation that clusters the states of the environment and ranks
each cluster according to the importance of decisions made in its states. We
compare our measure against a previous statistical fault localization based
ranking procedure.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12976" title="Abstract">arXiv:2311.12976</a> [<a href="/pdf/2311.12976" title="Download PDF">pdf</a>, <a href="/ps/2311.12976" title="Download PostScript">ps</a>, <a href="/format/2311.12976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Deterministic Rendezvous in Labeled Lines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miller%2C+A">Avery Miller</a>, 
<a href="/search/cs?searchtype=author&query=Pelc%2C+A">Andrzej Pelc</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A preliminary version of this paper appeared in the Proceedings of the 37th International Symposium on Distributed Computing (DISC 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Two mobile agents, starting from different nodes of a network modeled as a
graph, and woken up at possibly different times, have to meet at the same node.
This problem is known as rendezvous. We consider deterministic distributed
rendezvous in the infinite path. Each node has a distinct label which is a
positive integer. The time of rendezvous is the number of rounds until meeting,
counted from the starting round of the earlier agent. We consider three
scenarios. In the first scenario, each agent knows its position in the line,
i.e., each of them knows its initial distance from the smallest-labeled node,
on which side of this node it is located, and the direction towards it. For
this scenario, we give a rendezvous algorithm working in time $O(D)$, where $D$
is the initial distance between the agents. This complexity is clearly optimal.
In the second scenario, each agent initially knows only the label of its
starting node and the initial distance $D$ between the agents. In this
scenario, we give a rendezvous algorithm working in time $O(D\log^*\ell)$,
where $\ell$ is the larger label of the starting nodes. We prove a matching
lower bound $\Omega(D\log^*\ell)$. Finally, in the most general scenario, where
each agent initially knows only the label of its starting node, we give a
rendezvous algorithm working in time $O(D^2(\log^*\ell)^3)$, which is at most
cubic in the lower bound. All our results remain valid (with small changes) for
arbitrary finite paths and for cycles. Our algorithms are drastically better
than approaches that use graph exploration, whose running times depend on the
graph's size or diameter. Our main methodological tool, and the main novelty of
the paper, is a two way reduction: from fast colouring of the infinite labeled
path using a constant number of colours in the LOCAL model to fast rendezvous
in this path, and vice-versa.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12977" title="Abstract">arXiv:2311.12977</a> [<a href="/pdf/2311.12977" title="Download PDF">pdf</a>, <a href="/ps/2311.12977" title="Download PostScript">ps</a>, <a href="/format/2311.12977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is your vote truly secret? Ballot Secrecy iff Ballot Independence:  Proving necessary conditions and analysing case studies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kharman%2C+A+M">Aida Manzano Kharman</a>, 
<a href="/search/cs?searchtype=author&query=Smyth%2C+B">Ben Smyth</a>, 
<a href="/search/cs?searchtype=author&query=Page%2C+F">Freddie Page</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">We formalise definitions of ballot secrecy and ballot independence by Smyth,
JCS'21 as indistinguishability games in the computational model of security.
These definitions improve upon Smyth, draft '21 to consider a wider class of
voting systems. Both Smyth, JCS'21 and Smyth, draft '21 improve on earlier
works by considering a more realistic adversary model wherein they have access
to the ballot collection. We prove that ballot secrecy implies ballot
independence. We say ballot independence holds if a system has non-malleable
ballots. We construct games for ballot secrecy and non-malleability and show
that voting schemes with malleable ballots do not preserve ballot secrecy. We
demonstrate that Helios does not satisfy our definition of ballot secrecy.
Furthermore, the Python framework we constructed for our case study shows that
if an attack exists against non-malleability, this attack can be used to break
ballot secrecy.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12981" title="Abstract">arXiv:2311.12981</a> [<a href="/pdf/2311.12981" title="Download PDF">pdf</a>, <a href="/format/2311.12981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SD-NAE: Generating Natural Adversarial Examples with Stable Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yueqian Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jingyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiran Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hai Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Robustly evaluating deep learning image classifiers is challenging due to
some limitations of standard datasets. Natural Adversarial Examples (NAEs),
arising naturally from the environment and capable of deceiving classifiers,
are instrumental in identifying vulnerabilities in trained models. Existing
works collect such NAEs by filtering from a huge set of real images, a process
that is passive and lacks control. In this work, we propose to actively
synthesize NAEs with the state-of-the-art Stable Diffusion. Specifically, our
method formulates a controlled optimization process, where we perturb the token
embedding that corresponds to a specified class to synthesize NAEs. The
generation is guided by the gradient of loss from the target classifier so that
the created image closely mimics the ground-truth class yet fools the
classifier. Named SD-NAE (Stable Diffusion for Natural Adversarial Examples),
our innovative method is effective in producing valid and useful NAEs, which is
demonstrated through a meticulously designed experiment. Our work thereby
provides a valuable method for obtaining challenging evaluation data, which in
turn can potentially advance the development of more robust deep learning
models. Code is available at https://github.com/linyueqian/SD-NAE.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12983" title="Abstract">arXiv:2311.12983</a> [<a href="/pdf/2311.12983" title="Download PDF">pdf</a>, <a href="/format/2311.12983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GAIA: a benchmark for General AI Assistants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mialon%2C+G">Gr&#xe9;goire Mialon</a>, 
<a href="/search/cs?searchtype=author&query=Fourrier%2C+C">Cl&#xe9;mentine Fourrier</a>, 
<a href="/search/cs?searchtype=author&query=Swift%2C+C">Craig Swift</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+T">Thomas Wolf</a>, 
<a href="/search/cs?searchtype=author&query=LeCun%2C+Y">Yann LeCun</a>, 
<a href="/search/cs?searchtype=author&query=Scialom%2C+T">Thomas Scialom</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We introduce GAIA, a benchmark for General AI Assistants that, if solved,
would represent a milestone in AI research. GAIA proposes real-world questions
that require a set of fundamental abilities such as reasoning, multi-modality
handling, web browsing, and generally tool-use proficiency. GAIA questions are
conceptually simple for humans yet challenging for most advanced AIs: we show
that human respondents obtain 92\% vs. 15\% for GPT-4 equipped with plugins.
This notable performance disparity contrasts with the recent trend of LLMs
outperforming humans on tasks requiring professional skills in e.g. law or
chemistry. GAIA's philosophy departs from the current trend in AI benchmarks
suggesting to target tasks that are ever more difficult for humans. We posit
that the advent of Artificial General Intelligence (AGI) hinges on a system's
capability to exhibit similar robustness as the average human does on such
questions. Using GAIA's methodology, we devise 466 questions and their answer.
We release our questions while retaining answers to 300 of them to power a
leader-board available at https://huggingface.co/gaia-benchmark.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12984" title="Abstract">arXiv:2311.12984</a> [<a href="/pdf/2311.12984" title="Download PDF">pdf</a>, <a href="/ps/2311.12984" title="Download PostScript">ps</a>, <a href="/format/2311.12984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information Diffusion, Word-of-mouth effects, and Mutual Funds  Performance: A Mathematical Modelling Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mushunje%2C+L">Leonard Mushunje</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">This paper puts forward that money managers and prospective investors
exchange information and ideas about assets directly through word-of-mouth
communication. This, in turn, affects the performance of the mutual funds and
their respective managers. We develop a novel "Epi-Finance" model that connects
epidemiology and finance to provide a solid explanation behind information
transmission in the fund industry. By considering factors such as location,
race, gender, and education concerning the equity market, several claims and
connections are observed and modeled using an epidemic model. For example,
based on location, a mutual fund manager is likelier to buy (or sell) a
particular equity at any time if other managers in the
{\epsilon}-neighborhoods({\epsilon}&gt;0) are buying (or selling) that same
equity. If the information about that particular equity spreads fast and the
communication network is well connected, the same pattern shows up even when
the fund managers are far apart. Also, a male fund manager is likelier to
relate his investment style to other male managers, which is true otherwise.
The same fashionable results are expected on race education, among others with
special contextual differences.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12986" title="Abstract">arXiv:2311.12986</a> [<a href="/pdf/2311.12986" title="Download PDF">pdf</a>, <a href="/format/2311.12986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Graph Attention Autoencoder for Attributed Networks using  K-means Loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bekkaira%2C+A">Abdelfateh Bekkaira</a>, 
<a href="/search/cs?searchtype=author&query=Bellaouar%2C+S">Slimane Bellaouar</a>, 
<a href="/search/cs?searchtype=author&query=Oulad-Naoui%2C+S">Slimane Oulad-Naoui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multimodal Sentiment Analysis (MSA) has recently become a centric research
direction for many real-world applications. This proliferation is due to the
fact that opinions are central to almost all human activities and are key
influencers of our behaviors. In addition, the recent deployment of Deep
Learning-based (DL) models has proven their high efficiency for a wide range of
Western languages. In contrast, Arabic DL-based multimodal sentiment analysis
(MSA) is still in its infantile stage due, mainly, to the lack of standard
datasets. % The contribution In this paper, our investigation is twofold.
First, we design a pipeline that helps building our Arabic Multimodal dataset
leveraging both state-of-the-art transformers and feature extraction tools
within word alignment techniques. Thereafter, we validate our dataset using
state-of-the-art transformer-based model dealing with multimodality. Despite
the small size of the outcome dataset, experiments show that Arabic
multimodality is very promising.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12987" title="Abstract">arXiv:2311.12987</a> [<a href="/pdf/2311.12987" title="Download PDF">pdf</a>, <a href="/ps/2311.12987" title="Download PostScript">ps</a>, <a href="/format/2311.12987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Volatility and irregularity Capturing in stock price indices using time  series Generative adversarial networks (TimeGAN)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mushunje%2C+L">Leonard Mushunje</a>, 
<a href="/search/cs?searchtype=author&query=Allen%2C+D">David Allen</a>, 
<a href="/search/cs?searchtype=author&query=Peiris%2C+S">Shelton Peiris</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">This paper captures irregularities in financial time series data,
particularly stock prices, in the presence of COVID-19 shock. We conjectured
that jumps and irregularities are embedded in stock data due to the pandemic
shock, which brings forth irregular trends in the time series data. We put
forward that efficient and robust forecasting methods are needed to predict
stock closing prices in the presence of the pandemic shock. This piece of
information is helpful to investors as far as confidence risk and return boost
are concerned. Generative adversarial networks of a time series nature are used
to provide new ways of modeling and learning the proper and suitable
distribution for the financial time series data under complex setups. Ideally,
these traditional models are liable to producing high forecasting errors, and
they need to be more robust to capture dependency structures and other stylized
facts like volatility in stock markets. The TimeGAN model is used, effectively
dealing with this risk of poor forecasts. Using the DAX stock index from
January 2010 to November 2022, we trained the LSTM, GRU, WGAN, and TimeGAN
models as benchmarks and forecasting errors were noted, and our TimeGAN
outperformed them all as indicated by a small forecasting error.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12989" title="Abstract">arXiv:2311.12989</a> [<a href="/pdf/2311.12989" title="Download PDF">pdf</a>, <a href="/format/2311.12989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Controlled Study on Evaluation of Thermal Stimulation Influence on  Affective Measures of Uninformed Individuals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hojatmadani%2C+M">Mehdi Hojatmadani</a>, 
<a href="/search/cs?searchtype=author&query=Shepard%2C+S">Samantha Shepard</a>, 
<a href="/search/cs?searchtype=author&query=Salomon%2C+K">Kristen Salomon</a>, 
<a href="/search/cs?searchtype=author&query=Reed%2C+K">Kyle Reed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Although the relationship between temperature and emotional states has been
investigated in the field of haptics, it remains unknown if, or in what
direction, temperature affects emotional states. We approach this question at
the intersection of haptics and psychology using a custom-built thermal device
and emotional responses based on photos from the International Affective
Picture System (IAPS) library. Unlike past research, this study incorporates
deception and a control (i.e., neutral temperature) condition. One hundred and
twenty naive subjects reported their emotional responses to fifty-six images
varying on normative arousal and valence ratings while being exposed to a
cool~(30{\deg}C), neutral (33{\deg}C), or warm (36{\deg}C) temperature applied
to the upper back. Participants exposed to warm temperatures reported higher
arousal ratings in some image categories than participants exposed to neutral
or cool temperatures. Valence ratings were decreased in warm conditions
compared to neutral conditions. The emotion wheel was used as a complementary
method of affective response measurement, and exploratory analysis methods were
implemented. Although the valence and arousal showed statistical significance,
the emotion wheel results did not demonstrate any significant differences
between the temperature conditions.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12990" title="Abstract">arXiv:2311.12990</a> [<a href="/pdf/2311.12990" title="Download PDF">pdf</a>, <a href="/format/2311.12990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NERIF: GPT-4V for Automatic Scoring of Drawn Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+G">Gyeong-Geon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xiaoming Zhai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Scoring student-drawn models is time-consuming. Recently released GPT-4V
provides a unique opportunity to advance scientific modeling practices by
leveraging the powerful image processing capability. To test this ability
specifically for automatic scoring, we developed a method NERIF
(Notation-Enhanced Rubric Instruction for Few-shot Learning) employing
instructional note and rubrics to prompt GPT-4V to score students' drawn models
for science phenomena. We randomly selected a set of balanced data (N = 900)
that includes student-drawn models for six modeling assessment tasks. Each
model received a score from GPT-4V ranging at three levels: 'Beginning,'
'Developing,' or 'Proficient' according to scoring rubrics. GPT-4V scores were
compared with human experts' scores to calculate scoring accuracy. Results show
that GPT-4V's average scoring accuracy was mean =.51, SD = .037. Specifically,
average scoring accuracy was .64 for the 'Beginning' class, .62 for the
'Developing' class, and .26 for the 'Proficient' class, indicating that more
proficient models are more challenging to score. Further qualitative study
reveals how GPT-4V retrieves information from image input, including problem
context, example evaluations provided by human coders, and students' drawing
models. We also uncovered how GPT-4V catches the characteristics of
student-drawn models and narrates them in natural language. At last, we
demonstrated how GPT-4V assigns scores to student-drawn models according to the
given scoring rubric and instructional notes. Our findings suggest that the
NERIF is an effective approach for employing GPT-4V to score drawn models. Even
though there is space for GPT-4V to improve scoring accuracy, some mis-assigned
scores seemed interpretable to experts. The results of this study show that
utilizing GPT-4V for automatic scoring of student-drawn models is promising.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12992" title="Abstract">arXiv:2311.12992</a> [<a href="/pdf/2311.12992" title="Download PDF">pdf</a>, <a href="/format/2311.12992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FollowMe: a Robust Person Following Framework Based on Re-Identification  and Gestures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rollo%2C+F">Federico Rollo</a>, 
<a href="/search/cs?searchtype=author&query=Zunino%2C+A">Andrea Zunino</a>, 
<a href="/search/cs?searchtype=author&query=Raiola%2C+G">Gennaro Raiola</a>, 
<a href="/search/cs?searchtype=author&query=Amadio%2C+F">Fabio Amadio</a>, 
<a href="/search/cs?searchtype=author&query=Ajoudani%2C+A">Arash Ajoudani</a>, 
<a href="/search/cs?searchtype=author&query=Tsagarakis%2C+N">Nikolaos Tsagarakis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> published in "2023 IEEE International Conference on Advanced Robotics and Its Social Impacts (ARSO)"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Human-robot interaction (HRI) has become a crucial enabler in houses and
industries for facilitating operational flexibility. When it comes to mobile
collaborative robots, this flexibility can be further increased due to the
autonomous mobility and navigation capacity of the robotic agents, expanding
their workspace and consequently, the personalizable assistance they can
provide to the human operators. This however requires that the robot is capable
of detecting and identifying the human counterpart in all stages of the
collaborative task, and in particular while following a human in crowded
workplaces. To respond to this need, we developed a unified perception and
navigation framework, which enables the robot to identify and follow a target
person using a combination of visual Re-Identification (Re-ID), hand gestures
detection, and collision-free navigation. The Re-ID module can autonomously
learn the features of a target person and use the acquired knowledge to
visually re-identify the target. The navigation stack is used to follow the
target avoiding obstacles and other individuals in the environment. Experiments
are conducted with few subjects in a laboratory setting where some unknown
dynamic obstacles are introduced.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12993" title="Abstract">arXiv:2311.12993</a> [<a href="/pdf/2311.12993" title="Download PDF">pdf</a>, <a href="/format/2311.12993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI for Agriculture: the Comparison of Semantic Segmentation Methods for  Crop Mapping with Sentinel-2 Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Korotkova%2C+I">Irina Korotkova</a>, 
<a href="/search/cs?searchtype=author&query=Efremova%2C+N">Natalia Efremova</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Crop mapping is one of the most common tasks in artificial intelligence for
agriculture due to higher food demands from a growing population and increased
awareness of climate change. In case of vineyards, the texture is very
important for crop segmentation: with higher resolution satellite imagery the
texture is easily detected by majority of state-of-the-art algorithms. However,
this task becomes increasingly more difficult as the resolution of satellite
imagery decreases and the information about the texture becomes unavailable. In
this paper we aim to explore the main machine learning methods that can be used
with freely available satellite imagery and discuss how and when they can be
applied for vineyard segmentation problem. We assess the effectiveness of
various widely-used machine learning techniques and offer guidance on selecting
the most suitable model for specific scenarios.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12994" title="Abstract">arXiv:2311.12994</a> [<a href="/pdf/2311.12994" title="Download PDF">pdf</a>, <a href="/format/2311.12994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sum-of-Squares Lower Bounds for the Minimum Circuit Size Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Austrin%2C+P">Per Austrin</a>, 
<a href="/search/cs?searchtype=author&query=Risse%2C+K">Kilian Risse</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A conference version appeared previously in CCC'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">We prove lower bounds for the Minimum Circuit Size Problem (MCSP) in the
Sum-of-Squares (SoS) proof system. Our main result is that for every Boolean
function $f: \{0,1\}^n \rightarrow \{0,1\}$, SoS requires degree
$\Omega(s^{1-\epsilon})$ to prove that $f$ does not have circuits of size $s$
(for any $s &gt; \mathrm{poly}(n)$). As a corollary we obtain that there are no
low degree SoS proofs of the statement NP $\not \subseteq $ P/poly.
<br />We also show that for any $0 &lt; \alpha &lt; 1$ there are Boolean functions with
circuit complexity larger than $2^{n^{\alpha}}$ but SoS requires size
$2^{2^{\Omega(n^{\alpha})}}$ to prove this. In addition we prove analogous
results on the minimum \emph{monotone} circuit size for monotone Boolean slice
functions.
<br />Our approach is quite general. Namely, we show that if a proof system $Q$ has
strong enough constraint satisfaction problem lower bounds that only depend on
good expansion of the constraint-variable incidence graph and, furthermore, $Q$
is expressive enough that variables can be substituted by local Boolean
functions, then the MCSP problem is hard for $Q$.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12996" title="Abstract">arXiv:2311.12996</a> [<a href="/pdf/2311.12996" title="Download PDF">pdf</a>, <a href="/format/2311.12996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RLIF: Interactive Imitation Learning as Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jianlan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+P">Perry Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+Y">Yuexiang Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+S">Sergey Levine</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Although reinforcement learning methods offer a powerful framework for
automatic skill acquisition, for practical learning-based control problems in
domains such as robotics, imitation learning often provides a more convenient
and accessible alternative. In particular, an interactive imitation learning
method such as DAgger, which queries a near-optimal expert to intervene online
to collect correction data for addressing the distributional shift challenges
that afflict na\"ive behavioral cloning, can enjoy good performance both in
theory and practice without requiring manually specified reward functions and
other components of full reinforcement learning methods. In this paper, we
explore how off-policy reinforcement learning can enable improved performance
under assumptions that are similar but potentially even more practical than
those of interactive imitation learning. Our proposed method uses reinforcement
learning with user intervention signals themselves as rewards. This relaxes the
assumption that intervening experts in interactive imitation learning should be
near-optimal and enables the algorithm to learn behaviors that improve over the
potential suboptimal human expert. We also provide a unified framework to
analyze our RL method and DAgger; for which we present the asymptotic analysis
of the suboptimal gap for both methods as well as the non-asymptotic sample
complexity bound of our method. We then evaluate our method on challenging
high-dimensional continuous control simulation benchmarks as well as real-world
robotic vision-based manipulation tasks. The results show that it strongly
outperforms DAgger-like approaches across the different tasks, especially when
the intervening experts are suboptimal. Code and videos can be found on the
project website: rlif-page.github.io
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12997" title="Abstract">arXiv:2311.12997</a> [<a href="/pdf/2311.12997" title="Download PDF">pdf</a>, <a href="/format/2311.12997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Capable Can a Transformer Become? A Study on Synthetic,  Interpretable Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramesh%2C+R">Rahul Ramesh</a>, 
<a href="/search/cs?searchtype=author&query=Khona%2C+M">Mikail Khona</a>, 
<a href="/search/cs?searchtype=author&query=Dick%2C+R+P">Robert P. Dick</a>, 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+H">Hidenori Tanaka</a>, 
<a href="/search/cs?searchtype=author&query=Lubana%2C+E+S">Ekdeep Singh Lubana</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Transformers trained on huge text corpora exhibit a remarkable set of
capabilities, e.g., performing simple logical operations. Given the inherent
compositional nature of language, one can expect the model to learn to compose
these capabilities, potentially yielding a combinatorial explosion of what
operations it can perform on an input. Motivated by the above, we aim to assess
in this paper "how capable can a transformer become?". Specifically, we train
autoregressive Transformer models on a data-generating process that involves
compositions of a set of well-defined monolithic capabilities. Through a series
of extensive and systematic experiments on this data-generating process, we
show that: (1) autoregressive Transformers can learn compositional structures
from the training data and generalize to exponentially or even combinatorially
many functions; (2) composing functions by generating intermediate outputs is
more effective at generalizing to unseen compositions, compared to generating
no intermediate outputs; (3) the training data has a significant impact on the
model's ability to compose unseen combinations of functions; and (4) the
attention layers in the latter half of the model are critical to
compositionality.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12998" title="Abstract">arXiv:2311.12998</a> [<a href="/pdf/2311.12998" title="Download PDF">pdf</a>, <a href="/ps/2311.12998" title="Download PostScript">ps</a>, <a href="/format/2311.12998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Systematic Review Protocol: Requirements Engineering in Quantum  Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sep%C3%BAlveda%2C+S">Samuel Sep&#xfa;lveda</a>, 
<a href="/search/cs?searchtype=author&query=Cravero%2C+A">Ania Cravero</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">Context: Quantum computing (QC) represents a paradigm shift in computational
capabilities, presenting unique challenges in requirements engineering (RE).
The complexity of quantum systems and rapid technological advancements
necessitate a comprehensive understanding of the current state and future
trajectories in RE for QC. Objective: A protocol for carrying out a systematic
literature review about the evidence for identifying and analyzing the
challenges in RE for QC software. It seeks to evaluate the current
methodologies employed in this domain and propose a forward-looking perspective
on the evolution of these methodologies to meet future industry and academic
needs. Method: This protocol employs a structured approach to search and
analyze relevant literature systematically, according to Barbara Kitchenham's
guidelines. Results: A validated protocol to conduct a systematic review. The
protocol is expected to yield diverse literature spanning theoretical
frameworks, empirical studies, and methodological advancements in RE for QC. It
will highlight the current challenges, opportunities, and future directions,
offering insights into the field's academic and practical aspects. Conclusions:
The systematic review aims to provide a nuanced understanding of the RE
landscape in QC. It will offer valuable insights for academic researchers,
industry professionals, software engineers, industry analysts, and educators,
shaping the future discourse in QC development.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12999" title="Abstract">arXiv:2311.12999</a> [<a href="/pdf/2311.12999" title="Download PDF">pdf</a>, <a href="/format/2311.12999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CovarNav: Machine Unlearning via Model Inversion and Covariance  Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abbasi%2C+A">Ali Abbasi</a>, 
<a href="/search/cs?searchtype=author&query=Thrash%2C+C">Chayne Thrash</a>, 
<a href="/search/cs?searchtype=author&query=Akbari%2C+E">Elaheh Akbari</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Daniel Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kolouri%2C+S">Soheil Kolouri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The rapid progress of AI, combined with its unprecedented public adoption and
the propensity of large neural networks to memorize training data, has given
rise to significant data privacy concerns. To address these concerns, machine
unlearning has emerged as an essential technique to selectively remove the
influence of specific training data points on trained models. In this paper, we
approach the machine unlearning problem through the lens of continual learning.
Given a trained model and a subset of training data designated to be forgotten
(i.e., the "forget set"), we introduce a three-step process, named CovarNav, to
facilitate this forgetting. Firstly, we derive a proxy for the model's training
data using a model inversion attack. Secondly, we mislabel the forget set by
selecting the most probable class that deviates from the actual ground truth.
Lastly, we deploy a gradient projection method to minimize the cross-entropy
loss on the modified forget set (i.e., learn incorrect labels for this set)
while preventing forgetting of the inverted samples. We rigorously evaluate
CovarNav on the CIFAR-10 and Vggface2 datasets, comparing our results with
recent benchmarks in the field and demonstrating the efficacy of our proposed
approach.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13004" title="Abstract">arXiv:2311.13004</a> [<a href="/pdf/2311.13004" title="Download PDF">pdf</a>, <a href="/format/2311.13004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Self-Consistent Field Solution for Robust Common Spatial Pattern  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Roh%2C+D+M">Dong Min Roh</a>, 
<a href="/search/math?searchtype=author&query=Bai%2C+Z">Zhaojun Bai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The common spatial pattern analysis (CSP) is a widely used signal processing
technique in brain-computer interface (BCI) systems to increase the
signal-to-noise ratio in electroencephalogram (EEG) recordings. Despite its
popularity, the CSP's performance is often hindered by the nonstationarity and
artifacts in EEG signals. The minmax CSP improves the robustness of the CSP by
using data-driven covariance matrices to accommodate the uncertainties. We show
that by utilizing the optimality conditions, the minmax CSP can be recast as an
eigenvector-dependent nonlinear eigenvalue problem (NEPv). We introduce a
self-consistent field (SCF) iteration with line search that solves the NEPv of
the minmax CSP. Local quadratic convergence of the SCF for solving the NEPv is
illustrated using synthetic datasets. More importantly, experiments with
real-world EEG datasets show the improved motor imagery classification rates
and shorter running time of the proposed SCF-based solver compared to the
existing algorithm for the minmax CSP.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13006" title="Abstract">arXiv:2311.13006</a> [<a href="/pdf/2311.13006" title="Download PDF">pdf</a>, <a href="/ps/2311.13006" title="Download PostScript">ps</a>, <a href="/format/2311.13006" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning-Augmented Dynamic Submodular Maximization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+A">Arpit Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Balkanski%2C+E">Eric Balkanski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">In dynamic submodular maximization, the goal is to maintain a high-value
solution over a sequence of element insertions and deletions with a fast update
time. Motivated by large-scale applications and the fact that dynamic data
often exhibits patterns, we ask the following question: can predictions be used
to accelerate the update time of dynamic submodular maximization algorithms?
<br />We consider the model for dynamic algorithms with predictions where
predictions regarding the insertion and deletion times of elements can be used
for preprocessing. Our main result is an algorithm with an $O(poly(\log \eta,
\log w, \log k))$ amortized update time over the sequence of updates that
achieves a $1/2 - \epsilon$ approximation in expectation for dynamic monotone
submodular maximization under a cardinality constraint $k$, where the
prediction error $\eta$ is the number of elements that are not inserted and
deleted within $w$ time steps of their predicted insertion and deletion times.
This amortized update time is independent of the length of the stream and
instead depends on the prediction error.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13008" title="Abstract">arXiv:2311.13008</a> [<a href="/pdf/2311.13008" title="Download PDF">pdf</a>, <a href="/format/2311.13008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> zkTax: A pragmatic way to support zero-knowledge tax disclosures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berke%2C+A">Alex Berke</a>, 
<a href="/search/cs?searchtype=author&query=South%2C+T">Tobin South</a>, 
<a href="/search/cs?searchtype=author&query=Mahari%2C+R">Robert Mahari</a>, 
<a href="/search/cs?searchtype=author&query=Larson%2C+K">Kent Larson</a>, 
<a href="/search/cs?searchtype=author&query=Pentland%2C+A">Alex Pentland</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Tax returns contain key financial information of interest to third parties:
public officials are asked to share financial data for transparency, companies
seek to assess the financial status of business partners, and individuals need
to prove their income to landlords or to receive benefits. Tax returns also
contain sensitive data such that sharing them in their entirety undermines
privacy. We introduce a zero-knowledge tax disclosure system (zkTax) that
allows individuals and organizations to make provable claims about select
information in their tax returns without revealing additional information,
which can be independently verified by third parties. The system consists of
three 3distinct services that can be distributed: a tax authority provides tax
documents signed with a public key; a Redact &amp; Prove Service enables users to
produce a redacted version of the tax documents with a zero-knowledge proof
attesting the provenance of the redacted data; a Verify Service enables anyone
to verify the proof. We implement a prototype with a user interface, compatible
with U.S. tax forms, and demonstrate how this design could be implemented with
minimal changes to existing tax infrastructure. Our system is designed to be
extensible to other contexts and jurisdictions. This work provides a practical
example of how distributed tools leveraging cryptography can enhance existing
government or financial infrastructures, providing immediate transparency
alongside privacy without system overhauls.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13009" title="Abstract">arXiv:2311.13009</a> [<a href="/pdf/2311.13009" title="Download PDF">pdf</a>, <a href="/ps/2311.13009" title="Download PostScript">ps</a>, <a href="/format/2311.13009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Compression Using Neural Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Postels%2C+J">Janis Postels</a>, 
<a href="/search/cs?searchtype=author&query=Str%C3%BCmpler%2C+Y">Yannick Str&#xfc;mpler</a>, 
<a href="/search/cs?searchtype=author&query=Reichard%2C+K">Klara Reichard</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>, 
<a href="/search/cs?searchtype=author&query=Tombari%2C+F">Federico Tombari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural Fields (NFs) have gained momentum as a tool for compressing various
data modalities - e.g. images and videos. This work leverages previous advances
and proposes a novel NF-based compression algorithm for 3D data. We derive two
versions of our approach - one tailored to watertight shapes based on Signed
Distance Fields (SDFs) and, more generally, one for arbitrary non-watertight
shapes using Unsigned Distance Fields (UDFs). We demonstrate that our method
excels at geometry compression on 3D point clouds as well as meshes. Moreover,
we show that, due to the NF formulation, it is straightforward to extend our
compression algorithm to compress both geometry and attribute (e.g. color) of
3D data.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13014" title="Abstract">arXiv:2311.13014</a> [<a href="/pdf/2311.13014" title="Download PDF">pdf</a>, <a href="/format/2311.13014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Graph Control Barrier Functions Guided Distributed  Collision-avoidance Multi-agent Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+S">Songyuan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Garg%2C+K">Kunal Garg</a>, 
<a href="/search/eess?searchtype=author&query=Fan%2C+C">Chuchu Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 10 figures; Accepted by 7th Conference on Robot Learning (CoRL 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">We consider the problem of designing distributed collision-avoidance
multi-agent control in large-scale environments with potentially moving
obstacles, where a large number of agents are required to maintain safety using
only local information and reach their goals. This paper addresses the problem
of collision avoidance, scalability, and generalizability by introducing graph
control barrier functions (GCBFs) for distributed control. The newly introduced
GCBF is based on the well-established CBF theory for safety guarantees but
utilizes a graph structure for scalable and generalizable decentralized
control. We use graph neural networks to learn both neural a GCBF certificate
and distributed control. We also extend the framework from handling state-based
models to directly taking point clouds from LiDAR for more practical robotics
settings. We demonstrated the efficacy of GCBF in a variety of numerical
experiments, where the number, density, and traveling distance of agents, as
well as the number of unseen and uncontrolled obstacles increase. Empirical
results show that GCBF outperforms leading methods such as MAPPO and
multi-agent distributed CBF (MDCBF). Trained with only 16 agents, GCBF can
achieve up to 3 times improvement of success rate (agents reach goals and never
encountered in any collisions) on &lt;500 agents, and still maintain more than 50%
success rates for &gt;1000 agents when other methods completely fail.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13015" title="Abstract">arXiv:2311.13015</a> [<a href="/pdf/2311.13015" title="Download PDF">pdf</a>, <a href="/format/2311.13015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast and Interpretable Mortality Risk Scores for Critical Care Patients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C+Q">Chloe Qinyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+M">Muhang Tian</a>, 
<a href="/search/cs?searchtype=author&query=Semenova%2C+L">Lesia Semenova</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiachang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jack Xu</a>, 
<a href="/search/cs?searchtype=author&query=Scarpa%2C+J">Joseph Scarpa</a>, 
<a href="/search/cs?searchtype=author&query=Rudin%2C+C">Cynthia Rudin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Prediction of mortality in intensive care unit (ICU) patients is an important
task in critical care medicine. Prior work in creating mortality risk models
falls into two major categories: domain-expert-created scoring systems, and
black box machine learning (ML) models. Both of these have disadvantages: black
box models are unacceptable for use in hospitals, whereas manual creation of
models (including hand-tuning of logistic regression parameters) relies on
humans to perform high-dimensional constrained optimization, which leads to a
loss in performance. In this work, we bridge the gap between accurate black box
models and hand-tuned interpretable models. We build on modern interpretable ML
techniques to design accurate and interpretable mortality risk scores. We
leverage the largest existing public ICU monitoring datasets, namely the MIMIC
III and eICU datasets. By evaluating risk across medical centers, we are able
to study generalization across domains. In order to customize our risk score
models, we develop a new algorithm, GroupFasterRisk, which has several
important benefits: (1) it uses hard sparsity constraint, allowing users to
directly control the number of features; (2) it incorporates group sparsity to
allow more cohesive models; (3) it allows for monotonicity correction on models
for including domain knowledge; (4) it produces many equally-good models at
once, which allows domain experts to choose among them. GroupFasterRisk creates
its risk scores within hours, even on the large datasets we study here.
GroupFasterRisk's risk scores perform better than risk scores currently used in
hospitals, and have similar prediction performance to black box ML models
(despite being much sparser). Because GroupFasterRisk produces a variety of
risk scores and handles constraints, it allows design flexibility, which is the
key enabler of practical and trustworthy model creation.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13018" title="Abstract">arXiv:2311.13018</a> [<a href="/pdf/2311.13018" title="Download PDF">pdf</a>, <a href="/format/2311.13018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention: Large Multimodal Model is Watching your Geo-privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yifan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yixian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Daoyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shuju Sun</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+J">Junhong Duan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junzhou He</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingyang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Geographic privacy, a crucial aspect of personal security, often goes
unnoticed in daily activities. This paper addresses the underestimation of this
privacy in the context of increasing online data sharing and the advancements
in information gathering technologies. With the surge in the use of Large
Multimodal Models, such as GPT-4, for Open Source Intelligence (OSINT), the
potential risks associated with geographic privacy breaches have intensified.
This study highlights the criticality of these developments, focusing on their
implications for individual privacy. The primary objective is to demonstrate
the capabilities of advanced AI tools, specifically a GPT-4 based model named
"Dr. Watson," in identifying and potentially compromising geographic privacy
through online shared content. We developed "Dr. Watson" to analyze and extract
geographic information from publicly available data sources. The study involved
five experimental cases, each offering different perspectives on the tool's
application in extracting precise location data from partial images and social
media content. The experiments revealed that "Dr. Watson" could successfully
identify specific geographic details, thereby exposing the vulnerabilities in
current geo-privacy measures. These findings underscore the ease with which
geographic information can be unintentionally disclosed. The paper concludes
with a discussion on the broader implications of these findings for individuals
and the community at large. It emphasizes the urgency for enhanced awareness
and protective measures against geo-privacy leakage in the era of advanced AI
and widespread social media usage.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13021" title="Abstract">arXiv:2311.13021</a> [<a href="/pdf/2311.13021" title="Download PDF">pdf</a>, <a href="/format/2311.13021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Study of Human-Robot Handover through Human-Human Object Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morissette%2C+C">Charlotte Morissette</a>, 
<a href="/search/cs?searchtype=author&query=Baghi%2C+B+H">Bobak H. Baghi</a>, 
<a href="/search/cs?searchtype=author&query=Hogan%2C+F+R">Francois R. Hogan</a>, 
<a href="/search/cs?searchtype=author&query=Dudek%2C+G">Gregory Dudek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, appeared in NeurIPS 2022 Workshop on Human in the Loop Learning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">In this preliminary study, we investigate changes in handover behaviour when
transferring hazardous objects with the help of a high-resolution touch sensor.
Participants were asked to hand over a safe and hazardous object (a full cup
and an empty cup) while instrumented with a modified STS sensor. Our data shows
a clear distinction in the length of handover for the full cup vs the empty
one, with the former being slower. Sensor data further suggests a change in
tactile behaviour dependent on the object's risk factor. The results of this
paper motivate a deeper study of tactile factors which could characterize a
risky handover, allowing for safer human-robot interactions in the future.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13022" title="Abstract">arXiv:2311.13022</a> [<a href="/pdf/2311.13022" title="Download PDF">pdf</a>, <a href="/format/2311.13022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Multimodal Surface Registration with Geometric Deep  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suliman%2C+M+A">Mohamed A. Suliman</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+L+Z+J">Logan Z. J. Williams</a>, 
<a href="/search/cs?searchtype=author&query=Fawaz%2C+A">Abdulah Fawaz</a>, 
<a href="/search/cs?searchtype=author&query=Robinson%2C+E+C">Emma C. Robinson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This paper introduces GeoMorph, a novel geometric deep-learning framework
designed for image registration of cortical surfaces. The registration process
consists of two main steps. First, independent feature extraction is performed
on each input surface using graph convolutions, generating low-dimensional
feature representations that capture important cortical surface
characteristics. Subsequently, features are registered in a deep-discrete
manner to optimize the overlap of common structures across surfaces by learning
displacements of a set of control points. To ensure smooth and biologically
plausible deformations, we implement regularization through a deep conditional
random field implemented with a recurrent neural network. Experimental results
demonstrate that GeoMorph surpasses existing deep-learning methods by achieving
improved alignment with smoother deformations. Furthermore, GeoMorph exhibits
competitive performance compared to classical frameworks. Such versatility and
robustness suggest strong potential for various neuroscience applications.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13028" title="Abstract">arXiv:2311.13028</a> [<a href="/pdf/2311.13028" title="Download PDF">pdf</a>, <a href="/format/2311.13028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DMLR: Data-centric Machine Learning Research -- Past, Present and Future
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oala%2C+L">Luis Oala</a>, 
<a href="/search/cs?searchtype=author&query=Maskey%2C+M">Manil Maskey</a>, 
<a href="/search/cs?searchtype=author&query=Bat-Leah%2C+L">Lilith Bat-Leah</a>, 
<a href="/search/cs?searchtype=author&query=Parrish%2C+A">Alicia Parrish</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCrel%2C+N+M">Nezihe Merve G&#xfc;rel</a>, 
<a href="/search/cs?searchtype=author&query=Kuo%2C+T">Tzu-Sheng Kuo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dror%2C+R">Rotem Dror</a>, 
<a href="/search/cs?searchtype=author&query=Brajovic%2C+D">Danilo Brajovic</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+X">Xiaozhe Yao</a>, 
<a href="/search/cs?searchtype=author&query=Bartolo%2C+M">Max Bartolo</a>, 
<a href="/search/cs?searchtype=author&query=Rojas%2C+W+A+G">William A Gaviria Rojas</a>, 
<a href="/search/cs?searchtype=author&query=Hileman%2C+R">Ryan Hileman</a>, 
<a href="/search/cs?searchtype=author&query=Aliment%2C+R">Rainier Aliment</a>, 
<a href="/search/cs?searchtype=author&query=Mahoney%2C+M+W">Michael W. Mahoney</a>, 
<a href="/search/cs?searchtype=author&query=Risdal%2C+M">Meg Risdal</a>, 
<a href="/search/cs?searchtype=author&query=Lease%2C+M">Matthew Lease</a>, 
<a href="/search/cs?searchtype=author&query=Samek%2C+W">Wojciech Samek</a>, 
<a href="/search/cs?searchtype=author&query=Dutta%2C+D">Debojyoti Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Northcutt%2C+C+G">Curtis G Northcutt</a>, 
<a href="/search/cs?searchtype=author&query=Coleman%2C+C">Cody Coleman</a>, 
<a href="/search/cs?searchtype=author&query=Hancock%2C+B">Braden Hancock</a>, 
<a href="/search/cs?searchtype=author&query=Koch%2C+B">Bernard Koch</a>, 
<a href="/search/cs?searchtype=author&query=Tadesse%2C+G+A">Girmaw Abebe Tadesse</a>, 
<a href="/search/cs?searchtype=author&query=Karla%C5%A1%2C+B">Bojan Karla&#x161;</a>, 
<a href="/search/cs?searchtype=author&query=Alaa%2C+A">Ahmed Alaa</a>, 
<a href="/search/cs?searchtype=author&query=Dieng%2C+A+B">Adji Bousso Dieng</a>, 
<a href="/search/cs?searchtype=author&query=Noy%2C+N">Natasha Noy</a>, 
<a href="/search/cs?searchtype=author&query=Reddi%2C+V+J">Vijay Janapa Reddi</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">James Zou</a>, 
<a href="/search/cs?searchtype=author&query=Paritosh%2C+P">Praveen Paritosh</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Schaar%2C+M">Mihaela van der Schaar</a>, 
<a href="/search/cs?searchtype=author&query=Bollacker%2C+K">Kurt Bollacker</a>, 
<a href="/search/cs?searchtype=author&query=Aroyo%2C+L">Lora Aroyo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Ce Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Vanschoren%2C+J">Joaquin Vanschoren</a>, 
<a href="/search/cs?searchtype=author&query=Guyon%2C+I">Isabelle Guyon</a>, 
<a href="/search/cs?searchtype=author&query=Mattson%2C+P">Peter Mattson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This editorial report accompanies the inaugural Data-centric Machine Learning Research (DMLR) Workshop that took place at ICML 2023 <a href="https://dmlr.ai/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Signal Processing (eess.SP)

</div>
<p class="mathjax">Drawing from discussions at the inaugural DMLR workshop at ICML 2023 and
meetings prior, in this report we outline the relevance of community engagement
and infrastructure development for the creation of next-generation public
datasets that will advance machine learning science. We chart a path forward as
a collective effort to sustain the creation and maintenance of these datasets
and methods towards positive scientific, societal and business impact.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13029" title="Abstract">arXiv:2311.13029</a> [<a href="/pdf/2311.13029" title="Download PDF">pdf</a>, <a href="/format/2311.13029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Systematic word meta-sense extension
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lei Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The meaning of polysemous words often varies in a highly productive yet
predictable way. Generalizing the regularity between conventional senses to
derive novel word meaning is crucial for automated processing of non-literal
language uses such as figurative expressions. We introduce a novel task called
systematic word meta-sense extension (SWORME) to test and improve language
models' ability to extend word meaning to denote new semantic domains (also
called meta-senses) that bear regular semantic relations with existing senses.
We found that language models prefer incremental lexical semantic change toward
conceptually similar meta-senses such as logical metonymy, and are much worse
at predicting highly non-literal meaning extensions such as metaphors. We
propose a novel analogy-based method of word meaning extension, and show that
it effectively improves language model systematicity in making both gradual and
radical types of meta-sense extension. We further demonstrate that learning
systematic meta-sense extensions benefits language models on multiple
benchmarks of figurative language understanding.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13035" title="Abstract">arXiv:2311.13035</a> [<a href="/pdf/2311.13035" title="Download PDF">pdf</a>, <a href="/format/2311.13035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-Time Distributed Infrastructure-free Searching and Target Tracking  via Virtual Pheromones
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mathew%2C+J+P">Joseph Prince Mathew</a>, 
<a href="/search/cs?searchtype=author&query=Nowzari%2C+C">Cameron Nowzari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 22 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Actively searching for targets using a multi-agent system in an unknown
environment poses a two-pronged problem, where on the one hand we need agents
to cover as much of the environment as possible with little overlap and on the
other hand the agents must coordinate among themselves to select and track
targets thereby maximizing detection performance. This paper proposes a fully
distributed solution for an ad hoc network of agents to cooperatively search
for targets and monitor them in an unknown infrastructure-free environment. The
solution combines a distributed pheromone-based coverage control strategy with
a distributed target selection mechanism. We further expand the scope to show
the implementation of the proposed algorithm on a Lighter Than Air (LTA)
multi-robotic system that can search and track objects in priori unknown
locations.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13036" title="Abstract">arXiv:2311.13036</a> [<a href="/pdf/2311.13036" title="Download PDF">pdf</a>, <a href="/format/2311.13036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Favour: FAst Variance Operator for Uncertainty Rating
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahle%2C+T+D">Thomas D. Ahle</a>, 
<a href="/search/cs?searchtype=author&query=Karimi%2C+S">Sahar Karimi</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+P+T+P">Peter Tak Peter Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Bayesian Neural Networks (BNN) have emerged as a crucial approach for
interpreting ML predictions. By sampling from the posterior distribution, data
scientists may estimate the uncertainty of an inference. Unfortunately many
inference samples are often needed, the overhead of which greatly hinder BNN's
wide adoption. To mitigate this, previous work proposed propagating the first
and second moments of the posterior directly through the network. However, on
its own this method is even slower than sampling, so the propagated variance
needs to be approximated such as assuming independence between neural nodes.
The resulting trade-off between quality and inference time did not match even
plain Monte Carlo sampling.
<br />Our contribution is a more principled variance propagation framework based on
"spiked covariance matrices", which smoothly interpolates between quality and
inference time. This is made possible by a new fast algorithm for updating a
diagonal-plus-low-rank matrix approximation under various operations. We tested
our algorithm against sampling based MC Dropout and Variational Inference on a
number of downstream uncertainty themed tasks, such as calibration and
out-of-distribution testing. We find that Favour is as fast as performing 2-3
inference samples, while matching the performance of 10-100 samples.
<br />In summary, this work enables the use of BNN in the realm of performance
critical tasks where they have previously been out of reach.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13038" title="Abstract">arXiv:2311.13038</a> [<a href="/pdf/2311.13038" title="Download PDF">pdf</a>, <a href="/format/2311.13038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synaptic Sampling of Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aimone%2C+J+B">James B. Aimone</a>, 
<a href="/search/cs?searchtype=author&query=Severa%2C+W">William Severa</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+J+D">J. Darby Smith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, accepted to 2023 IEEE International Conference on Rebooting Computing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Probabilistic artificial neural networks offer intriguing prospects for
enabling the uncertainty of artificial intelligence methods to be described
explicitly in their function; however, the development of techniques that
quantify uncertainty by well-understood methods such as Monte Carlo sampling
has been limited by the high costs of stochastic sampling on deterministic
computing hardware. Emerging computing systems that are amenable to
hardware-level probabilistic computing, such as those that leverage stochastic
devices, may make probabilistic neural networks more feasible in the
not-too-distant future. This paper describes the scANN technique --
\textit{sampling (by coinflips) artificial neural networks} -- which enables
neural networks to be sampled directly by treating the weights as Bernoulli
coin flips. This method is natively well suited for probabilistic computing
techniques that focus on tunable stochastic devices, nearly matches fully
deterministic performance while also describing the uncertainty of correct and
incorrect neural network outputs.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13045" title="Abstract">arXiv:2311.13045</a> [<a href="/pdf/2311.13045" title="Download PDF">pdf</a>, <a href="/format/2311.13045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Camera-Independent Single Image Depth Estimation from Defocus Blur
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wijayasingha%2C+L">Lahiru Wijayasingha</a>, 
<a href="/search/cs?searchtype=author&query=Alemzadeh%2C+H">Homa Alemzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Stankovic%2C+J+A">John A. Stankovic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Monocular depth estimation is an important step in many downstream tasks in
machine vision. We address the topic of estimating monocular depth from defocus
blur which can yield more accurate results than the semantic based depth
estimation methods. The existing monocular depth from defocus techniques are
sensitive to the particular camera that the images are taken from. We show how
several camera-related parameters affect the defocus blur using optical physics
equations and how they make the defocus blur depend on these parameters. The
simple correction procedure we propose can alleviate this problem which does
not require any retraining of the original model. We created a synthetic
dataset which can be used to test the camera independent performance of depth
from defocus blur models. We evaluate our model on both synthetic and real
datasets (DDFF12 and NYU depth V2) obtained with different cameras and show
that our methods are significantly more robust to the changes of cameras. Code:
https://github.com/sleekEagle/defocus_camind.git
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13049" title="Abstract">arXiv:2311.13049</a> [<a href="/pdf/2311.13049" title="Download PDF">pdf</a>, <a href="/ps/2311.13049" title="Download PostScript">ps</a>, <a href="/format/2311.13049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fourier pseudospectral methods for the spatial variable-order fractional  wave equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhou%2C+S">Shiping Zhou</a>, 
<a href="/search/math?searchtype=author&query=Zhao%2C+X">Xiaofei Zhao</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+Y">Yanzhi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we propose Fourier pseudospectral methods to solve
variable-order fractional viscoacoustic wave equations. Our approach involves a
Fourier pseudospectral method for spatial discretization and an accelerated
matrix-free technique for efficient computation and storage costs, with a
computational cost of $\mathcal{O}(MN\log N)$ and storage cost
$\mathcal{O}(MN)$ where $M\ll N$. For temporal discretization, we employ the
Crank-Nicolson, leap-frog, and time-splitting schemes. Numerical experiments
are conducted to assess their performance. The results demonstrate the
advantages of our fast method, particularly in computational and storage costs,
and its feasibility in high dimensions. The numerical findings reveal that all
three temporal discretization methods exhibit second-order accuracy, while the
Fourier pseudospectral spatial discretization showcases spectral accuracy.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13050" title="Abstract">arXiv:2311.13050</a> [<a href="/pdf/2311.13050" title="Download PDF">pdf</a>, <a href="/format/2311.13050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-fidelity Bayesian Optimization in Engineering Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Do%2C+B">Bach Do</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruda Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">Resided at the intersection of multi-fidelity optimization (MFO) and Bayesian
optimization (BO), MF BO has found a niche in solving expensive engineering
design optimization problems, thanks to its advantages in incorporating
physical and mathematical understandings of the problems, saving resources,
addressing exploitation-exploration trade-off, considering uncertainty, and
processing parallel computing. The increasing number of works dedicated to MF
BO suggests the need for a comprehensive review of this advanced optimization
technique. In this paper, we survey recent developments of two essential
ingredients of MF BO: Gaussian process (GP) based MF surrogates and acquisition
functions. We first categorize the existing MF modeling methods and MFO
strategies to locate MF BO in a large family of surrogate-based optimization
and MFO algorithms. We then exploit the common properties shared between the
methods from each ingredient of MF BO to describe important GP-based MF
surrogate models and review various acquisition functions. By doing so, we
expect to provide a structured understanding of MF BO. Finally, we attempt to
reveal important aspects that require further research for applications of MF
BO in solving intricate yet important design optimization problems, including
constrained optimization, high-dimensional optimization, optimization under
uncertainty, and multi-objective optimization.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13051" title="Abstract">arXiv:2311.13051</a> [<a href="/pdf/2311.13051" title="Download PDF">pdf</a>, <a href="/format/2311.13051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Lab: Large Language Models for Knowledge Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dunnell%2C+K">Kevin Dunnell</a>, 
<a href="/search/cs?searchtype=author&query=Painter%2C+T">Trudy Painter</a>, 
<a href="/search/cs?searchtype=author&query=Stoddard%2C+A">Andrew Stoddard</a>, 
<a href="/search/cs?searchtype=author&query=Lippman%2C+A">Andy Lippman</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Conference on Computational Creativity, 2023,
  417-421
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">This paper investigates the potential of AI models, particularly large
language models (LLMs), to support knowledge exploration and augment human
creativity during ideation. We present "Latent Lab" an interactive tool for
discovering connections among MIT Media Lab research projects, emphasizing
"exploration" over search. The work offers insights into collaborative AI
systems by addressing the challenges of organizing, searching, and synthesizing
content. In a user study, the tool's success was evaluated based on its ability
to introduce users to an unfamiliar knowledge base, ultimately setting the
groundwork for the ongoing advancement of human-AI knowledge exploration
systems.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13053" title="Abstract">arXiv:2311.13053</a> [<a href="/pdf/2311.13053" title="Download PDF">pdf</a>, <a href="/format/2311.13053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Text: Unveiling Multimodal Proficiency of Large Language Models  with MultiAPI Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jianfeng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiawei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in Progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The proliferation of Large Language Models like ChatGPT has significantly
advanced language understanding and generation, impacting a broad spectrum of
applications. However, these models predominantly excel in text-based tasks,
overlooking the complexity of real-world multimodal information. This study
introduces MultiAPI, a pioneering comprehensive large-scale API benchmark
dataset aimed at expanding LLMs' proficiency in multimodal contexts. Developed
collaboratively through ChatGPT, MultiAPI consists of 235 diverse API calls and
2,038 contextual prompts, offering a unique platform evaluation of
tool-augmented LLMs handling multimodal tasks. Through comprehensive
experiments, our findings reveal that while LLMs demonstrate proficiency in API
call decision-making, they face challenges in domain identification, function
selection, and argument generation. What's more, we surprisingly notice that
auxiliary context can actually impair the performance. An in-depth error
analysis paves the way for a new paradigm to address these challenges,
suggesting a potential direction for future LLM research.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13056" title="Abstract">arXiv:2311.13056</a> [<a href="/pdf/2311.13056" title="Download PDF">pdf</a>, <a href="/format/2311.13056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Composite Adaptive Lyapunov-Based Deep Neural Network (Lb-DNN)  Controller
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Patil%2C+O+S">Omkar Sudhir Patil</a>, 
<a href="/search/eess?searchtype=author&query=Griffis%2C+E+J">Emily J. Griffis</a>, 
<a href="/search/eess?searchtype=author&query=Makumi%2C+W+A">Wanjiku A. Makumi</a>, 
<a href="/search/eess?searchtype=author&query=Dixon%2C+W+E">Warren E. Dixon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Recent advancements in adaptive control have equipped deep neural network
(DNN)-based controllers with Lyapunov-based adaptation laws that work across a
range of DNN architectures to uniquely enable online learning. However, the
adaptation laws are based on tracking error, and offer convergence guarantees
on only the tracking error without providing conclusions on the parameter
estimation performance. Motivated to provide guarantees on the DNN parameter
estimation performance, this paper provides the first result on composite
adaptation for adaptive Lyapunov-based DNN controllers, which uses the Jacobian
of the DNN and a prediction error of the dynamics that is computed using a
novel method involving an observer of the dynamics. A Lyapunov-based stability
analysis is performed which guarantees the tracking, observer, and parameter
estimation errors are uniformly ultimately bounded (UUB), with stronger
performance guarantees when the DNN's Jacobian satisfies the persistence of
excitation (PE) condition. Comparative simulation results demonstrate a
significant performance improvement with the developed composite adaptive
Lb-DNN controller in comparison to the tracking error-based Lb-DNN.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13057" title="Abstract">arXiv:2311.13057</a> [<a href="/pdf/2311.13057" title="Download PDF">pdf</a>, <a href="/format/2311.13057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The HaLLMark Effect: Supporting Provenance and Transparent Use of Large  Language Models in Writing through Interactive Visualization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoque%2C+M+N">Md Naimul Hoque</a>, 
<a href="/search/cs?searchtype=author&query=Mashiat%2C+T">Tasfia Mashiat</a>, 
<a href="/search/cs?searchtype=author&query=Ghai%2C+B">Bhavya Ghai</a>, 
<a href="/search/cs?searchtype=author&query=Shelton%2C+C">Cecilia Shelton</a>, 
<a href="/search/cs?searchtype=author&query=Chevalier%2C+F">Fanny Chevalier</a>, 
<a href="/search/cs?searchtype=author&query=Kraus%2C+K">Kari Kraus</a>, 
<a href="/search/cs?searchtype=author&query=Elmqvist%2C+N">Niklas Elmqvist</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">The use of Large Language Models (LLMs) for writing has sparked controversy
both among readers and writers. On one hand, writers are concerned that LLMs
will deprive them of agency and ownership, and readers are concerned about
spending their time on text generated by soulless machines. On the other hand,
writers who genuinely want to use LLMs must conform to publisher policies for
AI-assisted writing, and readers need assurance that a text has been verified
by a human. We argue that a system that captures the provenance of interaction
with an LLM can help writers retain their agency, conform to policies, and
communicate their use of AI to publishers and readers transparently. Thus we
propose HaLLMark, a tool for facilitating and visualizing writers' interaction
with LLMs. We evaluated HaLLMark with 13 creative writers, and found that it
helped them retain a sense of control and ownership of the written text.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13058" title="Abstract">arXiv:2311.13058</a> [<a href="/pdf/2311.13058" title="Download PDF">pdf</a>, <a href="/format/2311.13058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Music Source Separation Using Vector-Quantized Source  Category Estimates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pasini%2C+M">Marco Pasini</a>, 
<a href="/search/cs?searchtype=author&query=Lattner%2C+S">Stefan Lattner</a>, 
<a href="/search/cs?searchtype=author&query=Fazekas%2C+G">George Fazekas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 2 figures, 1 table; Accepted at the 37th Conference on Neural Information Processing Systems (2023), Machine Learning for Audio Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Music source separation is focused on extracting distinct sonic elements from
composite tracks. Historically, many methods have been grounded in supervised
learning, necessitating labeled data, which is occasionally constrained in its
diversity. More recent methods have delved into N-shot techniques that utilize
one or more audio samples to aid in the separation. However, a challenge with
some of these methods is the necessity for an audio query during inference,
making them less suited for genres with varied timbres and effects. This paper
offers a proof-of-concept for a self-supervised music source separation system
that eliminates the need for audio queries at inference time. In the training
phase, while it adopts a query-based approach, we introduce a modification by
substituting the continuous embedding of query audios with Vector Quantized
(VQ) representations. Trained end-to-end with up to N classes as determined by
the VQ's codebook size, the model seeks to effectively categorise instrument
classes. During inference, the input is partitioned into N sources, with some
potentially left unutilized based on the mix's instrument makeup. This
methodology suggests an alternative avenue for considering source separation
across diverse music genres. We provide examples and additional results online.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13061" title="Abstract">arXiv:2311.13061</a> [<a href="/pdf/2311.13061" title="Download PDF">pdf</a>, <a href="/format/2311.13061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attribution and Alignment: Effects of Local Context Repetition on  Utterance Production and Comprehension in Dialogue
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Molnar%2C+A">Aron Molnar</a>, 
<a href="/search/cs?searchtype=author&query=Jumelet%2C+J">Jaap Jumelet</a>, 
<a href="/search/cs?searchtype=author&query=Giulianelli%2C+M">Mario Giulianelli</a>, 
<a href="/search/cs?searchtype=author&query=Sinclair%2C+A">Arabella Sinclair</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CoNLL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Language models are often used as the backbone of modern dialogue systems.
These models are pre-trained on large amounts of written fluent language.
Repetition is typically penalised when evaluating language model generations.
However, it is a key component of dialogue. Humans use local and partner
specific repetitions; these are preferred by human users and lead to more
successful communication in dialogue. In this study, we evaluate (a) whether
language models produce human-like levels of repetition in dialogue, and (b)
what are the processing mechanisms related to lexical re-use they use during
comprehension. We believe that such joint analysis of model production and
comprehension behaviour can inform the development of cognitively inspired
dialogue generation systems.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13063" title="Abstract">arXiv:2311.13063</a> [<a href="/pdf/2311.13063" title="Download PDF">pdf</a>, <a href="/format/2311.13063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Classification to Clinical Insights: Towards Analyzing and  Reasoning About Mobile and Behavioral Health Data With Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Englhardt%2C+Z">Zachary Englhardt</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chengqian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Morris%2C+M+E">Margaret E. Morris</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X+%22">Xuhai &quot;Orson&quot; Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+C">Chun-Cheng Chang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+L">Lianhui Qin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+S">Shwetak Patel</a>, 
<a href="/search/cs?searchtype=author&query=Iyer%2C+V">Vikram Iyer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Passively collected behavioral health data from ubiquitous sensors holds
significant promise to provide mental health professionals insights from
patient's daily lives; however, developing analysis tools to use this data in
clinical practice requires addressing challenges of generalization across
devices and weak or ambiguous correlations between the measured signals and an
individual's mental health. To address these challenges, we take a novel
approach that leverages large language models (LLMs) to synthesize clinically
useful insights from multi-sensor data. We develop chain of thought prompting
methods that use LLMs to generate reasoning about how trends in data such as
step count and sleep relate to conditions like depression and anxiety. We first
demonstrate binary depression classification with LLMs achieving accuracies of
61.1% which exceed the state of the art. While it is not robust for clinical
use, this leads us to our key finding: even more impactful and valued than
classification is a new human-AI collaboration approach in which clinician
experts interactively query these tools and combine their domain expertise and
context about the patient with AI generated reasoning to support clinical
decision-making. We find models like GPT-4 correctly reference numerical data
75% of the time, and clinician participants express strong interest in using
this approach to interpret self-tracking data.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13069" title="Abstract">arXiv:2311.13069</a> [<a href="/pdf/2311.13069" title="Download PDF">pdf</a>, <a href="/format/2311.13069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FuseNet: Self-Supervised Dual-Path Network for Medical Image  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kazerouni%2C+A">Amirhossein Kazerouni</a>, 
<a href="/search/cs?searchtype=author&query=Karimijafarbigloo%2C+S">Sanaz Karimijafarbigloo</a>, 
<a href="/search/cs?searchtype=author&query=Azad%2C+R">Reza Azad</a>, 
<a href="/search/cs?searchtype=author&query=Velichko%2C+Y">Yury Velichko</a>, 
<a href="/search/cs?searchtype=author&query=Bagci%2C+U">Ulas Bagci</a>, 
<a href="/search/cs?searchtype=author&query=Merhof%2C+D">Dorit Merhof</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Semantic segmentation, a crucial task in computer vision, often relies on
labor-intensive and costly annotated datasets for training. In response to this
challenge, we introduce FuseNet, a dual-stream framework for self-supervised
semantic segmentation that eliminates the need for manual annotation. FuseNet
leverages the shared semantic dependencies between the original and augmented
images to create a clustering space, effectively assigning pixels to
semantically related clusters, and ultimately generating the segmentation map.
Additionally, FuseNet incorporates a cross-modal fusion technique that extends
the principles of CLIP by replacing textual data with augmented images. This
approach enables the model to learn complex visual representations, enhancing
robustness against variations similar to CLIP's text invariance. To further
improve edge alignment and spatial consistency between neighboring pixels, we
introduce an edge refinement loss. This loss function considers edge
information to enhance spatial coherence, facilitating the grouping of nearby
pixels with similar visual features. Extensive experiments on skin lesion and
lung segmentation datasets demonstrate the effectiveness of our method.
\href{https://github.com/xmindflow/FuseNet}{Codebase.}
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13073" title="Abstract">arXiv:2311.13073</a> [<a href="/pdf/2311.13073" title="Download PDF">pdf</a>, <a href="/format/2311.13073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FusionFrames: Efficient Architectural Aspects for Text-to-Video  Generation Pipeline
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arkhipkin%2C+V">Vladimir Arkhipkin</a>, 
<a href="/search/cs?searchtype=author&query=Shaheen%2C+Z">Zein Shaheen</a>, 
<a href="/search/cs?searchtype=author&query=Vasilev%2C+V">Viacheslav Vasilev</a>, 
<a href="/search/cs?searchtype=author&query=Dakhova%2C+E">Elizaveta Dakhova</a>, 
<a href="/search/cs?searchtype=author&query=Kuznetsov%2C+A">Andrey Kuznetsov</a>, 
<a href="/search/cs?searchtype=author&query=Dimitrov%2C+D">Denis Dimitrov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://ai-forever.github.io/kandinsky-video/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">Multimedia generation approaches occupy a prominent place in artificial
intelligence research. Text-to-image models achieved high-quality results over
the last few years. However, video synthesis methods recently started to
develop. This paper presents a new two-stage latent diffusion text-to-video
generation architecture based on the text-to-image diffusion model. The first
stage concerns keyframes synthesis to figure the storyline of a video, while
the second one is devoted to interpolation frames generation to make movements
of the scene and objects smooth. We compare several temporal conditioning
approaches for keyframes generation. The results show the advantage of using
separate temporal blocks over temporal layers in terms of metrics reflecting
video generation quality aspects and human preference. The design of our
interpolation model significantly reduces computational costs compared to other
masked frame interpolation approaches. Furthermore, we evaluate different
configurations of MoVQ-based video decoding scheme to improve consistency and
achieve higher PSNR, SSIM, MSE, and LPIPS scores. Finally, we compare our
pipeline with existing solutions and achieve top-2 scores overall and top-1
among open-source solutions: CLIPSIM = 0.2976 and FVD = 433.054. Project page:
https://ai-forever.github.io/kandinsky-video/
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13078" title="Abstract">arXiv:2311.13078</a> [<a href="/pdf/2311.13078" title="Download PDF">pdf</a>, <a href="/format/2311.13078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Terminal Phase Navigation for AUV Docking: An Innovative Electromagnetic  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gutnik%2C+Y">Yevgeni Gutnik</a>, 
<a href="/search/eess?searchtype=author&query=Groper%2C+M">Morel Groper</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This study introduces a groundbreaking approach for real-time 3D
localization, specifically focusing on achieving seamless and precise
localization during an AUV's terminal guidance phase as it approaches an
omnidirectional docking component in an automated Launch and Recovery System
(LARS). Through the use of the AUV's magnetometer, an economical
electromagnetic beacon embedded in the docking station, and an advanced signal
processing algorithm, this novel approach ensures the accurate localization of
the docking component in three dimensions without the need for direct
line-of-sight contact. The method's real-time capabilities were rigorously
evaluated via simulations, prototype experiments in a controlled lab setting,
and extensive full-scale pool experiments. These assessments consistently
demonstrated an exceptional average positioning accuracy of under 3 cm.,
marking a significant advancement in AUV guidance systems.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13079" title="Abstract">arXiv:2311.13079</a> [<a href="/pdf/2311.13079" title="Download PDF">pdf</a>, <a href="/ps/2311.13079" title="Download PostScript">ps</a>, <a href="/format/2311.13079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FEM for 1D-problems involving the logarithmic Laplacian: error estimates  and numerical implementation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hern%C3%A1ndez-Santamar%C3%ADa%2C+V">V&#xed;ctor Hern&#xe1;ndez-Santamar&#xed;a</a>, 
<a href="/search/math?searchtype=author&query=Jarohs%2C+S">Sven Jarohs</a>, 
<a href="/search/math?searchtype=author&query=Salda%C3%B1a%2C+A">Alberto Salda&#xf1;a</a>, 
<a href="/search/math?searchtype=author&query=Sinsch%2C+L">Leonard Sinsch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">We present the numerical analysis of a finite element method (FEM) for
one-dimensional Dirichlet problems involving the logarithmic Laplacian (the
pseudo-differential operator that appears as a first-order expansion of the
fractional Laplacian as the exponent $s\to 0^+$). Our analysis exhibits new
phenomena in this setting; in particular, using recently obtained regularity
results, we prove rigorous error estimates and provide a logarithmic order of
convergence in the energy norm using suitable \emph{log}-weighted spaces.
Numerical evidence suggests that this type of rate cannot be improved.
Moreover, we show that the stiffness matrix of logarithmic problems can be
obtained as the derivative of the fractional stiffness matrix evaluated at
$s=0$. Lastly, we investigate the relationship between the discrete eigenvalue
problem and its convergence to the continuous one.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13080" title="Abstract">arXiv:2311.13080</a> [<a href="/pdf/2311.13080" title="Download PDF">pdf</a>, <a href="/format/2311.13080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Speed Voltage Control in Active Distribution Systems with Smart  Inverter Coordination and Deep Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Golgol%2C+M">Mohammad Golgol</a>, 
<a href="/search/eess?searchtype=author&query=Pal%2C+A">Anamitra Pal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The increasing penetration of renewable energy resources in distribution
systems necessitates high-speed monitoring and control of voltage for ensuring
reliable system operation. However, existing voltage control algorithms often
make simplifying assumptions in their formulation, such as real-time
availability of smart meter measurements (for monitoring), or real-time
knowledge of every power injection information(for control).This paper
leverages the recent advances made in highspeed state estimation for real-time
unobservable distribution systems to formulate a deep reinforcement
learning-based control algorithm that utilizes the state estimates alone to
control the voltage of the entire system. The results obtained for a modified
(renewable-rich) IEEE34-nodedistributionfeeder indicate that the proposed
approach excels in monitoring and controlling voltage of active distribution
systems.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13081" title="Abstract">arXiv:2311.13081</a> [<a href="/pdf/2311.13081" title="Download PDF">pdf</a>, <a href="/format/2311.13081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Fly in Seconds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eschmann%2C+J">Jonas Eschmann</a>, 
<a href="/search/cs?searchtype=author&query=Albani%2C+D">Dario Albani</a>, 
<a href="/search/cs?searchtype=author&query=Loianno%2C+G">Giuseppe Loianno</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">Learning-based methods, particularly Reinforcement Learning (RL), hold great
promise for streamlining deployment, enhancing performance, and achieving
generalization in the control of autonomous multirotor aerial vehicles. Deep RL
has been able to control complex systems with impressive fidelity and agility
in simulation but the simulation-to-reality transfer often brings a
hard-to-bridge reality gap. Moreover, RL is commonly plagued by prohibitively
long training times. In this work, we propose a novel asymmetric
actor-critic-based architecture coupled with a highly reliable RL-based
training paradigm for end-to-end quadrotor control. We show how curriculum
learning and a highly optimized simulator enhance sample complexity and lead to
fast training times. To precisely discuss the challenges related to
low-level/end-to-end multirotor control, we also introduce a taxonomy that
classifies the existing levels of control abstractions as well as
non-linearities and domain parameters. Our framework enables
Simulation-to-Reality (Sim2Real) transfer for direct RPM control after only 18
seconds of training on a consumer-grade laptop as well as its deployment on
microcontrollers to control a multirotor under real-time guarantees. Finally,
our solution exhibits competitive performance in trajectory tracking, as
demonstrated through various experimental comparisons with existing
state-of-the-art control solutions using a real Crazyflie nano quadrotor. We
open source the code including a very fast multirotor dynamics simulator that
can simulate about 5 months of flight per second on a laptop GPU. The fast
training times and deployment to a cheap, off-the-shelf quadrotor lower the
barriers to entry and help democratize the research and development of these
systems.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13087" title="Abstract">arXiv:2311.13087</a> [<a href="/pdf/2311.13087" title="Download PDF">pdf</a>, <a href="/format/2311.13087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predict-Then-Optimize by Proxy: Learning Joint Models of Prediction and  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kotary%2C+J">James Kotary</a>, 
<a href="/search/cs?searchtype=author&query=Di+Vito%2C+V">Vincenzo Di Vito</a>, 
<a href="/search/cs?searchtype=author&query=Christopher%2C+J">Jacob Christopher</a>, 
<a href="/search/cs?searchtype=author&query=Van+Hentenryck%2C+P">Pascal Van Hentenryck</a>, 
<a href="/search/cs?searchtype=author&query=Fioretto%2C+F">Ferdinando Fioretto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Many real-world decision processes are modeled by optimization problems whose
defining parameters are unknown and must be inferred from observable data. The
Predict-Then-Optimize framework uses machine learning models to predict unknown
parameters of an optimization problem from features before solving. Recent
works show that decision quality can be improved in this setting by solving and
differentiating the optimization problem in the training loop, enabling
end-to-end training with loss functions defined directly on the resulting
decisions. However, this approach can be inefficient and requires handcrafted,
problem-specific rules for backpropagation through the optimization step. This
paper proposes an alternative method, in which optimal solutions are learned
directly from the observable features by predictive models. The approach is
generic, and based on an adaptation of the Learning-to-Optimize paradigm, from
which a rich variety of existing techniques can be employed. Experimental
evaluations show the ability of several Learning-to-Optimize methods to provide
efficient, accurate, and flexible solutions to an array of challenging
Predict-Then-Optimize problems.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13088" title="Abstract">arXiv:2311.13088</a> [<a href="/pdf/2311.13088" title="Download PDF">pdf</a>, <a href="/ps/2311.13088" title="Download PostScript">ps</a>, <a href="/format/2311.13088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Validation of Consumer-grade Digital Camera-based Human Activity  Evaluation for Upper Limb Exercises and Development of a Therapist-guided,  Automated Telerehabilitation Framework and Platform for Stroke Rehabilitation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yeung%2C+E+H+L">Elton H.L. Yeung</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yingxian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fok%2C+W+W+T">Wilton W.T. Fok</a>, 
<a href="/search/cs?searchtype=author&query=Lau%2C+G+K+K">Gary K.K. Lau</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Timely and adequate rehabilitation is critical in facilitating post-stroke
recovery. However, the organization and delivery of rehabilitation are
resource-demanding, and are only available to approximately 25% of stroke
survivors in low-to-middle-income countries. Improving access to stroke
rehabilitation services through innovative solutions is therefore urgently
required. Tele-rehabilitation, which transits care to home- and community
settings, has emerged as a promising solution. However, current approaches
using video tutorial, teleconference, or other specialized devices face
inherent shortfalls that limit their uptake. In this study, we proposed and
validated the use of an open-source, markerless motion capture model with
consumer-grade devices to overcome these challenges. Our solution enables
reliable measurement of the end range of motion during upper limb exercises
with near-perfect waveform similarity and intraclass correlation to that of the
gold standard Kinect approach. Our multidisciplinary team developed an
automated telerehabilitation framework incorporating the validated markerless
technique to facilitate a seamless telerehabilitation process. It enables
personalized rehabilitation plans with real-time feedback, and individual
progress reports using objective quantitative and qualitative features to
improve patient monitoring and management, and home-based rehabilitation
service uptake and compliance. This study serves as a proof-of-concept in
preparation for the future development of a detailed model of care, and
feasibility, usability, and cost-effectiveness studies of an automated
telerehabilitation platform and framework in improving the state of post-stroke
rehabilitation and functional outcome.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13090" title="Abstract">arXiv:2311.13090</a> [<a href="/pdf/2311.13090" title="Download PDF">pdf</a>, <a href="/format/2311.13090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Limitation of Diffusion Models for Synthesizing Training Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yamaguchi%2C+S">Shin&#x27;ya Yamaguchi</a>, 
<a href="/search/cs?searchtype=author&query=Fukuda%2C+T">Takuma Fukuda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 SyntheticData4ML Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Synthetic samples from diffusion models are promising for leveraging in
training discriminative models as replications of real training datasets.
However, we found that the synthetic datasets degrade classification
performance over real datasets even when using state-of-the-art diffusion
models. This means that modern diffusion models do not perfectly represent the
data distribution for the purpose of replicating datasets for training
discriminative tasks. This paper investigates the gap between synthetic and
real samples by analyzing the synthetic samples reconstructed from real samples
through the diffusion and reverse process. By varying the time steps starting
the reverse process in the reconstruction, we can control the trade-off between
the information in the original real data and the information added by
diffusion models. Through assessing the reconstructed samples and trained
models, we found that the synthetic data are concentrated in modes of the
training data distribution as the reverse step increases, and thus, they are
difficult to cover the outer edges of the distribution. Our findings imply that
modern diffusion models are insufficient to replicate training data
distribution perfectly, and there is room for the improvement of generative
modeling in the replication of training datasets.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13091" title="Abstract">arXiv:2311.13091</a> [<a href="/pdf/2311.13091" title="Download PDF">pdf</a>, <a href="/format/2311.13091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stable Unlearnable Example: Enhancing the Robustness of Unlearnable  Examples via Stable Error-Minimizing Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yixin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kaidi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 11 figures, 13 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The open source of large amounts of image data promotes the development of
deep learning techniques. Along with this comes the privacy risk of these
open-source image datasets being exploited by unauthorized third parties to
train deep learning models for commercial or illegal purposes. To avoid the
abuse of public data, a poisoning-based technique, the unlearnable example, is
proposed to significantly degrade the generalization performance of models by
adding a kind of imperceptible noise to the data. To further enhance its
robustness against adversarial training, existing works leverage iterative
adversarial training on both the defensive noise and the surrogate model.
However, it still remains unknown whether the robustness of unlearnable
examples primarily comes from the effect of enhancement in the surrogate model
or the defensive noise. Observing that simply removing the adversarial noise on
the training process of the defensive noise can improve the performance of
robust unlearnable examples, we identify that solely the surrogate model's
robustness contributes to the performance. Furthermore, we found a negative
correlation exists between the robustness of defensive noise and the protection
performance, indicating defensive noise's instability issue. Motivated by this,
to further boost the robust unlearnable example, we introduce stable
error-minimizing noise (SEM), which trains the defensive noise against random
perturbation instead of the time-consuming adversarial perturbation to improve
the stability of defensive noise. Through extensive experiments, we demonstrate
that SEM achieves a new state-of-the-art performance on CIFAR-10, CIFAR-100,
and ImageNet Subset in terms of both effectiveness and efficiency. The code is
available at https://github.com/liuyixin-louis/Stable-Unlearnable-Example.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13095" title="Abstract">arXiv:2311.13095</a> [<a href="/pdf/2311.13095" title="Download PDF">pdf</a>, <a href="/format/2311.13095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Logical Reasoning in Large Language Models to Facilitate Legal  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H">Ha-Thanh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Fungwacharakorn%2C+W">Wachara Fungwacharakorn</a>, 
<a href="/search/cs?searchtype=author&query=Satoh%2C+K">Ken Satoh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ALP@JURIX2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Language serves as a vehicle for conveying thought, enabling communication
among individuals. The ability to distinguish between diverse concepts,
identify fairness and injustice, and comprehend a range of legal notions
fundamentally relies on logical reasoning. Large Language Models (LLMs) attempt
to emulate human language understanding and generation, but their competency in
logical reasoning remains limited. This paper seeks to address the
philosophical question: How can we effectively teach logical reasoning to LLMs
while maintaining a deep understanding of the intricate relationship between
language and logic? By focusing on bolstering LLMs' capabilities in logical
reasoning, we aim to expand their applicability in law and other
logic-intensive disciplines. To this end, we propose a Reinforcement Learning
from Logical Feedback (RLLF) approach, which serves as a potential framework
for refining LLMs' reasoning capacities. Through RLLF and a revised evaluation
methodology, we explore new avenues for research in this domain and contribute
to the development of LLMs capable of handling complex legal reasoning tasks
while acknowledging the fundamental connection between language and logic.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13099" title="Abstract">arXiv:2311.13099</a> [<a href="/pdf/2311.13099" title="Download PDF">pdf</a>, <a href="/format/2311.13099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PIE-NeRF: Physics-based Interactive Elastodynamics with NeRF
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yutao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+Y">Yintong Shang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+T">Tianjia Shao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Chenfanfu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yin Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">We show that physics-based simulations can be seamlessly integrated with NeRF
to generate high-quality elastodynamics of real-world objects. Unlike existing
methods, we discretize nonlinear hyperelasticity in a meshless way, obviating
the necessity for intermediate auxiliary shape proxies like a tetrahedral mesh
or voxel grid. A quadratic generalized moving least square (Q-GMLS) is employed
to capture nonlinear dynamics and large deformation on the implicit model. Such
meshless integration enables versatile simulations of complex and codimensional
shapes. We adaptively place the least-square kernels according to the NeRF
density field to significantly reduce the complexity of the nonlinear
simulation. As a result, physically realistic animations can be conveniently
synthesized using our method for a wide range of hyperelastic materials at an
interactive rate. For more information, please visit our project page at
https://fytalon.github.io/pienerf/.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13102" title="Abstract">arXiv:2311.13102</a> [<a href="/pdf/2311.13102" title="Download PDF">pdf</a>, <a href="/format/2311.13102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting out-of-distribution text using topological features of  transformer-based language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pollano%2C+A">Andres Pollano</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhuri%2C+A">Anupam Chaudhuri</a>, 
<a href="/search/cs?searchtype=author&query=Simmons%2C+A">Anj Simmons</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Algebraic Topology (math.AT)

</div>
<p class="mathjax">We attempt to detect out-of-distribution (OOD) text samples though applying
Topological Data Analysis (TDA) to attention maps in transformer-based language
models. We evaluate our proposed TDA-based approach for out-of-distribution
detection on BERT, a transformer-based language model, and compare the to a
more traditional OOD approach based on BERT CLS embeddings. We found that our
TDA approach outperforms the CLS embedding approach at distinguishing
in-distribution data (politics and entertainment news articles from HuffPost)
from far out-of-domain samples (IMDB reviews), but its effectiveness
deteriorates with near out-of-domain (CNN/Dailymail) or same-domain (business
news articles from HuffPost) datasets.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13104" title="Abstract">arXiv:2311.13104</a> [<a href="/pdf/2311.13104" title="Download PDF">pdf</a>, <a href="/format/2311.13104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AC Power Flow Informed Parameter Learning for DC Power Flow Network  Equivalents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Taheri%2C+B">Babak Taheri</a>, 
<a href="/search/eess?searchtype=author&query=Molzahn%2C+D+K">Daniel K. Molzahn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper presents an algorithm to optimize the parameters of power systems
equivalents to enhance the accuracy of the DC power flow approximation in
reduced networks. Based on a zonal division of the network, the algorithm
produces a reduced power system equivalent that captures inter-zonal flows with
aggregated buses and equivalent transmission lines. The algorithm refines
coefficient and bias parameters for the DC power flow model of the reduced
network, aiming to minimize discrepancies between inter-zonal flows in DC and
AC power flow results. Using optimization methods like BFGS, L-BFGS, and TNC in
an offline training phase, these parameters boost the accuracy of online DC
power flow computations. In contrast to existing network equivalencing methods,
the proposed algorithm optimizes accuracy over a specified range of operation
as opposed to only considering a single nominal point. Numerical tests
demonstrate substantial accuracy improvements over traditional equivalencing
and approximation methods.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13105" title="Abstract">arXiv:2311.13105</a> [<a href="/pdf/2311.13105" title="Download PDF">pdf</a>, <a href="/format/2311.13105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perceptual Structure in the Absence of Grounding for LLMs: The Impact of  Abstractedness and Subjectivity in Color Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Loyola%2C+P">Pablo Loyola</a>, 
<a href="/search/cs?searchtype=author&query=Marrese-Taylor%2C+E">Edison Marrese-Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Hoyos-Idobro%2C+A">Andres Hoyos-Idobro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The need for grounding in language understanding is an active research topic.
Previous work has suggested that color perception and color language appear as
a suitable test bed to empirically study the problem, given its cognitive
significance and showing that there is considerable alignment between a defined
color space and the feature space defined by a language model. To further study
this issue, we collect a large scale source of colors and their descriptions,
containing almost a 1 million examples , and perform an empirical analysis to
compare two kinds of alignments: (i) inter-space, by learning a mapping between
embedding space and color space, and (ii) intra-space, by means of prompting
comparatives between color descriptions. Our results show that while color
space alignment holds for monolexemic, highly pragmatic color descriptions,
this alignment drops considerably in the presence of examples that exhibit
elements of real linguistic usage such as subjectivity and abstractedness,
suggesting that grounding may be required in such cases.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13106" title="Abstract">arXiv:2311.13106</a> [<a href="/pdf/2311.13106" title="Download PDF">pdf</a>, <a href="/format/2311.13106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ten issues of NetGPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tong%2C+W">Wen Tong</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Chenghui Peng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tingting Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Juan Deng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rongpeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Honggang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+M">Ming Ai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Li Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guangyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+L">Liexiang Yue</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wanfei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zexu Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wenwen Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">With the rapid development and application of foundation models (FMs), it is
foreseeable that FMs will play an important role in future wireless
communications. As current Artificial Intelligence (AI) algorithms applied in
wireless networks are dedicated models that aim for different neural network
architectures and objectives, drawbacks in aspects of generality, performance
gain, management, collaboration, etc. need to be conquered. In this paper, we
define NetGPT (Network Generative Pre-trained Transformer) -- the foundation
models for wireless communications, and summarize ten issues regarding design
and application of NetGPT.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13110" title="Abstract">arXiv:2311.13110</a> [<a href="/pdf/2311.13110" title="Download PDF">pdf</a>, <a href="/format/2311.13110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> White-Box Transformers via Sparse Rate Reduction: Compression Is All  There Is?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yaodong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Buchanan%2C+S">Sam Buchanan</a>, 
<a href="/search/cs?searchtype=author&query=Pai%2C+D">Druv Pai</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+T">Tianzhe Chu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Ziyang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+S">Shengbang Tong</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+H">Hao Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+Y">Yuexiang Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Haeffele%2C+B+D">Benjamin D. Haeffele</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yi Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper integrates the works <a href="/abs/2306.01129">arXiv:2306.01129</a> and <a href="/abs/2308.16271">arXiv:2308.16271</a>, as well as this under-review work: <a href="https://openreview.net/forum?id=PvyOYleymy">this https URL</a> into a complete story. In this paper, we improve the writing and organization, and also add conceptual, empirical, and theoretical improvements over the previous work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In this paper, we contend that a natural objective of representation learning
is to compress and transform the distribution of the data, say sets of tokens,
towards a low-dimensional Gaussian mixture supported on incoherent subspaces.
The goodness of such a representation can be evaluated by a principled measure,
called sparse rate reduction, that simultaneously maximizes the intrinsic
information gain and extrinsic sparsity of the learned representation. From
this perspective, popular deep network architectures, including transformers,
can be viewed as realizing iterative schemes to optimize this measure.
Particularly, we derive a transformer block from alternating optimization on
parts of this objective: the multi-head self-attention operator compresses the
representation by implementing an approximate gradient descent step on the
coding rate of the features, and the subsequent multi-layer perceptron
sparsifies the features. This leads to a family of white-box transformer-like
deep network architectures, named CRATE, which are mathematically fully
interpretable. We show, by way of a novel connection between denoising and
compression, that the inverse to the aforementioned compressive encoding can be
realized by the same class of CRATE architectures. Thus, the so-derived
white-box architectures are universal to both encoders and decoders.
Experiments show that these networks, despite their simplicity, indeed learn to
compress and sparsify representations of large-scale real-world image and text
datasets, and achieve performance very close to highly engineered
transformer-based models: ViT, MAE, DINO, BERT, and GPT2. We believe the
proposed computational framework demonstrates great potential in bridging the
gap between theory and practice of deep learning, from a unified perspective of
data compression. Code is available at: https://ma-lab-berkeley.github.io/CRATE .
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13111" title="Abstract">arXiv:2311.13111</a> [<a href="/pdf/2311.13111" title="Download PDF">pdf</a>, <a href="/ps/2311.13111" title="Download PostScript">ps</a>, <a href="/format/2311.13111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An arbitrary order locking-free weak Galerkin method for linear  elasticity problems based on a reconstruction operator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Huo%2C+F">Fuchang Huo</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+R">Ruishu Wang</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+Y">Yanqiu Wang</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+R">Ran Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The weak Galerkin (WG) finite element method has shown great potential in
solving various type of partial differential equations. In this paper, we
propose an arbitrary order locking-free WG method for solving linear elasticity
problems, with the aid of an appropriate $H(div)$-conforming displacement
reconstruction operator. Optimal order locking-free error estimates in both the
$H^1$-norm and the $L^2$-norm are proved, i.e., the error is independent of the
$Lam\acute{e}$ constant $\lambda$. Moreover, the term $\lambda\|\nabla\cdot
\mathbf{u}\|_k$ does not need to be bounded in order to achieve these
estimates. We validate the accuracy and the robustness of the proposed
locking-free WG algorithm by numerical experiments.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13118" title="Abstract">arXiv:2311.13118</a> [<a href="/pdf/2311.13118" title="Download PDF">pdf</a>, <a href="/format/2311.13118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combatting Human Trafficking in the Cyberspace: A Natural Language  Processing-Based Methodology to Analyze the Language in Online Advertisements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Perez%2C+A+R">Alejandro Rodriguez Perez</a>, 
<a href="/search/cs?searchtype=author&query=Rivas%2C+P">Pablo Rivas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computers and Society (cs.CY); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">This project tackles the pressing issue of human trafficking in online C2C
marketplaces through advanced Natural Language Processing (NLP) techniques. We
introduce a novel methodology for generating pseudo-labeled datasets with
minimal supervision, serving as a rich resource for training state-of-the-art
NLP models. Focusing on tasks like Human Trafficking Risk Prediction (HTRP) and
Organized Activity Detection (OAD), we employ cutting-edge Transformer models
for analysis. A key contribution is the implementation of an interpretability
framework using Integrated Gradients, providing explainable insights crucial
for law enforcement. This work not only fills a critical gap in the literature
but also offers a scalable, machine learning-driven approach to combat human
exploitation online. It serves as a foundation for future research and
practical applications, emphasizing the role of machine learning in addressing
complex social issues.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13120" title="Abstract">arXiv:2311.13120</a> [<a href="/pdf/2311.13120" title="Download PDF">pdf</a>, <a href="/format/2311.13120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-modal In-Context Learning Makes an Ego-evolving Scene Text  Recognizer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Can Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Binghong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chunhui Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhizhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xin Tan</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jingqun Tang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yuan Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Scene text recognition (STR) in the wild frequently encounters challenges
when coping with domain variations, font diversity, shape deformations, etc. A
straightforward solution is performing model fine-tuning tailored to a specific
scenario, but it is computationally intensive and requires multiple model
copies for various scenarios. Recent studies indicate that large language
models (LLMs) can learn from a few demonstration examples in a training-free
manner, termed "In-Context Learning" (ICL). Nevertheless, applying LLMs as a
text recognizer is unacceptably resource-consuming. Moreover, our pilot
experiments on LLMs show that ICL fails in STR, mainly attributed to the
insufficient incorporation of contextual information from diverse samples in
the training stage. To this end, we introduce E$^2$STR, a STR model trained
with context-rich scene text sequences, where the sequences are generated via
our proposed in-context training strategy. E$^2$STR demonstrates that a
regular-sized model is sufficient to achieve effective ICL capabilities in STR.
Extensive experiments show that E$^2$STR exhibits remarkable training-free
adaptation in various scenarios and outperforms even the fine-tuned
state-of-the-art approaches on public benchmarks.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13121" title="Abstract">arXiv:2311.13121</a> [<a href="/pdf/2311.13121" title="Download PDF">pdf</a>, <a href="/format/2311.13121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GENET: Unleashing the Power of Side Information for Recommendation via  Hypergraph Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qi&#x27;ao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenjie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaomin Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Recommendation with side information has drawn significant research interest
due to its potential to mitigate user feedback sparsity. However, existing
models struggle with generalization across diverse domains and types of side
information. In particular, three challenges have not been addressed, and they
are (1) the diverse formats of side information, including text sequences. (2)
The diverse semantics of side information that describes items and users from
multi-level in a context different from recommendation systems. (3) The diverse
correlations in side information to measure similarity over multiple objects
beyond pairwise relations. In this paper, we introduce GENET (Generalized
hypErgraph pretraiNing on sidE informaTion), which pre-trains user and item
representations on feedback-irrelevant side information and fine-tunes the
representations on user feedback data. GENET leverages pre-training as a means
to prevent side information from overshadowing critical ID features and
feedback signals. It employs a hypergraph framework to accommodate various
types of diverse side information. During pre-training, GENET integrates tasks
for hyperlink prediction and self-supervised contrast to capture fine-grained
semantics at both local and global levels. Additionally, it introduces a unique
strategy to enhance pre-training robustness by perturbing positive samples
while maintaining high-order relations. Extensive experiments demonstrate that
GENET exhibits strong generalization capabilities, outperforming the SOTA
method by up to 38% in TOP-N recommendation and Sequential recommendation tasks
on various datasets with different side information.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13123" title="Abstract">arXiv:2311.13123</a> [<a href="/pdf/2311.13123" title="Download PDF">pdf</a>, <a href="/ps/2311.13123" title="Download PostScript">ps</a>, <a href="/format/2311.13123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Parallel Algorithms for Submodular $p$-Superseparable Maximization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cervenjak%2C+P">Philip Cervenjak</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+J">Junhao Gan</a>, 
<a href="/search/cs?searchtype=author&query=Wirth%2C+A">Anthony Wirth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages. To be published in Approximation and Online Algorithms (Proceedings of the 21st International Workshop, WAOA 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Maximizing a non-negative, monontone, submodular function $f$ over $n$
elements under a cardinality constraint $k$ (SMCC) is a well-studied NP-hard
problem. It has important applications in, e.g., machine learning and influence
maximization. Though the theoretical problem admits polynomial-time
approximation algorithms, solving it in practice often involves frequently
querying submodular functions that are expensive to compute. This has motivated
significant research into designing parallel approximation algorithms in the
adaptive complexity model; adaptive complexity (adaptivity) measures the number
of sequential rounds of $\text{poly}(n)$ function queries an algorithm
requires. The state-of-the-art algorithms can achieve
$(1-\frac{1}{e}-\varepsilon)$-approximate solutions with
$O(\frac{1}{\varepsilon^2}\log n)$ adaptivity, which approaches the known
adaptivity lower-bounds. However, the $O(\frac{1}{\varepsilon^2} \log n)$
adaptivity only applies to maximizing worst-case functions that are unlikely to
appear in practice. Thus, in this paper, we consider the special class of
$p$-superseparable submodular functions, which places a reasonable constraint
on $f$, based on the parameter $p$, and is more amenable to maximization, while
also having real-world applicability. Our main contribution is the algorithm
LS+GS, a finer-grained version of the existing LS+PGB algorithm, designed for
instances of SMCC when $f$ is $p$-superseparable; it achieves an expected
$(1-\frac{1}{e}-\varepsilon)$-approximate solution with
$O(\frac{1}{\varepsilon^2}\log(p k))$ adaptivity independent of $n$.
Additionally, unrelated to $p$-superseparability, our LS+GS algorithm uses only
$O(\frac{n}{\varepsilon} + \frac{\log n}{\varepsilon^2})$ oracle queries, which
has an improved dependence on $\varepsilon^{-1}$ over the state-of-the-art
LS+PGB; this is achieved through the design of a novel thresholding subroutine.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13124" title="Abstract">arXiv:2311.13124</a> [<a href="/pdf/2311.13124" title="Download PDF">pdf</a>, <a href="/format/2311.13124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Height of walks with resets, the Moran model, and the discrete Gumbel  distribution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aguech%2C+R">Rafik Aguech</a>, 
<a href="/search/cs?searchtype=author&query=Althagafi%2C+A">Asma Althagafi</a>, 
<a href="/search/cs?searchtype=author&query=Banderier%2C+C">Cyril Banderier</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> S\'eminaire Lotharingien de Combinatoire, vol. 87B, article #12,
  2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO); Probability (math.PR)

</div>
<p class="mathjax">In this article, we consider several models of random walks in one or several
dimensions, additionally allowing, at any unit of time, a reset (or
"catastrophe") of the walk with probability $q$. We establish the distribution
of the final altitude. We prove algebraicity of the generating functions of
walks of bounded height $h$ (showing in passing the equivalence between
Lagrange interpolation and the kernel method). To get these generating
functions, our approach offers an algorithm of cost $O(1)$, instead of cost
$O(h^3)$ if a Markov chain approach would be used. The simplest nontrivial
model corresponds to famous dynamics in population genetics: the Moran model.
<br />We prove that the height of these Moran walks asymptotically follows a
discrete Gumbel distribution. For $q=1/2$, this generalizes a model of carry
propagation over binary numbers considered e.g. by von Neumann and Knuth. For
generic $q$, using a Mellin transform approach, we show that the asymptotic
height exhibits fluctuations for which we get an explicit description (and, in
passing, new bounds for the digamma function). We end by showing how to solve
multidimensional generalizations of these walks (where any subset of particles
is attributed a different probability of dying) and we give an application to
the soliton wave model.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13125" title="Abstract">arXiv:2311.13125</a> [<a href="/pdf/2311.13125" title="Download PDF">pdf</a>, <a href="/format/2311.13125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DAE-Net: Deforming Auto-Encoder for fine-grained shape co-segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhiqin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qimin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code: <a href="https://github.com/czq142857/DAE-Net">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We present an unsupervised 3D shape co-segmentation method which learns a set
of deformable part templates from a shape collection. To accommodate structural
variations in the collection, our network composes each shape by a selected
subset of template parts which are affine-transformed. To maximize the
expressive power of the part templates, we introduce a per-part deformation
network to enable the modeling of diverse parts with substantial geometry
variations, while imposing constraints on the deformation capacity to ensure
fidelity to the originally represented parts. We also propose a training scheme
to effectively overcome local minima. Architecturally, our network is a
branched autoencoder, with a CNN encoder taking a voxel shape as input and
producing per-part transformation matrices, latent codes, and part existence
scores, and the decoder outputting point occupancies to define the
reconstruction loss. Our network, coined DAE-Net for Deforming Auto-Encoder,
can achieve unsupervised 3D shape co-segmentation that yields fine-grained,
compact, and meaningful parts that are consistent across diverse shapes. We
conduct extensive experiments on the ShapeNet Part dataset, DFAUST, and an
animal subset of Objaverse to show superior performance over prior methods.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13126" title="Abstract">arXiv:2311.13126</a> [<a href="/pdf/2311.13126" title="Download PDF">pdf</a>, <a href="/format/2311.13126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Better Parameter-Efficient Fine-Tuning for Large Language  Models: A Position Paper
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junbing Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jun Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper delves into the pressing need in Parameter-Efficient Fine-Tuning
(PEFT) for Large Language Models (LLMs). While LLMs possess remarkable
capabilities, their extensive parameter requirements and associated
computational demands hinder their practicality and scalability for real-world
applications. Our position paper highlights current states and the necessity of
further studying into the topic, and recognizes significant challenges and open
issues that must be addressed to fully harness the powerful abilities of LLMs.
These challenges encompass novel efficient PEFT architectures, PEFT for
different learning settings, PEFT combined with model compression techniques,
and the exploration of PEFT for multi-modal LLMs. By presenting this position
paper, we aim to stimulate further research and foster discussions surrounding
more efficient and accessible PEFT for LLMs.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13127" title="Abstract">arXiv:2311.13127</a> [<a href="/pdf/2311.13127" title="Download PDF">pdf</a>, <a href="/format/2311.13127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Robust Imperceptible Perturbation against Unauthorized  Text-to-image Diffusion-based Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yixin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Chenrui Fan</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yutong Dai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Pan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 15 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Text-to-image diffusion models allow seamless generation of personalized
images from scant reference photos. Yet, these tools, in the wrong hands, can
fabricate misleading or harmful content, endangering individuals. To address
this problem, existing poisoning-based approaches perturb user images in an
imperceptible way to render them "unlearnable" from malicious uses. We identify
two limitations of these defending approaches: i) sub-optimal due to the
hand-crafted heuristics for solving the intractable bilevel optimization and
ii) lack of robustness against simple data transformations like Gaussian
filtering. To solve these challenges, we propose MetaCloak, which solves the
bi-level poisoning problem with a meta-learning framework with an additional
transformation sampling process to craft transferable and robust perturbation.
Specifically, we employ a pool of surrogate diffusion models to craft
transferable and model-agnostic perturbation. Furthermore, by incorporating an
additional transformation process, we design a simple denoising-error
maximization loss that is sufficient for causing transformation-robust semantic
distortion and degradation in a personalized generation. Extensive experiments
on the VGGFace2 and CelebA-HQ datasets show that MetaCloak outperforms existing
approaches. Notably, MetaCloak can successfully fool online training services
like Replicate, in a black-box manner, demonstrating the effectiveness of
MetaCloak in real-world scenarios. Our code is available at
https://github.com/liuyixin-louis/MetaCloak.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13128" title="Abstract">arXiv:2311.13128</a> [<a href="/pdf/2311.13128" title="Download PDF">pdf</a>, <a href="/format/2311.13128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> P2RBox: A Single Point is All You Need for Oriented Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+G">Guangming Cao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xuehui Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenwen Yu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xumeng Han</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xue Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guorong Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+J">Jianbin Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhenjun Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Oriented object detection, a specialized subfield in computer vision, finds
applications across diverse scenarios, excelling particularly when dealing with
objects of arbitrary orientations. Conversely, point annotation, which treats
objects as single points, offers a cost-effective alternative to rotated and
horizontal bounding boxes but sacrifices performance due to the loss of size
and orientation information. In this study, we introduce the P2RBox network,
which leverages point annotations and a mask generator to create mask
proposals, followed by filtration through our Inspector Module and Constrainer
Module. This process selects high-quality masks, which are subsequently
converted into rotated box annotations for training a fully supervised
detector. Specifically, we've thoughtfully crafted an Inspector Module rooted
in multi-instance learning principles to evaluate the semantic score of masks.
We've also proposed a more robust mask quality assessment in conjunction with
the Constrainer Module. Furthermore, we've introduced a Symmetry Axis
Estimation (SAE) Module inspired by the spectral theorem for symmetric matrices
to transform the top-performing mask proposal into rotated bounding boxes.
P2RBox performs well with three fully supervised rotated object detectors:
RetinaNet, Rotated FCOS, and Oriented R-CNN. By combining with Oriented R-CNN,
P2RBox achieves 62.26% on DOTA-v1.0 test dataset. As far as we know, this is
the first attempt at training an oriented object detector with point
supervision.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13132" title="Abstract">arXiv:2311.13132</a> [<a href="/pdf/2311.13132" title="Download PDF">pdf</a>, <a href="/format/2311.13132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Orientable Burning Number of Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Courtiel%2C+J">Julien Courtiel</a>, 
<a href="/search/cs?searchtype=author&query=Dorbec%2C+P">Paul Dorbec</a>, 
<a href="/search/cs?searchtype=author&query=Gima%2C+T">Tatsuya Gima</a>, 
<a href="/search/cs?searchtype=author&query=Lecoq%2C+R">Romain Lecoq</a>, 
<a href="/search/cs?searchtype=author&query=Otachi%2C+Y">Yota Otachi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17pages, 3 figures, WALCOM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">In this paper, we introduce the problem of finding an orientation of a given
undirected graph that maximizes the burning number of the resulting directed
graph. We show that the problem is polynomial-time solvable on
K\H{o}nig-Egerv\'{a}ry graphs (and thus on bipartite graphs) and that an almost
optimal solution can be computed in polynomial time for perfect graphs. On the
other hand, we show that the problem is NP-hard in general and W[1]-hard
parameterized by the target burning number. The hardness results are
complemented by several fixed-parameter tractable results parameterized by
structural parameters. Our main result in this direction shows that the problem
is fixed-parameter tractable parameterized by cluster vertex deletion number
plus clique number (and thus also by vertex cover number).
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13133" title="Abstract">arXiv:2311.13133</a> [<a href="/pdf/2311.13133" title="Download PDF">pdf</a>, <a href="/format/2311.13133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LIMIT: Less Is More for Instruction Tuning Across Evaluation Paradigms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jha%2C+A">Aditi Jha</a>, 
<a href="/search/cs?searchtype=author&query=Havens%2C+S">Sam Havens</a>, 
<a href="/search/cs?searchtype=author&query=Dohmann%2C+J">Jeremey Dohmann</a>, 
<a href="/search/cs?searchtype=author&query=Trott%2C+A">Alex Trott</a>, 
<a href="/search/cs?searchtype=author&query=Portes%2C+J">Jacob Portes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 12 figures, NeurIPS 2023 Workshop on Instruction Tuning and Instruction Following
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Large Language Models are traditionally finetuned on large instruction
datasets. However recent studies suggest that small, high-quality datasets can
suffice for general purpose instruction following. This lack of consensus
surrounding finetuning best practices is in part due to rapidly diverging
approaches to LLM evaluation. In this study, we ask whether a small amount of
diverse finetuning samples can improve performance on both traditional
perplexity-based NLP benchmarks, and on open-ended, model-based evaluation. We
finetune open-source MPT-7B and MPT-30B models on instruction finetuning
datasets of various sizes ranging from 1k to 60k samples. We find that subsets
of 1k-6k instruction finetuning samples are sufficient to achieve good
performance on both (1) traditional NLP benchmarks and (2) model-based
evaluation. Finally, we show that mixing textbook-style and open-ended QA
finetuning datasets optimizes performance on both evaluation paradigms.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13134" title="Abstract">arXiv:2311.13134</a> [<a href="/pdf/2311.13134" title="Download PDF">pdf</a>, <a href="/format/2311.13134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lightweight High-Speed Photography Built on Coded Exposure and Implicit  Neural Representation of Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhihong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Runzhao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Suo%2C+J">Jinli Suo</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yuxiao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Q">Qionghai Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">The compact cameras recording high-speed scenes with high resolution are
highly demanded, but the required high bandwidth often leads to bulky, heavy
systems, which limits their applications on low-capacity platforms. Adopting a
coded exposure setup to encode a frame sequence into a blurry snapshot and
retrieve the latent sharp video afterward can serve as a lightweight solution.
However, restoring motion from blur is quite challenging due to the high
ill-posedness of motion blur decomposition, intrinsic ambiguity in motion
direction, and diverse motions in natural videos. In this work, by leveraging
classical coded exposure imaging technique and emerging implicit neural
representation for videos, we tactfully embed the motion direction cues into
the blurry image during the imaging process and develop a novel self-recursive
neural network to sequentially retrieve the latent video sequence from the
blurry image utilizing the embedded motion direction cues. To validate the
effectiveness and efficiency of the proposed framework, we conduct extensive
experiments on benchmark datasets and real-captured blurry images. The results
demonstrate that our proposed framework significantly outperforms existing
methods in quality and flexibility. The code for our work is available at
https://github.com/zhihongz/BDINR
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13139" title="Abstract">arXiv:2311.13139</a> [<a href="/pdf/2311.13139" title="Download PDF">pdf</a>, <a href="/ps/2311.13139" title="Download PostScript">ps</a>, <a href="/format/2311.13139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Distributed Precoding and Beamforming for RIS-aided Cell-Free  Massive MIMO Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiayi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+H">Huahua Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaodan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+D+W+K">Derrick Wing Kwan Ng</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+B">Bo Ai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The amalgamation of cell-free networks and reconfigurable intelligent surface
(RIS) has become a prospective technique for future sixth-generation wireless
communication systems. In this paper, we focus on the precoding and beamforming
design for a downlink RIS-aided cell-free network. The design is formulated as
a non-convex optimization problem by jointly optimizing the combining vector,
active precoding, and passive RIS beamforming for minimizing the weighted sum
of users' mean square error. A novel joint distributed precoding and
beamforming framework is proposed to decentralize the alternating optimization
method for acquiring a suboptimal solution to the design problem. Finally,
numerical results validate the effectiveness of the proposed distributed
precoding and beamforming framework, showing its low-complexity and improved
scalability compared with the centralized method.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13141" title="Abstract">arXiv:2311.13141</a> [<a href="/pdf/2311.13141" title="Download PDF">pdf</a>, <a href="/format/2311.13141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion360: Seamless 360 Degree Panoramic Image Generation based on  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+M">Mengyang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinlin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+M">Miaomiao Cui</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xuansong Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 pages, 8 figures, Tech. Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This is a technical report on the 360-degree panoramic image generation task
based on diffusion models. Unlike ordinary 2D images, 360-degree panoramic
images capture the entire $360^\circ\times 180^\circ$ field of view. So the
rightmost and the leftmost sides of the 360 panoramic image should be
continued, which is the main challenge in this field. However, the current
diffusion pipeline is not appropriate for generating such a seamless 360-degree
panoramic image. To this end, we propose a circular blending strategy on both
the denoising and VAE decoding stages to maintain the geometry continuity.
Based on this, we present two models for \textbf{Text-to-360-panoramas} and
\textbf{Single-Image-to-360-panoramas} tasks. The code has been released as an
open-source project at
\href{https://github.com/ArcherFMY/SD-T2I-360PanoImage}{https://github.com/ArcherFMY/SD-T2I-360PanoImage}
and
\href{https://www.modelscope.cn/models/damo/cv_diffusion_text-to-360panorama-image_generation/summary}{ModelScope}
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13147" title="Abstract">arXiv:2311.13147</a> [<a href="/pdf/2311.13147" title="Download PDF">pdf</a>, <a href="/format/2311.13147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Transport with Cyclic Symmetry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Takeda%2C+S">Shoichiro Takeda</a>, 
<a href="/search/cs?searchtype=author&query=Akagi%2C+Y">Yasunori Akagi</a>, 
<a href="/search/cs?searchtype=author&query=Marumo%2C+N">Naoki Marumo</a>, 
<a href="/search/cs?searchtype=author&query=Niwa%2C+K">Kenta Niwa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We propose novel fast algorithms for optimal transport (OT) utilizing a
cyclic symmetry structure of input data. Such OT with cyclic symmetry appears
universally in various real-world examples: image processing, urban planning,
and graph processing. Our main idea is to reduce OT to a small optimization
problem that has significantly fewer variables by utilizing cyclic symmetry and
various optimization techniques. On the basis of this reduction, our algorithms
solve the small optimization problem instead of the original OT. As a result,
our algorithms obtain the optimal solution and the objective function value of
the original OT faster than solving the original OT directly. In this paper,
our focus is on two crucial OT formulations: the linear programming OT (LOT)
and the strongly convex-regularized OT, which includes the well-known
entropy-regularized OT (EROT). Experiments show the effectiveness of our
algorithms for LOT and EROT in synthetic/real-world data that has a
strict/approximate cyclic symmetry structure. Through theoretical and
experimental results, this paper successfully introduces the concept of
symmetry into the OT research field for the first time.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13148" title="Abstract">arXiv:2311.13148</a> [<a href="/pdf/2311.13148" title="Download PDF">pdf</a>, <a href="/format/2311.13148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building the Future of Responsible AI: A Pattern-Oriented Reference  Architecture for Designing Large Language Model based Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Q">Qinghua Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Liming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Z">Zhenchang Xing</a>, 
<a href="/search/cs?searchtype=author&query=Harrer%2C+S">Stefan Harrer</a>, 
<a href="/search/cs?searchtype=author&query=Whittle%2C+J">Jon Whittle</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Large language models (LLMs) have been widely recognized as transformative
technology due to their capabilities to understand and generate natural
language text, including plans with some limited reasoning capabilities.
LLM-based agents derive their autonomy from the capabilities of LLMs, which
enable them to autonomously break down the given goal into a set of manageable
tasks and orchestrate the task execution to fulfill the goal. Despite the huge
efforts put into building LLM-based autonomous agents, the architecture design
of the agents has not yet been systematically explored. Also, while there are
significant benefits of using autonomous agents for planning and execution,
there are serious considerations regarding responsible AI related software
quality attributes, such as security and accountability. Therefore, this paper
presents a pattern-oriented reference architecture that serves as architecture
design guidelines and enables responsible-AI-by-design when designing LLM-based
autonomous agents. We evaluate the completeness and utility of the proposed
reference architecture by mapping it to the architecture of two real-world
agents.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13149" title="Abstract">arXiv:2311.13149</a> [<a href="/pdf/2311.13149" title="Download PDF">pdf</a>, <a href="/ps/2311.13149" title="Download PostScript">ps</a>, <a href="/format/2311.13149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Microgrid Resilience with Green Hydrogen Storage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dhankar%2C+S">Shreshtha Dhankar</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+C">Cong Chen</a>, 
<a href="/search/eess?searchtype=author&query=Tong%2C+L">Lang Tong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 7 figure, PESGM2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">We consider the problem of hydrogen storage integration in microgrids to
improve the electricity supply resilience. Nonlinear effects from
electrochemical models of electrolyzers and fuel cells for hydrogen storage are
considered, making scheduling under the nonlinear model intractable and the
conventional linear approximation infeasible. A piecewise linear model
approximation with feasibility projection is proposed, resulting in a
computationally efficient model predictive control for hydrogen storage
operation. Several resilience performance measures, such as loss-of-load,
duration-of-outage, and system cost, are used in performance evaluation.
Simulations for the proposed optimization demonstrated a 13%-48% reduction in
duration-of-outage, a 6.4%-21.7% reduction in system cost, and a 95% reduction
in loss-of-load for critical loads compared to the scheduling algorithm
involving linear model approximation. The performance gap of the proposed
optimization to the benchmark involving the accurate nonlinear electrochemical
model is less than 1% in most metrics.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13152" title="Abstract">arXiv:2311.13152</a> [<a href="/pdf/2311.13152" title="Download PDF">pdf</a>, <a href="/format/2311.13152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Test-Time Augmentation for 3D Point Cloud Classification and  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vu%2C+T">Tuan-Anh Vu</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+S">Srinjay Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+B">Binh-Son Hua</a>, 
<a href="/search/cs?searchtype=author&query=Yeung%2C+S">Sai-Kit Yeung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted in 3DV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Data augmentation is a powerful technique to enhance the performance of a
deep learning task but has received less attention in 3D deep learning. It is
well known that when 3D shapes are sparsely represented with low point density,
the performance of the downstream tasks drops significantly. This work explores
test-time augmentation (TTA) for 3D point clouds. We are inspired by the recent
revolution of learning implicit representation and point cloud upsampling,
which can produce high-quality 3D surface reconstruction and
proximity-to-surface, respectively. Our idea is to leverage the implicit field
reconstruction or point cloud upsampling techniques as a systematic way to
augment point cloud data. Mainly, we test both strategies by sampling points
from the reconstructed results and using the sampled point cloud as test-time
augmented data. We show that both strategies are effective in improving
accuracy. We observed that point cloud upsampling for test-time augmentation
can lead to more significant performance improvement on downstream tasks such
as object classification and segmentation on the ModelNet40, ShapeNet,
ScanObjectNN, and SemanticKITTI datasets, especially for sparse point clouds.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13154" title="Abstract">arXiv:2311.13154</a> [<a href="/pdf/2311.13154" title="Download PDF">pdf</a>, <a href="/format/2311.13154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Testing Closeness of Multivariate Distributions via Ramsey Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Diakonikolas%2C+I">Ilias Diakonikolas</a>, 
<a href="/search/cs?searchtype=author&query=Kane%2C+D+M">Daniel M. Kane</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sihan Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
<p class="mathjax">We investigate the statistical task of closeness (or equivalence) testing for
multidimensional distributions. Specifically, given sample access to two
unknown distributions $\mathbf p, \mathbf q$ on $\mathbb R^d$, we want to
distinguish between the case that $\mathbf p=\mathbf q$ versus $\|\mathbf
p-\mathbf q\|_{A_k} &gt; \epsilon$, where $\|\mathbf p-\mathbf q\|_{A_k}$ denotes
the generalized ${A}_k$ distance between $\mathbf p$ and $\mathbf q$ --
measuring the maximum discrepancy between the distributions over any collection
of $k$ disjoint, axis-aligned rectangles. Our main result is the first
closeness tester for this problem with {\em sub-learning} sample complexity in
any fixed dimension and a nearly-matching sample complexity lower bound.
<br />In more detail, we provide a computationally efficient closeness tester with
sample complexity $O\left((k^{6/7}/ \mathrm{poly}_d(\epsilon))
\log^d(k)\right)$. On the lower bound side, we establish a qualitatively
matching sample complexity lower bound of
$\Omega(k^{6/7}/\mathrm{poly}(\epsilon))$, even for $d=2$. These sample
complexity bounds are surprising because the sample complexity of the problem
in the univariate setting is $\Theta(k^{4/5}/\mathrm{poly}(\epsilon))$. This
has the interesting consequence that the jump from one to two dimensions leads
to a substantial increase in sample complexity, while increases beyond that do
not.
<br />As a corollary of our general $A_k$ tester, we obtain $d_{\mathrm
TV}$-closeness testers for pairs of $k$-histograms on $\mathbb R^d$ over a
common unknown partition, and pairs of uniform distributions supported on the
union of $k$ unknown disjoint axis-aligned rectangles.
<br />Both our algorithm and our lower bound make essential use of tools from
Ramsey theory.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13158" title="Abstract">arXiv:2311.13158</a> [<a href="/pdf/2311.13158" title="Download PDF">pdf</a>, <a href="/format/2311.13158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Principles to Practice: An Accountability Metrics Catalogue for  Managing AI Risks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+B">Boming Xia</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Q">Qinghua Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Liming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S+U">Sung Une Lee</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Z">Zhenchang Xing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Artificial Intelligence (AI), particularly through the advent of large-scale
generative AI (GenAI) models such as Large Language Models (LLMs), has become a
transformative element in contemporary technology. While these models have
unlocked new possibilities, they simultaneously present significant challenges,
such as concerns over data privacy and the propensity to generate misleading or
fabricated content. Current frameworks for Responsible AI (RAI) often fall
short in providing the granular guidance necessary for tangible application,
especially for Accountability-a principle that is pivotal for ensuring
transparent and auditable decision-making, bolstering public trust, and meeting
increasing regulatory expectations. This study bridges the accountability gap
by introducing a comprehensive metrics catalogue, formulated through a
systematic multivocal literature review (MLR) that integrates findings from
both academic and grey literature. Our catalogue delineates process metrics
that underpin procedural integrity, resource metrics that provide necessary
tools and frameworks, and product metrics that reflect the outputs of AI
systems. This tripartite framework is designed to operationalize Accountability
in AI, with a special emphasis on addressing the intricacies of GenAI. The
proposed metrics catalogue provides a robust framework for instilling
Accountability in AI systems. It offers practical, actionable guidance for
organizations, thereby shaping responsible practices in the field.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13159" title="Abstract">arXiv:2311.13159</a> [<a href="/pdf/2311.13159" title="Download PDF">pdf</a>, <a href="/format/2311.13159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Objective Optimization via Wasserstein-Fisher-Rao Gradient Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yinuo Ren</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+T">Tesi Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Gangwani%2C+T">Tanmay Gangwani</a>, 
<a href="/search/cs?searchtype=author&query=Rangi%2C+A">Anshuka Rangi</a>, 
<a href="/search/cs?searchtype=author&query=Rahmanian%2C+H">Holakou Rahmanian</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+L">Lexing Ying</a>, 
<a href="/search/cs?searchtype=author&query=Sanyal%2C+S">Subhajit Sanyal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">Multi-objective optimization (MOO) aims to optimize multiple, possibly
conflicting objectives with widespread applications. We introduce a novel
interacting particle method for MOO inspired by molecular dynamics simulations.
Our approach combines overdamped Langevin and birth-death dynamics,
incorporating a "dominance potential" to steer particles toward global Pareto
optimality. In contrast to previous methods, our method is able to relocate
dominated particles, making it particularly adept at managing Pareto fronts of
complicated geometries. Our method is also theoretically grounded as a
Wasserstein-Fisher-Rao gradient flow with convergence guarantees. Extensive
experiments confirm that our approach outperforms state-of-the-art methods on
challenging synthetic and real-world datasets.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13160" title="Abstract">arXiv:2311.13160</a> [<a href="/pdf/2311.13160" title="Download PDF">pdf</a>, <a href="/format/2311.13160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models in Education: Vision and Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gan%2C+W">Wensheng Gan</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Z">Zhenlian Qi</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiayang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J+C">Jerry Chun-Wei Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE BigData 2023. 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">With the rapid development of artificial intelligence technology, large
language models (LLMs) have become a hot research topic. Education plays an
important role in human social development and progress. Traditional education
faces challenges such as individual student differences, insufficient
allocation of teaching resources, and assessment of teaching effectiveness.
Therefore, the applications of LLMs in the field of digital/smart education
have broad prospects. The research on educational large models (EduLLMs) is
constantly evolving, providing new methods and approaches to achieve
personalized learning, intelligent tutoring, and educational assessment goals,
thereby improving the quality of education and the learning experience. This
article aims to investigate and summarize the application of LLMs in smart
education. It first introduces the research background and motivation of LLMs
and explains the essence of LLMs. It then discusses the relationship between
digital education and EduLLMs and summarizes the current research status of
educational large models. The main contributions are the systematic summary and
vision of the research background, motivation, and application of large models
for education (LLM4Edu). By reviewing existing research, this article provides
guidance and insights for educators, researchers, and policy-makers to gain a
deep understanding of the potential and challenges of LLM4Edu. It further
provides guidance for further advancing the development and application of
LLM4Edu, while still facing technical, ethical, and practical challenges
requiring further research and exploration.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13162" title="Abstract">arXiv:2311.13162</a> [<a href="/pdf/2311.13162" title="Download PDF">pdf</a>, <a href="/format/2311.13162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Top-$L$ Most Influential Community Detection Over Social Networks  (Technical Report)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Nan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yutong Ye</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+X">Xiang Lian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mingsong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Databases (cs.DB)

</div>
<p class="mathjax">In many real-world applications such as social network analysis and online
marketing/advertising, the \textit{community detection} is a fundamental task
to identify communities (subgraphs) in social networks with high structural
cohesiveness. While previous works focus on detecting communities alone, they
do not consider the collective influences of users in these communities on
other user nodes in social networks. Inspired by this, in this paper, we
investigate the influence propagation from some \textit{seed communities} and
their influential effects that result in the \textit{influenced communities}.
We propose a novel problem, named \textit{\underline{Top-$L$} most
\underline{I}nfluential \underline{C}ommunity \underline{DE}tection}
(Top$L$-ICDE) over social networks, which aims to retrieve top-$L$ seed
communities with the highest influences, having high structural cohesiveness,
and containing user-specified query keywords. In order to efficiently tackle
the Top$L$-ICDE problem, we design effective pruning strategies to filter out
false alarms of seed communities and propose an effective index mechanism to
facilitate efficient Top-$L$ community retrieval. We develop an efficient
Top$L$-ICDE answering algorithm by traversing the index and applying our
proposed pruning strategies. We also formulate and tackle a variant of
Top$L$-ICDE, named \textit{diversified top-$L$ most influential community
detection} (DTop$L$-ICDE), which returns a set of $L$ diversified communities
with the highest diversity score (i.e., collaborative influences by $L$
communities). We prove that DTop$L$-ICDE is NP-hard, and propose an efficient
greedy algorithm with our designed diversity score pruning. Through extensive
experiments, we verify the efficiency and effectiveness of our proposed
Top$L$-ICDE and DTop$L$-ICDE approaches over real/synthetic social networks
under various parameter settings.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13163" title="Abstract">arXiv:2311.13163</a> [<a href="/pdf/2311.13163" title="Download PDF">pdf</a>, <a href="/format/2311.13163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Have Your Cake and Eat It Too: Toward Efficient and Accurate Split  Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+D">Dengke Yan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+M">Ming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Z">Zeke Xia</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yanxin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+J">Jun Xia</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaofei Xie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mingsong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Due to its advantages in resource constraint scenarios, Split Federated
Learning (SFL) is promising in AIoT systems. However, due to data heterogeneity
and stragglers, SFL suffers from the challenges of low inference accuracy and
low efficiency. To address these issues, this paper presents a novel SFL
approach, named Sliding Split Federated Learning (S$^2$FL), which adopts an
adaptive sliding model split strategy and a data balance-based training
mechanism. By dynamically dispatching different model portions to AIoT devices
according to their computing capability, S$^2$FL can alleviate the low training
efficiency caused by stragglers. By combining features uploaded by devices with
different data distributions to generate multiple larger batches with a uniform
distribution for back-propagation, S$^2$FL can alleviate the performance
degradation caused by data heterogeneity. Experimental results demonstrate
that, compared to conventional SFL, S$^2$FL can achieve up to 16.5\% inference
accuracy improvement and 3.54X training acceleration.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13165" title="Abstract">arXiv:2311.13165</a> [<a href="/pdf/2311.13165" title="Download PDF">pdf</a>, <a href="/format/2311.13165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Large Language Models: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiayang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+W">Wensheng Gan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zefeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+S">Shicheng Wan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S. Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE BigData 2023. 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The exploration of multimodal language models integrates multiple data types,
such as images, text, language, audio, and other heterogeneity. While the
latest large language models excel in text-based tasks, they often struggle to
understand and process other data types. Multimodal models address this
limitation by combining various modalities, enabling a more comprehensive
understanding of diverse data. This paper begins by defining the concept of
multimodal and examining the historical development of multimodal algorithms.
Furthermore, we introduce a range of multimodal products, focusing on the
efforts of major technology companies. A practical guide is provided, offering
insights into the technical aspects of multimodal models. Moreover, we present
a compilation of the latest algorithms and commonly used datasets, providing
researchers with valuable resources for experimentation and evaluation. Lastly,
we explore the applications of multimodal models and discuss the challenges
associated with their development. By addressing these aspects, this paper aims
to facilitate a deeper understanding of multimodal models and their potential
in various domains.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13166" title="Abstract">arXiv:2311.13166</a> [<a href="/pdf/2311.13166" title="Download PDF">pdf</a>, <a href="/format/2311.13166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdaptiveFL: Adaptive Heterogeneous Federated Learning for  Resource-Constrained AIoT Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+C">Chentao Jia</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+M">Ming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zekai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yanxin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaofei Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mingsong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Although Federated Learning (FL) is promising to enable collaborative
learning among Artificial Intelligence of Things (AIoT) devices, it suffers
from the problem of low classification performance due to various heterogeneity
factors (e.g., computing capacity, memory size) of devices and uncertain
operating environments. To address these issues, this paper introduces an
effective FL approach named AdaptiveFL based on a novel fine-grained width-wise
model pruning strategy, which can generate various heterogeneous local models
for heterogeneous AIoT devices. By using our proposed reinforcement
learning-based device selection mechanism, AdaptiveFL can adaptively dispatch
suitable heterogeneous models to corresponding AIoT devices on the fly based on
their available resources for local training. Experimental results show that,
compared to state-of-the-art methods, AdaptiveFL can achieve up to 16.83%
inference improvements for both IID and non-IID scenarios.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13168" title="Abstract">arXiv:2311.13168</a> [<a href="/pdf/2311.13168" title="Download PDF">pdf</a>, <a href="/format/2311.13168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Face Style Transfer with a Hybrid Solution of NeRF and Mesh  Rasterization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jianwei Feng</a>, 
<a href="/search/cs?searchtype=author&query=Singhal%2C+P">Prateek Singhal</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Style transfer for human face has been widely researched in recent years.
Majority of the existing approaches work in 2D image domain and have 3D
inconsistency issue when applied on different viewpoints of the same face. In
this paper, we tackle the problem of 3D face style transfer which aims at
generating stylized novel views of a 3D human face with multi-view consistency.
We propose to use a neural radiance field (NeRF) to represent 3D human face and
combine it with 2D style transfer to stylize the 3D face. We find that directly
training a NeRF on stylized images from 2D style transfer brings in 3D
inconsistency issue and causes blurriness. On the other hand, training a NeRF
jointly with 2D style transfer objectives shows poor convergence due to the
identity and head pose gap between style image and content image. It also poses
challenge in training time and memory due to the need of volume rendering for
full image to apply style transfer loss functions. We therefore propose a
hybrid framework of NeRF and mesh rasterization to combine the benefits of high
fidelity geometry reconstruction of NeRF and fast rendering speed of mesh. Our
framework consists of three stages: 1. Training a NeRF model on input face
images to learn the 3D geometry; 2. Extracting a mesh from the trained NeRF
model and optimizing it with style transfer objectives via differentiable
rasterization; 3. Training a new color network in NeRF conditioned on a style
embedding to enable arbitrary style transfer to the 3D face. Experiment results
show that our approach generates high quality face style transfer with great 3D
consistency, while also enabling a flexible style control.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13169" title="Abstract">arXiv:2311.13169</a> [<a href="/pdf/2311.13169" title="Download PDF">pdf</a>, <a href="/format/2311.13169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SiGeo: Sub-One-Shot NAS via Information Theory and Geometry of Loss  Landscape
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hua Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kuang-Hung Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fedorov%2C+I">Igor Fedorov</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wen-Yen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+W">Wei Wen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Neural Architecture Search (NAS) has become a widely used tool for automating
neural network design. While one-shot NAS methods have successfully reduced
computational requirements, they often require extensive training. On the other
hand, zero-shot NAS utilizes training-free proxies to evaluate a candidate
architecture's test performance but has two limitations: (1) inability to use
the information gained as a network improves with training and (2) unreliable
performance, particularly in complex domains like RecSys, due to the
multi-modal data inputs and complex architecture configurations. To synthesize
the benefits of both methods, we introduce a "sub-one-shot" paradigm that
serves as a bridge between zero-shot and one-shot NAS. In sub-one-shot NAS, the
supernet is trained using only a small subset of the training data, a phase we
refer to as "warm-up." Within this framework, we present SiGeo, a proxy founded
on a novel theoretical framework that connects the supernet warm-up with the
efficacy of the proxy. Extensive experiments have shown that SiGeo, with the
benefit of warm-up, consistently outperforms state-of-the-art NAS proxies on
various established NAS benchmarks. When a supernet is warmed up, it can
achieve comparable performance to weight-sharing one-shot NAS methods, but with
a significant reduction ($\sim 60$\%) in computational costs.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13171" title="Abstract">arXiv:2311.13171</a> [<a href="/pdf/2311.13171" title="Download PDF">pdf</a>, <a href="/format/2311.13171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ComPEFT: Compression for Communicating Parameter Efficient Updates via  Sparsification and Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yadav%2C+P">Prateek Yadav</a>, 
<a href="/search/cs?searchtype=author&query=Choshen%2C+L">Leshem Choshen</a>, 
<a href="/search/cs?searchtype=author&query=Raffel%2C+C">Colin Raffel</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+M">Mohit Bansal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 Pages, 6 Figures, 16 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Parameter-efficient fine-tuning (PEFT) techniques make it possible to
efficiently adapt a language model to create "expert" models that specialize to
new tasks or domains. Recent techniques in model merging and compositional
generalization leverage these expert models by dynamically composing modules to
improve zero/few-shot generalization. Despite the efficiency of PEFT methods,
the size of expert models can make it onerous to retrieve expert models per
query over high-latency networks like the Internet or serve multiple experts on
a single GPU. To address these issues, we present ComPEFT, a novel method for
compressing fine-tuning residuals (task vectors) of PEFT based models. ComPEFT
employs sparsification and ternary quantization to reduce the size of the PEFT
module without performing any additional retraining while preserving or
enhancing model performance. In extensive evaluation across T5, T0, and
LLaMA-based models with 200M - 65B parameters, ComPEFT achieves compression
ratios of 8x - 50x. In particular, we show that ComPEFT improves with scale -
stronger models exhibit higher compressibility and better performance. For
example, we show that ComPEFT applied to LLaMA outperforms QLoRA by 4.16% on
MMLU with a storage size reduction of up to 26x. In addition, we show that the
compressed experts produced by ComPEFT maintain few-shot compositional
generalization capabilities, facilitate efficient communication and
computation, and exhibit enhanced performance when merged. Lastly, we provide
an analysis of different method components, compare it with other PEFT methods,
and test ComPEFT's efficacy for compressing the residual of full-finetuning.
Our code is available at https://github.com/prateeky2806/compeft.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13172" title="Abstract">arXiv:2311.13172</a> [<a href="/pdf/2311.13172" title="Download PDF">pdf</a>, <a href="/format/2311.13172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Complement with Multiple Humans (LECOMH): Integrating  Multi-rater and Noisy-Label Learning into Human-AI Collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wells%2C+K">Kevin Wells</a>, 
<a href="/search/cs?searchtype=author&query=Carneiro%2C+G">Gustavo Carneiro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The advent of learning with noisy labels (LNL), multi-rater learning, and
human-AI collaboration has revolutionised the development of robust
classifiers, enabling them to address the challenges posed by different types
of data imperfections and complex decision processes commonly encountered in
real-world applications. While each of these methodologies has individually
made significant strides in addressing their unique challenges, the development
of techniques that can simultaneously tackle these three problems remains
underexplored. This paper addresses this research gap by integrating
noisy-label learning, multi-rater learning, and human-AI collaboration with new
benchmarks and the innovative Learning to Complement with Multiple Humans
(LECOMH) approach. LECOMH optimises the level of human collaboration during
testing, aiming to optimise classification accuracy while minimising
collaboration costs that vary from 0 to M, where M is the maximum number of
human collaborators. We quantitatively compare LECOMH with leading human-AI
collaboration methods using our proposed benchmarks. LECOMH consistently
outperforms the competition, with accuracy improving as collaboration costs
increase. Notably, LECOMH is the only method enhancing human labeller
performance across all benchmarks.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13174" title="Abstract">arXiv:2311.13174</a> [<a href="/pdf/2311.13174" title="Download PDF">pdf</a>, <a href="/format/2311.13174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SecureCut: Federated Gradient Boosting Decision Trees with Efficient  Machine Unlearning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B+L+J">Bowen Li Jie Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chentao Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">In response to legislation mandating companies to honor the \textit{right to
be forgotten} by erasing user data, it has become imperative to enable data
removal in Vertical Federated Learning (VFL) where multiple parties provide
private features for model training. In VFL, data removal, i.e.,
\textit{machine unlearning}, often requires removing specific features across
all samples under privacy guarentee in federated learning. To address this
challenge, we propose \methname, a novel Gradient Boosting Decision Tree (GBDT)
framework that effectively enables both \textit{instance unlearning} and
\textit{feature unlearning} without the need for retraining from scratch.
Leveraging a robust GBDT structure, we enable effective data deletion while
reducing degradation of model performance. Extensive experimental results on
popular datasets demonstrate that our method achieves superior model utility
and forgetfulness compared to \textit{state-of-the-art} methods. To our best
knowledge, this is the first work that investigates machine unlearning in VFL
scenarios.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13182" title="Abstract">arXiv:2311.13182</a> [<a href="/pdf/2311.13182" title="Download PDF">pdf</a>, <a href="/format/2311.13182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable Radio Frequency Ray Tracing for Millimeter-Wave Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xingyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Q">Qiyue Xia</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+X">Xinmin Fang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C+X">Chris Xiaoxuan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhengxiong Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Millimeter wave (mmWave) sensing is an emerging technology with applications
in 3D object characterization and environment mapping. However, realizing
precise 3D reconstruction from sparse mmWave signals remains challenging.
Existing methods rely on data-driven learning, constrained by dataset
availability and difficulty in generalization. We propose DiffSBR, a
differentiable framework for mmWave-based 3D reconstruction. DiffSBR
incorporates a differentiable ray tracing engine to simulate radar point clouds
from virtual 3D models. A gradient-based optimizer refines the model parameters
to minimize the discrepancy between simulated and real point clouds.
Experiments using various radar hardware validate DiffSBR's capability for
fine-grained 3D reconstruction, even for novel objects unseen by the radar
previously. By integrating physics-based simulation with gradient optimization,
DiffSBR transcends the limitations of data-driven approaches and pioneers a new
paradigm for mmWave sensing.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13184" title="Abstract">arXiv:2311.13184</a> [<a href="/pdf/2311.13184" title="Download PDF">pdf</a>, <a href="/format/2311.13184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AS-LLM: When Algorithm Selection Meets Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xingyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yan Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jibin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+K+C">Kay Chen Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Algorithm selection aims to identify the most suitable algorithm for solving
a specific problem before execution, which has become a critical process of the
AutoML. Current mainstream algorithm selection techniques rely heavily on
feature representations of various problems and employ the performance of each
algorithm as supervised information. However, there is a significant research
gap concerning the consideration of algorithm features. This gap is primarily
attributed to the inherent complexity of algorithms, making it particularly
challenging to find a universally effective feature extraction method that is
applicable across a diverse range of algorithms. Unfortunately, neglecting this
aspect undoubtedly impacts the accuracy of algorithm selection and indirectly
necessitates an increased volume of problem data for training purposes. This
paper takes a significant stride towards addressing this gap by proposing an
approach that integrates algorithm representation into the algorithm selection
process. Specifically, our proposed model employs distinct modules to extract
representations of both problems and algorithms, where the algorithm
representation leverages the capabilities of pre-trained LLMs in the realm of
code comprehension. Following the extraction of embedding vectors for both
algorithms and problems, the most suitable algorithm is determined through
calculations of matching degrees. Our experiments not only validate the
effectiveness of the proposed model but also showcase the performance of
different embedded pre-trained LLMs, which suggests that the proposed algorithm
selection framework holds the potential to serve as a baseline task for
evaluating the code representation capabilities of LLMs.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13186" title="Abstract">arXiv:2311.13186</a> [<a href="/pdf/2311.13186" title="Download PDF">pdf</a>, <a href="/format/2311.13186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applications of Spiking Neural Networks in Visual Place Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hussaini%2C+S">Somayeh Hussaini</a>, 
<a href="/search/cs?searchtype=author&query=Milford%2C+M">Michael Milford</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+T">Tobias Fischer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 8 figures, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">In robotics, Spiking Neural Networks (SNNs) are increasingly recognized for
their largely-unrealized potential energy efficiency and low latency
particularly when implemented on neuromorphic hardware. Our paper highlights
three advancements for SNNs in Visual Place Recognition (VPR). First, we
propose Modular SNNs, where each SNN represents a set of non-overlapping
geographically distinct places, enabling scalable networks for large
environments. Secondly, we present Ensembles of Modular SNNs, where multiple
networks represent the same place, significantly enhancing accuracy compared to
single-network models. Our SNNs are compact and small, comprising only 1500
neurons and 474k synapses, which makes them ideally suited for ensembling due
to this small size. Lastly, we investigate the role of sequence matching in
SNN-based VPR, a technique where consecutive images are used to refine place
recognition. We analyze the responsiveness of SNNs to ensembling and sequence
matching compared to other VPR techniques. Our contributions highlight the
viability of SNNs for VPR, offering scalable and robust solutions, paving the
way for their application in various energy-sensitive robotic tasks.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13187" title="Abstract">arXiv:2311.13187</a> [<a href="/pdf/2311.13187" title="Download PDF">pdf</a>, <a href="/format/2311.13187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeISF: Neural Incident Stokes Field for Geometry and Material Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Ono%2C+T">Taishi Ono</a>, 
<a href="/search/cs?searchtype=author&query=Uemori%2C+T">Takeshi Uemori</a>, 
<a href="/search/cs?searchtype=author&query=Mihara%2C+H">Hajime Mihara</a>, 
<a href="/search/cs?searchtype=author&query=Gatto%2C+A">Alexander Gatto</a>, 
<a href="/search/cs?searchtype=author&query=Nagahara%2C+H">Hajime Nagahara</a>, 
<a href="/search/cs?searchtype=author&query=Moriuchi%2C+Y">Yuseke Moriuchi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multi-view inverse rendering is the problem of estimating the scene
parameters such as shapes, materials, or illuminations from a sequence of
images captured under different viewpoints. Many approaches, however, assume
single light bounce and thus fail to recover challenging scenarios like
inter-reflections. On the other hand, simply extending those methods to
consider multi-bounced light requires more assumptions to alleviate the
ambiguity. To address this problem, we propose Neural Incident Stokes Fields
(NeISF), a multi-view inverse rendering framework that reduces ambiguities
using polarization cues. The primary motivation for using polarization cues is
that it is the accumulation of multi-bounced light, providing rich information
about geometry and material. Based on this knowledge, the proposed incident
Stokes field efficiently models the accumulated polarization effect with the
aid of an original physically-based differentiable polarimetric renderer.
Lastly, experimental results show that our method outperforms the existing
works in synthetic and real scenarios.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13188" title="Abstract">arXiv:2311.13188</a> [<a href="/pdf/2311.13188" title="Download PDF">pdf</a>, <a href="/format/2311.13188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cracking the Code of Negative Transfer: A Cooperative Game Theoretic  Approach for Cross-Domain Sequential Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+C">Chung Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taesan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+T">Taekyoon Choi</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+J">Junui Hong</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yelim Yu</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+M">Mincheol Cho</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kyunam Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ryu%2C+S">Sungil Ryu</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+H">Hyungjun Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+M">Minsung Choi</a>, 
<a href="/search/cs?searchtype=author&query=Choo%2C+J">Jaegul Choo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at 32nd ACM International Conference on Information and Knowledge Management (CIKM 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper investigates Cross-Domain Sequential Recommendation (CDSR), a
promising method that uses information from multiple domains (more than three)
to generate accurate and diverse recommendations, and takes into account the
sequential nature of user interactions. The effectiveness of these systems
often depends on the complex interplay among the multiple domains. In this
dynamic landscape, the problem of negative transfer arises, where heterogeneous
knowledge between dissimilar domains leads to performance degradation due to
differences in user preferences across these domains. As a remedy, we propose a
new CDSR framework that addresses the problem of negative transfer by assessing
the extent of negative transfer from one domain to another and adaptively
assigning low weight values to the corresponding prediction losses. To this
end, the amount of negative transfer is estimated by measuring the marginal
contribution of each domain to model performance based on a cooperative game
theory. In addition, a hierarchical contrastive learning approach that
incorporates information from the sequence of coarse-level categories into that
of fine-level categories (e.g., item level) when implementing contrastive
learning was developed to mitigate negative transfer. Despite the potentially
low relevance between domains at the fine-level, there may be higher relevance
at the category level due to its generalised and broader preferences. We show
that our model is superior to prior works in terms of model performance on two
real-world datasets across ten different domains.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13193" title="Abstract">arXiv:2311.13193</a> [<a href="/pdf/2311.13193" title="Download PDF">pdf</a>, <a href="/format/2311.13193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal trajectory planning meets network-level routing: Integrated  control framework for emerging mobility systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bang%2C+H">Heeseung Bang</a>, 
<a href="/search/eess?searchtype=author&query=Malikopoulos%2C+A+A">Andreas A. Malikopoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this paper, we introduce a hierarchical decision-making framework for
emerging mobility systems. Despite numerous studies focusing on optimizing
vehicle flow, practical feasibility has often been overlooked. To address this
gap, we present a route-recovery method and energy-optimal trajectory planning
tailored for connected and automated vehicles (CAVs) to ensure the realization
of optimal flow. Our approach identifies the optimal vehicle flow to minimize
total travel time while considering consistent mobility demands in urban
settings. We deploy a heuristic route-recovery algorithm that assigns routes to
CAVs and departure/arrival time at each road segment. Furthermore, we propose
an efficient coordination method that rapidly solves constrained optimization
problems by flexibly piecing together unconstrained energy-optimal
trajectories. The proposed method has the potential to effectively generate
optimal vehicle flow, contributing to the reduction of travel time and energy
consumption in urban areas.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13194" title="Abstract">arXiv:2311.13194</a> [<a href="/pdf/2311.13194" title="Download PDF">pdf</a>, <a href="/format/2311.13194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Improving Document Understanding: An Exploration on  Text-Grounding via MLLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yonghui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wengang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+H">Hao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Keyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Houqiang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the field of document understanding, significant advances have been made
in the fine-tuning of Multimodal Large Language Models (MLLMs) with
instruction-following data. Nevertheless, the potential of text-grounding
capability within text-rich scenarios remains underexplored. In this paper, we
present a text-grounding document understanding model, termed TGDoc, which
addresses this deficiency by enhancing MLLMs with the ability to discern the
spatial positioning of text within images. Empirical evidence suggests that
text-grounding improves the model's interpretation of textual content, thereby
elevating its proficiency in comprehending text-rich images. Specifically, we
compile a dataset containing 99K PowerPoint presentations sourced from the
internet. We formulate instruction tuning tasks including text detection,
recognition, and spotting to facilitate the cohesive alignment between the
visual encoder and large language model. Moreover, we curate a collection of
text-rich images and prompt the text-only GPT-4 to generate 12K high-quality
conversations, featuring textual locations within text-rich scenarios. By
integrating text location data into the instructions, TGDoc is adept at
discerning text locations during the visual question process. Extensive
experiments demonstrate that our method achieves state-of-the-art performance
across multiple text-rich benchmarks, validating the effectiveness of our
method.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13196" title="Abstract">arXiv:2311.13196</a> [<a href="/pdf/2311.13196" title="Download PDF">pdf</a>, <a href="/format/2311.13196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Time of Arrival Estimation for MIMO Backscatter Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+C">Chen He</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+L">Luyang Han</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z+J">Z.Jane Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP); Methodology (stat.ME)

</div>
<p class="mathjax">In this paper, we propose a novel time of arrival (TOA) estimator for
multiple-input-multiple-output (MIMO) backscatter channels in closed form. The
proposed estimator refines the estimation precision from the topological
structure of the MIMO backscatter channels, and can considerably enhance the
estimation accuracy. Particularly, we show that for the general $M \times N$
bistatic topology, the mean square error (MSE) is $\frac{M+N-1}{MN}\sigma^2_0$,
and for the general $M \times M$ monostatic topology, it is
$\frac{2M-1}{M^2}\sigma^2_0$ for the diagonal subchannels, and
$\frac{M-1}{M^2}\sigma^2_0$ for the off-diagonal subchannels, where
$\sigma^2_0$ is the MSE of the conventional least square estimator. In
addition, we derive the Cramer-Rao lower bound (CRLB) for MIMO backscatter TOA
estimation which indicates that the proposed estimator is optimal. Simulation
results verify that the proposed TOA estimator can considerably improve both
estimation and positioning accuracy, especially when the MIMO scale is large.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13198" title="Abstract">arXiv:2311.13198</a> [<a href="/pdf/2311.13198" title="Download PDF">pdf</a>, <a href="/format/2311.13198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DoubleAUG: Single-domain Generalized Object Detector in Urban via Color  Perturbation and Dual-style Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+L">Lei Qi</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+P">Peng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+T">Tan Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+H">Hui Xue</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+X">Xin Geng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM Transactions on Multimedia Computing, Communications, and Applications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Object detection in urban scenarios is crucial for autonomous driving in
intelligent traffic systems. However, unlike conventional object detection
tasks, urban-scene images vary greatly in style. For example, images taken on
sunny days differ significantly from those taken on rainy days. Therefore,
models trained on sunny day images may not generalize well to rainy day images.
In this paper, we aim to solve the single-domain generalizable object detection
task in urban scenarios, meaning that a model trained on images from one
weather condition should be able to perform well on images from any other
weather conditions. To address this challenge, we propose a novel Double
AUGmentation (DoubleAUG) method that includes image- and feature-level
augmentation schemes. In the image-level augmentation, we consider the
variation in color information across different weather conditions and propose
a Color Perturbation (CP) method that randomly exchanges the RGB channels to
generate various images. In the feature-level augmentation, we propose to
utilize a Dual-Style Memory (DSM) to explore the diverse style information on
the entire dataset, further enhancing the model's generalization capability.
Extensive experiments demonstrate that our proposed method outperforms
state-of-the-art methods. Furthermore, ablation studies confirm the
effectiveness of each module in our proposed method. Moreover, our method is
plug-and-play and can be integrated into existing methods to further improve
model performance.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13199" title="Abstract">arXiv:2311.13199</a> [<a href="/pdf/2311.13199" title="Download PDF">pdf</a>, <a href="/format/2311.13199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DRIFu: Differentiable Rendering and Implicit Function-based Single-View  3D Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuang%2C+Z">Zijian Kuang</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+L">Lihang Ying</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Shi Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/1905.05172">arXiv:1905.05172</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The Differentiable Rendering and Implicit Function-based model (DRIFu) draws
its roots from the Pixel-aligned Implicit Function (PIFU), a pioneering 3D
digitization technique initially designed for clothed human bodies. PIFU excels
in capturing nuanced body shape variations within a low-dimensional space and
has been extensively trained on human 3D scans. However, the application of
PIFU to live animals poses significant challenges, primarily due to the
inherent difficulty in obtaining the cooperation of animals for 3D scanning. In
response to this challenge, we introduce the DRIFu model, specifically tailored
for animal digitization. To train DRIFu, we employ a curated set of synthetic
3D animal models, encompassing diverse shapes, sizes, and even accounting for
variations such as baby birds. Our innovative alignment tools play a pivotal
role in mapping these diverse synthetic animal models onto a unified template,
facilitating precise predictions of animal shape and texture. Crucially, our
template alignment strategy establishes a shared shape space, allowing for the
seamless sampling of new animal shapes, posing them realistically, animating
them, and aligning them with real-world data. This groundbreaking approach
revolutionizes our capacity to comprehensively understand and represent avian
forms. For further details and access to the project, the project website can
be found at https://github.com/kuangzijian/drifu-for-animals
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13200" title="Abstract">arXiv:2311.13200</a> [<a href="/pdf/2311.13200" title="Download PDF">pdf</a>, <a href="/format/2311.13200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-guided Few-shot Semantic Segmentation for Remote Sensing Imagery  Based on Large Vision Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xiyu Qi</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yifan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yongqiang Mao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenhui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yidan Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The Segment Anything Model (SAM) exhibits remarkable versatility and
zero-shot learning abilities, owing largely to its extensive training data
(SA-1B). Recognizing SAM's dependency on manual guidance given its
category-agnostic nature, we identified unexplored potential within few-shot
semantic segmentation tasks for remote sensing imagery. This research
introduces a structured framework designed for the automation of few-shot
semantic segmentation. It utilizes the SAM model and facilitates a more
efficient generation of semantically discernible segmentation outcomes. Central
to our methodology is a novel automatic prompt learning approach, leveraging
prior guided masks to produce coarse pixel-wise prompts for SAM. Extensive
experiments on the DLRSD datasets underline the superiority of our approach,
outperforming other available few-shot methodologies.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13206" title="Abstract">arXiv:2311.13206</a> [<a href="/pdf/2311.13206" title="Download PDF">pdf</a>, <a href="/ps/2311.13206" title="Download PostScript">ps</a>, <a href="/format/2311.13206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Breast Cancer classification by adaptive weighted average ensemble of  previously trained models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farea%2C+M+S+M">Mosab S. M. Farea</a>, 
<a href="/search/cs?searchtype=author&query=chen%2C+z">zhe chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages article
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Breast cancer is a serious disease that inflicts millions of people each
year, and the number of cases is increasing. Early detection is the best way to
reduce the impact of the disease. Researchers have developed many techniques to
detect breast cancer, including the use of histopathology images in CAD
systems. This research proposes a technique that combine already fully trained
model using adaptive average ensemble, this is different from the literature
which uses average ensemble before training and the average ensemble is trained
simultaneously. Our approach is different because it used adaptive average
ensemble after training which has increased the performance of evaluation
metrics. It averages the outputs of every trained model, and every model will
have weight according to its accuracy. The accuracy in the adaptive weighted
ensemble model has achieved 98% where the accuracy has increased by 1 percent
which is better than the best participating model in the ensemble which was
97%. Also, it decreased the numbers of false positive and false negative and
enhanced the performance metrics.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13209" title="Abstract">arXiv:2311.13209</a> [<a href="/pdf/2311.13209" title="Download PDF">pdf</a>, <a href="/format/2311.13209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Test-time Adaptive Vision-and-Language Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Junyu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+X">Xuan Yao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Changsheng Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vision-and-Language Navigation (VLN) has witnessed significant advancements
in recent years, largely attributed to meticulously curated datasets and
proficiently trained models. Nevertheless, when tested in diverse environments,
the trained models inevitably encounter significant shifts in data
distribution, highlighting that relying solely on pre-trained and fixed
navigation models is insufficient. To enhance models' generalization ability,
test-time adaptation (TTA) demonstrates significant potential in the computer
vision field by leveraging unlabeled test samples for model updates. However,
simply applying existing TTA methods to the VLN task cannot well handle the
adaptability-stability dilemma of VLN models, i.e., frequent updates can result
in drastic changes in model parameters, while occasional updates can make the
models ill-equipped to handle dynamically changing environments. Therefore, we
propose a Fast-Slow Test-Time Adaptation (FSTTA) approach for VLN by performing
decomposition-accumulation analysis for both gradients and parameters in a
unified framework. Specifically, in the fast update phase, gradients generated
during the recent multi-step navigation process are decomposed into components
with varying levels of consistency. Then, these components are adaptively
accumulated to pinpoint a concordant direction for fast model adaptation. In
the slow update phase, historically recorded parameters are gathered, and a
similar decomposition-accumulation analysis is conducted to revert the model to
a stable state. Extensive experiments show that our method obtains impressive
performance gains on four popular benchmarks.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13213" title="Abstract">arXiv:2311.13213</a> [<a href="/pdf/2311.13213" title="Download PDF">pdf</a>, <a href="/format/2311.13213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Artificial Intelligence in the Service of Entrepreneurial Finance:  Knowledge Structure and the Foundational Algorithmic Paradigm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kudeli%C4%87%2C+R">Robert Kudeli&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=%C5%A0maguc%2C+T">Tamara &#x160;maguc</a>, 
<a href="/search/cs?searchtype=author&query=Robinson%2C+S">Sherry Robinson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">While the application of Artificial Intelligence in Finance has a long
tradition, its potential in Entrepreneurship has been intensively explored only
recently. In this context, Entrepreneurial Finance is a particularly fertile
ground for future Artificial Intelligence proliferation. To support the latter,
the study provides a bibliometric review of Artificial Intelligence
applications in (1) entrepreneurial finance literature, and (2) corporate
finance literature with implications for Entrepreneurship. Rigorous search and
screening procedures of the scientific database Web of Science Core Collection
resulted in the identification of 1890 relevant journal articles subjected to
analysis. The bibliometric analysis gives a rich insight into the knowledge
field's conceptual, intellectual, and social structure, indicating nascent and
underdeveloped research directions. As far as we were able to identify, this is
the first study to map and bibliometrically analyze the academic field
concerning the relationship between Artificial Intelligence, Entrepreneurship,
and Finance, and the first review that deals with Artificial Intelligence
methods in Entrepreneurship. According to the results, Artificial Neural
Network, Deep Neural Network and Support Vector Machine are highly represented
in almost all identified topic niches. At the same time, applying Topic
Modeling, Fuzzy Neural Network and Growing Hierarchical Self-organizing Map is
quite rare. As an element of the research, and before final remarks, the
article deals as well with a discussion of certain gaps in the relationship
between Computer Science and Economics. These gaps do represent problems in the
application of Artificial Intelligence in Economic Science. As a way to at
least in part remedy this situation, the foundational paradigm and the bespoke
demonstration of the Monte Carlo randomized algorithm are presented.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13214" title="Abstract">arXiv:2311.13214</a> [<a href="/pdf/2311.13214" title="Download PDF">pdf</a>, <a href="/format/2311.13214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Passivity-Preserving, Balancing-Based Model Reduction for Interconnected  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Poort%2C+L">Luuk Poort</a>, 
<a href="/search/eess?searchtype=author&query=Besselink%2C+B">Bart Besselink</a>, 
<a href="/search/eess?searchtype=author&query=Fey%2C+R+H+B">Rob H.B. Fey</a>, 
<a href="/search/eess?searchtype=author&query=van+de+Wouw%2C+N">Nathan van de Wouw</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures, to appear in Proceedings of IFAC World Congress 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper proposes a balancing-based model reduction approach for an
interconnection of passive dynamic subsystems. This approach preserves the
passivity and stability of both the subsystems and the interconnected system.
Hereto, one Linear Matrix Inequality (LMI) per subsystem and a single Lyapunov
equation for the entire interconnected system needs to be solved, the latter of
which warrants the relevance of the reduction of the subsystems for the
accurate reduction of the interconnected system, while preserving the
modularity of the reduction approach. In a numerical example from structural
dynamics, the presented approach displays superior accuracy with respect to an
approach in which the individual subsystems are reduced independently.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13216" title="Abstract">arXiv:2311.13216</a> [<a href="/pdf/2311.13216" title="Download PDF">pdf</a>, <a href="/format/2311.13216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asymptotically compatible energy and dissipation law of the nonuniform  L2-$1_&#x3c3;$ scheme for time fractional Allen-Cahn model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liao%2C+H">Hong-lin Liao</a>, 
<a href="/search/math?searchtype=author&query=Zhu%2C+X">Xiaohan Zhu</a>, 
<a href="/search/math?searchtype=author&query=Sun%2C+H">Hong Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages,23 figues
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We build an asymptotically compatible energy of the variable-step
L2-$1_{\sigma}$ scheme for the time-fractional Allen-Cahn model with the
Caputo's fractional derivative of order $\alpha\in(0,1)$, under a weak
step-ratio constraint $\tau_k/\tau_{k-1}\geq r_{\star}(\alpha)$ for $k\ge2$,
where $\tau_k$ is the $k$-th time-step size and
$r_{\star}(\alpha)\in(0.3865,0.4037)$ for $\alpha\in(0,1)$. It provides a
positive answer to the open problem in [J. Comput. Phys., 414:109473], and, to
the best of our knowledge, it is the first second-order nonuniform
time-stepping scheme to preserve both the maximum bound principle and the
energy dissipation law of time-fractional Allen-Cahn model. The compatible
discrete energy is constructed via a novel discrete gradient structure of the
second-order L2-$1_{\sigma}$ formula by a local-nonlocal splitting technique.
It splits the discrete fractional derivative into two parts: one is a local
term analogue to the trapezoid rule of the first derivative and the other is a
nonlocal summation analogue to the L1 formula of Caputo derivative. Numerical
examples with an adaptive time-stepping strategy are provided to show the
effectiveness of our scheme and the asymptotic properties of the associated
modified energy.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13219" title="Abstract">arXiv:2311.13219</a> [<a href="/pdf/2311.13219" title="Download PDF">pdf</a>, <a href="/format/2311.13219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Outlier Bound Condition to Phase Retrieval with Adversarial  Sparse Outliers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Gao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Song Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hang Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first version of this article was submitted on October 28, 2022 at <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4296843">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Functional Analysis (math.FA); Probability (math.PR)

</div>
<p class="mathjax">We consider the problem of recovering an unknown signal $\pmb{x}_0\in
\mathbb{R}^{n}$ from phaseless measurements. In this paper, we study the convex
phase retrieval problem via PhaseLift from linear Gaussian measurements
perturbed by $\ell_{1}$-bounded noise and sparse outliers that can change an
adversarially chosen $s$-fraction of the measurement vector. We show that the
Robust-PhaseLift model can successfully reconstruct the ground-truth up to
global phase for any $s&lt; s^{*}\approx 0.1185$ with $\mathcal{O}(n)$
measurements, even in the case where the sparse outliers may depend on the
measurement and the observation. The recovery guarantees are based on the
robust outlier bound condition and the analysis of the product of two Gaussian
variables. Moreover, we construct adaptive counterexamples to show that the
Robust-PhaseLift model fails when $s&gt; s^{*}$ with high probability.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13222" title="Abstract">arXiv:2311.13222</a> [<a href="/pdf/2311.13222" title="Download PDF">pdf</a>, <a href="/format/2311.13222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Detecting, Recognizing, and Parsing the Address Information from  Bangla Signboard: A Deep Learning-based Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Murad%2C+H">Hasan Murad</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+M+E">Mohammed Eunus Ali</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Retrieving textual information from natural scene images is an active
research area in the field of computer vision with numerous practical
applications. Detecting text regions and extracting text from signboards is a
challenging problem due to special characteristics like reflecting lights,
uneven illumination, or shadows found in real-life natural scene images. With
the advent of deep learning-based methods, different sophisticated techniques
have been proposed for text detection and text recognition from the natural
scene. Though a significant amount of effort has been devoted to extracting
natural scene text for resourceful languages like English, little has been done
for low-resource languages like Bangla. In this research work, we have proposed
an end-to-end system with deep learning-based models for efficiently detecting,
recognizing, correcting, and parsing address information from Bangla
signboards. We have created manually annotated datasets and synthetic datasets
to train signboard detection, address text detection, address text recognition,
address text correction, and address text parser models. We have conducted a
comparative study among different CTC-based and Encoder-Decoder model
architectures for Bangla address text recognition. Moreover, we have designed a
novel address text correction model using a sequence-to-sequence
transformer-based network to improve the performance of Bangla address text
recognition model by post-correction. Finally, we have developed a Bangla
address text parser using the state-of-the-art transformer-based pre-trained
language model.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13223" title="Abstract">arXiv:2311.13223</a> [<a href="/pdf/2311.13223" title="Download PDF">pdf</a>, <a href="/ps/2311.13223" title="Download PostScript">ps</a>, <a href="/format/2311.13223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design Recommendations Based on Speech Analysis for Disability-Friendly  Interfaces for the Control of a Home Automation Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vigouroux%2C+N">Nadine Vigouroux</a> (IRIT-ELIPSE), 
<a href="/search/cs?searchtype=author&query=Vella%2C+F">Fr&#xe9;d&#xe9;ric Vella</a> (IRIT, IRIT-ELIPSE), 
<a href="/search/cs?searchtype=author&query=Lepage%2C+G">Ga&#xeb;lle Lepage</a> (UT2J), 
<a href="/search/cs?searchtype=author&query=Campo%2C+%C3%89">&#xc9;ric Campo</a> (LAAS-S4M, UT2J)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Universal Access in Human-Computer Interaction. HCII 2023, Jul
  2023, Copenhagen (Virtual), Denmark. pp.197-211
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">The objective of this paper is to describe the study on speech interaction
mode for home automation control of equipment by impaired people for an
inclusive housing. The study is related to the HIP HOPE project concerning a
building of 19 inclusive housing units. 7 participants with different types of
disabilities were invited to carry out use cases using voice and touch control.
Only the results obtained on the voice interaction mode through the Amazon
voice assistant are reported here. The results show, according to the type of
handicap, the success rates in the speech recognition of the command emitted on
the equipment and highlight the errors related to the formulation, the noisy
environment, the intelligible speech, the speech segmentation and the bad
synchronization of the audio channel opening.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13225" title="Abstract">arXiv:2311.13225</a> [<a href="/pdf/2311.13225" title="Download PDF">pdf</a>, <a href="/format/2311.13225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeutronOrch: Rethinking Sample-based GNN Training under CPU-GPU  Heterogeneous Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ai%2C+X">Xin Ai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiange Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+C">Chunyu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanfeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chaoyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Hao Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yu Gu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Ge Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Graph Neural Networks (GNNs) have demonstrated outstanding performance in
various applications. Existing frameworks utilize CPU-GPU heterogeneous
environments to train GNN models and integrate mini-batch and sampling
techniques to overcome the GPU memory limitation. In CPU-GPU heterogeneous
environments, we can divide sample-based GNN training into three steps: sample,
gather, and train. Existing GNN systems use different task orchestrating
methods to employ each step on CPU or GPU. After extensive experiments and
analysis, we find that existing task orchestrating methods fail to fully
utilize the heterogeneous resources, limited by inefficient CPU processing or
GPU resource contention. In this paper, we propose NeutronOrch, a system for
sample-based GNN training that incorporates a layer-based task orchestrating
method and ensures balanced utilization of the CPU and GPU. NeutronOrch
decouples the training process by layer and pushes down the training task of
the bottom layer to the CPU. This significantly reduces the computational load
and memory footprint of GPU training. To avoid inefficient CPU processing,
NeutronOrch only offloads the training of frequently accessed vertices to the
CPU and lets GPU reuse their embeddings with bounded staleness. Furthermore,
NeutronOrch provides a fine-grained pipeline design for the layer-based task
orchestrating method, fully overlapping different tasks on heterogeneous
resources while strictly guaranteeing bounded staleness. The experimental
results show that compared with the state-of-the-art GNN systems, NeutronOrch
can achieve up to 4.61x performance speedup.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13226" title="Abstract">arXiv:2311.13226</a> [<a href="/pdf/2311.13226" title="Download PDF">pdf</a>, <a href="/format/2311.13226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robot at the Mirror: Learning to Imitate via Associating Self-supervised  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=L%C3%BA%C4%8Dny%2C+A">Andrej L&#xfa;&#x10d;ny</a>, 
<a href="/search/cs?searchtype=author&query=Malinovsk%C3%A1%2C+K">Krist&#xed;na Malinovsk&#xe1;</a>, 
<a href="/search/cs?searchtype=author&query=Farka%C5%A1%2C+I">Igor Farka&#x161;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICANN 2023 <a href="https://github.com/andylucny/learningImitation">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We introduce an approach to building a custom model from ready-made
self-supervised models via their associating instead of training and
fine-tuning. We demonstrate it with an example of a humanoid robot looking at
the mirror and learning to detect the 3D pose of its own body from the image it
perceives. To build our model, we first obtain features from the visual input
and the postures of the robot's body via models prepared before the robot's
operation. Then, we map their corresponding latent spaces by a sample-efficient
robot's self-exploration at the mirror. In this way, the robot builds the
solicited 3D pose detector, which quality is immediately perfect on the
acquired samples instead of obtaining the quality gradually. The mapping, which
employs associating the pairs of feature vectors, is then implemented in the
same way as the key-value mechanism of the famous transformer models. Finally,
deploying our model for imitation to a simulated robot allows us to study, tune
up, and systematically evaluate its hyperparameters without the involvement of
the human counterpart, advancing our previous research.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13230" title="Abstract">arXiv:2311.13230</a> [<a href="/pdf/2311.13230" title="Download PDF">pdf</a>, <a href="/format/2311.13230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Uncertainty-Based Hallucination Detection with Stronger Focus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianhang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+L">Lin Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qipeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+C">Cheng Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chenghu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinbing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+L">Luoyi Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EMNLP 2023 (main conference)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models (LLMs) have gained significant popularity for their
impressive performance across diverse fields. However, LLMs are prone to
hallucinate untruthful or nonsensical outputs that fail to meet user
expectations in many real-world applications. Existing works for detecting
hallucinations in LLMs either rely on external knowledge for reference
retrieval or require sampling multiple responses from the LLM for consistency
verification, making these methods costly and inefficient. In this paper, we
propose a novel reference-free, uncertainty-based method for detecting
hallucinations in LLMs. Our approach imitates human focus in factuality
checking from three aspects: 1) focus on the most informative and important
keywords in the given text; 2) focus on the unreliable tokens in historical
context which may lead to a cascade of hallucinations; and 3) focus on the
token properties such as token type and token frequency. Experimental results
on relevant datasets demonstrate the effectiveness of our proposed method,
which achieves state-of-the-art performance across all the evaluation metrics
and eliminates the need for additional information.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13231" title="Abstract">arXiv:2311.13231</a> [<a href="/pdf/2311.13231" title="Download PDF">pdf</a>, <a href="/format/2311.13231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Human Feedback to Fine-tune Diffusion Models without Any Reward  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kai Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+J">Jian Tao</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+J">Jiafei Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+C">Chunjiang Ge</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiaxin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qimai Li</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Weihan Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaolong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiu Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Using reinforcement learning with human feedback (RLHF) has shown significant
promise in fine-tuning diffusion models. Previous methods start by training a
reward model that aligns with human preferences, then leverage RL techniques to
fine-tune the underlying models. However, crafting an efficient reward model
demands extensive datasets, optimal architecture, and manual hyperparameter
tuning, making the process both time and cost-intensive. The direct preference
optimization (DPO) method, effective in fine-tuning large language models,
eliminates the necessity for a reward model. However, the extensive GPU memory
requirement of the diffusion model's denoising process hinders the direct
application of the DPO method. To address this issue, we introduce the Direct
Preference for Denoising Diffusion Policy Optimization (D3PO) method to
directly fine-tune diffusion models. The theoretical analysis demonstrates that
although D3PO omits training a reward model, it effectively functions as the
optimal reward model trained using human feedback data to guide the learning
process. This approach requires no training of a reward model, proving to be
more direct, cost-effective, and minimizing computational overhead. In
experiments, our method uses the relative scale of objectives as a proxy for
human preference, delivering comparable results to methods using ground-truth
rewards. Moreover, D3PO demonstrates the ability to reduce image distortion
rates and generate safer images, overcoming challenges lacking robust reward
models.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13233" title="Abstract">arXiv:2311.13233</a> [<a href="/pdf/2311.13233" title="Download PDF">pdf</a>, <a href="/format/2311.13233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Adversarial CAPTCHAs on its History, Classification and  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zisheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Q">Qiao Yan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+F+R">F. Richard Yu</a>, 
<a href="/search/cs?searchtype=author&query=Leung%2C+V+C+M">Victor C. M. Leung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ACM Computing Surveys (Under Review)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Completely Automated Public Turing test to tell Computers and Humans Apart,
short for CAPTCHA, is an essential and relatively easy way to defend against
malicious attacks implemented by bots. The security and usability trade-off
limits the use of massive geometric transformations to interfere deep model
recognition and deep models even outperformed humans in complex CAPTCHAs. The
discovery of adversarial examples provides an ideal solution to the security
and usability trade-off by integrating adversarial examples and CAPTCHAs to
generate adversarial CAPTCHAs that can fool the deep models. In this paper, we
extend the definition of adversarial CAPTCHAs and propose a classification
method for adversarial CAPTCHAs. Then we systematically review some commonly
used methods to generate adversarial examples and methods that are successfully
used to generate adversarial CAPTCHAs. Also, we analyze some defense methods
that can be used to defend adversarial CAPTCHAs, indicating potential threats
to adversarial CAPTCHAs. Finally, we discuss some possible future research
directions for adversarial CAPTCHAs at the end of this paper.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13234" title="Abstract">arXiv:2311.13234</a> [<a href="/pdf/2311.13234" title="Download PDF">pdf</a>, <a href="/format/2311.13234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TSegFormer: 3D Tooth Segmentation in Intraoral Scans with Geometry  Guided Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Huimin Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kunle Li</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+K">Kaiyuan Tan</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J+T">Joey Tianyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+J">Jin Hao</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+H">Haochao Ying</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zuozhu Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MICCAI 2023, STAR(Student Travel) award. 11 pages, 3 figures, 5 tables. arXiv admin note: text overlap with <a href="/abs/2210.16627">arXiv:2210.16627</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Optical Intraoral Scanners (IOS) are widely used in digital dentistry to
provide detailed 3D information of dental crowns and the gingiva. Accurate 3D
tooth segmentation in IOSs is critical for various dental applications, while
previous methods are error-prone at complicated boundaries and exhibit
unsatisfactory results across patients. In this paper, we propose TSegFormer
which captures both local and global dependencies among different teeth and the
gingiva in the IOS point clouds with a multi-task 3D transformer architecture.
Moreover, we design a geometry-guided loss based on a novel point curvature to
refine boundaries in an end-to-end manner, avoiding time-consuming
post-processing to reach clinically applicable segmentation. In addition, we
create a dataset with 16,000 IOSs, the largest ever IOS dataset to the best of
our knowledge. The experimental results demonstrate that our TSegFormer
consistently surpasses existing state-of-the-art baselines. The superiority of
TSegFormer is corroborated by extensive analysis, visualizations and real-world
clinical applicability tests. Our code is available at
https://github.com/huiminxiong/TSegFormer.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13240" title="Abstract">arXiv:2311.13240</a> [<a href="/pdf/2311.13240" title="Download PDF">pdf</a>, <a href="/format/2311.13240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Calibration of Large Language Models and Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chiwei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Benfeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Quan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongdong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Z">Zhendong Mao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to be published in findings of EMNLP-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">As large language models attract increasing attention and find widespread
application, concurrent challenges of reliability also arise at the same time.
Confidence calibration, an effective analysis method for gauging the
reliability of deep models, serves as a crucial tool for assessing and
improving their reliability. However, such investigation has been comparatively
underexplored. In this work, we conduct a systematic examination of the
calibration of aligned language models throughout the entire construction
process, including pretraining and alignment training. At each stage, we
investigate how different training settings, such as parameter scales and
training data, affect model calibration. To thoroughly assess model
calibration, we evaluate models on three most concerned aspects: generation,
factuality and understanding. Our work sheds light on whether popular LLMs are
well-calibrated and how the training process influences model calibration.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13242" title="Abstract">arXiv:2311.13242</a> [<a href="/pdf/2311.13242" title="Download PDF">pdf</a>, <a href="/ps/2311.13242" title="Download PostScript">ps</a>, <a href="/format/2311.13242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Cost Dynamics of Serverless Computing: An Empirical Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamza%2C+M">Muhammad Hamza</a>, 
<a href="/search/cs?searchtype=author&query=Akbar%2C+M+A">Muhammad Azeem Akbar</a>, 
<a href="/search/cs?searchtype=author&query=Capilla%2C+R">Rafael Capilla</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The advent of serverless computing has revolutionized the landscape of cloud
computing, offering a new paradigm that enables developers to focus solely on
their applications rather than managing and provisioning the underlying
infrastructure. These applications involve integrating individual functions
into a cohesive workflow for complex tasks. The pay-per-use model and
nontransparent reporting by cloud providers make it difficult to estimate
serverless costs, imped-ing informed business decisions. Existing research
studies on serverless compu-ting focus on performance optimization and state
management, both from empir-ical and technical perspectives. However, the
state-of-the-art shows a lack of em-pirical investigations on the understanding
of the cost dynamics of serverless computing over traditional cloud computing.
Therefore, this study delves into how organizations anticipate the costs of
adopting serverless. It also aims to com-prehend workload suitability and
identify best practices for cost optimization of serverless applications. To
this end, we conducted a qualitative (interviews) study with 15 experts from 8
companies involved in the migration and development of serverless systems. The
findings revealed that, while serverless computing is highly suitable for
unpredictable workloads, it may not be cost-effective for cer-tain high-scale
applications. The study also introduces a taxonomy for comparing the cost of
adopting serverless versus traditional cloud.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13243" title="Abstract">arXiv:2311.13243</a> [<a href="/pdf/2311.13243" title="Download PDF">pdf</a>, <a href="/format/2311.13243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An enriched hybrid high-order method for the Stokes problem with  application to flow around submerged cylinders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yemm%2C+L">Liam Yemm</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 10 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">An enriched hybrid high-order method is designed for the Stokes equations of
fluid flow and is fully applicable to generic curved meshes. Minimal regularity
requirements of the enrichment spaces are given, and an abstract error analysis
of the scheme is provided. The method achieves consistency in the enrichment
space and is proven to converge optimally in energy error. The scheme is
applied to 2D flow around circular cylinders, for which the local behaviour of
the velocity and pressure fields are known. By enriching the local spaces with
these solutions, superior numerical results near the submerged cylinders are
achieved.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13244" title="Abstract">arXiv:2311.13244</a> [<a href="/pdf/2311.13244" title="Download PDF">pdf</a>, <a href="/format/2311.13244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hard Label Black Box Node Injection Attack on Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zihao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guofeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jingchen Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">While graph neural networks have achieved state-of-the-art performances in
many real-world tasks including graph classification and node classification,
recent works have demonstrated they are also extremely vulnerable to
adversarial attacks. Most previous works have focused on attacking node
classification networks under impractical white-box scenarios. In this work, we
will propose a non-targeted Hard Label Black Box Node Injection Attack on Graph
Neural Networks, which to the best of our knowledge, is the first of its kind.
Under this setting, more real world tasks can be studied because our attack
assumes no prior knowledge about (1): the model architecture of the GNN we are
attacking; (2): the model's gradients; (3): the output logits of the target GNN
model. Our attack is based on an existing edge perturbation attack, from which
we restrict the optimization process to formulate a node injection attack. In
the work, we will evaluate the performance of the attack using three datasets,
COIL-DEL, IMDB-BINARY, and NCI1.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13245" title="Abstract">arXiv:2311.13245</a> [<a href="/pdf/2311.13245" title="Download PDF">pdf</a>, <a href="/format/2311.13245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A model-free approach to fingertip slip and disturbance detection for  grasp stability inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kitouni%2C+D">Dounia Kitouni</a> (ISIR), 
<a href="/search/cs?searchtype=author&query=Khoramshahi%2C+M">Mahdi Khoramshahi</a> (ISIR), 
<a href="/search/cs?searchtype=author&query=Perdereau%2C+V">Veronique Perdereau</a> (ISIR)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE International Conference on Development and Learning 2023 (ICDL), Nov 2023, Macau, China
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Signal Processing (eess.SP); Machine Learning (stat.ML)

</div>
<p class="mathjax">Robotic capacities in object manipulation are incomparable to those of
humans. Besides years of learning, humans rely heavily on the richness of
information from physical interaction with the environment. In particular,
tactile sensing is crucial in providing such rich feedback. Despite its
potential contributions to robotic manipulation, tactile sensing is less
exploited; mainly due to the complexity of the time series provided by tactile
sensors. In this work, we propose a method for assessing grasp stability using
tactile sensing. More specifically, we propose a methodology to extract
task-relevant features and design efficient classifiers to detect object
slippage with respect to individual fingertips. We compare two classification
models: support vector machine and logistic regression. We use highly sensitive
Uskin tactile sensors mounted on an Allegro hand to test and validate our
method. Our results demonstrate that the proposed method is effective in
slippage detection in an online fashion.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13246" title="Abstract">arXiv:2311.13246</a> [<a href="/pdf/2311.13246" title="Download PDF">pdf</a>, <a href="/format/2311.13246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Instruction Optimization for Open-source LLM Instruction  Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yilun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+S">Shimin Tao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiaofeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Ming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Wenbing Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Junhao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+C">Chang Su</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yutai Hou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Miao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Hongxia Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Li Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yanfei Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Instruction tuning is crucial for enabling Language Learning Models (LLMs) in
responding to human instructions. The quality of instruction pairs used for
tuning greatly affects the performance of LLMs. However, the manual creation of
high-quality instruction datasets is costly, leading to the adoption of
automatic generation of instruction pairs by LLMs as a popular alternative in
the training of open-source LLMs. To ensure the high quality of LLM-generated
instruction datasets, several approaches have been proposed. Nevertheless,
existing methods either compromise dataset integrity by filtering a large
proportion of samples, or are unsuitable for industrial applications. In this
paper, instead of discarding low-quality samples, we propose CoachLM, a novel
approach to enhance the quality of instruction datasets through automatic
revisions on samples in the dataset. CoachLM is trained from the samples
revised by human experts and significantly increases the proportion of
high-quality samples in the dataset from 17.7% to 78.9%. The effectiveness of
CoachLM is further assessed on various real-world instruction test sets. The
results show that CoachLM improves the instruction-following capabilities of
the instruction-tuned LLM by an average of 29.9%, which even surpasses larger
LLMs with nearly twice the number of parameters. Furthermore, CoachLM is
successfully deployed in a data management system for LLMs at Huawei, resulting
in an efficiency improvement of up to 20% in the cleaning of 40k real-world
instruction pairs. We release the training data and code of CoachLM
(https://github.com/lunyiliu/CoachLM).
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13249" title="Abstract">arXiv:2311.13249</a> [<a href="/pdf/2311.13249" title="Download PDF">pdf</a>, <a href="/ps/2311.13249" title="Download PostScript">ps</a>, <a href="/format/2311.13249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Journey to Serverless Migration: An Empirical Analysis of  Intentions, Strategies, and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamza%2C+M">Muhammad Hamza</a>, 
<a href="/search/cs?searchtype=author&query=Akbar%2C+M+A">Muhammad Azeem Akbar</a>, 
<a href="/search/cs?searchtype=author&query=Smolander%2C+K">Kari Smolander</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Serverless is an emerging cloud computing paradigm that facilitates
developers to focus solely on the application logic rather than provisioning
and managing the underlying infrastructure. The inherent characteristics such
as scalability, flexibility, and cost efficiency of serverless computing,
attracted many companies to migrate their legacy applications toward this
paradigm. However, the stateless nature of serverless requires careful
migration planning, consideration of its subsequent implications, and potential
challenges. To this end, this study investigates the intentions, strategies,
and technical and organizational challenges while migrating to a serverless
architecture. We investigated the migration processes of 11 systems across
diverse domains by conducting 15 in-depth interviews with professionals from 11
organizations. we also presented a detailed discussion of each migration case.
Our findings reveal that large enterprises primarily migrate to enhance
scalability and operational efficiency, while smaller organizations intend to
reduce the cost. Furthermore, organizations use a domain-driven design approach
to identify the use case and gradually migrate to serverless using a strangler
pattern. However, migration encounters technical challenges i.e., testing
event-driven architecture, integrating with the legacy system, lack of
standardization, and organizational challenges i.e., mindset change and hiring
skilled serverless developers as a prominent. The findings of this study
provide a comprehensive understanding that can guide future implementations and
advancements in the context of serverless migration.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13250" title="Abstract">arXiv:2311.13250</a> [<a href="/pdf/2311.13250" title="Download PDF">pdf</a>, <a href="/format/2311.13250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Hetero-Client Federated Multi-Task Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yuxiang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Suizhi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuwen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Sirejiding%2C+S">Shalayiding Sirejiding</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yue Ding</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hongtao Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Federated Learning (FL) enables joint training across distributed clients
using their local data privately. Federated Multi-Task Learning (FMTL) builds
on FL to handle multiple tasks, assuming model congruity that identical model
architecture is deployed in each client. To relax this assumption and thus
extend real-world applicability, we introduce a novel problem setting,
Hetero-Client Federated Multi-Task Learning (HC-FMTL), to accommodate diverse
task setups. The main challenge of HC-FMTL is the model incongruity issue that
invalidates conventional aggregation methods. It also escalates the
difficulties in accurate model aggregation to deal with data and task
heterogeneity inherent in FMTL. To address these challenges, we propose the
FedHCA$^2$ framework, which allows for federated training of personalized
models by modeling relationships among heterogeneous clients. Drawing on our
theoretical insights into the difference between multi-task and federated
optimization, we propose the Hyper Conflict-Averse Aggregation scheme to
mitigate conflicts during encoder updates. Additionally, inspired by task
interaction in MTL, the Hyper Cross Attention Aggregation scheme uses
layer-wise cross attention to enhance decoder interactions while alleviating
model incongruity. Moreover, we employ learnable Hyper Aggregation Weights for
each client to customize personalized parameter updates. Extensive experiments
demonstrate the superior performance of FedHCA$^2$ in various HC-FMTL scenarios
compared to representative methods. Our code will be made publicly available.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13254" title="Abstract">arXiv:2311.13254</a> [<a href="/pdf/2311.13254" title="Download PDF">pdf</a>, <a href="/format/2311.13254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DA-STC: Domain Adaptive Video Semantic Segmentation via Spatio-Temporal  Consistency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+G">Gaochang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chunhua Shen</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+T">Tianyou Chai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages,9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Video semantic segmentation is a pivotal aspect of video representation
learning. However, significant domain shifts present a challenge in effectively
learning invariant spatio-temporal features across the labeled source domain
and unlabeled target domain for video semantic segmentation. To solve the
challenge, we propose a novel DA-STC method for domain adaptive video semantic
segmentation, which incorporates a bidirectional multi-level spatio-temporal
fusion module and a category-aware spatio-temporal feature alignment module to
facilitate consistent learning for domain-invariant features. Firstly, we
perform bidirectional spatio-temporal fusion at the image sequence level and
shallow feature level, leading to the construction of two fused intermediate
video domains. This prompts the video semantic segmentation model to
consistently learn spatio-temporal features of shared patch sequences which are
influenced by domain-specific contexts, thereby mitigating the feature gap
between the source and target domain. Secondly, we propose a category-aware
feature alignment module to promote the consistency of spatio-temporal
features, facilitating adaptation to the target domain. Specifically, we
adaptively aggregate the domain-specific deep features of each category along
spatio-temporal dimensions, which are further constrained to achieve
cross-domain intra-class feature alignment and inter-class feature separation.
Extensive experiments demonstrate the effectiveness of our method, which
achieves state-of-the-art mIOUs on multiple challenging benchmarks.
Furthermore, we extend the proposed DA-STC to the image domain, where it also
exhibits superior performance for domain adaptive semantic segmentation. The
source code and models will be made available at
\url{https://github.com/ZHE-SAPI/DA-STC}.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13255" title="Abstract">arXiv:2311.13255</a> [<a href="/pdf/2311.13255" title="Download PDF">pdf</a>, <a href="/format/2311.13255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An $hp$-adaptive strategy based on locally predicted error reductions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bammer%2C+P">Patrick Bammer</a>, 
<a href="/search/math?searchtype=author&query=Schr%C3%B6der%2C+A">Andreas Schr&#xf6;der</a>, 
<a href="/search/math?searchtype=author&query=Wihler%2C+T+P">Thomas P. Wihler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We introduce a new $hp$-adaptive strategy for self-adjoint elliptic boundary
value problems that does not rely on using classical a posteriori error
estimators. Instead, our approach is based on a generally applicable prediction
strategy for the reduction of the energy error that can be expressed in terms
of local modifications of the degrees of freedom in the underlying discrete
approximation space. The computations related to the proposed prediction
strategy involve low-dimensional linear problems that are computationally
inexpensive and highly parallelizable. The mathematical building blocks for
this new concept are first developed on an abstract Hilbert space level, before
they are employed within the specific context of $hp$-type finite element
discretizations. For this particular framework, we discuss an explicit
construction of $p$-enrichments and $hp$-refinements by means of an appropriate
constraint coefficient technique that can be employed in any dimensions. The
applicability and effectiveness of the resulting $hp$-adaptive strategy is
illustrated with some $1$- and $2$-dimensional numerical examples.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13258" title="Abstract">arXiv:2311.13258</a> [<a href="/pdf/2311.13258" title="Download PDF">pdf</a>, <a href="/format/2311.13258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ViStruct: Visual Structural Knowledge Extraction via Curriculum Guided  Code-Vision Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yangyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xingyao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Manling Li</a>, 
<a href="/search/cs?searchtype=author&query=Hoiem%2C+D">Derek Hoiem</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+H">Heng Ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">State-of-the-art vision-language models (VLMs) still have limited performance
in structural knowledge extraction, such as relations between objects. In this
work, we present ViStruct, a training framework to learn VLMs for effective
visual structural knowledge extraction. Two novel designs are incorporated.
First, we propose to leverage the inherent structure of programming language to
depict visual structural information. This approach enables explicit and
consistent representation of visual structural information of multiple
granularities, such as concepts, relations, and events, in a well-organized
structured format. Second, we introduce curriculum-based learning for VLMs to
progressively comprehend visual structures, from fundamental visual concepts to
intricate event structures. Our intuition is that lower-level knowledge may
contribute to complex visual structure understanding. Furthermore, we compile
and release a collection of datasets tailored for visual structural knowledge
extraction. We adopt a weakly-supervised approach to directly generate visual
event structures from captions for ViStruct training, capitalizing on abundant
image-caption pairs from the web. In experiments, we evaluate ViStruct on
visual structure prediction tasks, demonstrating its effectiveness in improving
the understanding of visual structures. The code is public at
\url{https://github.com/Yangyi-Chen/vi-struct}.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13262" title="Abstract">arXiv:2311.13262</a> [<a href="/pdf/2311.13262" title="Download PDF">pdf</a>, <a href="/format/2311.13262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Rise of Creative Machines: Exploring the Impact of Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shaikh%2C+S">Saad Shaikh</a>, 
<a href="/search/cs?searchtype=author&query=bendre%2C+R">Rajat bendre</a>, 
<a href="/search/cs?searchtype=author&query=Mhaske%2C+S">Sakshi Mhaske</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The impact of generative AI on research, product creation, ethical concerns etc is examined in this six-page article. Figures 1, 2, and 3, which are essential to the analysis, are included in the discussion along with opportunities, hazards, and ethical considerations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This study looks at how generative artificial intelligence (AI) can
revolutionize marketing, product development, and research. It discusses the
latest developments in the field, easy-to-use resources, and moral and social
hazards. In addition to addressing mitigating techniques for issues like
prejudice and disinformation, the debate emphasizes the significance of
responsible development through continual stakeholder communication and ethical
principles.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13263" title="Abstract">arXiv:2311.13263</a> [<a href="/pdf/2311.13263" title="Download PDF">pdf</a>, <a href="/format/2311.13263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CMFDFormer: Transformer-based Copy-Move Forgery Detection with Continual  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yaqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+C">Chao Xia</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+S">Song Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+Q">Qingxiao Guan</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+W">Wenqian Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+N">Nenghai Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12pages,6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Copy-move forgery detection aims at detecting duplicated regions in a
suspected forged image, and deep learning based copy-move forgery detection
methods are in the ascendant. These deep learning based methods heavily rely on
synthetic training data, and the performance will degrade when facing new
tasks. In this paper, we propose a Transformer-style copy-move forgery
detection network named as CMFDFormer, and provide a novel PCSD (Pooled Cube
and Strip Distillation) continual learning framework to help CMFDFormer handle
new tasks. CMFDFormer consists of a MiT (Mix Transformer) backbone network and
a PHD (Pluggable Hybrid Decoder) mask prediction network. The MiT backbone
network is a Transformer-style network which is adopted on the basis of
comprehensive analyses with CNN-style and MLP-style backbones. The PHD network
is constructed based on self-correlation computation, hierarchical feature
integration, a multi-scale cycle fully-connected block and a mask
reconstruction block. The PHD network is applicable to feature extractors of
different styles for hierarchical multi-scale information extraction, achieving
comparable performance. Last but not least, we propose a PCSD continual
learning framework to improve the forgery detectability and avoid catastrophic
forgetting when handling new tasks. Our continual learning framework restricts
intermediate features from the PHD network, and takes advantage of both cube
pooling and strip pooling. Extensive experiments on publicly available datasets
demonstrate the good performance of CMFDFormer and the effectiveness of the
PCSD continual learning framework.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13267" title="Abstract">arXiv:2311.13267</a> [<a href="/pdf/2311.13267" title="Download PDF">pdf</a>, <a href="/format/2311.13267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedFN: Feature Normalization for Alleviating Data Heterogeneity Problem  in Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seongyoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+G">Gihun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+J">Jaehoon Oh</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+S">Se-Young Yun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS Workshop: "Federated Learning in the Age of Foundation Models" 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Federated Learning (FL) is a collaborative method for training models while
preserving data privacy in decentralized settings. However, FL encounters
challenges related to data heterogeneity, which can result in performance
degradation. In our study, we observe that as data heterogeneity increases,
feature representation in the FedAVG model deteriorates more significantly
compared to classifier weight. Additionally, we observe that as data
heterogeneity increases, the gap between higher feature norms for observed
classes, obtained from local models, and feature norms of unobserved classes
widens, in contrast to the behavior of classifier weight norms. This widening
gap extends to encompass the feature norm disparities between local and the
global models. To address these issues, we introduce Federated Averaging with
Feature Normalization Update (FedFN), a straightforward learning method. We
demonstrate the superior performance of FedFN through extensive experiments,
even when applied to pretrained ResNet18. Subsequently, we confirm the
applicability of FedFN to foundation models.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13273" title="Abstract">arXiv:2311.13273</a> [<a href="/pdf/2311.13273" title="Download PDF">pdf</a>, <a href="/format/2311.13273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative Experimentation of Accuracy Metrics in Automated Medical  Reporting: The Case of Otitis Consultations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Faber%2C+W">Wouter Faber</a>, 
<a href="/search/cs?searchtype=author&query=Bootsma%2C+R+E">Renske Eline Bootsma</a>, 
<a href="/search/cs?searchtype=author&query=Huibers%2C+T">Tom Huibers</a>, 
<a href="/search/cs?searchtype=author&query=van+Dulmen%2C+S">Sandra van Dulmen</a>, 
<a href="/search/cs?searchtype=author&query=Brinkkemper%2C+S">Sjaak Brinkkemper</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 1 figure, submitted to HEALTHINF 2024, Author contributions: Wouter Faber and Renske Eline Bootsma performed research and wrote paper, Tom Huibers provided needed software and research inspiration, Sandra van Dulmen provided the data and feedback on paper, Sjaak Brinkkemper supervised the project and provided continuous feedback
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Generative Artificial Intelligence (AI) can be used to automatically generate
medical reports based on transcripts of medical consultations. The aim is to
reduce the administrative burden that healthcare professionals face. The
accuracy of the generated reports needs to be established to ensure their
correctness and usefulness. There are several metrics for measuring the
accuracy of AI generated reports, but little work has been done towards the
application of these metrics in medical reporting. A comparative
experimentation of 10 accuracy metrics has been performed on AI generated
medical reports against their corresponding General Practitioner's (GP) medical
reports concerning Otitis consultations. The number of missing, incorrect, and
additional statements of the generated reports have been correlated with the
metric scores. In addition, we introduce and define a Composite Accuracy Score
which produces a single score for comparing the metrics within the field of
automated medical reporting. Findings show that based on the correlation study
and the Composite Accuracy Score, the ROUGE-L and Word Mover's Distance metrics
are the preferred metrics, which is not in line with previous work. These
findings help determine the accuracy of an AI generated medical report, which
aids the development of systems that generate medical reports for GPs to reduce
the administrative burden.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13274" title="Abstract">arXiv:2311.13274</a> [<a href="/pdf/2311.13274" title="Download PDF">pdf</a>, <a href="/format/2311.13274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Summarization Performance through Transformer-Based Prompt  Engineering in Automated Medical Reporting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+Zandvoort%2C+D">Daphne van Zandvoort</a>, 
<a href="/search/cs?searchtype=author&query=Wiersema%2C+L">Laura Wiersema</a>, 
<a href="/search/cs?searchtype=author&query=Huibers%2C+T">Tom Huibers</a>, 
<a href="/search/cs?searchtype=author&query=van+Dulmen%2C+S">Sandra van Dulmen</a>, 
<a href="/search/cs?searchtype=author&query=Brinkkemper%2C+S">Sjaak Brinkkemper</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures, submitted to Healthinf 2024, author roles: research conducted and written by Daphne van Zandvoort and Laura Wiersema, research suggested and used software created by Tom Huibers, data provided and feedback provided by Sandra van Dulmen, supervision and feedback provided by Sjaak Brinkkemper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Customized medical prompts enable Large Language Models (LLM) to effectively
address medical dialogue summarization. The process of medical reporting is
often time-consuming for healthcare professionals. Implementing medical
dialogue summarization techniques presents a viable solution to alleviate this
time constraint by generating automated medical reports. The effectiveness of
LLMs in this process is significantly influenced by the formulation of the
prompt, which plays a crucial role in determining the quality and relevance of
the generated reports. In this research, we used a combination of two distinct
prompting strategies, known as shot prompting and pattern prompting to enhance
the performance of automated medical reporting. The evaluation of the automated
medical reports is carried out using the ROUGE score and a human evaluation
with the help of an expert panel. The two-shot prompting approach in
combination with scope and domain context outperforms other methods and
achieves the highest score when compared to the human reference set by a
general practitioner. However, the automated reports are approximately twice as
long as the human references, due to the addition of both redundant and
relevant statements that are added to the report.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13277" title="Abstract">arXiv:2311.13277</a> [<a href="/pdf/2311.13277" title="Download PDF">pdf</a>, <a href="/format/2311.13277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Matrix Factorization for Interpretable Collaborative  Filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sugahara%2C+K">Kai Sugahara</a>, 
<a href="/search/cs?searchtype=author&query=Okamoto%2C+K">Kazushi Okamoto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Matrix factorization (MF) is a simple collaborative filtering technique that
achieves superior recommendation accuracy by decomposing the user-item rating
matrix into user and item latent matrices. This approach relies on learning
from user-item interactions, which may not effectively capture the underlying
shared dependencies between users or items. Therefore, there is scope to
explicitly capture shared dependencies to further improve recommendation
accuracy and the interpretability of learning results by summarizing user-item
interactions. Based on these insights, we propose "Hierarchical Matrix
Factorization" (HMF), which incorporates clustering concepts to capture the
hierarchy, where leaf nodes and other nodes correspond to users/items and
clusters, respectively. Central to our approach, called hierarchical
embeddings, is the additional decomposition of the user and item latent
matrices (embeddings) into probabilistic connection matrices, which link the
hierarchy, and a root cluster latent matrix. Thus, each node is represented by
the weighted average of the embeddings of its parent clusters. The embeddings
are differentiable, allowing simultaneous learning of interactions and
clustering using a single gradient descent method. Furthermore, the obtained
cluster-specific interactions naturally summarize user-item interactions and
provide interpretability. Experimental results on rating and ranking
predictions demonstrated the competitiveness of HMF over vanilla and
hierarchical MF methods, especially its robustness in sparse interactions.
Additionally, it was confirmed that the clustering integration of HMF has the
potential for faster learning convergence and mitigation of overfitting
compared to MF, and also provides interpretability through a cluster-centered
case study.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13279" title="Abstract">arXiv:2311.13279</a> [<a href="/pdf/2311.13279" title="Download PDF">pdf</a>, <a href="/format/2311.13279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comprehensive Evaluation of GNN Training Systems: A Data Management  Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Hao Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yajiong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanfeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+X">Xin Ai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiange Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chaoyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yu Gu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Ge Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Many Graph Neural Network (GNN) training systems have emerged recently to
support efficient GNN training. Since GNNs embody complex data dependencies
between training samples, the training of GNNs should address distinct
challenges different from DNN training in data management, such as data
partitioning, batch preparation for mini-batch training, and data transferring
between CPUs and GPUs. These factors, which take up a large proportion of
training time, make data management in GNN training more significant. This
paper reviews GNN training from a data management perspective and provides a
comprehensive analysis and evaluation of the representative approaches. We
conduct extensive experiments on various benchmark datasets and show many
interesting and valuable results. We also provide some practical tips learned
from these experiments, which are helpful for designing GNN training systems in
the future.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13281" title="Abstract">arXiv:2311.13281</a> [<a href="/pdf/2311.13281" title="Download PDF">pdf</a>, <a href="/format/2311.13281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intention and Context Elicitation with Large Language Models in the  Legal Aid Intake Process
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goodson%2C+N">Nick Goodson</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+R">Rongfei Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large Language Models (LLMs) and chatbots show significant promise in
streamlining the legal intake process. This advancement can greatly reduce the
workload and costs for legal aid organizations, improving availability while
making legal assistance more accessible to a broader audience. However, a key
challenge with current LLMs is their tendency to overconfidently deliver an
immediate 'best guess' to a client's question based on the output distribution
learned over the training data. This approach often overlooks the client's
actual intentions or the specifics of their legal situation. As a result,
clients may not realize the importance of providing essential additional
context or expressing their underlying intentions, which are crucial for their
legal cases. Traditionally, logic based decision trees have been used to
automate intake for specific access to justice issues, such as immigration and
eviction. But those solutions lack scalability. We demonstrate a
proof-of-concept using LLMs to elicit and infer clients' underlying intentions
and specific legal circumstances through free-form, language-based
interactions. We also propose future research directions to use supervised
fine-tuning or offline reinforcement learning to automatically incorporate
intention and context elicitation in chatbots without explicit prompting.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13285" title="Abstract">arXiv:2311.13285</a> [<a href="/pdf/2311.13285" title="Download PDF">pdf</a>, <a href="/format/2311.13285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving performance of heart rate time series classification by  grouping subjects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beekhuizen%2C+M">Michael Beekhuizen</a> (1), 
<a href="/search/cs?searchtype=author&query=Naseri%2C+A">Arman Naseri</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Tax%2C+D">David Tax</a> (1), 
<a href="/search/cs?searchtype=author&query=van+der+Bilt%2C+I">Ivo van der Bilt</a> (2), 
<a href="/search/cs?searchtype=author&query=Reinders%2C+M">Marcel Reinders</a> (1) ((1) Delft University of Technology, (2) Haga Teaching Hospital)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Unlike the more commonly analyzed ECG or PPG data for activity
classification, heart rate time series data is less detailed, often noisier and
can contain missing data points. Using the BigIdeasLab_STEP dataset, which
includes heart rate time series annotated with specific tasks performed by
individuals, we sought to determine if general classification was achievable.
Our analyses showed that the accuracy is sensitive to the choice of
window/stride size. Moreover, we found variable classification performances
between subjects due to differences in the physical structure of their hearts.
Various techniques were used to minimize this variability. First of all,
normalization proved to be a crucial step and significantly improved the
performance. Secondly, grouping subjects and performing classification inside a
group helped to improve performance and decrease inter-subject variability.
Finally, we show that including handcrafted features as input to a deep
learning (DL) network improves the classification performance further.
Together, these findings indicate that heart rate time series can be utilized
for classification tasks like predicting activity. However, normalization or
grouping techniques need to be chosen carefully to minimize the issue of
subject variability.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13286" title="Abstract">arXiv:2311.13286</a> [<a href="/pdf/2311.13286" title="Download PDF">pdf</a>, <a href="/ps/2311.13286" title="Download PostScript">ps</a>, <a href="/format/2311.13286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithmic Transparency and Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klenk%2C+M">Michael Klenk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">A series of recent papers raises worries about the manipulative potential of
algorithmic transparency. But while the concern is apt and relevant, it is
based on a fraught understanding of manipulation. Therefore, this paper draws
attention to the indifference view of manipulation, which explains better than
the vulnerability view why algorithmic transparency has manipulative potential.
The paper also raises pertinent research questions for future studies of
manipulation in the context of algorithmic transparency.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13290" title="Abstract">arXiv:2311.13290</a> [<a href="/pdf/2311.13290" title="Download PDF">pdf</a>, <a href="/format/2311.13290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Softmax Acceleration with Adaptive Numeric Format for both Training and  Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+T">Tianhua Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S+Q">Sai Qian Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">The attention mechanism is a pivotal element within the Transformer
architecture, making a substantial contribution to its exceptional performance.
Within this attention mechanism, Softmax is an imperative component that
enables the model to assess the degree of correlation between various segments
of the input. Yet, prior research has shown that Softmax operations can
significantly increase processing latency and energy consumption in the
Transformer network due to their internal nonlinear operations and data
dependencies. In this work, we proposed~\textit{Hyft}, a hardware efficient
floating point Softmax accelerator for both training and inference. Hyft aims
to reduce the implementation cost of different nonlinear arithmetic operations
by adaptively converting intermediate results into the most suitable numeric
format for each specific operation, leading to reconfigurable accelerator with
hybrid numeric format. The evaluation results highlight that Hyft achieves a
remarkable $15\times$ reduction in hardware resource utilization and a $20
\times$ reduction in processing latency, all while maintaining a negligible
impact on Transformer accuracy.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13293" title="Abstract">arXiv:2311.13293</a> [<a href="/pdf/2311.13293" title="Download PDF">pdf</a>, <a href="/format/2311.13293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Influence of Neural Networks on Hydropower Plant Management in  Agriculture: Addressing Challenges and Exploring Untapped Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Coelho%2C+C">C. Coelho</a>, 
<a href="/search/cs?searchtype=author&query=Costa%2C+M+F+P">M. Fernanda P. Costa</a>, 
<a href="/search/cs?searchtype=author&query=Ferr%C3%A1s%2C+L+L">L.L. Ferr&#xe1;s</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Hydropower plants are crucial for stable renewable energy and serve as vital
water sources for sustainable agriculture. However, it is essential to assess
the current water management practices associated with hydropower plant
management software. A key concern is the potential conflict between
electricity generation and agricultural water needs. Prioritising water for
electricity generation can reduce irrigation availability in agriculture during
crucial periods like droughts, impacting crop yields and regional food
security. Coordination between electricity and agricultural water allocation is
necessary to ensure optimal and environmentally sound practices. Neural
networks have become valuable tools for hydropower plant management, but their
black-box nature raises concerns about transparency in decision making.
Additionally, current approaches often do not take advantage of their potential
to create a system that effectively balances water allocation.
<br />This work is a call for attention and highlights the potential risks of
deploying neural network-based hydropower plant management software without
proper scrutiny and control. To address these concerns, we propose the adoption
of the Agriculture Conscious Hydropower Plant Management framework, aiming to
maximise electricity production while prioritising stable irrigation for
agriculture. We also advocate reevaluating government-imposed minimum water
guidelines for irrigation to ensure flexibility and effective water allocation.
Additionally, we suggest a set of regulatory measures to promote model
transparency and robustness, certifying software that makes conscious and
intelligent water allocation decisions, ultimately safeguarding agriculture
from undue strain during droughts.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13294" title="Abstract">arXiv:2311.13294</a> [<a href="/pdf/2311.13294" title="Download PDF">pdf</a>, <a href="/format/2311.13294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Inference in Reinforcement Learning Done Right
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tarbouriech%2C+J">Jean Tarbouriech</a>, 
<a href="/search/cs?searchtype=author&query=Lattimore%2C+T">Tor Lattimore</a>, 
<a href="/search/cs?searchtype=author&query=O%27Donoghue%2C+B">Brendan O&#x27;Donoghue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">A popular perspective in Reinforcement learning (RL) casts the problem as
probabilistic inference on a graphical model of the Markov decision process
(MDP). The core object of study is the probability of each state-action pair
being visited under the optimal policy. Previous approaches to approximate this
quantity can be arbitrarily poor, leading to algorithms that do not implement
genuine statistical inference and consequently do not perform well in
challenging problems. In this work, we undertake a rigorous Bayesian treatment
of the posterior probability of state-action optimality and clarify how it
flows through the MDP. We first reveal that this quantity can indeed be used to
generate a policy that explores efficiently, as measured by regret.
Unfortunately, computing it is intractable, so we derive a new variational
Bayesian approximation yielding a tractable convex optimization problem and
establish that the resulting policy also explores efficiently. We call our
approach VAPOR and show that it has strong connections to Thompson sampling,
K-learning, and maximum entropy exploration. We conclude with some experiments
demonstrating the performance advantage of a deep RL version of VAPOR.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13295" title="Abstract">arXiv:2311.13295</a> [<a href="/pdf/2311.13295" title="Download PDF">pdf</a>, <a href="/format/2311.13295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feedback control of plant-soil autotoxicity via pulse-width modulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rino%2C+T">Tancredi Rino</a>, 
<a href="/search/eess?searchtype=author&query=Giannino%2C+F">Francesco Giannino</a>, 
<a href="/search/eess?searchtype=author&query=Fiore%2C+D">Davide Fiore</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ECC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Plant-soil negative feedback (PSNF) is the rise in soil of negative
conditions for plant performance induced by the plants themselves, limiting the
full potential yield and thus representing a loss for the agricultural
industry. It has been recently shown that detrimental effects the PSNF has on
the growth of plant's biomass can be mitigated by periodically intervening on
the plant/soil system, for example by washing the soil. The periodic control
inputs were computed by using an average model of the system and then applied
in open-loop. In this paper we present two feedback control strategies, namely
a PI and a MPC-based controllers, that, by adapting online the duty-cycle of
the periodic control input, guarantee precise regulation of the biomass yield
and at the same time robustness to unavoidable modeling errors and
perturbations acting on the system. The performance of the proposed control
strategies is then validated by means of extensive numerical simulations.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13297" title="Abstract">arXiv:2311.13297</a> [<a href="/pdf/2311.13297" title="Download PDF">pdf</a>, <a href="/format/2311.13297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retargeting Visual Data with Deformation Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elsner%2C+T">Tim Elsner</a>, 
<a href="/search/cs?searchtype=author&query=Berger%2C+J">Julia Berger</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Czech%2C+V">Victor Czech</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Lin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Kobbelt%2C+L">Leif Kobbelt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Seam carving is an image editing method that enable content-aware resizing,
including operations like removing objects. However, the seam-finding strategy
based on dynamic programming or graph-cut limits its applications to broader
visual data formats and degrees of freedom for editing. Our observation is that
describing the editing and retargeting of images more generally by a
displacement field yields a generalisation of content-aware deformations. We
propose to learn a deformation with a neural network that keeps the output
plausible while trying to deform it only in places with low information
content. This technique applies to different kinds of visual data, including
images, 3D scenes given as neural radiance fields, or even polygon meshes.
Experiments conducted on different visual data show that our method achieves
better content-aware retargeting compared to previous methods.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13307" title="Abstract">arXiv:2311.13307</a> [<a href="/pdf/2311.13307" title="Download PDF">pdf</a>, <a href="/format/2311.13307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Radiology Report Generation via Causal Reasoning and  Counterfactual Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xiao Song</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiafan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yun Li</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+W">Wenbin Lei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruxin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages,5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Multimedia (cs.MM)

</div>
<p class="mathjax">Radiology Report Generation (RRG) draws attention as an interaction between
vision and language fields. Previous works inherited the ideology of
vision-to-language generation tasks,aiming to generate paragraphs with high
consistency as reports. However, one unique characteristic of RRG, the
independence between diseases, was neglected, leading to the injection of the
spurious confounder, i.e., the disease co-occurrence. Unfortunately, this
confounder confuses the process of report generation worse because of the
biased RRG data distribution. In this paper, to rethink this issue thoroughly,
we reason about its causes and effects from a novel perspective of statistics
and causality, where the Joint Vision Coupling and the Conditional Sentence
Coherence Coupling are two aspects prone to implicitly decrease the accuracy of
reports. Then, a counterfactual augmentation strategy that contains the
Counterfactual Sample Synthesis and the Counterfactual Report Reconstruction
sub-methods is proposed to break these two aspects of spurious effects.
Experimental results and further analyses on two widely used datasets justify
our reasoning and proposed methods.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13310" title="Abstract">arXiv:2311.13310</a> [<a href="/pdf/2311.13310" title="Download PDF">pdf</a>, <a href="/format/2311.13310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the parallel solution of hydro-mechanical problems with fracture  networks and contact conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Stebel%2C+J">Jan Stebel</a>, 
<a href="/search/math?searchtype=author&query=Kru%C5%BE%C3%ADk%2C+J">Jakub Kru&#x17e;&#xed;k</a>, 
<a href="/search/math?searchtype=author&query=Hor%C3%A1k%2C+D">David Hor&#xe1;k</a>, 
<a href="/search/math?searchtype=author&query=B%C5%99ezina%2C+J">Jan B&#x159;ezina</a>, 
<a href="/search/math?searchtype=author&query=B%C3%A9re%C5%A1%2C+M">Michal B&#xe9;re&#x161;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The paper presents a numerical method for the simulation of flow and
mechanics in fractured rock. The governing equations which couple the effects
in the rock mass and in the fractures are obtained using the discrete
fracture-matrix approach. The fracture flow is driven by the cubic law, and the
non-penetration contact conditions prevent fractures from closing. A stable
finite element discretization is proposed for the displacement-pressure-flux
formulation. The resulting nonlinear algebraic system of equations and
inequalities is decoupled using a robust iterative splitting into the
linearized flow subproblem, and the quadratic programming problem for the
mechanical part. The non-penetration conditions are solved by means of the MPGP
algorithm. The capability of the numerical scheme is demonstrated on a
benchmark problem for borehole excavation with hundreds of fractures in 3D. The
paper's novelty consists in combination of three crucial ingredients: (i)
application of discrete fracture matrix approach, (ii) robust iterative
splitting of resulting nonlinear algebraic system working for real-world 3D
problems and (iii) efficient solution of its mechanical quadratic programming
part with large number of fractures in mutual contact by means of own solvers
with known rate of convergence implemented into in-house PERMON library.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13314" title="Abstract">arXiv:2311.13314</a> [<a href="/pdf/2311.13314" title="Download PDF">pdf</a>, <a href="/format/2311.13314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Large Language Model Hallucinations via Autonomous Knowledge  Graph-based Retrofitting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+X">Xinyan Guan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yanjiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hongyu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yaojie Lu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+B">Ben He</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xianpei Han</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Le Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Incorporating factual knowledge in knowledge graph is regarded as a promising
approach for mitigating the hallucination of large language models (LLMs).
Existing methods usually only use the user's input to query the knowledge
graph, thus failing to address the factual hallucination generated by LLMs
during its reasoning process. To address this problem, this paper proposes
Knowledge Graph-based Retrofitting (KGR), a new framework that incorporates
LLMs with KGs to mitigate factual hallucination during the reasoning process by
retrofitting the initial draft responses of LLMs based on the factual knowledge
stored in KGs. Specifically, KGR leverages LLMs to extract, select, validate,
and retrofit factual statements within the model-generated responses, which
enables an autonomous knowledge verifying and refining procedure without any
additional manual efforts. Experiments show that KGR can significantly improve
the performance of LLMs on factual QA benchmarks especially when involving
complex reasoning processes, which demonstrates the necessity and effectiveness
of KGR in mitigating hallucination and enhancing the reliability of LLMs.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13317" title="Abstract">arXiv:2311.13317</a> [<a href="/pdf/2311.13317" title="Download PDF">pdf</a>, <a href="/format/2311.13317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recognition-Guided Diffusion Model for Scene Text Image Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuxuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Liangcai Gao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zhi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+B">Baole Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Scene Text Image Super-Resolution (STISR) aims to enhance the resolution and
legibility of text within low-resolution (LR) images, consequently elevating
recognition accuracy in Scene Text Recognition (STR). Previous methods
predominantly employ discriminative Convolutional Neural Networks (CNNs)
augmented with diverse forms of text guidance to address this issue.
Nevertheless, they remain deficient when confronted with severely blurred
images, due to their insufficient generation capability when little structural
or semantic information can be extracted from original images. Therefore, we
introduce RGDiffSR, a Recognition-Guided Diffusion model for scene text image
Super-Resolution, which exhibits great generative diversity and fidelity even
in challenging scenarios. Moreover, we propose a Recognition-Guided Denoising
Network, to guide the diffusion model generating LR-consistent results through
succinct semantic guidance. Experiments on the TextZoom dataset demonstrate the
superiority of RGDiffSR over prior state-of-the-art methods in both text
recognition accuracy and image fidelity.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13321" title="Abstract">arXiv:2311.13321</a> [<a href="/pdf/2311.13321" title="Download PDF">pdf</a>, <a href="/format/2311.13321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Supervision for Continual Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marczak%2C+D">Daniel Marczak</a>, 
<a href="/search/cs?searchtype=author&query=Cygert%2C+S">Sebastian Cygert</a>, 
<a href="/search/cs?searchtype=author&query=Trzci%C5%84ski%2C+T">Tomasz Trzci&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Twardowski%2C+B">Bart&#x142;omiej Twardowski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In the field of continual learning, models are designed to learn tasks one
after the other. While most research has centered on supervised continual
learning, recent studies have highlighted the strengths of self-supervised
continual representation learning. The improved transferability of
representations built with self-supervised methods is often associated with the
role played by the multi-layer perceptron projector. In this work, we depart
from this observation and reexamine the role of supervision in continual
representation learning. We reckon that additional information, such as human
annotations, should not deteriorate the quality of representations. Our
findings show that supervised models when enhanced with a multi-layer
perceptron head, can outperform self-supervised models in continual
representation learning.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13325" title="Abstract">arXiv:2311.13325</a> [<a href="/pdf/2311.13325" title="Download PDF">pdf</a>, <a href="/format/2311.13325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AA-DL: AoI-Aware Deep Learning Approach for D2D-Assisted Industrial IoT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farag%2C+H">Hossam Farag</a>, 
<a href="/search/cs?searchtype=author&query=Ragab%2C+M">Mohamed Ragab</a>, 
<a href="/search/cs?searchtype=author&query=Stefanovic%2C+C">Cedomir Stefanovic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In real-time Industrial Internet of Things (IIoT), e.g., monitoring and
control scenarios, the freshness of data is crucial to maintain the system
functionality and stability. In this paper, we propose an AoI-Aware Deep
Learning (AA-DL) approach to minimize the Peak Age of Information (PAoI) in
D2D-assisted IIoT networks. Particularly, we analyzed the success probability
and the average PAoI via stochastic geometry, and formulate an optimization
problem with the objective to find the optimal scheduling policy that minimizes
PAoI. In order to solve the non-convex scheduling problem, we develop a Neural
Network (NN) structure that exploits the Geographic Location Information (GLI)
along with feedback stages to perform unsupervised learning over randomly
deployed networks. Our motivation is based on the observation that in various
transmission contexts, the wireless channel intensity is mainly influenced by
distancedependant path loss, which could be calculated using the GLI of each
link. The performance of the AA-DL method is evaluated via numerical results
that demonstrate the effectiveness of our proposed method to improve the PAoI
performance compared to a recent benchmark while maintains lower complexity
against the conventional iterative optimization method.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13326" title="Abstract">arXiv:2311.13326</a> [<a href="/pdf/2311.13326" title="Download PDF">pdf</a>, <a href="/format/2311.13326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Curriculum Learning and Imitation Learning for Model-free Control on  Financial Time-series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koh%2C+W">Woosung Koh</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+I">Insu Choi</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+Y">Yuntae Jang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+G">Gimin Kang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+W+C">Woo Chang Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Portfolio Management (q-fin.PM)

</div>
<p class="mathjax">Curriculum learning and imitation learning have been leveraged extensively in
the robotics domain. However, minimal research has been done on leveraging
these ideas on control tasks over highly stochastic time-series data. Here, we
theoretically and empirically explore these approaches in a representative
control task over complex time-series data. We implement the fundamental ideas
of curriculum learning via data augmentation, while imitation learning is
implemented via policy distillation from an oracle. Our findings reveal that
curriculum learning should be considered a novel direction in improving
control-task performance over complex time-series. Our ample random-seed
out-sample empirics and ablation studies are highly encouraging for curriculum
learning for time-series control. These findings are especially encouraging as
we tune all overlapping hyperparameters on the baseline -- giving an advantage
to the baseline. On the other hand, we find that imitation learning should be
used with caution.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13329" title="Abstract">arXiv:2311.13329</a> [<a href="/pdf/2311.13329" title="Download PDF">pdf</a>, <a href="/format/2311.13329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Timely and Efficient Information Delivery in Real-Time Industrial IoT  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farag%2C+H">Hossam Farag</a>, 
<a href="/search/cs?searchtype=author&query=Vukobratovic%2C+D">Dejan Vukobratovic</a>, 
<a href="/search/cs?searchtype=author&query=Munari%2C+A">Andrea Munari</a>, 
<a href="/search/cs?searchtype=author&query=Stefanovic%2C+C">Cedomir Stefanovic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Enabling real-time communication in Industrial Internet of Things (IIoT)
networks is crucial to support autonomous, self-organized and re-configurable
industrial automation for Industry 4.0 and the forthcoming Industry 5.0. In
this paper, we consider a SIC-assisted real-time IIoT network, in which sensor
nodes generate reports according to an event-generation probability that is
specific for the monitored phenomena. The reports are delivered over a
block-fading channel to a common Access Point (AP) in slotted ALOHA fashion,
which leverages the imbalances in the received powers among the contending
users and applies successive interference cancellation (SIC) to decode user
packets from the collisions. We provide an extensive analytical treatment of
the setup, deriving the Age of Information (AoI), throughput and deadline
violation probability, when the AP has access to both the perfect as well as
the imperfect channel-state information. We show that adopting SIC improves all
the performance parameters with respect to the standard slotted ALOHA, as well
as to an age-dependent access method. The analytical results agree with the
simulation based ones, demonstrating that investing in the SIC capability at
the receiver enables this simple access method to support timely and efficient
information delivery in IIoT networks.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13331" title="Abstract">arXiv:2311.13331</a> [<a href="/pdf/2311.13331" title="Download PDF">pdf</a>, <a href="/format/2311.13331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated generation of attack trees with optimal shape and labelling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gadyatskaya%2C+O">Olga Gadyatskaya</a>, 
<a href="/search/cs?searchtype=author&query=Mauw%2C+S">Sjouke Mauw</a>, 
<a href="/search/cs?searchtype=author&query=Trujillo-Rasuac%2C+R">Rolando Trujillo-Rasuac</a>, 
<a href="/search/cs?searchtype=author&query=Willemse%2C+T+A+C">Tim A. C.Willemse</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
<p class="mathjax">The problem this article addresses is, given a formal specification of a
system, how to produce an attack tree that correctly and clearly describes the
ways the system can be attacked. Correctness means that the attacks displayed
by the attack tree are indeed attacks in the system; clarity means that the
tree is efficient in communicating the attack scenario. To pursue clarity, we
introduce an attack-tree generation algorithm that minimises the tree size and
the information length of its labels without sacrificing correctness. We
achieve this by establishing a connection between the problem of factorising
algebraic expressions and the problem of minimising the tree size. Notably, our
generation algorithm can handle complex attacks that execute actions in
parallel and sequentially. For completeness, we introduce a system model that
integrates well with our generation approach, and validate the resulting
framework via a running example.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13333" title="Abstract">arXiv:2311.13333</a> [<a href="/pdf/2311.13333" title="Download PDF">pdf</a>, <a href="/format/2311.13333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trace-enabled Timing Model Synthesis for ROS2-based Autonomous  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abaza%2C+H">Hazem Abaza</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+D">Debayan Roy</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+S">Shiqing Fan</a>, 
<a href="/search/cs?searchtype=author&query=Saidi%2C+S">Selma Saidi</a>, 
<a href="/search/cs?searchtype=author&query=Motakis%2C+A">Antonios Motakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Operating Systems (cs.OS)</span>

</div>
<p class="mathjax">Autonomous applications are typically developed over Robot Operating System
2.0 (ROS2) even in time-critical systems like automotive. Recent years have
seen increased interest in developing model-based timing analysis and schedule
optimization approaches for ROS2-based applications. To complement these
approaches, we propose a tracing and measurement framework to \emph{obtain
timing models} of ROS2-based applications. It offers a tracer based on
\emph{extended Berkeley Packet Filter} that probes different functions in ROS2
middleware and reads their arguments or return values to reason about the data
flow in applications. It combines event traces from ROS2 and the operating
system to generate a \emph{directed acyclic graph} showing ROS2 callbacks,
precedence relations between them, and their timing attributes. While being
compatible with existing analyses, we also show how to model (i)~message
synchronization, e.g., in sensor fusion, and (ii)~service requests from
multiple clients, e.g., in motion planning. Considering that, in real-world
scenarios, the application code might be \emph{confidential} and formal models
are unavailable, our framework still enables the application of existing
analysis and optimization techniques.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13334" title="Abstract">arXiv:2311.13334</a> [<a href="/pdf/2311.13334" title="Download PDF">pdf</a>, <a href="/format/2311.13334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Analysis of Socialbots Activity and Influence in Modern Japanese  Social Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ippa%2C+S">Shuhei Ippa</a>, 
<a href="/search/cs?searchtype=author&query=Hashimoto%2C+M">Masaki Hashimoto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">In recent years, the proliferation of disinformation has become an issue
against the backdrop of the spread of social media. In this study, we focus on
socialbots, one of the causes of this problem, and analyze several domestic
cases to clarify the actual activities and influence of socialbots. As a result
of this analysis, we found that the influence of socialbots is greater in Japan
than in the U.S. presidential election of 2016, which is a representative case
of socialbot influence, and that socialbots retweeted by humans are not
significantly different from human accounts. In addition, socialbot accounts
retweeted by humans are not significantly different from human accounts. This
paper also discusses specific methods and perspectives for further analysis and
research on the influence of socialbots.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13335" title="Abstract">arXiv:2311.13335</a> [<a href="/pdf/2311.13335" title="Download PDF">pdf</a>, <a href="/format/2311.13335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum learning and essential cognition under the traction of  meta-characteristics in an open world
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+C">Changlin Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages,5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Artificial intelligence has made significant progress in the Close World
problem, being able to accurately recognize old knowledge through training and
classification. However, AI faces significant challenges in the Open World
problem, as it involves a new and unknown exploration journey. AI is not
inherently proactive in exploration, and its challenge lies in not knowing how
to approach and adapt to the unknown world. How do humans acquire knowledge of
the unknown world. Humans identify new knowledge through intrinsic cognition.
In the process of recognizing new colors, the cognitive cues are different from
known color features and involve hue, saturation, brightness, and other
characteristics. When AI encounters objects with different features in the new
world, it faces another challenge: where are the distinguishing features
between influential features of new and old objects? AI often mistakes a new
world's brown bear for a known dog because it has not learned the differences
in feature distributions between knowledge systems. This is because things in
the new and old worlds have different units and dimensions for their features.
This paper proposes an open-world model and elemental feature system that
focuses on fundamentally recognizing the distribution differences in objective
features between the new and old worlds. The quantum tunneling effect of
learning ability in the new and old worlds is realized through the tractive
force of meta-characteristic. The outstanding performance of the model system
in learning new knowledge (using pedestrian re-identification datasets as an
example) demonstrates that AI has acquired the ability to recognize the new
world with an accuracy of $96.71\%$ at most and has gained the capability to
explore new knowledge, similar to humans.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13336" title="Abstract">arXiv:2311.13336</a> [<a href="/pdf/2311.13336" title="Download PDF">pdf</a>, <a href="/format/2311.13336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Analysis of AoI-Reliability Tradeoff in Heterogeneous IIoT  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farag%2C+H">Hossam Farag</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+S+M">Syed Muhammad Ali</a>, 
<a href="/search/cs?searchtype=author&query=Stefanovic%2C+C">Cedomir Stefanovic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Age of information (AoI) and reliability are two critical metrics to support
real-time applications in Industrial Internet of Things (IIoT). These metrics
reflect different concepts of timely delivery of sensor information. Monitoring
traffic serves to maintain fresh status updates, expressed in a low AoI, which
is important for proper control and actuation actions. On the other hand,
safety-critical information, e.g., emergency alarms, is generated sporadically
and must be delivered with high reliability within a predefined deadline. In
this work, we investigate the AoI-reliability trade-off in a real-time
monitoring scenario that supports two traffic flows, namely AoI-oriented
traffic and deadline-oriented traffic. Both traffic flows are transmitted to a
central controller over an unreliable shared channel. We derive expressions of
the average AoI for the AoI-oriented traffic and reliability, represented by
Packet Loss Probability (PLP), for the deadline-oriented traffic using
Discrete-Time Markov Chain (DTMC). We also conduct discrete-event simulations
in MATLAB to validate the analytical results and evaluate the interaction
between the two types of traffic flows. The results clearly demonstrate the
tradeoff between the AoI and PLP in such heterogeneous IIoT networks and give
insights on how to configure the network to achieve a target pair of AoI and
PLP.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13338" title="Abstract">arXiv:2311.13338</a> [<a href="/pdf/2311.13338" title="Download PDF">pdf</a>, <a href="/format/2311.13338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Quality Face Caricature via Style Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Laishram%2C+L">Lamyanba Laishram</a>, 
<a href="/search/cs?searchtype=author&query=Shaheryar%2C+M">Muhammad Shaheryar</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+T">Jong Taek Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+S+K">Soon Ki Jung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 21 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Caricature is an exaggerated form of artistic portraiture that accentuates
unique yet subtle characteristics of human faces. Recently, advancements in
deep end-to-end techniques have yielded encouraging outcomes in capturing both
style and elevated exaggerations in creating face caricatures. Most of these
approaches tend to produce cartoon-like results that could be more practical
for real-world applications. In this study, we proposed a high-quality,
unpaired face caricature method that is appropriate for use in the real world
and uses computer vision techniques and GAN models. We attain the exaggeration
of facial features and the stylization of appearance through a two-step
process: Face caricature generation and face caricature projection. The face
caricature generation step creates new caricature face datasets from real
images and trains a generative model using the real and newly created
caricature datasets. The Face caricature projection employs an encoder trained
with real and caricature faces with the pretrained generator to project real
and caricature faces. We perform an incremental facial exaggeration from the
real image to the caricature faces using the encoder and generator's latent
space. Our projection preserves the facial identity, attributes, and
expressions from the input image. Also, it accounts for facial occlusions, such
as reading glasses or sunglasses, to enhance the robustness of our model.
Furthermore, we conducted a comprehensive comparison of our approach with
various state-of-the-art face caricature methods, highlighting our process's
distinctiveness and exceptional realism.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13341" title="Abstract">arXiv:2311.13341</a> [<a href="/pdf/2311.13341" title="Download PDF">pdf</a>, <a href="/format/2311.13341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning principle and mathematical realization of the learning  mechanism in the brain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Katayose%2C+T">Taisuke Katayose</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT); Neurons and Cognition (q-bio.NC); Machine Learning (stat.ML)

</div>
<p class="mathjax">While deep learning has achieved remarkable success, there is no clear
explanation about why it works so well. In order to discuss this question
quantitatively, we need a mathematical framework that explains what learning is
in the first place. After several considerations, we succeeded in constructing
a mathematical framework that can provide a unified understanding of all types
of learning, including deep learning and learning in the brain. We call it
learning principle, and it follows that all learning is equivalent to
estimating the probability of input data. We not only derived this principle,
but also mentioned its application to actual machine learning models. For
example, we found that conventional supervised learning is equivalent to
estimating conditional probabilities, and succeeded in making supervised
learning more effective and generalized. We also proposed a new method of
defining the values of estimated probability using differentiation, and showed
that unsupervised learning can be performed on arbitrary dataset without any
prior knowledge. Namely, this method is a general-purpose machine learning in
the true sense. Moreover, we succeeded in describing the learning mechanism in
the brain by considering the time evolution of a fully or partially connected
model and applying this new method. The learning principle provides solutions
to many unsolved problems in deep learning and cognitive neuroscience.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13344" title="Abstract">arXiv:2311.13344</a> [<a href="/pdf/2311.13344" title="Download PDF">pdf</a>, <a href="/ps/2311.13344" title="Download PostScript">ps</a>, <a href="/format/2311.13344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A highly efficient finite volume method with a diffusion control  parameter for hyperbolic problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Aboussi%2C+W">Wassim Aboussi</a>, 
<a href="/search/math?searchtype=author&query=Ziggaf%2C+M">Moussa Ziggaf</a>, 
<a href="/search/math?searchtype=author&query=Kissami%2C+I">Imad Kissami</a>, 
<a href="/search/math?searchtype=author&query=Boubekeur%2C+M">Mohamed Boubekeur</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Mathematics and Computers in Simulation 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This article proposes a highly accurate and conservative method for
hyperbolic systems using the finite volume approach. This innovative scheme
constructs the intermediate states at the interfaces of the control volumes
using the method of characteristics. The approach is simple to implement,
generates entropic solutions, and avoids solving Riemann problems. A diffusion
control parameter is introduced to increase the accuracy of the scheme.
Numerical examples are presented for the Euler equation for an ideal gas. The
results demonstrate the method's ability to capture contact discontinuity and
shock wave profiles with high accuracy and low cost as well as its robustness.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13348" title="Abstract">arXiv:2311.13348</a> [<a href="/pdf/2311.13348" title="Download PDF">pdf</a>, <a href="/format/2311.13348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MergeSFL: Split Federated Learning with Feature Merging and Batch Size  Regulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Yunming Liao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hongli Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Z">Zhiwei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+C">Chunming Qiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Recently, federated learning (FL) has emerged as a popular technique for edge
AI to mine valuable knowledge in edge computing (EC) systems. To mitigate the
computing/communication burden on resource-constrained workers and protect
model privacy, split federated learning (SFL) has been released by integrating
both data and model parallelism. Despite resource limitations, SFL still faces
two other critical challenges in EC, i.e., statistical heterogeneity and system
heterogeneity. To address these challenges, we propose a novel SFL framework,
termed MergeSFL, by incorporating feature merging and batch size regulation in
SFL. Concretely, feature merging aims to merge the features from workers into a
mixed feature sequence, which is approximately equivalent to the features
derived from IID data and is employed to promote model accuracy. While batch
size regulation aims to assign diverse and suitable batch sizes for
heterogeneous workers to improve training efficiency. Moreover, MergeSFL
explores to jointly optimize these two strategies upon their coupled
relationship to better enhance the performance of SFL. Extensive experiments
are conducted on a physical platform with 80 NVIDIA Jetson edge devices, and
the experimental results show that MergeSFL can improve the final model
accuracy by 5.82% to 26.22%, with a speedup by about 1.74x to 4.14x, compared
to the baselines.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13349" title="Abstract">arXiv:2311.13349</a> [<a href="/pdf/2311.13349" title="Download PDF">pdf</a>, <a href="/format/2311.13349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> REDS: Resource-Efficient Deep Subnetworks for Dynamic Resource  Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Corti%2C+F">Francesco Corti</a>, 
<a href="/search/cs?searchtype=author&query=Maag%2C+B">Balz Maag</a>, 
<a href="/search/cs?searchtype=author&query=Schauer%2C+J">Joachim Schauer</a>, 
<a href="/search/cs?searchtype=author&query=Pferschy%2C+U">Ulrich Pferschy</a>, 
<a href="/search/cs?searchtype=author&query=Saukh%2C+O">Olga Saukh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Deep models deployed on edge devices frequently encounter resource
variability, which arises from fluctuating energy levels, timing constraints,
or prioritization of other critical tasks within the system. State-of-the-art
machine learning pipelines generate resource-agnostic models, not capable to
adapt at runtime. In this work we introduce Resource-Efficient Deep Subnetworks
(REDS) to tackle model adaptation to variable resources. In contrast to the
state-of-the-art, REDS use structured sparsity constructively by exploiting
permutation invariance of neurons, which allows for hardware-specific
optimizations. Specifically, REDS achieve computational efficiency by (1)
skipping sequential computational blocks identified by a novel iterative
knapsack optimizer, and (2) leveraging simple math to re-arrange the order of
operations in REDS computational graph to take advantage of the data cache.
REDS support conventional deep networks frequently deployed on the edge and
provide computational benefits even for small and simple networks. We evaluate
REDS on six benchmark architectures trained on the Google Speech Commands,
FMNIST and CIFAR10 datasets, and test on four off-the-shelf mobile and embedded
hardware platforms. We provide a theoretical result and empirical evidence for
REDS outstanding performance in terms of submodels' test set accuracy, and
demonstrate an adaptation time in response to dynamic resource constraints of
under 40$\mu$s, utilizing a 2-layer fully-connected network on Arduino Nano 33
BLE Sense.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13350" title="Abstract">arXiv:2311.13350</a> [<a href="/pdf/2311.13350" title="Download PDF">pdf</a>, <a href="/ps/2311.13350" title="Download PostScript">ps</a>, <a href="/format/2311.13350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fact-based Court Judgment Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nigam%2C+S+K">Shubham Kumar Nigam</a>, 
<a href="/search/cs?searchtype=author&query=Deroy%2C+A">Aniket Deroy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">This extended abstract extends the research presented in "ILDC for CJPE:
Indian Legal Documents Corpus for Court Judgment Prediction and Explanation"
\cite{malik-etal-2021-ildc}, focusing on fact-based judgment prediction within
the context of Indian legal documents. We introduce two distinct problem
variations: one based solely on facts, and another combining facts with rulings
from lower courts (RLC). Our research aims to enhance early-phase case outcome
prediction, offering significant benefits to legal professionals and the
general public. The results, however, indicated a performance decline compared
to the original ILDC for CJPE study, even after implementing various weightage
schemes in our DELSumm algorithm. Additionally, using only facts for legal
judgment prediction with different transformer models yielded results inferior
to the state-of-the-art outcomes reported in the "ILDC for CJPE" study.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13351" title="Abstract">arXiv:2311.13351</a> [<a href="/pdf/2311.13351" title="Download PDF">pdf</a>, <a href="/format/2311.13351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradual Verification for Smart Contracts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Haojia Sun</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+K">Kunal Singh</a>, 
<a href="/search/cs?searchtype=author&query=Ramos-D%C3%A1vila%2C+J">Jan-Paul Ramos-D&#xe1;vila</a>, 
<a href="/search/cs?searchtype=author&query=Aldrich%2C+J">Jonathan Aldrich</a>, 
<a href="/search/cs?searchtype=author&query=DiVincenzo%2C+J">Jenna DiVincenzo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Logic in Computer Science (cs.LO); Programming Languages (cs.PL)

</div>
<p class="mathjax">Blockchains facilitate secure resource transactions through smart contracts,
yet these digital agreements are prone to vulnerabilities, particularly when
interacting with external contracts, leading to substantial monetary losses.
Traditional verification techniques fall short in providing comprehensive
security assurances, especially against re-entrancy attacks, due to the
unavailable implementations of external contracts. This paper introduces an
incremental approach: gradual verification. We combine static and dynamic
verification techniques to enhance security, guarantee soundness and
flexibility, and optimize resource usage in smart contract interactions. By
implementing a prototype for gradually verifying Algorand smart contracts via
the pyTEAL language, we demonstrate the effectiveness of our approach,
contributing to the safe and efficient execution of smart contracts.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13355" title="Abstract">arXiv:2311.13355</a> [<a href="/pdf/2311.13355" title="Download PDF">pdf</a>, <a href="/format/2311.13355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unified Classification and Rejection: A One-versus-All Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhen Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xu-Yao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cheng-Lin Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Classifying patterns of known classes and rejecting ambiguous and novel (also
called as out-of-distribution (OOD)) inputs are involved in open world pattern
recognition. Deep neural network models usually excel in closed-set
classification while performing poorly in rejecting OOD. To tackle this
problem, numerous methods have been designed to perform open set recognition
(OSR) or OOD rejection/detection tasks. Previous methods mostly take
post-training score transformation or hybrid models to ensure low scores on OOD
inputs while separating known classes. In this paper, we attempt to build a
unified framework for building open set classifiers for both classification and
OOD rejection. We formulate the open set recognition of $ K $-known-class as a
$ (K + 1) $-class classification problem with model trained on known-class
samples only. By decomposing the $ K $-class problem into $ K $ one-versus-all
(OVA) binary classification tasks and binding some parameters, we show that
combining the scores of OVA classifiers can give $ (K + 1) $-class posterior
probabilities, which enables classification and OOD rejection in a unified
framework. To maintain the closed-set classification accuracy of the OVA
trained classifier, we propose a hybrid training strategy combining OVA loss
and multi-class cross-entropy loss. We implement the OVA framework and hybrid
training strategy on the recently proposed convolutional prototype network.
Experiments on popular OSR and OOD detection datasets demonstrate that the
proposed framework, using a single multi-class classifier, yields competitive
performance in closed-set classification, OOD detection, and misclassification
detection.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13356" title="Abstract">arXiv:2311.13356</a> [<a href="/pdf/2311.13356" title="Download PDF">pdf</a>, <a href="/format/2311.13356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty Estimation in Multi-Agent Distributed Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Radchenko%2C+G">Gleb Radchenko</a>, 
<a href="/search/cs?searchtype=author&query=Fill%2C+V+A">Victoria Andrea Fill</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Poster for SAL Symposium on 6G. 22 November 2023 - 23 November 2023 Linz, Austria
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Traditionally, IoT edge devices have been perceived primarily as low-power
components with limited capabilities for autonomous operations. Yet, with
emerging advancements in embedded AI hardware design, a foundational shift
paves the way for future possibilities. Thus, the aim of the KDT NEUROKIT2E
project is to establish a new open-source framework to further facilitate AI
applications on edge devices by developing new methods in quantization,
pruning-aware training, and sparsification. These innovations hold the
potential to expand the functional range of such devices considerably, enabling
them to manage complex Machine Learning (ML) tasks utilizing local resources
and laying the groundwork for innovative learning approaches.
<br />In the context of 6G's transformative potential, distributed learning among
independent agents emerges as a pivotal application, attributed to 6G networks'
support for ultra-reliable low-latency communication, enhanced data rates, and
advanced edge computing capabilities.
<br />Our research focuses on the mechanisms and methodologies that allow edge
network-enabled agents to engage in collaborative learning in distributed
environments. Particularly, one of the key issues within distributed
collaborative learning is determining the degree of confidence in the learning
results, considering the spatio-temporal locality of data sets perceived by
independent agents.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13361" title="Abstract">arXiv:2311.13361</a> [<a href="/pdf/2311.13361" title="Download PDF">pdf</a>, <a href="/format/2311.13361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applying Large Language Models to Power Systems: Potential Security  Threats
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruan%2C+J">Jiaqi Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+G">Gaoqi Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Huan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guolong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+J">Jing Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Junhua Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+F">Fushuan Wen</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z+Y">Zhao Yang Dong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC); Systems and Control (eess.SY)

</div>
<p class="mathjax">Applying large language models (LLMs) to power systems presents a promising
avenue for enhancing decision-making and operational efficiency. However, this
action may also incur potential security threats, which have not been fully
recognized so far. To this end, this letter analyzes potential threats incurred
by applying LLMs to power systems, emphasizing the need for urgent research and
development of countermeasures.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13371" title="Abstract">arXiv:2311.13371</a> [<a href="/pdf/2311.13371" title="Download PDF">pdf</a>, <a href="/format/2311.13371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Dynamic Event-triggered Mechanism for Dynamic Average Consensus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xu%2C+T">Tao Xu</a>, 
<a href="/search/eess?searchtype=author&query=Duan%2C+Z">Zhisheng Duan</a>, 
<a href="/search/eess?searchtype=author&query=Wen%2C+G">Guanghui Wen</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+Z">Zhiyong Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper studies a challenging issue introduced in a recent survey, namely
designing a distributed event-based scheme to solve the dynamic average
consensus (DAC) problem. First, a robust adaptive distributed event-based DAC
algorithm is designed without imposing specific initialization criteria to
perform estimation task under intermittent communication. Second, a novel
adaptive distributed dynamic event-triggered mechanism is proposed to determine
the triggering time when neighboring agents broadcast information to each
other. Compared to the existing event-triggered mechanisms, the novelty of the
proposed dynamic event-triggered mechanism lies in that it guarantees the
existence of a positive and uniform minimum inter-event interval without
sacrificing any accuracy of the estimation, which is much more practical than
only ensuring the exclusion of the Zeno behavior or the boundedness of the
estimation error. Third, a composite adaptive law is developed to update the
adaptive gain employed in the distributed event-based DAC algorithm and dynamic
event-triggered mechanism. Using the composite adaptive update law, the
distributed event-based solution proposed in our work is implemented without
requiring any global information. Finally, numerical simulations are provided
to illustrate the effectiveness of the theoretical results.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13372" title="Abstract">arXiv:2311.13372</a> [<a href="/pdf/2311.13372" title="Download PDF">pdf</a>, <a href="/ps/2311.13372" title="Download PostScript">ps</a>, <a href="/format/2311.13372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MRGazer: Decoding Eye Gaze Points from Functional Magnetic Resonance  Imaging in Individual Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiuwen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+R">Rongjie Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jie Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+B">Bensheng Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoxiao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Eye-tracking research has proven valuable in understanding numerous cognitive
functions. Recently, Frey et al. provided an exciting deep learning method for
learning eye movements from fMRI data. However, it needed to co-register fMRI
into standard space to obtain eyeballs masks, and thus required additional
templates and was time consuming. To resolve this issue, in this paper, we
propose a framework named MRGazer for predicting eye gaze points from fMRI in
individual space. The MRGazer consisted of eyeballs extraction module and a
residual network-based eye gaze prediction. Compared to the previous method,
the proposed framework skips the fMRI co-registration step, simplifies the
processing protocol and achieves end-to-end eye gaze regression. The proposed
method achieved superior performance in a variety of eye movement tasks than
the co-registration-based method, and delivered objective results within a
shorter time (~ 0.02 Seconds for each volume) than prior method (~0.3 Seconds
for each volume).
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13373" title="Abstract">arXiv:2311.13373</a> [<a href="/pdf/2311.13373" title="Download PDF">pdf</a>, <a href="/format/2311.13373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Model is a Good Policy Teacher for Training Reinforcement  Learning Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zihao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Bin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chenyang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bin Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Recent studies have shown that Large Language Models (LLMs) can be utilized
for solving complex sequential decision-making tasks by providing high-level
instructions. However, LLM-based agents face limitations in real-time dynamic
environments due to their lack of specialization in solving specific target
problems. Moreover, the deployment of such LLM-based agents is both costly and
time-consuming in practical scenarios. In this paper, we introduce a novel
framework that addresses these challenges by training a smaller scale
specialized student agent using instructions from an LLM-based teacher agent.
By leveraging guided actions provided by the teachers, the prior knowledge of
the LLM is distilled into the local student model. Consequently, the student
agent can be trained with significantly less data. Furthermore, subsequent
training with environment feedback empowers the student agents to surpass the
capabilities of their teachers. We conducted experiments on three challenging
MiniGrid environments to evaluate the effectiveness of our framework. The
results demonstrate that our approach enhances sample efficiency and achieves
superior performance compared to baseline methods.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13374" title="Abstract">arXiv:2311.13374</a> [<a href="/pdf/2311.13374" title="Download PDF">pdf</a>, <a href="/format/2311.13374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Study of Uncertainty Estimation Techniques for Detecting  Drift in Data Streams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Winter%2C+A">Anton Winter</a>, 
<a href="/search/cs?searchtype=author&query=Jourdan%2C+N">Nicolas Jourdan</a>, 
<a href="/search/cs?searchtype=author&query=Wirth%2C+T">Tristan Wirth</a>, 
<a href="/search/cs?searchtype=author&query=Knauthe%2C+V">Volker Knauthe</a>, 
<a href="/search/cs?searchtype=author&query=Kuijper%2C+A">Arjan Kuijper</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023: Workshop on Distribution Shifts
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In safety-critical domains such as autonomous driving and medical diagnosis,
the reliability of machine learning models is crucial. One significant
challenge to reliability is concept drift, which can cause model deterioration
over time. Traditionally, drift detectors rely on true labels, which are often
scarce and costly. This study conducts a comprehensive empirical evaluation of
using uncertainty values as substitutes for error rates in detecting drifts,
aiming to alleviate the reliance on labeled post-deployment data. We examine
five uncertainty estimation methods in conjunction with the ADWIN detector
across seven real-world datasets. Our results reveal that while the SWAG method
exhibits superior calibration, the overall accuracy in detecting drifts is not
notably impacted by the choice of uncertainty estimation method, with even the
most basic method demonstrating competitive performance. These findings offer
valuable insights into the practical applicability of uncertainty-based drift
detection in real-world, safety-critical applications.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13379" title="Abstract">arXiv:2311.13379</a> [<a href="/pdf/2311.13379" title="Download PDF">pdf</a>, <a href="/format/2311.13379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deriving Comprehensible Theories from Probabilistic Circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bocklandt%2C+S">Sieben Bocklandt</a>, 
<a href="/search/cs?searchtype=author&query=Meert%2C+W">Wannes Meert</a>, 
<a href="/search/cs?searchtype=author&query=Vanderstraeten%2C+K">Koen Vanderstraeten</a>, 
<a href="/search/cs?searchtype=author&query=Pijpops%2C+W">Wouter Pijpops</a>, 
<a href="/search/cs?searchtype=author&query=Jaspers%2C+K">Kurt Jaspers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages; 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The field of Explainable AI (XAI) is seeking to shed light on the inner
workings of complex AI models and uncover the rationale behind their decisions.
One of the models gaining attention are probabilistic circuits (PCs), which are
a general and unified framework for tractable probabilistic models that support
efficient computation of various probabilistic queries. Probabilistic circuits
guarantee inference that is polynomial in the size of the circuit. In this
paper, we improve the explainability of probabilistic circuits by computing a
comprehensible, readable logical theory that covers the high-density regions
generated by a PC. To achieve this, pruning approaches based on generative
significance are used in a new method called PUTPUT (Probabilistic circuit
Understanding Through Pruning Underlying logical Theories). The method is
applied to a real world use case where music playlists are automatically
generated and expressed as readable (database) queries. Evaluation shows that
this approach can effectively produce a comprehensible logical theory that
describes the high-density regions of a PC and outperforms state of the art
methods when exploring the performance-comprehensibility trade-off.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13380" title="Abstract">arXiv:2311.13380</a> [<a href="/pdf/2311.13380" title="Download PDF">pdf</a>, <a href="/format/2311.13380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing the Evolution and Maintenance of ML Models on Hugging Face
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Casta%C3%B1o%2C+J">Joel Casta&#xf1;o</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADnez-Fern%C3%A1ndez%2C+S">Silverio Mart&#xed;nez-Fern&#xe1;ndez</a>, 
<a href="/search/cs?searchtype=author&query=Franch%2C+X">Xavier Franch</a>, 
<a href="/search/cs?searchtype=author&query=Bogner%2C+J">Justus Bogner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Hugging Face (HF) has established itself as a crucial platform for the
development and sharing of machine learning (ML) models. This repository mining
study, which delves into more than 380,000 models using data gathered via the
HF Hub API, aims to explore the community engagement, evolution, and
maintenance around models hosted on HF, aspects that have yet to be
comprehensively explored in the literature. We first examine the overall growth
and popularity of HF, uncovering trends in ML domains, framework usage, authors
grouping and the evolution of tags and datasets used. Through text analysis of
model card descriptions, we also seek to identify prevalent themes and insights
within the developer community. Our investigation further extends to the
maintenance aspects of models, where we evaluate the maintenance status of ML
models, classify commit messages into various categories (corrective,
perfective, and adaptive), analyze the evolution across development stages of
commits metrics and introduce a new classification system that estimates the
maintenance status of models based on multiple attributes. This study aims to
provide valuable insights about ML model maintenance and evolution that could
inform future model development, maintenance, and community engagement
strategies on community-driven platforms like HF.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13381" title="Abstract">arXiv:2311.13381</a> [<a href="/pdf/2311.13381" title="Download PDF">pdf</a>, <a href="/format/2311.13381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Confidant: Customizing Transformer-based LLMs via Collaborative Edge  Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yuxuan Yan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qianqian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+Y">Yuanchao Shu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+S">Shibo He</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiming Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 7 figures; Submitted to HotMobile 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Transformer-based large language models (LLMs) have demonstrated impressive
capabilities in a variety of natural language processing (NLP) tasks.
Nonetheless, it is challenging to deploy and fine-tune LLMs on mobile edge
devices with limited computing, memory, and energy budgets. In this paper, we
propose Confidant, a multi-backend collaborative training framework for
customizing state-of-the-art LLMs on commodity mobile devices like smartphones.
Confidant partitions an LLM into several sub-models so that each fits into a
mobile device's memory. A pipeline parallel training mechanism is further
developed to ensure fast and efficient distributed training. In addition, we
propose a novel backend scheduler to allocate different attention heads to
heterogeneous compute hardware, including mobile CPU and GPUs, to maximize the
compute resource utilization on each edge device. Our preliminary experimental
results show that Confidant achieves at most 45.3% memory reduction and 8.03x
inference speedup in practical settings.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13383" title="Abstract">arXiv:2311.13383</a> [<a href="/pdf/2311.13383" title="Download PDF">pdf</a>, <a href="/format/2311.13383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Spatial Dataset Search over Multiple Data Sources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenzhe Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhiyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Z">Zhiyong Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">In this paper, we investigate a novel spatial dataset search paradigm over
multiple spatial data sources, which enables users to conduct join and union
searches seamlessly. Specifically, we define two search problems called Maximum
Intersection Query (MIQ) and Maximum Coverage Query with a Connection
constraint (MCQC). To address these problems, we propose a unified Multi-source
Spatial Dataset Search (MSDS) framework. In MSDS, we design a multi-layer index
to accelerate the MIQ and MCQC. In addition, we prove that the MCQC is NP-hard
and design two greedy algorithms to solve the problem. To deal with the
constant update of spatial datasets in each data source, we design a dynamic
index updating strategy and optimize search algorithms to reduce communication
costs and improve search efficiency. We evaluate the efficiency of MSDS on five
real-world data sources, and the experimental results show that our framework
is able to achieve a significant reduction in running time and communication
cost.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13384" title="Abstract">arXiv:2311.13384</a> [<a href="/pdf/2311.13384" title="Download PDF">pdf</a>, <a href="/format/2311.13384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LucidDreamer: Domain-free Generation of 3D Gaussian Splatting Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chung%2C+J">Jaeyoung Chung</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Suyoung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Nam%2C+H">Hyeongjin Nam</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaerin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K+M">Kyoung Mu Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the widespread usage of VR devices and contents, demands for 3D scene
generation techniques become more popular. Existing 3D scene generation models,
however, limit the target scene to specific domain, primarily due to their
training strategies using 3D scan dataset that is far from the real-world. To
address such limitation, we propose LucidDreamer, a domain-free scene
generation pipeline by fully leveraging the power of existing large-scale
diffusion-based generative model. Our LucidDreamer has two alternate steps:
Dreaming and Alignment. First, to generate multi-view consistent images from
inputs, we set the point cloud as a geometrical guideline for each image
generation. Specifically, we project a portion of point cloud to the desired
view and provide the projection as a guidance for inpainting using the
generative model. The inpainted images are lifted to 3D space with estimated
depth maps, composing a new points. Second, to aggregate the new points into
the 3D scene, we propose an aligning algorithm which harmoniously integrates
the portions of newly generated 3D scenes. The finally obtained 3D scene serves
as initial points for optimizing Gaussian splats. LucidDreamer produces
Gaussian splats that are highly-detailed compared to the previous 3D scene
generation methods, with no constraint on domain of the target scene.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13385" title="Abstract">arXiv:2311.13385</a> [<a href="/pdf/2311.13385" title="Download PDF">pdf</a>, <a href="/format/2311.13385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SegVol: Universal and Interactive Volumetric Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yuxin Du</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+F">Fan Bai</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tiejun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bo Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Precise image segmentation provides clinical study with meaningful and
well-structured information. Despite the remarkable progress achieved in
medical image segmentation, there is still an absence of foundation
segmentation model that can segment a wide range of anatomical categories with
easy user interaction. In this paper, we propose a universal and interactive
volumetric medical image segmentation model, named SegVol. By training on 90k
unlabeled Computed Tomography (CT) volumes and 6k labeled CTs, this foundation
model supports the segmentation of over 200 anatomical categories using
semantic and spatial prompts. Extensive experiments verify that SegVol
outperforms the state of the art by a large margin on multiple segmentation
benchmarks. Notably, on three challenging lesion datasets, our method achieves
around 20% higher Dice score than nnU-Net. The model and data are publicly
available at: https://github.com/BAAI-DCAI/SegVol.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13386" title="Abstract">arXiv:2311.13386</a> [<a href="/pdf/2311.13386" title="Download PDF">pdf</a>, <a href="/format/2311.13386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical Approximation of Optimal Convex Shapes in $\mathbb{R}^3$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bartels%2C+S">S&#xf6;ren Bartels</a> (1), 
<a href="/search/math?searchtype=author&query=Keller%2C+H">Hedwig Keller</a> (1), 
<a href="/search/math?searchtype=author&query=Wachsmuth%2C+G">Gerd Wachsmuth</a> (2) ((1) University Freiburg, (2) BTU Cottbus)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">In the optimization of convex domains under a PDE constraint numerical
difficulties arise in the approximation of convex domains in $\mathbb{R}^3$.
Previous research used a restriction to rotationally symmetric domains to
reduce shape optimization problems to a two-dimensional setting. In the current
research, two approaches for the approximation in $\mathbb{R}^3$ are
considered. First, a notion of discrete convexity allows for a nearly convex
approximation with polyhedral domains. An alternative approach is based on the
recent observation that higher order finite elements can approximate convex
functions conformally. As a second approach these results are used to
approximate optimal convex domains with isoparametric convex domains. The
proposed algorithms were tested on shape optimization problems constrained by a
Poisson equation and both algorithms achieved similar results.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13387" title="Abstract">arXiv:2311.13387</a> [<a href="/pdf/2311.13387" title="Download PDF">pdf</a>, <a href="/format/2311.13387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SystemC Model of Power Side-Channel Attacks Against AI Accelerators:  Superstition or not?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ne%C5%A1kovi%C4%87%2C+A">Andrija Ne&#x161;kovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Mulhem%2C+S">Saleh Mulhem</a>, 
<a href="/search/cs?searchtype=author&query=Treff%2C+A">Alexander Treff</a>, 
<a href="/search/cs?searchtype=author&query=Buchty%2C+R">Rainer Buchty</a>, 
<a href="/search/cs?searchtype=author&query=Eisenbarth%2C+T">Thomas Eisenbarth</a>, 
<a href="/search/cs?searchtype=author&query=Berekovic%2C+M">Mladen Berekovic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">As training artificial intelligence (AI) models is a lengthy and hence costly
process, leakage of such a model's internal parameters is highly undesirable.
In the case of AI accelerators, side-channel information leakage opens up the
threat scenario of extracting the internal secrets of pre-trained models.
Therefore, sufficiently elaborate methods for design verification as well as
fault and security evaluation at the electronic system level are in demand. In
this paper, we propose estimating information leakage from the early design
steps of AI accelerators to aid in a more robust architectural design. We first
introduce the threat scenario before diving into SystemC as a standard method
for early design evaluation and how this can be applied to threat modeling. We
present two successful side-channel attack methods executed via SystemC-based
power modeling: correlation power analysis and template attack, both leading to
total information leakage. The presented models are verified against an
industry-standard netlist-level power estimation to prove general feasibility
and determine accuracy. Consequently, we explore the impact of additive noise
in our simulation to establish indicators for early threat evaluation. The
presented approach is again validated via a model-vs-netlist comparison,
showing high accuracy of the achieved results. This work hence is a solid step
towards fast attack deployment and, subsequently, the design of
attack-resilient AI accelerators.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13389" title="Abstract">arXiv:2311.13389</a> [<a href="/pdf/2311.13389" title="Download PDF">pdf</a>, <a href="/format/2311.13389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conflict Management in the Near-RT-RIC of Open RAN: A Game Theoretic  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wadud%2C+A">Abdul Wadud</a>, 
<a href="/search/cs?searchtype=author&query=Golpayegani%2C+F">Fatemeh Golpayegani</a>, 
<a href="/search/cs?searchtype=author&query=Afraz%2C+N">Nima Afraz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Open Radio Access Network (RAN) was introduced recently to incorporate
intelligence and openness into the upcoming generation of RAN. Open RAN offers
standardized interfaces and the capacity to accommodate network applications
from external vendors through extensible applications (xApps), which enhance
network management flexibility. The Near-Real-Time Radio Intelligent Controller
(Near-RT-RIC) employs specialized and intelligent xApps for achieving
time-critical optimization objectives, but conflicts may arise due to different
vendors' xApps modifying the same parameters or indirectly affecting each
others' performance. A standardized Conflict Management System (CMS) is absent
in most of the popular Open RAN architectures including the most prominent
O-RAN Alliance architecture. To address this, we propose a CMS with independent
controllers for conflict detection and mitigation between xApps in the
Near-RT-RIC. We utilize cooperative bargain game theory, including Nash Social
Welfare Function (NSWF) and the Equal Gains (EG) solution, to find optimal
configurations for conflicting parameters. Experimental results demonstrate the
effectiveness of the proposed Conflict Management Controller (CMC) in balancing
conflicting parameters and mitigating adverse impacts in the Near-RT-RIC on a
theoretical example scenario.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13391" title="Abstract">arXiv:2311.13391</a> [<a href="/pdf/2311.13391" title="Download PDF">pdf</a>, <a href="/ps/2311.13391" title="Download PostScript">ps</a>, <a href="/format/2311.13391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simultaneous uniqueness and numerical inversion for an inverse problem  in the time-domain diffuse optical tomography with fluorescence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+Z">Zhiyuan Li</a>, 
<a href="/search/math?searchtype=author&query=Sun%2C+C">Chunlong Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph)

</div>
<p class="mathjax">In this work, an inverse problem on the determination of multiple
coefficients arising from the time-domain diffuse optical tomography with
fluorescence (DOT-FDOT) is investigated. We simultaneously recover the
distribution of background absorption coefficient, photon diffusion coefficient
as well as the fluorescence absorption in biological tissue by the
time-dependent boundary measurements. We build the uniqueness theorem of this
multiple coefficients simultaneous inverse problem. After that, the numerical
inversions are considered. We introduce an accelerated Landweber iterative
algorithm and give several numerical examples illustrating the performance of
the proposed inversion schemes.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13398" title="Abstract">arXiv:2311.13398</a> [<a href="/pdf/2311.13398" title="Download PDF">pdf</a>, <a href="/format/2311.13398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Depth-Regularized Optimization for 3D Gaussian Splatting in Few-Shot  Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chung%2C+J">Jaeyoung Chung</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+J">Jeongtaek Oh</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K+M">Kyoung Mu Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">In this paper, we present a method to optimize Gaussian splatting with a
limited number of images while avoiding overfitting. Representing a 3D scene by
combining numerous Gaussian splats has yielded outstanding visual quality.
However, it tends to overfit the training views when only a small number of
images are available. To address this issue, we introduce a dense depth map as
a geometry guide to mitigate overfitting. We obtained the depth map using a
pre-trained monocular depth estimation model and aligning the scale and offset
using sparse COLMAP feature points. The adjusted depth aids in the color-based
optimization of 3D Gaussian splatting, mitigating floating artifacts, and
ensuring adherence to geometric constraints. We verify the proposed method on
the NeRF-LLFF dataset with varying numbers of few images. Our approach
demonstrates robust geometry compared to the original method that relies solely
on images.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13404" title="Abstract">arXiv:2311.13404</a> [<a href="/pdf/2311.13404" title="Download PDF">pdf</a>, <a href="/format/2311.13404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Animatable 3D Gaussians for High-fidelity Synthesis of Human Motions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+K">Keyang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+T">Tianjia Shao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kun Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We present a novel animatable 3D Gaussian model for rendering high-fidelity
free-view human motions in real time. Compared to existing NeRF-based methods,
the model owns better capability in synthesizing high-frequency details without
the jittering problem across video frames. The core of our model is a novel
augmented 3D Gaussian representation, which attaches each Gaussian with a
learnable code. The learnable code serves as a pose-dependent appearance
embedding for refining the erroneous appearance caused by geometric
transformation of Gaussians, based on which an appearance refinement model is
learned to produce residual Gaussian properties to match the appearance in
target pose. To force the Gaussians to learn the foreground human only without
background interference, we further design a novel alpha loss to explicitly
constrain the Gaussians within the human body. We also propose to jointly
optimize the human joint parameters to improve the appearance accuracy. The
animatable 3D Gaussian model can be learned with shallow MLPs, so new human
motions can be synthesized in real time (66 fps on avarage). Experiments show
that our model has superior performance over NeRF-based methods.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13409" title="Abstract">arXiv:2311.13409</a> [<a href="/pdf/2311.13409" title="Download PDF">pdf</a>, <a href="/format/2311.13409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CompenHR: Efficient Full Compensation for High-resolution Projector
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+H">Haibin Ling</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Bingyao Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Full projector compensation is a practical task of projector-camera systems.
It aims to find a projector input image, named compensation image, such that
when projected it cancels the geometric and photometric distortions due to the
physical environment and hardware. State-of-the-art methods use deep learning
to address this problem and show promising performance for low-resolution
setups. However, directly applying deep learning to high-resolution setups is
impractical due to the long training time and high memory cost. To address this
issue, this paper proposes a practical full compensation solution. Firstly, we
design an attention-based grid refinement network to improve geometric
correction quality. Secondly, we integrate a novel sampling scheme into an
end-to-end compensation network to alleviate computation and introduce
attention blocks to preserve key features. Finally, we construct a benchmark
dataset for high-resolution projector full compensation. In experiments, our
method demonstrates clear advantages in both efficiency and quality.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13411" title="Abstract">arXiv:2311.13411</a> [<a href="/pdf/2311.13411" title="Download PDF">pdf</a>, <a href="/format/2311.13411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian inference of a new Mallows model for characterising symptom  sequences applied in primary progressive aphasia
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taylor%2C+B">Beatrice Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Shand%2C+C">Cameron Shand</a>, 
<a href="/search/cs?searchtype=author&query=Hardy%2C+C+J+D">Chris J. D. Hardy</a>, 
<a href="/search/cs?searchtype=author&query=Oxtoby%2C+N">Neil Oxtoby</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2023, December 10th, 2023, New Orleans, United States, 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Machine learning models offer the potential to understand diverse datasets in
a data-driven way, powering insights into individual disease experiences and
ensuring equitable healthcare. In this study, we explore Bayesian inference for
characterising symptom sequences, and the associated modelling challenges. We
adapted the Mallows model to account for partial rankings and right-censored
data, employing custom MCMC fitting. Our evaluation, encompassing synthetic
data and a primary progressive aphasia dataset, highlights the model's efficacy
in revealing mean orderings and estimating ranking variance. This holds the
potential to enhance clinical comprehension of symptom occurrence. However, our
work encounters limitations concerning model scalability and small dataset
sizes.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13413" title="Abstract">arXiv:2311.13413</a> [<a href="/pdf/2311.13413" title="Download PDF">pdf</a>, <a href="/format/2311.13413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Machine Learning based Test Case Prioritization for  Continuous Integration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yifan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+D">Dan Hao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by ICSME 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">To alleviate the cost of regression testing in continuous integration (CI), a
large number of machine learning-based (ML-based) test case prioritization
techniques have been proposed. However, it is yet unknown how they perform
under the same experimental setup, because they are evaluated on different
datasets with different metrics. To bridge this gap, we conduct the first
comprehensive study on these ML-based techniques in this paper. We investigate
the performance of 11 representative ML-based prioritization techniques for CI
on 11 open-source subjects and obtain a series of findings. For example, the
performance of the techniques changes across CI cycles, mainly resulting from
the changing amount of training data, instead of code evolution and test
removal/addition. Based on the findings, we give some actionable suggestions on
enhancing the effectiveness of ML-based techniques, e.g., pretraining a
prioritization technique with cross-subject data to get it thoroughly trained
and then finetuning it with within-subject data dramatically improves its
performance. In particular, the pretrained MART achieves state-of-the-art
performance, producing the optimal sequence on 80% subjects, while the existing
best technique, the original MART, only produces the optimal sequence on 50%
subjects.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13414" title="Abstract">arXiv:2311.13414</a> [<a href="/pdf/2311.13414" title="Download PDF">pdf</a>, <a href="/format/2311.13414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Images to Connections: Can DQN with GNNs learn the Strategic Game  of Hex?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Keller%2C+Y">Yannik Keller</a>, 
<a href="/search/cs?searchtype=author&query=Bl%C3%BCml%2C+J">Jannis Bl&#xfc;ml</a>, 
<a href="/search/cs?searchtype=author&query=Sudhakaran%2C+G">Gopika Sudhakaran</a>, 
<a href="/search/cs?searchtype=author&query=Kersting%2C+K">Kristian Kersting</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">The gameplay of strategic board games such as chess, Go and Hex is often
characterized by combinatorial, relational structures -- capturing distinct
interactions and non-local patterns -- and not just images. Nonetheless, most
common self-play reinforcement learning (RL) approaches simply approximate
policy and value functions using convolutional neural networks (CNN). A key
feature of CNNs is their relational inductive bias towards locality and
translational invariance. In contrast, graph neural networks (GNN) can encode
more complicated and distinct relational structures. Hence, we investigate the
crucial question: Can GNNs, with their ability to encode complex connections,
replace CNNs in self-play reinforcement learning? To this end, we do a
comparison with Hex -- an abstract yet strategically rich board game -- serving
as our experimental platform. Our findings reveal that GNNs excel at dealing
with long range dependency situations in game states and are less prone to
overfitting, but also showing a reduced proficiency in discerning local
patterns. This suggests a potential paradigm shift, signaling the use of
game-specific structures to reshape self-play reinforcement learning.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13416" title="Abstract">arXiv:2311.13416</a> [<a href="/pdf/2311.13416" title="Download PDF">pdf</a>, <a href="/ps/2311.13416" title="Download PostScript">ps</a>, <a href="/format/2311.13416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comprehensive Survey: Biometric User Authentication Application,  Evaluation, and Discussion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alrawili%2C+R">Reem Alrawili</a>, 
<a href="/search/cs?searchtype=author&query=AlQahtani%2C+A+A+S">Ali Abdullah S. AlQahtani</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+M+K">Muhammad Khurram Khan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">This paper conducts an extensive review of biometric user authentication
literature, addressing three primary research questions: (1) commonly used
biometric traits and their suitability for specific applications, (2)
performance factors such as security, convenience, and robustness, and
potential countermeasures against cyberattacks, and (3) factors affecting
biometric system accuracy and po-tential improvements. Our analysis delves into
physiological and behavioral traits, exploring their pros and cons. We discuss
factors influencing biometric system effectiveness and highlight areas for
enhancement. Our study differs from previous surveys by extensively examining
biometric traits, exploring various application domains, and analyzing measures
to mitigate cyberattacks. This paper aims to inform researchers and
practitioners about the biometric authentication landscape and guide future
advancements.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13422" title="Abstract">arXiv:2311.13422</a> [<a href="/pdf/2311.13422" title="Download PDF">pdf</a>, <a href="/ps/2311.13422" title="Download PostScript">ps</a>, <a href="/format/2311.13422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparative Analysis Between SciTokens, Verifiable Credentials, and  Smart Contracts: Novel Approaches for Authentication and Secure Access to  Scientific Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Faruk%2C+M+J+H">Md Jobair Hossain Faruk</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+B">Bilash Saha</a>, 
<a href="/search/cs?searchtype=author&query=Basney%2C+J">Jim Basney</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM Practice &amp; Experience in Advanced Research Computing (PEARC) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Managing and exchanging sensitive information securely is a paramount concern
for the scientific and cybersecurity community. The increasing reliance on
computing workflows and digital data transactions requires ensuring that
sensitive information is protected from unauthorized access, tampering, or
misuse. This research paper presents a comparative analysis of three novel
approaches for authenticating and securing access to scientific data:
SciTokens, Verifiable Credentials, and Smart Contracts. The aim of this study
is to investigate the strengths and weaknesses of each approach from trust,
revocation, privacy, and security perspectives. We examine the technical
features and privacy and security mechanisms of each technology and provide a
comparative synthesis with the proposed model. Through our analysis, we
demonstrate that each technology offers unique advantages and limitations, and
the integration of these technologies can lead to more secure and efficient
solutions for authentication and access to scientific data.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13435" title="Abstract">arXiv:2311.13435</a> [<a href="/pdf/2311.13435" title="Download PDF">pdf</a>, <a href="/format/2311.13435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PG-Video-LLaVA: Pixel Grounding Large Video-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Munasinghe%2C+S">Shehan Munasinghe</a>, 
<a href="/search/cs?searchtype=author&query=Thushara%2C+R">Rusiru Thushara</a>, 
<a href="/search/cs?searchtype=author&query=Maaz%2C+M">Muhammad Maaz</a>, 
<a href="/search/cs?searchtype=author&query=Rasheed%2C+H+A">Hanoona Abdul Rasheed</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S">Salman Khan</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+M">Mubarak Shah</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+F">Fahad Khan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Extending image-based Large Multimodal Models (LMM) to videos is challenging
due to the inherent complexity of video data. The recent approaches extending
image-based LMM to videos either lack the grounding capabilities (e.g.,
VideoChat, Video-ChatGPT, Video-LLaMA) or do not utilize the audio-signals for
better video understanding (e.g., Video-ChatGPT). Addressing these gaps, we
propose Video-LLaVA, the first LMM with pixel-level grounding capability,
integrating audio cues by transcribing them into text to enrich video-context
understanding. Our framework uses an off-the-shelf tracker and a novel
grounding module, enabling it to spatially and temporally localize objects in
videos following user instructions. We evaluate Video-LLaVA using video-based
generative and question-answering benchmarks and introduce new benchmarks
specifically designed to measure prompt-based object grounding performance in
videos. Further, we propose the use of Vicuna over GPT-3.5, as utilized in
Video-ChatGPT, for video-based conversation benchmarking, ensuring
reproducibility of results which is a concern with the proprietary nature of
GPT-3.5. Our framework builds on SoTA image-based LLaVA model and extends its
advantages to the video domain, delivering promising gains on video-based
conversation and grounding tasks. Project Page:
https://github.com/mbzuai-oryx/Video-LLaVA
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13442" title="Abstract">arXiv:2311.13442</a> [<a href="/pdf/2311.13442" title="Download PDF">pdf</a>, <a href="/format/2311.13442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal Network Analysis of Email Communication Patterns in a Long  Standing Hierarchy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barnes%2C+M+R">Matthew Russell Barnes</a>, 
<a href="/search/cs?searchtype=author&query=Karan%2C+M">Mladen Karan</a>, 
<a href="/search/cs?searchtype=author&query=McQuistin%2C+S">Stephen McQuistin</a>, 
<a href="/search/cs?searchtype=author&query=Perkins%2C+C">Colin Perkins</a>, 
<a href="/search/cs?searchtype=author&query=Tyson%2C+G">Gareth Tyson</a>, 
<a href="/search/cs?searchtype=author&query=Purver%2C+M">Matthew Purver</a>, 
<a href="/search/cs?searchtype=author&query=Castro%2C+I">Ignacio Castro</a>, 
<a href="/search/cs?searchtype=author&query=Clegg%2C+R+G">Richard G. Clegg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">An important concept in organisational behaviour is how hierarchy affects the
voice of individuals, whereby members of a given organisation exhibit differing
power relations based on their hierarchical position. Although there have been
prior studies of the relationship between hierarchy and voice, they tend to
focus on more qualitative small-scale methods and do not account for structural
aspects of the organisation. This paper develops large-scale computational
techniques utilising temporal network analysis to measure the effect that
organisational hierarchy has on communication patterns within an organisation,
focusing on the structure of pairwise interactions between individuals. We
focus on one major organisation as a case study - the Internet Engineering Task
Force (IETF) - a major technical standards development organisation for the
Internet. A particularly useful feature of the IETF is a transparent hierarchy,
where participants take on explicit roles (e.g. Area Directors, Working Group
Chairs). Its processes are also open, so we have visibility into the
communication of people at different hierarchy levels over a long time period.
We utilise a temporal network dataset of 989,911 email interactions among
23,741 participants to study how hierarchy impacts communication patterns. We
show that the middle levels of the IETF are growing in terms of their dominance
in communications. Higher levels consistently experience a higher proportion of
incoming communication than lower levels, with higher levels initiating more
communications too. We find that communication tends to flow "up" the hierarchy
more than "down". Finally, we find that communication with higher-levels is
associated with future communication more than for lower-levels, which we
interpret as "facilitation". We conclude by discussing the implications this
has on patterns within the wider IETF and for other organisations.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13443" title="Abstract">arXiv:2311.13443</a> [<a href="/pdf/2311.13443" title="Download PDF">pdf</a>, <a href="/format/2311.13443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guided Flows for Generative Modeling and Decision Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Q">Qinqing Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+M">Matt Le</a>, 
<a href="/search/cs?searchtype=author&query=Shaul%2C+N">Neta Shaul</a>, 
<a href="/search/cs?searchtype=author&query=Lipman%2C+Y">Yaron Lipman</a>, 
<a href="/search/cs?searchtype=author&query=Grover%2C+A">Aditya Grover</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R+T+Q">Ricky T. Q. Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO); Machine Learning (stat.ML)

</div>
<p class="mathjax">Classifier-free guidance is a key component for improving the performance of
conditional generative models for many downstream tasks. It drastically
improves the quality of samples produced, but has so far only been used for
diffusion models. Flow Matching (FM), an alternative simulation-free approach,
trains Continuous Normalizing Flows (CNFs) based on regressing vector fields.
It remains an open question whether classifier-free guidance can be performed
for Flow Matching models, and to what extent does it improve performance. In
this paper, we explore the usage of Guided Flows for a variety of downstream
applications involving conditional image generation, speech synthesis, and
reinforcement learning. In particular, we are the first to apply flow models to
the offline reinforcement learning setting. We also show that Guided Flows
significantly improves the sample quality in image generation and zero-shot
text-to-speech synthesis, and can make use of drastically low amounts of
computation without affecting the agent's overall performance.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13444" title="Abstract">arXiv:2311.13444</a> [<a href="/pdf/2311.13444" title="Download PDF">pdf</a>, <a href="/format/2311.13444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SkeletonGait: Gait Recognition Using Skeleton Maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Chao Fan</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jingzhe Ma</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+D">Dongyang Jin</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chuanfu Shen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shiqi Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The choice of the representations is essential for deep gait recognition
methods. The binary silhouettes and skeletal coordinates are two dominant
representations in recent literature, achieving remarkable advances in many
scenarios. However, inherent challenges remain, in which silhouettes are not
always guaranteed in unconstrained scenes, and structural cues have not been
fully utilized from skeletons. In this paper, we introduce a novel skeletal
gait representation named Skeleton Map, together with SkeletonGait, a
skeleton-based method to exploit structural information from human skeleton
maps. Specifically, the skeleton map represents the coordinates of human joints
as a heatmap with Gaussian approximation, exhibiting a silhouette-like image
devoid of exact body structure. Beyond achieving state-of-the-art performances
over five popular gait datasets, more importantly, SkeletonGait uncovers novel
insights about how important structural features are in describing gait and
when do they play a role. Furthermore, we propose a multi-branch architecture,
named SkeletonGait++, to make use of complementary features from both skeletons
and silhouettes. Experiments indicate that SkeletonGait++ outperforms existing
state-of-the-art methods by a significant margin in various scenarios. For
instance, it achieves an impressive rank-1 accuracy of over $85\%$ on the
challenging GREW dataset. All the source code will be available at
https://github.com/ShiqiYu/OpenGait.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13445" title="Abstract">arXiv:2311.13445</a> [<a href="/pdf/2311.13445" title="Download PDF">pdf</a>, <a href="/format/2311.13445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transfer Attacks and Defenses for Large Language Models on Coding Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mangal%2C+R">Ravi Mangal</a>, 
<a href="/search/cs?searchtype=author&query=Fredrikson%2C+M">Matt Fredrikson</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+L">Limin Jia</a>, 
<a href="/search/cs?searchtype=author&query=Pasareanu%2C+C">Corina Pasareanu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Modern large language models (LLMs), such as ChatGPT, have demonstrated
impressive capabilities for coding tasks including writing and reasoning about
code. They improve upon previous neural network models of code, such as
code2seq or seq2seq, that already demonstrated competitive results when
performing tasks such as code summarization and identifying code
vulnerabilities. However, these previous code models were shown vulnerable to
adversarial examples, i.e. small syntactic perturbations that do not change the
program's semantics, such as the inclusion of "dead code" through false
conditions or the addition of inconsequential print statements, designed to
"fool" the models. LLMs can also be vulnerable to the same adversarial
perturbations but a detailed study on this concern has been lacking so far. In
this paper we aim to investigate the effect of adversarial perturbations on
coding tasks with LLMs. In particular, we study the transferability of
adversarial examples, generated through white-box attacks on smaller code
models, to LLMs. Furthermore, to make the LLMs more robust against such
adversaries without incurring the cost of retraining, we propose prompt-based
defenses that involve modifying the prompt to include additional information
such as examples of adversarially perturbed code and explicit instructions for
reversing adversarial perturbations. Our experiments show that adversarial
examples obtained with a smaller code model are indeed transferable, weakening
the LLMs' performance. The proposed defenses show promise in improving the
model's resilience, paving the way to more robust defensive solutions for LLMs
in code-related applications.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13447" title="Abstract">arXiv:2311.13447</a> [<a href="/pdf/2311.13447" title="Download PDF">pdf</a>, <a href="/ps/2311.13447" title="Download PostScript">ps</a>, <a href="/format/2311.13447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially Private Non-Convex Optimization under the KL Condition  with Optimal Rates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Menart%2C+M">Michael Menart</a>, 
<a href="/search/cs?searchtype=author&query=Ullah%2C+E">Enayat Ullah</a>, 
<a href="/search/cs?searchtype=author&query=Arora%2C+R">Raman Arora</a>, 
<a href="/search/cs?searchtype=author&query=Bassily%2C+R">Raef Bassily</a>, 
<a href="/search/cs?searchtype=author&query=Guzm%C3%A1n%2C+C">Crist&#xf3;bal Guzm&#xe1;n</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">We study private empirical risk minimization (ERM) problem for losses
satisfying the $(\gamma,\kappa)$-Kurdyka-{\L}ojasiewicz (KL) condition. The
Polyak-{\L}ojasiewicz (PL) condition is a special case of this condition when
$\kappa=2$. Specifically, we study this problem under the constraint of $\rho$
zero-concentrated differential privacy (zCDP). When $\kappa\in[1,2]$ and the
loss function is Lipschitz and smooth over a sufficiently large region, we
provide a new algorithm based on variance reduced gradient descent that
achieves the rate
$\tilde{O}\big(\big(\frac{\sqrt{d}}{n\sqrt{\rho}}\big)^\kappa\big)$ on the
excess empirical risk, where $n$ is the dataset size and $d$ is the dimension.
We further show that this rate is nearly optimal. When $\kappa \geq 2$ and the
loss is instead Lipschitz and weakly convex, we show it is possible to achieve
the rate $\tilde{O}\big(\big(\frac{\sqrt{d}}{n\sqrt{\rho}}\big)^\kappa\big)$
with a private implementation of the proximal point method. When the KL
parameters are unknown, we provide a novel modification and analysis of the
noisy gradient descent algorithm and show that this algorithm achieves a rate
of
$\tilde{O}\big(\big(\frac{\sqrt{d}}{n\sqrt{\rho}}\big)^{\frac{2\kappa}{4-\kappa}}\big)$
adaptively, which is nearly optimal when $\kappa = 2$. We further show that,
without assuming the KL condition, the same gradient descent algorithm can
achieve fast convergence to a stationary point when the gradient stays
sufficiently large during the run of the algorithm. Specifically, we show that
this algorithm can approximate stationary points of Lipschitz, smooth (and
possibly nonconvex) objectives with rate as fast as
$\tilde{O}\big(\frac{\sqrt{d}}{n\sqrt{\rho}}\big)$ and never worse than
$\tilde{O}\big(\big(\frac{\sqrt{d}}{n\sqrt{\rho}}\big)^{1/2}\big)$. The latter
rate matches the best known rate for methods that do not rely on variance
reduction.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13454" title="Abstract">arXiv:2311.13454</a> [<a href="/pdf/2311.13454" title="Download PDF">pdf</a>, <a href="/format/2311.13454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explaining high-dimensional text classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Melamed%2C+O">Odelia Melamed</a>, 
<a href="/search/cs?searchtype=author&query=Caruana%2C+R">Rich Caruana</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to "XAI in Action" workshop @ NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)

</div>
<p class="mathjax">Explainability has become a valuable tool in the last few years, helping
humans better understand AI-guided decisions. However, the classic
explainability tools are sometimes quite limited when considering
high-dimensional inputs and neural network classifiers. We present a new
explainability method using theoretically proven high-dimensional properties in
neural network classifiers. We present two usages of it: 1) On the classical
sentiment analysis task for the IMDB reviews dataset, and 2) our
Malware-Detection task for our PowerShell scripts dataset.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13455" title="Abstract">arXiv:2311.13455</a> [<a href="/pdf/2311.13455" title="Download PDF">pdf</a>, <a href="/format/2311.13455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generation of Explanations for Logic Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pu%2C+Y">Yanyi Pu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 78 Pages, 16 Figures, Thesis Presentation is available at <a href="https://drive.google.com/file/d/1wLIBsjfLvO11PjCS6qx4Y9UgRBUfq3wQ/view?usp=sharing">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">This thesis delves into a fortiori arguments in deductive reasoning,
underscoring their relevance in various domains such as law, philosophy, and
artificial intelligence. The research is centred on employing GPT-3.5-turbo to
automate the analysis of these arguments, with a focus on understanding
intricate reasoning processes, generating clear and coherent explanations, and
creating novel arguments. The methodology encompasses a series of tasks
including detailed reasoning, interpretation, and the augmentation of a
fortiori arguments. It involves meticulously identifying these arguments in
diverse contexts, differentiating comparative elements, and categorizing them
based on their logical structure.
<br />Extensive experiments reveals the challenges encountered by GPT-3.5-turbo in
accurately detecting and classifying a fortiori arguments. Nevertheless, the
model demonstrates a performance that rivals specialized models, particularly
in extracting key components and interpreting underlying properties. The
integration of external information into the model's processing significantly
elevates the quality of the generated explanations. Additionally, the model
exhibits a noteworthy capability in augmenting arguments, thus contributing to
the enrichment of the data set.
<br />Despite facing certain limitations, this thesis makes significant
contributions to the fields of artificial intelligence and logical reasoning.
It introduces novel methodologies, establishes a rigorous evaluation framework,
and provides deep insights that set the stage for future advancements in
automated logical reasoning. The findings and methodologies presented herein
not only underscore the potential of AI in complex reasoning tasks but also
highlight areas for future research and development.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13459" title="Abstract">arXiv:2311.13459</a> [<a href="/pdf/2311.13459" title="Download PDF">pdf</a>, <a href="/format/2311.13459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Tempered Hilbert Simplex Distance and Its Application To Non-linear  Embeddings of TEMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amid%2C+E">Ehsan Amid</a>, 
<a href="/search/cs?searchtype=author&query=Nielsen%2C+F">Frank Nielsen</a>, 
<a href="/search/cs?searchtype=author&query=Nock%2C+R">Richard Nock</a>, 
<a href="/search/cs?searchtype=author&query=Warmuth%2C+M+K">Manfred K. Warmuth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Tempered Exponential Measures (TEMs) are a parametric generalization of the
exponential family of distributions maximizing the tempered entropy function
among positive measures subject to a probability normalization of their power
densities. Calculus on TEMs relies on a deformed algebra of arithmetic
operators induced by the deformed logarithms used to define the tempered
entropy. In this work, we introduce three different parameterizations of finite
discrete TEMs via Legendre functions of the negative tempered entropy function.
In particular, we establish an isometry between such parameterizations in terms
of a generalization of the Hilbert log cross-ratio simplex distance to a
tempered Hilbert co-simplex distance. Similar to the Hilbert geometry, the
tempered Hilbert distance is characterized as a $t$-symmetrization of the
oriented tempered Funk distance. We motivate our construction by introducing
the notion of $t$-lengths of smooth curves in a tautological Finsler manifold.
We then demonstrate the properties of our generalized structure in different
settings and numerically examine the quality of its differentiable
approximations for optimization in machine learning settings.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13460" title="Abstract">arXiv:2311.13460</a> [<a href="/pdf/2311.13460" title="Download PDF">pdf</a>, <a href="/format/2311.13460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Objective Bayesian Optimization with Active Preference Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ozaki%2C+R">Ryota Ozaki</a>, 
<a href="/search/cs?searchtype=author&query=Ishikawa%2C+K">Kazuki Ishikawa</a>, 
<a href="/search/cs?searchtype=author&query=Kanzaki%2C+Y">Youhei Kanzaki</a>, 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+S">Shinya Suzuki</a>, 
<a href="/search/cs?searchtype=author&query=Takeno%2C+S">Shion Takeno</a>, 
<a href="/search/cs?searchtype=author&query=Takeuchi%2C+I">Ichiro Takeuchi</a>, 
<a href="/search/cs?searchtype=author&query=Karasuyama%2C+M">Masayuki Karasuyama</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">There are a lot of real-world black-box optimization problems that need to
optimize multiple criteria simultaneously. However, in a multi-objective
optimization (MOO) problem, identifying the whole Pareto front requires the
prohibitive search cost, while in many practical scenarios, the decision maker
(DM) only needs a specific solution among the set of the Pareto optimal
solutions. We propose a Bayesian optimization (BO) approach to identifying the
most preferred solution in the MOO with expensive objective functions, in which
a Bayesian preference model of the DM is adaptively estimated by an interactive
manner based on the two types of supervisions called the pairwise preference
and improvement request. To explore the most preferred solution, we define an
acquisition function in which the uncertainty both in the objective functions
and the DM preference is incorporated. Further, to minimize the interaction
cost with the DM, we also propose an active learning strategy for the
preference estimation. We empirically demonstrate the effectiveness of our
proposed method through the benchmark function optimization and the
hyper-parameter optimization problems for machine learning models.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13462" title="Abstract">arXiv:2311.13462</a> [<a href="/pdf/2311.13462" title="Download PDF">pdf</a>, <a href="/ps/2311.13462" title="Download PostScript">ps</a>, <a href="/format/2311.13462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experimentation in Early-Stage Video Game Startups: Practices and  Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Edison%2C+H">Henry Edison</a>, 
<a href="/search/cs?searchtype=author&query=Melegati%2C+J">Jorge Melegati</a>, 
<a href="/search/cs?searchtype=author&query=Bjarnason%2C+E">Elizabeth Bjarnason</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Experimentation has been considered critical for successful software product
and business development, including in video game startups. Video game startups
need "wow" qualities that distinguish them from the competition. Thus, they
need to continuously experiment to find these qualities before running out of
time and resources. In this study, we aimed to explore how these companies
perform experimentation. We interviewed four co-founders of video game
startups. Our findings identify six practices, or scenarios, through which
video game startups conduct experiments and challenges associated with these.
The initial results could inform these startups about the possibilities and
challenges and guide future research.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13469" title="Abstract">arXiv:2311.13469</a> [<a href="/pdf/2311.13469" title="Download PDF">pdf</a>, <a href="/ps/2311.13469" title="Download PostScript">ps</a>, <a href="/format/2311.13469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Span-Based Optimal Sample Complexity for Average Reward MDPs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zurek%2C+M">Matthew Zurek</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yudong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">We study the sample complexity of learning an $\varepsilon$-optimal policy in
an average-reward Markov decision process (MDP) under a generative model. We
establish the complexity bound $\widetilde{O}\left(SA\frac{H}{\varepsilon^2}
\right)$, where $H$ is the span of the bias function of the optimal policy and
$SA$ is the cardinality of the state-action space. Our result is the first that
is minimax optimal (up to log factors) in all parameters $S,A,H$ and
$\varepsilon$, improving on existing work that either assumes uniformly bounded
mixing times for all policies or has suboptimal dependence on the parameters.
<br />Our result is based on reducing the average-reward MDP to a discounted MDP.
To establish the optimality of this reduction, we develop improved bounds for
$\gamma$-discounted MDPs, showing that
$\widetilde{O}\left(SA\frac{H}{(1-\gamma)^2\varepsilon^2} \right)$ samples
suffice to learn a $\varepsilon$-optimal policy in weakly communicating MDPs
under the regime that $\gamma \geq 1 - \frac{1}{H}$, circumventing the
well-known lower bound of
$\widetilde{\Omega}\left(SA\frac{1}{(1-\gamma)^3\varepsilon^2} \right)$ for
general $\gamma$-discounted MDPs. Our analysis develops upper bounds on certain
instance-dependent variance parameters in terms of the span parameter. These
bounds are tighter than those based on the mixing time or diameter of the MDP
and may be of broader use.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13471" title="Abstract">arXiv:2311.13471</a> [<a href="/pdf/2311.13471" title="Download PDF">pdf</a>, <a href="/format/2311.13471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative Analysis of Linear Regression, Gaussian Elimination, and LU  Decomposition for CT Real Estate Purchase Decisions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xilin Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Complexity (cs.CC); Computational Engineering, Finance, and Science (cs.CE); Numerical Analysis (math.NA)

</div>
<p class="mathjax">This paper presents a comprehensive evaluation of three distinct
computational algorithms applied to the decision-making process of real estate
purchases. Specifically, we analyze the efficacy of Linear Regression from
Scikit-learn library, Gaussian Elimination with partial pivoting, and LU
Decomposition in predicting the advisability of buying a house in the State of
Connecticut based on a set of financial and market-related parameters. The
algorithms' performances were compared using a dataset encompassing
town-specific details, yearly data, interest rates, and median sale ratios. Our
results demonstrate significant differences in predictive accuracy, with Linear
Regression and LU Decomposition providing the most reliable recommendations and
Gaussian Elimination showing limitations in stability and performance. The
study's findings emphasize the importance of algorithm selection in predictive
analytic and offer insights into the practical applications of computational
methods in real estate investment strategies. By evaluating model efficacy
through metrics such as R-squared scores and Mean Squared Error, we provide a
nuanced understanding of each method's strengths and weaknesses, contributing
valuable knowledge to the fields of real estate analysis and predictive
modeling.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13472" title="Abstract">arXiv:2311.13472</a> [<a href="/pdf/2311.13472" title="Download PDF">pdf</a>, <a href="/format/2311.13472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Complexity-Guided Curriculum Learning for Text Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vakil%2C+N">Nidhi Vakil</a>, 
<a href="/search/cs?searchtype=author&query=Amiri%2C+H">Hadi Amiri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Long Paper Accepted at EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Curriculum learning provides a systematic approach to training. It refines
training progressively, tailors training to task requirements, and improves
generalization through exposure to diverse examples. We present a curriculum
learning approach that builds on existing knowledge about text and graph
complexity formalisms for training with text graph data. The core part of our
approach is a novel data scheduler, which employs "spaced repetition" and
complexity formalisms to guide the training process. We demonstrate the
effectiveness of the proposed approach on several text graph tasks and graph
neural network architectures. The proposed model gains more and uses less data;
consistently prefers text over graph complexity indices throughout training,
while the best curricula derived from text and graph complexity indices are
equally effective; and it learns transferable curricula across GNN models and
datasets. In addition, we find that both node-level (local) and graph-level
(global) graph complexity indices, as well as shallow and traditional text
complexity indices play a crucial role in effective curriculum learning.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13475" title="Abstract">arXiv:2311.13475</a> [<a href="/pdf/2311.13475" title="Download PDF">pdf</a>, <a href="/format/2311.13475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Translation to Control Formality Features in the Target Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tyagi%2C+H">Harshita Tyagi</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+P">Prashasta Jung</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hyowon Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, based on DCU MCM Practicum 2022/2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Formality plays a significant role in language communication, especially in
low-resource languages such as Hindi, Japanese and Korean. These languages
utilise formal and informal expressions to convey messages based on social
contexts and relationships. When a language translation technique is used to
translate from a source language that does not pertain the formality (e.g.
English) to a target language that does, there is a missing information on
formality that could be a challenge in producing an accurate outcome. This
research explores how this issue should be resolved when machine learning
methods are used to translate from English to languages with formality, using
Hindi as the example data. This was done by training a bilingual model in a
formality-controlled setting and comparing its performance with a pre-trained
multilingual model in a similar setting. Since there are not a lot of training
data with ground truth, automated annotation techniques were employed to
increase the data size. The primary modeling approach involved leveraging
transformer models, which have demonstrated effectiveness in various natural
language processing tasks. We evaluate the official formality accuracy(ACC) by
comparing the predicted masked tokens with the ground truth. This metric
provides a quantitative measure of how well the translations align with the
desired outputs. Our study showcases a versatile translation strategy that
considers the nuances of formality in the target language, catering to diverse
language communication needs and scenarios.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13478" title="Abstract">arXiv:2311.13478</a> [<a href="/pdf/2311.13478" title="Download PDF">pdf</a>, <a href="/format/2311.13478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solution discovery via reconfiguration for problems in P
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grobler%2C+M">Mario Grobler</a>, 
<a href="/search/cs?searchtype=author&query=Maaz%2C+S">Stephanie Maaz</a>, 
<a href="/search/cs?searchtype=author&query=Megow%2C+N">Nicole Megow</a>, 
<a href="/search/cs?searchtype=author&query=Mouawad%2C+A+E">Amer E. Mouawad</a>, 
<a href="/search/cs?searchtype=author&query=Ramamoorthi%2C+V">Vijayaragunathan Ramamoorthi</a>, 
<a href="/search/cs?searchtype=author&query=Schmand%2C+D">Daniel Schmand</a>, 
<a href="/search/cs?searchtype=author&query=Siebertz%2C+S">Sebastian Siebertz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Data Structures and Algorithms (cs.DS); Combinatorics (math.CO)

</div>
<p class="mathjax">In the recently introduced framework of solution discovery via
reconfiguration [Fellows et al., ECAI 2023], we are given an initial
configuration of $k$ tokens on a graph and the question is whether we can
transform this configuration into a feasible solution (for some problem) via a
bounded number $b$ of small modification steps. In this work, we study solution
discovery variants of polynomial-time solvable problems, namely Spanning Tree
Discovery, Shortest Path Discovery, Matching Discovery, and Vertex/Edge Cut
Discovery in the unrestricted token addition/removal model, the token jumping
model, and the token sliding model. In the unrestricted token addition/removal
model, we show that all four discovery variants remain in P. For the toking
jumping model we also prove containment in P, except for Vertex/Edge Cut
Discovery, for which we prove NP-completeness. Finally, in the token sliding
model, almost all considered problems become NP-complete, the exception being
Spanning Tree Discovery, which remains polynomial-time solvable. We then study
the parameterized complexity of the NP-complete problems and provide a full
classification of tractability with respect to the parameters solution size
(number of tokens) $k$ and transformation budget (number of steps) $b$. Along
the way, we observe strong connections between the solution discovery variants
of our base problems and their (weighted) rainbow variants as well as their
red-blue variants with cardinality constraints.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13488" title="Abstract">arXiv:2311.13488</a> [<a href="/pdf/2311.13488" title="Download PDF">pdf</a>, <a href="/format/2311.13488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning based Post Event Analysis for Cybersecurity of  Cyber-Physical System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Park%2C+K">Kuchan Park</a>, 
<a href="/search/eess?searchtype=author&query=Hong%2C+J">Junho Hong</a>, 
<a href="/search/eess?searchtype=author&query=Su%2C+W">Wencong Su</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+H">HyoJong Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to 2024 IEEE Power and Energy Society General Meeting
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">As Information and Communication Technology (ICT) equipment continues to be
integrated into power systems, issues related to cybersecurity are increasingly
emerging. Particularly noteworthy is the transition to digital substations,
which is shifting operations from traditional hardwired-based systems to
communication-based Supervisory Control and Data Acquisition (SCADA) system
operations. These changes in the power system have increased the vulnerability
of the system to cyber-attacks and emphasized its importance. This paper
proposes a machine learning (ML) based post event analysis of the power system
in order to respond to these cybersecurity issues. An artificial neural network
(ANN) and other ML models are trained using transient fault measurements and
cyber-attack data on substations. The trained models can successfully
distinguish between power system faults and cyber-attacks. Furthermore, the
results of the proposed ML-based methods can also identify 10 different fault
types and the location where the event occurred.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13489" title="Abstract">arXiv:2311.13489</a> [<a href="/pdf/2311.13489" title="Download PDF">pdf</a>, <a href="/format/2311.13489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large-scale Package Deliveries with Unmanned Aerial Vehicles using  Collective Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Narayanan%2C+A">Arun Narayanan</a>, 
<a href="/search/cs?searchtype=author&query=Pournaras%2C+E">Evangelos Pournaras</a>, 
<a href="/search/cs?searchtype=author&query=Nardelli%2C+P+H+J">Pedro H. J. Nardelli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">Unmanned aerial vehicles (UAVs) have significant practical advantages for
delivering packages, and many logistics companies have begun deploying UAVs for
commercial package deliveries. To deliver packages quickly and
cost-effectively, the routes taken by UAVs from depots to customers must be
optimized. This route optimization problem, a type of capacitated vehicle
routing problem, has recently attracted considerable research interest.
However, few papers have dealt with large-scale deliveries, where the number of
customers exceed 1000. We present an innovative, practical package delivery
model wherein multiple UAVs deliver multiple packages to customers who are
compensated for late deliveries. Further, we propose an innovative methodology
that combines a new plan-generation algorithm with a collective-learning
heuristic to quickly determine cost-effective paths of UAVs even for
large-scale deliveries up to 10000 customers. Specialized settings are applied
to a collective-learning heuristic, the Iterative Economic Planning and
Optimized Selections (I-EPOS) in order to coordinate collective actions of the
UAVs. To demonstrate our methodology, we applied our highly flexible approach
to a depot in Heathrow Airport, London. We show that a coordinated approach, in
which the UAVs collectively determine their flight paths, leads to lower
operational costs than an uncoordinated approach. Further, the coordinated
approach enables large-scale package deliveries.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13494" title="Abstract">arXiv:2311.13494</a> [<a href="/pdf/2311.13494" title="Download PDF">pdf</a>, <a href="/ps/2311.13494" title="Download PostScript">ps</a>, <a href="/format/2311.13494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparative Analysis of Supportive Navigation on Movie Recommenders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ali%2C+M+S">Mohammad Sualeh Ali</a>, 
<a href="/search/cs?searchtype=author&query=Tariq%2C+M+M">Muhammed Maaz Tariq</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+A">Alina Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Soomro%2C+A+R">Abdul Razaque Soomro</a>, 
<a href="/search/cs?searchtype=author&query=Syed%2C+D">Danysh Syed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This was an extensive survey and prototyping we did to purpose and alternative user interface for movie recommender systems like Netflix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">This literature review covers the research and thought process that went into
making a solution for the infinite scrolling problem faced in streaming
services such as Netflix. Using the data collected, we have come to the
conclusion that an alternate layout can somewhat alleviate the problems it
takes in navigating a list of movies. We also found out by a comparative
analysis that some layouts, the circular one in particular, is advantageous in
certain settings making it an ideal candidate for a movie recommender system.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13495" title="Abstract">arXiv:2311.13495</a> [<a href="/pdf/2311.13495" title="Download PDF">pdf</a>, <a href="/format/2311.13495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Current Topological and Machine Learning Applications for Bias Detection  in Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farrelly%2C+C">Colleen Farrelly</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+Y">Yashbir Singh</a>, 
<a href="/search/cs?searchtype=author&query=Hathaway%2C+Q+A">Quincy A. Hathaway</a>, 
<a href="/search/cs?searchtype=author&query=Carlsson%2C+G">Gunnar Carlsson</a>, 
<a href="/search/cs?searchtype=author&query=Choudhary%2C+A">Ashok Choudhary</a>, 
<a href="/search/cs?searchtype=author&query=Paul%2C+R">Rahul Paul</a>, 
<a href="/search/cs?searchtype=author&query=Doretto%2C+G">Gianfranco Doretto</a>, 
<a href="/search/cs?searchtype=author&query=Himeur%2C+Y">Yassine Himeur</a>, 
<a href="/search/cs?searchtype=author&query=Atalls%2C+S">Shadi Atalls</a>, 
<a href="/search/cs?searchtype=author&query=Mansoor%2C+W">Wathiq Mansoor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Institutional bias can impact patient outcomes, educational attainment, and
legal system navigation. Written records often reflect bias, and once bias is
identified; it is possible to refer individuals for training to reduce bias.
Many machine learning tools exist to explore text data and create predictive
models that can search written records to identify real-time bias. However, few
previous studies investigate large language model embeddings and geometric
models of biased text data to understand geometry's impact on bias modeling
accuracy. To overcome this issue, this study utilizes the RedditBias database
to analyze textual biases. Four transformer models, including BERT and RoBERTa
variants, were explored. Post-embedding, t-SNE allowed two-dimensional
visualization of data. KNN classifiers differentiated bias types, with lower
k-values proving more effective. Findings suggest BERT, particularly mini BERT,
excels in bias classification, while multilingual models lag. The
recommendation emphasizes refining monolingual models and exploring
domain-specific biases.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13502" title="Abstract">arXiv:2311.13502</a> [<a href="/pdf/2311.13502" title="Download PDF">pdf</a>, <a href="/format/2311.13502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bitformer: An efficient Transformer with bitwise operation-based  attention for Big Data Analytics at low-cost low-precision devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+G">Gaoxiang Duan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junkai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiaoying Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yongxin Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the current landscape of large models, the Transformer stands as a
cornerstone, playing a pivotal role in shaping the trajectory of modern models.
However, its application encounters challenges attributed to the substantial
computational intricacies intrinsic to its attention mechanism. Moreover, its
reliance on high-precision floating-point operations presents specific hurdles,
particularly evident in computation-intensive scenarios such as edge computing
environments. These environments, characterized by resource-constrained devices
and a preference for lower precision, necessitate innovative solutions.
<br />To tackle the exacting data processing demands posed by edge devices, we
introduce the Bitformer model, an inventive extension of the Transformer
paradigm. Central to this innovation is a novel attention mechanism that
adeptly replaces conventional floating-point matrix multiplication with bitwise
operations. This strategic substitution yields dual advantages. Not only does
it maintain the attention mechanism's prowess in capturing intricate long-range
information dependencies, but it also orchestrates a profound reduction in the
computational complexity inherent in the attention operation. The transition
from an $O(n^2d)$ complexity, typical of floating-point operations, to an
$O(n^2T)$ complexity characterizing bitwise operations, substantiates this
advantage. Notably, in this context, the parameter $T$ remains markedly smaller
than the conventional dimensionality parameter $d$.
<br />The Bitformer model in essence endeavors to reconcile the indomitable
requirements of modern computing landscapes with the constraints posed by edge
computing scenarios. By forging this innovative path, we bridge the gap between
high-performing models and resource-scarce environments, thus unveiling a
promising trajectory for further advancements in the field.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13507" title="Abstract">arXiv:2311.13507</a> [<a href="/pdf/2311.13507" title="Download PDF">pdf</a>, <a href="/format/2311.13507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applying Dimensionality Reduction as Precursor to LSTM-CNN Models for  Classifying Imagery and Motor Signals in ECoG-Based BCIs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bafana%2C+S">Soham Bafana</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 Pages, 12 Figures. The dataset used in this paper can be found here: <a href="https://osf.io/ksqv8/download">this https URL</a>, from the Miller 2010 paper. All code used in this research can be found at <a href="https://github.com/bafanaS/dim-reduction-with-cnn-lstm.git">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC); Signal Processing (eess.SP)

</div>
<p class="mathjax">Motor impairments, frequently caused by neurological incidents like strokes
or traumatic brain injuries, present substantial obstacles in rehabilitation
therapy. This research aims to elevate the field by optimizing motor imagery
classification algorithms within Brain-Computer Interfaces (BCIs). By improving
the efficiency of BCIs, we offer a novel approach that holds significant
promise for enhancing motor rehabilitation outcomes. Utilizing unsupervised
techniques for dimensionality reduction, namely Uniform Manifold Approximation
and Projection (UMAP) coupled with K-Nearest Neighbors (KNN), we evaluate the
necessity of employing supervised methods such as Long Short-Term Memory (LSTM)
and Convolutional Neural Networks (CNNs) for classification tasks. Importantly,
participants who exhibited high KNN scores following UMAP dimensionality
reduction also achieved high accuracy in supervised deep learning (DL) models.
Due to individualized model requirements and massive neural training data,
dimensionality reduction becomes an effective preprocessing step that minimizes
the need for extensive data labeling and supervised deep learning techniques.
This approach has significant implications not only for targeted therapies in
motor dysfunction but also for addressing regulatory, safety, and reliability
concerns in the rapidly evolving BCI field.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13508" title="Abstract">arXiv:2311.13508</a> [<a href="/pdf/2311.13508" title="Download PDF">pdf</a>, <a href="/format/2311.13508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Naturalness of Attention: Revisiting Attention in Code Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saad%2C+M">Mootez Saad</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+T">Tushar Sharma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICSE-NIER (2024) track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Language models for code such as CodeBERT offer the capability to learn
advanced source code representation, but their opacity poses barriers to
understanding of captured properties. Recent attention analysis studies provide
initial interpretability insights by focusing solely on attention weights
rather than considering the wider context modeling of Transformers. This study
aims to shed some light on the previously ignored factors of the attention
mechanism beyond the attention weights. We conduct an initial empirical study
analyzing both attention distributions and transformed representations in
CodeBERT. Across two programming languages, Java and Python, we find that the
scaled transformation norms of the input better capture syntactic structure
compared to attention weights alone. Our analysis reveals characterization of
how CodeBERT embeds syntactic code properties. The findings demonstrate the
importance of incorporating factors beyond just attention weights for
rigorously understanding neural code models. This lays the groundwork for
developing more interpretable models and effective uses of attention mechanisms
in program analysis.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13509" title="Abstract">arXiv:2311.13509</a> [<a href="/pdf/2311.13509" title="Download PDF">pdf</a>, <a href="/format/2311.13509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy and Time-Aware Inference Offloading for DNN-based Applications in  LEO Satellites
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yijie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yiran Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+A">Ao Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICNP 2023 Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">In recent years, Low Earth Orbit (LEO) satellites have witnessed rapid
development, with inference based on Deep Neural Network (DNN) models emerging
as the prevailing technology for remote sensing satellite image recognition.
However, the substantial computation capability and energy demands of DNN
models, coupled with the instability of the satellite-ground link, pose
significant challenges, burdening satellites with limited power intake and
hindering the timely completion of tasks. Existing approaches, such as
transmitting all images to the ground for processing or executing DNN models on
the satellite, is unable to effectively address this issue. By exploiting the
internal hierarchical structure of DNNs and treating each layer as an
independent subtask, we propose a satellite-ground collaborative computation
partial offloading approach to address this challenge. We formulate the problem
of minimizing the inference task execution time and onboard energy consumption
through offloading as an integer linear programming (ILP) model. The complexity
in solving the problem arises from the combinatorial explosion in the discrete
solution space. To address this, we have designed an improved optimization
algorithm based on branch and bound. Simulation results illustrate that,
compared to the existing approaches, our algorithm improve the performance by
10%-18%
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13512" title="Abstract">arXiv:2311.13512</a> [<a href="/pdf/2311.13512" title="Download PDF">pdf</a>, <a href="/format/2311.13512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Whale-Mud-Ring Optimization for Precise Color Skin Cancer Image  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamza%2C+A">Amir Hamza</a>, 
<a href="/search/cs?searchtype=author&query=Lekouaghet%2C+B">Badis Lekouaghet</a>, 
<a href="/search/cs?searchtype=author&query=Himeur%2C+Y">Yassine Himeur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Timely identification and treatment of rapidly progressing skin cancers can
significantly contribute to the preservation of patients' health and
well-being. Dermoscopy, a dependable and accessible tool, plays a pivotal role
in the initial stages of skin cancer detection. Consequently, the effective
processing of digital dermoscopy images holds significant importance in
elevating the accuracy of skin cancer diagnoses. Multilevel thresholding is a
key tool in medical imaging that extracts objects within the image to
facilitate its analysis. In this paper, an enhanced version of the Mud Ring
Algorithm hybridized with the Whale Optimization Algorithm, named WMRA, is
proposed. The proposed approach utilizes bubble-net attack and mud ring
strategy to overcome stagnation in local optima and obtain optimal thresholds.
The experimental results show that WMRA is powerful against a cluster of recent
methods in terms of fitness, Peak Signal to Noise Ratio (PSNR), and Mean Square
Error (MSE).
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13517" title="Abstract">arXiv:2311.13517</a> [<a href="/pdf/2311.13517" title="Download PDF">pdf</a>, <a href="/format/2311.13517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning-Based Relaxation of Completeness Requirements for Data Entry  Forms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Belgacem%2C+H">Hichem Belgacem</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaochen Li</a>, 
<a href="/search/cs?searchtype=author&query=Bianculli%2C+D">Domenico Bianculli</a>, 
<a href="/search/cs?searchtype=author&query=Briand%2C+L+C">Lionel C. Briand</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Data entry forms use completeness requirements to specify the fields that are
required or optional to fill for collecting necessary information from
different types of users.
<br />However, some required fields may not be applicable for certain types of
users anymore. Nevertheless, they may still be incorrectly marked as required
in the form; we call such fields obsolete required fields.
<br />Since obsolete required fields usually have not-null validation checks before
submitting the form, users have to enter meaningless values in such fields in
order to complete the form submission. These meaningless values threaten the
quality of the filled data. To avoid users filling meaningless values, existing
techniques usually rely on manually written rules to identify the obsolete
required fields and relax their completeness requirements. However, these
techniques are ineffective and costly. In this paper, we propose LACQUER, a
learning-based automated approach for relaxing the completeness requirements of
data entry forms. LACQUER builds Bayesian Network models to automatically learn
conditions under which users had to fill meaningless values. To improve its
learning ability, LACQUER identifies the cases where a required field is only
applicable for a small group of users, and uses SMOTE, an oversampling
technique, to generate more instances on such fields for effectively mining
dependencies on them. Our experimental results show that LACQUER can accurately
relax the completeness requirements of required fields in data entry forms with
precision values ranging between 0.76 and 0.90 on different datasets. LACQUER
can prevent users from filling 20% to 64% of meaningless values, with negative
predictive values between 0.72 and 0.91. Furthermore, LACQUER is efficient; it
takes at most 839 ms to predict the completeness requirement of an instance.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13523" title="Abstract">arXiv:2311.13523</a> [<a href="/pdf/2311.13523" title="Download PDF">pdf</a>, <a href="/format/2311.13523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Outerplanar and Forest Storyplans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fiala%2C+J">Ji&#x159;&#xed; Fiala</a>, 
<a href="/search/cs?searchtype=author&query=Firman%2C+O">Oksana Firman</a>, 
<a href="/search/cs?searchtype=author&query=Liotta%2C+G">Giuseppe Liotta</a>, 
<a href="/search/cs?searchtype=author&query=Wolff%2C+A">Alexander Wolff</a>, 
<a href="/search/cs?searchtype=author&query=Zink%2C+J">Johannes Zink</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in Proc. SOFSEM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We study the problem of gradually representing a complex graph as a sequence
of drawings of small subgraphs whose union is the complex graph. The sequence
of drawings is called \emph{storyplan}, and each drawing in the sequence is
called a \emph{frame}. In an outerplanar storyplan, every frame is outerplanar;
in a forest storyplan, every frame is acyclic. We identify graph families that
admit such storyplans and families for which such storyplans do not always
exist. In the affirmative case, we present efficient algorithms that produce
straight-line storyplans.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13531" title="Abstract">arXiv:2311.13531</a> [<a href="/pdf/2311.13531" title="Download PDF">pdf</a>, <a href="/ps/2311.13531" title="Download PostScript">ps</a>, <a href="/format/2311.13531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging CNNs and Ensemble Learning for Automated Disaster Image  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rathod%2C+A">Archit Rathod</a>, 
<a href="/search/cs?searchtype=author&query=Pariawala%2C+V">Veer Pariawala</a>, 
<a href="/search/cs?searchtype=author&query=Surana%2C+M">Mokshit Surana</a>, 
<a href="/search/cs?searchtype=author&query=Saxena%2C+K">Kumkum Saxena</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 11 figures, 4 tables, ICSISCET 2023 Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Natural disasters act as a serious threat globally, requiring effective and
efficient disaster management and recovery. This paper focuses on classifying
natural disaster images using Convolutional Neural Networks (CNNs). Multiple
CNN architectures were built and trained on a dataset containing images of
earthquakes, floods, wildfires, and volcanoes. A stacked CNN ensemble approach
proved to be the most effective, achieving 95% accuracy and an F1 score going
up to 0.96 for individual classes. Tuning hyperparameters of individual models
for optimization was critical to maximize the models' performance. The stacking
of CNNs with XGBoost acting as the meta-model utilizes the strengths of the CNN
and ResNet models to improve the overall accuracy of the classification.
Results obtained from the models illustrated the potency of CNN-based models
for automated disaster image classification. This lays the foundation for
expanding these techniques to build robust systems for disaster response,
damage assessment, and recovery management.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13534" title="Abstract">arXiv:2311.13534</a> [<a href="/pdf/2311.13534" title="Download PDF">pdf</a>, <a href="/format/2311.13534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LM-Cocktail: Resilient Tuning of Language Models via Model Merging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+S">Shitao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peitian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+X">Xingrun Xing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">The pre-trained language models are continually fine-tuned to better support
downstream applications. However, this operation may result in significant
performance degeneration on general tasks beyond the targeted domain. To
overcome this problem, we propose a novel method which enables the fine-tuned
model to stay resilient in general perspectives. Our method is conducted in the
form of model merging (namely LM-Cocktail), where the fine-tuned language model
is merged with the pre-trained base model or the peer models from other domains
through weighted average. Despite simplicity, LM-Cocktail is surprisingly
effective: the resulted model is able to achieve a strong empirical performance
in the whole scope of general tasks while preserving a superior capacity in its
targeted domain. We conduct comprehensive experiments with LLama and BGE model
on popular benchmarks, including FLAN, MMLU, MTEB, whose results validate the
efficacy of our proposed method. The code and checkpoints are available at
https://github.com/FlagOpen/FlagEmbedding.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13535" title="Abstract">arXiv:2311.13535</a> [<a href="/pdf/2311.13535" title="Download PDF">pdf</a>, <a href="/format/2311.13535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffusionMat: Alpha Matting as Sequential Refinement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yangyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+S">Shengfeng He</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+W">Wenqi Shao</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K+K">Kwan-Yee K. Wong</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we introduce DiffusionMat, a novel image matting framework
that employs a diffusion model for the transition from coarse to refined alpha
mattes. Diverging from conventional methods that utilize trimaps merely as
loose guidance for alpha matte prediction, our approach treats image matting as
a sequential refinement learning process. This process begins with the addition
of noise to trimaps and iteratively denoises them using a pre-trained diffusion
model, which incrementally guides the prediction towards a clean alpha matte.
The key innovation of our framework is a correction module that adjusts the
output at each denoising step, ensuring that the final result is consistent
with the input image's structures. We also introduce the Alpha Reliability
Propagation, a novel technique designed to maximize the utility of available
guidance by selectively enhancing the trimap regions with confident alpha
information, thus simplifying the correction task. To train the correction
module, we devise specialized loss functions that target the accuracy of the
alpha matte's edges and the consistency of its opaque and transparent regions.
We evaluate our model across several image matting benchmarks, and the results
indicate that DiffusionMat consistently outperforms existing methods. Project
page at~\url{https://cnnlstm.github.io/DiffusionMat
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13538" title="Abstract">arXiv:2311.13538</a> [<a href="/pdf/2311.13538" title="Download PDF">pdf</a>, <a href="/format/2311.13538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speak Like a Native: Prompting Large Language Models in a Native Style
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhicheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yinya Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+J">Jing Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiaodan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jing Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Existing work has found that the prompt engineering heavily influences the
performance of large language models (LLMs). Chain-of-thought (CoT), as a
popular prompt engineering technique, prompted LLMs using in-context examples
with reasoning steps. In current studies, the few-shot examples of CoT are
generally handcrafted by humans. However, how the text style of in-context
examples influence the outputs of LLMs still remains under-explored. This paper
presents a novel and effective approach, named \textbf{AlignCoT}, to improve
the reasoning capability of LLMs by aligning the in-context examples with the
native style of LLMs. ``Native'' refers to the inherent characteristic style of
LLMs which can be probed by original zero-shot scenarios. AlignCoT is
orthogonal to other prompt engineering methods, making it easy to combine with
state-of-the-art techniques to further improve the LLMs' performance. We
conduct extensive and comprehensive experiments on several benchmarks. The
empirical results demonstrate that our AlignCoTsignificantly improves
performance over the carefully handcrafted in-context examples. For instance,
with GPT-3.5-turbo, we observed a +2.5\% improvement on GSM8K. Furthermore, our
AlignCoT consistently improve the performance when combined with other
state-of-the-art prompt engineering methods. The source code and dataset will
be available at
\href{https://github.com/yangzhch6/AlignCoT}{https://github.com/yangzhch6/AlignCoT}.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13541" title="Abstract">arXiv:2311.13541</a> [<a href="/pdf/2311.13541" title="Download PDF">pdf</a>, <a href="/format/2311.13541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear Log-Normal Attention with Unbiased Concentration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nahshan%2C+Y">Yury Nahshan</a>, 
<a href="/search/cs?searchtype=author&query=Kampeas%2C+J">Joseph Kampeas</a>, 
<a href="/search/cs?searchtype=author&query=Haleva%2C+E">Emir Haleva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 20 figures, 5 tables, submitted to ICLR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Transformer models have achieved remarkable results in a wide range of
applications. However, their scalability is hampered by the quadratic time and
memory complexity of the self-attention mechanism concerning the sequence
length. This limitation poses a substantial obstacle when dealing with long
documents or high-resolution images. In this work, we study the self-attention
mechanism by analyzing the distribution of the attention matrix and its
concentration ability. Furthermore, we propose instruments to measure these
quantities and introduce a novel self-attention mechanism, Linear Log-Normal
Attention, designed to emulate the distribution and concentration behavior of
the original self-attention. Our experimental results on popular natural
language benchmarks reveal that our proposed Linear Log-Normal Attention
outperforms other linearized attention alternatives, offering a promising
avenue for enhancing the scalability of transformer models. Our code is
available in supplementary materials.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13547" title="Abstract">arXiv:2311.13547</a> [<a href="/pdf/2311.13547" title="Download PDF">pdf</a>, <a href="/format/2311.13547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Medical Image Retrieval Using Pretrained Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jush%2C+F+K">Farnaz Khun Jush</a>, 
<a href="/search/cs?searchtype=author&query=Truong%2C+T">Tuan Truong</a>, 
<a href="/search/cs?searchtype=author&query=Vogler%2C+S">Steffen Vogler</a>, 
<a href="/search/cs?searchtype=author&query=Lenga%2C+M">Matthias Lenga</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">A wide range of imaging techniques and data formats available for medical
images make accurate retrieval from image databases challenging.
<br />Efficient retrieval systems are crucial in advancing medical research,
enabling large-scale studies and innovative diagnostic tools. Thus, addressing
the challenges of medical image retrieval is essential for the continued
enhancement of healthcare and research.
<br />In this study, we evaluated the feasibility of employing four
state-of-the-art pretrained models for medical image retrieval at modality,
body region, and organ levels and compared the results of two similarity
indexing approaches. Since the employed networks take 2D images, we analyzed
the impacts of weighting and sampling strategies to incorporate 3D information
during retrieval of 3D volumes. We showed that medical image retrieval is
feasible using pretrained networks without any additional training or
fine-tuning steps. Using pretrained embeddings, we achieved a recall of 1 for
various tasks at modality, body region, and organ level.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13549" title="Abstract">arXiv:2311.13549</a> [<a href="/pdf/2311.13549" title="Download PDF">pdf</a>, <a href="/format/2311.13549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ADriver-I: A General World Model for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+F">Fan Jia</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+W">Weixin Mao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yingfei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yucheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yuqing Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tiancai Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Tech Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Typically, autonomous driving adopts a modular design, which divides the full
stack into perception, prediction, planning and control parts. Though
interpretable, such modular design tends to introduce a substantial amount of
redundancy. Recently, multimodal large language models (MLLM) and diffusion
techniques have demonstrated their superior performance on comprehension and
generation ability. In this paper, we first introduce the concept of
interleaved vision-action pair, which unifies the format of visual features and
control signals. Based on the vision-action pairs, we construct a general world
model based on MLLM and diffusion model for autonomous driving, termed
ADriver-I. It takes the vision-action pairs as inputs and autoregressively
predicts the control signal of the current frame. The generated control signals
together with the historical vision-action pairs are further conditioned to
predict the future frames. With the predicted next frame, ADriver-I performs
further control signal prediction. Such a process can be repeated infinite
times, ADriver-I achieves autonomous driving in the world created by itself.
Extensive experiments are conducted on nuScenes and our large-scale private
datasets. ADriver-I shows impressive performance compared to several
constructed baselines. We hope our ADriver-I can provide some new insights for
future autonomous driving and embodied intelligence.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13559" title="Abstract">arXiv:2311.13559</a> [<a href="/pdf/2311.13559" title="Download PDF">pdf</a>, <a href="/ps/2311.13559" title="Download PostScript">ps</a>, <a href="/format/2311.13559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transfer Learning-based Real-time Handgun Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elmir%2C+Y">Youssef Elmir</a>, 
<a href="/search/cs?searchtype=author&query=Laouar%2C+S+A">Sid Ahmed Laouar</a>, 
<a href="/search/cs?searchtype=author&query=Hamdaoui%2C+L">Larbi Hamdaoui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Traditional surveillance systems rely on human attention, limiting their
effectiveness. This study employs convolutional neural networks and transfer
learning to develop a real-time computer vision system for automatic handgun
detection. Comprehensive analysis of online handgun detection methods is
conducted, emphasizing reducing false positives and learning time. Transfer
learning is demonstrated as an effective approach. Despite technical
challenges, the proposed system achieves a precision rate of 84.74%,
demonstrating promising performance comparable to related works, enabling
faster learning and accurate automatic handgun detection for enhanced security.
This research advances security measures by reducing human monitoring
dependence, showcasing the potential of transfer learning-based approaches for
efficient and reliable handgun detection.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13562" title="Abstract">arXiv:2311.13562</a> [<a href="/pdf/2311.13562" title="Download PDF">pdf</a>, <a href="/format/2311.13562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Soulstyler: Using Large Language Model to Guide Image Style Transfer for  Target Object
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Rong%2C+P">Peng Rong</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jingbo Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chao Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+H">Hongwu Lv</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages,3 figures,ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Image style transfer occupies an important place in both computer graphics
and computer vision. However, most current methods require reference to
stylized images and cannot individually stylize specific objects. To overcome
this limitation, we propose the "Soulstyler" framework, which allows users to
guide the stylization of specific objects in an image through simple textual
descriptions. We introduce a large language model to parse the text and
identify stylization goals and specific styles. Combined with a CLIP-based
semantic visual embedding encoder, the model understands and matches text and
image content. We also introduce a novel localized text-image block matching
loss that ensures that style transfer is performed only on specified target
objects, while non-target regions remain in their original style. Experimental
results demonstrate that our model is able to accurately perform style transfer
on target objects according to textual descriptions without affecting the style
of background regions. Our code will be available at
https://github.com/yisuanwang/Soulstyler.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13565" title="Abstract">arXiv:2311.13565</a> [<a href="/pdf/2311.13565" title="Download PDF">pdf</a>, <a href="/format/2311.13565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Drilling Down into the Discourse Structure with LLMs for Long Document  Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nair%2C+I">Inderjeet Nair</a>, 
<a href="/search/cs?searchtype=author&query=Somasundaram%2C+S">Shwetha Somasundaram</a>, 
<a href="/search/cs?searchtype=author&query=Saxena%2C+A">Apoorv Saxena</a>, 
<a href="/search/cs?searchtype=author&query=Goswami%2C+K">Koustava Goswami</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">We address the task of evidence retrieval for long document question
answering, which involves locating relevant paragraphs within a document to
answer a question. We aim to assess the applicability of large language models
(LLMs) in the task of zero-shot long document evidence retrieval, owing to
their unprecedented performance across various NLP tasks. However, currently
the LLMs can consume limited context lengths as input, thus providing document
chunks as inputs might overlook the global context while missing out on
capturing the inter-segment dependencies. Moreover, directly feeding the large
input sets can incur significant computational costs, particularly when
processing the entire document (and potentially incurring monetary expenses
with enterprise APIs like OpenAI's GPT variants). To address these challenges,
we propose a suite of techniques that exploit the discourse structure commonly
found in documents. By utilizing this structure, we create a condensed
representation of the document, enabling a more comprehensive understanding and
analysis of relationships between different parts. We retain $99.6\%$ of the
best zero-shot approach's performance, while processing only $26\%$ of the
total tokens used by the best approach in the information seeking evidence
retrieval setup. We also show how our approach can be combined with
\textit{self-ask} reasoning agent to achieve best zero-shot performance in
complex multi-hop question answering, just $\approx 4\%$ short of zero-shot
performance using gold evidence.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13568" title="Abstract">arXiv:2311.13568</a> [<a href="/pdf/2311.13568" title="Download PDF">pdf</a>, <a href="/ps/2311.13568" title="Download PostScript">ps</a>, <a href="/format/2311.13568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning from similar systems and online data-driven LQR using iterative  randomised data compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kedia%2C+V">Vatsal Kedia</a>, 
<a href="/search/eess?searchtype=author&query=George%2C+S+S">Sneha Susan George</a>, 
<a href="/search/eess?searchtype=author&query=Chakraborty%2C+D">Debraj Chakraborty</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 figures and Submitted to ECC 2024 (Under Review)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The problem of data-driven recursive computation of receding horizon LQR
control through a randomized combination of online/current and
historical/recorded data is considered. It is assumed that large amounts of
historical input-output data from a system, which is similar but not identical
to the current system under consideration, is available. This (possibly large)
data set is compressed through a novel randomized subspace algorithm to
directly synthesize an initial solution of the standard LQR problem, which
however is sub-optimal due to the inaccuracy of the historical model. The first
instance of this input is used to actuate the current system and the
corresponding instantaneous output is used to iteratively re-solve the LQR
problem through a computationally inexpensive randomized rank-one update of the
old compressed data. The first instance of the re-computed input is applied to
the system at the next instant, output recorded and the entire procedure is
repeated at each subsequent instant. As more current data becomes available,
the algorithm learns automatically from the new data while simultaneously
controlling the system in near optimal manner. The proposed algorithm is
computationally inexpensive due to the initial and repeated compression of old
and newly available data. Moreover, the simultaneous learning and control makes
this algorithm particularly suited for adapting to unknown, poorly modeled and
time-varying systems without any explicit exploration stage. Simulations
demonstrate the effectiveness of the proposed algorithm vs popular
exploration/exploitation approaches to LQR control.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13569" title="Abstract">arXiv:2311.13569</a> [<a href="/pdf/2311.13569" title="Download PDF">pdf</a>, <a href="/format/2311.13569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combinatorial Optimization with Policy Adaptation using Latent Space  Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chalumeau%2C+F">Felix Chalumeau</a>, 
<a href="/search/cs?searchtype=author&query=Surana%2C+S">Shikha Surana</a>, 
<a href="/search/cs?searchtype=author&query=Bonnet%2C+C">Clement Bonnet</a>, 
<a href="/search/cs?searchtype=author&query=Grinsztajn%2C+N">Nathan Grinsztajn</a>, 
<a href="/search/cs?searchtype=author&query=Pretorius%2C+A">Arnu Pretorius</a>, 
<a href="/search/cs?searchtype=author&query=Laterre%2C+A">Alexandre Laterre</a>, 
<a href="/search/cs?searchtype=author&query=Barrett%2C+T+D">Thomas D. Barrett</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Neurips 2023. Small updates in results reported
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Combinatorial Optimization underpins many real-world applications and yet,
designing performant algorithms to solve these complex, typically NP-hard,
problems remains a significant research challenge. Reinforcement Learning (RL)
provides a versatile framework for designing heuristics across a broad spectrum
of problem domains. However, despite notable progress, RL has not yet
supplanted industrial solvers as the go-to solution. Current approaches
emphasize pre-training heuristics that construct solutions but often rely on
search procedures with limited variance, such as stochastically sampling
numerous solutions from a single policy or employing computationally expensive
fine-tuning of the policy on individual problem instances. Building on the
intuition that performant search at inference time should be anticipated during
pre-training, we propose COMPASS, a novel RL approach that parameterizes a
distribution of diverse and specialized policies conditioned on a continuous
latent space. We evaluate COMPASS across three canonical problems - Travelling
Salesman, Capacitated Vehicle Routing, and Job-Shop Scheduling - and
demonstrate that our search strategy (i) outperforms state-of-the-art
approaches on 11 standard benchmarking tasks and (ii) generalizes better,
surpassing all other approaches on a set of 18 procedurally transformed
instance distributions.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13570" title="Abstract">arXiv:2311.13570</a> [<a href="/pdf/2311.13570" title="Download PDF">pdf</a>, <a href="/format/2311.13570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WildFusion: Learning 3D-Aware Latent Diffusion Models in View Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schwarz%2C+K">Katja Schwarz</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S+W">Seung Wook Kim</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jun Gao</a>, 
<a href="/search/cs?searchtype=author&query=Fidler%2C+S">Sanja Fidler</a>, 
<a href="/search/cs?searchtype=author&query=Geiger%2C+A">Andreas Geiger</a>, 
<a href="/search/cs?searchtype=author&query=Kreis%2C+K">Karsten Kreis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Modern learning-based approaches to 3D-aware image synthesis achieve high
photorealism and 3D-consistent viewpoint changes for the generated images.
Existing approaches represent instances in a shared canonical space. However,
for in-the-wild datasets a shared canonical system can be difficult to define
or might not even exist. In this work, we instead model instances in view
space, alleviating the need for posed images and learned camera distributions.
We find that in this setting, existing GAN-based methods are prone to
generating flat geometry and struggle with distribution coverage. We hence
propose WildFusion, a new approach to 3D-aware image synthesis based on latent
diffusion models (LDMs). We first train an autoencoder that infers a compressed
latent representation, which additionally captures the images' underlying 3D
structure and enables not only reconstruction but also novel view synthesis. To
learn a faithful 3D representation, we leverage cues from monocular depth
prediction. Then, we train a diffusion model in the 3D-aware latent space,
thereby enabling synthesis of high-quality 3D-consistent image samples,
outperforming recent state-of-the-art GAN-based methods. Importantly, our
3D-aware LDM is trained without any direct supervision from multiview images or
3D geometry and does not require posed images or learned pose or camera
distributions. It directly learns a 3D representation without relying on
canonical camera coordinates. This opens up promising research avenues for
scalable 3D-aware image synthesis and 3D content creation from in-the-wild
image data. See https://katjaschwarz.github.io/wildfusion for videos of our 3D
results.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13571" title="Abstract">arXiv:2311.13571</a> [<a href="/pdf/2311.13571" title="Download PDF">pdf</a>, <a href="/ps/2311.13571" title="Download PostScript">ps</a>, <a href="/format/2311.13571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ball Mill Fault Prediction Based on Deep Convolutional Auto-Encoding  Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ai%2C+X">Xinkun Ai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Wei Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yonggang Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xinwu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peilong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">LiYe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">JanFeng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yuan Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Ball mills play a critical role in modern mining operations, making their
bearing failures a significant concern due to the potential loss of production
efficiency and economic consequences. This paper presents an anomaly detection
method based on Deep Convolutional Auto-encoding Neural Networks (DCAN) for
addressing the issue of ball mill bearing fault detection. The proposed
approach leverages vibration data collected during normal operation for
training, overcoming challenges such as labeling issues and data imbalance
often encountered in supervised learning methods. DCAN includes the modules of
convolutional feature extraction and transposed convolutional feature
reconstruction, demonstrating exceptional capabilities in signal processing and
feature extraction. Additionally, the paper describes the practical deployment
of the DCAN-based anomaly detection model for bearing fault detection,
utilizing data from the ball mill bearings of Wuhan Iron &amp; Steel Resources
Group and fault data from NASA's bearing vibration dataset. Experimental
results validate the DCAN model's reliability in recognizing fault vibration
patterns. This method holds promise for enhancing bearing fault detection
efficiency, reducing production interruptions, and lowering maintenance costs.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13574" title="Abstract">arXiv:2311.13574</a> [<a href="/pdf/2311.13574" title="Download PDF">pdf</a>, <a href="/format/2311.13574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> XAGen: 3D Expressive Human Avatars Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhongcong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianfeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liew%2C+J+H">Jun Hao Liew</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiashi Feng</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023, Project Page at <a href="https://showlab.github.io/xagen">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advances in 3D-aware GAN models have enabled the generation of
realistic and controllable human body images. However, existing methods focus
on the control of major body joints, neglecting the manipulation of expressive
attributes, such as facial expressions, jaw poses, hand poses, and so on. In
this work, we present XAGen, the first 3D generative model for human avatars
capable of expressive control over body, face, and hands. To enhance the
fidelity of small-scale regions like face and hands, we devise a multi-scale
and multi-part 3D representation that models fine details. Based on this
representation, we propose a multi-part rendering technique that disentangles
the synthesis of body, face, and hands to ease model training and enhance
geometric quality. Furthermore, we design multi-part discriminators that
evaluate the quality of the generated avatars with respect to their appearance
and fine-grained control capabilities. Experiments show that XAGen surpasses
state-of-the-art methods in terms of realism, diversity, and expressive control
abilities. Code and data will be made available at
https://showlab.github.io/xagen.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13577" title="Abstract">arXiv:2311.13577</a> [<a href="/pdf/2311.13577" title="Download PDF">pdf</a>, <a href="/format/2311.13577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physical Reasoning and Object Planning for Household Embodied Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+A">Ayush Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Prabhakar%2C+R">Raghav Prabhakar</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+A">Anirudh Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dianbo Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Total: 32 pages ( 16 pages main content, 11 Figures)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">In this study, we explore the sophisticated domain of task planning for
robust household embodied agents, with a particular emphasis on the intricate
task of selecting substitute objects. We introduce the CommonSense Object
Affordance Task (COAT), a novel framework designed to analyze reasoning
capabilities in commonsense scenarios. This approach is centered on
understanding how these agents can effectively identify and utilize alternative
objects when executing household tasks, thereby offering insights into the
complexities of practical decision-making in real-world environments.Drawing
inspiration from human decision-making, we explore how large language models
tackle this challenge through three meticulously crafted commonsense
question-and-answer datasets, featuring refined rules and human annotations.
Our evaluation of state-of-the-art language models on these datasets sheds
light on three pivotal considerations: 1) aligning an object's inherent utility
with the task at hand, 2) navigating contextual dependencies (societal norms,
safety, appropriateness, and efficiency), and 3) accounting for the current
physical state of the object. To maintain accessibility, we introduce five
abstract variables reflecting an object's physical condition, modulated by
human insights to simulate diverse household scenarios. Our contributions
include insightful Object-Utility mappings addressing the first consideration
and two extensive QA datasets (15k and 130k questions) probing the intricacies
of contextual dependencies and object states. The datasets, along with our
findings, are accessible at: \url{https://github.com/com-phy-affordance/COAT}.
This research not only advances our understanding of physical commonsense
reasoning in language models but also paves the way for future improvements in
household agent intelligence.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13580" title="Abstract">arXiv:2311.13580</a> [<a href="/pdf/2311.13580" title="Download PDF">pdf</a>, <a href="/format/2311.13580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $&#x3c3;$-PCA: a unified neural model for linear and nonlinear principal  component analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kanavati%2C+F">Fahdi Kanavati</a>, 
<a href="/search/cs?searchtype=author&query=Katsnith%2C+L">Lucy Katsnith</a>, 
<a href="/search/cs?searchtype=author&query=Tsuneki%2C+M">Masayuki Tsuneki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Linear principal component analysis (PCA), nonlinear PCA, and linear
independent component analysis (ICA) -- those are three methods with
single-layer autoencoder formulations for learning linear transformations from
data. Linear PCA learns orthogonal transformations (rotations) that orient axes
to maximise variance, but it suffers from a subspace rotational indeterminacy:
it fails to find a unique rotation for axes that share the same variance. Both
nonlinear PCA and linear ICA reduce the subspace indeterminacy from rotational
to permutational by maximising statistical independence under the assumption of
unit variance. The main difference between them is that nonlinear PCA only
learns rotations while linear ICA learns not just rotations but any linear
transformation with unit variance. The relationship between all three can be
understood by the singular value decomposition of the linear ICA transformation
into a sequence of rotation, scale, rotation. Linear PCA learns the first
rotation; nonlinear PCA learns the second. The scale is simply the inverse of
the standard deviations. The problem is that, in contrast to linear PCA,
conventional nonlinear PCA cannot be used directly on the data to learn the
first rotation, the first being special as it reduces dimensionality and orders
by variances. In this paper, we have identified the cause, and as a solution we
propose $\sigma$-PCA: a unified neural model for linear and nonlinear PCA as
single-layer autoencoders. One of its key ingredients: modelling not just the
rotation but also the scale -- the variances. This model bridges the disparity
between linear and nonlinear PCA. And so, like linear PCA, it can learn a
semi-orthogonal transformation that reduces dimensionality and orders by
variances, but, unlike linear PCA, it does not suffer from rotational
indeterminacy.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13581" title="Abstract">arXiv:2311.13581</a> [<a href="/pdf/2311.13581" title="Download PDF">pdf</a>, <a href="/format/2311.13581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PaSS: Parallel Speculative Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Monea%2C+G">Giovanni Monea</a>, 
<a href="/search/cs?searchtype=author&query=Joulin%2C+A">Armand Joulin</a>, 
<a href="/search/cs?searchtype=author&query=Grave%2C+E">Edouard Grave</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 3rd workshop on Efficient Natural Language and Speech Processing (ENLSP, NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Scaling the size of language models to tens of billions of parameters has led
to impressive performance on a wide range of tasks. At generation, these models
are used auto-regressively, requiring a forward pass for each generated token,
and thus reading the full set of parameters from memory. This memory access
forms the primary bottleneck for generation and it worsens as the model size
increases. Moreover, executing a forward pass for multiple tokens in parallel
often takes nearly the same time as it does for just one token. These two
observations lead to the development of speculative sampling, where a second
smaller model is used to draft a few tokens, that are then validated or
rejected using a single forward pass of the large model. Unfortunately, this
method requires two models that share the same tokenizer and thus limits its
adoption. As an alternative, we propose to use parallel decoding as a way to
draft multiple tokens from a single model with no computational cost, nor the
need for a second model. Our approach only requires an additional input token
that marks the words that will be generated simultaneously. We show promising
performance (up to $30\%$ speed-up) while requiring only as few as $O(d_{emb})$
additional parameters.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13583" title="Abstract">arXiv:2311.13583</a> [<a href="/pdf/2311.13583" title="Download PDF">pdf</a>, <a href="/format/2311.13583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Sampling for Deep Learning via Efficient Nonparametric Proxies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Daghaghi%2C+S">Shabnam Daghaghi</a>, 
<a href="/search/cs?searchtype=author&query=Coleman%2C+B">Benjamin Coleman</a>, 
<a href="/search/cs?searchtype=author&query=Geordie%2C+B">Benito Geordie</a>, 
<a href="/search/cs?searchtype=author&query=Shrivastava%2C+A">Anshumali Shrivastava</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Data sampling is an effective method to improve the training speed of neural
networks, with recent results demonstrating that it can even break the neural
scaling laws. These results critically rely on high-quality scores to estimate
the importance of an input to the network. We observe that there are two
dominant strategies: static sampling, where the scores are determined before
training, and dynamic sampling, where the scores can depend on the model
weights. Static algorithms are computationally inexpensive but less effective
than their dynamic counterparts, which can cause end-to-end slowdown due to
their need to explicitly compute losses. To address this problem, we propose a
novel sampling distribution based on nonparametric kernel regression that
learns an effective importance score as the neural network trains. However,
nonparametric regression models are too computationally expensive to accelerate
end-to-end training. Therefore, we develop an efficient sketch-based
approximation to the Nadaraya-Watson estimator. Using recent techniques from
high-dimensional statistics and randomized algorithms, we prove that our
Nadaraya-Watson sketch approximates the estimator with exponential convergence
guarantees. Our sampling algorithm outperforms the baseline in terms of
wall-clock time and accuracy on four datasets.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13584" title="Abstract">arXiv:2311.13584</a> [<a href="/pdf/2311.13584" title="Download PDF">pdf</a>, <a href="/ps/2311.13584" title="Download PostScript">ps</a>, <a href="/format/2311.13584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On diffusion-based generative models and their error bounds: The  log-concave case with full convergence estimates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bruno%2C+S">Stefano Bruno</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Ying Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+D">Dong-Young Lim</a>, 
<a href="/search/cs?searchtype=author&query=Akyildiz%2C+%C3%96+D">&#xd6;mer Deniz Akyildiz</a>, 
<a href="/search/cs?searchtype=author&query=Sabanis%2C+S">Sotirios Sabanis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Probability (math.PR); Machine Learning (stat.ML)

</div>
<p class="mathjax">We provide full theoretical guarantees for the convergence behaviour of
diffusion-based generative models under the assumption of strongly logconcave
data distributions while our approximating class of functions used for score
estimation is made of Lipschitz continuous functions. We demonstrate via a
motivating example, sampling from a Gaussian distribution with unknown mean,
the powerfulness of our approach. In this case, explicit estimates are provided
for the associated optimization problem, i.e. score approximation, while these
are combined with the corresponding sampling estimates. As a result, we obtain
the best known upper bound estimates in terms of key quantities of interest,
such as the dimension and rates of convergence, for the Wasserstein-2 distance
between the data distribution (Gaussian with unknown mean) and our sampling
algorithm.
<br />Beyond the motivating example and in order to allow for the use of a diverse
range of stochastic optimizers, we present our results using an $L^2$-accurate
score estimation assumption, which crucially is formed under an expectation
with respect to the stochastic optimizer and our novel auxiliary process that
uses only known information. This approach yields the best known convergence
rate for our sampling algorithm.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13586" title="Abstract">arXiv:2311.13586</a> [<a href="/pdf/2311.13586" title="Download PDF">pdf</a>, <a href="/format/2311.13586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Summary Reports Optimization in the Privacy Sandbox Attribution  Reporting API
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aksu%2C+H">Hidayet Aksu</a>, 
<a href="/search/cs?searchtype=author&query=Ghazi%2C+B">Badih Ghazi</a>, 
<a href="/search/cs?searchtype=author&query=Kamath%2C+P">Pritish Kamath</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+R">Ravi Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Manurangsi%2C+P">Pasin Manurangsi</a>, 
<a href="/search/cs?searchtype=author&query=Sealfon%2C+A">Adam Sealfon</a>, 
<a href="/search/cs?searchtype=author&query=Varadarajan%2C+A+V">Avinash V Varadarajan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The Privacy Sandbox Attribution Reporting API has been recently deployed by
Google Chrome to support the basic advertising functionality of attribution
reporting (aka conversion measurement) after deprecation of third-party
cookies. The API implements a collection of privacy-enhancing guardrails
including contribution bounding and noise injection. It also offers flexibility
for the analyst to allocate the contribution budget.
<br />In this work, we present methods for optimizing the allocation of the
contribution budget for summary reports from the Attribution Reporting API. We
evaluate them on real-world datasets as well as on a synthetic data model that
we find to accurately capture real-world conversion data. Our results
demonstrate that optimizing the parameters that can be set by the analyst can
significantly improve the utility achieved by querying the API while satisfying
the same privacy bounds.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13587" title="Abstract">arXiv:2311.13587</a> [<a href="/pdf/2311.13587" title="Download PDF">pdf</a>, <a href="/ps/2311.13587" title="Download PostScript">ps</a>, <a href="/format/2311.13587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Serverless Machine Learning Model Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kojs%2C+K">Kamil Kojs</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent developments in Generative AI, Computer Vision, and Natural Language
Processing have led to an increased integration of AI models into various
products. This widespread adoption of AI requires significant efforts in
deploying these models in production environments. When hosting machine
learning models for real-time predictions, it is important to meet defined
Service Level Objectives (SLOs), ensuring reliability, minimal downtime, and
optimizing operational costs of the underlying infrastructure. Large machine
learning models often demand GPU resources for efficient inference to meet
SLOs. In the context of these trends, there is growing interest in hosting AI
models in a serverless architecture while still providing GPU access for
inference tasks. This survey aims to summarize and categorize the emerging
challenges and optimization opportunities for large-scale deep learning serving
systems. By providing a novel taxonomy and summarizing recent trends, we hope
that this survey could shed light on new optimization perspectives and motivate
novel works in large-scale deep learning serving systems.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13588" title="Abstract">arXiv:2311.13588</a> [<a href="/pdf/2311.13588" title="Download PDF">pdf</a>, <a href="/format/2311.13588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> User-guided Page Merging for Memory Deduplication in Serverless Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+W">Wei Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Copik%2C+M">Marcin Copik</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Calotoiu%2C+A">Alexandru Calotoiu</a>, 
<a href="/search/cs?searchtype=author&query=Hoefler%2C+T">Torsten Hoefler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE BigData 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Serverless computing is an emerging cloud paradigm that offers an elastic and
scalable allocation of computing resources with pay-as-you-go billing. In the
Function-as-a-Service (FaaS) programming model, applications comprise
short-lived and stateless serverless functions executed in isolated containers
or microVMs, which can quickly scale to thousands of instances and process
terabytes of data. This flexibility comes at the cost of duplicated runtimes,
libraries, and user data spread across many function instances, and cloud
providers do not utilize this redundancy. The memory footprint of serverless
forces removing idle containers to make space for new ones, which decreases
performance through more cold starts and fewer data caching opportunities. We
address this issue by proposing deduplicating memory pages of serverless
workers with identical content, based on the content-based page-sharing concept
of Linux Kernel Same-page Merging (KSM). We replace the background memory
scanning process of KSM, as it is too slow to locate sharing candidates in
short-lived functions. Instead, we design User-Guided Page Merging (UPM), a
built-in Linux kernel module that leverages the madvise system call: we enable
users to advise the kernel of memory areas that can be shared with others. We
show that UPM reduces memory consumption by up to 55% on 16 concurrent
containers executing a typical image recognition function, more than doubling
the density for containers of the same function that can run on a system.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13589" title="Abstract">arXiv:2311.13589</a> [<a href="/pdf/2311.13589" title="Download PDF">pdf</a>, <a href="/ps/2311.13589" title="Download PostScript">ps</a>, <a href="/format/2311.13589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Risk-sensitive Markov Decision Process and Learning under General  Utility Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhengqi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Renyuan Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Reinforcement Learning (RL) has gained substantial attention across diverse
application domains and theoretical investigations. Existing literature on RL
theory largely focuses on risk-neutral settings where the decision-maker learns
to maximize the expected cumulative reward. However, in practical scenarios
such as portfolio management and e-commerce recommendations, decision-makers
often persist in heterogeneous risk preferences subject to outcome
uncertainties, which can not be well-captured by the risk-neural framework.
Incorporating these preferences can be approached through utility theory, yet
the development of risk-sensitive RL under general utility functions remains an
open question for theoretical exploration.
<br />In this paper, we consider a scenario where the decision-maker seeks to
optimize a general utility function of the cumulative reward in the framework
of a Markov decision process (MDP). To facilitate the Dynamic Programming
Principle and Bellman equation, we enlarge the state space with an additional
dimension that accounts for the cumulative reward. We propose a discretized
approximation scheme to the MDP under enlarged state space, which is tractable
and key for algorithmic design. We then propose a modified value iteration
algorithm that employs an epsilon-covering over the space of cumulative reward.
When a simulator is accessible, our algorithm efficiently learns a near-optimal
policy with guaranteed sample complexity. In the absence of a simulator, our
algorithm, designed with an upper-confidence-bound exploration approach,
identifies a near-optimal policy while ensuring a guaranteed regret bound. For
both algorithms, we match the theoretical lower bounds for the risk-neutral
setting.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13590" title="Abstract">arXiv:2311.13590</a> [<a href="/pdf/2311.13590" title="Download PDF">pdf</a>, <a href="/format/2311.13590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Triangle-free $2$-matchings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paluch%2C+K">Katarzyna Paluch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We consider the problem of finding a maximum size triangle-free $2$-matching
in a graph $G$. A $2$-matching is any subset of the edges such that each vertex
is incident to at most two edges from the subset. We present a fast
combinatorial algorithm for the problem. Our algorithm and its analysis are
dramatically simpler than the very complicated result by Hartvigsen from 1984.
<br />In the design of this algorithm we use several new concepts. It has been
proven before that for any triangle-free $2$-matching $M$ which is not maximum
the graph contains an $M$-augmenting path, whose application to $M$ results in
a bigger triangle-free $2$-matching. It was not known how to efficiently find
such a path. A new observation is that the search for an augmenting path $P$
can be restricted to so-called {\em amenable} paths that go through any
triangle $t$ contained in $P \cup M$ a limited number of times. To find an
augmenting path that is amenable and hence whose application does not create
any triangle we forbid some edges to be followed by certain others. This
operation can be thought of as using gadgets, in which some pairs of edges get
disconnected. To be able to disconnect two edges we employ {\em half-edges}. A
{\em half-edge} of edge $e$ is, informally speaking, a half of $e$ containing
exactly one of its endpoints. This is another novel application of half-edges
that were already been used for TSP and other matching problems. Additionally,
gadgets are not fixed during any augmentation phase, but are dynamically
changing according to the currently discovered state of reachability by
amenable paths.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13594" title="Abstract">arXiv:2311.13594</a> [<a href="/pdf/2311.13594" title="Download PDF">pdf</a>, <a href="/format/2311.13594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Labeling Neural Representations with Inverse Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bykov%2C+K">Kirill Bykov</a>, 
<a href="/search/cs?searchtype=author&query=Kopf%2C+L">Laura Kopf</a>, 
<a href="/search/cs?searchtype=author&query=Nakajima%2C+S">Shinichi Nakajima</a>, 
<a href="/search/cs?searchtype=author&query=Kloft%2C+M">Marius Kloft</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%B6hne%2C+M+M+-">Marina M.-C. H&#xf6;hne</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 16 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 37th Conference on Neural Information Processing Systems (NeurIPS
  2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Deep Neural Networks (DNNs) demonstrated remarkable capabilities in learning
complex hierarchical data representations, but the nature of these
representations remains largely unknown. Existing global explainability
methods, such as Network Dissection, face limitations such as reliance on
segmentation masks, lack of statistical significance testing, and high
computational demands. We propose Inverse Recognition (INVERT), a scalable
approach for connecting learned representations with human-understandable
concepts by leveraging their capacity to discriminate between these concepts.
In contrast to prior work, INVERT is capable of handling diverse types of
neurons, exhibits less computational complexity, and does not rely on the
availability of segmentation masks. Moreover, INVERT provides an interpretable
metric assessing the alignment between the representation and its corresponding
explanation and delivering a measure of statistical significance, emphasizing
its utility and credibility. We demonstrate the applicability of INVERT in
various scenarios, including the identification of representations affected by
spurious correlations, and the interpretation of the hierarchical structure of
decision-making within the models.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13596" title="Abstract">arXiv:2311.13596</a> [<a href="/pdf/2311.13596" title="Download PDF">pdf</a>, <a href="/format/2311.13596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> T-Rex: Counting by Visual Prompting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Q">Qing Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Feng Li</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+T">Tianhe Ren</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shilong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zhaoyang Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kent Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report. Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce T-Rex, an interactive object counting model designed to first
detect and then count any objects. We formulate object counting as an open-set
object detection task with the integration of visual prompts. Users can specify
the objects of interest by marking points or boxes on a reference image, and
T-Rex then detects all objects with a similar pattern. Guided by the visual
feedback from T-Rex, users can also interactively refine the counting results
by prompting on missing or falsely-detected objects. T-Rex has achieved
state-of-the-art performance on several class-agnostic counting benchmarks. To
further exploit its potential, we established a new counting benchmark
encompassing diverse scenarios and challenges. Both quantitative and
qualitative results show that T-Rex possesses exceptional zero-shot counting
capabilities. We also present various practical application scenarios for
T-Rex, illustrating its potential in the realm of visual prompting.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13600" title="Abstract">arXiv:2311.13600</a> [<a href="/pdf/2311.13600" title="Download PDF">pdf</a>, <a href="/format/2311.13600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZipLoRA: Any Subject in Any Style by Effectively Merging LoRAs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shah%2C+V">Viraj Shah</a>, 
<a href="/search/cs?searchtype=author&query=Ruiz%2C+N">Nataniel Ruiz</a>, 
<a href="/search/cs?searchtype=author&query=Cole%2C+F">Forrester Cole</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+E">Erika Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lazebnik%2C+S">Svetlana Lazebnik</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanzhen Li</a>, 
<a href="/search/cs?searchtype=author&query=Jampani%2C+V">Varun Jampani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://ziplora.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Methods for finetuning generative models for concept-driven personalization
generally achieve strong results for subject-driven or style-driven generation.
Recently, low-rank adaptations (LoRA) have been proposed as a
parameter-efficient way of achieving concept-driven personalization. While
recent work explores the combination of separate LoRAs to achieve joint
generation of learned styles and subjects, existing techniques do not reliably
address the problem; they often compromise either subject fidelity or style
fidelity. We propose ZipLoRA, a method to cheaply and effectively merge
independently trained style and subject LoRAs in order to achieve generation of
any user-provided subject in any user-provided style. Experiments on a wide
range of subject and style combinations show that ZipLoRA can generate
compelling results with meaningful improvements over baselines in subject and
style fidelity while preserving the ability to recontextualize. Project page:
https://ziplora.github.io
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13601" title="Abstract">arXiv:2311.13601</a> [<a href="/pdf/2311.13601" title="Download PDF">pdf</a>, <a href="/format/2311.13601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual In-Context Prompting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Feng Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Q">Qing Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+T">Tianhe Ren</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shilong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+X">Xueyan Zou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Huaizhe Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chunyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianwei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jianfeng Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> technical report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In-context prompting in large language models (LLMs) has become a prevalent
approach to improve zero-shot capabilities, but this idea is less explored in
the vision domain. Existing visual prompting methods focus on referring
segmentation to segment the most relevant object, falling short of addressing
many generic vision tasks like open-set segmentation and detection. In this
paper, we introduce a universal visual in-context prompting framework for both
tasks. In particular, we build on top of an encoder-decoder architecture, and
develop a versatile prompt encoder to support a variety of prompts like
strokes, boxes, and points. We further enhance it to take an arbitrary number
of reference image segments as the context. Our extensive explorations show
that the proposed visual in-context prompting elicits extraordinary referring
and generic segmentation capabilities to refer and detect, yielding competitive
performance to close-set in-domain datasets and showing promising results on
many open-set segmentation datasets. By joint training on COCO and SA-1B, our
model achieves $57.7$ PQ on COCO and $23.2$ PQ on ADE20K. Code will be
available at https://github.com/UX-Decoder/DINOv.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13602" title="Abstract">arXiv:2311.13602</a> [<a href="/pdf/2311.13602" title="Download PDF">pdf</a>, <a href="/format/2311.13602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrieval-Augmented Layout Transformer for Content-Aware Layout  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Horita%2C+D">Daichi Horita</a>, 
<a href="/search/cs?searchtype=author&query=Inoue%2C+N">Naoto Inoue</a>, 
<a href="/search/cs?searchtype=author&query=Kikuchi%2C+K">Kotaro Kikuchi</a>, 
<a href="/search/cs?searchtype=author&query=Yamaguchi%2C+K">Kota Yamaguchi</a>, 
<a href="/search/cs?searchtype=author&query=Aizawa%2C+K">Kiyoharu Aizawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Webpage: <a href="https://udonda.github.io/RALF/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Content-aware graphic layout generation aims to automatically arrange visual
elements along with a given content, such as an e-commerce product image. In
this paper, we argue that the current layout generation approaches suffer from
the limited training data for the high-dimensional layout structure. We show
that a simple retrieval augmentation can significantly improve the generation
quality. Our model, which is named Retrieval-Augmented Layout Transformer
(RALF), retrieves nearest neighbor layout examples based on an input image and
feeds these results into an autoregressive generator. Our model can apply
retrieval augmentation to various controllable generation tasks and yield
high-quality layouts within a unified architecture. Our extensive experiments
show that RALF successfully generates content-aware layouts in both constrained
and unconstrained settings and significantly outperforms the baselines.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Thu, 23 Nov 23</h3>
<dl>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06573" title="Abstract">arXiv:2311.06573</a> (cross-list from quant-ph) [<a href="/pdf/2311.06573" title="Download PDF">pdf</a>, <a href="/format/2311.06573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Generalized Space-Efficient Algorithm for Quantum Bit String  Comparators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Shahzad%2C+K">Khuram Shahzad</a>, 
<a href="/search/quant-ph?searchtype=author&query=Khan%2C+O+U">Omar Usman Khan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET); Logic in Computer Science (cs.LO); Software Engineering (cs.SE)

</div>
<p class="mathjax">Quantum Bit String Comparators (QBSC) operate on two sequences of n-qubits,
enabling the determination of their relationships, such as equality, greater
than, or less than. This is analogous to the way conditional statements are
used in programming languages. Consequently, QBSCs play a crucial role in
various algorithms that can be executed or adapted for quantum computers. The
development of efficient and generalized comparators for any $n$-qubit length
has long posed a challenge, as they have a high-cost footprint and lead to
quantum delays. Comparators that are efficient are associated with inputs of
fixed length. As a result, comparators without a generalized circuit cannot be
employed at a higher level, though they are well-suited for problems with
limited size requirements. In this paper, we introduce a generalized design for
the comparison of two $n$-qubit logic states using just two ancillary bits. The
design is examined on the basis of qubit requirements, ancillary bit usage,
quantum cost, quantum delay, gate operations, and circuit complexity, and is
tested comprehensively on various input lengths. The work allows for sufficient
flexibility in the design of quantum algorithms, which can accelerate quantum
algorithm development.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10115" title="Abstract">arXiv:2311.10115</a> (cross-list from eess.IV) [<a href="/pdf/2311.10115" title="Download PDF">pdf</a>, <a href="/ps/2311.10115" title="Download PostScript">ps</a>, <a href="/format/2311.10115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combined Channel and Spatial Attention-based Stereo Endoscopic Image  Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hayat%2C+M">Mansoor Hayat</a>, 
<a href="/search/eess?searchtype=author&query=Armvith%2C+S">Supavadee Armvith</a>, 
<a href="/search/eess?searchtype=author&query=Achakulvisut%2C+D+T">Dr. Titipat Achakulvisut</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Stereo Imaging technology integration into medical diagnostics and surgeries
brings a great revolution in the field of medical sciences. Now, surgeons and
physicians have better insight into the anatomy of patients' organs. Like other
technologies, stereo cameras have limitations, e.g., low resolution (LR) and
blurry output images. Currently, most of the proposed techniques for
super-resolution focus on developing complex blocks and complicated loss
functions, which cause high system complexity. We proposed a combined channel
and spatial attention block to extract features incorporated with a specific
but very strong parallax attention module (PAM) for endoscopic image
super-resolution. The proposed model is trained using the da Vinci dataset on
scales 2 and 4. Our proposed model has improved PSNR up to 2.12 dB for scale 2
and 1.29 dB for scale 4, while SSIM is improved by 0.03 for scale 2 and 0.0008
for scale 4. By incorporating this method, diagnosis and treatment for
endoscopic images can be more accurate and effective.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11166" title="Abstract">arXiv:2311.11166</a> (cross-list from math.OC) [<a href="/pdf/2311.11166" title="Download PDF">pdf</a>, <a href="/format/2311.11166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Optimization to Control: Quasi Policy Iteration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kolarijani%2C+M+A+S">Mohammad Amin Sharifi Kolarijani</a>, 
<a href="/search/math?searchtype=author&query=Esfahani%2C+P+M">Peyman Mohajerin Esfahani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">Recent control algorithms for Markov decision processes (MDPs) have been
designed using an implicit analogy with well-established optimization
algorithms. In this paper, we make this analogy explicit across four problem
classes with a unified solution characterization. This novel framework, in
turn, allows for a systematic transformation of algorithms from one domain to
the other. In particular, we identify equivalent optimization and control
algorithms that have already been pointed out in the existing literature, but
mostly in a scattered way. With this unifying framework in mind, we then
exploit two linear structural constraints specific to MDPs for approximating
the Hessian in a second-order-type algorithm from optimization, namely,
Anderson mixing. This leads to a novel first-order control algorithm that
modifies the standard value iteration (VI) algorithm by incorporating two new
directions and adaptive step sizes. While the proposed algorithm, coined as
quasi-policy iteration, has the same computational complexity as VI, it
interestingly exhibits an empirical convergence behavior similar to policy
iteration with a very low sensitivity to the discount factor.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12218" title="Abstract">arXiv:2311.12218</a> (cross-list from math.CO) [<a href="/pdf/2311.12218" title="Download PDF">pdf</a>, <a href="/ps/2311.12218" title="Download PostScript">ps</a>, <a href="/format/2311.12218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizing traces of processes defined by precedence and response  constraints: an order theory approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dukes%2C+M">Mark Dukes</a>, 
<a href="/search/math?searchtype=author&query=Sohn%2C+A">Anton Sohn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">In this paper we consider a general system of activities that can, but do not
have to, occur. This system is governed by a set of two types of constraints:
precedence and response. A precedence constraint dictates that an activity can
only occur if it has been preceded by some other specified activity. Response
constraints are similarly defined. An execution of the system is a listing of
activities in the order they occur and which satisfies all constraints. Such
systems naturally arise in areas of theoretical computer science and decision
science. An outcome of the freedom with which activities can occur is that
there are many different possible executions, and gaining a combinatorial
insight into these is a non-trivial problem.
<br />We characterize all of the ways in which such a system can be executed. Our
approach uses order theory to provide a classification in terms of the linear
extensions of posets constructed from the constraint sets. This
characterization is essential in calculating the stakeholder utility metrics
that have been developed by the first author that allow for quantitative
comparisons of such systems/processes. It also allows for a better
understanding of the theoretical backbone to these processes and their
deconstruction as a shuffle product of smaller systems.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12814" title="Abstract">arXiv:2311.12814</a> (cross-list from q-bio.BM) [<a href="/pdf/2311.12814" title="Download PDF">pdf</a>, <a href="/format/2311.12814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HydraScreen: A Generalizable Structure-Based Deep Learning Approach to  Drug Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Prat%2C+A">Alvaro Prat</a>, 
<a href="/search/q-bio?searchtype=author&query=Aty%2C+H+A">Hisham Abdel Aty</a>, 
<a href="/search/q-bio?searchtype=author&query=Kamuntavi%C4%8Dius%2C+G">Gintautas Kamuntavi&#x10d;ius</a>, 
<a href="/search/q-bio?searchtype=author&query=Paquet%2C+T">Tanya Paquet</a>, 
<a href="/search/q-bio?searchtype=author&query=Norvai%C5%A1as%2C+P">Povilas Norvai&#x161;as</a>, 
<a href="/search/q-bio?searchtype=author&query=Gasparotto%2C+P">Piero Gasparotto</a>, 
<a href="/search/q-bio?searchtype=author&query=Tal%2C+R">Roy Tal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose HydraScreen, a deep-learning approach that aims to provide a
framework for more robust machine-learning-accelerated drug discovery.
HydraScreen utilizes a state-of-the-art 3D convolutional neural network,
designed for the effective representation of molecular structures and
interactions in protein-ligand binding. We design an end-to-end pipeline for
high-throughput screening and lead optimization, targeting applications in
structure-based drug design. We assess our approach using established public
benchmarks based on the CASF 2016 core set, achieving top-tier results in
affinity and pose prediction (Pearson's r = 0.86, RMSE = 1.15, Top-1 = 0.95).
Furthermore, we utilize a novel interaction profiling approach to identify
potential biases in the model and dataset to boost interpretability and support
the unbiased nature of our method. Finally, we showcase HydraScreen's capacity
to generalize across unseen proteins and ligands, offering directions for
future development of robust machine learning scoring functions. HydraScreen
(accessible at https://hydrascreen.ro5.ai) provides a user-friendly GUI and a
public API, facilitating easy assessment of individual protein-ligand
complexes.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12842" title="Abstract">arXiv:2311.12842</a> (cross-list from eess.IV) [<a href="/pdf/2311.12842" title="Download PDF">pdf</a>, <a href="/format/2311.12842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Identification of Alzheimer&#x27;s Disease: A Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fang%2C+G">Guian Fang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+M">Mengsha Liu</a>, 
<a href="/search/eess?searchtype=author&query=Zhong%2C+Y">Yi Zhong</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Z">Zhuolin Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+J">Jiehui Huang</a>, 
<a href="/search/eess?searchtype=author&query=Tang%2C+Z">Zhenchao Tang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+C+Y">Calvin Yu-Chian Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Alzheimer's disease is a progressive neurological disorder characterized by
cognitive impairment and memory loss. With the increasing aging population, the
incidence of AD is continuously rising, making early diagnosis and intervention
an urgent need. In recent years, a considerable number of teams have applied
computer-aided diagnostic techniques to early classification research of AD.
Most studies have utilized imaging modalities such as magnetic resonance
imaging (MRI), positron emission tomography (PET), and electroencephalogram
(EEG). However, there have also been studies that attempted to use other
modalities as input features for the models, such as sound, posture,
biomarkers, cognitive assessment scores, and their fusion. Experimental results
have shown that the combination of multiple modalities often leads to better
performance compared to a single modality. Therefore, this paper will focus on
different modalities and their fusion, thoroughly elucidate the mechanisms of
various modalities, explore which methods should be combined to better harness
their utility, analyze and summarize the literature in the field of early
classification of AD in recent years, in order to explore more possibilities of
modality combinations.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12856" title="Abstract">arXiv:2311.12856</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2311.12856" title="Download PDF">pdf</a>, <a href="/format/2311.12856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Density of States Prediction of Crystalline Materials via Prompt-guided  Multi-Modal Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Lee%2C+N">Namkyeong Lee</a>, 
<a href="/search/cond-mat?searchtype=author&query=Noh%2C+H">Heewoong Noh</a>, 
<a href="/search/cond-mat?searchtype=author&query=Kim%2C+S">Sungwon Kim</a>, 
<a href="/search/cond-mat?searchtype=author&query=Hyun%2C+D">Dongmin Hyun</a>, 
<a href="/search/cond-mat?searchtype=author&query=Na%2C+G+S">Gyoung S. Na</a>, 
<a href="/search/cond-mat?searchtype=author&query=Park%2C+C">Chanyoung Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023. arXiv admin note: text overlap with <a href="/abs/2303.07000">arXiv:2303.07000</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The density of states (DOS) is a spectral property of crystalline materials,
which provides fundamental insights into various characteristics of the
materials. While previous works mainly focus on obtaining high-quality
representations of crystalline materials for DOS prediction, we focus on
predicting the DOS from the obtained representations by reflecting the nature
of DOS: DOS determines the general distribution of states as a function of
energy. That is, DOS is not solely determined by the crystalline material but
also by the energy levels, which has been neglected in previous works. In this
paper, we propose to integrate heterogeneous information obtained from the
crystalline materials and the energies via a multi-modal transformer, thereby
modeling the complex relationships between the atoms in the crystalline
materials and various energy levels for DOS prediction. Moreover, we propose to
utilize prompts to guide the model to learn the crystal structural
system-specific interactions between crystalline materials and energies.
Extensive experiments on two types of DOS, i.e., Phonon DOS and Electron DOS,
with various real-world scenarios demonstrate the superiority of
DOSTransformer.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12864" title="Abstract">arXiv:2311.12864</a> (cross-list from math.OC) [<a href="/pdf/2311.12864" title="Download PDF">pdf</a>, <a href="/format/2311.12864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OptScaler: A Hybrid Proactive-Reactive Framework for Robust Autoscaling  in the Cloud
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zou%2C+D">Ding Zou</a>, 
<a href="/search/math?searchtype=author&query=Lu%2C+W">Wei Lu</a>, 
<a href="/search/math?searchtype=author&query=Zhu%2C+Z">Zhibo Zhu</a>, 
<a href="/search/math?searchtype=author&query=Lu%2C+X">Xingyu Lu</a>, 
<a href="/search/math?searchtype=author&query=Zhou%2C+J">Jun Zhou</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+X">Xiaojin Wang</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+K">Kangyu Liu</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+H">Haiqing Wang</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+K">Kefan Wang</a>, 
<a href="/search/math?searchtype=author&query=Sun%2C+R">Renen Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Autoscaling is a vital mechanism in cloud computing that supports the
autonomous adjustment of computing resources under dynamic workloads. A primary
goal of autoscaling is to stabilize resource utilization at a desirable level,
thus reconciling the need for resource-saving with the satisfaction of Service
Level Objectives (SLOs). Existing proactive autoscaling methods anticipate the
future workload and scale the resources in advance, whereas the reliability may
suffer from prediction deviations arising from the frequent fluctuations and
noise of cloud workloads; reactive methods rely on real-time system feedback,
while the hysteretic nature of reactive methods could cause violations of the
rigorous SLOs. To this end, this paper presents OptScaler, a hybrid autoscaling
framework that integrates the power of both proactive and reactive methods for
regulating CPU utilization. Specifically, the proactive module of OptScaler
consists of a sophisticated workload prediction model and an optimization
model, where the former provides reliable inputs to the latter for making
optimal scaling decisions. The reactive module provides a self-tuning estimator
of CPU utilization to the optimization model. We embed Model Predictive Control
(MPC) mechanism and robust optimization techniques into the optimization model
to further enhance its reliability. Numerical results have demonstrated the
superiority of both the workload prediction model and the hybrid framework of
OptScaler in the scenario of online services compared to prevalent reactive,
proactive, or hybrid autoscalers. OptScaler has been successfully deployed at
Alipay, supporting the autoscaling of applets in the world-leading payment
platform.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12867" title="Abstract">arXiv:2311.12867</a> (cross-list from quant-ph) [<a href="/pdf/2311.12867" title="Download PDF">pdf</a>, <a href="/format/2311.12867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Amplitude-Ensemble Quantum-Inspired Tabu Search Algorithm for Solving  0/1 Knapsack Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Tseng%2C+K">Kuo-Chun Tseng</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lai%2C+W">Wei-Chieh Lai</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+I">I-Chia Chen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hsiao%2C+Y">Yun-Hsiang Hsiao</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chiue%2C+J">Jr-Yu Chiue</a>, 
<a href="/search/quant-ph?searchtype=author&query=Huang%2C+W">Wei-Chun Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">In this paper, we introduce an enhanced version of the "Quantum-inspired Tabu
Search Algorithm" (QTS), termed "amplitude-ensemble" QTS (AE-QTS). By utilizing
population information, we bring QTS closer to the quantum algorithm -- Glover
Search Algorithm, maintaining algorithmic simplicity. AE-QTS is validated
against the 0/1 knapsack problem, showing at least a 20% performance boost
across all problems and over a 30% efficiency increase in some cases compared
to the original QTS. Even with increasingly complex problems, this method
consistently outperforms the original QTS.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12874" title="Abstract">arXiv:2311.12874</a> (cross-list from q-bio.QM) [<a href="/pdf/2311.12874" title="Download PDF">pdf</a>, <a href="/format/2311.12874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpecHD: Hyperdimensional Computing Framework for FPGA-based Mass  Spectrometry Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Pinge%2C+S">Sumukh Pinge</a>, 
<a href="/search/q-bio?searchtype=author&query=Xu%2C+W">Weihong Xu</a>, 
<a href="/search/q-bio?searchtype=author&query=Kang%2C+J">Jaeyoung Kang</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+T">Tianqi Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Moshiri%2C+N">Neima Moshiri</a>, 
<a href="/search/q-bio?searchtype=author&query=Bittremieux%2C+W">Wout Bittremieux</a>, 
<a href="/search/q-bio?searchtype=author&query=Rosing%2C+T">Tajana Rosing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Hardware Architecture (cs.AR); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Mass spectrometry-based proteomics is a key enabler for personalized
healthcare, providing a deep dive into the complex protein compositions of
biological systems. This technology has vast applications in biotechnology and
biomedicine but faces significant computational bottlenecks. Current
methodologies often require multiple hours or even days to process extensive
datasets, particularly in the domain of spectral clustering. To tackle these
inefficiencies, we introduce SpecHD, a hyperdimensional computing (HDC)
framework supplemented by an FPGA-accelerated architecture with integrated
near-storage preprocessing. Utilizing streamlined binary operations in an HDC
environment, SpecHD capitalizes on the low-latency and parallel capabilities of
FPGAs. This approach markedly improves clustering speed and efficiency, serving
as a catalyst for real-time, high-throughput data analysis in future healthcare
applications. Our evaluations demonstrate that SpecHD not only maintains but
often surpasses existing clustering quality metrics while drastically cutting
computational time. Specifically, it can cluster a large-scale human proteome
dataset-comprising 25 million MS/MS spectra and 131 GB of MS data-in just 5
minutes. With energy efficiency exceeding 31x and a speedup factor that spans a
range of 6x to 54x over existing state of-the-art solutions, SpecHD emerges as
a promising solution for the rapid analysis of mass spectrometry data with
great implications for personalized healthcare.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12875" title="Abstract">arXiv:2311.12875</a> (cross-list from quant-ph) [<a href="/pdf/2311.12875" title="Download PDF">pdf</a>, <a href="/format/2311.12875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nav-Q: Quantum Deep Reinforcement Learning for Collision-Free Navigation  of Self-Driving Cars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Sinha%2C+A">Akash Sinha</a>, 
<a href="/search/quant-ph?searchtype=author&query=Macaluso%2C+A">Antonio Macaluso</a>, 
<a href="/search/quant-ph?searchtype=author&query=Klusch%2C+M">Matthias Klusch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 9 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The challenge of collision-free navigation (CFN) for self-driving cars is an
NP-hard problem addressed through Deep Reinforcement Learning (DRL). Despite
the effectiveness of DRL methods, their application demands significant
computing resources and prolonged training periods to establish a resilient
agent. On the other hand, quantum reinforcement learning algorithms have
recently demonstrated faster convergence and improved stability in simple,
non-real-world environments. However, their application in the real-world CFN
domain has not been explored, and their direct adaptation would require a
quantum computing device onboard the vehicle for testing.
<br />In this work, we propose Nav-Q, the first quantum-supported DRL algorithm for
CFN of self-driving cars, that leverages quantum computation for improving the
training performance without the requirement for onboard quantum hardware.
Nav-Q is based on the actor-critic approach, where the critic is implemented
using a hybrid quantum-classical algorithm suitable for near-term quantum
devices. We assess the performance of Nav-Q using the CARLA driving simulator,
a de facto standard benchmark for evaluating state-of-the-art DRL methods. Our
empirical evaluations showcase that Nav-Q surpasses its classical counterpart
not only in terms of training stability but also, in certain instances, with
respect to the convergence rate when analyzing the Reward vs. Episode curve.
This enhancement is accomplished without negatively impacting the learned
policy by the agent. Furthermore, we assess Nav-Q in relation to effective
dimension, unveiling that the incorporation of a quantum component results in a
model possessing greater descriptive power compared to classical baselines.
Finally, we evaluate the performance of Nav-Q using noisy quantum simulation,
observing that the quantum noise enhances the exploratory tendencies of the
agent during training.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12876" title="Abstract">arXiv:2311.12876</a> (cross-list from eess.IV) [<a href="/pdf/2311.12876" title="Download PDF">pdf</a>, <a href="/ps/2311.12876" title="Download PostScript">ps</a>, <a href="/format/2311.12876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy efficiency in Edge TPU vs. embedded GPU for computer-aided  medical imaging segmentation and classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Corral%2C+J+M+R">Jos&#xe9; Mar&#xed;a Rodr&#xed;guez Corral</a>, 
<a href="/search/eess?searchtype=author&query=Civit-Masot%2C+J">Javier Civit-Masot</a>, 
<a href="/search/eess?searchtype=author&query=Luna-Perej%C3%B3n%2C+F">Francisco Luna-Perej&#xf3;n</a>, 
<a href="/search/eess?searchtype=author&query=D%C3%ADaz-Cano%2C+I">Ignacio D&#xed;az-Cano</a>, 
<a href="/search/eess?searchtype=author&query=Morgado-Est%C3%A9vez%2C+A">Arturo Morgado-Est&#xe9;vez</a>, 
<a href="/search/eess?searchtype=author&query=Dom%C3%ADnguez-Morales%2C+M">Manuel Dom&#xed;nguez-Morales</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 20 figures. Accepted manuscript. Published in "Engineering Applications of Artificial Intelligence" (Elsevier), ISSN 0952-1976
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Engineering Applications of Artificial Intelligence, Volume 127,
  Part B, January (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this work, we evaluate the energy usage of fully embedded medical
diagnosis aids based on both segmentation and classification of medical images
implemented on Edge TPU and embedded GPU processors. We use glaucoma diagnosis
based on color fundus images as an example to show the possibility of
performing segmentation and classification in real time on embedded boards and
to highlight the different energy requirements of the studied implementations.
<br />Several other works develop the use of segmentation and feature extraction
techniques to detect glaucoma, among many other pathologies, with deep neural
networks. Memory limitations and low processing capabilities of embedded
accelerated systems (EAS) limit their use for deep network-based system
training. However, including specific acceleration hardware, such as NVIDIA's
Maxwell GPU or Google's Edge TPU, enables them to perform inferences using
complex pre-trained networks in very reasonable times.
<br />In this study, we evaluate the timing and energy performance of two EAS
equipped with Machine Learning (ML) accelerators executing an example
diagnostic tool developed in a previous work. For optic disc (OD) and cup (OC)
segmentation, the obtained prediction times per image are under 29 and 43 ms
using Edge TPUs and Maxwell GPUs, respectively. Prediction times for the
classification subsystem are lower than 10 and 14 ms for Edge TPUs and Maxwell
GPUs, respectively. Regarding energy usage, in approximate terms, for OD
segmentation Edge TPUs and Maxwell GPUs use 38 and 190 mJ per image,
respectively. For fundus classification, Edge TPUs and Maxwell GPUs use 45 and
70 mJ, respectively.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12878" title="Abstract">arXiv:2311.12878</a> (cross-list from stat.ME) [<a href="/pdf/2311.12878" title="Download PDF">pdf</a>, <a href="/format/2311.12878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Bayesian Learning with Action and State-Dependent Signal  Variance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Hou%2C+K">Kaiwen Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Econometrics (econ.EM); Statistics Theory (math.ST)

</div>
<p class="mathjax">This manuscript presents an advanced framework for Bayesian learning by
incorporating action and state-dependent signal variances into decision-making
models. This framework is pivotal in understanding complex data-feedback loops
and decision-making processes in various economic systems. Through a series of
examples, we demonstrate the versatility of this approach in different
contexts, ranging from simple Bayesian updating in stable environments to
complex models involving social learning and state-dependent uncertainties. The
paper uniquely contributes to the understanding of the nuanced interplay
between data, actions, outcomes, and the inherent uncertainty in economic
models.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12879" title="Abstract">arXiv:2311.12879</a> (cross-list from q-bio.QM) [<a href="/pdf/2311.12879" title="Download PDF">pdf</a>, <a href="/format/2311.12879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MiniAnDE: a reduced AnDE ensemble to deal with microarray data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Torrijos%2C+P">Pablo Torrijos</a>, 
<a href="/search/q-bio?searchtype=author&query=G%C3%A1mez%2C+J+A">Jos&#xe9; A. G&#xe1;mez</a>, 
<a href="/search/q-bio?searchtype=author&query=Puerta%2C+J+M">Jos&#xe9; M. Puerta</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Engineering Applications of Neural Networks. EANN 2023.
  Communications in Computer and Information Science, vol 1826. Springer, Cham
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This article focuses on the supervised classification of datasets with a
large number of variables and a small number of instances. This is the case,
for example, for microarray data sets commonly used in bioinformatics. Complex
classifiers that require estimating statistics over many variables are not
suitable for this type of data. Probabilistic classifiers with low-order
probability tables, e.g. NB and AODE, are good alternatives for dealing with
this type of data. AODE usually improves NB in accuracy, but suffers from high
spatial complexity since $k$ models, each with $n+1$ variables, are included in
the AODE ensemble. In this paper, we propose MiniAnDE, an algorithm that
includes only a small number of heterogeneous base classifiers in the ensemble,
i.e., each model only includes a different subset of the $k$ predictive
variables. Experimental evaluation shows that using MiniAnDE classifiers on
microarray data is feasible and outperforms NB and other ensembles such as
bagging and random forest.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12884" title="Abstract">arXiv:2311.12884</a> (cross-list from q-bio.GN) [<a href="/pdf/2311.12884" title="Download PDF">pdf</a>, <a href="/format/2311.12884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying DNA Sequence Motifs Using Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Poddar%2C+A">Asmita Poddar</a>, 
<a href="/search/q-bio?searchtype=author&query=Uzun%2C+V">Vladimir Uzun</a>, 
<a href="/search/q-bio?searchtype=author&query=Tunbridge%2C+E">Elizabeth Tunbridge</a>, 
<a href="/search/q-bio?searchtype=author&query=Haerty%2C+W">Wilfried Haerty</a>, 
<a href="/search/q-bio?searchtype=author&query=Nevado-Holgado%2C+A">Alejo Nevado-Holgado</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Splice sites play a crucial role in gene expression, and accurate prediction
of these sites in DNA sequences is essential for diagnosing and treating
genetic disorders. We address the challenge of splice site prediction by
introducing DeepDeCode, an attention-based deep learning sequence model to
capture the long-term dependencies in the nucleotides in DNA sequences. We
further propose using visualization techniques for accurate identification of
sequence motifs, which enhance the interpretability and trustworthiness of
DeepDeCode. We compare DeepDeCode to other state-of-the-art methods for splice
site prediction and demonstrate its accuracy, explainability and efficiency.
Given the results of our methodology, we expect that it can used for healthcare
applications to reason about genomic processes and be extended to discover new
splice sites and genomic regulatory elements.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12887" title="Abstract">arXiv:2311.12887</a> (cross-list from quant-ph) [<a href="/pdf/2311.12887" title="Download PDF">pdf</a>, <a href="/ps/2311.12887" title="Download PostScript">ps</a>, <a href="/format/2311.12887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal, and approximately optimal, quantum strategies for  $\mathrm{XOR}^{*}$ and $\mathrm{FFL}$ games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Rigas%2C+P">Pete Rigas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">We analyze optimal, and approximately optimal, quantum strategies for a
variety of non-local XOR games. Building upon previous arguments due to Ostrev
in 2016, which characterized approximately optimal, and optimal, strategies
that players Alice and Bob can adopt for maximizing a linear functional to win
non-local games after a Referee party examines each answer to a question drawn
from some probability distribution, we identify additional applications of the
framework for analyzing the performance of a broader class of quantum
strategies in which it is possible for Alice and Bob to realize quantum
advantage if the two players adopt strategies relying upon quantum
entanglement, two-dimensional resource systems, and reversible transformations.
For the Fortnow-Feige-Lovasz (FFL) game, the 2016 framework is directly
applicable, which consists of five steps, including: (1) constructing a
suitable, nonzero, linear transformation for the intertwining operations, (2)
demonstrating that the operator has unit Frobenius norm, (3) constructing error
bounds, and corresponding approximate operations, for $\big( A_k \otimes
\textbf{I} \big) \ket{\psi}$, and $\big( \textbf{I} \otimes \big( \frac{\pm
B_{kl} + B_{lk}}{\sqrt{2}} \big) \big) \ket{\psi}$, (4) constructing additional
bounds for permuting the order in which $A^{j_i}_i$ operators are applied, (5)
obtaining Frobenius norm upper bounds for Alice and Bob's strategies. We draw
the attention of the reader to applications of this framework in other games
with less regular structure.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12888" title="Abstract">arXiv:2311.12888</a> (cross-list from math.OC) [<a href="/pdf/2311.12888" title="Download PDF">pdf</a>, <a href="/format/2311.12888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Acceleration and Implicit Regularization in Gaussian Phase Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Maunu%2C+T">Tyler Maunu</a>, 
<a href="/search/math?searchtype=author&query=Molina-Fructuoso%2C+M">Martin Molina-Fructuoso</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
<p class="mathjax">We study accelerated optimization methods in the Gaussian phase retrieval
problem. In this setting, we prove that gradient methods with Polyak or
Nesterov momentum have similar implicit regularization to gradient descent.
This implicit regularization ensures that the algorithms remain in a nice
region, where the cost function is strongly convex and smooth despite being
nonconvex in general. This ensures that these accelerated methods achieve
faster rates of convergence than gradient descent. Experimental evidence
demonstrates that the accelerated methods converge faster than gradient descent
in practice.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12892" title="Abstract">arXiv:2311.12892</a> (cross-list from eess.IV) [<a href="/pdf/2311.12892" title="Download PDF">pdf</a>, <a href="/ps/2311.12892" title="Download PostScript">ps</a>, <a href="/format/2311.12892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IMJENSE: Scan-specific Implicit Representation for Joint Coil  Sensitivity and Image Estimation in Parallel MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Feng%2C+R">Ruimin Feng</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Q">Qing Wu</a>, 
<a href="/search/eess?searchtype=author&query=Feng%2C+J">Jie Feng</a>, 
<a href="/search/eess?searchtype=author&query=She%2C+H">Huajun She</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+C">Chunlei Liu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yuyao Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wei%2C+H">Hongjiang Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">Parallel imaging is a commonly used technique to accelerate magnetic
resonance imaging (MRI) data acquisition. Mathematically, parallel MRI
reconstruction can be formulated as an inverse problem relating the sparsely
sampled k-space measurements to the desired MRI image. Despite the success of
many existing reconstruction algorithms, it remains a challenge to reliably
reconstruct a high-quality image from highly reduced k-space measurements.
Recently, implicit neural representation has emerged as a powerful paradigm to
exploit the internal information and the physics of partially acquired data to
generate the desired object. In this study, we introduced IMJENSE, a
scan-specific implicit neural representation-based method for improving
parallel MRI reconstruction. Specifically, the underlying MRI image and coil
sensitivities were modeled as continuous functions of spatial coordinates,
parameterized by neural networks and polynomials, respectively. The weights in
the networks and coefficients in the polynomials were simultaneously learned
directly from sparsely acquired k-space measurements, without fully sampled
ground truth data for training. Benefiting from the powerful continuous
representation and joint estimation of the MRI image and coil sensitivities,
IMJENSE outperforms conventional image or k-space domain reconstruction
algorithms. With extremely limited calibration data, IMJENSE is more stable
than supervised calibrationless and calibration-based deep-learning methods.
Results show that IMJENSE robustly reconstructs the images acquired at
5$\mathbf{\times}$ and 6$\mathbf{\times}$ accelerations with only 4 or 8
calibration lines in 2D Cartesian acquisitions, corresponding to 22.0% and
19.5% undersampling rates. The high-quality results and scanning specificity
make the proposed method hold the potential for further accelerating the data
acquisition of parallel MRI.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12898" title="Abstract">arXiv:2311.12898</a> (cross-list from q-bio.QM) [<a href="/pdf/2311.12898" title="Download PDF">pdf</a>, <a href="/format/2311.12898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Assessment of PC-mer&#x27;s Performance in Alignment-Free Phylogenetic  Tree Construction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Abadi%2C+S+A+R">Saeedeh Akbari Rokn Abadi</a>, 
<a href="/search/q-bio?searchtype=author&query=Honarmand%2C+M">Melika Honarmand</a>, 
<a href="/search/q-bio?searchtype=author&query=Hajialinaghi%2C+A">Ali Hajialinaghi</a>, 
<a href="/search/q-bio?searchtype=author&query=Koohi%2C+S">Somayyeh Koohi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Mathematical Software (cs.MS)

</div>
<p class="mathjax">Background: Sequence comparison is essential in bioinformatics, serving
various purposes such as taxonomy, functional inference, and drug discovery.
The traditional method of aligning sequences for comparison is time-consuming,
especially with large datasets. To overcome this, alignment-free methods have
emerged as an alternative approach, prioritizing comparison scores over
alignment itself. These methods directly compare sequences without the need for
alignment. However, accurately representing the relationships between sequences
is a significant challenge in the design of these tools. Methods:One of the
alignment-free comparison approaches utilizes the frequency of fixed-length
substrings, known as K-mers, which serves as the foundation for many sequence
comparison methods. However, a challenge arises in these methods when
increasing the length of the substring (K), as it leads to an exponential
growth in the number of possible states. In this work, we explore the PC-mer
method, which utilizes a more limited set of words that experience slower
growth 2^k instead of 4^k compared to K. We conducted a comparison of sequences
and evaluated how the reduced input vector size influenced the performance of
the PC-mer method. Results: For the evaluation, we selected the Clustal Omega
method as our reference approach, alongside three alignment-free methods:
kmacs, FFP, and alfpy (word count). These methods also leverage the frequency
of K-mers. We applied all five methods to 9 datasets for comprehensive
analysis. The results were compared using phylogenetic trees and metrics such
as Robinson-Foulds and normalized quartet distance (nQD). Conclusion: Our
findings indicate that, unlike reducing the input features in other
alignment-independent methods, the PC-mer method exhibits competitive
performance when compared to the aforementioned methods especially when input
sequences are very varied.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12901" title="Abstract">arXiv:2311.12901</a> (cross-list from q-bio.QM) [<a href="/pdf/2311.12901" title="Download PDF">pdf</a>, <a href="/format/2311.12901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Microbes to Methane: AI-Based Predictive Modeling of Feed Additive  Efficacy in Dairy Cows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Altshuler%2C+Y">Yaniv Altshuler</a>, 
<a href="/search/q-bio?searchtype=author&query=Chebach%2C+T+C">Tzruya Calvao Chebach</a>, 
<a href="/search/q-bio?searchtype=author&query=Cohen%2C+S">Shalom Cohen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 51 pages, 24 figures, 11 tables, 93 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In an era of increasing pressure to achieve sustainable agriculture, the
optimization of livestock feed for enhancing yield and minimizing environmental
impact is a paramount objective. This study presents a pioneering approach
towards this goal, using rumen microbiome data to predict the efficacy of feed
additives in dairy cattle.
<br />We collected an extensive dataset that includes methane emissions from 2,190
Holstein cows distributed across 34 distinct sites. The cows were divided into
control and experimental groups in a double-blind, unbiased manner, accounting
for variables such as age, days in lactation, and average milk yield. The
experimental groups were administered one of four leading commercial feed
additives: Agolin, Kexxtone, Allimax, and Relyon. Methane emissions were
measured individually both before the administration of additives and over a
subsequent 12-week period. To develop our predictive model for additive
efficacy, rumen microbiome samples were collected from 510 cows from the same
herds prior to the study's onset. These samples underwent deep metagenomic
shotgun sequencing, yielding an average of 15.7 million reads per sample.
Utilizing innovative artificial intelligence techniques we successfully
estimated the efficacy of these feed additives across different farms. The
model's robustness was further confirmed through validation with independent
cohorts, affirming its generalizability and reliability.
<br />Our results underscore the transformative capability of using targeted feed
additive strategies to both optimize dairy yield and milk composition, and to
significantly reduce methane emissions. Specifically, our predictive model
demonstrates a scenario where its application could guide the assignment of
additives to farms where they are most effective. In doing so, we could achieve
an average potential reduction of over 27\% in overall emissions.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12904" title="Abstract">arXiv:2311.12904</a> (cross-list from math.AC) [<a href="/pdf/2311.12904" title="Download PDF">pdf</a>, <a href="/ps/2311.12904" title="Download PostScript">ps</a>, <a href="/format/2311.12904" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Compute Gr&#xf6;bner Bases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kera%2C+H">Hiroshi Kera</a>, 
<a href="/search/math?searchtype=author&query=Ishihara%2C+Y">Yuki Ishihara</a>, 
<a href="/search/math?searchtype=author&query=Kambe%2C+Y">Yuta Kambe</a>, 
<a href="/search/math?searchtype=author&query=Vaccon%2C+T">Tristan Vaccon</a>, 
<a href="/search/math?searchtype=author&query=Yokoyama%2C+K">Kazuhiro Yokoyama</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Commutative Algebra (math.AC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Solving a polynomial system, or computing an associated Gr\"obner basis, has
been a fundamental task in computational algebra. However, it is also known for
its notoriously expensive computational cost -- doubly exponential time
complexity in the number of variables in the worst case. In this paper, we
achieve for the first time Gr\"obner basis computation through the training of
a transformer. The training requires many pairs of a polynomial system and the
associated Gr\"obner basis, thus motivating us to address two novel algebraic
problems: random generation of Gr\"obner bases and the transformation of them
into non-Gr\"obner polynomial systems, termed as \textit{backward Gr\"obner
problem}. We resolve these problems with zero-dimensional radical ideals, the
ideals appearing in various applications. The experiments show that in the
five-variate case, the proposed dataset generation method is five orders of
magnitude faster than a naive approach, overcoming a crucial challenge in
learning to compute Gr\"obner bases.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12909" title="Abstract">arXiv:2311.12909</a> (cross-list from stat.ML) [<a href="/pdf/2311.12909" title="Download PDF">pdf</a>, <a href="/format/2311.12909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Sequential Ensemble Kalman Filtering using Distributed Arrays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Travelletti%2C+C">C&#xe9;dric Travelletti</a>, 
<a href="/search/stat?searchtype=author&query=Franke%2C+J">J&#xf6;rg Franke</a>, 
<a href="/search/stat?searchtype=author&query=Ginsbourger%2C+D">David Ginsbourger</a>, 
<a href="/search/stat?searchtype=author&query=Br%C3%B6nnimann%2C+S">Stefan Br&#xf6;nnimann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This work introduces a new, distributed implementation of the Ensemble Kalman
Filter (EnKF) that allows for non-sequential assimilation of large datasets in
high-dimensional problems. The traditional EnKF algorithm is computationally
intensive and exhibits difficulties in applications requiring interaction with
the background covariance matrix, prompting the use of methods like sequential
assimilation which can introduce unwanted consequences, such as dependency on
observation ordering. Our implementation leverages recent advancements in
distributed computing to enable the construction and use of the full model
error covariance matrix in distributed memory, allowing for single-batch
assimilation of all observations and eliminating order dependencies.
Comparative performance assessments, involving both synthetic and real-world
paleoclimatic reconstruction applications, indicate that the new,
non-sequential implementation outperforms the traditional, sequential one.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12917" title="Abstract">arXiv:2311.12917</a> (cross-list from q-bio.PE) [<a href="/pdf/2311.12917" title="Download PDF">pdf</a>, <a href="/format/2311.12917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Orchard: building large cancer phylogenies using stochastic  combinatorial search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Kulman%2C+E">E. Kulman</a>, 
<a href="/search/q-bio?searchtype=author&query=Kuang%2C+R">R. Kuang</a>, 
<a href="/search/q-bio?searchtype=author&query=Morris%2C+Q">Q. Morris</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Populations and Evolution (q-bio.PE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Phylogenies depicting the evolutionary history of genetically heterogeneous
subpopulations of cells from the same cancer i.e., cancer phylogenies, provide
useful insights about cancer development and inform treatment. Cancer
phylogenies can be reconstructed using data obtained from bulk DNA sequencing
of multiple tissue samples from the same cancer. We introduce Orchard, a fast
algorithm that reconstructs cancer phylogenies using point mutations detected
in bulk DNA sequencing data. Orchard constructs cancer phylogenies
progressively, one point mutation at a time, ultimately sampling complete
phylogenies from a posterior distribution implied by the bulk DNA data. Orchard
reconstructs more plausible phylogenies than state-of-the-art cancer phylogeny
reconstruction methods on 90 simulated cancers and 14 B-progenitor acute
lymphoblastic leukemias (B-ALLs). These results demonstrate that Orchard
accurately reconstructs cancer phylogenies with up to 300 mutations. We then
introduce a simple graph based clustering algorithm that uses a reconstructed
phylogeny to infer unique groups of mutations i.e., mutation clusters, that
characterize the genetic differences between cancer cell populations, and show
that this approach is competitive with state-of-the-art mutation clustering
methods.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12918" title="Abstract">arXiv:2311.12918</a> (cross-list from eess.IV) [<a href="/pdf/2311.12918" title="Download PDF">pdf</a>, <a href="/format/2311.12918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning-Based Real-Time Quality Control of Standard Video  Compression for Live Streaming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mortaheb%2C+M">Matin Mortaheb</a>, 
<a href="/search/eess?searchtype=author&query=Khojastepour%2C+M+A+A">Mohammad A. Amir Khojastepour</a>, 
<a href="/search/eess?searchtype=author&query=Chakradhar%2C+S+T">Srimat T. Chakradhar</a>, 
<a href="/search/eess?searchtype=author&query=Ulukus%2C+S">Sennur Ulukus</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2310.06857">arXiv:2310.06857</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI); Systems and Control (eess.SY)

</div>
<p class="mathjax">Ensuring high-quality video content for wireless users has become
increasingly vital. Nevertheless, maintaining a consistent level of video
quality faces challenges due to the fluctuating encoded bitrate, primarily
caused by dynamic video content, especially in live streaming scenarios. Video
compression is typically employed to eliminate unnecessary redundancies within
and between video frames, thereby reducing the required bandwidth for video
transmission. The encoded bitrate and the quality of the compressed video
depend on encoder parameters, specifically, the quantization parameter (QP).
Poor choices of encoder parameters can result in reduced bandwidth efficiency
and high likelihood of non-conformance. Non-conformance refers to the violation
of the peak signal-to-noise ratio (PSNR) constraint for an encoded video
segment. To address these issues, a real-time deep learning-based H.264
controller is proposed. This controller dynamically estimates the optimal
encoder parameters based on the content of a video chunk with minimal delay.
The objective is to maintain video quality in terms of PSNR above a specified
threshold while minimizing the average bitrate of the compressed video.
Experimental results, conducted on both QCIF dataset and a diverse range of
random videos from public datasets, validate the effectiveness of this
approach. Notably, it achieves improvements of up to 2.5 times in average
bandwidth usage compared to the state-of-the-art adaptive bitrate video
streaming, with a negligible non-conformance probability below $10^{-2}$.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12929" title="Abstract">arXiv:2311.12929</a> (cross-list from quant-ph) [<a href="/pdf/2311.12929" title="Download PDF">pdf</a>, <a href="/format/2311.12929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Learning for Quantum ML: Novel Training Technique for  Large-Scale Variational Quantum Circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Gharibyan%2C+H">Hrant Gharibyan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Su%2C+V">Vincent Su</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tepanyan%2C+H">Hayk Tepanyan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We present hierarchical learning, a novel variational architecture for
efficient training of large-scale variational quantum circuits. We test and
benchmark our technique for distribution loading with quantum circuit born
machines (QCBMs). With QCBMs, probability distributions are loaded into the
squared amplitudes of computational basis vectors represented by bitstrings.
Our key insight is to take advantage of the fact that the most significant
(qu)bits have a greater effect on the final distribution and can be learned
first. One can think of it as a generalization of layerwise learning, where
some parameters of the variational circuit are learned first to prevent the
phenomena of barren plateaus. We briefly review adjoint methods for computing
the gradient, in particular for loss functions that are not expectation values
of observables. We first compare the role of connectivity in the variational
ansatz for the task of loading a Gaussian distribution on nine qubits, finding
that 2D connectivity greatly outperforms qubits arranged on a line. Based on
our observations, we then implement this strategy on large-scale numerical
experiments with GPUs, training a QCBM to reproduce a 3-dimensional
multivariate Gaussian distribution on 27 qubits up to $\sim4\%$ total variation
distance. Though barren plateau arguments do not strictly apply here due to the
objective function not being tied to an observable, this is to our knowledge
the first practical demonstration of variational learning on large numbers of
qubits. We also demonstrate hierarchical learning as a resource-efficient way
to load distributions for existing quantum hardware (IBM's 7 and 27 qubit
devices) in tandem with Fire Opal optimizations.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12962" title="Abstract">arXiv:2311.12962</a> (cross-list from math.CO) [<a href="/pdf/2311.12962" title="Download PDF">pdf</a>, <a href="/ps/2311.12962" title="Download PostScript">ps</a>, <a href="/format/2311.12962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The analogue of overlap-freeness for the Fibonacci morphism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Currie%2C+J+D">James D. Currie</a>, 
<a href="/search/math?searchtype=author&query=Rampersad%2C+N">Narad Rampersad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
<p class="mathjax">A $4^-$-power is a non-empty word of the form $XXXX^-$, where $X^-$ is
obtained from $X$ by erasing the last letter. A binary word is called {\em
faux-bonacci} if it contains no $4^-$-powers, and no factor 11. We show that
faux-bonacci words bear the same relationship to the Fibonacci morphism that
overlap-free words bear to the Thue-Morse morphism. We prove the analogue of
Fife's Theorem for faux-bonacci words, and characterize the lexicographically
least and greatest infinite faux-bonacci words.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12975" title="Abstract">arXiv:2311.12975</a> (cross-list from math.OC) [<a href="/pdf/2311.12975" title="Download PDF">pdf</a>, <a href="/format/2311.12975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Approximate Dynamic Programming for the Ultra-fast Order  Dispatching Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dehghan%2C+A">Arash Dehghan</a>, 
<a href="/search/math?searchtype=author&query=Cevik%2C+M">Mucahit Cevik</a>, 
<a href="/search/math?searchtype=author&query=Bodur%2C+M">Merve Bodur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Same-Day Delivery (SDD) services aim to maximize the fulfillment of online
orders while minimizing delivery delays but are beset by operational
uncertainties such as those in order volumes and courier planning. Our work
aims to enhance the operational efficiency of SDD by focusing on the ultra-fast
Order Dispatching Problem (ODP), which involves matching and dispatching orders
to couriers within a centralized warehouse setting, and completing the delivery
within a strict timeline (e.g., within minutes). We introduce important
extensions to ultra-fast ODP such as order batching and explicit courier
assignments to provide a more realistic representation of dispatching
operations and improve delivery efficiency. As a solution method, we primarily
focus on NeurADP, a methodology that combines Approximate Dynamic Programming
(ADP) and Deep Reinforcement Learning (DRL), and our work constitutes the first
application of NeurADP outside of the ride-pool matching problem. NeurADP is
particularly suitable for ultra-fast ODP as it addresses complex one-to-many
matching and routing intricacies through a neural network-based VFA that
captures high-dimensional problem dynamics without requiring manual feature
engineering as in generic ADP methods. We test our proposed approach using four
distinct realistic datasets tailored for ODP and compare the performance of
NeurADP against myopic and DRL baselines by also making use of non-trivial
bounds to assess the quality of the policies. Our numerical results indicate
that the inclusion of order batching and courier queues enhances the efficiency
of delivery operations and that NeurADP significantly outperforms other
methods. Detailed sensitivity analysis with important parameters confirms the
robustness of NeurADP under different scenarios, including variations in
courier numbers, spatial setup, vehicle capacity, and permitted delay time.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13003" title="Abstract">arXiv:2311.13003</a> (cross-list from math.CO) [<a href="/pdf/2311.13003" title="Download PDF">pdf</a>, <a href="/ps/2311.13003" title="Download PostScript">ps</a>, <a href="/format/2311.13003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Critical exponent of binary words with few distinct palindromes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dvo%C5%99%C3%A1kov%C3%A1%2C+L">L&#x27;ubom&#xed;ra Dvo&#x159;&#xe1;kov&#xe1;</a>, 
<a href="/search/math?searchtype=author&query=Ochem%2C+P">Pascal Ochem</a>, 
<a href="/search/math?searchtype=author&query=Opo%C4%8Densk%C3%A1%2C+D">Daniela Opo&#x10d;ensk&#xe1;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We study infinite binary words that contain few distinct palindromes. In
particular, we classify such words according to their critical exponents. This
extends results by Fici and Zamboni [TCS 2013]. Interestingly, the words with
18 and 20 palindromes happen to be morphic images of the fixed point of the
morphism $\texttt{0}\mapsto\texttt{01}$, $\texttt{1}\mapsto\texttt{21}$,
$\texttt{2}\mapsto\texttt{0}$.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13010" title="Abstract">arXiv:2311.13010</a> (cross-list from math.ST) [<a href="/pdf/2311.13010" title="Download PDF">pdf</a>, <a href="/format/2311.13010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Catoni: Sharper Rates for Heavy-Tailed and Robust Mean Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gupta%2C+S">Shivam Gupta</a>, 
<a href="/search/math?searchtype=author&query=Hopkins%2C+S+B">Samuel B. Hopkins</a>, 
<a href="/search/math?searchtype=author&query=Price%2C+E">Eric Price</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Data Structures and Algorithms (cs.DS); Information Theory (cs.IT)

</div>
<p class="mathjax">We study the fundamental problem of estimating the mean of a $d$-dimensional
distribution with covariance $\Sigma \preccurlyeq \sigma^2 I_d$ given $n$
samples. When $d = 1$, Catoni \cite{catoni} showed an estimator with error
$(1+o(1)) \cdot \sigma \sqrt{\frac{2 \log \frac{1}{\delta}}{n}}$, with
probability $1 - \delta$, matching the Gaussian error rate. For $d&gt;1$, a
natural estimator outputs the center of the minimum enclosing ball of
one-dimensional confidence intervals to achieve a $1-\delta$ confidence radius
of $\sqrt{\frac{2 d}{d+1}} \cdot \sigma \left(\sqrt{\frac{d}{n}} +
\sqrt{\frac{2 \log \frac{1}{\delta}}{n}}\right)$, incurring a
$\sqrt{\frac{2d}{d+1}}$-factor loss over the Gaussian rate. When the
$\sqrt{\frac{d}{n}}$ term dominates by a $\sqrt{\log \frac{1}{\delta}}$ factor,
\cite{lee2022optimal-highdim} showed an improved estimator matching the
Gaussian rate. This raises a natural question: is the Gaussian rate achievable
in general? Or is the $\sqrt{\frac{2 d}{d+1}}$ loss \emph{necessary} when the
$\sqrt{\frac{2 \log \frac{1}{\delta}}{n}}$ term dominates?
<br />We show that the answer to both these questions is \emph{no} -- we show that
\emph{some} constant-factor loss over the Gaussian rate is necessary, but
construct an estimator that improves over the above naive estimator by a
constant factor. We also consider robust estimation, where an adversary is
allowed to corrupt an $\epsilon$-fraction of samples arbitrarily: in this case,
we show that the above strategy of combining one-dimensional estimates and
incurring the $\sqrt{\frac{2d}{d+1}}$-factor \emph{is} optimal in the
infinite-sample limit.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13016" title="Abstract">arXiv:2311.13016</a> (cross-list from eess.IV) [<a href="/pdf/2311.13016" title="Download PDF">pdf</a>, <a href="/format/2311.13016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image-Based Soil Organic Carbon Remote Sensing from Satellite Images  with Fourier Neural Operator and Structural Similarity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wong%2C+K+C+L">Ken C. L. Wong</a>, 
<a href="/search/eess?searchtype=author&query=Klein%2C+L">Levente Klein</a>, 
<a href="/search/eess?searchtype=author&query=da+Silva%2C+A+F">Ademir Ferreira da Silva</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Hongzhi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Singh%2C+J">Jitendra Singh</a>, 
<a href="/search/eess?searchtype=author&query=Syeda-Mahmood%2C+T">Tanveer Syeda-Mahmood</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was accepted by the 2023 IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Soil organic carbon (SOC) sequestration is the transfer and storage of
atmospheric carbon dioxide in soils, which plays an important role in climate
change mitigation. SOC concentration can be improved by proper land use, thus
it is beneficial if SOC can be estimated at a regional or global scale. As
multispectral satellite data can provide SOC-related information such as
vegetation and soil properties at a global scale, estimation of SOC through
satellite data has been explored as an alternative to manual soil sampling.
Although existing studies show promising results, they are mainly based on
pixel-based approaches with traditional machine learning methods, and
convolutional neural networks (CNNs) are uncommon. To study the use of CNNs on
SOC remote sensing, here we propose the FNO-DenseNet based on the Fourier
neural operator (FNO). By combining the advantages of the FNO and DenseNet, the
FNO-DenseNet outperformed the FNO in our experiments with hundreds of times
fewer parameters. The FNO-DenseNet also outperformed a pixel-based random
forest by 18% in the mean absolute percentage error.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13033" title="Abstract">arXiv:2311.13033</a> (cross-list from math.OC) [<a href="/pdf/2311.13033" title="Download PDF">pdf</a>, <a href="/ps/2311.13033" title="Download PostScript">ps</a>, <a href="/format/2311.13033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Invariance Proximity: Closed-Form Error Bounds for Finite-Dimensional  Koopman-Based Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Haseli%2C+M">Masih Haseli</a>, 
<a href="/search/math?searchtype=author&query=Cort%C3%A9s%2C+J">Jorge Cort&#xe9;s</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY); Dynamical Systems (math.DS)

</div>
<p class="mathjax">A popular way to approximate the Koopman operator's action on a
finite-dimensional subspace of functions is via orthogonal projections. The
quality of the projected model directly depends on the selected subspace,
specifically on how close it is to being invariant under the Koopman operator.
The notion of invariance proximity provides a tight upper bound on the
worst-case relative prediction error of the finite-dimensional model. However,
its direct calculation is computationally challenging. This paper leverages the
geometric structure behind the definition of invariance proximity to provide a
closed-form expression in terms of Jordan principal angles on general inner
product spaces. Unveiling this connection allows us to exploit specific
isomorphisms to circumvent the computational challenges associated with spaces
of functions and enables the use of existing efficient numerical routines to
compute invariance proximity.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13046" title="Abstract">arXiv:2311.13046</a> (cross-list from econ.GN) [<a href="/pdf/2311.13046" title="Download PDF">pdf</a>, <a href="/ps/2311.13046" title="Download PostScript">ps</a>, <a href="/format/2311.13046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do we listen to what we are told? An empirical study on human behaviour  during the COVID-19 pandemic: neural networks vs. regression analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Heluo%2C+Y">Yuxi Heluo</a>, 
<a href="/search/econ?searchtype=author&query=Wang%2C+K">Kexin Wang</a>, 
<a href="/search/econ?searchtype=author&query=Robson%2C+C+W">Charles W. Robson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Economics (econ.GN)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Applications (stat.AP)

</div>
<p class="mathjax">In this work, we contribute the first visual open-source empirical study on
human behaviour during the COVID-19 pandemic, in order to investigate how
compliant a general population is to mask-wearing-related public-health policy.
Object-detection-based convolutional neural networks, regression analysis and
multilayer perceptrons are combined to analyse visual data of the Viennese
public during 2020. We find that mask-wearing-related government regulations
and public-transport announcements encouraged correct mask-wearing-behaviours
during the COVID-19 pandemic. Importantly, changes in announcement and
regulation contents led to heterogeneous effects on people's behaviour.
Comparing the predictive power of regression analysis and neural networks, we
demonstrate that the latter produces more accurate predictions of population
reactions during the COVID-19 pandemic. Our use of regression modelling also
allows us to unearth possible causal pathways underlying societal behaviour.
Since our findings highlight the importance of appropriate communication
contents, our results will facilitate more effective non-pharmaceutical
interventions to be developed in future. Adding to the literature, we
demonstrate that regression modelling and neural networks are not mutually
exclusive but instead complement each other.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13052" title="Abstract">arXiv:2311.13052</a> (cross-list from eess.IV) [<a href="/pdf/2311.13052" title="Download PDF">pdf</a>, <a href="/format/2311.13052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Novel OCT mosaicking pipeline with Feature- and Pixel-based registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jiacheng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+D">Dewei Hu</a>, 
<a href="/search/eess?searchtype=author&query=Tao%2C+Y+K">Yuankai K. Tao</a>, 
<a href="/search/eess?searchtype=author&query=Oguz%2C+I">Ipek Oguz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">High-resolution Optical Coherence Tomography (OCT) images are crucial for
ophthalmology studies but are limited by their relatively narrow field of view
(FoV). Image mosaicking is a technique for aligning multiple overlapping images
to obtain a larger FoV. Current mosaicking pipelines often struggle with
substantial noise and considerable displacement between the input sub-fields.
In this paper, we propose a versatile pipeline for stitching multi-view
OCT/OCTA \textit{en face} projection images. Our method combines the strengths
of learning-based feature matching and robust pixel-based registration to align
multiple images effectively. Furthermore, we advance the application of a
trained foundational model, Segment Anything Model (SAM), to validate
mosaicking results in an unsupervised manner. The efficacy of our pipeline is
validated using an in-house dataset and a large public dataset, where our
method shows superior performance in terms of both accuracy and computational
efficiency. We also made our evaluation tool for image mosaicking and the
corresponding pipeline publicly available at
\url{https://github.com/MedICL-VU/OCT-mosaicking}.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13059" title="Abstract">arXiv:2311.13059</a> (cross-list from stat.ML) [<a href="/pdf/2311.13059" title="Download PDF">pdf</a>, <a href="/ps/2311.13059" title="Download PostScript">ps</a>, <a href="/format/2311.13059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A note on estimating the dimension from a random geometric graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Atamanchuk%2C+C">Caelan Atamanchuk</a>, 
<a href="/search/stat?searchtype=author&query=Devroye%2C+L">Luc Devroye</a>, 
<a href="/search/stat?searchtype=author&query=Lugosi%2C+G">Gabor Lugosi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
<p class="mathjax">Let $G_n$ be a random geometric graph with vertex set $[n]$ based on $n$
i.i.d.\ random vectors $X_1,\ldots,X_n$ drawn from an unknown density $f$ on
$\R^d$. An edge $(i,j)$ is present when $\|X_i -X_j\| \le r_n$, for a given
threshold $r_n$ possibly depending upon $n$, where $\| \cdot \|$ denotes
Euclidean distance. We study the problem of estimating the dimension $d$ of the
underlying space when we have access to the adjacency matrix of the graph but
do not know $r_n$ or the vectors $X_i$. The main result of the paper is that
there exists an estimator of $d$ that converges to $d$ in probability as $n \to
\infty$ for all densities with $\int f^5 &lt; \infty$ whenever $n^{3/2} r_n^d \to
\infty$ and $r_n = o(1)$. The conditions allow very sparse graphs since when
$n^{3/2} r_n^d \to 0$, the graph contains isolated edges only, with high
probability. We also show that, without any condition on the density, a
consistent estimator of $d$ exists when $n r_n^d \to \infty$ and $r_n = o(1)$.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13094" title="Abstract">arXiv:2311.13094</a> (cross-list from math.OC) [<a href="/pdf/2311.13094" title="Download PDF">pdf</a>, <a href="/ps/2311.13094" title="Download PostScript">ps</a>, <a href="/format/2311.13094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Newton-CG methods for nonconvex unconstrained optimization with H&#xf6;lder  continuous Hessian
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=He%2C+C">Chuan He</a>, 
<a href="/search/math?searchtype=author&query=Lu%2C+Z">Zhaosong Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2301.03139">arXiv:2301.03139</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper we consider a nonconvex unconstrained optimization problem
minimizing a twice differentiable objective function with H\"older continuous
Hessian. Specifically, we first propose a Newton-conjugate gradient (Newton-CG)
method for finding an approximate first-order stationary point (FOSP) of this
problem, assuming the associated the H\"older parameters are explicitly known.
Then we develop a parameter-free Newton-CG method without requiring any prior
knowledge of these parameters. To the best of our knowledge, this method is the
first parameter-free second-order method achieving the best-known iteration and
operation complexity for finding an approximate FOSP of this problem.
Furthermore, we propose a Newton-CG method for finding an approximate
second-order stationary point (SOSP) of the considered problem with high
probability and establish its iteration and operation complexity. Finally, we
present preliminary numerical results to demonstrate the superior practical
performance of our parameter-free Newton-CG method over a well-known
regularized Newton method.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13100" title="Abstract">arXiv:2311.13100</a> (cross-list from eess.IV) [<a href="/pdf/2311.13100" title="Download PDF">pdf</a>, <a href="/format/2311.13100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Measurement of Pericoronary Adipose Tissue Attenuation and  Volume in CT Angiography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+A+M">Andrew M. Nguyen</a>, 
<a href="/search/eess?searchtype=author&query=Mathai%2C+T+S">Tejas Sudharshan Mathai</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+L">Liangchen Liu</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+J">Jianfei Liu</a>, 
<a href="/search/eess?searchtype=author&query=Summers%2C+R+M">Ronald M. Summers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures, IEE ISBI2024 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Pericoronary adipose tissue (PCAT) is the deposition of fat in the vicinity
of the coronary arteries. It is an indicator of coronary inflammation and
associated with coronary artery disease. Non-invasive coronary CT angiography
(CCTA) is presently used to obtain measures of the thickness, volume, and
attenuation of fat deposition. However, prior works solely focus on measuring
PCAT using semi-automated approaches at the right coronary artery (RCA) over
the left coronary artery (LCA). In this pilot work, we developed a fully
automated approach for the measurement of PCAT mean attenuation and volume in
the region around both coronary arteries. First, we used a large subset of
patients from the public ImageCAS dataset (n = 735) to train a 3D full
resolution nnUNet to segment LCA and RCA. Then, we automatically measured PCAT
in the surrounding arterial regions. We evaluated our method on a held-out test
set of patients (n = 183) from the same dataset. A mean Dice score of 83% and
PCAT attenuation of -73.81 $\pm$ 12.69 HU was calculated for the RCA, while a
mean Dice score of 81% and PCAT attenuation of -77.51 $\pm$ 7.94 HU was
computed for the LCA. To the best of our knowledge, we are the first to develop
a fully automated method to measure PCAT attenuation and volume at both the RCA
and LCA. Our work underscores how automated PCAT measurement holds promise as a
biomarker for identification of inflammation and cardiac disease.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13107" title="Abstract">arXiv:2311.13107</a> (cross-list from quant-ph) [<a href="/pdf/2311.13107" title="Download PDF">pdf</a>, <a href="/format/2311.13107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Powerful Quantum Circuit Resizing with Resource Efficient Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Niu%2C+S">Siyuan Niu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hashim%2C+A">Akel Hashim</a>, 
<a href="/search/quant-ph?searchtype=author&query=Iancu%2C+C">Costin Iancu</a>, 
<a href="/search/quant-ph?searchtype=author&query=de+Jong%2C+W+A">Wibe Albert de Jong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Younis%2C+E">Ed Younis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">In the noisy intermediate-scale quantum era, mid-circuit measurement and
reset operations facilitate novel circuit optimization strategies by reducing a
circuit's qubit count in a method called resizing. This paper introduces two
such algorithms. The first one leverages gate-dependency rules to reduce qubit
count by 61.6% or 45.3% when optimizing depth as well. Based on numerical
instantiation and synthesis, the second algorithm finds resizing opportunities
in previously unresizable circuits via dependency rules and other
state-of-the-art tools. This resizing algorithm reduces qubit count by 20.7% on
average for these previously impossible-to-resize circuits.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13144" title="Abstract">arXiv:2311.13144</a> (cross-list from eess.IV) [<a href="/pdf/2311.13144" title="Download PDF">pdf</a>, <a href="/format/2311.13144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single Image Compressed Sensing MRI via a Self-Supervised Deep Denoising  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lorenzana%2C+M+B">Marlon Bran Lorenzana</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+F">Feng Liu</a>, 
<a href="/search/eess?searchtype=author&query=Chandra%2C+S+S">Shekhar S. Chandra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures, 2 tables, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Popular methods in compressed sensing (CS) are dependent on deep learning
(DL), where large amounts of data are used to train non-linear reconstruction
models. However, ensuring generalisability over and access to multiple datasets
is challenging to realise for real-world applications. To address these
concerns, this paper proposes a single image, self-supervised (SS) CS-MRI
framework that enables a joint deep and sparse regularisation of CS artefacts.
The approach effectively dampens structured CS artefacts, which can be
difficult to remove assuming sparse reconstruction, or relying solely on the
inductive biases of CNN to produce noise-free images. Image quality is thereby
improved compared to either approach alone. Metrics are evaluated using
Cartesian 1D masks on a brain and knee dataset, with PSNR improving by 2-4dB on
average.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13155" title="Abstract">arXiv:2311.13155</a> (cross-list from math.AP) [<a href="/pdf/2311.13155" title="Download PDF">pdf</a>, <a href="/format/2311.13155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A threshold-type algorithm to the gradient flow of the Canham-Helfrich  functional
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ishi%2C+K">Katsuyuki Ishi</a>, 
<a href="/search/math?searchtype=author&query=Kohsaka%2C+Y">Yoshihito Kohsaka</a>, 
<a href="/search/math?searchtype=author&query=Miyake%2C+N">Nobuhito Miyake</a>, 
<a href="/search/math?searchtype=author&query=Sakakibara%2C+K">Koya Sakakibara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">We propose a threshold-type algorithm to the $L^2$-gradient flow of the
Canham-Helfrich functional generalized to $\mathbb{R}^N$. The algorithm to the
Willmore flow is derived as a special case in $\mathbb{R}^2$ or $\mathbb{R}^3$.
This algorithm is constructed based on an asymptotic expansion of the solution
to the initial value problem for a fourth order linear parabolic partial
differential equation whose initial data is the indicator function on the
compact set $\Omega_0$. The crucial points are to prove that the boundary
$\partial\Omega_1$ of the new set $\Omega_1$ generated by our algorithm is
included in $O(t)$-neighborhood from $\partial\Omega_0$ for small time $t&gt;0$
and to show that the derivative of the threshold function in the normal
direction for $\partial\Omega_0$ is far from zero in the small time interval.
Finally, numerical examples of planar curves governed by the Willmore flow are
provided by using our threshold-type algorithm.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13177" title="Abstract">arXiv:2311.13177</a> (cross-list from physics.med-ph) [<a href="/pdf/2311.13177" title="Download PDF">pdf</a>, <a href="/format/2311.13177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Volumetric Reconstruction Resolves Off-Resonance Artifacts in Static and  Dynamic PROPELLER MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Ghosh%2C+A">Annesha Ghosh</a>, 
<a href="/search/physics?searchtype=author&query=Wetzstein%2C+G">Gordon Wetzstein</a>, 
<a href="/search/physics?searchtype=author&query=Pilanci%2C+M">Mert Pilanci</a>, 
<a href="/search/physics?searchtype=author&query=Fridovich-Keil%2C+S">Sara Fridovich-Keil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is available at <a href="https://github.com/sarafridov/volumetric-propeller">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Off-resonance artifacts in magnetic resonance imaging (MRI) are visual
distortions that occur when the actual resonant frequencies of spins within the
imaging volume differ from the expected frequencies used to encode spatial
information. These discrepancies can be caused by a variety of factors,
including magnetic field inhomogeneities, chemical shifts, or susceptibility
differences within the tissues. Such artifacts can manifest as blurring,
ghosting, or misregistration of the reconstructed image, and they often
compromise its diagnostic quality. We propose to resolve these artifacts by
lifting the 2D MRI reconstruction problem to 3D, introducing an additional
"spectral" dimension to model this off-resonance. Our approach is inspired by
recent progress in modeling radiance fields, and is capable of reconstructing
both static and dynamic MR images as well as separating fat and water, which is
of independent clinical interest. We demonstrate our approach in the context of
PROPELLER (Periodically Rotated Overlapping ParallEL Lines with Enhanced
Reconstruction) MRI acquisitions, which are popular for their robustness to
motion artifacts. Our method operates in a few minutes on a single GPU, and to
our knowledge is the first to correct for chemical shift in gradient echo
PROPELLER MRI reconstruction without additional measurements or pretraining
data.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13180" title="Abstract">arXiv:2311.13180</a> (cross-list from stat.ML) [<a href="/pdf/2311.13180" title="Download PDF">pdf</a>, <a href="/format/2311.13180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provably Efficient High-Dimensional Bandit Learning with Batched  Feedbacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Fan%2C+J">Jianqing Fan</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+Z">Zhaoran Wang</a>, 
<a href="/search/stat?searchtype=author&query=Yang%2C+Z">Zhuoran Yang</a>, 
<a href="/search/stat?searchtype=author&query=Ye%2C+C">Chenlu Ye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We study high-dimensional multi-armed contextual bandits with batched
feedback where the $T$ steps of online interactions are divided into $L$
batches. In specific, each batch collects data according to a policy that
depends on previous batches and the rewards are revealed only at the end of the
batch. Such a feedback structure is popular in applications such as
personalized medicine and online advertisement, where the online data often do
not arrive in a fully serial manner. We consider high-dimensional and linear
settings where the reward function of the bandit model admits either a sparse
or low-rank structure and ask how small a number of batches are needed for a
comparable performance with fully dynamic data in which $L = T$. For these
settings, we design a provably sample-efficient algorithm which achieves a $
\mathcal{\tilde O}(s_0^2 \log^2 T)$ regret in the sparse case and $
\mathcal{\tilde O} ( r ^2 \log^2 T)$ regret in the low-rank case, using only $L
= \mathcal{O}( \log T)$ batches. Here $s_0$ and $r$ are the sparsity and rank
of the reward parameter in sparse and low-rank cases, respectively, and $
\mathcal{\tilde O}(\cdot)$ omits logarithmic factors involving the feature
dimensions. In other words, our algorithm achieves regret bounds comparable to
those in fully sequential setting with only $\mathcal{O}( \log T)$ batches. Our
algorithm features a novel batch allocation method that adjusts the batch sizes
according to the estimation accuracy within each batch and cumulative regret.
Furthermore, we also conduct experiments with synthetic and real-world data to
validate our theory.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13261" title="Abstract">arXiv:2311.13261</a> (cross-list from eess.IV) [<a href="/pdf/2311.13261" title="Download PDF">pdf</a>, <a href="/ps/2311.13261" title="Download PostScript">ps</a>, <a href="/format/2311.13261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Immunohistochemistry guided segmentation of benign epithelial cells, in  situ lesions, and invasive epithelial cells in breast cancer slides
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=H%C3%B8ib%C3%B8%2C+M">Maren H&#xf8;ib&#xf8;</a>, 
<a href="/search/eess?searchtype=author&query=Pedersen%2C+A">Andr&#xe9; Pedersen</a>, 
<a href="/search/eess?searchtype=author&query=Dale%2C+V+G">Vibeke Grotnes Dale</a>, 
<a href="/search/eess?searchtype=author&query=Berget%2C+S+M">Sissel Marie Berget</a>, 
<a href="/search/eess?searchtype=author&query=Ytterhus%2C+B">Borgny Ytterhus</a>, 
<a href="/search/eess?searchtype=author&query=Lindskog%2C+C">Cecilia Lindskog</a>, 
<a href="/search/eess?searchtype=author&query=Wik%2C+E">Elisabeth Wik</a>, 
<a href="/search/eess?searchtype=author&query=Akslen%2C+L+A">Lars A. Akslen</a>, 
<a href="/search/eess?searchtype=author&query=Reinertsen%2C+I">Ingerid Reinertsen</a>, 
<a href="/search/eess?searchtype=author&query=Smistad%2C+E">Erik Smistad</a>, 
<a href="/search/eess?searchtype=author&query=Valla%2C+M">Marit Valla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 6 figures. Submitted to a scientific journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Digital pathology enables automatic analysis of histopathological sections
using artificial intelligence (AI). Automatic evaluation could improve
diagnostic efficiency and help find associations between morphological features
and clinical outcome. For development of such prediction models, identifying
invasive epithelial cells, and separating these from benign epithelial cells
and in situ lesions would be the first step. In this study, we aimed to develop
an AI model for segmentation of epithelial cells in sections from breast
cancer. We generated epithelial ground truth masks by restaining hematoxylin
and eosin (HE) sections with cytokeratin (CK) AE1/AE3, and by pathologists'
annotations. HE/CK image pairs were used to train a convolutional neural
network, and data augmentation was used to make the model more robust. Tissue
microarrays (TMAs) from 839 patients, and whole slide images from two patients
were used for training and evaluation of the models. The sections were derived
from four cohorts of breast cancer patients. TMAs from 21 patients from a fifth
cohort was used as a second test set. In quantitative evaluation, a mean Dice
score of 0.70, 0.79, and 0.75 for invasive epithelial cells, benign epithelial
cells, and in situ lesions, respectively, were achieved. In qualitative scoring
(0-5) by pathologists, results were best for all epithelium and invasive
epithelium, with scores of 4.7 and 4.4. Scores for benign epithelium and in
situ lesions were 3.7 and 2.0. The proposed model segmented epithelial cells in
HE stained breast cancer slides well, but further work is needed for accurate
division between the classes. Immunohistochemistry, together with pathologists'
annotations, enabled the creation of accurate ground truths. The model is made
freely available in FastPathology and the code is available at
https://github.com/AICAN-Research/breast-epithelium-segmentation
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13265" title="Abstract">arXiv:2311.13265</a> (cross-list from stat.ML) [<a href="/pdf/2311.13265" title="Download PDF">pdf</a>, <a href="/format/2311.13265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved identification accuracy in equation learning via comprehensive  $\boldsymbol{R^2}$-elimination and Bayesian model selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Nickelsen%2C+D">Daniel Nickelsen</a>, 
<a href="/search/stat?searchtype=author&query=Bah%2C+B">Bubacarr Bah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages main text and 11 pages appendix, accepted in Transactions on Machine Learning Research (TMLR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
<p class="mathjax">In the field of equation learning, exhaustively considering all possible
equations derived from a basis function dictionary is infeasible. Sparse
regression and greedy algorithms have emerged as popular approaches to tackle
this challenge. However, the presence of multicollinearity poses difficulties
for sparse regression techniques, and greedy steps may inadvertently exclude
terms of the true equation, leading to reduced identification accuracy. In this
article, we present an approach that strikes a balance between
comprehensiveness and efficiency in equation learning. Inspired by stepwise
regression, our approach combines the coefficient of determination, $R^2$, and
the Bayesian model evidence, $p(\boldsymbol y|\mathcal M)$, in a novel way. Our
procedure is characterized by a comprehensive search with just a minor
reduction of the model space at each iteration step. With two flavors of our
approach and the adoption of $p(\boldsymbol y|\mathcal M)$ for bi-directional
stepwise regression, we present a total of three new avenues for equation
learning. Through three extensive numerical experiments involving random
polynomials and dynamical systems, we compare our approach against four
state-of-the-art methods and two standard approaches. The results demonstrate
that our comprehensive search approach surpasses all other methods in terms of
identification accuracy. In particular, the second flavor of our approach
establishes an efficient overfitting penalty solely based on $R^2$, which
achieves highest rates of exact equation recovery.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13319" title="Abstract">arXiv:2311.13319</a> (cross-list from eess.IV) [<a href="/pdf/2311.13319" title="Download PDF">pdf</a>, <a href="/format/2311.13319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning for Vascular Segmentation and Applications in Phase  Contrast Tomography Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yagis%2C+E">Ekin Yagis</a>, 
<a href="/search/eess?searchtype=author&query=Aslani%2C+S">Shahab Aslani</a>, 
<a href="/search/eess?searchtype=author&query=Jain%2C+Y">Yashvardhan Jain</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Y">Yang Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Rahmani%2C+S">Shahrokh Rahmani</a>, 
<a href="/search/eess?searchtype=author&query=Brunet%2C+J">Joseph Brunet</a>, 
<a href="/search/eess?searchtype=author&query=Bellier%2C+A">Alexandre Bellier</a>, 
<a href="/search/eess?searchtype=author&query=Werlein%2C+C">Christopher Werlein</a>, 
<a href="/search/eess?searchtype=author&query=Ackermann%2C+M">Maximilian Ackermann</a>, 
<a href="/search/eess?searchtype=author&query=Jonigk%2C+D">Danny Jonigk</a>, 
<a href="/search/eess?searchtype=author&query=Tafforeau%2C+P">Paul Tafforeau</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+P+D">Peter D Lee</a>, 
<a href="/search/eess?searchtype=author&query=Walsh%2C+C">Claire Walsh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Automated blood vessel segmentation is vital for biomedical imaging, as
vessel changes indicate many pathologies. Still, precise segmentation is
difficult due to the complexity of vascular structures, anatomical variations
across patients, the scarcity of annotated public datasets, and the quality of
images. We present a thorough literature review, highlighting the state of
machine learning techniques across diverse organs. Our goal is to provide a
foundation on the topic and identify a robust baseline model for application to
vascular segmentation in a new imaging modality, Hierarchical Phase Contrast
Tomography (HiP CT). Introduced in 2020 at the European Synchrotron Radiation
Facility, HiP CT enables 3D imaging of complete organs at an unprecedented
resolution of ca. 20mm per voxel, with the capability for localized zooms in
selected regions down to 1mm per voxel without sectioning. We have created a
training dataset with double annotator validated vascular data from three
kidneys imaged with HiP CT in the context of the Human Organ Atlas Project.
Finally, utilising the nnU Net model, we conduct experiments to assess the
models performance on both familiar and unseen samples, employing vessel
specific metrics. Our results show that while segmentations yielded reasonably
high scores such as clDice values ranging from 0.82 to 0.88, certain errors
persisted. Large vessels that collapsed due to the lack of hydrostatic pressure
(HiP CT is an ex vivo technique) were segmented poorly. Moreover, decreased
connectivity in finer vessels and higher segmentation errors at vessel
boundaries were observed. Such errors obstruct the understanding of the
structures by interrupting vascular tree connectivity. Through our review and
outputs, we aim to set a benchmark for subsequent model evaluations using
various modalities, especially with the HiP CT imaging database.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13337" title="Abstract">arXiv:2311.13337</a> (cross-list from q-bio.NC) [<a href="/pdf/2311.13337" title="Download PDF">pdf</a>, <a href="/format/2311.13337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vast TVB parameter space exploration: A Modular Framework for  Accelerating the Multi-Scale Simulation of Human Brain Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=van+der+Vlag%2C+M">Michiel van der Vlag</a>, 
<a href="/search/q-bio?searchtype=author&query=Kusch%2C+L">Lionel Kusch</a>, 
<a href="/search/q-bio?searchtype=author&query=Destexhe%2C+A">Alain Destexhe</a>, 
<a href="/search/q-bio?searchtype=author&query=Jirsa%2C+V">Viktor Jirsa</a>, 
<a href="/search/q-bio?searchtype=author&query=Diaz-Pier%2C+S">Sandra Diaz-Pier</a>, 
<a href="/search/q-bio?searchtype=author&query=Goldman%2C+J+S">Jennifer S. Goldman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Global neural dynamics emerge from multi-scale brain structures, with neurons
communicating through synapses to form transiently communicating networks.
Network activity arises from intercellular communication that depends on the
structure of connectome tracts and local connection, intracellular signalling
cascades, and the extracellular molecular milieu that regulate cellular
properties. Multi-scale models of brain function have begun to directly link
the emergence of global brain dynamics in conscious and unconscious brain
states to microscopic changes at the level of cells. In particular, AdEx
mean-field models representing statistical properties of local populations of
neurons have been connected following human tractography data to represent
multi-scale neural phenomena in simulations using The Virtual Brain (TVB).
While mean-field models can be run on personal computers for short simulations,
or in parallel on high-performance computing (HPC) architectures for longer
simulations and parameter scans, the computational burden remains high and vast
areas of the parameter space remain unexplored. In this work, we report that
our TVB-HPC framework, a modular set of methods used here to implement the
TVB-AdEx model for GPU and analyze emergent dynamics, notably accelerates
simulations and substantially reduces computational resource requirements. The
framework preserves the stability and robustness of the TVB-AdEx model, thus
facilitating finer resolution exploration of vast parameter spaces as well as
longer simulations previously near impossible to perform. Given that simulation
and analysis toolkits are made public as open-source packages, our framework
serves as a template onto which other models can be easily scripted and
personalized datasets can be used for studies of inter-individual variability
of parameters related to functional brain dynamics.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13378" title="Abstract">arXiv:2311.13378</a> (cross-list from eess.IV) [<a href="/pdf/2311.13378" title="Download PDF">pdf</a>, <a href="/format/2311.13378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Point Projection Mapping System for Tracking, Registering, Labeling and  Validating Optical Tissue Measurements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Feenstra%2C+L">Lianne Feenstra</a>, 
<a href="/search/eess?searchtype=author&query=van+der+Stel%2C+S+D">Stefan D.van der Stel</a>, 
<a href="/search/eess?searchtype=author&query=Da+Silva+Guimaraes%2C+M">Marcos Da Silva Guimaraes</a>, 
<a href="/search/eess?searchtype=author&query=Ruers%2C+T+J+M">Theo J.M Ruers</a>, 
<a href="/search/eess?searchtype=author&query=Dashtbozorg%2C+B">Behdad Dashtbozorg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Validation of newly developed optical tissue sensing techniques for tumor
detection during cancer surgery requires an accurate correlation with
histological results. Additionally, such accurate correlation facilitates
precise data labeling for developing high-performance machine-learning tissue
classification models. In this paper, a newly developed Point Projection
Mapping system will be introduced, which allows non-destructive tracking of the
measurement locations on tissue specimens. Additionally, a framework for
accurate registration, validation, and labeling with histopathology results is
proposed and validated on a case study. The proposed framework provides a more
robust and accurate method for tracking and validation of optical tissue
sensing techniques, which saves time and resources compared to conventional
techniques available.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13397" title="Abstract">arXiv:2311.13397</a> (cross-list from eess.AS) [<a href="/pdf/2311.13397" title="Download PDF">pdf</a>, <a href="/format/2311.13397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial Audio and Individualized HRTFs using a Convolutional Neural  Network (CNN)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pirard%2C+L">Ludovic Pirard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Spatial audio and 3-Dimensional sound rendering techniques play a pivotal and
essential role in immersive audio experiences. Head-Related Transfer Functions
(HRTFs) are acoustic filters which represent how sound interacts with an
individual's unique head and ears anatomy. The use of HRTFs compliant to the
subjects anatomical traits is crucial to ensure a personalized and unique
spatial experience. This work proposes the implementation of an HRTF
individualization method based on anthropometric features automatically
extracted from ear images using a Convolutional Neural Network (CNN). Firstly,
a CNN is implemented and tested to assess the performance of machine learning
on positioning landmarks on ear images. The I-BUG dataset, containing ear
images with corresponding 55 landmarks, was used to train and test the neural
network. Subsequently, 12 relevant landmarks were selected to correspond to 7
specific anthropometric measurements established by the HUTUBS database. These
landmarks serve as a reference for distance computation in pixels in order to
retrieve the anthropometric measurements from the ear images. Once the 7
distances in pixels are extracted from the ear image, they are converted in
centimetres using conversion factors, a best match method vector is implemented
computing the Euclidean distance for each set in a database of 116 ears with
their corresponding 7 anthropometric measurements provided by the HUTUBS
database. The closest match of anthropometry can be identified and the
corresponding set of HRTFs can be obtained for personnalized use. The method is
evaluated in its validity instead of the accuracy of the results. The
conceptual scope of each stage has been verified and substantiated to function
correctly. The various steps and the available elements in the process are
reviewed and challenged to define a greater algorithm entity designed for the
desired task.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13431" title="Abstract">arXiv:2311.13431</a> (cross-list from stat.ML) [<a href="/pdf/2311.13431" title="Download PDF">pdf</a>, <a href="/format/2311.13431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extracting individual variable information for their decoupling, direct  mutual information and multi-feature Granger causality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Duda%2C+J">Jarek Duda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
<p class="mathjax">Working with multiple variables they usually contain difficult to control
complex dependencies. This article proposes extraction of their individual
information, e.g. $\overline{X|Y}$ as random variable containing information
from $X$, but with removed information about $Y$, by using $(x,y)
\leftrightarrow (\bar{x}=\textrm{CDF}_{X|Y=y}(x),y)$ reversible normalization.
One application can be decoupling of individual information of variables:
reversibly transform $(X_1,\ldots,X_n)\leftrightarrow(\tilde{X}_1,\ldots
\tilde{X}_n)$ together containing the same information, but being independent:
$\forall_{i\neq j} \tilde{X}_i\perp \tilde{X}_j, \tilde{X}_i\perp X_j$. It
requires detailed models of complex conditional probability distributions - it
is generally a difficult task, but here can be done through multiple dependency
reducing iterations, using imperfect methods (here HCR: Hierarchical
Correlation Reconstruction). It could be also used for direct mutual
information - evaluating direct information transfer: without use of
intermediate variables. For causality direction there is discussed
multi-feature Granger causality, e.g. to trace various types of individual
information transfers between such decoupled variables, including propagation
time (delay).
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13434" title="Abstract">arXiv:2311.13434</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2311.13434" title="Download PDF">pdf</a>, <a href="/ps/2311.13434" title="Download PostScript">ps</a>, <a href="/format/2311.13434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recurrent neural networks and transfer learning for elasto-plasticity in  woven composites
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Ghane%2C+E">Ehsan Ghane</a>, 
<a href="/search/cond-mat?searchtype=author&query=Fagerstr%C3%B6m%2C+M">Martin Fagerstr&#xf6;m</a>, 
<a href="/search/cond-mat?searchtype=author&query=Mirkhalaf%2C+M">Mohsen Mirkhalaf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> There are 25 pages and 13 EPS images. The paper includes links to supporting materials
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">As a surrogate for computationally intensive meso-scale simulation of woven
composites, this article presents Recurrent Neural Network (RNN) models.
Leveraging the power of transfer learning, the initialization challenges and
sparse data issues inherent in cyclic shear strain loads are addressed in the
RNN models. A mean-field model generates a comprehensive data set representing
elasto-plastic behavior. In simulations, arbitrary six-dimensional strain
histories are used to predict stresses under random walking as the source task
and cyclic loading conditions as the target task. Incorporating sub-scale
properties enhances RNN versatility. In order to achieve accurate predictions,
the model uses a grid search method to tune network architecture and
hyper-parameter configurations. The results of this study demonstrate that
transfer learning can be used to effectively adapt the RNN to varying strain
conditions, which establishes its potential as a useful tool for modeling
path-dependent responses in woven composites.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13466" title="Abstract">arXiv:2311.13466</a> (cross-list from q-bio.BM) [<a href="/pdf/2311.13466" title="Download PDF">pdf</a>, <a href="/format/2311.13466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Inference in Molecular Diffusion Models with Latent  Representations of Protein Structure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Dunn%2C+I">Ian Dunn</a>, 
<a href="/search/q-bio?searchtype=author&query=Koes%2C+D+R">David Ryan Koes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper appeared as a spotlight paper at the NeurIPS 2023 Generative AI and Biology Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Diffusion generative models have emerged as a powerful framework for
addressing problems in structural biology and structure-based drug design.
These models operate directly on 3D molecular structures. Due to the
unfavorable scaling of graph neural networks (GNNs) with graph size as well as
the relatively slow inference speeds inherent to diffusion models, many
existing molecular diffusion models rely on coarse-grained representations of
protein structure to make training and inference feasible. However, such
coarse-grained representations discard essential information for modeling
molecular interactions and impair the quality of generated structures. In this
work, we present a novel GNN-based architecture for learning latent
representations of molecular structure. When trained end-to-end with a
diffusion model for de novo ligand design, our model achieves comparable
performance to one with an all-atom protein representation while exhibiting a
3-fold reduction in inference time.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13485" title="Abstract">arXiv:2311.13485</a> (cross-list from eess.IV) [<a href="/pdf/2311.13485" title="Download PDF">pdf</a>, <a href="/ps/2311.13485" title="Download PostScript">ps</a>, <a href="/format/2311.13485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep-learning-based acceleration of MRI for radiotherapy planning of  pediatric patients with brain tumors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Alam%2C+S">Shahinur Alam</a>, 
<a href="/search/eess?searchtype=author&query=Uh%2C+J">Jinsoo Uh</a>, 
<a href="/search/eess?searchtype=author&query=Dresner%2C+A">Alexander Dresner</a>, 
<a href="/search/eess?searchtype=author&query=Hua%2C+C">Chia-ho Hua</a>, 
<a href="/search/eess?searchtype=author&query=Khairy%2C+K">Khaled Khairy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Magnetic Resonance Imaging (MRI) is a non-invasive diagnostic and
radiotherapy (RT) planning tool, offering detailed insights into the anatomy of
the human body. The extensive scan time is stressful for patients, who must
remain motionless in a prolonged imaging procedure that prioritizes reduction
of imaging artifacts. This is challenging for pediatric patients who may
require measures for managing voluntary motions such as anesthesia. Several
computational approaches reduce scan time (fast MRI), by recording fewer
measurements and digitally recovering full information via post-acquisition
reconstruction. However, most fast MRI approaches were developed for diagnostic
imaging, without addressing reconstruction challenges specific to RT planning.
In this work, we developed a deep learning-based method (DeepMRIRec) for MRI
reconstruction from undersampled data acquired with RT-specific receiver coil
arrangements. We evaluated our method against fully sampled data of T1-weighted
MR images acquired from 73 children with brain tumors/surgical beds using loop
and posterior coils (12 channels), with and without applying virtual
compression of coil elements. DeepMRIRec reduced scanning time by a factor of
four producing a structural similarity score surpassing the evaluated
state-of-the-art method (0.960 vs 0.896), thereby demonstrating its potential
for accelerating MRI scanning for RT planning.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13490" title="Abstract">arXiv:2311.13490</a> (cross-list from q-bio.QM) [<a href="/pdf/2311.13490" title="Download PDF">pdf</a>, <a href="/format/2311.13490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Toxic Molecule Classification using Graph Neural Networks  and Few Shot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Mehta%2C+B">Bhavya Mehta</a>, 
<a href="/search/q-bio?searchtype=author&query=Kothari%2C+K">Kush Kothari</a>, 
<a href="/search/q-bio?searchtype=author&query=Nambiar%2C+R">Reshmika Nambiar</a>, 
<a href="/search/q-bio?searchtype=author&query=Shrawne%2C+S">Seema Shrawne</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Traditional methods like Graph Convolutional Networks (GCNs) face challenges
with limited data and class imbalance, leading to suboptimal performance in
graph classification tasks during toxicity prediction of molecules as a whole.
To address these issues, we harness the power of Graph Isomorphic Networks,
Multi Headed Attention and Free Large-scale Adversarial Augmentation separately
on Graphs for precisely capturing the structural data of molecules and their
toxicological properties. Additionally, we incorporate Few-Shot Learning to
improve the model's generalization with limited annotated samples. Extensive
experiments on a diverse toxicology dataset demonstrate that our method
achieves an impressive state-of-art AUC-ROC value of 0.816, surpassing the
baseline GCN model by 11.4%. This highlights the significance of our proposed
methodology and Few Shot Learning in advancing Toxic Molecular Classification,
with the potential to enhance drug discovery and environmental risk assessment
processes.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13491" title="Abstract">arXiv:2311.13491</a> (cross-list from physics.plasm-ph) [<a href="/pdf/2311.13491" title="Download PDF">pdf</a>, <a href="/format/2311.13491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grad-Shafranov equilibria via data-free physics informed neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Jang%2C+B">Byoungchan Jang</a>, 
<a href="/search/physics?searchtype=author&query=Kaptanoglu%2C+A+A">Alan A. Kaptanoglu</a>, 
<a href="/search/physics?searchtype=author&query=Gaur%2C+R">Rahul Gaur</a>, 
<a href="/search/physics?searchtype=author&query=Pan%2C+S">Shaw Pan</a>, 
<a href="/search/physics?searchtype=author&query=Landreman%2C+M">Matt Landreman</a>, 
<a href="/search/physics?searchtype=author&query=Dorland%2C+W">William Dorland</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Plasma Physics (physics.plasm-ph)</span>; Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">A large number of magnetohydrodynamic (MHD) equilibrium calculations are
often required for uncertainty quantification, optimization, and real-time
diagnostic information, making MHD equilibrium codes vital to the field of
plasma physics. In this paper, we explore a method for solving the
Grad-Shafranov equation by using Physics-Informed Neural Networks (PINNs). For
PINNs, we optimize neural networks by directly minimizing the residual of the
PDE as a loss function. We show that PINNs can accurately and effectively solve
the Grad-Shafranov equation with several different boundary conditions. We also
explore the parameter space by varying the size of the model, the learning
rate, and boundary conditions to map various trade-offs such as between
reconstruction error and computational speed. Additionally, we introduce a
parameterized PINN framework, expanding the input space to include variables
such as pressure, aspect ratio, elongation, and triangularity in order to
handle a broader range of plasma scenarios within a single network.
Parametrized PINNs could be used in future work to solve inverse problems such
as shape optimization.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13539" title="Abstract">arXiv:2311.13539</a> (cross-list from eess.IV) [<a href="/pdf/2311.13539" title="Download PDF">pdf</a>, <a href="/format/2311.13539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learned Nonlinear Predictor for Critically Sampled 3D Point Cloud  Attribute Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Do%2C+T+T">Tam Thuc Do</a>, 
<a href="/search/eess?searchtype=author&query=Chou%2C+P+A">Philip A. Chou</a>, 
<a href="/search/eess?searchtype=author&query=Cheung%2C+G">Gene Cheung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">We study 3D point cloud attribute compression via a volumetric approach:
assuming point cloud geometry is known at both encoder and decoder, parameters
$\theta$ of a continuous attribute function $f: \mathbb{R}^3 \mapsto
\mathbb{R}$ are quantized to $\hat{\theta}$ and encoded, so that discrete
samples $f_{\hat{\theta}}(\mathbf{x}_i)$ can be recovered at known 3D points
$\mathbf{x}_i \in \mathbb{R}^3$ at the decoder. Specifically, we consider a
nested sequences of function subspaces $\mathcal{F}^{(p)}_{l_0} \subseteq
\cdots \subseteq \mathcal{F}^{(p)}_L$, where $\mathcal{F}_l^{(p)}$ is a family
of functions spanned by B-spline basis functions of order $p$, $f_l^*$ is the
projection of $f$ on $\mathcal{F}_l^{(p)}$ and encoded as low-pass coefficients
$F_l^*$, and $g_l^*$ is the residual function in orthogonal subspace
$\mathcal{G}_l^{(p)}$ (where $\mathcal{G}_l^{(p)} \oplus \mathcal{F}_l^{(p)} =
\mathcal{F}_{l+1}^{(p)}$) and encoded as high-pass coefficients $G_l^*$. In
this paper, to improve coding performance over [1], we study predicting
$f_{l+1}^*$ at level $l+1$ given $f_l^*$ at level $l$ and encoding of $G_l^*$
for the $p=1$ case (RAHT($1$)). For the prediction, we formalize RAHT(1) linear
prediction in MPEG-PCC in a theoretical framework, and propose a new nonlinear
predictor using a polynomial of bilateral filter. We derive equations to
efficiently compute the critically sampled high-pass coefficients $G_l^*$
amenable to encoding. We optimize parameters in our resulting feed-forward
network on a large training set of point clouds by minimizing a rate-distortion
Lagrangian. Experimental results show that our improved framework outperformed
the MPEG G-PCC predictor by $11$ to $12\%$ in bit rate reduction.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13546" title="Abstract">arXiv:2311.13546</a> (cross-list from quant-ph) [<a href="/pdf/2311.13546" title="Download PDF">pdf</a>, <a href="/format/2311.13546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enigma: Privacy-Preserving Execution of QAOA on Untrusted Quantum  Computers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Ayanzadeh%2C+R">Ramin Ayanzadeh</a>, 
<a href="/search/quant-ph?searchtype=author&query=Mousavi%2C+A">Ahmad Mousavi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Alavisamani%2C+N">Narges Alavisamani</a>, 
<a href="/search/quant-ph?searchtype=author&query=Qureshi%2C+M">Moinuddin Qureshi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Discrete Mathematics (cs.DM); Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Quantum computers can solve problems that are beyond the capabilities of
conventional computers. As quantum computers are expensive and hard to
maintain, the typical model for performing quantum computation is to send the
circuit to a quantum cloud provider. This leads to privacy concerns for
commercial entities as an untrusted server can learn protected information from
the provided circuit. Current proposals for Secure Quantum Computing (SQC)
either rely on emerging technologies (such as quantum networks) or incur
prohibitive overheads (for Quantum Homomorphic Encryption). The goal of our
paper is to enable low-cost privacy-preserving quantum computation that can be
used with current systems.
<br />We propose Enigma, a suite of privacy-preserving schemes specifically
designed for the Quantum Approximate Optimization Algorithm (QAOA). Unlike
previous SQC techniques that obfuscate quantum circuits, Enigma transforms the
input problem of QAOA, such that the resulting circuit and the outcomes are
unintelligible to the server. We introduce three variants of Enigma. Enigma-I
protects the coefficients of QAOA using random phase flipping and fudging of
values. Enigma-II protects the nodes of the graph by introducing decoy qubits,
which are indistinguishable from primary ones. Enigma-III protects the edge
information of the graph by modifying the graph such that each node has an
identical number of connections. For all variants of Enigma, we demonstrate
that we can still obtain the solution for the original problem. We evaluate
Enigma using IBM quantum devices and show that the privacy improvements of
Enigma come at only a small reduction in fidelity (1%-13%).
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13548" title="Abstract">arXiv:2311.13548</a> (cross-list from stat.ML) [<a href="/pdf/2311.13548" title="Download PDF">pdf</a>, <a href="/format/2311.13548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Numerical Integration in Reproducing Kernel Hilbert Spaces via  Leverage Scores Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Chatalic%2C+A">Antoine Chatalic</a>, 
<a href="/search/stat?searchtype=author&query=Schreuder%2C+N">Nicolas Schreuder</a>, 
<a href="/search/stat?searchtype=author&query=De+Vito%2C+E">Ernesto De Vito</a>, 
<a href="/search/stat?searchtype=author&query=Rosasco%2C+L">Lorenzo Rosasco</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 46 pages, 5 figures. Submitted to JMLR
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
<p class="mathjax">In this work we consider the problem of numerical integration, i.e.,
approximating integrals with respect to a target probability measure using only
pointwise evaluations of the integrand. We focus on the setting in which the
target distribution is only accessible through a set of $n$ i.i.d.
observations, and the integrand belongs to a reproducing kernel Hilbert space.
We propose an efficient procedure which exploits a small i.i.d. random subset
of $m&lt;n$ samples drawn either uniformly or using approximate leverage scores
from the initial observations. Our main result is an upper bound on the
approximation error of this procedure for both sampling strategies. It yields
sufficient conditions on the subsample size to recover the standard (optimal)
$n^{-1/2}$ rate while reducing drastically the number of functions evaluations,
and thus the overall computational cost. Moreover, we obtain rates with respect
to the number $m$ of evaluations of the integrand which adapt to its
smoothness, and match known optimal rates for instance for Sobolev spaces. We
illustrate our theoretical findings with numerical experiments on real
datasets, which highlight the attractive efficiency-accuracy tradeoff of our
method compared to existing randomized and greedy quadrature methods. We note
that, the problem of numerical integration in RKHS amounts to designing a
discrete approximation of the kernel mean embedding of the target distribution.
As a consequence, direct applications of our results also include the efficient
computation of maximum mean discrepancies between distributions and the design
of efficient kernel-based tests.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13552" title="Abstract">arXiv:2311.13552</a> (cross-list from quant-ph) [<a href="/pdf/2311.13552" title="Download PDF">pdf</a>, <a href="/format/2311.13552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Framework for Trace-induced Quantum Kernels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Gan%2C+B+Y">Beng Yee Gan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Leykam%2C+D">Daniel Leykam</a>, 
<a href="/search/quant-ph?searchtype=author&query=Thanasilp%2C+S">Supanut Thanasilp</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 + 15 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Quantum kernel methods are promising candidates for achieving a practical
quantum advantage for certain machine learning tasks. Similar to classical
machine learning, an exact form of a quantum kernel is expected to have a great
impact on the model performance. In this work we combine all trace-induced
quantum kernels, including the commonly-used global fidelity and local
projected quantum kernels, into a common framework. We show how generalized
trace-induced quantum kernels can be constructed as combinations of the
fundamental building blocks we coin "Lego" kernels, which impose an inductive
bias on the resulting quantum models. We relate the expressive power and
generalization ability to the number of non-zero weight Lego kernels and
propose a systematic approach to increase the complexity of a quantum kernel
model, leading to a new form of the local projected kernels that require fewer
quantum resources in terms of the number of quantum gates and measurement
shots. We show numerically that models based on local projected kernels can
achieve comparable performance to the global fidelity quantum kernel. Our work
unifies existing quantum kernels and provides a systematic framework to compare
their properties.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13564" title="Abstract">arXiv:2311.13564</a> (cross-list from q-fin.PM) [<a href="/pdf/2311.13564" title="Download PDF">pdf</a>, <a href="/format/2311.13564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High order universal portfolios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Turinici%2C+G">Gabriel Turinici</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Portfolio Management (q-fin.PM)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">The Cover universal portfolio (UP from now on) has many interesting
theoretical and numerical properties and was investigated for a long time.
Building on it, we explore what happens when we add this UP to the market as a
new synthetic asset and construct by recurrence higher order UPs. We
investigate some important theoretical properties of the high order UPs and
show in particular that they are indeed different from the Cover UP and are
capable to break the time permutation invariance. Numerical experiences on a
benchmark from the literature show that in all cases high order UPs improve
Cover's UP performances.
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13595" title="Abstract">arXiv:2311.13595</a> (cross-list from math.ST) [<a href="/pdf/2311.13595" title="Download PDF">pdf</a>, <a href="/format/2311.13595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Covariance alignment: from maximum likelihood estimation to  Gromov-Wasserstein
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Han%2C+Y">Yanjun Han</a>, 
<a href="/search/math?searchtype=author&query=Rigollet%2C+P">Philippe Rigollet</a>, 
<a href="/search/math?searchtype=author&query=Stepaniants%2C+G">George Stepaniants</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Machine Learning (cs.LG); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
<p class="mathjax">Feature alignment methods are used in many scientific disciplines for data
pooling, annotation, and comparison. As an instance of a permutation learning
problem, feature alignment presents significant statistical and computational
challenges. In this work, we propose the covariance alignment model to study
and compare various alignment methods and establish a minimax lower bound for
covariance alignment that has a non-standard dimension scaling because of the
presence of a nuisance parameter. This lower bound is in fact minimax optimal
and is achieved by a natural quasi MLE. However, this estimator involves a
search over all permutations which is computationally infeasible even when the
problem has moderate size. To overcome this limitation, we show that the
celebrated Gromov-Wasserstein algorithm from optimal transport which is more
amenable to fast implementation even on large-scale problems is also minimax
optimal. These results give the first statistical justification for the
deployment of the Gromov-Wasserstein algorithm in practice.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13598" title="Abstract">arXiv:2311.13598</a> (cross-list from eess.SP) [<a href="/pdf/2311.13598" title="Download PDF">pdf</a>, <a href="/format/2311.13598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cram&#xe9;r-Rao Bounds for the Simultaneous Estimation of Power System  Electromechanical Modes and Forced Oscillations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dosiek%2C+L">Luke Dosiek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 5 figures, submitted for review for the IEEE Power and Energy Society General Meeting (PESGM24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In this paper, the Cram\'{e}r-Rao Bounds (CRB) for the simultaneous
estimation of power system electromechanical modes and forced oscillations (FO)
are derived. Two cases are considered; in the first case only the steady-state
response to the FO is present in the measured system output used by estimation
algorithms. In the second, the startup transient of the FO is present in
addition to the steady-state response. The CRBs are analyzed numerically to
explore sensitivities to FO frequency, signal-to-noise ratio (SNR) and
observation window length. It is demonstrated that 1) the CRB of FO parameters
is not affected by the presence of the transient response, 2) the CRB of the
system modes is not affected by the presence of an FO in steady-state and 3)
the CRB of the system modes can be drastically reduced by the presence of a FO
startup transient.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Thu, 23 Nov 23</h3>
<dl>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1710.11250" title="Abstract">arXiv:1710.11250</a> (replaced) [<a href="/pdf/1710.11250" title="Download PDF">pdf</a>, <a href="/ps/1710.11250" title="Download PostScript">ps</a>, <a href="/format/1710.11250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reachability Preservers: New Extremal Bounds and Approximation  Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abboud%2C+A">Amir Abboud</a>, 
<a href="/search/cs?searchtype=author&query=Bodwin%2C+G">Greg Bodwin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SODA '18
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.02673" title="Abstract">arXiv:2107.02673</a> (replaced) [<a href="/pdf/2107.02673" title="Download PDF">pdf</a>, <a href="/format/2107.02673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention-based Adversarial Appearance Learning of Augmented Pedestrians
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Strauss%2C+K">Kevin Strauss</a>, 
<a href="/search/cs?searchtype=author&query=Savkin%2C+A">Artem Savkin</a>, 
<a href="/search/cs?searchtype=author&query=Tombari%2C+F">Federico Tombari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.00527" title="Abstract">arXiv:2108.00527</a> (replaced) [<a href="/pdf/2108.00527" title="Download PDF">pdf</a>, <a href="/format/2108.00527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gates Are Not What You Need in RNNs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zakovskis%2C+R">Ronalds Zakovskis</a>, 
<a href="/search/cs?searchtype=author&query=Draguns%2C+A">Andis Draguns</a>, 
<a href="/search/cs?searchtype=author&query=Gaile%2C+E">Eliza Gaile</a>, 
<a href="/search/cs?searchtype=author&query=Ozolins%2C+E">Emils Ozolins</a>, 
<a href="/search/cs?searchtype=author&query=Freivalds%2C+K">Karlis Freivalds</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Artificial Intelligence and Soft Computing. ICAISC 2023. Lecture Notes in Computer Science(), vol 14125. Springer, Cham., and is available online at <a href="https://doi.org/10.1007/978-3-031-42505-9_27">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.05402" title="Abstract">arXiv:2111.05402</a> (replaced) [<a href="/pdf/2111.05402" title="Download PDF">pdf</a>, <a href="/format/2111.05402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cutting a Cake Is Not Always a &#x27;Piece of Cake&#x27;: A Closer Look at the  Foundations of Cake-Cutting Through the Lens of Measure Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kern%2C+P">Peter Kern</a>, 
<a href="/search/cs?searchtype=author&query=Neugebauer%2C+D">Daniel Neugebauer</a>, 
<a href="/search/cs?searchtype=author&query=Rothe%2C+J">J&#xf6;rg Rothe</a>, 
<a href="/search/cs?searchtype=author&query=Schilling%2C+R+L">Ren&#xe9; L. Schilling</a>, 
<a href="/search/cs?searchtype=author&query=Stoyan%2C+D">Dietrich Stoyan</a>, 
<a href="/search/cs?searchtype=author&query=Weishaupt%2C+R">Robin Weishaupt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.08315" title="Abstract">arXiv:2112.08315</a> (replaced) [<a href="/pdf/2112.08315" title="Download PDF">pdf</a>, <a href="/ps/2112.08315" title="Download PostScript">ps</a>, <a href="/format/2112.08315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nirikshak: A Clustering Based Autonomous API Testing Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahalwal%2C+Y">Yash Mahalwal</a>, 
<a href="/search/cs?searchtype=author&query=Pratyush%2C+P">Pawel Pratyush</a>, 
<a href="/search/cs?searchtype=author&query=Poonia%2C+Y">Yogesh Poonia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.04819" title="Abstract">arXiv:2201.04819</a> (replaced) [<a href="/pdf/2201.04819" title="Download PDF">pdf</a>, <a href="/format/2201.04819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Rank-Consistent Pyramid Model for Enhanced Crowd Counting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jiaqi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhizhong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Y">Yiming Lei</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+H">Hongming Shan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J+Z">James Z. Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fei-Yue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junping Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Neural Networks and Learning Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.08494" title="Abstract">arXiv:2202.08494</a> (replaced) [<a href="/pdf/2202.08494" title="Download PDF">pdf</a>, <a href="/format/2202.08494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning continuous models for continuous physics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krishnapriyan%2C+A+S">Aditi S. Krishnapriyan</a>, 
<a href="/search/cs?searchtype=author&query=Queiruga%2C+A+F">Alejandro F. Queiruga</a>, 
<a href="/search/cs?searchtype=author&query=Erichson%2C+N+B">N. Benjamin Erichson</a>, 
<a href="/search/cs?searchtype=author&query=Mahoney%2C+M+W">Michael W. Mahoney</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.10209" title="Abstract">arXiv:2202.10209</a> (replaced) [<a href="/pdf/2202.10209" title="Download PDF">pdf</a>, <a href="/format/2202.10209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Degree-Preserving Randomized Response for Graph Neural Networks under  Local Differential Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hidano%2C+S">Seira Hidano</a>, 
<a href="/search/cs?searchtype=author&query=Murakami%2C+T">Takao Murakami</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.06450" title="Abstract">arXiv:2204.06450</a> (replaced) [<a href="/pdf/2204.06450" title="Download PDF">pdf</a>, <a href="/format/2204.06450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The effect of speech pathology on automatic speaker verification -- a  large-scale study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arasteh%2C+S+T">Soroosh Tayebi Arasteh</a>, 
<a href="/search/cs?searchtype=author&query=Weise%2C+T">Tobias Weise</a>, 
<a href="/search/cs?searchtype=author&query=Schuster%2C+M">Maria Schuster</a>, 
<a href="/search/cs?searchtype=author&query=Noeth%2C+E">Elmar Noeth</a>, 
<a href="/search/cs?searchtype=author&query=Maier%2C+A">Andreas Maier</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S+H">Seung Hee Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Scientific Reports
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sci Rep 13, 20476 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.02645" title="Abstract">arXiv:2205.02645</a> (replaced) [<a href="/pdf/2205.02645" title="Download PDF">pdf</a>, <a href="/format/2205.02645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovering stochastic dynamical equations from biological time series  data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Nabeel%2C+A">Arshed Nabeel</a>, 
<a href="/search/q-bio?searchtype=author&query=Karichannavar%2C+A">Ashwin Karichannavar</a>, 
<a href="/search/q-bio?searchtype=author&query=Palathingal%2C+S">Shuaib Palathingal</a>, 
<a href="/search/q-bio?searchtype=author&query=Jhawar%2C+J">Jitesh Jhawar</a>, 
<a href="/search/q-bio?searchtype=author&query=Br%C3%BCckner%2C+D+B">David B. Br&#xfc;ckner</a>, 
<a href="/search/q-bio?searchtype=author&query=M.%2C+D+R">Danny Raj M.</a>, 
<a href="/search/q-bio?searchtype=author&query=Guttal%2C+V">Vishwesha Guttal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages (+ 9 page appendix), 6 figures (+ 8 appendix figures). Updates: v3: Significantly reorganized the paper and added a section analysis of a cell migration dataset. v4: Update arXiv title to match the updated title of the manuscript
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG); Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.11603" title="Abstract">arXiv:2205.11603</a> (replaced) [<a href="/pdf/2205.11603" title="Download PDF">pdf</a>, <a href="/format/2205.11603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Representation Projection Invariance Mitigates Representation Collapse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Razdaibiedina%2C+A">Anastasia Razdaibiedina</a>, 
<a href="/search/cs?searchtype=author&query=Khetan%2C+A">Ashish Khetan</a>, 
<a href="/search/cs?searchtype=author&query=Karnin%2C+Z">Zohar Karnin</a>, 
<a href="/search/cs?searchtype=author&query=Khashabi%2C+D">Daniel Khashabi</a>, 
<a href="/search/cs?searchtype=author&query=Kapoor%2C+V">Vishaal Kapoor</a>, 
<a href="/search/cs?searchtype=author&query=Madan%2C+V">Vivek Madan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.04837" title="Abstract">arXiv:2206.04837</a> (replaced) [<a href="/pdf/2206.04837" title="Download PDF">pdf</a>, <a href="/format/2206.04837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Some Extremal Symmetric Inequalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ando%2C+T">Tetsuya Ando</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Geometry (math.AG)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.05077" title="Abstract">arXiv:2206.05077</a> (replaced) [<a href="/pdf/2206.05077" title="Download PDF">pdf</a>, <a href="/format/2206.05077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tensor Train for Global Optimization Problems in Robotics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shetty%2C+S">Suhan Shetty</a>, 
<a href="/search/cs?searchtype=author&query=Lembono%2C+T">Teguh Lembono</a>, 
<a href="/search/cs?searchtype=author&query=Loew%2C+T">Tobias Loew</a>, 
<a href="/search/cs?searchtype=author&query=Calinon%2C+S">Sylvain Calinon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 21 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP); Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.09159" title="Abstract">arXiv:2206.09159</a> (replaced) [<a href="/pdf/2206.09159" title="Download PDF">pdf</a>, <a href="/format/2206.09159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beating the fault-tolerance bound and security loopholes for Byzantine  agreement with a quantum solution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Weng%2C+C">Chen-Xun Weng</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gao%2C+R">Rui-Qi Gao</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bao%2C+Y">Yu Bao</a>, 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+B">Bing-Hong Li</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+W">Wen-Bo Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Xie%2C+Y">Yuan-Mei Xie</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lu%2C+Y">Yu-Shuo Lu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yin%2C+H">Hua-Lei Yin</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+Z">Zeng-Bing Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 7 figures. All comments are welcome!
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Research 6, 0272 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.06494" title="Abstract">arXiv:2207.06494</a> (replaced) [<a href="/pdf/2207.06494" title="Download PDF">pdf</a>, <a href="/ps/2207.06494" title="Download PostScript">ps</a>, <a href="/format/2207.06494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Micro-macro stochastic Galerkin methods for nonlinear Fokker-Plank  equations with random inputs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dimarco%2C+G">Giacomo Dimarco</a>, 
<a href="/search/math?searchtype=author&query=Pareschi%2C+L">Lorenzo Pareschi</a>, 
<a href="/search/math?searchtype=author&query=Zanella%2C+M">Mattia Zanella</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Adaptation and Self-Organizing Systems (nlin.AO)

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.08701" title="Abstract">arXiv:2207.08701</a> (replaced) [<a href="/pdf/2207.08701" title="Download PDF">pdf</a>, <a href="/ps/2207.08701" title="Download PostScript">ps</a>, <a href="/format/2207.08701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Notes on Boolean Read-k and Multilinear Circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jukna%2C+S">Stasys Jukna</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A throughout revised version. To appear in Discrete Applied Mathematics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.12261" title="Abstract">arXiv:2207.12261</a> (replaced) [<a href="/pdf/2207.12261" title="Download PDF">pdf</a>, <a href="/format/2207.12261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraphCFC: A Directed Graph Based Cross-Modal Feature Complementation  Approach for Multimodal Conversational Emotion Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+G">Guoqing Lv</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zhigang Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Multimedia (TMM)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.00339" title="Abstract">arXiv:2208.00339</a> (replaced) [<a href="/pdf/2208.00339" title="Download PDF">pdf</a>, <a href="/format/2208.00339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraphMFT: A Graph Network based Multimodal Fusion Technique for Emotion  Recognition in Conversation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+G">Guoqing Lv</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zhigang Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Neurocomputing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.07462" title="Abstract">arXiv:2208.07462</a> (replaced) [<a href="/pdf/2208.07462" title="Download PDF">pdf</a>, <a href="/format/2208.07462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speeding up random walk mixing by starting from a uniform vertex
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=D%C3%ADaz%2C+A+E">Alberto Espuny D&#xed;az</a>, 
<a href="/search/math?searchtype=author&query=Morris%2C+P">Patrick Morris</a>, 
<a href="/search/math?searchtype=author&query=Perarnau%2C+G">Guillem Perarnau</a>, 
<a href="/search/math?searchtype=author&query=Serra%2C+O">Oriol Serra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.08369" title="Abstract">arXiv:2208.08369</a> (replaced) [<a href="/pdf/2208.08369" title="Download PDF">pdf</a>, <a href="/format/2208.08369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Radial basis approximation of tensor fields on manifolds: From operator  estimation to manifold learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Harlim%2C+J">John Harlim</a>, 
<a href="/search/math?searchtype=author&query=Jiang%2C+S+W">Shixiao Willing Jiang</a>, 
<a href="/search/math?searchtype=author&query=Peoples%2C+J+W">John Wilson Peoples</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.13933" title="Abstract">arXiv:2208.13933</a> (replaced) [<a href="/pdf/2208.13933" title="Download PDF">pdf</a>, <a href="/format/2208.13933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Taylor-Approximated Gradients to Improve the Frank-Wolfe Method  for Empirical Risk Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zikai Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Freund%2C+R+M">Robert M. Freund</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.05567" title="Abstract">arXiv:2209.05567</a> (replaced) [<a href="/pdf/2209.05567" title="Download PDF">pdf</a>, <a href="/format/2209.05567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixed formulation for the computation of Miura surfaces with gradient  Dirichlet boundary conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Marazzato%2C+F">Frederic Marazzato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.10433" title="Abstract">arXiv:2209.10433</a> (replaced) [<a href="/pdf/2209.10433" title="Download PDF">pdf</a>, <a href="/ps/2209.10433" title="Download PostScript">ps</a>, <a href="/format/2209.10433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Arithmetic Average Density Fusion -- Part II: Unified Derivation for  Unlabeled and Labeled RFS Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+T">Tiancheng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures, 1 table
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Aerospace and Electronics Systems, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.07380" title="Abstract">arXiv:2210.07380</a> (replaced) [<a href="/pdf/2210.07380" title="Download PDF">pdf</a>, <a href="/ps/2210.07380" title="Download PostScript">ps</a>, <a href="/format/2210.07380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Positive Hennessy-Milner Logic for Branching Bisimulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geuvers%2C+H">Herman Geuvers</a>, 
<a href="/search/cs?searchtype=author&query=Golov%2C+A">Anton Golov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages + appendices (28 pages total)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.09414" title="Abstract">arXiv:2210.09414</a> (replaced) [<a href="/pdf/2210.09414" title="Download PDF">pdf</a>, <a href="/format/2210.09414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Data-Driven Sensor Placement Approach for Detecting Voltage Violations  in Distribution Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Buason%2C+P">Paprapee Buason</a>, 
<a href="/search/eess?searchtype=author&query=Misra%2C+S">Sidhant Misra</a>, 
<a href="/search/eess?searchtype=author&query=Molzahn%2C+D+K">Daniel K. Molzahn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08371" title="Abstract">arXiv:2211.08371</a> (replaced) [<a href="/pdf/2211.08371" title="Download PDF">pdf</a>, <a href="/format/2211.08371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pragmatics in Language Grounding: Phenomena, Tasks, and Modeling  Approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fried%2C+D">Daniel Fried</a>, 
<a href="/search/cs?searchtype=author&query=Tomlin%2C+N">Nicholas Tomlin</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jennifer Hu</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+R">Roma Patel</a>, 
<a href="/search/cs?searchtype=author&query=Nematzadeh%2C+A">Aida Nematzadeh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.14605" title="Abstract">arXiv:2211.14605</a> (replaced) [<a href="/pdf/2211.14605" title="Download PDF">pdf</a>, <a href="/format/2211.14605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Looking at the posterior: accuracy and uncertainty of neural-network  predictions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Linander%2C+H">H. Linander</a>, 
<a href="/search/cs?searchtype=author&query=Balabanov%2C+O">O. Balabanov</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">H. Yang</a>, 
<a href="/search/cs?searchtype=author&query=Mehlig%2C+B">B. Mehlig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 10 figures, 5 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Machine Learning: Science and Technology 4 (2023) 045032
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.02931" title="Abstract">arXiv:2212.02931</a> (replaced) [<a href="/pdf/2212.02931" title="Download PDF">pdf</a>, <a href="/format/2212.02931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Different Learning Styles for Improved Knowledge Distillation  in Biomedical Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niyaz%2C+U">Usma Niyaz</a>, 
<a href="/search/cs?searchtype=author&query=Sambyal%2C+A+S">Abhishek Singh Sambyal</a>, 
<a href="/search/cs?searchtype=author&query=Bathula%2C+D+R">Deepti R. Bathula</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in Computers in Biology and Medicine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.03292" title="Abstract">arXiv:2212.03292</a> (replaced) [<a href="/pdf/2212.03292" title="Download PDF">pdf</a>, <a href="/ps/2212.03292" title="Download PostScript">ps</a>, <a href="/format/2212.03292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistical Tools and Methodologies for Ultrareliable Low-Latency  Communications -- A Tutorial
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez%2C+O">Onel L&#xf3;pez</a>, 
<a href="/search/cs?searchtype=author&query=Mahmood%2C+N">Nurul Mahmood</a>, 
<a href="/search/cs?searchtype=author&query=Shehab%2C+M">Mohammad Shehab</a>, 
<a href="/search/cs?searchtype=author&query=Alves%2C+H">Hirley Alves</a>, 
<a href="/search/cs?searchtype=author&query=Rosabal%2C+O">Osmel Rosabal</a>, 
<a href="/search/cs?searchtype=author&query=Marata%2C+L">Leatile Marata</a>, 
<a href="/search/cs?searchtype=author&query=Latva-aho%2C+M">Matti Latva-aho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in IEEE Proceedings of the IEEE. 40 pages, 20 figures, 11 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the IEEE, vol. 111, no. 11, pp. 1502-1543, Nov.
  2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Information Theory (cs.IT); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.08131" title="Abstract">arXiv:2212.08131</a> (replaced) [<a href="/pdf/2212.08131" title="Download PDF">pdf</a>, <a href="/format/2212.08131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging the Gap Between Offline and Online Reinforcement Learning  Evaluation Methodologies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sujit%2C+S">Shivakanth Sujit</a>, 
<a href="/search/cs?searchtype=author&query=Braga%2C+P+H+M">Pedro H. M. Braga</a>, 
<a href="/search/cs?searchtype=author&query=Bornschein%2C+J">Jorg Bornschein</a>, 
<a href="/search/cs?searchtype=author&query=Kahou%2C+S+E">Samira Ebrahimi Kahou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> TMLR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.08941" title="Abstract">arXiv:2212.08941</a> (replaced) [<a href="/pdf/2212.08941" title="Download PDF">pdf</a>, <a href="/ps/2212.08941" title="Download PostScript">ps</a>, <a href="/format/2212.08941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Calder&#xf3;n&#x27;s problem via DeepONets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Castro%2C+J">Javier Castro</a>, 
<a href="/search/math?searchtype=author&query=Mu%C3%B1oz%2C+C">Claudio Mu&#xf1;oz</a>, 
<a href="/search/math?searchtype=author&query=Valenzuela%2C+N">Nicol&#xe1;s Valenzuela</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pp.; contribution to the special issue dedicated to Carlos Kenig's 70th birthday
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.14200" title="Abstract">arXiv:2212.14200</a> (replaced) [<a href="/pdf/2212.14200" title="Download PDF">pdf</a>, <a href="/ps/2212.14200" title="Download PostScript">ps</a>, <a href="/format/2212.14200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intersecting ellipses induced by a max-sum matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barabanshchikova%2C+P">Polina Barabanshchikova</a>, 
<a href="/search/cs?searchtype=author&query=Polyanskii%2C+A">Alexandr Polyanskii</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Global Optimization, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Combinatorics (math.CO); Metric Geometry (math.MG)

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05326" title="Abstract">arXiv:2302.05326</a> (replaced) [<a href="/pdf/2302.05326" title="Download PDF">pdf</a>, <a href="/format/2302.05326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Real-Time Recurrent Learning Using Columnar-Constructive  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Javed%2C+K">Khurram Javed</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+H">Haseeb Shah</a>, 
<a href="/search/cs?searchtype=author&query=Sutton%2C+R">Rich Sutton</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+M">Martha White</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Scalable recurrent learning, online learning, real-time recurrent learning, cascade correlation networks, agent-state construction, columnar networks, constructive networks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.07843" title="Abstract">arXiv:2302.07843</a> (replaced) [<a href="/pdf/2302.07843" title="Download PDF">pdf</a>, <a href="/format/2302.07843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying gender imbalance in East Asian academia: Research career and  citation practice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nakajima%2C+K">Kazuki Nakajima</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruodan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shudo%2C+K">Kazuyuki Shudo</a>, 
<a href="/search/cs?searchtype=author&query=Masuda%2C+N">Naoki Masuda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 8 figures, 10 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Informetrics, Volume 17, Issue 4, Article No. 101460,
  November 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.08934" title="Abstract">arXiv:2302.08934</a> (replaced) [<a href="/pdf/2302.08934" title="Download PDF">pdf</a>, <a href="/format/2302.08934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active RIS Aided ISAC Systems: Beamforming Design and Performance  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhiyuan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+H">Hong Ren</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+C">Cunhua Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Gui Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Boshi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+M">Mianxiong Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiangzhou Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages,11 figures, accepted by IEEE TCOM.The manuscript has been revised to correct several typographical errors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11381" title="Abstract">arXiv:2302.11381</a> (replaced) [<a href="/pdf/2302.11381" title="Download PDF">pdf</a>, <a href="/format/2302.11381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Convergence Rate for Exact Policy Mirror Descent in Discounted  Markov Decision Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Johnson%2C+E">Emmeran Johnson</a>, 
<a href="/search/math?searchtype=author&query=Pike-Burke%2C+C">Ciara Pike-Burke</a>, 
<a href="/search/math?searchtype=author&query=Rebeschini%2C+P">Patrick Rebeschini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10350" title="Abstract">arXiv:2303.10350</a> (replaced) [<a href="/pdf/2303.10350" title="Download PDF">pdf</a>, <a href="/format/2303.10350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Convergence of a Three-Layer Semi-Discrete Scheme for the Nonlinear  Dynamic String Equation of Kirchhoff-Type with Time-Dependent Coefficients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Rogava%2C+J">Jemal Rogava</a>, 
<a href="/search/math?searchtype=author&query=Vashakidze%2C+Z">Zurab Vashakidze</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In the introduction section, we have included discussions on the physical relevance and applications of the problem. Additionally, we have completed a study on the stability of the three-point system obtained through the spatial discretization algorithm. The literature list has been expanded, with a focus on containing recent applications in engineering and physics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Mathematical Physics (math-ph); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10706" title="Abstract">arXiv:2303.10706</a> (replaced) [<a href="/pdf/2303.10706" title="Download PDF">pdf</a>, <a href="/format/2303.10706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intersecting diametral balls induced by a geometric graph II
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Barabanshchikova%2C+P">Polina Barabanshchikova</a>, 
<a href="/search/math?searchtype=author&query=Polyanskii%2C+A">Alexandr Polyanskii</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Discrete Mathematics, 347(1) 2024, 113694
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Geometry (cs.CG); Metric Geometry (math.MG)

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01959" title="Abstract">arXiv:2304.01959</a> (replaced) [<a href="/pdf/2304.01959" title="Download PDF">pdf</a>, <a href="/format/2304.01959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Randomized Adversarial Style Perturbations for Domain Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taehoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bohyung Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07061" title="Abstract">arXiv:2304.07061</a> (replaced) [<a href="/pdf/2304.07061" title="Download PDF">pdf</a>, <a href="/format/2304.07061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoDroid-0shot: A Simple Baseline for GPT-powered UI-grounded  Smartphone Task Automation in Android
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+H">Hao Wen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaxuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanchun Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07647" title="Abstract">arXiv:2304.07647</a> (replaced) [<a href="/pdf/2304.07647" title="Download PDF">pdf</a>, <a href="/format/2304.07647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LASER: A Neuro-Symbolic Framework for Learning Spatial-Temporal Scene  Graphs with Weak Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiani Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Naik%2C+M">Mayur Naik</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+S">Ser-Nam Lim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08586" title="Abstract">arXiv:2304.08586</a> (replaced) [<a href="/pdf/2304.08586" title="Download PDF">pdf</a>, <a href="/format/2304.08586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Navigation and Obstacle Avoidance Using Differentiable Optimization  Based Control Barrier Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Bolun Dai</a>, 
<a href="/search/cs?searchtype=author&query=Khorrambakht%2C+R">Rooholla Khorrambakht</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamurthy%2C+P">Prashanth Krishnamurthy</a>, 
<a href="/search/cs?searchtype=author&query=Gon%C3%A7alves%2C+V">Vin&#xed;cius Gon&#xe7;alves</a>, 
<a href="/search/cs?searchtype=author&query=Tzes%2C+A">Anthony Tzes</a>, 
<a href="/search/cs?searchtype=author&query=Khorrami%2C+F">Farshad Khorrami</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08837" title="Abstract">arXiv:2304.08837</a> (replaced) [<a href="/pdf/2304.08837" title="Download PDF">pdf</a>, <a href="/ps/2304.08837" title="Download PostScript">ps</a>, <a href="/format/2304.08837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sensor Fault Detection and Isolation in Autonomous Nonlinear Systems  Using Neural Network-Based Observers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cao%2C+J">John Cao</a>, 
<a href="/search/math?searchtype=author&query=Niazi%2C+M+U+B">Muhammad Umar B. Niazi</a>, 
<a href="/search/math?searchtype=author&query=Barreau%2C+M">Matthieu Barreau</a>, 
<a href="/search/math?searchtype=author&query=Johansson%2C+K+H">Karl Henrik Johansson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07940" title="Abstract">arXiv:2305.07940</a> (replaced) [<a href="/pdf/2305.07940" title="Download PDF">pdf</a>, <a href="/format/2305.07940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MHDnet: Physics-preserving learning for solving magnetohydrodynamics  problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Guan%2C+X">Xiaofei Guan</a>, 
<a href="/search/math?searchtype=author&query=Hu%2C+B">Boya Hu</a>, 
<a href="/search/math?searchtype=author&query=Mao%2C+S">Shipeng Mao</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+X">Xintong Wang</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+Z">Zihao Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08768" title="Abstract">arXiv:2305.08768</a> (replaced) [<a href="/pdf/2305.08768" title="Download PDF">pdf</a>, <a href="/format/2305.08768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Introduction to String Diagrams for Computer Scientists
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Piedeleu%2C+R">Robin Piedeleu</a>, 
<a href="/search/cs?searchtype=author&query=Zanasi%2C+F">Fabio Zanasi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11731" title="Abstract">arXiv:2305.11731</a> (replaced) [<a href="/pdf/2305.11731" title="Download PDF">pdf</a>, <a href="/ps/2305.11731" title="Download PostScript">ps</a>, <a href="/format/2305.11731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Persian Typographical Error Type Detection Using Deep Neural Networks on  Algorithmically-Generated Misspellings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dehghani%2C+M">Mohammad Dehghani</a>, 
<a href="/search/cs?searchtype=author&query=Faili%2C+H">Heshaam Faili</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13318" title="Abstract">arXiv:2305.13318</a> (replaced) [<a href="/pdf/2305.13318" title="Download PDF">pdf</a>, <a href="/format/2305.13318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A principled deep learning approach for geological facies generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Bhavsar%2C+F">Ferdinand Bhavsar</a>, 
<a href="/search/physics?searchtype=author&query=Desassis%2C+N">Nicolas Desassis</a>, 
<a href="/search/physics?searchtype=author&query=Ors%2C+F">Fabien Ors</a>, 
<a href="/search/physics?searchtype=author&query=Romary%2C+T">Thomas Romary</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geophysics (physics.geo-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13536" title="Abstract">arXiv:2305.13536</a> (replaced) [<a href="/pdf/2305.13536" title="Download PDF">pdf</a>, <a href="/format/2305.13536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Subspace-Configurable Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saukh%2C+O">Olga Saukh</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dong Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiaoxi He</a>, 
<a href="/search/cs?searchtype=author&query=Thiele%2C+L">Lothar Thiele</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14032" title="Abstract">arXiv:2305.14032</a> (replaced) [<a href="/pdf/2305.14032" title="Download PDF">pdf</a>, <a href="/format/2305.14032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Patch-Mix Contrastive Learning with Audio Spectrogram Transformer on  Respiratory Sound Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bae%2C+S">Sangmin Bae</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+J">June-Woo Kim</a>, 
<a href="/search/eess?searchtype=author&query=Cho%2C+W">Won-Yang Cho</a>, 
<a href="/search/eess?searchtype=author&query=Baek%2C+H">Hyerim Baek</a>, 
<a href="/search/eess?searchtype=author&query=Son%2C+S">Soyoun Son</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+B">Byungjo Lee</a>, 
<a href="/search/eess?searchtype=author&query=Ha%2C+C">Changwan Ha</a>, 
<a href="/search/eess?searchtype=author&query=Tae%2C+K">Kyongpil Tae</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+S">Sungnyun Kim</a>, 
<a href="/search/eess?searchtype=author&query=Yun%2C+S">Se-Young Yun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> INTERSPEECH 2023, Code URL: <a href="https://github.com/raymin0223/patch-mix_contrastive_learning">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14264" title="Abstract">arXiv:2305.14264</a> (replaced) [<a href="/pdf/2305.14264" title="Download PDF">pdf</a>, <a href="/format/2305.14264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Learning Principles for In-Context Learning with Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Margatina%2C+K">Katerina Margatina</a>, 
<a href="/search/cs?searchtype=author&query=Schick%2C+T">Timo Schick</a>, 
<a href="/search/cs?searchtype=author&query=Aletras%2C+N">Nikolaos Aletras</a>, 
<a href="/search/cs?searchtype=author&query=Dwivedi-Yu%2C+J">Jane Dwivedi-Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at Findings of EMNLP (Camera Ready version)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14457" title="Abstract">arXiv:2305.14457</a> (replaced) [<a href="/pdf/2305.14457" title="Download PDF">pdf</a>, <a href="/format/2305.14457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-training Language Models for Comparative Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+M">Mengxia Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhihan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenhao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Meng Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 - Camera Ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15851" title="Abstract">arXiv:2305.15851</a> (replaced) [<a href="/pdf/2305.15851" title="Download PDF">pdf</a>, <a href="/format/2305.15851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On sampling determinantal and Pfaffian point processes on a quantum  computer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bardenet%2C+R">R&#xe9;mi Bardenet</a>, 
<a href="/search/stat?searchtype=author&query=Fanuel%2C+M">Micha&#xeb;l Fanuel</a>, 
<a href="/search/stat?searchtype=author&query=Feller%2C+A">Alexandre Feller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 53 pages, 9 figures. Additional results about parity of cardinality of PfPP samples. Minor corrections in Section 5 and slight generalization of Lemma 5.4. Extra example and derivations in appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation (stat.CO)</span>; Machine Learning (cs.LG); Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16213" title="Abstract">arXiv:2305.16213</a> (replaced) [<a href="/pdf/2305.16213" title="Download PDF">pdf</a>, <a href="/format/2305.16213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation with  Variational Score Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhengyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yikai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+F">Fan Bao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chongxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hang Su</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jun Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 (Spotlight)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16854" title="Abstract">arXiv:2305.16854</a> (replaced) [<a href="/pdf/2305.16854" title="Download PDF">pdf</a>, <a href="/format/2305.16854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Channel and Gradient-Importance Aware Device Scheduling for Over-the-Air  Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuchang Sun</a>, 
<a href="/search/cs?searchtype=author&query=lin%2C+Z">Zehong lin</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yuyi Mao</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Shi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00560" title="Abstract">arXiv:2306.00560</a> (replaced) [<a href="/pdf/2306.00560" title="Download PDF">pdf</a>, <a href="/format/2306.00560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hinge-Wasserstein: Mitigating Overconfidence in Regression by  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Ziliang Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Jonnarth%2C+A">Arvi Jonnarth</a>, 
<a href="/search/cs?searchtype=author&query=Eldesokey%2C+A">Abdelrahman Eldesokey</a>, 
<a href="/search/cs?searchtype=author&query=Johnander%2C+J">Joakim Johnander</a>, 
<a href="/search/cs?searchtype=author&query=Wandt%2C+B">Bastian Wandt</a>, 
<a href="/search/cs?searchtype=author&query=Forssen%2C+P">Per-Erik Forssen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01665" title="Abstract">arXiv:2306.01665</a> (replaced) [<a href="/pdf/2306.01665" title="Download PDF">pdf</a>, <a href="/format/2306.01665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SourceP: Detecting Ponzi Schemes on Ethereum with Source Code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+P">Pengcheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+L">Liang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+K">Keting Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02659" title="Abstract">arXiv:2306.02659</a> (replaced) [<a href="/pdf/2306.02659" title="Download PDF">pdf</a>, <a href="/format/2306.02659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Trajectory Optimization for Autonomous Terrain Traversal of  Articulated Tracked Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhengzhe Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yanbo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jian%2C+Z">Zhuozhu Jian</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+J">Junbo Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xueqian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+B">Bin Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Robotics and Automation Letters (RA-L)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04225" title="Abstract">arXiv:2306.04225</a> (replaced) [<a href="/pdf/2306.04225" title="Download PDF">pdf</a>, <a href="/format/2306.04225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Vision Transformer for Human Pose Estimation via Patch  Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kinfu%2C+K+A">Kaleab A. Kinfu</a>, 
<a href="/search/cs?searchtype=author&query=Vidal%2C+R">Rene Vidal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> BMVC 2023 Oral Paper: <a href="https://proceedings.bmvc2023.org/167/">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 34th British Machine Vision Conference 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04889" title="Abstract">arXiv:2306.04889</a> (replaced) [<a href="/pdf/2306.04889" title="Download PDF">pdf</a>, <a href="/format/2306.04889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ShaDDR: Interactive Example-Based Geometry and Texture Generation via 3D  Shape Detailization and Differentiable Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qimin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhiqin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to SIGGRAPH Asia 2023 conference track. Code: <a href="https://github.com/qiminchen/ShaDDR">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05047" title="Abstract">arXiv:2306.05047</a> (replaced) [<a href="/pdf/2306.05047" title="Download PDF">pdf</a>, <a href="/format/2306.05047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Introducing Reduced-Width QNNs, an AI-inspired Ansatz Design Pattern
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Stein%2C+J">Jonas Stein</a>, 
<a href="/search/quant-ph?searchtype=author&query=Rohe%2C+T">Tobias Rohe</a>, 
<a href="/search/quant-ph?searchtype=author&query=Nappi%2C+F">Francesco Nappi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hager%2C+J">Julian Hager</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bucher%2C+D">David Bucher</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zorn%2C+M">Maximilian Zorn</a>, 
<a href="/search/quant-ph?searchtype=author&query=K%C3%B6lle%2C+M">Michael K&#xf6;lle</a>, 
<a href="/search/quant-ph?searchtype=author&query=Linnhoff-Popien%2C+C">Claudia Linnhoff-Popien</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05705" title="Abstract">arXiv:2306.05705</a> (replaced) [<a href="/pdf/2306.05705" title="Download PDF">pdf</a>, <a href="/format/2306.05705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Challenges and Perspectives of Foundation Models for Medical  Image Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+S">Shaoting Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Metaxas%2C+D">Dimitris Metaxas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06202" title="Abstract">arXiv:2306.06202</a> (replaced) [<a href="/pdf/2306.06202" title="Download PDF">pdf</a>, <a href="/format/2306.06202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuroGraph: Benchmarks for Graph Machine Learning in Brain Connectomics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Said%2C+A">Anwar Said</a>, 
<a href="/search/cs?searchtype=author&query=Bayrak%2C+R+G">Roza G. Bayrak</a>, 
<a href="/search/cs?searchtype=author&query=Derr%2C+T">Tyler Derr</a>, 
<a href="/search/cs?searchtype=author&query=Shabbir%2C+M">Mudassir Shabbir</a>, 
<a href="/search/cs?searchtype=author&query=Moyer%2C+D">Daniel Moyer</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+C">Catie Chang</a>, 
<a href="/search/cs?searchtype=author&query=Koutsoukos%2C+X">Xenofon Koutsoukos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06820" title="Abstract">arXiv:2306.06820</a> (replaced) [<a href="/pdf/2306.06820" title="Download PDF">pdf</a>, <a href="/ps/2306.06820" title="Download PostScript">ps</a>, <a href="/format/2306.06820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Fair Influence Maximization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rui%2C+X">Xiaobin Rui</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhixiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiayu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08280" title="Abstract">arXiv:2306.08280</a> (replaced) [<a href="/pdf/2306.08280" title="Download PDF">pdf</a>, <a href="/format/2306.08280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially Private Wireless Federated Learning Using Orthogonal  Sequences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xizixiang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+R">Ruiquan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Cong Shen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Poor%2C+H+V">H. Vincent Poor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG); Signal Processing (eess.SP); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08326" title="Abstract">arXiv:2306.08326</a> (replaced) [<a href="/e-print/2306.08326" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Early Detection of Late Blight Tomato Disease using Histogram Oriented  Gradient based Support Vector Machine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ishaq%2C+M">M. Ishaq</a>, 
<a href="/search/cs?searchtype=author&query=Waqas%2C+M">M. Waqas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The article titled "Early Detection of Late Blight Tomato Disease using Histogram Oriented Gradient based Support Vector Machine" need to be withdrawn there are other contributors in the improvement of this article
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08704" title="Abstract">arXiv:2306.08704</a> (replaced) [<a href="/pdf/2306.08704" title="Download PDF">pdf</a>, <a href="/ps/2306.08704" title="Download PostScript">ps</a>, <a href="/format/2306.08704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Pulse Shaping for Delay-Doppler Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuangyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Weijie Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhiqiang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jinhong Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+B">Baoming Bai</a>, 
<a href="/search/cs?searchtype=author&query=Caire%2C+G">Giuseppe Caire</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13458" title="Abstract">arXiv:2306.13458</a> (replaced) [<a href="/pdf/2306.13458" title="Download PDF">pdf</a>, <a href="/ps/2306.13458" title="Download PostScript">ps</a>, <a href="/format/2306.13458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Influence Maximization based on Threshold Model in Hypergraphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Renquan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+X">Xilong Qu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xirong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+S">Sen Pei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Chaotic Dynamics (nlin.CD)

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15670" title="Abstract">arXiv:2306.15670</a> (replaced) [<a href="/pdf/2306.15670" title="Download PDF">pdf</a>, <a href="/format/2306.15670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symphonize 3D Semantic Scene Completion with Contextual Instance Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Haoyi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+T">Tianheng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+N">Naiyu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haoyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+T">Tianwei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinggang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report. Code and models at: <a href="https://github.com/hustvl/Symphonies">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15755" title="Abstract">arXiv:2306.15755</a> (replaced) [<a href="/pdf/2306.15755" title="Download PDF">pdf</a>, <a href="/format/2306.15755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Backdoor Attack by Naturalistic Data Poisoning on Trajectory  Prediction in Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pourkeshavarz%2C+M">Mozhgan Pourkeshavarz</a>, 
<a href="/search/cs?searchtype=author&query=Sabokrou%2C+M">Mohammad Sabokrou</a>, 
<a href="/search/cs?searchtype=author&query=Rasouli%2C+A">Amir Rasouli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16430" title="Abstract">arXiv:2306.16430</a> (replaced) [<a href="/pdf/2306.16430" title="Download PDF">pdf</a>, <a href="/format/2306.16430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DNA-TEQ: An Adaptive Exponential Quantization of Tensors for DNN  Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khabbazan%2C+B">Bahareh Khabbazan</a>, 
<a href="/search/cs?searchtype=author&query=Riera%2C+M">Marc Riera</a>, 
<a href="/search/cs?searchtype=author&query=Gonz%C3%A1lez%2C+A">Antonio Gonz&#xe1;lez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Hardware Architecture (cs.AR)

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16773" title="Abstract">arXiv:2306.16773</a> (replaced) [<a href="/pdf/2306.16773" title="Download PDF">pdf</a>, <a href="/ps/2306.16773" title="Download PostScript">ps</a>, <a href="/format/2306.16773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Influence Maximization based on Simplicial Contagion Models in  Hypergraphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Renquan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+T">Ting Wei</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yifan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+S">Sen Pei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages,17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16861" title="Abstract">arXiv:2306.16861</a> (replaced) [<a href="/pdf/2306.16861" title="Download PDF">pdf</a>, <a href="/format/2306.16861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beamfocusing Optimization for Near-Field Wideband Multi-User  Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaolin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+X">Xidong Mu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17301" title="Abstract">arXiv:2306.17301</a> (replaced) [<a href="/pdf/2306.17301" title="Download PDF">pdf</a>, <a href="/format/2306.17301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Why Shallow Networks Struggle with Approximating and Learning High  Frequency: A Numerical Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shijun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hongkai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yimin Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Haomin Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00449" title="Abstract">arXiv:2307.00449</a> (replaced) [<a href="/pdf/2307.00449" title="Download PDF">pdf</a>, <a href="/format/2307.00449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Dual-Stream Recurrence-Attention Network With Global-Local Awareness  for Emotion Recognition in Textual Dialog
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zhigang Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Engineering Applications of Artificial Intelligence (EAAI)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01121" title="Abstract">arXiv:2307.01121</a> (replaced) [<a href="/pdf/2307.01121" title="Download PDF">pdf</a>, <a href="/format/2307.01121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Artifacts Mapping: Multi-Modal Semantic Mapping for Object Detection and  3D Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rollo%2C+F">Federico Rollo</a>, 
<a href="/search/cs?searchtype=author&query=Raiola%2C+G">Gennaro Raiola</a>, 
<a href="/search/cs?searchtype=author&query=Zunino%2C+A">Andrea Zunino</a>, 
<a href="/search/cs?searchtype=author&query=Tsagarakis%2C+N">Nikolaos Tsagarakis</a>, 
<a href="/search/cs?searchtype=author&query=Ajoudani%2C+A">Arash Ajoudani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 11th European Conference on Mobile Robots (ECMR) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03357" title="Abstract">arXiv:2307.03357</a> (replaced) [<a href="/pdf/2307.03357" title="Download PDF">pdf</a>, <a href="/ps/2307.03357" title="Download PostScript">ps</a>, <a href="/format/2307.03357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stability and Generalization of Stochastic Compositional Gradient  Descent Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xiyuan Wei</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tianbao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+Y">Yiming Ying</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03817" title="Abstract">arXiv:2307.03817</a> (replaced) [<a href="/pdf/2307.03817" title="Download PDF">pdf</a>, <a href="/format/2307.03817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring and Characterizing Large Language Models For Embedded System  Development and Debugging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Englhardt%2C+Z">Zachary Englhardt</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Richard Li</a>, 
<a href="/search/cs?searchtype=author&query=Nissanka%2C+D">Dilini Nissanka</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhihan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Narayanswamy%2C+G">Girish Narayanswamy</a>, 
<a href="/search/cs?searchtype=author&query=Breda%2C+J">Joseph Breda</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+S">Shwetak Patel</a>, 
<a href="/search/cs?searchtype=author&query=Iyer%2C+V">Vikram Iyer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08430" title="Abstract">arXiv:2307.08430</a> (replaced) [<a href="/pdf/2307.08430" title="Download PDF">pdf</a>, <a href="/format/2307.08430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Long-range Meta-path Search through Progressive Sampling on Large-scale  Heterogeneous Information Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chao Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zijie Guo</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Q">Qiuting He</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hao Xu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+K">Kun He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09754" title="Abstract">arXiv:2307.09754</a> (replaced) [<a href="/pdf/2307.09754" title="Download PDF">pdf</a>, <a href="/format/2307.09754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProNav: Proprioceptive Traversability Estimation for Legged Robot  Navigation in Outdoor Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elnoor%2C+M">Mohamed Elnoor</a>, 
<a href="/search/cs?searchtype=author&query=Sathyamoorthy%2C+A+J">Adarsh Jagan Sathyamoorthy</a>, 
<a href="/search/cs?searchtype=author&query=Weerakoon%2C+K">Kasun Weerakoon</a>, 
<a href="/search/cs?searchtype=author&query=Manocha%2C+D">Dinesh Manocha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10045" title="Abstract">arXiv:2307.10045</a> (replaced) [<a href="/pdf/2307.10045" title="Download PDF">pdf</a>, <a href="/ps/2307.10045" title="Download PostScript">ps</a>, <a href="/format/2307.10045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Alignment complete relational Hoare logics for some and all
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nagasamudram%2C+R">Ramana Nagasamudram</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+A">Anindya Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Naumann%2C+D+A">David A. Naumann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2212.10338">arXiv:2212.10338</a>; Vsn2 fixes a def, also adds semantic completeness for filtered automata and Cook completeness for all-exists logic; Vsn3 adds section on entailment completeness and additional proof rules
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10447" title="Abstract">arXiv:2307.10447</a> (replaced) [<a href="/pdf/2307.10447" title="Download PDF">pdf</a>, <a href="/format/2307.10447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reducing Ambiguities in Line-based Density Plots by Image-space  Colorization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+Y">Yumeng Xue</a>, 
<a href="/search/cs?searchtype=author&query=Paetzold%2C+P">Patrick Paetzold</a>, 
<a href="/search/cs?searchtype=author&query=Kehlbeck%2C+R">Rebecca Kehlbeck</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kwan%2C+K+C">Kin Chung Kwan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunhai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Deussen%2C+O">Oliver Deussen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in IEEE Transactions on Visualization and Computer Graphics (Supplementary Material: <a href="https://osf.io/jm5yz/">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10838" title="Abstract">arXiv:2307.10838</a> (replaced) [<a href="/pdf/2307.10838" title="Download PDF">pdf</a>, <a href="/format/2307.10838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hybrid Adaptive Controller for Soft Robot Interchangeability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zixi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xuyang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Bernabei%2C+M">Matteo Bernabei</a>, 
<a href="/search/cs?searchtype=author&query=Mainardi%2C+V">Vanessa Mainardi</a>, 
<a href="/search/cs?searchtype=author&query=Ciuti%2C+G">Gastone Ciuti</a>, 
<a href="/search/cs?searchtype=author&query=Stefanini%2C+C">Cesare Stefanini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by IEEE Robotics and Automation Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11280" title="Abstract">arXiv:2307.11280</a> (replaced) [<a href="/pdf/2307.11280" title="Download PDF">pdf</a>, <a href="/format/2307.11280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Epsilon*: Privacy Metric for Machine Learning Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Negoescu%2C+D+M">Diana M. Negoescu</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+H">Humberto Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Orjany%2C+S+E+A">Saad Eddin Al Orjany</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jilei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lut%2C+Y">Yuliia Lut</a>, 
<a href="/search/cs?searchtype=author&query=Tandra%2C+R">Rahul Tandra</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaowen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xinyi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Douglas%2C+Z">Zach Douglas</a>, 
<a href="/search/cs?searchtype=author&query=Nolkha%2C+V">Vidita Nolkha</a>, 
<a href="/search/cs?searchtype=author&query=Ahammad%2C+P">Parvez Ahammad</a>, 
<a href="/search/cs?searchtype=author&query=Samorodnitsky%2C+G">Gennady Samorodnitsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11494" title="Abstract">arXiv:2307.11494</a> (replaced) [<a href="/pdf/2307.11494" title="Download PDF">pdf</a>, <a href="/format/2307.11494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predict, Refine, Synthesize: Self-Guiding Diffusion Models for  Probabilistic Time Series Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kollovieh%2C+M">Marcel Kollovieh</a>, 
<a href="/search/cs?searchtype=author&query=Ansari%2C+A+F">Abdul Fatir Ansari</a>, 
<a href="/search/cs?searchtype=author&query=Bohlke-Schneider%2C+M">Michael Bohlke-Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Zschiegner%2C+J">Jasper Zschiegner</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuyang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code available at <a href="https://github.com/amazon-science/unconditional-time-series-diffusion">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13390" title="Abstract">arXiv:2307.13390</a> (replaced) [<a href="/pdf/2307.13390" title="Download PDF">pdf</a>, <a href="/format/2307.13390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Counterfactual Explanation via Search in Gaussian Mixture Distributed  Latent Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Broelemann%2C+K">Klaus Broelemann</a>, 
<a href="/search/cs?searchtype=author&query=Kasneci%2C+G">Gjergji Kasneci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> XAI workshop of IJCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08404" title="Abstract">arXiv:2308.08404</a> (replaced) [<a href="/pdf/2308.08404" title="Download PDF">pdf</a>, <a href="/ps/2308.08404" title="Download PostScript">ps</a>, <a href="/format/2308.08404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A topological counterpart of well-founded trees in dependent type theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maietti%2C+M+E">Maria Emilia Maietti</a>, 
<a href="/search/cs?searchtype=author&query=Sabelli%2C+P">Pietro Sabelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in the post-proceedings of the 39th Conference on Mathematical Foundations of Programming Semantics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09936" title="Abstract">arXiv:2308.09936</a> (replaced) [<a href="/pdf/2308.09936" title="Download PDF">pdf</a>, <a href="/format/2308.09936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BLIVA: A Simple Multimodal LLM for Better Handling of Text-Rich Visual  Questions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wenbo Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yifan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yi Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weiyue Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zeyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhuowen Tu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10631" title="Abstract">arXiv:2308.10631</a> (replaced) [<a href="/pdf/2308.10631" title="Download PDF">pdf</a>, <a href="/format/2308.10631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PsyMo: A Dataset for Estimating Self-Reported Psychological Traits from  Gait
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cosma%2C+A">Adrian Cosma</a>, 
<a href="/search/cs?searchtype=author&query=Radoi%2C+E">Emilian Radoi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at 2024 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13890" title="Abstract">arXiv:2308.13890</a> (replaced) [<a href="/pdf/2308.13890" title="Download PDF">pdf</a>, <a href="/ps/2308.13890" title="Download PostScript">ps</a>, <a href="/format/2308.13890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spanning Adjacency Oracles in Sublinear Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bodwin%2C+G">Greg Bodwin</a>, 
<a href="/search/cs?searchtype=author&query=Fleischmann%2C+H">Henry Fleischmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 1 figure. Accepted to ITCS '24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14606" title="Abstract">arXiv:2308.14606</a> (replaced) [<a href="/pdf/2308.14606" title="Download PDF">pdf</a>, <a href="/format/2308.14606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Tradeoff between Privacy Preservation and Byzantine-Robustness in  Decentralized Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Haoxiang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Heng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+Q">Qing Ling</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15158" title="Abstract">arXiv:2308.15158</a> (replaced) [<a href="/pdf/2308.15158" title="Download PDF">pdf</a>, <a href="/format/2308.15158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Advanced Tree Algorithm with Interference Cancellation in Uplink and  Downlink
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vogel%2C+Q">Quirin Vogel</a>, 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+Y">Yash Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Stefanovi%C4%87%2C+%C4%8C">&#x10c;edomir Stefanovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Kellerer%2C+W">Wolfgang Kellerer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was be presented at the ASILOMAR Conference on Signals, Systems, and Computers. Copyright IEEE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00168" title="Abstract">arXiv:2309.00168</a> (replaced) [<a href="/pdf/2309.00168" title="Download PDF">pdf</a>, <a href="/format/2309.00168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pose-Graph Attentional Graph Neural Network for Lidar Place Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramezani%2C+M">Milad Ramezani</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Knights%2C+J">Joshua Knights</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhibin Li</a>, 
<a href="/search/cs?searchtype=author&query=Pounds%2C+P">Pauline Pounds</a>, 
<a href="/search/cs?searchtype=author&query=Moghadam%2C+P">Peyman Moghadam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00846" title="Abstract">arXiv:2309.00846</a> (replaced) [<a href="/pdf/2309.00846" title="Download PDF">pdf</a>, <a href="/format/2309.00846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> pSTarC: Pseudo Source Guided Target Clustering for Fully Test-Time  Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sreenivas%2C+M">Manogna Sreenivas</a>, 
<a href="/search/cs?searchtype=author&query=Chakrabarty%2C+G">Goirik Chakrabarty</a>, 
<a href="/search/cs?searchtype=author&query=Biswas%2C+S">Soma Biswas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00904" title="Abstract">arXiv:2309.00904</a> (replaced) [<a href="/pdf/2309.00904" title="Download PDF">pdf</a>, <a href="/format/2309.00904" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Developmental Scaffolding with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Celik%2C+B">Batuhan Celik</a>, 
<a href="/search/cs?searchtype=author&query=Ahmetoglu%2C+A">Alper Ahmetoglu</a>, 
<a href="/search/cs?searchtype=author&query=Ugur%2C+E">Emre Ugur</a>, 
<a href="/search/cs?searchtype=author&query=Oztop%2C+E">Erhan Oztop</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in IEEE Transactions on Robotics \copyright IEEE2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01897" title="Abstract">arXiv:2309.01897</a> (replaced) [<a href="/pdf/2309.01897" title="Download PDF">pdf</a>, <a href="/format/2309.01897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inferring Actual Treatment Pathways from Patient Records
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wilkins-Caruana%2C+A">Adrian Wilkins-Caruana</a>, 
<a href="/search/cs?searchtype=author&query=Bandara%2C+M">Madhushi Bandara</a>, 
<a href="/search/cs?searchtype=author&query=Musial%2C+K">Katarzyna Musial</a>, 
<a href="/search/cs?searchtype=author&query=Catchpoole%2C+D">Daniel Catchpoole</a>, 
<a href="/search/cs?searchtype=author&query=Kennedy%2C+P+J">Paul J. Kennedy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02185" title="Abstract">arXiv:2309.02185</a> (replaced) [<a href="/pdf/2309.02185" title="Download PDF">pdf</a>, <a href="/format/2309.02185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BEVTrack: A Simple and Strong Baseline for 3D Single Object Tracking in  Bird&#x27;s-Eye View
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuxiang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yingqi Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+J">Jiahao Nie</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+Z">Zheng-Jun Zha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The code will be released at <a href="https://github.com/xmm-prio/BEVTrack">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04153" title="Abstract">arXiv:2309.04153</a> (replaced) [<a href="/pdf/2309.04153" title="Download PDF">pdf</a>, <a href="/format/2309.04153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mapping EEG Signals to Visual Stimuli: A Deep Learning Approach to Match  vs. Mismatch Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yiqian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhengqiao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingdong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05254" title="Abstract">arXiv:2309.05254</a> (replaced) [<a href="/pdf/2309.05254" title="Download PDF">pdf</a>, <a href="/format/2309.05254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Better Data Exploitation in Self-Supervised Monocular Depth  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinfeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Lingtong Kong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, accepted by IEEE Robotics and Automation Letters (RA-L, 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07675" title="Abstract">arXiv:2309.07675</a> (replaced) [<a href="/pdf/2309.07675" title="Download PDF">pdf</a>, <a href="/format/2309.07675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Goal Space Abstraction in Hierarchical Reinforcement Learning via  Set-Based Reachability Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zadem%2C+M">Mehdi Zadem</a>, 
<a href="/search/cs?searchtype=author&query=Mover%2C+S">Sergio Mover</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+S+M">Sao Mai Nguyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08273" title="Abstract">arXiv:2309.08273</a> (replaced) [<a href="/pdf/2309.08273" title="Download PDF">pdf</a>, <a href="/format/2309.08273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Disentangling of Facial Representations with 3D-aware  Latent Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ruian He</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Z">Zhen Xing</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+W">Weimin Tan</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+B">Bo Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08549" title="Abstract">arXiv:2309.08549</a> (replaced) [<a href="/pdf/2309.08549" title="Download PDF">pdf</a>, <a href="/format/2309.08549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HINT: Healthy Influential-Noise based Training to Defend against Data  Poisoning Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Van%2C+M">Minh-Hao Van</a>, 
<a href="/search/cs?searchtype=author&query=Carey%2C+A+N">Alycia N. Carey</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xintao Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11983" title="Abstract">arXiv:2309.11983</a> (replaced) [<a href="/pdf/2309.11983" title="Download PDF">pdf</a>, <a href="/format/2309.11983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variational Connectionist Temporal Classification for Order-Preserving  Sequence Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nan%2C+Z">Zheng Nan</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+T">Ting Dang</a>, 
<a href="/search/cs?searchtype=author&query=Sethu%2C+V">Vidhyasaharan Sethu</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+B">Beena Ahmed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13289" title="Abstract">arXiv:2309.13289</a> (replaced) [<a href="/pdf/2309.13289" title="Download PDF">pdf</a>, <a href="/format/2309.13289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> USL-Net: Uncertainty Self-Learning Network for Unsupervised Skin Lesion  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaofan Li</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Bo Peng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jie Hu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Changyou Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Daipeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhuyang Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 9 figures, 71 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13972" title="Abstract">arXiv:2309.13972</a> (replaced) [<a href="/pdf/2309.13972" title="Download PDF">pdf</a>, <a href="/ps/2309.13972" title="Download PostScript">ps</a>, <a href="/format/2309.13972" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Audio classification with Dilated Convolution with Learnable Spacings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khalfaoui-Hassani%2C+I">Ismail Khalfaoui-Hassani</a>, 
<a href="/search/cs?searchtype=author&query=Masquelier%2C+T">Timoth&#xe9;e Masquelier</a>, 
<a href="/search/cs?searchtype=author&query=Pellegrini%2C+T">Thomas Pellegrini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14845" title="Abstract">arXiv:2309.14845</a> (replaced) [<a href="/pdf/2309.14845" title="Download PDF">pdf</a>, <a href="/format/2309.14845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Neural Network Based Method for Path Planning Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Diao%2C+X">Xingrong Diao</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+W">Wenzheng Chi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiankun Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16020" title="Abstract">arXiv:2309.16020</a> (replaced) [<a href="/pdf/2309.16020" title="Download PDF">pdf</a>, <a href="/format/2309.16020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GeoCLIP: Clip-Inspired Alignment between Locations and Images for  Effective Worldwide Geo-localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cepeda%2C+V+V">Vicente Vivanco Cepeda</a>, 
<a href="/search/cs?searchtype=author&query=Nayak%2C+G+K">Gaurav Kumar Nayak</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+M">Mubarak Shah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00603" title="Abstract">arXiv:2310.00603</a> (replaced) [<a href="/pdf/2310.00603" title="Download PDF">pdf</a>, <a href="/format/2310.00603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faithful Explanations of Black-box NLP Models Using LLM-generated  Counterfactuals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gat%2C+Y">Yair Gat</a>, 
<a href="/search/cs?searchtype=author&query=Calderon%2C+N">Nitay Calderon</a>, 
<a href="/search/cs?searchtype=author&query=Feder%2C+A">Amir Feder</a>, 
<a href="/search/cs?searchtype=author&query=Chapanin%2C+A">Alexander Chapanin</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Amit Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Reichart%2C+R">Roi Reichart</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00615" title="Abstract">arXiv:2310.00615</a> (replaced) [<a href="/pdf/2310.00615" title="Download PDF">pdf</a>, <a href="/format/2310.00615" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scene-aware Human Motion Forecasting via Mutual Distance Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xing%2C+C">Chaoyue Xing</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+W">Wei Mao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Miaomiao Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00938" title="Abstract">arXiv:2310.00938</a> (replaced) [<a href="/pdf/2310.00938" title="Download PDF">pdf</a>, <a href="/ps/2310.00938" title="Download PostScript">ps</a>, <a href="/format/2310.00938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An FPRAS for two terminal reliability in directed acyclic graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+W">Weiming Feng</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Heng Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages. v2: improved running time
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01012" title="Abstract">arXiv:2310.01012</a> (replaced) [<a href="/pdf/2310.01012" title="Download PDF">pdf</a>, <a href="/format/2310.01012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Algorithms for the CCA Family: Unconstrained Objectives with  Unbiased Gradients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chapman%2C+J">James Chapman</a>, 
<a href="/search/cs?searchtype=author&query=Wells%2C+L">Lennie Wells</a>, 
<a href="/search/cs?searchtype=author&query=Aguila%2C+A+L">Ana Lawry Aguila</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03214" title="Abstract">arXiv:2310.03214</a> (replaced) [<a href="/pdf/2310.03214" title="Download PDF">pdf</a>, <a href="/format/2310.03214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FreshLLMs: Refreshing Large Language Models with Search Engine  Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vu%2C+T">Tu Vu</a>, 
<a href="/search/cs?searchtype=author&query=Iyyer%2C+M">Mohit Iyyer</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuezhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Constant%2C+N">Noah Constant</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jerry Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jason Wei</a>, 
<a href="/search/cs?searchtype=author&query=Tar%2C+C">Chris Tar</a>, 
<a href="/search/cs?searchtype=author&query=Sung%2C+Y">Yun-Hsuan Sung</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Denny Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+Q">Quoc Le</a>, 
<a href="/search/cs?searchtype=author&query=Luong%2C+T">Thang Luong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint, 26 pages, 10 figures, 5 tables; Added FreshEval
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03789" title="Abstract">arXiv:2310.03789</a> (replaced) [<a href="/pdf/2310.03789" title="Download PDF">pdf</a>, <a href="/format/2310.03789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Droplets of Good Representations: Grokking as a First Order Phase  Transition in Two Layer Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Rubin%2C+N">Noa Rubin</a>, 
<a href="/search/stat?searchtype=author&query=Seroussi%2C+I">Inbar Seroussi</a>, 
<a href="/search/stat?searchtype=author&query=Ringel%2C+Z">Zohar Ringel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08420" title="Abstract">arXiv:2310.08420</a> (replaced) [<a href="/pdf/2310.08420" title="Download PDF">pdf</a>, <a href="/format/2310.08420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Attention-Prompted Prediction and Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+S">Siyi Gu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+B">Bo Pan</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+G">Guangji Bai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaofeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Liang Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08568" title="Abstract">arXiv:2310.08568</a> (replaced) [<a href="/pdf/2310.08568" title="Download PDF">pdf</a>, <a href="/format/2310.08568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Placement Optimization of Substitutable Products
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Housni%2C+O+E">Omar El Housni</a>, 
<a href="/search/cs?searchtype=author&query=Udwani%2C+R">Rajan Udwani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08897" title="Abstract">arXiv:2310.08897</a> (replaced) [<a href="/pdf/2310.08897" title="Download PDF">pdf</a>, <a href="/format/2310.08897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self supervised convolutional kernel based handcrafted feature  harmonization: Enhanced left ventricle hypertension disease phenotyping on  echocardiography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lee%2C+J">Jina Lee</a>, 
<a href="/search/eess?searchtype=author&query=Hong%2C+Y">Youngtaek Hong</a>, 
<a href="/search/eess?searchtype=author&query=Jeong%2C+D">Dawun Jeong</a>, 
<a href="/search/eess?searchtype=author&query=Jang%2C+Y">Yeonggul Jang</a>, 
<a href="/search/eess?searchtype=author&query=Jeon%2C+J">Jaeik Jeon</a>, 
<a href="/search/eess?searchtype=author&query=Jeong%2C+S">Sihyeon Jeong</a>, 
<a href="/search/eess?searchtype=author&query=Jung%2C+T">Taekgeun Jung</a>, 
<a href="/search/eess?searchtype=author&query=Yoon%2C+Y+E">Yeonyee E. Yoon</a>, 
<a href="/search/eess?searchtype=author&query=Moon%2C+I">Inki Moon</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+S">Seung-Ah Lee</a>, 
<a href="/search/eess?searchtype=author&query=Chang%2C+H">Hyuk-Jae Chang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09832" title="Abstract">arXiv:2310.09832</a> (replaced) [<a href="/pdf/2310.09832" title="Download PDF">pdf</a>, <a href="/format/2310.09832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Merging Experts into One: Improving Computational Efficiency of Mixture  of Experts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+S">Shwai He</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+R">Run-Ze Fan</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Liang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Li Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 Main Conference (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09886" title="Abstract">arXiv:2310.09886</a> (replaced) [<a href="/pdf/2310.09886" title="Download PDF">pdf</a>, <a href="/format/2310.09886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lifelong Sequence Generation with Dynamic Module Expansion and  Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+C">Chengwei Qin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Joty%2C+S">Shafiq Joty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12036" title="Abstract">arXiv:2310.12036</a> (replaced) [<a href="/pdf/2310.12036" title="Download PDF">pdf</a>, <a href="/format/2310.12036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A General Theoretical Paradigm to Understand Learning from Human  Preferences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azar%2C+M+G">Mohammad Gheshlaghi Azar</a>, 
<a href="/search/cs?searchtype=author&query=Rowland%2C+M">Mark Rowland</a>, 
<a href="/search/cs?searchtype=author&query=Piot%2C+B">Bilal Piot</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+D">Daniel Guo</a>, 
<a href="/search/cs?searchtype=author&query=Calandriello%2C+D">Daniele Calandriello</a>, 
<a href="/search/cs?searchtype=author&query=Valko%2C+M">Michal Valko</a>, 
<a href="/search/cs?searchtype=author&query=Munos%2C+R">R&#xe9;mi Munos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12942" title="Abstract">arXiv:2310.12942</a> (replaced) [<a href="/pdf/2310.12942" title="Download PDF">pdf</a>, <a href="/format/2310.12942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Representational Capacity of Recurrent Neural Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nowak%2C+F">Franz Nowak</a>, 
<a href="/search/cs?searchtype=author&query=Svete%2C+A">Anej Svete</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+L">Li Du</a>, 
<a href="/search/cs?searchtype=author&query=Cotterell%2C+R">Ryan Cotterell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published at EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13458" title="Abstract">arXiv:2310.13458</a> (replaced) [<a href="/pdf/2310.13458" title="Download PDF">pdf</a>, <a href="/format/2310.13458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Correspondence learning between morphologically different robots via  task demonstrations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aktas%2C+H">Hakan Aktas</a>, 
<a href="/search/cs?searchtype=author&query=Nagai%2C+Y">Yukie Nagai</a>, 
<a href="/search/cs?searchtype=author&query=Asada%2C+M">Minoru Asada</a>, 
<a href="/search/cs?searchtype=author&query=Oztop%2C+E">Erhan Oztop</a>, 
<a href="/search/cs?searchtype=author&query=Ugur%2C+E">Emre Ugur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 12 figures, Submitted to IEEE Robotics Automation Letters (RA-L)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14860" title="Abstract">arXiv:2310.14860</a> (replaced) [<a href="/pdf/2310.14860" title="Download PDF">pdf</a>, <a href="/format/2310.14860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Tuning of Robotic Polishing Skills based on Force Feedback  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zhouyi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zezheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhitao Gao</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+F">Fangyu Peng</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xiaowei Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Rong Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by The 2023 IEEE International Conference on Robotics and Biomimetics (IEEE ROBIO 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15290" title="Abstract">arXiv:2310.15290</a> (replaced) [<a href="/pdf/2310.15290" title="Download PDF">pdf</a>, <a href="/format/2310.15290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reliable Generation of EHR Time Series via Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+M">Muhang Tian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bernie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+A">Allan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Shiyi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A+R">Anru R. Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19274" title="Abstract">arXiv:2310.19274</a> (replaced) [<a href="/pdf/2310.19274" title="Download PDF">pdf</a>, <a href="/format/2310.19274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prediction of Effective Elastic Moduli of Rocks using Graph Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chung%2C+J">Jaehong Chung</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+R">Rasool Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">WaiChing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+W">Wei Cai</a>, 
<a href="/search/cs?searchtype=author&query=Mukerji%2C+T">Tapan Mukerji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Physics (physics.comp-ph); Geophysics (physics.geo-ph)

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19680" title="Abstract">arXiv:2310.19680</a> (replaced) [<a href="/pdf/2310.19680" title="Download PDF">pdf</a>, <a href="/format/2310.19680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating Pre-trained Language Model into Neural Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hwang%2C+S">Soon-Jae Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+C">Chang-Sung Jeong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20477" title="Abstract">arXiv:2310.20477</a> (replaced) [<a href="/pdf/2310.20477" title="Download PDF">pdf</a>, <a href="/format/2310.20477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Practitioner Perspectives On Training Data Attribution  Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+E">Elisa Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Kortukov%2C+E">Evgenii Kortukov</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J+Y">Jean Y. Song</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+S+J">Seong Joon Oh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS XAI in Action workshop 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00321" title="Abstract">arXiv:2311.00321</a> (replaced) [<a href="/pdf/2311.00321" title="Download PDF">pdf</a>, <a href="/format/2311.00321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HARE: Explainable Hate Speech Detection with Step-by-Step Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yongjin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Joonkee Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yujin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+N">Namgyu Ho</a>, 
<a href="/search/cs?searchtype=author&query=Thorne%2C+J">James Thorne</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+S">Se-young Yun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of EMNLP 2023; The first three authors contribute equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00474" title="Abstract">arXiv:2311.00474</a> (replaced) [<a href="/pdf/2311.00474" title="Download PDF">pdf</a>, <a href="/ps/2311.00474" title="Download PostScript">ps</a>, <a href="/format/2311.00474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion models for probabilistic programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dirmeier%2C+S">Simon Dirmeier</a>, 
<a href="/search/cs?searchtype=author&query=Perez-Cruz%2C+F">Fernando Perez-Cruz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> * Fix mathematical typos * Add conference info
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01483" title="Abstract">arXiv:2311.01483</a> (replaced) [<a href="/pdf/2311.01483" title="Download PDF">pdf</a>, <a href="/format/2311.01483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedSN: A General Federated Learning Framework over LEO Satellite  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zihan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xianhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yue Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01588" title="Abstract">arXiv:2311.01588</a> (replaced) [<a href="/pdf/2311.01588" title="Download PDF">pdf</a>, <a href="/format/2311.01588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Adaptive Graph Neural Networks for Constraining Cosmological  Parameters Across Multiple Data Sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Roncoli%2C+A">Andrea Roncoli</a>, 
<a href="/search/astro-ph?searchtype=author&query=%C4%86iprijanovi%C4%87%2C+A">Aleksandra &#x106;iprijanovi&#x107;</a>, 
<a href="/search/astro-ph?searchtype=author&query=Voetberg%2C+M">Maggie Voetberg</a>, 
<a href="/search/astro-ph?searchtype=author&query=Villaescusa-Navarro%2C+F">Francisco Villaescusa-Navarro</a>, 
<a href="/search/astro-ph?searchtype=author&query=Nord%2C+B">Brian Nord</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in Machine Learning and the Physical Sciences Workshop at NeurIPS 2023; 9 pages, 2 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cosmology and Nongalactic Astrophysics (astro-ph.CO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02476" title="Abstract">arXiv:2311.02476</a> (replaced) [<a href="/pdf/2311.02476" title="Download PDF">pdf</a>, <a href="/format/2311.02476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forecasting Success of Computer Science Professors and Students Based on  Their Academic and Personal Backgrounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kalhor%2C+G">Ghazal Kalhor</a>, 
<a href="/search/cs?searchtype=author&query=Bahrak%2C+B">Behnam Bahrak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02921" title="Abstract">arXiv:2311.02921</a> (replaced) [<a href="/pdf/2311.02921" title="Download PDF">pdf</a>, <a href="/format/2311.02921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Edge2Node: Reducing Edge Prediction to Node Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahmati%2C+Z">Zahed Rahmati</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03105" title="Abstract">arXiv:2311.03105</a> (replaced) [<a href="/pdf/2311.03105" title="Download PDF">pdf</a>, <a href="/ps/2311.03105" title="Download PostScript">ps</a>, <a href="/format/2311.03105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pelvic floor MRI segmentation based on semi-supervised deep learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zuo%2C+J">Jianwei Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+F">Fei Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhuhui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ashton-Miller%2C+J+A">James A. Ashton-Miller</a>, 
<a href="/search/cs?searchtype=author&query=Delancey%2C+J+O+L">John O.L. Delancey</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jiajia Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03328" title="Abstract">arXiv:2311.03328</a> (replaced) [<a href="/pdf/2311.03328" title="Download PDF">pdf</a>, <a href="/format/2311.03328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Asynchrony, Memory, and Communication: Separations and Landscapes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Flocchini%2C+P">Paola Flocchini</a>, 
<a href="/search/cs?searchtype=author&query=Santoro%2C+N">Nicola Santoro</a>, 
<a href="/search/cs?searchtype=author&query=Sudo%2C+Y">Yuichi Sudo</a>, 
<a href="/search/cs?searchtype=author&query=Wada%2C+K">Koichi Wada</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03738" title="Abstract">arXiv:2311.03738</a> (replaced) [<a href="/pdf/2311.03738" title="Download PDF">pdf</a>, <a href="/format/2311.03738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> deep-REMAP: Parameterization of Stellar Spectra Using Regularized  Multi-Task Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Gilda%2C+S">Sankalp Gilda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 main pages + 2 figures. Accepted to the ML4PS workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Solar and Stellar Astrophysics (astro-ph.SR)</span>; Astrophysics of Galaxies (astro-ph.GA); Instrumentation and Methods for Astrophysics (astro-ph.IM); Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03906" title="Abstract">arXiv:2311.03906</a> (replaced) [<a href="/pdf/2311.03906" title="Download PDF">pdf</a>, <a href="/format/2311.03906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SymPhase: Phase Symbolization for Fast Simulation of Stabilizer Circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Fang%2C+W">Wang Fang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ying%2C+M">Mingsheng Ying</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures; v2: fix inappropriate use of Stim
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03943" title="Abstract">arXiv:2311.03943</a> (replaced) [<a href="/pdf/2311.03943" title="Download PDF">pdf</a>, <a href="/format/2311.03943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLIP Guided Image-perceptive Prompt Learning for Image Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weiwen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+Q">Qiuhong Ke</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zinuo Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A trial work to the image enhancement
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05997" title="Abstract">arXiv:2311.05997</a> (replaced) [<a href="/pdf/2311.05997" title="Download PDF">pdf</a>, <a href="/format/2311.05997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JARVIS-1: Open-World Multi-task Agents with Memory-Augmented Multimodal  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+S">Shaofei Cai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Anji Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yonggang Jin</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Jinbing Hou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bowei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Haowei Lin</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhaofeng He</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zilong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yaodong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaojian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yitao Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2206.11795">arXiv:2206.11795</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08228" title="Abstract">arXiv:2311.08228</a> (replaced) [<a href="/pdf/2311.08228" title="Download PDF">pdf</a>, <a href="/format/2311.08228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Counterfactual Explanation for Regression via Disentanglement in Latent  Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Broelemann%2C+K">Klaus Broelemann</a>, 
<a href="/search/cs?searchtype=author&query=Kasneci%2C+G">Gjergji Kasneci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CXAI workshop @ ICDM 2023. arXiv admin note: text overlap with <a href="/abs/2307.13390">arXiv:2307.13390</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08350" title="Abstract">arXiv:2311.08350</a> (replaced) [<a href="/pdf/2311.08350" title="Download PDF">pdf</a>, <a href="/format/2311.08350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChoralSynth: Synthetic Dataset of Choral Singing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Narang%2C+J">Jyoti Narang</a>, 
<a href="/search/cs?searchtype=author&query=De+La+Vega%2C+V">Viviana De La Vega</a>, 
<a href="/search/cs?searchtype=author&query=Lizarraga%2C+X">Xavier Lizarraga</a>, 
<a href="/search/cs?searchtype=author&query=Mayor%2C+O">Oscar Mayor</a>, 
<a href="/search/cs?searchtype=author&query=Parra%2C+H">Hector Parra</a>, 
<a href="/search/cs?searchtype=author&query=Janer%2C+J">Jordi Janer</a>, 
<a href="/search/cs?searchtype=author&query=Serra%2C+X">Xavier Serra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Dataset Link: <a href="https://doi.org/10.5281/zenodo.10137883">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Information Retrieval (cs.IR); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08936" title="Abstract">arXiv:2311.08936</a> (replaced) [<a href="/pdf/2311.08936" title="Download PDF">pdf</a>, <a href="/format/2311.08936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Confident Naturalness Explanation (CNE): A Framework to Explain and  Assess Patterns Forming Naturalness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Emam%2C+A">Ahmed Emam</a>, 
<a href="/search/cs?searchtype=author&query=Farag%2C+M">Mohamed Farag</a>, 
<a href="/search/cs?searchtype=author&query=Roscher%2C+R">Ribana Roscher</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10242" title="Abstract">arXiv:2311.10242</a> (replaced) [<a href="/pdf/2311.10242" title="Download PDF">pdf</a>, <a href="/ps/2311.10242" title="Download PostScript">ps</a>, <a href="/format/2311.10242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancements in Generative AI: A Comprehensive Review of GANs, GPT,  Autoencoders, Diffusion Model, and Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bengesi%2C+S">Staphord Bengesi</a>, 
<a href="/search/cs?searchtype=author&query=El-Sayed%2C+H">Hoda El-Sayed</a>, 
<a href="/search/cs?searchtype=author&query=Sarker%2C+M+K">Md Kamruzzaman Sarker</a>, 
<a href="/search/cs?searchtype=author&query=Houkpati%2C+Y">Yao Houkpati</a>, 
<a href="/search/cs?searchtype=author&query=Irungu%2C+J">John Irungu</a>, 
<a href="/search/cs?searchtype=author&query=Oladunni%2C+T">Timothy Oladunni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10256" title="Abstract">arXiv:2311.10256</a> (replaced) [<a href="/pdf/2311.10256" title="Download PDF">pdf</a>, <a href="/ps/2311.10256" title="Download PostScript">ps</a>, <a href="/format/2311.10256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring User Perceptions of Virtual Reality Scene Design in Metaverse  Learning Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferdousi%2C+R">Rahatara Ferdousi</a>, 
<a href="/search/cs?searchtype=author&query=Faisal%2C+M">Mohammed Faisal</a>, 
<a href="/search/cs?searchtype=author&query=Laamarti%2C+F">Fedwa Laamarti</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chunsheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Saddik%2C+A+E">Abdulmotaleb El Saddik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages,3 figures, accepted to present at IEEE 42nd International Conference on Consumer Electronics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10500" title="Abstract">arXiv:2311.10500</a> (replaced) [<a href="/pdf/2311.10500" title="Download PDF">pdf</a>, <a href="/format/2311.10500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Principle to Practice: Vertical Data Minimization for Machine  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Staab%2C+R">Robin Staab</a>, 
<a href="/search/cs?searchtype=author&query=Jovanovi%C4%87%2C+N">Nikola Jovanovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Balunovi%C4%87%2C+M">Mislav Balunovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Vechev%2C+M">Martin Vechev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE S&amp;P 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10732" title="Abstract">arXiv:2311.10732</a> (replaced) [<a href="/pdf/2311.10732" title="Download PDF">pdf</a>, <a href="/ps/2311.10732" title="Download PostScript">ps</a>, <a href="/format/2311.10732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> White Paper: The Generative Education (GenEd) Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leiker%2C+D">Daniel Leiker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10747" title="Abstract">arXiv:2311.10747</a> (replaced) [<a href="/pdf/2311.10747" title="Download PDF">pdf</a>, <a href="/format/2311.10747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safety-aware Causal Representation for Trustworthy Reinforcement  Learning in Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Haohong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+W">Wenhao Ding</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zuxin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+Y">Yaru Niu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiacheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+Y">Yuming Niu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Ding Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10813" title="Abstract">arXiv:2311.10813</a> (replaced) [<a href="/pdf/2311.10813" title="Download PDF">pdf</a>, <a href="/format/2311.10813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Language Agent for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+J">Jiageng Mao</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Junjie Ye</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Y">Yuxi Qian</a>, 
<a href="/search/cs?searchtype=author&query=Pavone%2C+M">Marco Pavone</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yue Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10840" title="Abstract">arXiv:2311.10840</a> (replaced) [<a href="/pdf/2311.10840" title="Download PDF">pdf</a>, <a href="/ps/2311.10840" title="Download PostScript">ps</a>, <a href="/format/2311.10840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integration and Implementation Strategies for AI Algorithm Deployment  with Smart Routing Rules and Workflow Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Erdal%2C+B+S">Barbaros Selnur Erdal</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+V">Vikash Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Demirer%2C+M">Mutlu Demirer</a>, 
<a href="/search/cs?searchtype=author&query=Fair%2C+K+H">Kim H. Fair</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+R+D">Richard D. White</a>, 
<a href="/search/cs?searchtype=author&query=Blair%2C+J">Jeff Blair</a>, 
<a href="/search/cs?searchtype=author&query=Deichert%2C+B">Barbara Deichert</a>, 
<a href="/search/cs?searchtype=author&query=Lafleur%2C+L">Laurie Lafleur</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+M+M">Ming Melvin Qin</a>, 
<a href="/search/cs?searchtype=author&query=Bericat%2C+D">David Bericat</a>, 
<a href="/search/cs?searchtype=author&query=Genereaux%2C+B">Brad Genereaux</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10863" title="Abstract">arXiv:2311.10863</a> (replaced) [<a href="/pdf/2311.10863" title="Download PDF">pdf</a>, <a href="/format/2311.10863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Verified Compositional Neuro-Symbolic Control for Stochastic Systems  with Temporal Logic Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haojun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zihe Sun</a>, 
<a href="/search/cs?searchtype=author&query=Kantaros%2C+Y">Yiannis Kantaros</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2209.06130">arXiv:2209.06130</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10911" title="Abstract">arXiv:2311.10911</a> (replaced) [<a href="/pdf/2311.10911" title="Download PDF">pdf</a>, <a href="/format/2311.10911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dazed &amp; Confused: A Large-Scale Real-World User Study of reCAPTCHAv2
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Searles%2C+A">Andrew Searles</a>, 
<a href="/search/cs?searchtype=author&query=Prapty%2C+R+T">Renascence Tarafder Prapty</a>, 
<a href="/search/cs?searchtype=author&query=Tsudik%2C+G">Gene Tsudik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10986" title="Abstract">arXiv:2311.10986</a> (replaced) [<a href="/pdf/2311.10986" title="Download PDF">pdf</a>, <a href="/format/2311.10986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EdgeFM: Leveraging Foundation Model for Open-set Learning on the Edge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bufang Yang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Lixing He</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+N">Neiwen Ling</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zhenyu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+G">Guoliang Xing</a>, 
<a href="/search/cs?searchtype=author&query=Shuai%2C+X">Xian Shuai</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiaozhe Ren</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xin Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 21th ACM Conference on Embedded Networked Sensor Systems (SenSys 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10990" title="Abstract">arXiv:2311.10990</a> (replaced) [<a href="/pdf/2311.10990" title="Download PDF">pdf</a>, <a href="/format/2311.10990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Centralized or Decentralized?&quot;: Concerns and Value Judgments of  Stakeholders in the Non-Fungible Tokens (NFTs) Market
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yunpeng Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+B">Bufan Deng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Siqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K+Z">Kyrie Zhixuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=LC%2C+R">Ray LC</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Luyao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+X">Xin Tong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CSCW 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11045" title="Abstract">arXiv:2311.11045</a> (replaced) [<a href="/pdf/2311.11045" title="Download PDF">pdf</a>, <a href="/format/2311.11045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Orca 2: Teaching Small Language Models How to Reason
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mitra%2C+A">Arindam Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Del+Corro%2C+L">Luciano Del Corro</a>, 
<a href="/search/cs?searchtype=author&query=Mahajan%2C+S">Shweti Mahajan</a>, 
<a href="/search/cs?searchtype=author&query=Codas%2C+A">Andres Codas</a>, 
<a href="/search/cs?searchtype=author&query=Simoes%2C+C">Clarisse Simoes</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+S">Sahaj Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuxi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Razdaibiedina%2C+A">Anastasia Razdaibiedina</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+E">Erik Jones</a>, 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+K">Kriti Aggarwal</a>, 
<a href="/search/cs?searchtype=author&query=Palangi%2C+H">Hamid Palangi</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+G">Guoqing Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Rosset%2C+C">Corby Rosset</a>, 
<a href="/search/cs?searchtype=author&query=Khanpour%2C+H">Hamed Khanpour</a>, 
<a href="/search/cs?searchtype=author&query=Awadallah%2C+A">Ahmed Awadallah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Added url to model weights fixed typo in Author name
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11254" title="Abstract">arXiv:2311.11254</a> (replaced) [<a href="/pdf/2311.11254" title="Download PDF">pdf</a>, <a href="/format/2311.11254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BOIS: Bayesian Optimization of Interconnected Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Gonz%C3%A1lez%2C+L+D">Leonardo D. Gonz&#xe1;lez</a>, 
<a href="/search/stat?searchtype=author&query=Zavala%2C+V+M">Victor M. Zavala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11284" title="Abstract">arXiv:2311.11284</a> (replaced) [<a href="/pdf/2311.11284" title="Download PDF">pdf</a>, <a href="/format/2311.11284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LucidDreamer: Towards High-Fidelity Text-to-3D Generation via Interval  Score Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yixun Liang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jiantao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haodong Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaogang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yingcong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first two authors contributed equally to this work. Our code will be available at: <a href="https://github.com/EnVision-Research/LucidDreamer">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11313" title="Abstract">arXiv:2311.11313</a> (replaced) [<a href="/pdf/2311.11313" title="Download PDF">pdf</a>, <a href="/format/2311.11313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symbolic Execution for Quantum Error Correction Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Fang%2C+W">Wang Fang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ying%2C+M">Mingsheng Ying</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v2: fix inappropriate use of Stim
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11317" title="Abstract">arXiv:2311.11317</a> (replaced) [<a href="/pdf/2311.11317" title="Download PDF">pdf</a>, <a href="/format/2311.11317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discrete approximations of Gaussian smoothing and Gaussian derivatives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lindeberg%2C+T">Tony Lindeberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 34 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11388" title="Abstract">arXiv:2311.11388</a> (replaced) [<a href="/pdf/2311.11388" title="Download PDF">pdf</a>, <a href="/ps/2311.11388" title="Download PostScript">ps</a>, <a href="/format/2311.11388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Culture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brinkmann%2C+L">Levin Brinkmann</a>, 
<a href="/search/cs?searchtype=author&query=Baumann%2C+F">Fabian Baumann</a>, 
<a href="/search/cs?searchtype=author&query=Bonnefon%2C+J">Jean-Fran&#xe7;ois Bonnefon</a>, 
<a href="/search/cs?searchtype=author&query=Derex%2C+M">Maxime Derex</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+T+F">Thomas F. M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Nussberger%2C+A">Anne-Marie Nussberger</a>, 
<a href="/search/cs?searchtype=author&query=Czaplicka%2C+A">Agnieszka Czaplicka</a>, 
<a href="/search/cs?searchtype=author&query=Acerbi%2C+A">Alberto Acerbi</a>, 
<a href="/search/cs?searchtype=author&query=Griffiths%2C+T+L">Thomas L. Griffiths</a>, 
<a href="/search/cs?searchtype=author&query=Henrich%2C+J">Joseph Henrich</a>, 
<a href="/search/cs?searchtype=author&query=Leibo%2C+J+Z">Joel Z. Leibo</a>, 
<a href="/search/cs?searchtype=author&query=McElreath%2C+R">Richard McElreath</a>, 
<a href="/search/cs?searchtype=author&query=Oudeyer%2C+P">Pierre-Yves Oudeyer</a>, 
<a href="/search/cs?searchtype=author&query=Stray%2C+J">Jonathan Stray</a>, 
<a href="/search/cs?searchtype=author&query=Rahwan%2C+I">Iyad Rahwan</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Nat Hum Behav 7, 1855-1868 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11609" title="Abstract">arXiv:2311.11609</a> (replaced) [<a href="/pdf/2311.11609" title="Download PDF">pdf</a>, <a href="/ps/2311.11609" title="Download PostScript">ps</a>, <a href="/format/2311.11609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Research assessment under debate: disentangling the interest around the  DORA declaration on Twitter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Orduna-Malea%2C+E">E. Orduna-Malea</a>, 
<a href="/search/cs?searchtype=author&query=Bautista-Puig%2C+N">N. Bautista-Puig</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11655" title="Abstract">arXiv:2311.11655</a> (replaced) [<a href="/pdf/2311.11655" title="Download PDF">pdf</a>, <a href="/ps/2311.11655" title="Download PostScript">ps</a>, <a href="/format/2311.11655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Peeking Inside the Schufa Blackbox: Explaining the German Housing  Scoring System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kern%2C+D">Dean-Robin Kern</a>, 
<a href="/search/cs?searchtype=author&query=Stevens%2C+G">Gunnar Stevens</a>, 
<a href="/search/cs?searchtype=author&query=Dethier%2C+E">Erik Dethier</a>, 
<a href="/search/cs?searchtype=author&query=Naveed%2C+S">Sidra Naveed</a>, 
<a href="/search/cs?searchtype=author&query=Alizadeh%2C+F">Fatemeh Alizadeh</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+D">Delong Du</a>, 
<a href="/search/cs?searchtype=author&query=Shajalal%2C+M">Md Shajalal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures, ACM CHI 2023 Workshop on Human-Centered Explainable AI (HCXAI)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11772" title="Abstract">arXiv:2311.11772</a> (replaced) [<a href="/pdf/2311.11772" title="Download PDF">pdf</a>, <a href="/format/2311.11772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Good Feature Extractor Is All You Need for Weakly Supervised Learning  in Histopathology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=W%C3%B6lflein%2C+G">Georg W&#xf6;lflein</a>, 
<a href="/search/cs?searchtype=author&query=Ferber%2C+D">Dyke Ferber</a>, 
<a href="/search/cs?searchtype=author&query=Meneghetti%2C+A+R">Asier Rabasco Meneghetti</a>, 
<a href="/search/cs?searchtype=author&query=Nahhas%2C+O+S+M+E">Omar S. M. El Nahhas</a>, 
<a href="/search/cs?searchtype=author&query=Truhn%2C+D">Daniel Truhn</a>, 
<a href="/search/cs?searchtype=author&query=Carrero%2C+Z+I">Zunamys I. Carrero</a>, 
<a href="/search/cs?searchtype=author&query=Harrison%2C+D+J">David J. Harrison</a>, 
<a href="/search/cs?searchtype=author&query=Arandjelovi%C4%87%2C+O">Ognjen Arandjelovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Kather%2C+J+N">Jakob N. Kather</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11819" title="Abstract">arXiv:2311.11819</a> (replaced) [<a href="/pdf/2311.11819" title="Download PDF">pdf</a>, <a href="/ps/2311.11819" title="Download PostScript">ps</a>, <a href="/format/2311.11819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized super-resolution 4D Flow MRI $\unicode{x2013}$ using  ensemble learning to extend across the cardiovascular system
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ericsson%2C+L">Leon Ericsson</a>, 
<a href="/search/eess?searchtype=author&query=Hjalmarsson%2C+A">Adam Hjalmarsson</a>, 
<a href="/search/eess?searchtype=author&query=Akbar%2C+M+U">Muhammad Usman Akbar</a>, 
<a href="/search/eess?searchtype=author&query=Ferdian%2C+E">Edward Ferdian</a>, 
<a href="/search/eess?searchtype=author&query=Bonini%2C+M">Mia Bonini</a>, 
<a href="/search/eess?searchtype=author&query=Hardy%2C+B">Brandon Hardy</a>, 
<a href="/search/eess?searchtype=author&query=Schollenberger%2C+J">Jonas Schollenberger</a>, 
<a href="/search/eess?searchtype=author&query=Aristova%2C+M">Maria Aristova</a>, 
<a href="/search/eess?searchtype=author&query=Winter%2C+P">Patrick Winter</a>, 
<a href="/search/eess?searchtype=author&query=Burris%2C+N">Nicholas Burris</a>, 
<a href="/search/eess?searchtype=author&query=Fyrdahl%2C+A">Alexander Fyrdahl</a>, 
<a href="/search/eess?searchtype=author&query=Sigfridsson%2C+A">Andreas Sigfridsson</a>, 
<a href="/search/eess?searchtype=author&query=Schnell%2C+S">Susanne Schnell</a>, 
<a href="/search/eess?searchtype=author&query=Figueroa%2C+C+A">C. Alberto Figueroa</a>, 
<a href="/search/eess?searchtype=author&query=Nordsletten%2C+D">David Nordsletten</a>, 
<a href="/search/eess?searchtype=author&query=Young%2C+A+A">Alistair A. Young</a>, 
<a href="/search/eess?searchtype=author&query=Marlevi%2C+D">David Marlevi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12068" title="Abstract">arXiv:2311.12068</a> (replaced) [<a href="/pdf/2311.12068" title="Download PDF">pdf</a>, <a href="/format/2311.12068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Novel Object Detection via Cooperative Foundational Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bharadwaj%2C+R">Rohit Bharadwaj</a>, 
<a href="/search/cs?searchtype=author&query=Naseer%2C+M">Muzammal Naseer</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S">Salman Khan</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+F+S">Fahad Shahbaz Khan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code: <a href="https://github.com/rohit901/cooperative-foundational-models">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12144" title="Abstract">arXiv:2311.12144</a> (replaced) [<a href="/pdf/2311.12144" title="Download PDF">pdf</a>, <a href="/ps/2311.12144" title="Download PostScript">ps</a>, <a href="/format/2311.12144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applications of Large Scale Foundation Models for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yue Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhu Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages. arXiv admin note: text overlap with <a href="/abs/2304.03589">arXiv:2304.03589</a>, <a href="/abs/2111.05849">arXiv:2111.05849</a>, <a href="/abs/2306.03000">arXiv:2306.03000</a>, <a href="/abs/2301.02691">arXiv:2301.02691</a>, <a href="/abs/2309.16292">arXiv:2309.16292</a>, <a href="/abs/2309.17080">arXiv:2309.17080</a>, <a href="/abs/2309.10228">arXiv:2309.10228</a>, <a href="/abs/2310.01415">arXiv:2310.01415</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12161" title="Abstract">arXiv:2311.12161</a> (replaced) [<a href="/pdf/2311.12161" title="Download PDF">pdf</a>, <a href="/format/2311.12161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChemScraper: Graphics Extraction, Molecular Diagram Parsing, and  Annotated Data Generation for PDF Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shah%2C+A+K">Ayush Kumar Shah</a>, 
<a href="/search/cs?searchtype=author&query=Amador%2C+B+M">Bryan Manrique Amador</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+A">Abhisek Dey</a>, 
<a href="/search/cs?searchtype=author&query=Creekmore%2C+M">Ming Creekmore</a>, 
<a href="/search/cs?searchtype=author&query=Ocampo%2C+B">Blake Ocampo</a>, 
<a href="/search/cs?searchtype=author&query=Denmark%2C+S">Scott Denmark</a>, 
<a href="/search/cs?searchtype=author&query=Zanibbi%2C+R">Richard Zanibbi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages without references, 10 figures, 3 Tables, submitted to International Journal on Document Analysis and Recognition (IJDAR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12166" title="Abstract">arXiv:2311.12166</a> (replaced) [<a href="/pdf/2311.12166" title="Download PDF">pdf</a>, <a href="/ps/2311.12166" title="Download PostScript">ps</a>, <a href="/format/2311.12166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Creating Temporally Correlated High-Resolution Power Injection Profiles  Using Physics-Aware GAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shah%2C+H+G">Hritik Gopal Shah</a>, 
<a href="/search/eess?searchtype=author&query=Azimian%2C+B">Behrouz Azimian</a>, 
<a href="/search/eess?searchtype=author&query=Pal%2C+A">Anamitra Pal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12198" title="Abstract">arXiv:2311.12198</a> (replaced) [<a href="/pdf/2311.12198" title="Download PDF">pdf</a>, <a href="/format/2311.12198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PhysGaussian: Physics-Integrated 3D Gaussians for Generative Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+T">Tianyi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zong%2C+Z">Zeshun Zong</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Y">Yuxing Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yutao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Chenfanfu Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12207" title="Abstract">arXiv:2311.12207</a> (replaced) [<a href="/pdf/2311.12207" title="Download PDF">pdf</a>, <a href="/ps/2311.12207" title="Download PostScript">ps</a>, <a href="/format/2311.12207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Defense semantics of argumentation: revisit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+B">Beishui Liao</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Torre%2C+L">Leendert van der Torre</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/1705.00303">arXiv:1705.00303</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12437" title="Abstract">arXiv:2311.12437</a> (replaced) [<a href="/pdf/2311.12437" title="Download PDF">pdf</a>, <a href="/format/2311.12437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Site-specific Styles for Multi-institutional Unsupervised  Cross-modality Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Han Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yubo Fan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhoubing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Dawant%2C+B+M">Benoit M. Dawant</a>, 
<a href="/search/cs?searchtype=author&query=Oguz%2C+I">Ipek Oguz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> crossMoDA 2023 challenge 1st place solution
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12467" title="Abstract">arXiv:2311.12467</a> (replaced) [<a href="/pdf/2311.12467" title="Download PDF">pdf</a>, <a href="/format/2311.12467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GLAD: Global-Local View Alignment and Background Debiasing for  Unsupervised Video Domain Adaptation with Large Domain Gap
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hyogun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Bae%2C+K">Kyungho Bae</a>, 
<a href="/search/cs?searchtype=author&query=Ha%2C+S+J">Seong Jong Ha</a>, 
<a href="/search/cs?searchtype=author&query=Ko%2C+Y">Yumin Ko</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+G">Gyeong-Moon Park</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jinwoo Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is an accepted WACV 2024 paper. Our code is available at <a href="https://github.com/KHUVLL/GLAD">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12526" title="Abstract">arXiv:2311.12526</a> (replaced) [<a href="/pdf/2311.12526" title="Download PDF">pdf</a>, <a href="/format/2311.12526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Network Pruning by Gradient Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+R">Ruyi Tao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12538" title="Abstract">arXiv:2311.12538</a> (replaced) [<a href="/pdf/2311.12538" title="Download PDF">pdf</a>, <a href="/format/2311.12538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-Context Learning Functions with Varying Number of Minima
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oniani%2C+D">David Oniani</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanshan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12550" title="Abstract">arXiv:2311.12550</a> (replaced) [<a href="/pdf/2311.12550" title="Download PDF">pdf</a>, <a href="/format/2311.12550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable Anomaly Detection using Masked Latent Generative Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Daesoo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Malacarne%2C+S">Sara Malacarne</a>, 
<a href="/search/cs?searchtype=author&query=Aune%2C+E">Erlend Aune</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12603" title="Abstract">arXiv:2311.12603</a> (replaced) [<a href="/pdf/2311.12603" title="Download PDF">pdf</a>, <a href="/format/2311.12603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Surgical Temporal Action-aware Network with Sequence Regularization for  Phase Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+Y">Yuhao Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinqiao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12655" title="Abstract">arXiv:2311.12655</a> (replaced) [<a href="/pdf/2311.12655" title="Download PDF">pdf</a>, <a href="/format/2311.12655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hand-Eye Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Horaud%2C+R">Radu Horaud</a>, 
<a href="/search/cs?searchtype=author&query=Dornaika%2C+F">Fadi Dornaika</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Robotics Research 14(3), 1995
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12764" title="Abstract">arXiv:2311.12764</a> (replaced) [<a href="/pdf/2311.12764" title="Download PDF">pdf</a>, <a href="/format/2311.12764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating Weight-Perturbed Deep Neural Networks With Application in  Iris Presentation Attack Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+R">Renu Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Sony%2C+R">Redwan Sony</a>, 
<a href="/search/cs?searchtype=author&query=Ross%2C+A">Arun Ross</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item333">Cross-lists</a></li>
<li><a href="#item393">Replacements</a></li>
</ul>
<small>[ total of 567 entries:  <b>1-567</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2311">2311</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
